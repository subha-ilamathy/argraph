<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d9" for="edge" attr.name="file_path" attr.type="string"/>
<key id="d8" for="edge" attr.name="source_id" attr.type="string"/>
<key id="d7" for="edge" attr.name="keywords" attr.type="string"/>
<key id="d6" for="edge" attr.name="description" attr.type="string"/>
<key id="d5" for="edge" attr.name="weight" attr.type="double"/>
<key id="d4" for="node" attr.name="file_path" attr.type="string"/>
<key id="d3" for="node" attr.name="source_id" attr.type="string"/>
<key id="d2" for="node" attr.name="description" attr.type="string"/>
<key id="d1" for="node" attr.name="entity_type" attr.type="string"/>
<key id="d0" for="node" attr.name="entity_id" attr.type="string"/>
<graph edgedefault="undirected"><node id="Preprint">
  <data key="d0">Preprint</data>
  <data key="d1">Study Design</data>
  <data key="d2">A pre-publication version of the case study discussing complex question answering.&lt;SEP&gt;A preliminary research publication shared publicly before peer review, providing early insights into methodology and findings.&lt;SEP&gt;A preliminary version of a research paper shared publicly before peer review, providing early insights into the methodology and findings.&lt;SEP&gt;A preliminary version of a research paper shared publicly before peer review.&lt;SEP&gt;A preliminary version of a scientific or technical document shared publicly before formal peer review, used to present new ideas and methodologies.&lt;SEP&gt;A preliminary version of a scientific or technical document shared publicly before peer review, used to present new research ideas and methodologies.&lt;SEP&gt;A preprint version of a research paper or study, indicating early dissemination of research findings.&lt;SEP&gt;A version of a research paper shared before peer review, indicating preliminary dissemination of findings.&lt;SEP&gt;The document appears to be a preprint or draft, containing example prompts and schema information.&lt;SEP&gt;The text is a preprint or draft, providing instructions and example prompts for database querying tasks.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956&lt;SEP&gt;chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-9cee6a97737c75b57f27605ea82e4163&lt;SEP&gt;chunk-06f4652e3f59fe7bb73c99f5346f2b82&lt;SEP&gt;chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSP Y">
  <data key="d0">DSP Y</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A programming model designed to compose, optimize, and implement language model (LM) pipelines as text transformation graphs, enabling systematic development beyond manual prompt engineering.&lt;SEP&gt;A programming model introduced for composing and optimizing language model (LM) pipelines as text transformation graphs, enabling systematic development beyond manual prompt engineering.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Declarative Language">
  <data key="d0">Declarative Language</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A formal approach for defining LM pipelines as modular, parameterized components that can learn and optimize prompt, finetuning, augmentation, and reasoning techniques.&lt;SEP&gt;A formal framework where LM pipelines are represented as modular, parameterized, and learnable components, facilitating systematic composition and optimization.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Self-Improving Pipelines">
  <data key="d0">Self-Improving Pipelines</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Automated LM pipelines capable of learning from demonstrations and optimizing themselves to maximize task performance.&lt;SEP&gt;Automated LM pipelines that can optimize their own performance metrics through learning and composition of modules.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Language Models (LMs)">
  <data key="d0">Language Models (LMs)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Artificial intelligence models trained on large text corpora to generate or understand human language, used in various NLP tasks.&lt;SEP&gt;Artificial intelligence models trained on large text datasets to perform tasks such as reasoning, question answering, and retrieval, used as the primary processing units in DSP Y pipelines.&lt;SEP&gt;Artificial intelligence models trained to understand, generate, and manipulate human language, central to the framework for text transformation and processing.&lt;SEP&gt;Artificial intelligence models trained to understand, generate, and manipulate human language, central to the system described.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompting Techniques">
  <data key="d0">Prompting Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods for eliciting desired responses from LMs by providing specific input instructions or demonstrations, such as few-shot prompting, Chain of Thought, and ReAct.&lt;SEP&gt;Methods for eliciting desired responses from LMs, including few-shot, chain of thought, and reasoning prompts, which are formalized and optimized within DSP Y.&lt;SEP&gt;Methods such as zero-shot or few-shot prompting used to elicit LLMs to generate executable commands or scripts for calling domain tools.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Pipeline Optimization">
  <data key="d0">Pipeline Optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for automatically improving the structure and prompts of LM pipelines to maximize performance metrics.&lt;SEP&gt;Techniques involving automatic search, parameter tuning, and module composition to improve the performance of LM pipelines according to specific metrics.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Math Word Problems Reasoning">
  <data key="d0">Math Word Problems Reasoning</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A case study demonstrating DSP Y's capability to develop pipelines that reason about mathematical problems, outperforming standard approaches.&lt;SEP&gt;A case study demonstrating the use of DSPy to develop pipelines that reason about mathematical problems using LMs.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Multi-hop Retrieval">
  <data key="d0">Multi-hop Retrieval</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A case study illustrating DSP Y's effectiveness in designing pipelines that perform complex, multi-step information retrieval tasks.&lt;SEP&gt;A case study showing how DSPy pipelines can perform complex information retrieval across multiple sources or steps.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Complex Question Answering">
  <data key="d0">Complex Question Answering</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A case study illustrating the application of DSPy for answering intricate questions requiring reasoning and multiple inference steps.&lt;SEP&gt;A case study showing DSP Y's ability to construct pipelines that answer intricate, multi-faceted questions requiring reasoning.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Agent Loops">
  <data key="d0">Agent Loops</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A case study exploring the control of iterative agent behaviors within LM pipelines using DSPy.&lt;SEP&gt;A case study exploring the use of DSP Y to control iterative agent behaviors within pipelines for tasks like reasoning and decision-making.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GPT-3.5">
  <data key="d0">GPT-3.5</data>
  <data key="d1">Tools</data>
  <data key="d2">A closed-source language model from OpenAI, instruction-tuned and aligned to human preferences, accessible via API, used for inference and code generation tasks.&lt;SEP&gt;A language model used to evaluate whether DSPy-optimized systems outperform hand-crafted prompt systems, assessing performance improvements with smaller models.&lt;SEP&gt;A large language model developed by OpenAI, used as a baseline in experiments comparing prompting and pipeline optimization techniques.&lt;SEP&gt;A state-of-the-art large language model by OpenAI, used as a benchmark to evaluate the effectiveness of DSP Y-optimized pipelines.&lt;SEP&gt;A state-of-the-art large language model developed by OpenAI, used as a benchmark for AI capabilities.&lt;SEP&gt;A state-of-the-art large language model developed by OpenAI, used as a benchmark for performance comparison.&lt;SEP&gt;Investigating whether DSPy programs can outperform systems with hand-crafted prompts using smaller language models.&lt;SEP&gt;GPT-3.5 is an advanced language model from OpenAI, known for high performance in language understanding and generation.&lt;SEP&gt;A large language model used for evaluation purposes in the research.&lt;SEP&gt;An advanced GPT model assessed for pass@1, speedup, and efficiency in parallel code generation and translation tasks.&lt;SEP&gt;An advanced language model from the GPT series, evaluated for performance in parallel code generation and efficiency.&lt;SEP&gt;GPT-3.5 is a closed-source language model from OpenAI, instruction-tuned and aligned to human preferences, accessed via API, used for inference and code-related tasks.&lt;SEP&gt;GPT-3.5 is a proprietary language model by OpenAI, capable of code generation and understanding, with performance evaluated via pass@1.&lt;SEP&gt;GPT-3.5 is an OpenAI language model known for strong natural language and code generation capabilities, outperforming GPT-4 in certain parallel code benchmarks.&lt;SEP&gt;GPT-3.5 is an advanced version of OpenAI's Generative Pre-trained Transformer, known for strong natural language and code generation capabilities, and performs better than GPT-4 in certain parallel code tasks.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-061790de1df7d16a1cc9252b2f75290c&lt;SEP&gt;chunk-ed0f2ed4617819fd44b380fe3e3951f0&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Llama2-13b-Chat">
  <data key="d0">Llama2-13b-Chat</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A smaller open-source language model used in experiments to evaluate the performance gains achieved by DSP Y pipelines.&lt;SEP&gt;A smaller, open-source language model used in experiments to evaluate DSPy pipeline performance.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Performance Metrics">
  <data key="d0">Performance Metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics such as Pass@1 scores quantify the effectiveness of models in generating MPI code, with results indicating performance improvements with more data for smaller models.&lt;SEP&gt;Metrics used to evaluate the success of fine-tuned models in generating parallel code, such as accuracy or code quality assessments.&lt;SEP&gt;Quantitative measures such as accuracy improvements (over 25%, 65%, etc.) used to evaluate the effectiveness of optimized LM pipelines.&lt;SEP&gt;Quantitative measures such as accuracy improvements (over 25%, 65%, etc.) used to evaluate the success of pipeline optimization techniques.&lt;SEP&gt;Metrics such as pass@1 are used to evaluate the correctness and quality of generated code by LLMs.&lt;SEP&gt;Newly developed metrics to evaluate the effectiveness and quality of generated code, including correctness and performance aspects.&lt;SEP&gt;Novel metrics introduced to evaluate how well generated code performs across different problem types and parallel programming models.&lt;SEP&gt;The quantitative measures such as speedup, efficiency, and maximum speedup used to evaluate the performance of generated parallel code.&lt;SEP&gt;Metrics such as network cost, execution cost, and data reuse quantify the efficiency of data transfer, task execution, and resource utilization during optimization.&lt;SEP&gt;Metrics such as runtime in seconds are used to quantify the efficiency of code, comparing baseline, hand-tuned, and generated versions.&lt;SEP&gt;Metrics such as runtime in seconds quantify the efficiency of code, enabling comparison between baseline, hand-tuned, and generated versions.&lt;SEP&gt;Performance metrics are the evaluation criteria used to measure the effectiveness of the model on downstream tasks, including correctness of generated code and accuracy of performance predictions.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-aebb652b359c14534612e14559754bbc&lt;SEP&gt;chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Compiler">
  <data key="d0">Compiler</data>
  <data key="d1">Tools</data>
  <data key="d2">A component of DSPy that automatically optimizes text transformation graphs for maximum performance according to specified metrics.&lt;SEP&gt;Compilers are tools that can be integrated with AI suggestions to refine and validate generated code.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Text Transformation Graphs">
  <data key="d0">Text Transformation Graphs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Structured representations of LM pipelines composed of interconnected modules that perform sequential or parallel text processing tasks.&lt;SEP&gt;Structured representations of LM pipelines where modules are connected to perform sequential or parallel text processing tasks.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt Templates">
  <data key="d0">Prompt Templates</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Manual, handcrafted prompts used in traditional LM pipelines, which DSP Y aims to replace with modular, learnable components for scalability.&lt;SEP&gt;Manual, handcrafted strings used to prompt LMs, which DSPy aims to replace with modular, learnable components.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Finetuning">
  <data key="d0">Finetuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of further training LMs on specific data to improve task performance, integrated into DSPy modules.&lt;SEP&gt;The process of further training LMs on task-specific data, integrated as modules within DSP Y pipelines to improve task performance.&lt;SEP&gt;The process of training a pre-existing language model further on specific datasets to improve performance on targeted tasks like code generation.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Augmentation">
  <data key="d0">Augmentation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for enriching prompts or training data with additional information or sources to enhance LM responses.&lt;SEP&gt;Techniques for enriching training data or prompts with additional information to enhance LM responses.&lt;SEP&gt;The process of incorporating domain-specific knowledge into the model or its inputs/outputs, such as through data augmentation, prompt design, or external tools.&lt;SEP&gt;The process of incorporating domain-specific knowledge into the model or its inputs/outputs, such as through fine-tuning or prompt design.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Reasoning Techniques">
  <data key="d0">Reasoning Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods like Chain of Thought or ReAct that enable LMs to perform multi-step logical reasoning.&lt;SEP&gt;Methods such as Chain of Thought and ReAct that enable LMs to perform multi-step logical or inferential reasoning within pipelines.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Compiling">
  <data key="d0">Compiling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of transforming high-level DSP Y programs into optimized executable pipelines, including automatic optimization for performance metrics.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Optimizer">
  <data key="d0">Optimizer</data>
  <data key="d1">Tools</data>
  <data key="d2">A component of DSP Y that automatically searches for and applies pipeline configurations to maximize specified performance metrics.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Math Word Problems">
  <data key="d0">Math Word Problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Complex problems involving mathematical reasoning, used as benchmarks for evaluating DSP Y's reasoning capabilities.&lt;SEP&gt;The set of problem scenarios involving counting, sharing, and planting, used to explore computational problem-solving.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Question Answering">
  <data key="d0">Question Answering</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Tasks involving generating accurate responses to complex or multi-faceted questions, targeted by DSP Y pipelines.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Retrieval">
  <data key="d0">Retrieval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Retrieval involves fetching relevant documents or information from large datasets or knowledge bases to support tasks like question answering and content generation.&lt;SEP&gt;Retrieval involves fetching relevant information or documents from a large dataset or knowledge base, often as part of a hybrid NLP model like RAG to improve factual accuracy.&lt;SEP&gt;The process of fetching relevant information from sources, which DSP Y pipelines can perform in multi-hop or complex retrieval tasks.&lt;SEP&gt;The process of searching Wikipedia to find relevant evidence supporting or refuting claims in the FEVER task.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Pipeline">
  <data key="d0">Pipeline</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A structured composition of modular components (modules) that collectively perform complex NLP tasks in DSP Y.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Modules">
  <data key="d0">Modules</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Composable components within the text transformation graph that perform specific functions in processing or transforming text.&lt;SEP&gt;Individual components within DSP Y pipelines that perform specific functions such as prompting, finetuning, augmentation, or reasoning.&lt;SEP&gt;Modules are components within DSPy that replace hand-crafted prompts, allowing for flexible, reusable pipeline units that can be composed arbitrarily.&lt;SEP&gt;Modules in DSPy are reusable, parameterized components like ChainOfThought that implement specific prompting strategies for different tasks.&lt;SEP&gt;Modules in DSPy, such as ChainOfThought, are reusable, parameterized components that implement specific prompting strategies for various tasks.&lt;SEP&gt;Reusable, composable components within the text transformation graph that perform specific processing or transformation functions on language data.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85&lt;SEP&gt;chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Performance Improvements">
  <data key="d0">Performance Improvements</data>
  <data key="d1">Results</data>
  <data key="d2">Significant accuracy gains (over 25%, 65%, etc.) demonstrated by DSP Y-optimized pipelines when using models like GPT-3.5 and Llama2-13b-chat.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Comparison with Expert-Created Demonstrations">
  <data key="d0">Comparison with Expert-Created Demonstrations</data>
  <data key="d1">Results</data>
  <data key="d2">DSP Y pipelines with minimal code outperform pipelines built with manually crafted demonstrations, achieving up to 5-46% improvements.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Open-Source">
  <data key="d0">Open-Source</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">DSP Y is available publicly on GitHub, enabling broader adoption and further research in systematic LM pipeline development.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Optimization Techniques">
  <data key="d0">Optimization Techniques</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Algorithms and methods used within the compiler to automatically optimize text transformation graphs for maximum performance.&lt;SEP&gt;Optimization techniques include reordering, hardware mapping, inlining, and loop unrolling, used to improve performance.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Systematic Approach">
  <data key="d0">Systematic Approach</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A methodology that replaces manual prompt engineering with modular, learnable components and automated optimization for scalable, robust LM pipelines.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt Engineering">
  <data key="d0">Prompt Engineering</data>
  <data key="d1">Methodologies</data>
  <data key="d2">DSPy enhances prompt engineering by providing structured, reusable, and adaptable modules to improve language model performance and reliability.&lt;SEP&gt;Prompt engineering is a challenge in current LM workflows, often requiring manual effort to craft effective prompts, which DSPy aims to address through modular and automated approaches.&lt;SEP&gt;Prompt engineering refers to the manual, often labor-intensive process of designing prompts, which DSPy aims to mitigate through modular, automated units and high-level abstractions.&lt;SEP&gt;The practice of designing and crafting prompts to guide language models toward desired outputs, emphasizing the role of hand-written, task-specific prompts.&lt;SEP&gt;The practice of designing, refining, and optimizing prompts to elicit desired outputs from language models, emphasizing the importance of task-specific prompt design.&lt;SEP&gt;Traditional manual crafting of prompts, which DSP Y aims to automate and formalize through modular, learnable components.&lt;SEP&gt;Prompt engineering involves designing input prompts to guide AI models like Codex to generate accurate and relevant HPC kernels, aiming to optimize output quality.&lt;SEP&gt;Prompt engineering involves designing input prompts to optimize code generation quality from AI models for scientific computing."|&gt;&lt;SEP&gt;The process of designing and structuring input prompts to guide AI models like Codex to produce accurate and relevant HPC kernels, optimizing output quality.&lt;SEP&gt;Designing prompts to steer the model's outputs toward domain-specific responses without changing internal parameters.&lt;SEP&gt;The process of designing prompts to effectively elicit desired responses from LLMs.&lt;SEP&gt;Designing inputs to guide models toward desired outputs, used to evaluate and enhance model performance.&lt;SEP&gt;Prompt engineering involves designing and refining prompts to guide Codex's outputs effectively for various tasks such as code suggestion, decision support, and search queries.&lt;SEP&gt;Prompt engineering involves designing prompts to effectively guide Codex's outputs for tasks like code suggestion and decision support.&lt;SEP&gt;Techniques used to elicit specific behaviors from models by carefully designing input prompts to enhance task performance.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85&lt;SEP&gt;chunk-50450e84744379a5c4f059c7d4f84019&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482&lt;SEP&gt;chunk-735818e62b066d03c2144cdb5db162c1&lt;SEP&gt;chunk-daac5179ef8fa77fe775da37eb1276f3&lt;SEP&gt;chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Multi-stage Pipelines">
  <data key="d0">Multi-stage Pipelines</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Complex pipelines composed of multiple modules and stages, enabling sophisticated reasoning and task decomposition in DSP Y.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Task Decomposition">
  <data key="d0">Task Decomposition</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A conceptual framework where complex tasks are broken down into smaller, manageable subtasks, often facilitated by LLMs acting as task planners or controllers to coordinate multiple tools.&lt;SEP&gt;Breaking down complex tasks into manageable modules or steps within DSP Y pipelines to improve reasoning and performance.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Automation">
  <data key="d0">Automation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The process of automatically designing, optimizing, and deploying LM pipelines to improve scalability and performance.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Learning">
  <data key="d0">Learning</data>
  <data key="d1">Variables</data>
  <data key="d2">The process by which DSP Y modules adjust parameters based on demonstrations or feedback to improve task performance.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="layers">
  <data key="d0">layers</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Layers are modular components that can be combined to form complex architectures, enabling flexible system design and scalability.&lt;SEP&gt;Layers refer to modular components that can be assembled to build complex architectures, allowing flexible and scalable system design.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="model weights">
  <data key="d0">model weights</data>
  <data key="d1">Variables</data>
  <data key="d2">Model weights are parameters within a model that can be trained using optimization algorithms, allowing the model to learn and adapt.&lt;SEP&gt;Model weights are parameters within a model that can be trained using optimizers, as opposed to being manually tuned, enabling adaptive learning.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy programming model">
  <data key="d0">DSPy programming model</data>
  <data key="d1">Methodologies</data>
  <data key="d2">DSPy is a novel programming framework that translates prompting techniques into parameterized, task-adaptive modules, facilitating flexible NLP pipeline construction and self-improvement.&lt;SEP&gt;DSPy is a proposed programming framework that translates prompting techniques into modular, parameterized components, facilitating task adaptation and self-improvement in NLP systems.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="string-based prompting techniques">
  <data key="d0">string-based prompting techniques</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Techniques that involve creating prompts from strings to guide model behavior, including complex methods like Chain of Thought and ReAct.&lt;SEP&gt;These techniques involve generating prompts from strings to guide model behavior, including complex, task-dependent methods like Chain of Thought and ReAct.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Chain of Thought">
  <data key="d0">Chain of Thought</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A prompting approach that encourages models to generate intermediate reasoning steps, improving performance on complex tasks.&lt;SEP&gt;A prompting technique that encourages models to generate intermediate reasoning steps, improving complex problem-solving.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ReAct">
  <data key="d0">ReAct</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A prompting approach combining reasoning and acting, enabling models to interact with environments or tools effectively.&lt;SEP&gt;A prompting approach combining reasoning and acting, enabling models to interact with external tools or APIs during inference.&lt;SEP&gt;A prompting method that combines reasoning and acting by interacting with external tools or APIs during inference.&lt;SEP&gt;A prompting technique combining reasoning and acting, allowing models to interact with external environments or tools effectively.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c&lt;SEP&gt;chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="declarative modules">
  <data key="d0">declarative modules</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Modules in DSPy that carry natural-language signatures and perform specific text transformations, serving as building blocks for flexible pipelines.&lt;SEP&gt;Modules that carry natural-language signatures and perform specific text transformations, forming the building blocks of DSPy pipelines.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="neural network layers">
  <data key="d0">neural network layers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Layers within neural networks that process data, analogous to DSPy modules in the programming model.&lt;SEP&gt;Layers within neural networks that process data, analogous to DSPy modules, used for building deep learning architectures.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="bootstrapping demonstrations">
  <data key="d0">bootstrapping demonstrations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of iteratively training modules by providing useful example demonstrations to learn desired behaviors.&lt;SEP&gt;The process of iteratively training modules by providing useful examples, enabling modules to learn desired behaviors.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="PyTorch abstractions">
  <data key="d0">PyTorch abstractions</data>
  <data key="d1">Tools</data>
  <data key="d2">A set of software tools and conventions for building and training neural networks, inspiring the design of DSPy modules.&lt;SEP&gt;Software abstractions inspired by PyTorch that facilitate flexible construction of models and computational graphs, influencing DSPy design.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="computational graphs">
  <data key="d0">computational graphs</data>
  <data key="d1">Tools</data>
  <data key="d2">Dynamic graphs representing data flow and operations in DSPy, enabling flexible control flow and module connections.&lt;SEP&gt;Dynamic structures representing the flow of computations in DSPy, allowing flexible control flow and module connections.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy compiler">
  <data key="d0">DSPy compiler</data>
  <data key="d1">Tools</data>
  <data key="d2">A component that optimizes DSPy programs by simulating, self-improving, and constructing effective prompt and finetuning strategies based on input data.&lt;SEP&gt;A software component that optimizes DSPy programs for quality and cost, using simulation and self-improvement strategies.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="teleprompters">
  <data key="d0">teleprompters</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Optimization strategies within DSPy that automatically determine how modules learn from data, improving performance and efficiency.&lt;SEP&gt;Optimization strategies within DSPy that determine how modules learn from data, enhancing program performance.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="multi-hop question answering">
  <data key="d0">multi-hop question answering</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A case study exploring DSPy’s application to complex reasoning tasks requiring multiple reasoning steps across different pieces of information.&lt;SEP&gt;A case study exploring how DSPy can be applied to complex question answering tasks requiring reasoning across multiple information pieces.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="math word problems">
  <data key="d0">math word problems</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A case study evaluating DSPy's effectiveness in solving mathematical word problems using optimized pipelines.&lt;SEP&gt;A case study evaluating DSPy’s capability to solve math word problems, demonstrating its reasoning and pipeline optimization.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="llama2-13b-chat">
  <data key="d0">llama2-13b-chat</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A large language model (LLM) with 13 billion parameters, used here as a competitive baseline for AI performance.&lt;SEP&gt;A large language model with 13 billion parameters, used here as a competitive baseline for AI performance in language tasks.&lt;SEP&gt;A smaller language model tested within DSPy frameworks to evaluate effectiveness and efficiency gains.&lt;SEP&gt;Assessing the efficiency and performance of DSPy-optimized pipelines with smaller language models like llama2-13b-chat.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c&lt;SEP&gt;chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="T5-Large">
  <data key="d0">T5-Large</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A large language model used to assess the impact of DSPy on program quality and computational efficiency.&lt;SEP&gt;A large language model with 770M parameters, used for finetuning experiments to assess capacity and performance.&lt;SEP&gt;A pre-trained large language model with 770 million parameters, used for finetuning experiments.&lt;SEP&gt;Evaluating DSPy's ability to improve program quality and efficiency with different language models.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="self-improving NLP systems">
  <data key="d0">self-improving NLP systems</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Designing NLP pipelines that can bootstrap and enhance their own performance through modular, optimized components.&lt;SEP&gt;NLP systems that can bootstrap, self-optimize, and enhance their performance through modular, optimized pipelines enabled by DSPy.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Radford et al. 2018">
  <data key="d0">Radford et al. 2018</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Radford et al. 2018 discusses foundational mechanisms for programming foundation models, emphasizing the role of instruction tuning and prompting in eliciting complex behaviors from language models.&lt;SEP&gt;Radford et al. 2018 is a foundational work that discusses mechanisms for foundation model programming, emphasizing the importance of instruction tuning and prompting techniques in eliciting sophisticated behaviors from language models.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Brown et al. 2020">
  <data key="d0">Brown et al. 2020</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Brown et al. 2020 contributes to understanding foundation models, highlighting their capabilities and the role of instruction tuning.&lt;SEP&gt;Brown et al. 2020 provides insights into the capabilities and understanding of foundation models, supporting the development and application of instruction tuning and prompting techniques.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Instruction Tuning">
  <data key="d0">Instruction Tuning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Instruction tuning is a process by which language models are fine-tuned with specific instructions to elicit desired behaviors, improving their task performance.&lt;SEP&gt;Instruction tuning is a process that involves fine-tuning models with specific instructions to improve their ability to perform tasks based on prompts or directives.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompting">
  <data key="d0">Prompting</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Prompting involves providing input prompts to language models to guide their responses, enabling task-specific outputs without retraining the model.&lt;SEP&gt;Prompting involves providing specific input prompts to language models to guide their responses, enabling task-specific outputs without retraining the models.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Weak Supervision">
  <data key="d0">Weak Supervision</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Weak supervision refers to training or guiding models using indirect or less explicit signals, often through heuristics or indirect tasks, to improve performance.&lt;SEP&gt;Weak supervision refers to training or guiding models using indirect signals, heuristics, or less explicit labels, often to reduce the need for extensive labeled data.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="In-context Learning">
  <data key="d0">In-context Learning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">In-context learning is a paradigm where language models learn to perform tasks by conditioning on examples or instructions provided within the input context, without parameter updates.&lt;SEP&gt;In-context learning is a paradigm where language models learn to perform tasks by conditioning on provided examples or instructions within the input, without updating model parameters.&lt;SEP&gt;The ability of LLMs to perform tasks based on context provided within prompts, without explicit parameter updates.&lt;SEP&gt;The ability of LLMs to perform tasks based on context within prompts without explicit parameter updates, relying on learned representations.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Tools">
  <data key="d0">Tools</data>
  <data key="d1">Tools</data>
  <data key="d2">Instruments, software, or resources utilized to collect, analyze, or interpret data.&lt;SEP&gt;Modules and functionalities supporting various operations within DSPy, such as retrieval, code execution, and pipeline management.&lt;SEP&gt;Refers to the modules and functionalities supporting retrieval, execution, and integration of computation within the DSPy framework, such as retrieval models and code execution modules.&lt;SEP&gt;Tools include retrieval models, multimodal foundation models, APIs, calculators, and toolkits like LangChain, Semantic Kernel, LlamaIndex, which facilitate the integration and enhancement of language model capabilities.&lt;SEP&gt;Tools include retrieval models, multimodal foundation models, APIs, calculators, and toolkits like LangChain, Semantic Kernel, LlamaIndex, which facilitate the integration, retrieval, and enhancement of language model functionalities.&lt;SEP&gt;The process utilizes natural language processing techniques and systematic extraction methods to identify entities and relationships.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Retrieval Models">
  <data key="d0">Retrieval Models</data>
  <data key="d1">Tools</data>
  <data key="d2">Retrieval models are used within language model pipelines to fetch relevant external information, supporting tasks like question answering, fact retrieval, and knowledge augmentation.&lt;SEP&gt;Retrieval models are used within language model pipelines to fetch relevant information from external sources, supporting tasks like question answering and knowledge retrieval.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Multimodal Foundation Models">
  <data key="d0">Multimodal Foundation Models</data>
  <data key="d1">Tools</data>
  <data key="d2">Multimodal foundation models process and integrate multiple data modalities (e.g., text, images) to support complex tasks involving diverse data types.&lt;SEP&gt;Multimodal foundation models process and integrate multiple data modalities, such as text and images, to support complex tasks requiring diverse data inputs.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="APIs">
  <data key="d0">APIs</data>
  <data key="d1">Tools</data>
  <data key="d2">APIs (Application Programming Interfaces) provide programmatic access to external services or functionalities that can be integrated into language model workflows.&lt;SEP&gt;APIs (Application Programming Interfaces) provide programmatic access to external services, data, or functionalities, enabling language models to leverage additional resources.&lt;SEP&gt;APIs provide external access to LLMs, enabling techniques like external augmentation and prompt-based methods without internal access.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Calculators">
  <data key="d0">Calculators</data>
  <data key="d1">Tools</data>
  <data key="d2">Calculators are computational tools integrated into pipelines to perform mathematical or logical calculations, supporting tasks requiring precise computation.&lt;SEP&gt;Calculators are computational tools used within language model pipelines for performing calculations or mathematical reasoning.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="LangChain, Semantic Kernel, LlamaIndex">
  <data key="d0">LangChain, Semantic Kernel, LlamaIndex</data>
  <data key="d1">Tools</data>
  <data key="d2">These are specific toolkits designed to facilitate building and managing language model pipelines, enabling chaining, retrieval, and agent functionalities.&lt;SEP&gt;These are specific toolkits designed to facilitate building, chaining, and managing language model pipelines, providing pre-packaged components and integrations.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt Engineering Challenges">
  <data key="d0">Prompt Engineering Challenges</data>
  <data key="d1">Limitations</data>
  <data key="d2">Prompt engineering challenges refer to the difficulties and manual effort involved in designing effective prompts, often requiring task-specific templates, which DSPy aims to address through modular, automated pipeline construction.&lt;SEP&gt;Prompt engineering challenges refer to the difficulties in designing effective prompts for language models, often requiring manual, task-specific prompt templates, which can be labor-intensive and brittle.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy">
  <data key="d0">DSPy</data>
  <data key="d1">Tools</data>
  <data key="d2">A framework for constructing and compiling question answering programs, including retrieval and reasoning modules.&lt;SEP&gt;A modular programming framework designed to create, compile, and optimize program modules for language model tasks, facilitating modular and adaptable pipelines.&lt;SEP&gt;A modular programming framework that enables the creation, compilation, and optimization of program modules for language model tasks, facilitating flexible and reusable pipeline components.&lt;SEP&gt;A new programming framework for designing AI systems using pipelines of pretrained language models and tools, emphasizing modularity and rapid development.&lt;SEP&gt;A novel programming model designed for constructing AI systems using pipelines of pretrained language models and auxiliary tools, emphasizing rapid development and modularity.&lt;SEP&gt;A programming framework designed for composing, optimizing, and evaluating language model pipelines, enabling automation and efficiency in model deployment.&lt;SEP&gt;A software tool used to automatically generate prompts and manage data processing for question-answering tasks.&lt;SEP&gt;A software tool used to automatically generate prompts, manage data processing, and facilitate the creation of search queries in question-answering tasks.&lt;SEP&gt;DSPy is a framework and programming model that aims to optimize language model pipelines by abstracting prompts and enabling modular, high-level pipeline construction, potentially using optimization techniques like cross-validation, RL, and Bayesian hyperparameter tuning.&lt;SEP&gt;DSPy is a framework and programming model that aims to optimize language model pipelines by abstracting prompts into high-level signatures, modules, and teleprompters, enabling systematic, automated, and modular pipeline design.&lt;SEP&gt;DSPy is a framework designed to enable structured prompting, modular prompt components, and parsing strategies for language models, supporting task-specific and adaptive prompt engineering.&lt;SEP&gt;DSPy is a framework designed to facilitate structured prompting and parsing for language models, enabling task-specific, modular, and parameterized prompt engineering.&lt;SEP&gt;DSPy is a modular programming framework that allows compiling, bootstrapping, and ensembling of programs to enhance language model performance on reasoning tasks.&lt;SEP&gt;DSPy is a modular programming framework that enables compiling, bootstrapping, and ensembling of programs to improve language model reasoning performance, particularly on math word problems.&lt;SEP&gt;DSPy is a programming framework designed for composing, optimizing, and evaluating language model pipelines, emphasizing automation and efficiency.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-ed0f2ed4617819fd44b380fe3e3951f0&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85&lt;SEP&gt;chunk-8e85c7ed399116091462832c72381ba4&lt;SEP&gt;chunk-66e5a3f496b5e1530da70355696b5224&lt;SEP&gt;chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Model Selection Techniques">
  <data key="d0">Model Selection Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Model selection techniques such as cross-validation, reinforcement learning, and hyperparameter optimization are used within DSPy to improve pipeline performance and automate prompt and pipeline configuration.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="High-level Declarative Signatures">
  <data key="d0">High-level Declarative Signatures</data>
  <data key="d1">Methodologies</data>
  <data key="d2">DSPy employs high-level declarative signatures to specify the input/output behavior of modules, facilitating modular pipeline design and optimization.&lt;SEP&gt;High-level declarative signatures define the expected behavior of modules in natural language, facilitating systematic pipeline construction and optimization.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy Compiler">
  <data key="d0">DSPy Compiler</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The DSPy compiler translates high-level pipeline signatures into executable, optimized modular systems, supporting systematic exploration and high-level abstraction.&lt;SEP&gt;The DSPy compiler translates high-level pipeline specifications into optimized, modular language model systems, enabling systematic exploration of design space without hand-crafted prompts.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Benchmark Numbers and Qualitative Measures">
  <data key="d0">Benchmark Numbers and Qualitative Measures</data>
  <data key="d1">Results</data>
  <data key="d2">The empirical evaluation uses benchmark metrics and qualitative assessments to demonstrate DSPy's effectiveness in building prompt-free, modular LM systems.&lt;SEP&gt;The paper reports empirical results demonstrating that DSPy allows building effective LM systems without hand-crafted prompts, using modular units and systematic exploration.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Empirical Findings">
  <data key="d0">Empirical Findings</data>
  <data key="d1">Results</data>
  <data key="d2">Empirical findings show the effectiveness of DSPy in creating high-quality language model systems through modular, automated pipeline construction.&lt;SEP&gt;Empirical results show that DSPy enables constructing high-performance language model pipelines without hand-crafted prompts, emphasizing modularity and systematic optimization.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Modular Units">
  <data key="d0">Modular Units</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Modular units are components within DSPy that replace hand-crafted prompts, enabling flexible and systematic pipeline design.&lt;SEP&gt;Modular units are the core components in DSPy that replace traditional prompts, allowing for flexible, reusable pipeline building blocks.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Rich Design Space">
  <data key="d0">Rich Design Space</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">DSPy facilitates systematic exploration of a broad, high-level design space for language model pipelines, promoting innovation and efficiency in model deployment.&lt;SEP&gt;DSPy opens doors for exploring a rich space of pipeline designs at a high level of abstraction, facilitating innovation and optimization in language model applications.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Systematic Exploration">
  <data key="d0">Systematic Exploration</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Systematic exploration involves methodically testing and optimizing pipeline configurations to improve performance and robustness.&lt;SEP&gt;Systematic exploration refers to methodically investigating various pipeline configurations and parameters to optimize language model performance.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Benchmarking and Qualitative Measures">
  <data key="d0">Benchmarking and Qualitative Measures</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The study employs benchmarking and qualitative measures to evaluate the effectiveness of DSPy in building prompt-free, modular language model systems.&lt;SEP&gt;The study employs benchmarking and qualitative measures to evaluate the effectiveness of the DSPy framework in building language model systems.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="High-level Abstractions">
  <data key="d0">High-level Abstractions</data>
  <data key="d1">Methodologies</data>
  <data key="d2">DSPy employs high-level abstractions such as signatures, modules, and teleprompters to simplify pipeline design and enable systematic optimization.&lt;SEP&gt;DSPy utilizes high-level abstractions like signatures, modules, and teleprompters to simplify and optimize language model pipeline design.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Foundation Models">
  <data key="d0">Foundation Models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Foundation models are large-scale pre-trained models that serve as the basis for various NLP tasks, capable of being fine-tuned or prompted for specific behaviors.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Signatures">
  <data key="d0">Signatures</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Signatures are high-level, natural-language typed declarations that specify input/output behaviors of modules, abstracting prompt design and enabling compilation into optimized prompts.&lt;SEP&gt;Signatures define the interface for inputs and outputs in DSPy, guiding prompt structure and parsing logic for structured tasks.&lt;SEP&gt;Signatures in DSPy define structured input and output schemas for prompts, guiding prompt construction and response parsing to improve consistency and reliability.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Teleprompters">
  <data key="d0">Teleprompters</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Teleprompters are optimization components within DSPy that adjust and optimize all modules in a pipeline to maximize a target metric, often using techniques like model selection, RL, or Bayesian optimization.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Predict">
  <data key="d0">Predict</data>
  <data key="d1">Tools</data>
  <data key="d2">Predict is a core module within DSPy that formats prompts, invokes language models, and parses structured outputs based on defined signatures, supporting various advanced prompting modules like ChainOfThought.&lt;SEP&gt;Predict is a core module within DSPy used to format prompts, call language models, and parse outputs based on defined signatures, supporting various advanced prompting modules.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ChainOfThought">
  <data key="d0">ChainOfThought</data>
  <data key="d1">Tools</data>
  <data key="d2">A class implementing a reasoning process that guides the model to think step-by-step before producing output.&lt;SEP&gt;A reasoning module used within DSPy to generate answers based on a chain of logical steps or context.&lt;SEP&gt;A reasoning module used within DSPy to generate answers through a chain of logical steps, enhancing interpretability and performance.&lt;SEP&gt;ChainOfThought is a DSPy module that enhances reasoning by prompting models to think step-by-step before producing an answer, thereby improving interpretability and accuracy.&lt;SEP&gt;ChainOfThought is a DSPy module that enhances reasoning by prompting models to think step-by-step before producing an answer.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Structured Prompting">
  <data key="d0">Structured Prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Structured prompting in DSPy involves designing prompts with explicit input/output schemas to improve model performance and reliability.&lt;SEP&gt;Structured prompting involves designing prompts with explicit schemas for inputs and outputs, reducing brittleness and enhancing model performance.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bootstrapping">
  <data key="d0">Bootstrapping</data>
  <data key="d1">Methodology</data>
  <data key="d2">A process of generating and optimizing demonstration chains to self-improve the model's reasoning capabilities.&lt;SEP&gt;A statistical resampling technique involving repeated sampling with replacement to assess the stability, variability, or performance of models or methods, suggested as a dynamic test-time technique.&lt;SEP&gt;A statistical resampling technique that involves repeatedly sampling from data with replacement to estimate the stability or variability of a model or process, mentioned as a dynamic testing approach.&lt;SEP&gt;Bootstrapping in DSPy refers to generating and refining demonstration examples to improve model prompting effectiveness.&lt;SEP&gt;Bootstrapping in DSPy refers to generating and refining demonstration examples to improve prompt effectiveness and model adaptation.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-0696a875ae026175ba36c9e8529f7efd&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Self-Improving and Pipeline-Adaptive Prompts">
  <data key="d0">Self-Improving and Pipeline-Adaptive Prompts</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">DSPy enables prompts that can adapt and improve over time or across different tasks through structured signatures and modules.&lt;SEP&gt;DSPy supports the development of prompts that can adapt, improve, and evolve over time or across different tasks through structured signatures and modular design.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Brittle String Manipulation">
  <data key="d0">Brittle String Manipulation</data>
  <data key="d1">Limitations</data>
  <data key="d2">Traditional prompt engineering often involves fragile string manipulations, which DSPy aims to reduce through structured, formalized approaches.&lt;SEP&gt;Traditional prompt engineering often relies on fragile string manipulations, which DSPy aims to mitigate through formalized, structured approaches.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Parameterization">
  <data key="d0">Parameterization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">DSPy allows parameterization of prompting techniques, enabling flexible and task-specific prompt configurations.&lt;SEP&gt;The process of defining and configuring parameters that control the behavior of prompting techniques within the system.&lt;SEP&gt;The process of defining and configuring parameters that customize the behavior of the prompting techniques within the system.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt-Based Learning">
  <data key="d0">Prompt-Based Learning</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Prompt-based learning is a methodology within NLP that uses prompts to guide language models for various tasks, supported by DSPy frameworks.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Model Fine-tuning">
  <data key="d0">Model Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Adjustments made to the model parameters to improve performance on specific tasks or knowledge domains, often guided by reward signals.&lt;SEP&gt;Model fine-tuning involves updating the internal parameters of LLMs, through techniques like adapter-based, instruction-based, or partial knowledge updates, to specialize the model for domain-specific tasks.&lt;SEP&gt;Model fine-tuning involves updating the internal parameters of an LLM using domain-specific data, including techniques like adapter-based, instruction-based, or partial knowledge updates.&lt;SEP&gt;The process of adjusting a pre-trained model on domain-specific data to improve its performance in a particular area.&lt;SEP&gt;The process of training a pre-trained model further on domain-specific data to improve task-specific performance, such as code generation in HPC.&lt;SEP&gt;Training process that involves further training of pre-trained models on specialized HPC data to enhance code generation accuracy and relevance.&lt;SEP&gt;While DSPy focuses on prompting, it also impacts model fine-tuning strategies by providing structured prompt data for training or evaluation.&lt;SEP&gt;Fine-tuning in this context refers to adapting pre-trained language models on specific datasets, such as reformatting code samples to improve the model's ability to generate appropriate OpenMP pragmas.&lt;SEP&gt;The process of training pre-trained language models on HPC code datasets to adapt them for specific downstream tasks.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-ce8332c6d0b3d23f38189ff80650d4bc&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Prompt Optimization">
  <data key="d0">Prompt Optimization</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">DSPy facilitates prompt optimization through structured modules and signatures, improving task performance.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="forward the inputs to the sub-module">
  <data key="d0">forward the inputs to the sub-module</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A procedural instruction indicating the process of passing data to a sub-module within a computational system.&lt;SEP&gt;An instruction indicating the process of passing data to a sub-module within a computational framework, facilitating modular processing.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="12 return self.predict(**kwargs)">
  <data key="d0">12 return self.predict(**kwargs)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A code snippet representing a method call to generate predictions based on input parameters.&lt;SEP&gt;A code statement that invokes the prediction function with specified keyword arguments, used for generating model outputs.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="This is a fully-fledged module capable of learning effective few-shot prompting for any LM or task">
  <data key="d0">This is a fully-fledged module capable of learning effective few-shot prompting for any LM or task</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A comprehensive module designed to learn and adapt few-shot prompting strategies applicable across various language models and tasks.&lt;SEP&gt;Describes a comprehensive module designed to learn and implement few-shot prompting techniques applicable across various language models and tasks.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Appendix C">
  <data key="d0">Appendix C</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A referenced section in a document that contains examples or supplementary information related to prompting techniques.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="long reasoning prompts hand-written by sources">
  <data key="d0">long reasoning prompts hand-written by sources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Refers to manually crafted prompts created by various sources, used as examples or benchmarks in prompting research.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy parameterizes these prompting techniques">
  <data key="d0">DSPy parameterizes these prompting techniques</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Indicates that the DSPy framework is designed to systematically adjust and control prompting methods through parameter settings.&lt;SEP&gt;Indicates that the DSPy framework systematically adjusts prompting methods through parameter settings for flexibility and optimization.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="parameters that include: (1) the specific LM to call (Chen et al., 2023), (2) the prompt instructions (Yang et al., 2023) and the string prefix of each signature field and, most importantly, (3) the demonstrations used as few-shot prompts (for frozen LMs) or as training data (for finetuning)">
  <data key="d0">parameters that include: (1) the specific LM to call (Chen et al., 2023), (2) the prompt instructions (Yang et al., 2023) and the string prefix of each signature field and, most importantly, (3) the demonstrations used as few-shot prompts (for frozen LMs) or as training data (for finetuning)</data>
  <data key="d1">Variables</data>
  <data key="d2">Details the specific parameters involved in configuring the prompting system, including model selection, instruction prompts, and demonstration data.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="automatically generating and selecting useful demonstrations">
  <data key="d0">automatically generating and selecting useful demonstrations</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates methods for optimizing the selection and creation of demonstration examples to improve model performance.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="bootstrapping good demonstrations">
  <data key="d0">bootstrapping good demonstrations</data>
  <data key="d1">Methods</data>
  <data key="d2">A technique for iteratively generating and refining examples that teach the model effective behaviors in few-shot learning scenarios.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.Retrieve">
  <data key="d0">dspy.Retrieve</data>
  <data key="d1">Tools</data>
  <data key="d2">A module for retrieving relevant data or passages from external sources, supporting various retrieval backends like ColBERTv2, Pyserini, and Pinecone.&lt;SEP&gt;A retrieval module supporting multiple backends (e.g., ColBERTv2, Pyserini, Pinecone) to fetch relevant data or passages for downstream tasks.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.SQL">
  <data key="d0">dspy.SQL</data>
  <data key="d1">Tools</data>
  <data key="d2">An experimental module enabling execution of SQL queries within the DSPy environment for data manipulation and retrieval.&lt;SEP&gt;Experimental module for executing SQL queries within the DSPy system.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.PythonInterpreter">
  <data key="d0">dspy.PythonInterpreter</data>
  <data key="d1">Tools</data>
  <data key="d2">A sandboxed Python execution environment allowing dynamic code execution within DSPy pipelines.&lt;SEP&gt;Module enabling execution of Python code in a sandbox environment for dynamic computation.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Programs">
  <data key="d0">Programs</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Composable sequences of modules and operations that define a data processing or reasoning pipeline in DSPy.&lt;SEP&gt;Sequences of modules and operations that define data processing or reasoning workflows in DSPy, enabling modular pipeline construction.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy modules">
  <data key="d0">DSPy modules</data>
  <data key="d1">Tools</data>
  <data key="d2">Functional units within DSPy that perform specific tasks such as retrieval, reasoning, or generation, forming the building blocks of pipelines.&lt;SEP&gt;Individual functional units within DSPy that perform specific tasks, such as retrieval, reasoning, or generation.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="define-by-run interface">
  <data key="d0">define-by-run interface</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A flexible approach where the DSPy pipeline is declared and executed dynamically during runtime, allowing for adaptable pipeline design.&lt;SEP&gt;An approach where the pipeline and its components are declared and executed dynamically during runtime, allowing flexible pipeline construction.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="simple retrieval-augmented generation (RAG) system">
  <data key="d0">simple retrieval-augmented generation (RAG) system</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A specific pipeline architecture combining retrieval and generation modules to answer questions based on external data sources.&lt;SEP&gt;A specific type of pipeline combining retrieval and generation components to answer questions or generate responses based on external data.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="class RAG(dspy.Module)">
  <data key="d0">class RAG(dspy.Module)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A class definition in code representing a retrieval-augmented generation system, illustrating modular design and functionality.&lt;SEP&gt;A class definition in code representing a retrieval-augmented generation system, illustrating modular design and integration.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="self.retrieve = dspy.Retrieve(k=num_passages)">
  <data key="d0">self.retrieve = dspy.Retrieve(k=num_passages)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Initialization of the retrieval component within the RAG class, setting the number of passages to retrieve per query.&lt;SEP&gt;Initialization of the retrieval component within the RAG class, setting the number of passages to retrieve.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="self.generate_answer = dspy.ChainOfThought('context, question -&gt; answer')">
  <data key="d0">self.generate_answer = dspy.ChainOfThought('context, question -&gt; answer')</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Initialization of the answer generation component using ChainOfThought, which models reasoning chains.&lt;SEP&gt;Initialization of the reasoning/generation component using ChainOfThought, which models step-by-step reasoning to produce answers.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="def forward(self, question)">
  <data key="d0">def forward(self, question)</data>
  <data key="d1">Method</data>
  <data key="d2">Defines the process by which the RAG system takes a question, retrieves relevant passages, and generates an answer.&lt;SEP&gt;Defines the process for passing a question through the RAG system to produce an answer, involving retrieval and generation steps.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="context = self.retrieve(question).passages">
  <data key="d0">context = self.retrieve(question).passages</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Retrieves relevant passages based on the question to form the context for answer generation.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="return self.generate_answer(context=context, question=question)">
  <data key="d0">return self.generate_answer(context=context, question=question)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Outputs the final answer after reasoning over the retrieved context and the question.&lt;SEP&gt;Produces the final answer by passing the context and question to the generation module.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="modularity">
  <data key="d0">modularity</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Design principle emphasizing that components like retrieval and reasoning modules can be independently developed, swapped, and combined within the pipeline.&lt;SEP&gt;Design principle emphasizing that system components like retrieval and reasoning can be swapped or combined flexibly within DSPy.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="teleprompter">
  <data key="d0">teleprompter</data>
  <data key="d1">Tools</data>
  <data key="d2">An optimizer component in DSPy that enhances modules via prompting or finetuning, facilitating improved performance of language model components.&lt;SEP&gt;An optimizer component in DSPy that improves program modules through prompting or finetuning, enhancing their performance.&lt;SEP&gt;An optimizer component that refines and compiles DSPy programs based on training data and metrics, enhancing performance and efficiency.&lt;SEP&gt;An optimizer component that refines and compiles DSPy programs based on training data and metrics, improving system performance and efficiency.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca&lt;SEP&gt;chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="training sets">
  <data key="d0">training sets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Small datasets used to bootstrap or train DSPy programs, often containing question-answer pairs or examples for few-shot learning.&lt;SEP&gt;Small datasets used to train or optimize DSPy programs, potentially with limited examples for few-shot learning.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="answer_exact_match">
  <data key="d0">answer_exact_match</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A metric measuring the percentage of answers exactly matching the ground truth, used for evaluating accuracy.&lt;SEP&gt;A metric that evaluates the accuracy of generated answers by checking for exact text matches with reference answers.&lt;SEP&gt;A metric that evaluates the accuracy of generated answers by checking for exact textual matches with reference answers.&lt;SEP&gt;A metric used to evaluate the accuracy of the model's answer compared to the ground truth.&lt;SEP&gt;The function evaluate.answer_exact_match compares predicted answers to correct answers to determine exact matches, used for assessing answer accuracy.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca&lt;SEP&gt;chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="compiled_rag">
  <data key="d0">compiled_rag</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A version of the RAG system that has been optimized and generated via the teleprompter based on training data.&lt;SEP&gt;An optimized version of the RAG pipeline generated via teleprompter, tailored to specific training data and metrics.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="collect demonstrations of each module">
  <data key="d0">collect demonstrations of each module</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of gathering example input-output pairs for each component to improve or validate system behavior.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="behavior like this might be more accurately checked by another DSPy program that checks for faithful grounding of answers">
  <data key="d0">behavior like this might be more accurately checked by another DSPy program that checks for faithful grounding of answers</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Explores methods for ensuring that generated answers are properly grounded in retrieved data, enhancing reliability.&lt;SEP&gt;Explores methods for verifying that generated answers are properly grounded in retrieved data, ensuring factual correctness.&lt;SEP&gt;Investigates the development of metrics for assessing factual grounding and answer fidelity.&lt;SEP&gt;Investigates the development of metrics that assess the factual grounding of generated responses.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="metrics are fully supported and encouraged in DSPy">
  <data key="d0">metrics are fully supported and encouraged in DSPy</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Indicates that DSPy provides mechanisms for evaluating and optimizing system performance using various metrics.&lt;SEP&gt;Indicates that DSPy provides mechanisms for evaluating system performance using various metrics, supporting optimization and validation.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="answer and context match">
  <data key="d0">answer and context match</data>
  <data key="d1">Variables</data>
  <data key="d2">A custom evaluation function that checks whether the answer matches reference data and whether the context supports the answer.&lt;SEP&gt;A custom evaluation function that checks whether the generated answer matches the reference and whether the retrieved context supports the answer.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="We contrast that with Appendix C, which copies long reasoning prompts hand-written by sources">
  <data key="d0">We contrast that with Appendix C, which copies long reasoning prompts hand-written by sources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Refers to a section in a document that contains examples of manually written reasoning prompts used for comparison or analysis.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ranging from recent research to popular prompting libraries">
  <data key="d0">ranging from recent research to popular prompting libraries</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Sources of manually crafted prompts from recent academic studies and popular prompt libraries used as references.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="observe that any LM call seeking to implement a particular signature needs to specify parameters that include: (1) the specific LM to call (Chen et al., 2023), (2) the prompt instructions (Yang et al., 2023) and the string prefix of each signature field and, most importantly, (3) the demonstrations used as few-shot prompts (for frozen LMs) or as training data (for finetuning)">
  <data key="d0">observe that any LM call seeking to implement a particular signature needs to specify parameters that include: (1) the specific LM to call (Chen et al., 2023), (2) the prompt instructions (Yang et al., 2023) and the string prefix of each signature field and, most importantly, (3) the demonstrations used as few-shot prompts (for frozen LMs) or as training data (for finetuning)</data>
  <data key="d1">Variables</data>
  <data key="d2">Details the specific parameters involved in configuring the language model calls, including model choice, prompt instructions, and demonstration data.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="We focus primarily on automatically generating and selecting useful demonstrations">
  <data key="d0">We focus primarily on automatically generating and selecting useful demonstrations</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates methods for automatically creating and selecting effective demonstration examples to improve model performance in few-shot settings.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="In our case studies, we find that bootstrapping good demonstrations gives us a powerful way to teach sophisticated pipelines of LMs new behaviors systematically">
  <data key="d0">In our case studies, we find that bootstrapping good demonstrations gives us a powerful way to teach sophisticated pipelines of LMs new behaviors systematically</data>
  <data key="d1">Results</data>
  <data key="d2">Empirical finding that iterative bootstrapping of demonstrations enhances the ability of language model pipelines to learn new behaviors systematically.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="context_match">
  <data key="d0">context_match</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A metric that checks if the predicted answer is a substring of the context passage, indicating whether the answer is grounded in the provided context.&lt;SEP&gt;A metric that checks whether the predicted answer is a substring within the given context, indicating whether the answer is grounded in the context passage.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Predict modules">
  <data key="d0">Predict modules</data>
  <data key="d1">Tools</data>
  <data key="d2">Modules within DSPy responsible for generating predictions, including demonstrations and instructions, used during compilation and optimization stages.&lt;SEP&gt;Modules within DSPy that generate predictions or outputs, including demonstrations and instructions, used during compilation and optimization.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="candidate generation">
  <data key="d0">candidate generation</data>
  <data key="d1">Methodology</data>
  <data key="d2">A stage in DSPy where unique predictors are identified, and candidate parameters or demonstrations are generated to improve model outputs.&lt;SEP&gt;Stage of DSPy compilation where unique predictors are identified, and candidate parameters or demonstrations are generated to improve model performance.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="parameter optimization">
  <data key="d0">parameter optimization</data>
  <data key="d1">Methodology</data>
  <data key="d2">A stage involving hyperparameter tuning using methods like random search or Optuna to select optimal candidates for model parameters or demonstrations.&lt;SEP&gt;Stage involving hyperparameter tuning (e.g., random search, Optuna) to select the best candidates for model parameters or demonstrations.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="finetuning">
  <data key="d0">finetuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">Process where the language model's weights are updated using demonstrations to improve performance, often through gradient-based training.&lt;SEP&gt;The process of updating the language model's weights using demonstrations or data to improve performance, often through gradient-based training.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="higher-order program optimization">
  <data key="d0">higher-order program optimization</data>
  <data key="d1">Methodology</data>
  <data key="d2">A stage where DSPy modifies control flow structures, such as ensemble techniques, to enhance prediction accuracy and robustness.&lt;SEP&gt;Stage where DSPy modifies control flow, such as ensemble techniques, to enhance model predictions and robustness.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ensemble">
  <data key="d0">ensemble</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An ensemble in DSPy refers to multiple copies of the same program run in parallel, with their outputs combined (e.g., via majority voting) to improve overall prediction reliability.&lt;SEP&gt;An ensemble in DSPy refers to multiple copies of the same program run in parallel, with their outputs combined (e.g., via majority voting) to improve prediction accuracy.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="evaluate.answer_exact_match">
  <data key="d0">evaluate.answer_exact_match</data>
  <data key="d1">Methodology</data>
  <data key="d2">A function that compares predicted answers to correct answers to determine if they match exactly, used for measuring answer accuracy.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Majority Voting">
  <data key="d0">Majority Voting</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique that combines multiple model outputs by selecting the most frequently occurring response among them, used here as a custom function to ensemble predictions.&lt;SEP&gt;A technique that combines multiple outputs by selecting the most common response among them, used here as a custom function for ensemble decision-making.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Program Modules">
  <data key="d0">Program Modules</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Reusable components within DSPy that perform specific functions such as prediction, chaining, or comparison, forming the building blocks of task pipelines.&lt;SEP&gt;Reusable components within DSPy that perform specific tasks such as prediction, chaining, or comparison, forming the building blocks of the evaluation pipelines.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Evaluation Hypotheses">
  <data key="d0">Evaluation Hypotheses</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Statements predicting the effectiveness of DSPy modules and parameterization in replacing handcrafted prompts and improving adaptability across language models.&lt;SEP&gt;Statements proposing that modular DSPy prompts can replace handcrafted prompts, improve adaptability, and outperform expert prompts across various language models.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GSM8K Dataset">
  <data key="d0">GSM8K Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset consisting of grade school math word problems used to evaluate the reasoning and problem-solving capabilities of language models.&lt;SEP&gt;A dataset of grade school math word problems used to evaluate the performance of language models on mathematical reasoning tasks.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Program Compilation">
  <data key="d0">Program Compilation</data>
  <data key="d1">Methodology</data>
  <data key="d2">The process of converting DSPy programs into optimized versions for better performance, including strategies like zero-shot and labeled few-shot compilation.&lt;SEP&gt;The process of transforming DSPy programs into optimized, executable versions, using strategies like zero-shot or labeled few-shot to improve performance.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Results">
  <data key="d0">Results</data>
  <data key="d1">Results</data>
  <data key="d2">Empirical findings indicating that replacing string prompts with compiled DSPy modules significantly improves accuracy across models, from 4–20% to 49–88%.&lt;SEP&gt;The experimental outcomes showing accuracy improvements from 4–20% to 49–88% when replacing string prompts with compiled DSPy modules across different language models.&lt;SEP&gt;Findings and outcomes derived from data analysis, indicating the study's key discoveries.&lt;SEP&gt;Findings include assessments of the correctness, trade-offs, and overall value of GPT-3 and Codex in HPC kernel development, along with insights into prompt trade-offs.&lt;SEP&gt;The evaluation results indicate the proficiency levels of different programming languages and models in generating correct computational kernels, with complexity impacting success rates.&lt;SEP&gt;The evaluation results show the proficiency levels of different programming languages and models in generating correct kernels, with success decreasing as kernel complexity increases.&lt;SEP&gt;The outcomes of the study, indicating that increasing code complexity makes achieving acceptable results more challenging.&lt;SEP&gt;The study presents findings on the correctness, trade-offs, and overall value of large language models like GPT-3 for HPC practitioners, including insights on prompt trade-offs and output quality.&lt;SEP&gt;The output includes a list of identified entities with their descriptions and relationships, as well as overarching keywords summarizing the main themes.&lt;SEP&gt;Results from the evaluation demonstrate the model's performance in downstream tasks, informing improvements and applications.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-04aecdc2586d2c7966e70e02cac846b0&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-0696a875ae026175ba36c9e8529f7efd&lt;SEP&gt;chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Hypotheses Testing">
  <data key="d0">Hypotheses Testing</data>
  <data key="d1">Results</data>
  <data key="d2">The evaluation tests hypotheses that modular prompting can outperform handcrafted prompts and adapt better to various LMs.&lt;SEP&gt;The evaluation tests the hypotheses that modular prompting and compilation strategies enhance model performance and adaptability.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Reproducible Runs">
  <data key="d0">Reproducible Runs</data>
  <data key="d1">Study Design</data>
  <data key="d2">A structured approach to executing experiments with well-defined programs, strategies, and datasets to ensure reproducibility and precise comparison.&lt;SEP&gt;Structured experimental setups with well-defined programs, datasets, and evaluation protocols to ensure reproducibility and reliable comparison.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Evaluation Strategies">
  <data key="d0">Evaluation Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Different approaches such as in-context learning, prompt compilation, and ensemble methods used to assess model performance.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Program Modules: Predict, ChainOfThought, Reflection">
  <data key="d0">Program Modules: Predict, ChainOfThought, Reflection</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specific DSPy modules designed for reasoning and problem-solving tasks, each with distinct functionalities like prediction, multi-chain comparison, and reflection.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Composite Programs">
  <data key="d0">Composite Programs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Complex assembled DSPy programs combining multiple modules (e.g., vanilla, CoT, Reflection) for solving math problems.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Strategies for Compilation">
  <data key="d0">Strategies for Compilation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Different methods such as zero-shot, labeled few-shot, and ensemble compilation used to optimize DSPy programs for better performance.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Accuracy Metrics">
  <data key="d0">Accuracy Metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Quantitative measures of model correctness on GSM8K, showing significant improvements when using compiled modules versus prompts.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Task-Specific Prompts">
  <data key="d0">Task-Specific Prompts</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Hand-crafted prompts tailored for specific tasks, currently dominant but replaced by modular approaches in this context.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Reproducibility">
  <data key="d0">Reproducibility</data>
  <data key="d1">Limitations</data>
  <data key="d2">Challenges related to ensuring consistent results across different runs, models, and experimental setups, addressed by structured study designs.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Section 4">
  <data key="d0">Section 4</data>
  <data key="d1">Study Design</data>
  <data key="d2">Section 4 discusses the framework for compiling DSPy programs into optimized programs and evaluates different compilation strategies, including zero-shot, bootstrap, and ensembling, for improving performance on math word problems.&lt;SEP&gt;Section 4 discusses the process of compiling DSPy programs into optimized versions and evaluates different strategies such as zero-shot, bootstrap, and ensembling for performance gains.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="LabeledFewShot">
  <data key="d0">LabeledFewShot</data>
  <data key="d1">Methodology</data>
  <data key="d2">A compilation strategy that samples a fixed number (k=8) of demonstrations from the training set to create exemplars for program training.&lt;SEP&gt;A simple compilation strategy that samples a fixed number of demonstrations (k=8) from the training set to create exemplars for program training.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="BootstrapFewShotWithRandomSearch">
  <data key="d0">BootstrapFewShotWithRandomSearch</data>
  <data key="d1">Methodology</data>
  <data key="d2">A bootstrapping approach for improving question answering programs by random search techniques.&lt;SEP&gt;An advanced compilation technique that generates demonstration chains and optimizes their selection through random search to self-improve the program modules.&lt;SEP&gt;An advanced technique that generates demonstration chains and optimizes their selection via random search to self-improve the program modules.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ensemble">
  <data key="d0">Ensemble</data>
  <data key="d1">Methodology</data>
  <data key="d2">An ensembling approach that combines multiple candidate programs via majority voting to improve robustness and accuracy.&lt;SEP&gt;Combining multiple candidate programs via majority voting to boost overall accuracy and robustness.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GSM8K">
  <data key="d0">GSM8K</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">A benchmark dataset of math word problems used to evaluate the effectiveness of various compilation and prompting strategies across different language models.&lt;SEP&gt;A benchmark dataset of math word problems used to evaluate the performance of different program compilation strategies and language models.&lt;SEP&gt;A dataset used for evaluating mathematical reasoning capabilities of language models.&lt;SEP&gt;A dataset used for evaluating reasoning and mathematical problem-solving capabilities of language models.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zero-Shot">
  <data key="d0">Zero-Shot</data>
  <data key="d1">Study Design</data>
  <data key="d2">Evaluation of language models' performance on math problems without any compilation or demonstration exemplars.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Human Reasoning Chains">
  <data key="d0">Human Reasoning Chains</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Expert-generated reasoning chains that serve as a benchmark or training data to enhance model reasoning capabilities.&lt;SEP&gt;Expertly crafted reasoning chains provided by humans that serve as a benchmark for model performance and training data augmentation.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GPT-3.5 and llama2-13b-chat">
  <data key="d0">GPT-3.5 and llama2-13b-chat</data>
  <data key="d1">Discipline</data>
  <data key="d2">Large Language Models (LLMs) used to evaluate the impact of different compilation and prompting strategies on math problem solving.&lt;SEP&gt;Large Language Models used to assess the impact of different compilation strategies and modules on solving math problems.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Reflection Program">
  <data key="d0">Reflection Program</data>
  <data key="d1">Methodology</data>
  <data key="d2">A DSPy module designed to incorporate reflection steps into reasoning, which has shown to significantly improve performance.&lt;SEP&gt;A DSPy module designed to incorporate reflection steps, which has shown to be a particularly effective approach in improving accuracy.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Training and Evaluation">
  <data key="d0">Training and Evaluation</data>
  <data key="d1">Study Design</data>
  <data key="d2">The process involves training models with various compilation strategies and evaluating their accuracy on the GSM8K test set, comparing against benchmarks from prior work.&lt;SEP&gt;The process involves training models with various compilation strategies and evaluating their accuracy on the GSM8K test set, comparing against prior benchmarks.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="zero-shot">
  <data key="d0">zero-shot</data>
  <data key="d1">Study Design</data>
  <data key="d2">A baseline evaluation where models attempt to solve problems without any demonstration or compilation enhancements.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Answer Field">
  <data key="d0">Answer Field</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The answer field in the dataset contains the final numerical solutions that models aim to predict, and is leveraged during reasoning processes.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Demonstration Chains">
  <data key="d0">Demonstration Chains</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Sequences of reasoning steps generated to improve model performance through bootstrapping and optimization.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Metrics">
  <data key="d0">Metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics are quantitative measures used to evaluate the correctness, efficiency, or quality of generated or translated code across different execution models.&lt;SEP&gt;Metrics are quantitative measures used to evaluate the correctness, efficiency, or quality of the generated code across different execution models.&lt;SEP&gt;Quantitative measures such as accuracy or correctness used to evaluate model performance across different strategies.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Model Performance">
  <data key="d0">Model Performance</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics and evaluations indicating how well a model performs on domain-specific tasks after adaptation.&lt;SEP&gt;Model performance measures the effectiveness of a code LLM in generating correct and efficient parallel code, often evaluated through metrics like Pass@1.&lt;SEP&gt;Model performance measures the effectiveness of a language model in generating correct and efficient code, often evaluated through metrics like Pass@1.&lt;SEP&gt;The effectiveness of different models and compilation strategies in solving math problems, often expressed as accuracy percentages.&lt;SEP&gt;The measurable outcome indicating how well the fine-tuned model generates accurate and functional parallel code, affected by data quantity, quality, and model size.&lt;SEP&gt;Models like GPT-4 outperform others in speedup and efficiency, demonstrating superior scalability and resource utilization.&lt;SEP&gt;The effectiveness and accuracy of a model in achieving its intended purpose, often measured through various evaluation metrics.&lt;SEP&gt;Model performance is assessed using metrics such as pass@k and BLEU scores, indicating the effectiveness of models in solving coding problems.&lt;SEP&gt;Performance metrics such as pass@k and strict accuracy measure the effectiveness of language models on coding tasks.&lt;SEP&gt;The effectiveness of a model in executing tasks, influenced by size, training, and prompt design.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f&lt;SEP&gt;chunk-50450e84744379a5c4f059c7d4f84019&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Self-Consistency">
  <data key="d0">Self-Consistency</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A technique where multiple reasoning paths are generated and the most common answer is selected to improve accuracy.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompting Strategies">
  <data key="d0">Prompting Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Different methods of prompting language models, including manual CoT, automatic CoT, and DSPy modules, to enhance reasoning.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Comparison with Prior Work">
  <data key="d0">Comparison with Prior Work</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Analyzing how the current results align with or surpass previous benchmarks, informing the state-of-the-art in math reasoning with LLMs.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="llama2-34b">
  <data key="d0">llama2-34b</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Llama2-34b is a language model variant with a specific parameter size, used for comparative performance analysis.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="llama2-70b">
  <data key="d0">llama2-70b</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Llama2-70b is a larger language model variant, with performance metrics reported for its capabilities.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="13b variant">
  <data key="d0">13b variant</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A smaller variant of the language model, used in the program to compare with larger models.&lt;SEP&gt;A smaller variant of the language model, used in the program to evaluate competitiveness without human reasoning chains.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="CoT (Chain of Thought)">
  <data key="d0">CoT (Chain of Thought)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A reasoning framework that involves step-by-step logical thinking to improve model performance.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GPT-3.5-turbo">
  <data key="d0">GPT-3.5-turbo</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An OpenAI language model with a performance score of 80.8% for CoT, used as a benchmark.&lt;SEP&gt;An advanced language model by OpenAI, with performance metrics reported in the study.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GPT-4">
  <data key="d0">GPT-4</data>
  <data key="d1">Tools</data>
  <data key="d2">GPT-4 is a large language model developed by OpenAI, designed to understand and generate human-like text with advanced capabilities.&lt;SEP&gt;GPT-4 is a state-of-the-art large language model developed by OpenAI, designed for natural language understanding, generation, reasoning, and evaluation tasks. It is a more advanced, proprietary, and instruction-tuned model that is aligned with human preferences and accessible via API for inference, code generation, and assessment purposes. GPT-4 has demonstrated high performance across various benchmarks, including the ParEval benchmark, where it achieves pass@1 scores that measure its effectiveness in solving diverse computational problems using different parallel execution models. It is recognized for its capacity to understand, reason, and generate human-like text across a wide range of tasks, including complex language understanding, code generation, and evaluation. Compared to earlier models like GPT-3.5, GPT-4 generally offers improved overall performance and scalability, although it may slightly underperform GPT-3.5 in specific parallel code generation tasks. It is also evaluated for efficiency, speedup, and parallel code performance across multiple execution models, highlighting its high performance, scalability, and suitability for research and practical applications in natural language processing and code generation.&lt;SEP&gt;GPT-4 is an advanced large language model developed by OpenAI, designed for complex language understanding, instruction following, and generation.&lt;SEP&gt;The latest advanced language model by OpenAI, offering improved understanding and generation for complex language tasks.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-727ea750122a5bed30ad781918446611&lt;SEP&gt;chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7&lt;SEP&gt;chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HotPotQA">
  <data key="d0">HotPotQA</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark dataset and multi-hop question answering task that tests models' reasoning across multiple passages.&lt;SEP&gt;A benchmark dataset and task for multi-hop question answering that requires reasoning across multiple passages.&lt;SEP&gt;A dataset for multi-hop question answering in open-domain Wikipedia setting.&lt;SEP&gt;A dataset for multi-hop question answering in open-domain fullwiki setting, used for evaluation.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ColBERTv2">
  <data key="d0">ColBERTv2</data>
  <data key="d1">Tools</data>
  <data key="d2">A retrieval model employed to search Wikipedia abstracts for relevant passages in question answering.&lt;SEP&gt;A retrieval model used to search and retrieve relevant passages from Wikipedia for question answering.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.ReAct">
  <data key="d0">dspy.ReAct</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A multi-step agent framework for tool use in question answering, implemented in DSPy.&lt;SEP&gt;A multi-step reasoning and tool-use agent framework implemented in DSPy for question answering.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="BasicMultiHop">
  <data key="d0">BasicMultiHop</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A custom multi-hop question answering program that iteratively retrieves passages and generates answers.&lt;SEP&gt;A custom multi-hop question answering program that retrieves passages iteratively to answer complex questions.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Llama2-34b">
  <data key="d0">Llama2-34b</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Llama2-34b is a language model with a specific parameter size, used for performance comparison in language tasks.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Llama2-70b">
  <data key="d0">Llama2-70b</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Llama2-70b is a larger language model variant, with reported performance metrics.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zhao et al. (2023b)">
  <data key="d0">Zhao et al. (2023b)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A study reporting 80.8% for CoT with GPT-3.5-turbo, providing comparative performance data.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="OpenAI (2023)">
  <data key="d0">OpenAI (2023)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The authors of GPT-4, reporting its performance and pretraining details.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Wikipedia 2017 Abstracts Dump">
  <data key="d0">Wikipedia 2017 Abstracts Dump</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">A dataset containing Wikipedia abstracts used as the knowledge base for retrieval in HotPotQA.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy">
  <data key="d0">dspy</data>
  <data key="d1">Tools</data>
  <data key="d2">A framework for constructing, compiling, and executing question answering programs with modules like retrieval and reasoning.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="expert human reasoning">
  <data key="d0">expert human reasoning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Expert human reasoning involves applying knowledge, logic, and problem-solving skills to interpret, analyze, and make decisions based on information, here adapted for retrieval settings.&lt;SEP&gt;Expert human reasoning refers to the cognitive process of applying knowledge, logic, and problem-solving skills to interpret and analyze information, adapted here for retrieval settings.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yao et al. (2022)">
  <data key="d0">Yao et al. (2022)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A scholarly work that provides a theoretical foundation or framework related to expert reasoning and possibly other AI or retrieval concepts.&lt;SEP&gt;A scholarly work that provides a theoretical framework or foundational concepts related to expert reasoning, AI, or retrieval methodologies.&lt;SEP&gt;Research conducted by Yao and colleagues in 2022, involving methodologies related to AI, reasoning, or cognitive modeling.&lt;SEP&gt;Research conducted by Yao and colleagues in 2022, likely involving methodologies related to AI or cognitive science.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956&lt;SEP&gt;chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="compiler">
  <data key="d0">compiler</data>
  <data key="d1">Tools</data>
  <data key="d2">A software component that translates high-level programs into executable code, evaluated here for its multihop T5-Large implementation.&lt;SEP&gt;A software component that translates high-level programs into executable code; evaluated here for its multihop T5-Large implementation.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="multihop t5defined">
  <data key="d0">multihop t5defined</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A specific program or model designed to perform multihop reasoning tasks, based on T5-Large architecture, used to assess reasoning capacity.&lt;SEP&gt;A specific program or model designed to perform multihop reasoning tasks, based on T5-Large architecture.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="answer EM">
  <data key="d0">answer EM</data>
  <data key="d1">Results</data>
  <data key="d2">Answer Exact Match (EM) score indicating the percentage of answers that exactly match the ground truth, used to evaluate model accuracy.&lt;SEP&gt;Answer Exact Match (EM) score indicating the percentage of answers that exactly match the ground truth, used to evaluate model performance.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="passage accuracy">
  <data key="d0">passage accuracy</data>
  <data key="d1">Results</data>
  <data key="d2">A metric measuring the correctness of passage retrieval in question-answering tasks.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="answer pair-retrieval accuracy (Psg)">
  <data key="d0">answer pair-retrieval accuracy (Psg)</data>
  <data key="d1">Results</data>
  <data key="d2">A metric assessing the accuracy of retrieving relevant passage pairs in multi-hop QA.&lt;SEP&gt;A metric assessing the accuracy of retrieving relevant passage pairs in the context of multi-hop QA.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="in-context learning">
  <data key="d0">in-context learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A learning paradigm where models learn to perform tasks by conditioning on provided examples within the input context.&lt;SEP&gt;A paradigm where models learn to perform tasks by conditioning on examples within the input context, often used to improve reasoning.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="CoT prompting">
  <data key="d0">CoT prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Chain-of-Thought prompting technique that guides models to produce intermediate reasoning steps to enhance performance.&lt;SEP&gt;Chain-of-Thought prompting technique that guides models to produce intermediate reasoning steps to improve performance.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="PaLM-62B">
  <data key="d0">PaLM-62B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A 62-billion-parameter language model by Google, used for evidence recitation and reasoning in QA tasks.&lt;SEP&gt;A 62-billion-parameter language model by Google, used for evidence recitation in QA tasks.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="self-consistency">
  <data key="d0">self-consistency</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique that aggregates multiple model outputs to improve answer accuracy and consistency in reasoning.&lt;SEP&gt;A technique that aggregates multiple model outputs to improve answer reliability and accuracy.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Wikipedia API">
  <data key="d0">Wikipedia API</data>
  <data key="d1">Tools</data>
  <data key="d2">An external API providing access to Wikipedia content, used by models to retrieve factual information during reasoning processes.&lt;SEP&gt;An external tool that provides access to Wikipedia content, enabling models to retrieve factual information during reasoning.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="code-davinci-002">
  <data key="d0">code-davinci-002</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An OpenAI language model optimized for code generation and reasoning tasks.&lt;SEP&gt;An OpenAI language model optimized for code generation and reasoning, used in various reasoning pipelines.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy signatures, modules, teleprompters">
  <data key="d0">DSPy signatures, modules, teleprompters</data>
  <data key="d1">Methodologies</data>
  <data key="d2">New abstractions introduced in DSPy for defining system components, reasoning modules, and control mechanisms to coordinate AI workflows.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="information extraction">
  <data key="d0">information extraction</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">A task involving retrieving structured data from unstructured text, supported by DSPy for building efficient pipelines.&lt;SEP&gt;A task supported by DSPy involving extracting structured data from unstructured text, enabling efficient pipeline development.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="synthetic data generation">
  <data key="d0">synthetic data generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Synthetic data generation involves creating artificial data, here using seed snippets and prompt templates to produce problem-solution code pairs with LLMs.&lt;SEP&gt;The process of creating artificial data to augment training datasets, enabled by DSPy for low-resource scenarios.&lt;SEP&gt;Using DSPy to create artificial data for training or low-resource tasks, facilitating data augmentation.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0&lt;SEP&gt;chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="text transformation graphs">
  <data key="d0">text transformation graphs</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A formal representation of composed text processing modules and their interactions, central to DSPy's approach to systematic AI system design.&lt;SEP&gt;A formal representation of composed text processing modules and their interactions, central to DSPy's systematic approach to AI system design.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="composable modules">
  <data key="d0">composable modules</data>
  <data key="d1">Tools</data>
  <data key="d2">Reusable components within DSPy that perform specific text transformations or reasoning steps, facilitating flexible system construction.&lt;SEP&gt;Reusable components within DSPy that perform specific text transformations or reasoning tasks, enabling flexible pipeline construction.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="optimizers (teleprompters)">
  <data key="d0">optimizers (teleprompters)</data>
  <data key="d1">Tools</data>
  <data key="d2">Mechanisms within DSPy that guide and coordinate module execution, improving reliability and performance.&lt;SEP&gt;Mechanisms within DSPy that guide, coordinate, and optimize module execution, improving reliability and performance of AI systems.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Text Transformation Graph">
  <data key="d0">Text Transformation Graph</data>
  <data key="d1">&lt;Core Concepts</data>
  <data key="d2">A computational graph abstraction that organizes composable modules and optimizers (teleprompters) to leverage language models (LMs) in systematic and reliable ways.&lt;SEP&gt;A computational graph abstraction that organizes modules and optimizers (teleprompters) to systematically and reliably leverage language models (LMs).</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Optimizers (Teleprompters)">
  <data key="d0">Optimizers (Teleprompters)</data>
  <data key="d1">&lt;Objects of Study</data>
  <data key="d2">Tools or components designed to improve the performance, reliability, or systematic operation of the text transformation process involving language models.&lt;SEP&gt;Tools or components designed to improve the systematic operation, performance, or reliability of the language models within the graph, acting as guiding or enhancing mechanisms.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Research Support">
  <data key="d0">Research Support</data>
  <data key="d1">&lt;Study Populations/Dataset</data>
  <data key="d2">Various industry and academic organizations (IBM, Oracle, Virtusa, Cigna Healthcare, Stanford HAI, Facebook, Google, VMware, NSF, Apple Scholars) that fund, support, or collaborate on research related to the development and application of text transformation graphs and AI technologies.&lt;SEP&gt;Various research institutions and industry partners (IBM, Oracle, Virtusa, Cigna Healthcare, Stanford HAI, Facebook, Google, VMware, NSF, Apple Scholars) that fund or support the development and evaluation of the text transformation graph and related AI research.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Wenhu Chen">
  <data key="d0">Wenhu Chen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Wenhu Chen is an author contributing to research on computational reasoning and language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Xueguang Ma">
  <data key="d0">Xueguang Ma</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xueguang Ma is an author involved in studies related to prompting and reasoning in AI.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Xinyi Wang">
  <data key="d0">Xinyi Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xinyi Wang is a researcher working on numerical reasoning tasks and language model prompting.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="William W Cohen">
  <data key="d0">William W Cohen</data>
  <data key="d1">Researcher</data>
  <data key="d2">William W Cohen is an author focusing on computational reasoning and language model research.&lt;SEP&gt;William W Cohen is an author specializing in NLP, information retrieval, and reasoning datasets.&lt;SEP&gt;William W Cohen is an author working on information retrieval, NLP datasets, and reasoning in AI.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Aakanksha Chowdhery">
  <data key="d0">Aakanksha Chowdhery</data>
  <data key="d1">Researchers</data>
  <data key="d2">Aakanksha Chowdhery is involved in scaling language modeling with pathways.&lt;SEP&gt;Author involved in research on language model prompting and reasoning techniques.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sharan Narang">
  <data key="d0">Sharan Narang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on reasoning and prompting in language models.&lt;SEP&gt;Sharan Narang is a researcher contributing to language model scaling and pathways.&lt;SEP&gt;Sharan Narang is a researcher focusing on machine learning models and transfer learning techniques.&lt;SEP&gt;Sharan Narang researches transfer learning, model fine-tuning, and generalization in natural language processing.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jacob Devlin">
  <data key="d0">Jacob Devlin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher known for developing BERT, a pre-training model for language understanding.&lt;SEP&gt;Jacob Devlin is involved in language model development and scaling.&lt;SEP&gt;Jacob Devlin is known for his work in natural language understanding and developing models for question answering.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Maarten Bosma">
  <data key="d0">Maarten Bosma</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on zero-shot capabilities and emergent abilities of language models.&lt;SEP&gt;Maarten Bosma is a researcher working on language modeling techniques.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Gaurav Mishra">
  <data key="d0">Gaurav Mishra</data>
  <data key="d1">Researcher</data>
  <data key="d2">Gaurav Mishra is involved in language model research and scaling methodologies.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Adam Roberts">
  <data key="d0">Adam Roberts</data>
  <data key="d1">Researcher</data>
  <data key="d2">Adam Roberts is a researcher contributing to large-scale language model studies.&lt;SEP&gt;Adam Roberts is a researcher contributing to studies on large language models and their capabilities, including parameter efficiency.&lt;SEP&gt;Adam Roberts is a researcher focused on the development and analysis of large-scale language models and their parameter efficiency.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Paul Barham">
  <data key="d0">Paul Barham</data>
  <data key="d1">Researcher</data>
  <data key="d2">Paul Barham is involved in scaling language models with pathways.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Hyung Won Chung">
  <data key="d0">Hyung Won Chung</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hyung Won Chung is a researcher working on language model scaling.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Charles Sutton">
  <data key="d0">Charles Sutton</data>
  <data key="d1">Researcher</data>
  <data key="d2">Charles Sutton is involved in language modeling research.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sebastian Gehrmann">
  <data key="d0">Sebastian Gehrmann</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on BloombergGPT for finance.&lt;SEP&gt;Sebastian Gehrmann contributes to language model research and evaluation.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Karl Cobbe">
  <data key="d0">Karl Cobbe</data>
  <data key="d1">Researcher</data>
  <data key="d2">Karl Cobbe is a researcher focused on training verifiers for solving math word problems and evaluating model reasoning capabilities.&lt;SEP&gt;Karl Cobbe is involved in training verifiers for solving math word problems.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Vineet Kosaraju">
  <data key="d0">Vineet Kosaraju</data>
  <data key="d1">Researcher</data>
  <data key="d2">Vineet Kosaraju contributes to research on model training and evaluation in AI.&lt;SEP&gt;Vineet Kosaraju works on neural network training and verification.&lt;SEP&gt;Vineet Kosaraju focuses on AI models, human feedback, and system evaluation.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Mohammad Bavarian">
  <data key="d0">Mohammad Bavarian</data>
  <data key="d1">Researcher</data>
  <data key="d2">Mohammad Bavarian contributes to AI verification methods.&lt;SEP&gt;Mohammad Bavarian works on AI model training and evaluation methodologies.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Mark Chen">
  <data key="d0">Mark Chen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Mark Chen is involved in developing and evaluating AI models, including verifiers for complex problem solving.&lt;SEP&gt;Mark Chen is involved in training AI verifiers for mathematical problem solving.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Heewoo Jun">
  <data key="d0">Heewoo Jun</data>
  <data key="d1">Researcher</data>
  <data key="d2">Heewoo Jun contributes to research on AI model training and mathematical problem solving.&lt;SEP&gt;Heewoo Jun works on AI training and verification techniques.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Lukasz Kaiser">
  <data key="d0">Lukasz Kaiser</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lukasz Kaiser is involved in neural network training and language model research.&lt;SEP&gt;Lukasz Kaiser specializes in neural network architectures and training methods for AI models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Matthias Plappert">
  <data key="d0">Matthias Plappert</data>
  <data key="d1">Researcher</data>
  <data key="d2">Matthias Plappert contributes to AI training methodologies.&lt;SEP&gt;Matthias Plappert works on reinforcement learning and model evaluation in AI.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jerry Tworek">
  <data key="d0">Jerry Tworek</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jerry Tworek contributes to AI research focusing on language models and code generation.&lt;SEP&gt;Jerry Tworek is involved in training and verifying AI models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jacob Hilton">
  <data key="d0">Jacob Hilton</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jacob Hilton contributes to research on language models and human feedback mechanisms.&lt;SEP&gt;Jacob Hilton is a researcher focused on natural language processing, human feedback, and AI system training methodologies.&lt;SEP&gt;Jacob Hilton is involved in AI model training and evaluation, particularly in language understanding.&lt;SEP&gt;Jacob Hilton works on AI training and verification.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Reiichiro Nakano">
  <data key="d0">Reiichiro Nakano</data>
  <data key="d1">Researcher</data>
  <data key="d2">Reiichiro Nakano contributes to neural network training and evaluation.&lt;SEP&gt;Reiichiro Nakano works on AI model training, especially in language and reasoning tasks.&lt;SEP&gt;Reiichiro Nakano is a researcher involved in human-computer interaction and AI research, contributing to studies on AI systems and user interfaces.&lt;SEP&gt;Reiichiro Nakano is a researcher involved in studies related to human-computer interaction and AI systems.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Ronan Collobert">
  <data key="d0">Ronan Collobert</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ronan Collobert developed the Torch machine learning library.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Samy Bengio">
  <data key="d0">Samy Bengio</data>
  <data key="d1">Researcher</data>
  <data key="d2">Samy Bengio is involved in machine learning research and neural network development.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Johnny Mariétroz">
  <data key="d0">Johnny Mariétroz</data>
  <data key="d1">Researcher</data>
  <data key="d2">Johnny Mariétroz contributed to machine learning software development.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="David Dohan">
  <data key="d0">David Dohan</data>
  <data key="d1">Researcher</data>
  <data key="d2">David Dohan works on language model cascades and AI architectures.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Winnie Xu">
  <data key="d0">Winnie Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Winnie Xu is involved in language modeling and cascade research.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Aitor Lewkowycz">
  <data key="d0">Aitor Lewkowycz</data>
  <data key="d1">Researcher</data>
  <data key="d2">Aitor Lewkowycz contributes to language model research and cascades.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jacob Austin">
  <data key="d0">Jacob Austin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jacob Austin works on language models and AI cascades.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="David Bieber">
  <data key="d0">David Bieber</data>
  <data key="d1">Researcher</data>
  <data key="d2">David Bieber is involved in language model research.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Raphael Gontijo Lopes">
  <data key="d0">Raphael Gontijo Lopes</data>
  <data key="d1">Researcher</data>
  <data key="d2">Raphael Gontijo Lopes contributes to language modeling research.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yuhuai Wu">
  <data key="d0">Yuhuai Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuhuai Wu works on language models and cascades.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Henryk Michalewski">
  <data key="d0">Henryk Michalewski</data>
  <data key="d1">Researcher</data>
  <data key="d2">Henryk Michalewski is involved in AI research related to language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Rif A Saurous">
  <data key="d0">Rif A Saurous</data>
  <data key="d1">Researcher</data>
  <data key="d2">Rif A Saurous contributes to language modeling and cascades.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jascha Sohl-Dickstein">
  <data key="d0">Jascha Sohl-Dickstein</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jascha Sohl-Dickstein works on language model cascades.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ehud Karpas">
  <data key="d0">Ehud Karpas</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ehud Karpas develops modular neuro-symbolic AI architectures.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Omri Abend">
  <data key="d0">Omri Abend</data>
  <data key="d1">Researcher</data>
  <data key="d2">Omri Abend works on neuro-symbolic reasoning and language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yonatan Belinkov">
  <data key="d0">Yonatan Belinkov</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yonatan Belinkov contributes to AI models integrating external knowledge.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Barak Lenz">
  <data key="d0">Barak Lenz</data>
  <data key="d1">Researcher</data>
  <data key="d2">Barak Lenz researches neuro-symbolic AI systems.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Opher Lieber">
  <data key="d0">Opher Lieber</data>
  <data key="d1">Researcher</data>
  <data key="d2">Opher Lieber is involved in neuro-symbolic AI architectures.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Nir Ratner">
  <data key="d0">Nir Ratner</data>
  <data key="d1">Researcher</data>
  <data key="d2">Nir Ratner works on integrating knowledge sources into AI models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yoav Shoham">
  <data key="d0">Yoav Shoham</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yoav Shoham contributes to AI systems combining neural and symbolic reasoning.&lt;SEP&gt;Yoav Shoham is a researcher known for contributions to AI, including language models and multi-agent systems.&lt;SEP&gt;Yoav Shoham is a researcher with contributions to AI, multi-agent systems, and language modeling.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Hofit Bata">
  <data key="d0">Hofit Bata</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hofit Bata works on neuro-symbolic AI architectures.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yoav Levine">
  <data key="d0">Yoav Levine</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yoav Levine is involved in research on language models and retrieval techniques for enhanced performance.&lt;SEP&gt;Yoav Levine researches AI systems with external knowledge integration.&lt;SEP&gt;Yoav Levine researches retrieval methods, language models, and their applications in AI systems.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Kevin Leyton-Brown">
  <data key="d0">Kevin Leyton-Brown</data>
  <data key="d1">Researcher</data>
  <data key="d2">Kevin Leyton-Brown contributes to AI reasoning and system design.&lt;SEP&gt;Kevin Leyton-Brown is involved in research on AI models, including language models and their applications.&lt;SEP&gt;Kevin Leyton-Brown works on AI, game theory, and transfer learning in language models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Keshav Santhanam">
  <data key="d0">Keshav Santhanam</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of work on effective retrieval via lightweight late interaction, 2021.&lt;SEP&gt;Keshav Santhanam works on relevance-guided supervision for open QA.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Xi">
  <data key="d0">Xi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xi is involved in AI research, possibly related to relevance supervision.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Omar Khattab">
  <data key="d0">Omar Khattab</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author contributing to multiple studies on neural information processing and retrieval models.&lt;SEP&gt;An author contributing to research on neural information processing, retrieval, and reasoning models.&lt;SEP&gt;Co-author in retrieval and IR efficiency research, 2021.&lt;SEP&gt;Co-author in retrieval and information retrieval efficiency, 2021.&lt;SEP&gt;Omar Khattab researches multi-hop reasoning and retrieval in AI.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Christopher Potts">
  <data key="d0">Christopher Potts</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in developing relevance-guided supervision and language models for NLP applications.&lt;SEP&gt;An author involved in research on relevance-guided supervision and language models for NLP.&lt;SEP&gt;Christopher Potts works on relevance supervision and QA systems.&lt;SEP&gt;Contributor to retrieval and language understanding research, 2021.&lt;SEP&gt;Contributor to retrieval and language understanding, 2021.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Matei Zaharia">
  <data key="d0">Matei Zaharia</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author contributing to scalable NLP methods and neural information processing systems.&lt;SEP&gt;An author contributing to studies on neural information processing and retrieval techniques.&lt;SEP&gt;Contributor to retrieval efficiency and big data systems, 2021.&lt;SEP&gt;Contributor to retrieval efficiency research, 2021.&lt;SEP&gt;Matei Zaharia contributes to AI retrieval and reasoning at scale.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jiaxin Huang">
  <data key="d0">Jiaxin Huang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiaxin Huang is involved in research on large language models and self-improvement.&lt;SEP&gt;Jiaxin Huang researches AI self-improvement methods.&lt;SEP&gt;Jiaxin Huang researches AI self-improvement.&lt;SEP&gt;Jiaxin Huang researches self-improving language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Shixiang Shane Gu">
  <data key="d0">Shixiang Shane Gu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shixiang Shane Gu contributed to research on large language models.&lt;SEP&gt;Shixiang Shane Gu participated in grounded language reasoning studies.&lt;SEP&gt;Shixiang Shane Gu works on language model self-improvement.&lt;SEP&gt;Shixiang Shane Gu works on self-improving language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e&lt;SEP&gt;chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Le Hou">
  <data key="d0">Le Hou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Le Hou contributes to AI models capable of self-improvement.&lt;SEP&gt;Le Hou contributes to models capable of self-improvement.&lt;SEP&gt;Le Hou is involved in AI self-improvement research.&lt;SEP&gt;Le Hou is involved in NLP research, especially in model self-improvement.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yuexin Wu">
  <data key="d0">Yuexin Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuexin Wu contributed to NLP research on model performance.&lt;SEP&gt;Yuexin Wu contributes to language model enhancement.&lt;SEP&gt;Yuexin Wu researches self-improving language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Xuezhi Wang">
  <data key="d0">Xuezhi Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on rationale-augmented ensembles and other techniques to improve reasoning in language models.&lt;SEP&gt;Contributor to recitation-augmented language models, 2022.&lt;SEP&gt;Contributor to recitation-augmented models, 2022.&lt;SEP&gt;Xuezhi Wang is an author working on rationale-augmented ensembles and reasoning improvements in large language models.&lt;SEP&gt;Xuezhi Wang works on AI self-improvement techniques.&lt;SEP&gt;Xuezhi Wang works on self-improvement techniques for language models.&lt;SEP&gt;Xuezhi Wang works on techniques for self-improvement in language models.&lt;SEP&gt;Xuezhi Wang is involved in NLP research and models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-3f464ce07046c0201c72becc8d51da3e&lt;SEP&gt;chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Hongkun Yu">
  <data key="d0">Hongkun Yu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hongkun Yu contributed to NLP research and model development.&lt;SEP&gt;Hongkun Yu contributes to AI development focusing on self-improvement.&lt;SEP&gt;Hongkun Yu contributes to AI model development.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jiawei Han">
  <data key="d0">Jiawei Han</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiawei Han is involved in NLP research, especially in knowledge and data analysis.&lt;SEP&gt;Jiawei Han specializes in data analysis and AI model enhancement.&lt;SEP&gt;Jiawei Han works on data analysis and AI model self-improvement.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Gautier Izacard">
  <data key="d0">Gautier Izacard</data>
  <data key="d1">Researcher</data>
  <data key="d2">Gautier Izacard researches few-shot learning with retrieval-augmented models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Patrick Lewis">
  <data key="d0">Patrick Lewis</data>
  <data key="d1">Researcher</data>
  <data key="d2">Patrick Lewis works on retrieval-augmented language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Maria Lomeli">
  <data key="d0">Maria Lomeli</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Toolformer and tool-use research, 2023.&lt;SEP&gt;Contributor to Toolformer research, 2023.&lt;SEP&gt;Maria Lomeli contributes to few-shot learning and retrieval techniques.&lt;SEP&gt;Maria Lomeli contributes to retrieval and few-shot learning in language models.&lt;SEP&gt;Maria Lomeli works on language model adaptation and multi-domain learning.&lt;SEP&gt;Maria Lomeli works on multi-domain adaptation and training of language models.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Lucas Hosseini">
  <data key="d0">Lucas Hosseini</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lucas Hosseini researches retrieval-augmented AI systems.&lt;SEP&gt;Lucas Hosseini works on retrieval-augmented AI systems.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Fabio Petroni">
  <data key="d0">Fabio Petroni</data>
  <data key="d1">Researcher</data>
  <data key="d2">Fabio Petroni researches retrieval-augmented language modeling.&lt;SEP&gt;Fabio Petroni works on retrieval-augmented language modeling.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Timo Schick">
  <data key="d0">Timo Schick</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of Toolformer, a model that enables language models to learn to use external tools, 2023.&lt;SEP&gt;Author of Toolformer, a model that learns to use tools, 2023.&lt;SEP&gt;Timo Schick contributes to few-shot learning and retrieval in language models.&lt;SEP&gt;Timo Schick researches tool use in language models and few-shot learning techniques.&lt;SEP&gt;Timo Schick researches tool use, prompt engineering, and few-shot learning techniques in language models.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jane Dwivedi-Yu">
  <data key="d0">Jane Dwivedi-Yu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Toolformer development, 2023.&lt;SEP&gt;Jane Dwivedi-Yu researches retrieval-augmented AI.&lt;SEP&gt;Jane Dwivedi-Yu works on retrieval-augmented AI.&lt;SEP&gt;Jane Dwivedi-Yu explores prompt engineering and training strategies for language models.&lt;SEP&gt;Jane Dwivedi-Yu works on prompt engineering and language model training strategies.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Armand Joulin">
  <data key="d0">Armand Joulin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Armand Joulin contributes to retrieval-augmented language models.&lt;SEP&gt;Armand Joulin works on retrieval-augmented language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sebastian Riedel">
  <data key="d0">Sebastian Riedel</data>
  <data key="d1">Researcher</data>
  <data key="d2">Sebastian Riedel involved in research on prompt learning and knowledge fusion.&lt;SEP&gt;Sebastian Riedel participated in prompt learning research.&lt;SEP&gt;Sebastian Riedel researches retrieval and few-shot learning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Edouard Grave">
  <data key="d0">Edouard Grave</data>
  <data key="d1">Researcher</data>
  <data key="d2">Edouard Grave contributes to retrieval-augmented language models.&lt;SEP&gt;Edouard Grave works on retrieval-augmented language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Qingyan Guo">
  <data key="d0">Qingyan Guo</data>
  <data key="d1">Researcher</data>
  <data key="d2">Qingyan Guo investigates connecting language models with evolutionary algorithms for prompt optimization.&lt;SEP&gt;Qingyan Guo investigates connecting large language models with evolutionary algorithms for prompt optimization.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Rui Wang">
  <data key="d0">Rui Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Rui Wang is involved in research on language models and evolutionary algorithms.&lt;SEP&gt;Rui Wang works on connecting large language models with evolutionary algorithms.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Junliang Guo">
  <data key="d0">Junliang Guo</data>
  <data key="d1">Researcher</data>
  <data key="d2">Junliang Guo researches prompt optimization using evolutionary algorithms.&lt;SEP&gt;Junliang Guo works on AI prompt optimization using evolutionary strategies.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bei Li">
  <data key="d0">Bei Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bei Li contributes to prompt optimization and language model connection.&lt;SEP&gt;Bei Li contributes to research on large language models and optimization.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Kaitao Song">
  <data key="d0">Kaitao Song</data>
  <data key="d1">Researcher</data>
  <data key="d2">Kaitao Song researches connecting language models with evolutionary algorithms.&lt;SEP&gt;Kaitao Song works on connecting language models with evolutionary algorithms.&lt;SEP&gt;Kaitao Song works on AI models, especially in multi-modal and multi-task settings.&lt;SEP&gt;Kaitao Song works on multi-modal AI models and multi-task frameworks.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Xu Tan">
  <data key="d0">Xu Tan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xu Tan focuses on speech and language model integration.&lt;SEP&gt;Xu Tan researches prompt optimization techniques.&lt;SEP&gt;Xu Tan works on AI prompt optimization and evolutionary algorithms.&lt;SEP&gt;Xu Tan researches speech and language model integration for AI applications.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Guoqing Liu">
  <data key="d0">Guoqing Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Guoqing Liu contributes to AI systems integrating evolutionary algorithms.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jiang Bian">
  <data key="d0">Jiang Bian</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiang Bian researches AI prompt optimization.&lt;SEP&gt;Jiang Bian researches prompt optimization and language model connection.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yujiu Yang">
  <data key="d0">Yujiu Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yujiu Yang works on connecting language models with evolutionary algorithms.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Kelvin Guu">
  <data key="d0">Kelvin Guu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on prompting and reasoning techniques in language models.&lt;SEP&gt;Kelvin Guu developed Realm, a retrieval-augmented language model pre-training method.&lt;SEP&gt;Kelvin Guu developed Realm, a retrieval-augmented pre-training method for language models.&lt;SEP&gt;Kelvin Guu developed Realm, a retrieval-augmented pre-training method.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Kenton Lee">
  <data key="d0">Kenton Lee</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to language models for NLP tasks.&lt;SEP&gt;A researcher involved in NLP models for language understanding.&lt;SEP&gt;Kenton Lee contributes to retrieval-augmented language model pre-training.&lt;SEP&gt;Kenton Lee contributes to retrieval-augmented language modeling.&lt;SEP&gt;Kenton Lee is a researcher focusing on retrieval methods in question answering systems.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Zora Tung">
  <data key="d0">Zora Tung</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zora Tung works on retrieval-augmented pre-training techniques.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Panupong Pasupat">
  <data key="d0">Panupong Pasupat</data>
  <data key="d1">Researcher</data>
  <data key="d2">Panupong Pasupat researches retrieval and language model pre-training.&lt;SEP&gt;Panupong Pasupat researches retrieval-based language model training.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ming-Wei Chang">
  <data key="d0">Ming-Wei Chang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher involved in NLP pre-training models and language understanding.&lt;SEP&gt;Ming-Wei Chang contributes to retrieval-augmented language models.&lt;SEP&gt;Ming-Wei Chang is a researcher working on question answering and information retrieval.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Braden Hancock">
  <data key="d0">Braden Hancock</data>
  <data key="d1">Researcher</data>
  <data key="d2">Braden Hancock works on training classifiers with natural language explanations.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Paroma Varma">
  <data key="d0">Paroma Varma</data>
  <data key="d1">Researcher</data>
  <data key="d2">Paroma Varma researches explanations for classifiers.&lt;SEP&gt;Paroma Varma researches natural language explanations for classifiers.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Stephanie Wang">
  <data key="d0">Stephanie Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Stephanie Wang contributes to explainable AI and natural language explanations.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Martin Bringmann">
  <data key="d0">Martin Bringmann</data>
  <data key="d1">Researcher</data>
  <data key="d2">Martin Bringmann works on AI explanations and classifier training.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Percy Liang">
  <data key="d0">Percy Liang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Percy Liang contributed to research on prefix-tuning for natural language generation.&lt;SEP&gt;Percy Liang contributed to research on prefix-tuning for optimizing prompts in language models.&lt;SEP&gt;Percy Liang researches natural language explanations for AI classifiers.&lt;SEP&gt;Percy Liang researches natural language explanations in AI.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Christopher Ré">
  <data key="d0">Christopher Ré</data>
  <data key="d1">Researcher</data>
  <data key="d2">Christopher Ré works on AI explanation methods.&lt;SEP&gt;Christopher Ré works on AI explanations and classifier training.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bin Hu">
  <data key="d0">Bin Hu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bin Hu develops reinforcement learning approaches for agent interactions.&lt;SEP&gt;Bin Hu develops reinforcement learning approaches for intelligent agent interactions.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Chenyang Zhao">
  <data key="d0">Chenyang Zhao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Chenyang Zhao contributes to reinforcement learning in AI agents.&lt;SEP&gt;Chenyang Zhao researches reinforcement learning in AI agents.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Pu Zhang">
  <data key="d0">Pu Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Pu Zhang researches reinforcement learning approaches.&lt;SEP&gt;Pu Zhang works on reinforcement learning approaches.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zihao Zhou">
  <data key="d0">Zihao Zhou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zihao Zhou researches reinforcement learning for intelligent interactions.&lt;SEP&gt;Zihao Zhou works on reinforcement learning for intelligent interactions.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yuanhang Yang">
  <data key="d0">Yuanhang Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuanhang Yang contributes to reinforcement learning in AI systems.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zenglin Xu">
  <data key="d0">Zenglin Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zenglin Xu researches reinforcement learning approaches.&lt;SEP&gt;Zenglin Xu researches reinforcement learning techniques.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yonghang Yang">
  <data key="d0">Yonghang Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yonghang Yang works on AI reinforcement learning methods.&lt;SEP&gt;Yonghang Yang works on reinforcement learning methods.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bin Liu">
  <data key="d0">Bin Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bin Liu develops reinforcement learning algorithms for AI agents.&lt;SEP&gt;Bin Liu develops reinforcement learning techniques for AI agents.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Program of thoughts prompting">
  <data key="d0">Program of thoughts prompting</data>
  <data key="d1">&lt;"Core Concepts</data>
  <data key="d2">A framework for disentangling computation from reasoning in numerical reasoning tasks, focusing on prompting strategies to improve reasoning capabilities.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Scaling language modeling with pathways">
  <data key="d0">Scaling language modeling with pathways</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A methodology for scaling large language models by utilizing pathways to improve efficiency and performance.&lt;SEP&gt;This methodology involves scaling language models using pathways to improve efficiency and performance at scale.&lt;SEP&gt;This methodology involves scaling language models using pathways to improve efficiency and performance.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Training verifiers to solve math word problems">
  <data key="d0">Training verifiers to solve math word problems</data>
  <data key="d1">&lt;"Methodologies</data>
  <data key="d2">A training approach for verifiers that evaluate and solve math word problems, enhancing model reasoning abilities.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Torch">
  <data key="d0">Torch</data>
  <data key="d1">&lt;"Tools</data>
  <data key="d2">A modular machine learning library developed by Ronan Collobert, used for building and training neural networks.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Language model cascades">
  <data key="d0">Language model cascades</data>
  <data key="d1">&lt;"Methodologies</data>
  <data key="d2">A technique involving sequential language models to improve performance on complex tasks by cascading simpler models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Research on research">
  <data key="d0">Research on research</data>
  <data key="d1">&lt;"Disciplines</data>
  <data key="d2">An overarching field studying the methodology, evaluation, and development of scientific research practices in AI.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Researching and revising what language models say (RARR)">
  <data key="d0">Researching and revising what language models say (RARR)</data>
  <data key="d1">&lt;"Core Concepts</data>
  <data key="d2">A methodology and framework for researching and revising the outputs of language models using models themselves to improve accuracy and consistency.&lt;SEP&gt;A technique involving using language models to evaluate and revise their own outputs to improve reliability.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Program-aided language models (PAL)">
  <data key="d0">Program-aided language models (PAL)</data>
  <data key="d1">&lt;"Core Concepts</data>
  <data key="d2">A class of language models designed to incorporate programming capabilities to enhance reasoning and problem-solving.&lt;SEP&gt;Language models integrated with programming tools to assist in complex reasoning tasks.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Connecting large language models with evolutionary algorithms">
  <data key="d0">Connecting large language models with evolutionary algorithms</data>
  <data key="d1">&lt;"Core Concepts</data>
  <data key="d2">A methodology combining language models with evolutionary algorithms to optimize prompts and model performance.&lt;SEP&gt;A technique for optimizing prompts and model parameters by leveraging evolutionary algorithms to improve language model outputs.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Retrieval-augmented language model pre-training (Realm)">
  <data key="d0">Retrieval-augmented language model pre-training (Realm)</data>
  <data key="d1">&lt;"Core Concepts</data>
  <data key="d2">A methodology for pre-training language models that incorporates retrieval mechanisms to enhance knowledge access and performance.&lt;SEP&gt;A pre-training approach that uses retrieval techniques to improve language model capabilities.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Training classifiers with natural language explanations">
  <data key="d0">Training classifiers with natural language explanations</data>
  <data key="d1">&lt;"Methodologies</data>
  <data key="d2">A methodology for training AI classifiers using natural language explanations to improve interpretability and accuracy.&lt;SEP&gt;Enhancing AI interpretability and transparency by incorporating natural language explanations in classifier training.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Connecting language models with evolutionary algorithms">
  <data key="d0">Connecting language models with evolutionary algorithms</data>
  <data key="d1">&lt;"Research Questions/Hypotheses</data>
  <data key="d2">Can evolutionary algorithms effectively optimize prompts and model performance in conjunction with large language models?&lt;SEP&gt;Preliminary studies suggest that evolutionary algorithms can improve prompt quality and model performance when integrated with language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt optimization using evolutionary algorithms">
  <data key="d0">Prompt optimization using evolutionary algorithms</data>
  <data key="d1">&lt;"Core Concepts</data>
  <data key="d2">A research focus on improving prompt quality for language models through evolutionary strategies.&lt;SEP&gt;A technique involving evolutionary algorithms to iteratively refine prompts for better model responses.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Self-improving language models">
  <data key="d0">Self-improving language models</data>
  <data key="d1">&lt;"Core Concepts</data>
  <data key="d2">Can language models autonomously improve their performance through feedback and self-training mechanisms?&lt;SEP&gt;Initial experiments demonstrate models can iteratively enhance their responses with minimal human intervention.&lt;SEP&gt;Models capable of enhancing their own performance through mechanisms like feedback and self-training.&lt;SEP&gt;Potential for developing AI systems that autonomously improve over time without human intervention.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Few-shot learning with retrieval augmented models">
  <data key="d0">Few-shot learning with retrieval augmented models</data>
  <data key="d1">&lt;"Core Concepts</data>
  <data key="d2">A methodology for enabling models to learn effectively from few examples by leveraging retrieval mechanisms.&lt;SEP&gt;Retrieval-augmented models that facilitate few-shot learning by accessing external knowledge sources.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Reinforcement learning for agent-agent interactions">
  <data key="d0">Reinforcement learning for agent-agent interactions</data>
  <data key="d1">&lt;"Core Concepts</data>
  <data key="d2">A methodology for training AI agents to interact and learn through reinforcement learning techniques.&lt;SEP&gt;Improving multi-agent systems' cooperation and decision-making capabilities.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Reinforcement learning approaches">
  <data key="d0">Reinforcement learning approaches</data>
  <data key="d1">&lt;"Theories/Models</data>
  <data key="d2">Various algorithms and frameworks designed to enable agents to learn optimal behaviors through rewards and penalties.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Discussions on AI self-improvement">
  <data key="d0">Discussions on AI self-improvement</data>
  <data key="d1">&lt;"Core Concepts</data>
  <data key="d2">A theoretical framework for understanding how AI models can evolve and enhance their own capabilities.&lt;SEP&gt;Potential to create more autonomous, efficient, and adaptable AI systems.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Limitations">
  <data key="d0">Limitations</data>
  <data key="d1">Limitations</data>
  <data key="d2">Challenges include the availability of domain-specific training data, the complexity of HPC codes, and the accuracy of performance predictions across diverse hardware and workloads.&lt;SEP&gt;Limitations refer to various challenges and constraints faced in the development, analysis, and application of AI models and algorithms. These include difficulties in analyzing dynamic algorithms that are hard to optimize statically, as well as the overheads incurred during compile-time optimization processes. Challenges also encompass variability in code quality, overreliance on AI suggestions, dataset constraints, and complexities in prompt design, all of which can impact the reliability and generalizability of results. 

Furthermore, current AI tools such as Codex and large language models (LLMs) face significant limitations, including inefficiencies in tokenization for code, difficulties handling long or complex docstrings, and challenges in reliably binding attributes to objects. These models often struggle with system-level code synthesis and longer chains of operations, indicating areas needing further research and improvement. Additional constraints involve the inherent issues of unstable results, hallucination of facts, lack of access to real-time data, and precision limitations in specific tasks.

The development and deployment of these models are also hampered by computational costs, the sparsity of training data, and the size of models, which can limit their robustness and generalizability, especially when synthetic data is used to simulate real-world high-performance computing (HPC) scenarios. Self-improvement techniques are currently limited by available computational resources and the risk of model degradation without proper oversight. 

Overall, these limitations highlight the need for improved metrics, standardized evaluation methodologies, and more efficient sampling and optimization strategies to enhance the reliability, efficiency, and applicability of AI-based code generation and analysis tools.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-d25502af8737c59d857916af40cc4020&lt;SEP&gt;chunk-04aecdc2586d2c7966e70e02cac846b0&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-e6eb755f9f73ae3f7c76aff0920fdfae&lt;SEP&gt;chunk-d8772ec3475b4e5b1b113032265f9d74&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Numerical reasoning tasks">
  <data key="d0">Numerical reasoning tasks</data>
  <data key="d1">&lt;"Objects of Study</data>
  <data key="d2">A set of tasks designed to evaluate models' abilities to perform calculations, reasoning, and problem-solving involving numbers.&lt;SEP&gt;Used to assess and improve the reasoning capabilities of AI models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt strategies">
  <data key="d0">Prompt strategies</data>
  <data key="d1">&lt;"Core Concepts</data>
  <data key="d2">Key to improving model performance and accuracy in various tasks.&lt;SEP&gt;Techniques and methodologies for designing prompts to elicit desired responses from language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Evaluation metrics">
  <data key="d0">Evaluation metrics</data>
  <data key="d1">Variables</data>
  <data key="d2">Criteria such as accuracy, correctness, and prediction error used to assess model performance on downstream tasks.&lt;SEP&gt;Quantitative measures used to assess the performance of language models on tasks.&lt;SEP&gt;Statistical and computational methods to analyze model outputs and performance.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Knowledge access mechanisms">
  <data key="d0">Knowledge access mechanisms</data>
  <data key="d1">&lt;"Tools</data>
  <data key="d2">Improve accuracy and factual correctness of language model outputs.&lt;SEP&gt;Mechanisms that allow models to retrieve relevant information from external sources.&lt;SEP&gt;Retrieval systems integrated into language models to enhance access to external knowledge.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Model evaluation and benchmarking">
  <data key="d0">Model evaluation and benchmarking</data>
  <data key="d1">&lt;"Study Designs</data>
  <data key="d2">Establish standards and measure progress in AI research.&lt;SEP&gt;Protocols and experiments designed to compare different models and techniques.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Robust Multi-Hop Reasoning at Scale">
  <data key="d0">Robust Multi-Hop Reasoning at Scale</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A research paper discussing scalable multi-hop reasoning techniques in NLP, utilizing condensed retrieval methods for efficient knowledge inference.&lt;SEP&gt;A research work focusing on scalable multi-hop reasoning techniques in natural language processing, utilizing condensed retrieval methods.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Condensed Retrieval">
  <data key="d0">Condensed Retrieval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A retrieval technique that compresses relevant information to enable large-scale multi-hop reasoning efficiently.&lt;SEP&gt;A technique for efficient information retrieval that condenses relevant data to improve reasoning at scale.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Relevance-guided Supervision">
  <data key="d0">Relevance-guided Supervision</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A supervision approach for open question answering that guides models based on relevance signals.&lt;SEP&gt;A supervision approach that guides models in open question answering based on relevance signals to improve accuracy.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="OpenQA">
  <data key="d0">OpenQA</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Open-domain question answering systems that retrieve and generate answers based on large knowledge sources.&lt;SEP&gt;Open-domain question answering systems that retrieve and generate answers from large knowledge bases.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ColBERT">
  <data key="d0">ColBERT</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural retrieval model optimized for fast document ranking in information retrieval tasks.&lt;SEP&gt;A retrieval model designed for fast and effective document ranking in information retrieval tasks.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Transactions of the Association for Computational Linguistics">
  <data key="d0">Transactions of the Association for Computational Linguistics</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A peer-reviewed journal publishing research on computational linguistics and NLP.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Demonstrate-search-predict">
  <data key="d0">Demonstrate-search-predict</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A framework combining retrieval and language models to perform knowledge-intensive NLP tasks.&lt;SEP&gt;A framework that combines retrieval and language models to perform knowledge-intensive NLP tasks effectively.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2212.14024">
  <data key="d0">arXiv preprint arXiv:2212.14024</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A preprint repository hosting the study on demonstrate-search-predict, indicating preliminary research data and methods.&lt;SEP&gt;A preprint repository hosting the study on demonstrate-search-predict, indicating preliminary research data.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Decomposed Prompting">
  <data key="d0">Decomposed Prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A modular prompting approach for solving complex NLP tasks by breaking them into simpler components.&lt;SEP&gt;A modular prompting approach that decomposes complex tasks into simpler sub-tasks for improved performance in NLP.&lt;SEP&gt;A modular prompting approach that decomposes complex tasks into simpler components for better performance.&lt;SEP&gt;A modular prompting approach to solve complex tasks efficiently.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Large Language Models">
  <data key="d0">Large Language Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Advanced predictive models trained on extensive source code datasets, capable of automating coding tasks and understanding programming languages.&lt;SEP&gt;Advanced predictive models trained on extensive source code datasets, capable of understanding and generating code, used as the foundation for HPC-Coder.&lt;SEP&gt;Large Language Models (LLMs) are advanced neural network-based artificial intelligence models trained on vast and diverse text datasets to understand, generate, and manipulate human-like language across a wide range of applications. They are capable of performing complex natural language processing (NLP) tasks such as text generation, summarization, translation, code completion, and code lookup without task-specific training, demonstrating zero-shot reasoning abilities. These models serve as versatile, task-agnostic foundations for various domains, enabling sophisticated problem-solving and automation in programming, education, and other fields. LLMs are designed to learn universal language representations through extensive pre-training, allowing them to understand and produce human-like text and code across multiple tasks. They are also utilized to automate programming tasks, assist in code generation, and support educational tools. Despite their impressive capabilities, LLMs have limitations, including unstable result formats, inability to access real-time information, tendencies to fabricate facts, and challenges in achieving high precision in specific tasks like arithmetic. Overall, Large Language Models represent a significant advancement in AI, providing powerful tools for natural language understanding and generation, while still facing ongoing challenges related to accuracy and reliability.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-1c77a184d805ecadcb8dd5b0d1057e7c&lt;SEP&gt;chunk-bb9f9f9e90a0c162892181da55ffb7b4&lt;SEP&gt;chunk-d8772ec3475b4e5b1b113032265f9d74&lt;SEP&gt;chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Zero-Shot Reasoning">
  <data key="d0">Zero-Shot Reasoning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ability of language models to perform tasks without explicit training on specific examples.&lt;SEP&gt;The ability of large language models to perform reasoning tasks without prior specific training on those tasks.&lt;SEP&gt;The ability of large language models to perform reasoning tasks without prior specific training, demonstrating generalization.&lt;SEP&gt;The capability of language models to perform tasks without explicit training examples, relying on learned knowledge.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Internet-Augmented Language Models">
  <data key="d0">Internet-Augmented Language Models</data>
  <data key="d1">Tools</data>
  <data key="d2">Language models enhanced with internet access to improve open-domain question answering via few-shot prompting.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Few-Shot Prompting">
  <data key="d0">Few-Shot Prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique where models learn to perform tasks with minimal examples provided in prompts, leveraging external data sources.&lt;SEP&gt;A technique where models learn to perform tasks with minimal examples provided in prompts, leveraging external knowledge sources.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Retrieval-Augmented Generation">
  <data key="d0">Retrieval-Augmented Generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">A technique combining information retrieval with language generation to improve accuracy in knowledge-intensive NLP tasks.&lt;SEP&gt;An approach combining retrieval mechanisms with generative models to improve knowledge-intensive NLP tasks.&lt;SEP&gt;Retrieval-Augmented Generation (RAG) is a method that combines pre-trained parametric and non-parametric memory for language generation, aimed at improving knowledge access, transparency, and revision capabilities in NLP models.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="URL https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf">
  <data key="d0">URL https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf</data>
  <data key="d1">Tools</data>
  <data key="d2">A detailed publication link describing retrieval-augmented generation methods and experiments.&lt;SEP&gt;A link to a detailed publication on retrieval-augmented generation methods.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="LlamaIndex">
  <data key="d0">LlamaIndex</data>
  <data key="d1">Tools</data>
  <data key="d2">A document retrieval and management framework used to support relevant document retrieval and chatbot applications.&lt;SEP&gt;A library that facilitates retrieval-augmented generation, emphasizing prompt engineering and integration with data sources.&lt;SEP&gt;A library that supports retrieval-augmented generation, emphasizing prompt engineering and integration with external data sources to enhance model responses.&lt;SEP&gt;A software library designed for building and querying large language models with structured data.&lt;SEP&gt;A software library designed to facilitate the building and querying of large language models with structured data.&lt;SEP&gt;LlamaIndex is a tool or framework used for document retrieval and management, supporting applications like relevant document retrieval and chatbots.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Self-Refine">
  <data key="d0">Self-Refine</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An iterative process where models improve their outputs through self-feedback loops, enhancing accuracy and consistency.&lt;SEP&gt;An iterative refinement process where models improve their outputs through self-feedback loops.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bryan McCann">
  <data key="d0">Bryan McCann</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in research on multitask learning and question answering in NLP.&lt;SEP&gt;An author involved in research on multitask learning, question answering, and NLP benchmarks.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Natural Language Decathlon">
  <data key="d0">Natural Language Decathlon</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A benchmark dataset and challenge for evaluating multitask learning as question answering across diverse NLP tasks.&lt;SEP&gt;A benchmark dataset and challenge for multitask learning as question answering across diverse NLP tasks.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Microsoft Semantic Kernel">
  <data key="d0">Microsoft Semantic Kernel</data>
  <data key="d1">Tools</data>
  <data key="d2">A framework for integrating semantic understanding and reasoning capabilities into applications, supporting advanced NLP functionalities.&lt;SEP&gt;A framework for integrating semantic understanding into applications, supporting advanced NLP functionalities.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="WebGPT">
  <data key="d0">WebGPT</data>
  <data key="d1">Tools</data>
  <data key="d2">A browser-assisted question-answering system that incorporates human feedback to improve response quality and factual accuracy.&lt;SEP&gt;A browser-assisted question-answering system that incorporates human feedback to improve responses.&lt;SEP&gt;WebGPT is a question-answering AI system that utilizes browser assistance and human feedback to improve responses.&lt;SEP&gt;WebGPT is an AI system that combines web browsing capabilities with human feedback to improve question-answering accuracy.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Human Feedback">
  <data key="d0">Human Feedback</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Data collected from human interactions used to guide and refine language model outputs, improving factual correctness and safety.&lt;SEP&gt;Data obtained from human interactions used to guide and improve language model outputs.&lt;SEP&gt;Human feedback involves human evaluators providing preferences or judgments on model outputs, which inform reward models and policy updates.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Training Language Models">
  <data key="d0">Training Language Models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Processes involving instruction following and human feedback to enhance model performance.&lt;SEP&gt;Processes involving instruction tuning, human feedback, and reinforcement learning to improve model alignment with human instructions.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="OpenAI">
  <data key="d0">OpenAI</data>
  <data key="d1">Organization</data>
  <data key="d2">An AI research organization known for developing large language models like GPT-4.&lt;SEP&gt;An AI research organization responsible for developing advanced language models like GPT-4 and conducting AI safety research.&lt;SEP&gt;OpenAI is an AI research organization responsible for developing advanced language models and system architectures.&lt;SEP&gt;OpenAI develops advanced AI models, including GPT-4, and provides APIs and libraries for AI application development.&lt;SEP&gt;OpenAI develops advanced AI models, including GPT-4, and provides APIs for AI applications.&lt;SEP&gt;OpenAI is a leading research organization in artificial intelligence, known for developing GPT models and related tools.&lt;SEP&gt;OpenAI is an artificial intelligence research organization responsible for developing advanced language models such as GPT-4.&lt;SEP&gt;Research organization specializing in developing advanced AI models, including GPT-4, with a focus on safe and beneficial AI deployment.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="URL https://arxiv.org/abs/2112.09332">
  <data key="d0">URL https://arxiv.org/abs/2112.09332</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A preprint describing WebGPT's architecture, training process, and human-in-the-loop data collection.&lt;SEP&gt;A preprint detailing WebGPT's architecture and human-in-the-loop training data.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="URL https://arxiv.org/abs/2203.02155">
  <data key="d0">URL https://arxiv.org/abs/2203.02155</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A preprint describing the training of GPT-4 with instruction following using human feedback.&lt;SEP&gt;A preprint detailing GPT-4's training, instruction-following, and reinforcement learning with human feedback.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="PyTorch">
  <data key="d0">PyTorch</data>
  <data key="d1">Tools</data>
  <data key="d2">A deep learning framework used as the backend for inference of open-source models in code generation tasks.&lt;SEP&gt;A deep learning framework used as the backend for inference of open-source models, enabling code generation and evaluation workflows.&lt;SEP&gt;A high-performance deep learning library enabling imperative programming styles for building and training neural networks.&lt;SEP&gt;A high-performance deep learning library used for training and deploying neural network models.&lt;SEP&gt;A high-performance deep learning library widely used for training neural networks and deploying NLP models.&lt;SEP&gt;PyTorch is a widely used deep learning library enabling flexible and high-performance AI model development.&lt;SEP&gt;PyTorch is an imperative-style, high-performance deep learning library used in AI research and development.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd&lt;SEP&gt;chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Din-sql">
  <data key="d0">Din-sql</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A decomposed in-context learning approach for translating natural language into SQL queries, incorporating self-correction mechanisms for accuracy.&lt;SEP&gt;A decomposed in-context learning approach for translating natural language text into SQL queries with self-correction mechanisms.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Internet-augmented Language Models">
  <data key="d0">Internet-augmented Language Models</data>
  <data key="d1">Tools</data>
  <data key="d2">Language models enhanced with internet access to improve open-domain question answering via external data retrieval.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Retrieval-augmented Generation">
  <data key="d0">Retrieval-augmented Generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">An approach that combines retrieval mechanisms with generative models to improve performance on knowledge-intensive NLP tasks.&lt;SEP&gt;Combining retrieval mechanisms with generation models to improve knowledge-intensive NLP tasks.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Associates, Inc.">
  <data key="d0">Associates, Inc.</data>
  <data key="d1">Organization</data>
  <data key="d2">A professional organization involved in academic publishing and conference proceedings, including the NeurIPS 2019 paper.&lt;SEP&gt;A professional organization involved in academic publishing, hosting conferences such as NeurIPS 2019, and disseminating research papers.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Mohammadreza Pourreza">
  <data key="d0">Mohammadreza Pourreza</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of a preprint on decomposed in-context learning of text-to-SQL with self-correction, published in 2023.&lt;SEP&gt;Author of a preprint paper on decomposed in-context learning of text-to-SQL with self-correction, published in 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Davood Rafiei">
  <data key="d0">Davood Rafiei</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author of the same preprint on text-to-SQL with Pourreza, 2023.&lt;SEP&gt;Co-author of the same preprint paper on text-to-SQL in 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ofir Press">
  <data key="d0">Ofir Press</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in measuring and narrowing the compositionality gap in language models, published in 2022.&lt;SEP&gt;Author involved in research measuring and narrowing the compositionality gap in language models, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Muru Zhang">
  <data key="d0">Muru Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author in language model compositionality research, 2022.&lt;SEP&gt;Co-author in the study on language model compositionality, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sewon Min">
  <data key="d0">Sewon Min</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to language model research, 2022.&lt;SEP&gt;Contributor to language models' compositionality studies, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ludwig Schmidt">
  <data key="d0">Ludwig Schmidt</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to language model compositionality and performance research, 2022.&lt;SEP&gt;Contributor to language model research, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Noah A Smith">
  <data key="d0">Noah A Smith</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to language model compositionality research, 2022.&lt;SEP&gt;Contributor to language models' compositionality and understanding, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Mike Lewis">
  <data key="d0">Mike Lewis</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher involved in NLP models for dialogue and story generation.&lt;SEP&gt;Contributor to language model compositionality research, 2022.&lt;SEP&gt;Contributor to language model research, 2022.&lt;SEP&gt;Mike Lewis is involved in research on language models and their applications in scientific domains.&lt;SEP&gt;Mike Lewis works on language representations, especially in scientific and chemical domains.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Reid Pryzant">
  <data key="d0">Reid Pryzant</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of a preprint on automatic prompt optimization using gradient descent and beam search, 2023.&lt;SEP&gt;Author of work on automatic prompt optimization using gradient descent and beam search, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Dan Iter">
  <data key="d0">Dan Iter</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author on prompt optimization methods, 2023.&lt;SEP&gt;Co-author on prompt optimization research, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jerry Li">
  <data key="d0">Jerry Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Collaborator in prompt optimization research, 2023.&lt;SEP&gt;Collaborator in prompt optimization study, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yin Tat Lee">
  <data key="d0">Yin Tat Lee</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to prompt optimization methods, 2023.&lt;SEP&gt;Contributor to prompt optimization techniques, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Chenguang Zhu">
  <data key="d0">Chenguang Zhu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author on prompt optimization research, 2023.&lt;SEP&gt;Co-author on prompt optimization with self-correction, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Michael Zeng">
  <data key="d0">Michael Zeng</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to prompt and language model research, 2023.&lt;SEP&gt;Contributor to prompt optimization research, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Peng Qi">
  <data key="d0">Peng Qi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of multiple papers on open-domain question answering, iterative query generation, 2019 and 2020.&lt;SEP&gt;Author of papers on answering complex open-domain questions and iterative query generation, 2019 and 2020.&lt;SEP&gt;Peng Qi is an author involved in research on datasets and models for complex, explainable multi-hop question answering.&lt;SEP&gt;Peng Qi is an author involved in research on datasets and models for complex, explainable question answering.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Xiaowen Lin">
  <data key="d0">Xiaowen Lin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author in question answering and iterative query research, 2019, 2020.&lt;SEP&gt;Co-author in question answering and query generation studies, 2019, 2020.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Leo Mehr">
  <data key="d0">Leo Mehr</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to complex question answering research, 2019, 2020.&lt;SEP&gt;Contributor to open-domain question answering research, 2019, 2020.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zijian Wang">
  <data key="d0">Zijian Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to open-domain QA and retrieval techniques, 2019, 2020.&lt;SEP&gt;Contributor to open-domain question answering research, 2019, 2020.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Christopher D. Manning">
  <data key="d0">Christopher D. Manning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Author of work on iterative query answering and retrieval, 2019, 2020.&lt;SEP&gt;Author of work on iterative query generation and retrieval-based question answering, 2019, 2020.&lt;SEP&gt;Christopher D. Manning is a researcher collaborating on advancements in natural language processing.&lt;SEP&gt;Christopher D. Manning is a researcher collaborating on natural language processing research and technological advances.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Alec Radford">
  <data key="d0">Alec Radford</data>
  <data key="d1">Researcher</data>
  <data key="d2">Alec Radford is a prominent researcher known for contributions to language models and AI development.&lt;SEP&gt;Author of a paper on improving language understanding via generative pre-training, 2018.&lt;SEP&gt;Author of foundational work on language modeling and pre-training, 2018.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Karthik Narasimhan">
  <data key="d0">Karthik Narasimhan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author on language understanding and pre-training, 2018.&lt;SEP&gt;Co-author on language understanding and unsupervised pre-training, 2018.&lt;SEP&gt;Karthik Narasimhan is an author working on reasoning and language understanding in models.&lt;SEP&gt;Karthik Narasimhan is an author working on reasoning, understanding, and multi-hop question answering in language models.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Tim Salimans">
  <data key="d0">Tim Salimans</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to language model pre-training research, 2018.&lt;SEP&gt;Contributor to language model pre-training techniques, 2018.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ilya Sutskever">
  <data key="d0">Ilya Sutskever</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author of foundational work on language model pre-training, 2018.&lt;SEP&gt;Co-author of seminal work on language model pre-training, 2018.&lt;SEP&gt;Ilya Sutskever is a prominent AI researcher and co-founder of OpenAI, involved in language model development.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Alexander J Ratner">
  <data key="d0">Alexander J Ratner</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of data programming approach for creating training sets, 2016.&lt;SEP&gt;Author of data programming methodology for rapid creation of large datasets, 2016.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Christopher M De Sa">
  <data key="d0">Christopher M De Sa</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author of data programming framework, 2016.&lt;SEP&gt;Co-author on data programming methodology, 2016.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sen Wu">
  <data key="d0">Sen Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to data programming research, 2016.&lt;SEP&gt;Contributor to data programming techniques, 2016.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Daniel Selsam">
  <data key="d0">Daniel Selsam</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to data programming for large training set creation, 2016.&lt;SEP&gt;Contributor to data programming, 2016.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Christopher R Ré">
  <data key="d0">Christopher R Ré</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of data programming framework for training data generation, 2016.&lt;SEP&gt;Author of data programming framework, 2016.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jon Saad-Falcon">
  <data key="d0">Jon Saad-Falcon</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to retrieval techniques, 2021.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Roberto Dessi">
  <data key="d0">Roberto Dessi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Toolformer research, 2023.&lt;SEP&gt;Contributor to Toolformer, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Roberta Raileanu">
  <data key="d0">Roberta Raileanu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in enabling language models to teach themselves to use tools, 2023.&lt;SEP&gt;Researcher involved in language model tool-use, 2023.&lt;SEP&gt;Roberta Raileanu researches language models, multitask training, and tool learning.&lt;SEP&gt;Roberta Raileanu researches multitask training, tool learning, and language model adaptation.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Luke Zettlemoyer">
  <data key="d0">Luke Zettlemoyer</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to language model tool-learning, 2023.&lt;SEP&gt;Contributor to language models learning to use tools, 2023.&lt;SEP&gt;Luke Zettlemoyer contributes to datasets and models for data science and code generation.&lt;SEP&gt;Luke Zettlemoyer works on datasets and models for data science code generation and evaluation.&lt;SEP&gt;Luke Zettlemoyer is involved in research on language understanding and few-shot learning.&lt;SEP&gt;Luke Zettlemoyer researches language understanding, few-shot learning, and model generalization.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Nicola Cancedda">
  <data key="d0">Nicola Cancedda</data>
  <data key="d1">Researcher</data>
  <data key="d2">Nicola Cancedda develops multi-task learning and domain adaptation techniques for language models.&lt;SEP&gt;Nicola Cancedda researches language models and their ability to learn multiple tasks.&lt;SEP&gt;Researcher involved in tool-learning in language models, 2023.&lt;SEP&gt;Researcher involved in tool-use in language models, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Thomas Scialom">
  <data key="d0">Thomas Scialom</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Toolformer and tool-learning models, 2023.&lt;SEP&gt;Contributor to research on language models teaching themselves to use tools, 2023.&lt;SEP&gt;Thomas Scialom researches fine-tuning and continual learning in language models.&lt;SEP&gt;Thomas Scialom researches fine-tuning, continual learning, and prompt strategies in NLP.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zhihong Shao">
  <data key="d0">Zhihong Shao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of work on synthetic prompting for chain-of-thought demonstrations, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yeyun Gong">
  <data key="d0">Yeyun Gong</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to synthetic prompting research, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yelong Shen">
  <data key="d0">Yelong Shen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to chain-of-thought prompting, 2023.&lt;SEP&gt;Yelong Shen contributed to research on adaptation methods for language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e&lt;SEP&gt;chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Minlie Huang">
  <data key="d0">Minlie Huang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to synthetic prompting and chain-of-thought demonstrations, 2023.&lt;SEP&gt;Contributor to synthetic prompting research, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Nan Duan">
  <data key="d0">Nan Duan</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on knowledge infusion into pre-trained models using adapters.&lt;SEP&gt;Contributor to chain-of-thought and synthetic prompting, 2023.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Weizhu Chen">
  <data key="d0">Weizhu Chen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in synthetic prompting, 2023.&lt;SEP&gt;Weizhu Chen contributed to research on NLP models and techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e&lt;SEP&gt;chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Noah Shinn">
  <data key="d0">Noah Shinn</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of Reflexion, an autonomous agent with dynamic memory and self-reflection capabilities, 2023.&lt;SEP&gt;Author of Reflexion, an autonomous agent with self-reflection, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Beck Labash">
  <data key="d0">Beck Labash</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Reflexion agent development, 2023.&lt;SEP&gt;Contributor to Reflexion agent, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ashwin Gopinath">
  <data key="d0">Ashwin Gopinath</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Reflexion project, 2023.&lt;SEP&gt;Contributor to Reflexion, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Chenglei Si">
  <data key="d0">Chenglei Si</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of work on making GPT-3 more reliable through prompting techniques, 2022.&lt;SEP&gt;Author of work on making GPT-3 more reliable through prompting, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zhe Gan">
  <data key="d0">Zhe Gan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to prompting reliability and robustness research, 2022.&lt;SEP&gt;Contributor to prompting reliability research, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zhengyuan Yang">
  <data key="d0">Zhengyuan Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to GPT-3 prompting and reliability studies, 2022.&lt;SEP&gt;Contributor to GPT-3 prompting research, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Shuohang Wang">
  <data key="d0">Shuohang Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to prompting techniques for GPT-3, 2022.&lt;SEP&gt;Contributor to prompting techniques, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jianfeng Wang">
  <data key="d0">Jianfeng Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to GPT-3 prompting reliability, 2022.&lt;SEP&gt;Contributor to GPT-3 reliability and prompting research, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jordan Boyd-Graber">
  <data key="d0">Jordan Boyd-Graber</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in prompting and language understanding, 2022.&lt;SEP&gt;Researcher involved in prompting, language understanding, and model reliability, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Lijuan Wang">
  <data key="d0">Lijuan Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to prompting reliability and language models, 2022.&lt;SEP&gt;Contributor to prompting techniques and language models, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zhiqing Sun">
  <data key="d0">Zhiqing Sun</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of recitation-augmented language models, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yi Tay">
  <data key="d0">Yi Tay</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to recitation-augmented language models, 2022.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yiming Yang">
  <data key="d0">Yiming Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to recitation-augmented models, 2022.&lt;SEP&gt;Yiming Yang works on language model training and evaluation, especially in code and natural language tasks.&lt;SEP&gt;Yiming Yang contributed to research on language models' commonsense capabilities.&lt;SEP&gt;Yiming Yang participated in research on language models' capabilities for commonsense and reasoning.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Denny Zhou">
  <data key="d0">Denny Zhou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in multiple studies on language models, reasoning, and prompting techniques.&lt;SEP&gt;Contributor to recitation-augmented language models, 2022.&lt;SEP&gt;Denny Zhou is an author involved in research on reasoning, ensemble methods, and prompting strategies for large language models.&lt;SEP&gt;Denny Zhou is an author involved in research on reasoning, ensembles, and prompting strategies in language models.&lt;SEP&gt;Denny Zhou contributed to grounded language reasoning research.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Seiya Tokui">
  <data key="d0">Seiya Tokui</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of Chainer, an open-source deep learning framework, 2015.&lt;SEP&gt;Author of Chainer, an open-source framework for deep learning, 2015.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Kenta Oono">
  <data key="d0">Kenta Oono</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Chainer framework, 2015.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Shohei Hido">
  <data key="d0">Shohei Hido</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Chainer, 2015.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Justin Clayton">
  <data key="d0">Justin Clayton</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Chainer, 2015.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Hugo Touvron">
  <data key="d0">Hugo Touvron</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of Llama 2, an open foundation and fine-tuned chat model, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Louis Martin">
  <data key="d0">Louis Martin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Llama 2 research, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Kevin Stone">
  <data key="d0">Kevin Stone</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Llama 2, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Peter Albert">
  <data key="d0">Peter Albert</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Llama 2, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Amjad Almahairi">
  <data key="d0">Amjad Almahairi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Amjad Almahairi contributes to machine learning models, including continual and transfer learning.&lt;SEP&gt;Amjad Almahairi works on machine learning models and continual learning techniques.&lt;SEP&gt;Contributor to Llama 2, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yasmine Babaei">
  <data key="d0">Yasmine Babaei</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Llama 2, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Nikolay Bashlykov">
  <data key="d0">Nikolay Bashlykov</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Llama 2, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Soumya Batra">
  <data key="d0">Soumya Batra</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Llama 2, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prajjwal Bhargava">
  <data key="d0">Prajjwal Bhargava</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Llama 2, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Shruti Bhosale">
  <data key="d0">Shruti Bhosale</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to Llama 2, 2023.&lt;SEP&gt;Shruti Bhosale is an author contributing to research on large language models and their development.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="et al.">
  <data key="d0">et al.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Indicates additional authors contributing to Llama 2 research, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Harsh Trivedi">
  <data key="d0">Harsh Trivedi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of work on interleaving retrieval with chain-of-thought reasoning for multi-step questions, 2023.&lt;SEP&gt;Harsh Trivedi is an author involved in research on retrieval and reasoning techniques in language models.&lt;SEP&gt;Harsh Trivedi is an author involved in research on retrieval techniques and chain-of-thought reasoning for knowledge-intensive questions.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Niranjan Balasubramanian">
  <data key="d0">Niranjan Balasubramanian</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to multi-step reasoning and retrieval research, 2023.&lt;SEP&gt;Contributor to multi-step reasoning research, 2023.&lt;SEP&gt;Niranjan Balasubramanian is an author contributing to research on multi-step question answering and knowledge-intensive reasoning.&lt;SEP&gt;Niranjan Balasubramanian is an author contributing to studies on multi-step reasoning and retrieval integration in language models.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Tushar Khot">
  <data key="d0">Tushar Khot</data>
  <data key="d1">Researcher</data>
  <data key="d2">Contributor to reasoning and retrieval integration, 2023.&lt;SEP&gt;Tushar Khot is an author involved in studies on reasoning methods in language models.&lt;SEP&gt;Tushar Khot is an author working on reasoning methods and multi-step question answering in language models.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ashish Sabharwal">
  <data key="d0">Ashish Sabharwal</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ashish Sabharwal is an author involved in research on chain-of-thought reasoning, knowledge integration, and complex question answering.&lt;SEP&gt;Ashish Sabharwal is an author working on chain-of-thought reasoning and knowledge integration in language models.&lt;SEP&gt;Contributor to reasoning and knowledge integration, 2023.&lt;SEP&gt;Contributor to reasoning, retrieval, and knowledge integration, 2023.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Llama 2">
  <data key="d0">Llama 2</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Llama 2 is a family of large language models known for their capabilities in code generation, supporting longer contexts and infilling.&lt;SEP&gt;Llama 2 is a family of large language models, including variants fine-tuned for code, supporting longer context lengths and infilling capabilities.&lt;SEP&gt;Llama 2 is an open foundation and fine-tuned chat model designed for natural language processing tasks, emphasizing large-scale language modeling and fine-tuning techniques.&lt;SEP&gt;Llama 2 is an open foundation and fine-tuned chat model developed for natural language processing tasks, emphasizing large-scale language modeling and fine-tuning techniques.&lt;SEP&gt;Open foundation and fine-tuned chat models, an advanced set of language models designed for open access and customization.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv preprint arXiv:2307.09288">
  <data key="d0">arXiv preprint arXiv:2307.09288</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint publication presenting research findings related to Llama 2, including its architecture and applications.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2212.10509">
  <data key="d0">arXiv preprint arXiv:2212.10509</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint detailing methods for interleaving retrieval with chain-of-thought reasoning to improve knowledge-intensive question answering.&lt;SEP&gt;A preprint publication detailing methods for interleaving retrieval with chain-of-thought reasoning for complex questions.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Fei Wang">
  <data key="d0">Fei Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Fei Wang is an author contributing to foundational research on backpropagation, callbacks, and efficient differentiable programming in neural networks.&lt;SEP&gt;Fei Wang is an author contributing to research on backpropagation and differentiable programming foundations.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="James Decker">
  <data key="d0">James Decker</data>
  <data key="d1">Researcher</data>
  <data key="d2">James Decker is an author involved in studies on efficient and expressive differentiable programming for neural networks.&lt;SEP&gt;James Decker is an author working on the foundations of efficient and expressive differentiable programming techniques.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Xilun Wu">
  <data key="d0">Xilun Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xilun Wu is an author involved in research on backpropagation with callbacks and foundational differentiable programming.&lt;SEP&gt;Xilun Wu is an author working on foundational aspects of backpropagation and differentiable programming.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Gregory Essertel">
  <data key="d0">Gregory Essertel</data>
  <data key="d1">Researcher</data>
  <data key="d2">Gregory Essertel is an author contributing to the development of differentiable programming techniques.&lt;SEP&gt;Gregory Essertel is an author working on the theoretical foundations for efficient and expressive differentiable programming.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Tiark Rompf">
  <data key="d0">Tiark Rompf</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tiark Rompf is an author contributing to the theoretical and practical foundations of differentiable programming.&lt;SEP&gt;Tiark Rompf is an author involved in foundational research on efficient differentiable programming.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Advances in Neural Information Processing Systems, volume 31">
  <data key="d0">Advances in Neural Information Processing Systems, volume 31</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A conference proceeding that includes foundational research on backpropagation and differentiable programming.&lt;SEP&gt;A conference volume containing foundational research on backpropagation, callbacks, and differentiable programming.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jason Wei">
  <data key="d0">Jason Wei</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in multiple studies on language model reasoning, prompting, and zero-shot capabilities.&lt;SEP&gt;Author involved in multiple studies on zero-shot learning, emergent abilities, and prompting techniques in large language models.&lt;SEP&gt;Jason Wei contributed to research on grounded reasoning in language models.&lt;SEP&gt;Jason Wei is an author contributing to research on chain of thought prompting, self-consistency, and reasoning techniques in language models.&lt;SEP&gt;Jason Wei is an author involved in research on chain of thought prompting and self-consistency in reasoning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Dale Schuurmans">
  <data key="d0">Dale Schuurmans</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in studies on ensemble methods and reasoning in language models.&lt;SEP&gt;Dale Schuurmans explores the computational universality of memory-augmented language models.&lt;SEP&gt;Dale Schuurmans investigates the computational universality of memory-augmented large language models.&lt;SEP&gt;Dale Schuurmans is an author contributing to ensemble methods and reasoning techniques in language models.&lt;SEP&gt;Dale Schuurmans is an author involved in ensemble methods and reasoning strategies to enhance language model performance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Quoc Le">
  <data key="d0">Quoc Le</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in studies on language model training, prompting, and reasoning capabilities.&lt;SEP&gt;Quoc Le is a researcher focused on neural architectures and language models.&lt;SEP&gt;Quoc Le is an author focused on language model reasoning and model optimization.&lt;SEP&gt;Quoc Le is an author working on language model reasoning, optimization, and model selection techniques.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Ed Chi">
  <data key="d0">Ed Chi</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on language models and reasoning techniques.&lt;SEP&gt;Ed Chi is an author contributing to reasoning, ensemble strategies, and prompting methods in language models.&lt;SEP&gt;Ed Chi is an author working on reasoning and ensemble techniques in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2207.00747">
  <data key="d0">arXiv preprint arXiv:2207.00747</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint exploring rationale-augmented ensembles in language models for improved reasoning.&lt;SEP&gt;A preprint exploring rationale-augmented ensembles to improve reasoning in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2203.11171">
  <data key="d0">arXiv preprint arXiv:2203.11171</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint discussing self-consistency methods to enhance chain of thought reasoning in language models.&lt;SEP&gt;A preprint discussing self-consistency methods to enhance chain of thought reasoning in large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2201.11903">
  <data key="d0">arXiv preprint arXiv:2201.11903</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint demonstrating how chain of thought prompting elicits reasoning capabilities in large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Thomas Wolf">
  <data key="d0">Thomas Wolf</data>
  <data key="d1">Researcher</data>
  <data key="d2">Thomas Wolf contributes to datasets and machine learning models for software analysis.&lt;SEP&gt;Thomas Wolf contributes to datasets and machine learning models for source code analysis.&lt;SEP&gt;Thomas Wolf is an author involved in state-of-the-art NLP research, including transformer models and system demonstrations.&lt;SEP&gt;Thomas Wolf is an author involved in state-of-the-art natural language processing research, including transformer models.&lt;SEP&gt;Thomas Wolf is a researcher involved in developing and training large language models.&lt;SEP&gt;Thomas Wolf is involved in developing and training large language models, including GPT variants.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Lysandre Debut">
  <data key="d0">Lysandre Debut</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lysandre Debut is an author contributing to NLP system demonstrations and transformer-based models.&lt;SEP&gt;Lysandre Debut is an author contributing to transformer-based NLP system demonstrations and model development.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Victor Sanh">
  <data key="d0">Victor Sanh</data>
  <data key="d1">Researcher</data>
  <data key="d2">Victor Sanh is a researcher working on multitask prompt training and zero-shot generalization in language models.&lt;SEP&gt;Victor Sanh is an author working on transformer models and NLP advancements.&lt;SEP&gt;Victor Sanh is an author working on transformer models and advancing NLP techniques.&lt;SEP&gt;Victor Sanh researches multitask prompted training and zero-shot generalization in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Julien Chaumond">
  <data key="d0">Julien Chaumond</data>
  <data key="d1">Researcher</data>
  <data key="d2">Julien Chaumond is an author involved in NLP system development and transformer research.&lt;SEP&gt;Julien Chaumond is an author involved in developing transformer models and NLP systems.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Transformers: State-of-the-art natural language processing">
  <data key="d0">Transformers: State-of-the-art natural language processing</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A comprehensive overview of transformer architectures and their applications in NLP, highlighting the state-of-the-art techniques.&lt;SEP&gt;A comprehensive overview of transformer architectures, their state-of-the-art performance, and applications in NLP.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zhilin Yang">
  <data key="d0">Zhilin Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zhilin Yang is an author working on datasets and models for multi-hop question answering and explainability.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Saizheng Zhang">
  <data key="d0">Saizheng Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Saizheng Zhang is an author contributing to datasets and models designed for multi-hop reasoning tasks.&lt;SEP&gt;Saizheng Zhang is an author contributing to multi-hop reasoning and NLP datasets.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yoshua Bengio">
  <data key="d0">Yoshua Bengio</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yoshua Bengio is a prominent AI researcher involved in deep learning, foundational NLP, and reasoning methodologies.&lt;SEP&gt;Yoshua Bengio is a prominent researcher in deep learning and NLP, involved in foundational AI research.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ruslan Salakhutdinov">
  <data key="d0">Ruslan Salakhutdinov</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ruslan Salakhutdinov is an author involved in deep learning models and reasoning datasets for NLP.&lt;SEP&gt;Ruslan Salakhutdinov is an author working on deep learning models for NLP and reasoning tasks.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Christopher D Manning">
  <data key="d0">Christopher D Manning</data>
  <data key="d1">Researcher</data>
  <data key="d2">Christopher D Manning is an author known for work on NLP datasets and multi-hop question answering.&lt;SEP&gt;Christopher D Manning is an author specializing in NLP, datasets, and multi-hop question answering.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="HotpotQA">
  <data key="d0">HotpotQA</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">HotpotQA is a dataset designed for multi-hop question answering that requires reasoning over multiple facts and explanations.&lt;SEP&gt;HotpotQA is a dataset designed for multi-hop question answering, requiring reasoning over multiple facts and providing explanations.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:1809.09600">
  <data key="d0">arXiv preprint arXiv:1809.09600</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint describing HotpotQA, emphasizing its focus on diverse, explainable multi-hop reasoning tasks.&lt;SEP&gt;A preprint describing the HotpotQA dataset, emphasizing diverse and explainable multi-hop reasoning.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Shunyu Yao">
  <data key="d0">Shunyu Yao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shunyu Yao is an author working on reasoning and acting in language models, integrating reasoning with decision-making.&lt;SEP&gt;Shunyu Yao is an author working on reasoning and acting strategies in language models, aiming to synergize reasoning and decision-making.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jeffrey Zhao">
  <data key="d0">Jeffrey Zhao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jeffrey Zhao is an author involved in reasoning, acting, and language model research.&lt;SEP&gt;Jeffrey Zhao is an author involved in research on reasoning, actuation, and language model capabilities.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Dian Yu">
  <data key="d0">Dian Yu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dian Yu is an author contributing to reasoning and actuation techniques in language models.&lt;SEP&gt;Dian Yu is an author contributing to reasoning and language model actuation strategies.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Nan Du">
  <data key="d0">Nan Du</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on fine-tuning and prompting in language models.&lt;SEP&gt;Nan Du is an author working on reasoning in language models.&lt;SEP&gt;Nan Du is an author working on reasoning processes and model actuation strategies in NLP.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Izhak Shafran">
  <data key="d0">Izhak Shafran</data>
  <data key="d1">Researcher</data>
  <data key="d2">Izhak Shafran is an author involved in reasoning and language model research.&lt;SEP&gt;Izhak Shafran is an author involved in reasoning, meta-reasoning, and language model research.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yuan Cao">
  <data key="d0">Yuan Cao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuan Cao is an author contributing to reasoning frameworks and language model development.&lt;SEP&gt;Yuan Cao is an author focusing on reasoning and language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2210.03629">
  <data key="d0">arXiv preprint arXiv:2210.03629</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint on React, a framework for synergizing reasoning and acting in language models, integrating reasoning with decision-making.&lt;SEP&gt;A preprint on React, a framework for synergizing reasoning and acting in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ori Yoran">
  <data key="d0">Ori Yoran</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ori Yoran is an author researching meta-reasoning and multi-chain reasoning in language models.&lt;SEP&gt;Ori Yoran is an author researching meta-reasoning strategies and multi-chain reasoning techniques in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Tomer Wolfson">
  <data key="d0">Tomer Wolfson</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tomer Wolfson is an author involved in meta-reasoning and multi-chain question answering research.&lt;SEP&gt;Tomer Wolfson is an author involved in meta-reasoning and multi-chain question answering.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ben Bogin">
  <data key="d0">Ben Bogin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ben Bogin is an author working on meta-reasoning, multi-chain reasoning, and improving reasoning robustness.&lt;SEP&gt;Ben Bogin is an author working on reasoning strategies and meta-cognition in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Uri Katz">
  <data key="d0">Uri Katz</data>
  <data key="d1">Researcher</data>
  <data key="d2">Uri Katz is an author contributing to meta-reasoning over multiple chains of thought in language models.&lt;SEP&gt;Uri Katz is an author focusing on meta-reasoning over multiple chains of thought.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Daniel Deutch">
  <data key="d0">Daniel Deutch</data>
  <data key="d1">Researcher</data>
  <data key="d2">Daniel Deutch is an author involved in research on reasoning over multiple chains in language models.&lt;SEP&gt;Daniel Deutch is an author working on meta-reasoning, multi-chain reasoning, and question answering.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jonathan Berant">
  <data key="d0">Jonathan Berant</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher specializing in question answering and NLP methodologies.&lt;SEP&gt;Jonathan Berant is an author involved in research on reasoning, question answering, and meta-reasoning frameworks.&lt;SEP&gt;Jonathan Berant is an author working on meta-reasoning and question answering.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Star: Bootstrapping reasoning with reasoning">
  <data key="d0">Star: Bootstrapping reasoning with reasoning</data>
  <data key="d1">Tools</data>
  <data key="d2">Star is a framework or methodology that uses bootstrapping techniques to enhance reasoning capabilities in language models.&lt;SEP&gt;Star is a reasoning framework that uses bootstrapping techniques to improve reasoning capabilities in models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2203.14465">
  <data key="d0">arXiv preprint arXiv:2203.14465</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint discussing Star, a method for bootstrapping and improving reasoning in language models.&lt;SEP&gt;A preprint discussing Star, a method for bootstrapping reasoning processes in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bhargava">
  <data key="d0">Bhargava</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bhargava is an author involved in research on language models and foundational AI methodologies.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GenerateSearchQuery">
  <data key="d0">GenerateSearchQuery</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A class in Python that defines explicit instructions for transforming input fields into search queries, allowing for controlled and programmable query generation.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.Signature">
  <data key="d0">dspy.Signature</data>
  <data key="d1">Tools</data>
  <data key="d2">A class defining the signature of a model, including input and output specifications.&lt;SEP&gt;A core component in DSPy representing a formal specification of how to process inputs into outputs, used to define transformation processes within language model pipelines.&lt;SEP&gt;A signature in DSPy that specifies how to process input data and generate output, used for defining transformation processes in language model pipelines.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.InputField">
  <data key="d0">dspy.InputField</data>
  <data key="d1">Tools</data>
  <data key="d2">A class representing an input data field with descriptive metadata, used to specify the inputs required for a DSPy signature.&lt;SEP&gt;A class representing an input field in DSPy, with descriptive metadata to guide data collection or processing.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.OutputField">
  <data key="d0">dspy.OutputField</data>
  <data key="d1">Tools</data>
  <data key="d2">A class representing an output data field with specified data type and description, used to define the outputs of a DSPy signature.&lt;SEP&gt;A class representing an output field in DSPy, specifying the expected output type and description of the generated data.&lt;SEP&gt;A class representing an output field in a model signature, used for structuring model inputs or outputs.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.Predict">
  <data key="d0">dspy.Predict</data>
  <data key="d1">Tools</data>
  <data key="d2">A class responsible for executing predictions based on a given signature.&lt;SEP&gt;A module in DSPy that applies a signature to generate predictions or outputs based on input data, facilitating structured language model tasks.&lt;SEP&gt;A module that applies a defined signature to generate predictions or outputs based on specified inputs, facilitating structured language model tasks.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Language typology">
  <data key="d0">Language typology</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The classification and analysis of languages based on shared features, used here as the context for generating language classification queries.&lt;SEP&gt;The study of classification and analysis of languages based on shared features, used here as an example context for query generation.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Query generation">
  <data key="d0">Query generation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The process of creating search queries from context and questions to retrieve relevant information efficiently.&lt;SEP&gt;The process of creating search queries from context and questions to retrieve relevant information, exemplified by the query generation system.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Synthetic IR dataset">
  <data key="d0">Synthetic IR dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A synthetically created dataset consisting of information retrieval queries and related data used to train or evaluate models.&lt;SEP&gt;A synthetically created dataset used for training or evaluating information retrieval models, comprising generated queries and related data.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt engineering">
  <data key="d0">Prompt engineering</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The practice of designing and structuring prompts to elicit specific responses from language models, often involving extensive templates and templates.&lt;SEP&gt;The practice of designing, structuring, and optimizing prompts to elicit desired responses from language models, often involving extensive templates and templates.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt templates">
  <data key="d0">Prompt templates</data>
  <data key="d1">Tools</data>
  <data key="d2">Predefined structured prompts used to guide language model responses, often lengthy and tailored for specific tasks.&lt;SEP&gt;Predefined structured prompts used to guide language model responses, often lengthy and task-specific, designed to improve response accuracy and relevance.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt length">
  <data key="d0">Prompt length</data>
  <data key="d1">Variables</data>
  <data key="d2">The number of words or characters in a prompt, affecting model performance and prompt engineering complexity.&lt;SEP&gt;The number of words or characters in a prompt, influencing model performance, response quality, and prompt engineering complexity.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="LangChain">
  <data key="d0">LangChain</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A framework or tool used to implement language models and support tasks such as solving math word problems and question answering.&lt;SEP&gt;A library focused on chaining language model prompts and tasks, often involving manual prompt engineering with extensive templates for various applications.&lt;SEP&gt;A library focused on chaining language model prompts and tasks, often involving manual prompt engineering with extensive templates.&lt;SEP&gt;LangChain is a framework or tool used to implement language models and related applications, such as math problem solving and question answering.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt automation">
  <data key="d0">Prompt automation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using structured frameworks like DSPy to automatically generate and bootstrap prompts, reducing manual effort and improving modularity.&lt;SEP&gt;Using structured frameworks like DSPy to automatically generate, bootstrap, and optimize prompts, reducing manual effort and increasing modularity and scalability.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt complexity">
  <data key="d0">Prompt complexity</data>
  <data key="d1">Limitations</data>
  <data key="d2">The challenge posed by lengthy, handcrafted prompts in existing libraries, which can hinder scalability and adaptability.&lt;SEP&gt;The challenges posed by lengthy, handcrafted prompts in existing libraries, which can hinder scalability, maintainability, and adaptability of language model applications.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Python class GenerateSearchQuery">
  <data key="d0">Python class GenerateSearchQuery</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A Python class that defines explicit instructions for transforming input data into search queries, enabling controlled and programmable query generation for information retrieval tasks.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Gao et al. (2023a)">
  <data key="d0">Gao et al. (2023a)</data>
  <data key="d1">Study Design</data>
  <data key="d2">A research study conducted by Gao and colleagues in 2023, likely involving analysis of evidence or character data.&lt;SEP&gt;A study or research project conducted by Gao and colleagues in 2023, possibly involving evidence collection or analysis.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Nasal Cycle">
  <data key="d0">Nasal Cycle</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A physiological process where airflow switches between nostrils approximately every 2 hours to prevent mucus buildup, involving congestion and decongestion patterns.&lt;SEP&gt;The nasal cycle is a physiological process where airflow alternates between nostrils approximately every 2 hours, to prevent mucus buildup.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Little House Books">
  <data key="d0">Little House Books</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A series of children's books authored by Laura Ingalls Wilder, significant in literary and cultural contexts.&lt;SEP&gt;A series of children's books written by Laura Ingalls Wilder, notable for their cultural and literary significance.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Laura Ingalls Wilder">
  <data key="d0">Laura Ingalls Wilder</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Author of the Little House books, studied for their literary and cultural impact.&lt;SEP&gt;Author of the Little House books, whose works are studied for their literary and cultural impact.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="HarperCollins">
  <data key="d0">HarperCollins</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A publishing company that published the Little House books.&lt;SEP&gt;The publishing company that published the Little House books.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Stanford Prison Experiment">
  <data key="d0">Stanford Prison Experiment</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A famous psychological study conducted in 1971 to examine authority and power dynamics in a simulated prison environment.&lt;SEP&gt;A psychological study conducted in 1971 to examine authority and power dynamics in a simulated prison environment.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jordan Hall">
  <data key="d0">Jordan Hall</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The location of the Stanford Prison Experiment, specifically in the basement of Jordan Hall at Stanford University, conducted in August 1971.&lt;SEP&gt;The location where the Stanford Prison Experiment was conducted, specifically in the basement of Jordan Hall at Stanford University.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Social Work">
  <data key="d0">Social Work</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A professional discipline rooted in humanism, emerging in the 1880s, focusing on social justice, support, and intervention.&lt;SEP&gt;A professional discipline rooted in humanism, focusing on social justice, support, and intervention, emerging in the 1880s.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Havel-Hakimi Algorithm">
  <data key="d0">Havel-Hakimi Algorithm</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">An algorithm used for constructing or verifying the existence of simple graphs with a given degree sequence, based on recursive procedures, published by Havel (1955) and Hakimi (1962).&lt;SEP&gt;An algorithm used to construct or verify the existence of simple graphs with a given degree sequence, based on recursive procedures, published by Havel (1955) and Hakimi (1962).</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Time of My Life&quot; (song)">
  <data key="d0">Time of My Life" (song)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A song by Bill Medley from the 1987 film Dirty Dancing, produced by Michael Lloyd, notable in music and film history.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Michael Lloyd">
  <data key="d0">Michael Lloyd</data>
  <data key="d1">Tools</data>
  <data key="d2">A music producer who produced the song 'Time of My Life' and contributed to its remix and digital release.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Kelvin Hopins">
  <data key="d0">Kelvin Hopins</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A former Labor Party MP suspended due to allegations of sexual harassment and inappropriate behavior towards activist Ava Etemadzadeh, investigated in 2017.&lt;SEP&gt;A former Labour Party MP suspended in relation to allegations of sexual harassment and inappropriate behavior towards activist Ava Etemadzadeh, investigated in 2017.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Characters">
  <data key="d0">Characters</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The characters involved in the textual analysis or character-based AI tasks discussed in the document.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 1">
  <data key="d0">Prompt 1</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A specific prompt related to text-evidence checking involving character analysis.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 2">
  <data key="d0">Prompt 2</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A prompt involving math word problems (PAL) and AI problem-solving frameworks.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 3">
  <data key="d0">Prompt 3</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A prompt involving ReAct methodology in AI or reasoning tasks.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 4">
  <data key="d0">Prompt 4</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A prompt involving Zero-shot ReAct using LangChain framework.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 5">
  <data key="d0">Prompt 5</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A prompt involving question answering with sources, utilizing LangChain.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 6">
  <data key="d0">Prompt 6</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A prompt involving SQL querying with MyScale and LangChain.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 7">
  <data key="d0">Prompt 7</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A prompt involving relevant document retrieval using LlamaIndex.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 8">
  <data key="d0">Prompt 8</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A prompt involving an IRS chatbot powered by LlamaIndex.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Time of My Life (song)">
  <data key="d0">Time of My Life (song)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A song by Bill Medley from the 1987 film Dirty Dancing, produced by Michael Lloyd, notable in music and film history.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Kelvin Hopkins">
  <data key="d0">Kelvin Hopkins</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Kelvin Hopkins is an individual accused of inappropriate physical contact and sexual harassment, with a suspension by the Labour party pending investigation.&lt;SEP&gt;Kelvin Hopkins is an individual accused of inappropriate physical contact and sexual harassment, with a suspension pending investigation by the Labour party.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="2017">
  <data key="d0">2017</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research on Lift, a functional IR designed to facilitate high-performance code generation for GPU architectures.&lt;SEP&gt;Research on a functional intermediate representation (IR) called Lift for high-performance GPU code generation.&lt;SEP&gt;The year 2017 is when Kelvin Hopkins was accused of misconduct, indicating a temporal context for the allegation.&lt;SEP&gt;The year 2017 is when Kelvin Hopkins was accused of misconduct, providing a temporal context for the allegations.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Labour Party">
  <data key="d0">Labour Party</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The Labour Party is the organization that suspended Kelvin Hopkins following allegations of sexual harassment and inappropriate behavior.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ava Etemadzadeh">
  <data key="d0">Ava Etemadzadeh</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Ava Etemadzadeh is the Labour Party activist allegedly subjected to sexual harassment by Kelvin Hopkins.&lt;SEP&gt;Ava Etemadzadeh is the Labour Party activist who accused Kelvin Hopkins of sexual harassment and inappropriate conduct.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sexual Harassment Allegations">
  <data key="d0">Sexual Harassment Allegations</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The investigation aims to determine whether Kelvin Hopkins engaged in inappropriate sexual behavior towards an activist, and to conclude the case based on evidence.&lt;SEP&gt;The investigation aims to determine whether Kelvin Hopkins engaged in sexual harassment and inappropriate contact, and to conclude the case based on collected evidence.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Investigation">
  <data key="d0">Investigation</data>
  <data key="d1">Methodology</data>
  <data key="d2">An investigation process was conducted by the Labour Party to assess the allegations against Kelvin Hopkins, leading to his suspension.&lt;SEP&gt;An investigation process was conducted to confirm or deny the allegations against Kelvin Hopkins, leading to his suspension.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Suspension">
  <data key="d0">Suspension</data>
  <data key="d1">Results</data>
  <data key="d2">Kelvin Hopkins was suspended by the Labour Party as a result of the investigation into the allegations.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Inappropriate Physical Contact">
  <data key="d0">Inappropriate Physical Contact</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Inappropriate physical contact refers to unwanted or improper physical interactions, which Kelvin Hopkins was accused of engaging in.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="2017 Allegations">
  <data key="d0">2017 Allegations</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The 2017 allegations refer to the specific case and timeline of accusations against Kelvin Hopkins.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Party Confirmation">
  <data key="d0">Party Confirmation</data>
  <data key="d1">Results</data>
  <data key="d2">The Labour Party confirmed the allegations and the suspension of Kelvin Hopkins, concluding the investigation.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Leah">
  <data key="d0">Leah</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Leah is a person characterized by her possession of chocolates, involved in a problem-solving scenario about sharing and remaining chocolates.&lt;SEP&gt;Leah is a person with a certain number of chocolates, involved in a problem-solving scenario about sharing chocolates.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sister">
  <data key="d0">Sister</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Leah's sister is a person with chocolates, participating in a similar problem-solving context.&lt;SEP&gt;Leah's sister is a person with chocolates, participating in the same problem about sharing and consumption.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Chocolates">
  <data key="d0">Chocolates</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Chocolates are objects being counted and shared between Leah and her sister in a mathematical problem.&lt;SEP&gt;Chocolates are objects being counted, eaten, and remaining, central to the problem involving Leah and her sister.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Total Chocolates">
  <data key="d0">Total Chocolates</data>
  <data key="d1">Variables</data>
  <data key="d2">The sum of Leah's and her sister's chocolates, used as the initial total before consumption.&lt;SEP&gt;The total number of chocolates Leah and her sister have initially, used to calculate remaining chocolates after consumption.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Chocolates Eaten">
  <data key="d0">Chocolates Eaten</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of chocolates consumed by Leah and her sister, affecting the total remaining chocolates.&lt;SEP&gt;The quantity of chocolates consumed by Leah and her sister, used to compute remaining chocolates.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Chocolates Left">
  <data key="d0">Chocolates Left</data>
  <data key="d1">Results</data>
  <data key="d2">Remaining chocolates after consumption, calculated by subtracting eaten chocolates from total.&lt;SEP&gt;The quantity of chocolates remaining after they ate some, derived from initial total and consumption.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Parking Lot">
  <data key="d0">Parking Lot</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A parking lot with a certain number of cars, involved in a problem about counting cars after arrivals.&lt;SEP&gt;A parking lot with a specific number of cars, involved in a counting problem after arrivals.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Cars Initial">
  <data key="d0">Cars Initial</data>
  <data key="d1">Variables</data>
  <data key="d2">Initial number of cars in the parking lot, used as a starting point for counting.&lt;SEP&gt;Number of cars initially present in the parking lot, used to determine total cars after new arrivals.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Cars Arrived">
  <data key="d0">Cars Arrived</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of cars that arrive later, added to the initial count to find total cars.&lt;SEP&gt;Number of new cars arriving in the parking lot, added to initial cars to find total.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Total Cars">
  <data key="d0">Total Cars</data>
  <data key="d1">Results</data>
  <data key="d2">Total number of cars after arrivals, calculated by summing initial cars and new arrivals.&lt;SEP&gt;Total number of cars in the parking lot after new cars arrive, calculated by addition.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Trees in Grove">
  <data key="d0">Trees in Grove</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Number of trees initially in the grove, involved in a planting problem.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Trees After">
  <data key="d0">Trees After</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Number of trees after planting, used to determine how many trees were added.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Trees Added">
  <data key="d0">Trees Added</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of trees planted by workers, calculated as the difference between after and initial trees.&lt;SEP&gt;Number of trees planted by workers, calculated as the difference between trees after and initial trees.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Problem in Python">
  <data key="d0">Problem in Python</data>
  <data key="d1">Methodology</data>
  <data key="d2">Using Python code to solve arithmetic problems involving counting, addition, and subtraction.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Math Question">
  <data key="d0">Math Question</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">How to computationally solve basic arithmetic word problems using code.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Solution Function">
  <data key="d0">Solution Function</data>
  <data key="d1">Methodology</data>
  <data key="d2">A Python function designed to implement the logic for solving the specific arithmetic problem described in each question.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Planting Activity">
  <data key="d0">Planting Activity</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The activity of planting trees by workers, resulting in the increase in total trees.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Python Solution">
  <data key="d0">Python Solution</data>
  <data key="d1">Tools</data>
  <data key="d2">Python code implementing arithmetic operations to solve the described word problems.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Arithmetic Operations">
  <data key="d0">Arithmetic Operations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Addition and subtraction used in Python code to solve the word problems.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Problem-solving Approach">
  <data key="d0">Problem-solving Approach</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Using code to simulate and solve real-world counting problems through logical and arithmetic operations.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Rebel Without a Cause">
  <data key="d0">Rebel Without a Cause</data>
  <data key="d1">Object of Study</data>
  <data key="d2">Rebel Without a Cause is a 1955 film that is a significant work in American cinema, associated with Elia Kazan.&lt;SEP&gt;Rebel Without a Cause is a notable 1955 American film that explores themes of youth alienation and family dynamics.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Elia Kazan">
  <data key="d0">Elia Kazan</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Elia Kazan was a prominent American film and theatre director, producer, screenwriter, and actor, influential in cinema and theatre arts.&lt;SEP&gt;Elia Kazan was a prominent American film and theatre director, producer, screenwriter, and actor, known for his influence in cinema and theatre.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Arthur’s Magazine">
  <data key="d0">Arthur’s Magazine</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Arthur’s Magazine was an American literary periodical published in Philadelphia from 1844 to 1846, representing 19th-century American literary culture.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="First for Women">
  <data key="d0">First for Women</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">First for Women is a women's magazine published by Bauer Media Group in the USA, first started in 1989, focusing on women's interests.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Pavel Urysohn">
  <data key="d0">Pavel Urysohn</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Pavel Urysohn was a Soviet mathematician best known for his contributions to dimension theory, influential in mathematical topology.&lt;SEP&gt;Pavel Urysohn was a Soviet mathematician known for his contributions to dimension theory, a branch of topology dealing with the concept of dimension in mathematical spaces.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Leonid Levin">
  <data key="d0">Leonid Levin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Leonid Levin is a Soviet-American mathematician and computer scientist known for his work in computational complexity and algorithms.&lt;SEP&gt;Leonid Levin is a Soviet-American mathematician and computer scientist known for his work in computational complexity theory and algorithms.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="1911">
  <data key="d0">1911</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">1911 refers to a specific year, indicating a temporal point relevant to the context of the film and historical references.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="June 16, 1979">
  <data key="d0">June 16, 1979</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">June 16, 1979 is a specific date, marking a significant point in time related to the film director's biography.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="American film director">
  <data key="d0">American film director</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An American film director is a person responsible for overseeing the creative aspects of filmmaking, exemplified here by the individual associated with the 1955 film Rebel Without a Cause.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Screenwriter">
  <data key="d0">Screenwriter</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A screenwriter is a person who writes scripts for films, contributing to the narrative and dialogue of movies.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Actor">
  <data key="d0">Actor</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An actor is a person who performs in films, embodying characters and bringing stories to life.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Film">
  <data key="d0">Film</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A film is a motion picture; here, Rebel Without a Cause is the specific film studied or referenced.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ukrainian People">
  <data key="d0">Ukrainian People</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The Ukrainian people are characterized by their fearlessness, courage, and determination, inspiring the world through their resilience and collective action.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Groups of Citizens Blocking Tanks">
  <data key="d0">Groups of Citizens Blocking Tanks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Thirty-two groups of citizens demonstrating bravery by physically blocking tanks with their bodies, exemplifying collective resistance.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="COVID-19">
  <data key="d0">COVID-19</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">COVID-19 is a highly impactful, deadly disease that has caused significant loss of life and social disruption, prompting a societal reflection and call for reset.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Loss of Life and Time">
  <data key="d0">Loss of Life and Time</data>
  <data key="d1">Variables</data>
  <data key="d2">The loss of life and time due to COVID-19 are critical variables reflecting the pandemic's impact on society and individual well-being.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Reset and Reconciliation">
  <data key="d0">Reset and Reconciliation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The text suggests a hypothesis that societal reflection and a shift in perspective can lead to unity and progress beyond pandemic divisions.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Partisan Divide">
  <data key="d0">Partisan Divide</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">COVID-19 is viewed as a partisan dividing line, which the speaker urges to transcend for societal unity.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Fellow Americans">
  <data key="d0">Fellow Americans</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The collective identity and shared humanity of Americans are emphasized as a basis for overcoming division.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="US Sanctions and Economic Measures">
  <data key="d0">US Sanctions and Economic Measures</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The US employs targeted sanctions and strategic economic actions to exert pressure on Russia and protect national interests.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Russian Invasion of Ukraine">
  <data key="d0">Russian Invasion of Ukraine</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The invasion by Russia is a geopolitical event that has global repercussions, including economic sanctions and international response.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Oil Reserves and Strategic Petroleum Reserve">
  <data key="d0">Oil Reserves and Strategic Petroleum Reserve</data>
  <data key="d1">Tools</data>
  <data key="d2">The US utilizes its oil reserves, including the Strategic Petroleum Reserve, to influence energy prices and support economic stability.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="International Cooperation">
  <data key="d0">International Cooperation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The coordinated effort of 30 countries to release oil reserves demonstrates a model of international collaboration to address global energy and economic challenges.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ARPA-H (Advanced Research Projects Agency for Health)&quot;|">
  <data key="d0">ARPA-H (Advanced Research Projects Agency for Health)"|</data>
  <data key="d1">Methodologies</data>
  <data key="d2">ARPA-H is a research agency modeled after DARPA, aiming to drive breakthroughs in health-related fields such as cancer, Alzheimer’s, and diabetes through innovative research and technological development.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="US Policy and Leadership">
  <data key="d0">US Policy and Leadership</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The United States aims to lead global efforts in energy, health innovation, and geopolitical stability through strategic actions, alliances, and technological investments.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Pay attention to use only the column names you can see in the tables below">
  <data key="d0">Pay attention to use only the column names you can see in the tables below</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Instruction emphasizing careful attention to column names and query structure in SQL tasks.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="be careful to not query for columns that do not exist">
  <data key="d0">be careful to not query for columns that do not exist</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Guidance to avoid querying non-existent columns in SQL statements.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="pay attention to which column is in which table">
  <data key="d0">pay attention to which column is in which table</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Reminder to consider table-column relationships when constructing queries.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="use today() function to get the current date">
  <data key="d0">use today() function to get the current date</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Instruction to utilize the today() function for date-related queries.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ORDER BY clause should always be after WHERE clause">
  <data key="d0">ORDER BY clause should always be after WHERE clause</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">SQL syntax rule indicating the correct placement of ORDER BY.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DO NOT add semicolon to the end of SQL">
  <data key="d0">DO NOT add semicolon to the end of SQL</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Directive to omit semicolon at the end of SQL statements.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="pay attention to the comment in table schema">
  <data key="d0">pay attention to the comment in table schema</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Advice to consider schema comments for accurate query formulation.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="the question involves 'today'">
  <data key="d0">the question involves 'today'</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The question references 'today', implying a need for date functions in the SQL query.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Use the following format: ...">
  <data key="d0">Use the following format: ...</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Instruction to follow a specific output format for the task.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Here are some examples: ...">
  <data key="d0">Here are some examples: ...</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Provision of example templates for understanding the expected output structure.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Let’s begin: ...">
  <data key="d0">Let’s begin: ...</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Prompt indicating the start of the task.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Figure 6: Langchain example prompt for SQL querying using MyScale.">
  <data key="d0">Figure 6: Langchain example prompt for SQL querying using MyScale.</data>
  <data key="d1">Tools</data>
  <data key="d2">An example prompt illustrating the use of Langchain for SQL queries.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="column names">
  <data key="d0">column names</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The list of available column names in the database schema that can be used for constructing SQL queries.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="tables">
  <data key="d0">tables</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The database schema includes multiple tables, each representing different data entities relevant to the querying task.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="schema comments">
  <data key="d0">schema comments</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Comments within the database schema that provide guidance or clarification about table structures and column usage.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="current date">
  <data key="d0">current date</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The current date, obtained via the today() function, used for date-dependent queries.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="SQL syntax rules">
  <data key="d0">SQL syntax rules</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Rules governing the correct structure and order of SQL clauses, such as placing ORDER BY after WHERE.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="semicolons in SQL">
  <data key="d0">semicolons in SQL</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Guideline to avoid adding semicolons at the end of SQL statements in this context.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="question involving 'today'">
  <data key="d0">question involving 'today'</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The question references 'today', indicating the need to use date functions in the SQL query.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="example prompts">
  <data key="d0">example prompts</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Sample prompts provided to illustrate the expected format and approach for SQL queries.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="query format instructions">
  <data key="d0">query format instructions</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Specific instructions on how to structure the SQL query output, including formatting and content.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="table info">
  <data key="d0">table info</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Metadata or schema descriptions that inform the structure and relationships of database tables.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="question">
  <data key="d0">question</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The specific user query or problem that guides the SQL query generation.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="SQLQuery">
  <data key="d0">SQLQuery</data>
  <data key="d1">Tools</data>
  <data key="d2">The constructed SQL query based on the input question, schema, and instructions.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="example document summaries">
  <data key="d0">example document summaries</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Sample document summaries used to illustrate relevance scoring and document selection in retrieval tasks.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="relevance scores">
  <data key="d0">relevance scores</data>
  <data key="d1">Results</data>
  <data key="d2">Numerical scores indicating the relevance of documents to the user's query, used in document retrieval and ranking.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ParameterLM">
  <data key="d0">ParameterLM</data>
  <data key="d1">Methodology</data>
  <data key="d2">A language model parameter used as a default in the code, facilitating generation tasks.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ParameterDemonstrations">
  <data key="d0">ParameterDemonstrations</data>
  <data key="d1">Methodology</data>
  <data key="d2">A collection of demonstrations used to guide the language model's behavior during inference.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="forward">
  <data key="d0">forward</data>
  <data key="d1">Methodology</data>
  <data key="d2">A function that executes the language model with provided inputs to generate predictions.&lt;SEP&gt;A method that forwards inputs through the ChainOfThought module, executing the reasoning process.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="get_the_right_lm">
  <data key="d0">get_the_right_lm</data>
  <data key="d1">Methodology</data>
  <data key="d2">A function that retrieves the appropriate language model based on context or parameters.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="get_the_right_signature">
  <data key="d0">get_the_right_signature</data>
  <data key="d1">Methodology</data>
  <data key="d2">A function that obtains the correct signature for the model's input and output structure.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="get_the_right_demonstrations">
  <data key="d0">get_the_right_demonstrations</data>
  <data key="d1">Methodology</data>
  <data key="d2">A function that selects suitable demonstrations for guiding the model.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prediction">
  <data key="d0">Prediction</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An object representing the output generated by the language model, encapsulating the prediction details.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.ParameterLM">
  <data key="d0">dspy.ParameterLM</data>
  <data key="d1">Tools</data>
  <data key="d2">A tool or class representing a language model parameter within the dspy framework.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.ParameterDemonstrations">
  <data key="d0">dspy.ParameterDemonstrations</data>
  <data key="d1">Tools</data>
  <data key="d2">A tool or class managing demonstrations used for model prompting.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.settings.traces">
  <data key="d0">dspy.settings.traces</data>
  <data key="d1">Tools</data>
  <data key="d2">A list that stores traces of model execution for debugging or analysis.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="trace">
  <data key="d0">trace</data>
  <data key="d1">Tools</data>
  <data key="d2">A dictionary object that records the inputs, outputs, and context of a model prediction trace.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.setting.context">
  <data key="d0">dspy.setting.context</data>
  <data key="d1">Tools</data>
  <data key="d2">A context manager that enables or disables specific settings during execution, such as tracing.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="__init__">
  <data key="d0">__init__</data>
  <data key="d1">Methodology</data>
  <data key="d2">Constructor method initializing the ChainOfThought module with a specified signature.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="E.1 Bootstrap Fewshot">
  <data key="d0">E.1 Bootstrap Fewshot</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique to create few-shot learning prompts by bootstrapping traces from a teacher model to a student model, using training data.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="E.2 Bootstrap Fewshot with Random Search">
  <data key="d0">E.2 Bootstrap Fewshot with Random Search</data>
  <data key="d1">Methodology</data>
  <data key="d2">An extension of bootstrap few-shot that incorporates random search over multiple trials to optimize demonstration selection.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="E.3 Bootstrap Fewshot with Optuna">
  <data key="d0">E.3 Bootstrap Fewshot with Optuna</data>
  <data key="d1">Methodology</data>
  <data key="d2">An advanced bootstrap few-shot method employing Optuna for hyperparameter tuning to select demonstrations.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="number of demonstrations">
  <data key="d0">number of demonstrations</data>
  <data key="d1">Variable</data>
  <data key="d2">The number of demonstrations to be selected, which can be tuned for optimal performance.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="predictor1">
  <data key="d0">predictor1</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A predictor object used in the process, associated with a specific name and capable of providing demonstrations.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="predictor2">
  <data key="d0">predictor2</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A second predictor object, associated with a specific name, used alongside predictor1 in the process.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="all_demos">
  <data key="d0">all_demos</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A collection of demonstrations retrieved from predictor1, used for evaluation and selection.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="demo_index">
  <data key="d0">demo_index</data>
  <data key="d1">Variables</data>
  <data key="d2">An integer variable representing the index of the selected demonstration within all_demos, suggested via a hyperparameter tuning process.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="evaluate_program">
  <data key="d0">evaluate_program</data>
  <data key="d1">Methodology</data>
  <data key="d2">A function that evaluates a candidate program's performance based on a specified metric and validation set, returning a score.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="score">
  <data key="d0">score</data>
  <data key="d1">Results</data>
  <data key="d2">The numerical evaluation result of the candidate program, used to determine its quality.&lt;SEP&gt;The numerical outcome of evaluating a candidate program, used to compare and select the best performing program.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="candidate_program">
  <data key="d0">candidate_program</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A program candidate that is being evaluated and potentially selected as optimal.&lt;SEP&gt;A proposed computational program that is evaluated based on its performance score to determine its suitability as the best solution.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="self.metric">
  <data key="d0">self.metric</data>
  <data key="d1">Tools</data>
  <data key="d2">A metric used to evaluate the performance of candidate programs during optimization.&lt;SEP&gt;A performance metric used to assess the quality of candidate programs during evaluation, guiding the optimization process.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="self.valset">
  <data key="d0">self.valset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset used to validate the performance of candidate programs, ensuring the evaluation is unbiased and reliable.&lt;SEP&gt;The validation dataset used to assess candidate programs during evaluation.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="trial.set_user_attr">
  <data key="d0">trial.set_user_attr</data>
  <data key="d1">Tools</data>
  <data key="d2">A method to store attributes related to the current trial, such as the candidate program, for later analysis.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="compile">
  <data key="d0">compile</data>
  <data key="d1">Methodology</data>
  <data key="d2">A function that compiles a student, trainset, and optionally a teacher and validation set into a usable training environment.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="student">
  <data key="d0">student</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A student model object that is deep-copied for training or evaluation purposes.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="teacher">
  <data key="d0">teacher</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An optional teacher model object, deep-copied if provided, used for training or evaluation.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="trainset">
  <data key="d0">trainset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The dataset used for training the models, assigned during compilation.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="valset">
  <data key="d0">valset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The validation dataset used for evaluating model performance, defaults to trainset if not provided.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="BootstrapFewshot">
  <data key="d0">BootstrapFewshot</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to generate a large number of potential demonstrations by bootstrapping few-shot examples, used to expand training data.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="tp">
  <data key="d0">tp</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An instance of BootstrapFewshot responsible for creating a large pool of demonstrations for training or evaluation.&lt;SEP&gt;An instance of BootstrapFewshot, responsible for compiling demonstration pools.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="optimize_with_optuna">
  <data key="d0">optimize_with_optuna</data>
  <data key="d1">Methodology</data>
  <data key="d2">A function that employs the Optuna optimization framework to search for the best program based on an objective function.&lt;SEP&gt;A process that employs the Optuna framework to optimize the selection of candidate programs based on evaluation scores.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="best_program">
  <data key="d0">best_program</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The complete program object with attributes including its score and configuration.&lt;SEP&gt;The program identified by optimization as having the highest score, considered the optimal solution.&lt;SEP&gt;The program obtained through optimization that achieves the highest evaluation score, considered the optimal solution.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="best_program.score">
  <data key="d0">best_program.score</data>
  <data key="d1">Results</data>
  <data key="d2">The highest evaluation score achieved by the best program during optimization.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="print">
  <data key="d0">print</data>
  <data key="d1">Tools</data>
  <data key="d2">A function used to output information such as the best score and program details for review.&lt;SEP&gt;A function used to output the best score and program details for review.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="demonstrations">
  <data key="d0">demonstrations</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A collection of example instances used to evaluate or train models, generated via bootstrap methods for use in program optimization.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GSM8K Llama2-13b-chat CoT program">
  <data key="d0">GSM8K Llama2-13b-chat CoT program</data>
  <data key="d1">Methodology</data>
  <data key="d2">A Chain-of-Thought prompting approach applied with the Llama2-13b-chat model to generate search queries based on context and questions, used for reasoning in problem-solving tasks.&lt;SEP&gt;A computational approach utilizing Chain-of-Thought prompting with the Llama2-13b-chat model, designed to generate search queries from contextual information and questions.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Search Query">
  <data key="d0">Search Query</data>
  <data key="d1">Variables</data>
  <data key="d2">A specific string or question formulated based on context and reasoning, intended to retrieve relevant information from sources.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Twilight (novel series)">
  <data key="d0">Twilight (novel series)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A series of four vampire-themed fantasy romance novels by Stephenie Meyer, serving as literary objects within the context of genre and thematic analysis.&lt;SEP&gt;A series of four vampire-themed fantasy romance novels by Stephenie Meyer, serving as literary objects within the context.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Harper Connelly Mysteries">
  <data key="d0">Harper Connelly Mysteries</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A series of fantasy mystery novels by Charlaine Harris, relevant as objects of literary and genre analysis.&lt;SEP&gt;A series of fantasy mystery novels by Charlaine Harris, used as references for literary analysis.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="The Dark Heroine">
  <data key="d0">The Dark Heroine</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A series of vampire-themed fantasy romance novels by Abigail Gibbs, used as objects of genre and thematic study.&lt;SEP&gt;A vampire-themed fantasy romance novel series by Abigail Gibbs, relevant to genre studies.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Victorians">
  <data key="d0">Victorians</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Refers to Victorian art and culture, the focus of the documentary series 'The Victorians - Their Story In Pictures'.&lt;SEP&gt;Refers to Victorian art, culture, and era, which are the focus of the documentary series 'The Victorians - Their Story In Pictures'.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jeremy Paxman">
  <data key="d0">Jeremy Paxman</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A British journalist and broadcaster born in 1950, whose birth year is relevant to understanding the context of the documentary series.&lt;SEP&gt;A British journalist and broadcaster, born in 1950, whose involvement or contextual relevance relates to the Victorian documentary series and its historical framing.&lt;SEP&gt;A broadcaster and presenter associated with the Victorian documentary series, providing a narrative or interpretive perspective.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="search query">
  <data key="d0">search query</data>
  <data key="d1">Variables</data>
  <data key="d2">A specific formulated question or string derived from context and reasoning, intended to retrieve relevant information from sources.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="The Victorians - Their Story In Pictures">
  <data key="d0">The Victorians - Their Story In Pictures</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A documentary series examining Victorian art and culture, serving as a primary object of media and cultural analysis.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Year of Jeremy Paxman's Birth">
  <data key="d0">Year of Jeremy Paxman's Birth</data>
  <data key="d1">Variables</data>
  <data key="d2">A data point indicating Jeremy Paxman's birth year, relevant for historical and contextual analysis.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Objects of Study">
  <data key="d0">Objects of Study</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">The primary object of study is the text document from which entities and relationships are extracted.&lt;SEP&gt;The primary subjects, phenomena, or items being examined in the research.&lt;SEP&gt;These graphs are structured representations of modular NLP pipelines composed of interconnected modules."|&lt;SEP&gt;These graphs represent structured pipelines composed of modular components for NLP tasks.</data>
  <data key="d1">Objects of Study</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Applications/Implications">
  <data key="d0">Applications/Implications</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-130e4012ca037ccaf70ac4ffd0928777&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d2">DSP Y is publicly available on GitHub, promoting open research and broader application."|&lt;SEP&gt;Practical benefits such as faster code generation, better resource utilization, and enabling advanced HPC workflows; theoretical insights into data quality and model scaling.&lt;SEP&gt;Practical uses or consequences derived from the study's findings.&lt;SEP&gt;The findings have implications for adopting large language models in scientific computing, HPC kernel development, and automated code generation, influencing future research and practice.&lt;SEP&gt;The insights inform the adoption of large language models in scientific computing, HPC kernel automation, and AI-assisted code development, influencing future research and practical workflows.&lt;SEP&gt;Domain-specific LLMs can significantly benefit areas such as literature analysis, hypothesis generation, and complex data interpretation in various fields.&lt;SEP&gt;The trained HPC-specific language model can be used for code generation, labeling, and other downstream applications to improve HPC software development.</data>
  <data key="d1">Core Concepts</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Analytical Techniques">
  <data key="d0">Analytical Techniques</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">DSP Y employs algorithms within its compiler to automatically optimize pipeline graphs for maximum performance."|&lt;SEP&gt;Methods applied to process and analyze data to extract meaningful insights.&lt;SEP&gt;The analysis involves entity recognition and relationship extraction based on contextual cues within the text.</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Theories/Models">
  <data key="d0">Theories/Models</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">DSP Y embodies a systematic methodology replacing manual prompt crafting with modular, learnable components and automated optimization."|&lt;SEP&gt;Structured frameworks or conceptual models used to explain phenomena or guide analysis.</data>
  <data key="d1">Theories/Models</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Methodologies">
  <data key="d0">Methodologies</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">DSP Y aims to replace manual prompt engineering with modular, learnable components that can be systematically optimized."|&lt;SEP&gt;Systematic procedures and techniques employed to conduct research and analyze data.&lt;SEP&gt;The text discusses the process of identifying entities and relationships within a document, which involves systematic extraction and analysis techniques.&lt;SEP&gt;Training and Fine-tuning</data>
  <data key="d1">Study Designs</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Core Concepts">
  <data key="d0">Core Concepts</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">DSP Y supports multi-stage, multi-module pipelines for complex tasks, enabling decomposition and reasoning."|&lt;SEP&gt;Fundamental ideas and principles that underpin the study, including foundational theories and definitions.</data>
  <data key="d1">Core Concepts</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Variables">
  <data key="d0">Variables</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d2">DSP Y modules can learn and adapt their parameters based on demonstrations or feedback to improve performance."|&lt;SEP&gt;Quantifiable factors or attributes that are measured or manipulated in the research.&lt;SEP&gt;Factors such as programming languages, kernel types, prompt inputs, and evaluation scores, which influence the quality, correctness, and performance of generated code.&lt;SEP&gt;Variables include programming languages, kernel types, prompt inputs, and evaluation scores, which influence the quality and correctness of generated outputs.&lt;SEP&gt;Elements such as variable interdependencies, state tracking, and input/output parameters that are crucial in reasoning about code correctness and complexity.</data>
  <data key="d1">Variables</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="prompting techniques">
  <data key="d0">prompting techniques</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d2">Chain of Thought is a complex prompting method that guides models through intermediate reasoning steps.&lt;SEP&gt;Chain of Thought is a prompting method that guides models through intermediate reasoning steps, improving complex reasoning performance."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Study Designs">
  <data key="d0">Study Designs</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d2">Architectures of research such as experimental, observational, or computational setups used to structure investigations.&lt;SEP&gt;Case studies demonstrate DSPy's application to multi-hop reasoning tasks.&lt;SEP&gt;Case studies demonstrate DSPy’s application to complex reasoning tasks such as multi-hop question answering."|&lt;SEP&gt;The research employs evaluation and benchmarking methodologies to systematically assess AI-generated HPC kernels across multiple programming models and inputs.&lt;SEP&gt;The research employs systematic evaluation and benchmarking methodologies to analyze AI-generated HPC kernels across multiple programming models, prompts, and metrics.</data>
  <data key="d1">Study Designs</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Research Questions/Hypotheses">
  <data key="d0">Research Questions/Hypotheses</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-25ebcde4744e2b19ba1d5d1fd25807b0&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-061790de1df7d16a1cc9252b2f75290c&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">DSPy programs aim to outperform hand-crafted prompts with smaller LMs like GPT-3.5.&lt;SEP&gt;DSPy programs aim to outperform systems using hand-crafted prompts, even with smaller models like GPT-3.5."|&lt;SEP&gt;How does data quality versus data quantity impact the performance of HPC-specific code LLMs? How do model size and architecture affect throughput and accuracy?&lt;SEP&gt;Questions exploring how data quality versus data quantity affects model performance, and how model size impacts throughput, accuracy, and resource consumption.&lt;SEP&gt;Specific questions or predictions that the study aims to address or test.&lt;SEP&gt;The study aims to assess the impact of GPT-3's capabilities on the process of generating, optimizing, and testing HPC kernels, and to understand the current state of prompt engineering in this context.&lt;SEP&gt;The study investigates the impact of GPT-3’s capabilities on generating, optimizing, and testing HPC kernels, and assesses the effectiveness of prompt engineering.&lt;SEP&gt;The document aims to address how to extract relevant entities and their relationships from a given text, focusing on methodology and analysis.&lt;SEP&gt;Research focus</data>
  <data key="d1">How can deep learning models like Deepdev-perf and BART be utilized to improve software performance and NLP tasks, respectively?</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Disciplines">
  <data key="d0">Disciplines</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">Academic or professional fields related to the study, such as computer science, statistics, or engineering.&lt;SEP&gt;Prompt-based learning is an NLP methodology supported by DSPy, involving using prompts to guide language models for various tasks.</data>
  <data key="d1">Disciplines</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Ensemble Technique">
  <data key="d0">Ensemble Technique</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d2">Majority voting is used as a custom ensemble decision method to combine multiple model outputs for improved accuracy.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Evaluation Approach">
  <data key="d0">Evaluation Approach</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d2">Bootstrapping is mentioned as a technique to test model stability and performance under dynamic, test-time conditions.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Study Populations/Dataset">
  <data key="d0">Study Populations/Dataset</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">The dataset is used as the primary benchmark for assessing model performance on math word problems.&lt;SEP&gt;The group of subjects or data collections used for analysis in the research.</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Study Design">
  <data key="d0">Study Design</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d2">Structured experiments with well-defined programs and datasets ensure reproducibility and reliable comparisons.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Evaluation">
  <data key="d0">Evaluation</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d2">Assessing the performance of the adapted model against benchmarks, collecting feedback, and refining the process.&lt;SEP&gt;Assessing the performance of the specialized model against benchmarks, collecting feedback, and refining accordingly.&lt;SEP&gt;Evaluation assesses the performance and correctness of code generation tools through benchmarks and comparison with hand-written code.&lt;SEP&gt;Evaluation involves assessing the performance and correctness of code generation tools through benchmarks and comparison with hand-written code.&lt;SEP&gt;Evaluation involves assessing the performance of LLMs in generating code across different models, prompts, and programming paradigms.&lt;SEP&gt;GSM8K provides the benchmark problems to evaluate the effectiveness of various compilation strategies and models.&lt;SEP&gt;GSM8K serves as the primary dataset to evaluate the effectiveness of different compilation strategies and models.&lt;SEP&gt;Evaluation involves testing the trained models on specific tasks and analyzing results to determine their ability to generate correct code, label pragmas, and predict relative performance.</data>
  <data key="d1">Methodologies</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Training Data">
  <data key="d0">Training Data</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-96b489f22f60397ff887486ccf77f457&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f&lt;SEP&gt;chunk-10b08670a9cf75866c6b05fa5b5cfc12&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-bf1121c44634b616af61c49cd3adf29a&lt;SEP&gt;chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d2">Human reasoning chains are used as additional training data or benchmarks to assess the reasoning capabilities of models.&lt;SEP&gt;Human-generated reasoning chains are used as additional training data or benchmarks to improve model reasoning.&lt;SEP&gt;The datasets used for fine-tuning models on MPI code, with varying sample sizes (0k to 12k), impacting model performance.&lt;SEP&gt;Training data consists of datasets used to fine-tune language models, affecting their learning capacity, performance, and susceptibility to overfitting.&lt;SEP&gt;Training data refers to datasets used to fine-tune language models, impacting their performance and overfitting susceptibility.&lt;SEP&gt;The dataset used to pre-train and fine-tune Codex, which influences its suggestions and potential vulnerabilities.&lt;SEP&gt;The source code datasets used to train models like Codex, which may contain sensitive or proprietary information.&lt;SEP&gt;Training data comprises internet sources like GitHub repositories used to teach AI models coding capabilities.&lt;SEP&gt;Training data encompasses datasets used to train models, which may encode social biases and influence model representations.&lt;SEP&gt;Training data includes publicly available internet sources like GitHub repositories used to teach models like Codex-12B to generate code.</data>
  <data key="d1">Objects of Study</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Study Models">
  <data key="d0">Study Models</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d2">These large language models are evaluated across various compilation strategies to measure improvements in solving math word problems.&lt;SEP&gt;These large language models are evaluated with various compilation strategies to measure improvements in math problem solving.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Performance Comparison">
  <data key="d0">Performance Comparison</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d2">The 13b variant of the model is shown to be competitive with larger models despite its smaller size.&lt;SEP&gt;The 13b variant of the model is shown to be competitive with larger models like GPT-4, despite smaller size.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Model Technique">
  <data key="d0">Model Technique</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d2">A reasoning methodology involving step-by-step logical thinking to enhance model performance on complex tasks.&lt;SEP&gt;CoT is used as a reasoning methodology to enhance model reasoning capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Dataset">
  <data key="d0">Dataset</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d2">HotPotQA is used to evaluate multi-hop question answering performance in the study.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Retrieval Tool">
  <data key="d0">Retrieval Tool</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d2">ColBERTv2 is employed to retrieve relevant passages from Wikipedia for QA.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Methodology">
  <data key="d0">Methodology</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d2">An experimental approach involving prompting Copilot with structured queries in multiple languages and assessing the correctness and relevance of generated code snippets.&lt;SEP&gt;ReAct is a multi-step agent framework evaluated in the study for tool use in QA.&lt;SEP&gt;The experimental approach involves prompting Copilot with structured queries in multiple programming languages and assessing the output's correctness and relevance.</data>
  <data key="d1">Methodologies</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Model">
  <data key="d0">Model</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-aebb652b359c14534612e14559754bbc&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d2">Large language models (LLMs) like GPT, Llama 2, and DeepSeek-coder are AI models designed for natural language understanding, code generation, and AI tasks.&lt;SEP&gt;T5-Large is used for finetuning experiments to assess model capacity.&lt;SEP&gt;The large language model (LLM) used to generate code samples for performance assessment in parallel computing contexts.&lt;SEP&gt;The language model being evaluated for its ability to generate syntactically correct and functionally accurate code snippets from prompts.</data>
  <data key="d1">Core Concepts</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Evaluation Metric">
  <data key="d0">Evaluation Metric</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d2">Metrics such as accuracy are used to quantify the success of pragma generation, comparing generated pragmas against actual ones to assess correctness.&lt;SEP&gt;The answer exact match metric measures the correctness of model answers.</data>
  <data key="d1">Tools</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Study Reports">
  <data key="d0">Study Reports</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d2">Provides performance metrics for GPT-3.5-turbo using CoT in 2023.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Evidence Types">
  <data key="d0">Evidence Types</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">A preprint document presenting the case study on complex question answering.&lt;SEP&gt;Categories of data or proof supporting findings, including qualitative, quantitative, or mixed evidence.</data>
  <data key="d1">Evidence Types</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Spatiotemporal Information">
  <data key="d0">Spatiotemporal Information</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">Data describing the spatial and temporal aspects of the phenomena under investigation.&lt;SEP&gt;Serves as the knowledge base for retrieval in HotPotQA.</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="answer pair-retrieval accuracy">
  <data key="d0">answer pair-retrieval accuracy</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d2">Pair-retrieval accuracy measures how well models retrieve relevant passage pairs in multi-hop question answering.&lt;SEP&gt;Pair-retrieval accuracy measures the effectiveness of models in retrieving relevant passage pairs in multi-hop QA.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="models">
  <data key="d0">models</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb&lt;SEP&gt;chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d2">In-context learning paradigms like CoT prompting and others are used to enhance models' reasoning abilities by conditioning on example prompts.&lt;SEP&gt;In-context learning paradigms like CoT prompting and others are used to improve reasoning capabilities of models.&lt;SEP&gt;Models in this context refer to the specific code generation systems described in the paper, such as Codex, which are trained to generate code based on input prompts.</data>
  <data key="d1">Objects of Study</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Language Models">
  <data key="d0">Language Models</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-54d0e5495bc4b24b68d3cbc1c13d835e&lt;SEP&gt;chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-583d728170557abef78a4cab2b68abb2&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d2">Language Models are computational models trained on large text corpora to generate, understand, and support human language processing tasks.&lt;SEP&gt;Language models are leveraged within the modules and optimizers to perform text processing tasks in a systematic and reliable manner.&lt;SEP&gt;Language models are systems designed to understand, generate, and process human language, often trained using unsupervised learning techniques across large datasets.&lt;SEP&gt;Models that generate or understand text based on learned statistical patterns, foundational in NLP.&lt;SEP&gt;Models that generate or understand text based on learned statistical patterns, foundational to recent NLP advances.&lt;SEP&gt;Language models are statistical models that predict the likelihood of sequences of words, enabling tasks like text generation, translation, and understanding.</data>
  <data key="d1">Core Concepts</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Development of the text transformation graph">
  <data key="d0">Development of the text transformation graph</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">Funding and support from industry and academic organizations facilitate the research, development, and application of the graph and associated tools.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="compose and form the Text Transformation Graph">
  <data key="d0">compose and form the Text Transformation Graph</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">component assembly, modular architecture</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="are integrated into the Text Transformation Graph to enhance its systematic and reliable operation">
  <data key="d0">are integrated into the Text Transformation Graph to enhance its systematic and reliable operation</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">system enhancement, reliability</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="are leveraged by the Modules and Optimizers within the Text Transformation Graph">
  <data key="d0">are leveraged by the Modules and Optimizers within the Text Transformation Graph</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">technology utilization, core AI components</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="funds and supports the development of the Text Transformation Graph and related AI research">
  <data key="d0">funds and supports the development of the Text Transformation Graph and related AI research</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">funding, collaboration</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="includes organizations such as IBM, Oracle, Virtusa, Cigna Healthcare, Stanford HAI, Facebook, Google, VMware, NSF, and Apple Scholars">
  <data key="d0">includes organizations such as IBM, Oracle, Virtusa, Cigna Healthcare, Stanford HAI, Facebook, Google, VMware, NSF, and Apple Scholars</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">collaborative support, funding sources</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Math word problems (PAL)">
  <data key="d0">Math word problems (PAL)</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d2">LangChain is used as a methodology or tool to handle math word problems in the context of Gao et al.'s research.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Relevant docs retrieval">
  <data key="d0">Relevant docs retrieval</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d2">LlamaIndex is used to retrieve relevant documents or sources in the research context, supporting applications like chatbots or information retrieval.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Time of My Life">
  <data key="d0">Time of My Life</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d2">Produced by Michael Lloyd, the song is notable in music history and film.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Cars in Parking Lot">
  <data key="d0">Cars in Parking Lot</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d2">Initial cars plus new arrivals determine total cars in the parking lot.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Using code to model and solve real-world counting problems">
  <data key="d0">Using code to model and solve real-world counting problems</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d2">methodology, computational problem solving</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Resilience">
  <data key="d0">Resilience</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">The Ukrainian people's repeated resistance over 30 years exemplifies their resilience and refusal to accept regression in their sovereignty and independence.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Societal Reflection">
  <data key="d0">Societal Reflection</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">The pandemic has prompted a societal shift to see COVID-19 beyond partisan lines, emphasizing unity and collective responsibility.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Loss of Life">
  <data key="d0">Loss of Life</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">The loss of life due to COVID-19 underscores the pandemic's profound societal and emotional impact.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Societal Impact">
  <data key="d0">Societal Impact</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b&lt;SEP&gt;chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">Broader societal effects, including impacts on diversity, job market, and skill distribution due to automation and tool influence.&lt;SEP&gt;The loss of life due to COVID-19 underscores the pandemic's profound societal and emotional impact.</data>
  <data key="d1">Applications/Implications</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="US Sanctions">
  <data key="d0">US Sanctions</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">Sanctions are a response to Russia's invasion, aimed at exerting economic pressure and supporting Ukraine.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Energy Prices">
  <data key="d0">Energy Prices</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">Releasing oil from reserves aims to stabilize or reduce energy prices amid global supply issues.&lt;SEP&gt;Releasing oil reserves is a strategic measure to influence global energy prices during supply disruptions.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Oil Reserves">
  <data key="d0">Oil Reserves</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">Releasing oil from reserves aims to stabilize or reduce energy prices amid global supply issues.&lt;SEP&gt;Releasing oil reserves is a strategic measure to influence global energy prices during supply disruptions.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ARPA-H">
  <data key="d0">ARPA-H</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">ARPA-H is designed to catalyze breakthroughs in health through innovative research, similar to DARPA's role in technological advances.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Health Breakthroughs">
  <data key="d0">Health Breakthroughs</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">ARPA-H is designed to catalyze breakthroughs in health through innovative research, similar to DARPA's role in technological advances.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Unity">
  <data key="d0">Unity</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">The pandemic has led to a societal shift towards seeing COVID-19 as a shared challenge, fostering unity and collective action.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Impact">
  <data key="d0">Impact</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">The loss of life from COVID-19 highlights the profound human and societal toll of the pandemic.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Economic Impact">
  <data key="d0">Economic Impact</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">Sanctions are designed to exert economic pressure on Russia and support Ukraine, affecting global markets.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Health Innovation">
  <data key="d0">Health Innovation</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d2">ARPA-H aims to drive breakthroughs in health, leveraging innovative research similar to DARPA's technological advances.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="use the correct column-table associations">
  <data key="d0">use the correct column-table associations</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">The reminder aims to ensure correct referencing of columns within their respective tables.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="apply date functions for dynamic date retrieval">
  <data key="d0">apply date functions for dynamic date retrieval</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">The instruction suggests using the today() function for date-related queries, indicating its importance in the process.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="correct SQL syntax order">
  <data key="d0">correct SQL syntax order</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">This rule clarifies the proper sequence of SQL clauses to ensure valid queries.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="omit semicolon at query end">
  <data key="d0">omit semicolon at query end</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">This directive specifies formatting rules for the SQL statements, emphasizing omission of semicolons.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="schema comments inform correct query construction">
  <data key="d0">schema comments inform correct query construction</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">The advice highlights the importance of schema comments for accurate understanding of table structures.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="use date functions in the query">
  <data key="d0">use date functions in the query</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">The mention of 'today' in the question indicates the need to incorporate date functions like today() in the SQL query.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="guidance for query construction">
  <data key="d0">guidance for query construction</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">Schema comments provide additional context or instructions crucial for accurately constructing queries based on schema details.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="table references">
  <data key="d0">table references</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">The list of column names guides the correct referencing of columns within their respective tables to avoid errors.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="database structure">
  <data key="d0">database structure</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">The tables represent different entities within the database schema, essential for understanding data relationships.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="date functions">
  <data key="d0">date functions</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">Using the today() function provides the current date for date-dependent queries, aligning with the question involving 'today'.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="query structure">
  <data key="d0">query structure</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">Proper placement of ORDER BY after WHERE ensures valid SQL syntax, as instructed.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="query formatting">
  <data key="d0">query formatting</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">Omitting semicolons at the end of SQL statements adheres to the specified formatting rules.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="use date functions">
  <data key="d0">use date functions</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d2">The explicit mention of 'today' in the question indicates the need to incorporate date functions like today() into the SQL query.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="self.trainset">
  <data key="d0">self.trainset</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d2">The compile method assigns the trainset to the training environment, preparing models for training or evaluation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="'Best score:'">
  <data key="d0">'Best score:'</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d2">Outputs the highest score achieved by the selected program for review.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="'Best program:'">
  <data key="d0">'Best program:'</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d2">Outputs the details of the best program identified during optimization.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="The Victorian">
  <data key="d0">The Victorian</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d2">The series 'The Victorians - Their Story In Pictures' focuses on Victorian art and culture, which are part of the broader Victorian era."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Context">
  <data key="d0">Context</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d2">The search query is generated based on the context and question, using reasoning to formulate relevant information retrieval questions."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="context">
  <data key="d0">context</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d2">The search query is generated based on the context and reasoning process, linking the information in the context to the formulated question."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="HPC-Coder-V2">
  <data key="d0">HPC-Coder-V2</data>
  <data key="d1">Results</data>
  <data key="d2">A fine-tuned code language model (LLM) optimized for parallel code generation, developed through training on the HPC-I NSTRUCT dataset to enhance performance in parallel programming tasks.&lt;SEP&gt;HPC-Coder-V2 is a fine-tuned code language model (LLM) optimized for parallel code generation, developed through training on the HPC-I NSTRUCT dataset.&lt;SEP&gt;HPC-Coder-V2 is a fine-tuned specialized HPC LLM that is the best performing open-source model for parallel code generation, achieving performance near GPT-4 levels.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Parallel Code Generation">
  <data key="d0">Parallel Code Generation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Parallel code generation involves creating code that can run concurrently, evaluated here using specific benchmarks and metrics.&lt;SEP&gt;Parallel code generation involves creating code that executes multiple computations simultaneously to improve performance, a complex task that LLMs are being adapted to perform.&lt;SEP&gt;Parallel code generation involves creating code that executes simultaneously across multiple processors or cores, crucial for high-performance computing.&lt;SEP&gt;Parallel code generation involves creating code that executes simultaneously across multiple processors or cores, essential for high-performance computing applications.&lt;SEP&gt;Parallel code generation refers to creating code capable of concurrent execution, evaluated using benchmarks and metrics like pass@k.&lt;SEP&gt;The study investigates the capabilities of state-of-the-art large language models to generate parallel code effectively, addressing whether these models can handle complex programming tasks involving parallel algorithms and models.&lt;SEP&gt;The study investigates whether current state-of-the-art large language models can effectively generate parallel code for scientific and high-performance computing tasks.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="High-Quality Parallel Code Data">
  <data key="d0">High-Quality Parallel Code Data</data>
  <data key="d1">Variables</data>
  <data key="d2">High-quality parallel code data refers to accurately labeled, extensive datasets of parallel programming examples used to train and fine-tune LLMs for better performance in generating parallel code.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-INSTRUCT">
  <data key="d0">HPC-INSTRUCT</data>
  <data key="d1">Tools</data>
  <data key="d2">A large synthetic dataset of parallel code instruction-response pairs created to fine-tune HPC-capable code LLMs for high-performance computing tasks.&lt;SEP&gt;HPC-INSTRUCT is a large synthetic dataset of parallel code instruction-response pairs created to fine-tune code LLMs for high-performance computing tasks.&lt;SEP&gt;HPC-INSTRUCT is a synthetic dataset created to provide high-quality instruct-answer pairs of parallel code, aimed at improving LLM training for HPC applications.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="StarCoder2">
  <data key="d0">StarCoder2</data>
  <data key="d1">Study Designs</data>
  <data key="d2">StarCoder2 is a family of large language models (LLMs) with sizes 1.3B, 7B, and 15B, pre-trained on a large corpus of code data from The Stack V2, used for code generation tasks.&lt;SEP&gt;StarCoder2 is a family of large language models (LLMs) with sizes 1.3B, 7B, and 15B, pre-trained on a large corpus of mostly code data from The Stack V2, used for code generation tasks.&lt;SEP&gt;StarCoder2 is a project that trained code LLMs on The Stack v2 dataset, demonstrating that more data alone does not necessarily improve model performance without quality data.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="The Stack v2 dataset">
  <data key="d0">The Stack v2 dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large dataset containing permissively licensed code and related data used for training code LLMs like StarCoder2.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Fine-tuning">
  <data key="d0">Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Fine-tuning involves the process of adapting pre-trained language models, including large language models (LLMs) and code-specific models, to specific datasets or domains to enhance their performance on targeted tasks. This process typically entails further training of the pre-trained models on domain-specific data such as HPC source code, scientific codes, or synthetic datasets related to high-performance computing (HPC). By doing so, the models become better equipped to generate relevant and accurate outputs, particularly for specialized applications like parallel code generation, HPC code synthesis, and the inclusion of domain-specific constructs such as OpenMP pragmas. Fine-tuning often involves updating certain model parameters or employing techniques like adapters to improve efficiency and task-specific capabilities. Overall, it aims to improve the models' ability to produce high-quality, domain-relevant code and solutions by training on curated, domain-specific datasets.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda&lt;SEP&gt;chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Model Evaluation">
  <data key="d0">Model Evaluation</data>
  <data key="d1">Study Design</data>
  <data key="d2">Assessment of neural models' performance on tasks like code generation, summarization, and bug fixing.&lt;SEP&gt;Evaluation involves testing models like HPC-Coder-V2 against benchmarks such as ParEval to measure their capabilities in parallel code generation.&lt;SEP&gt;HPC-Coder-V2-6.7B and 16B outperform other open-source models in speed, memory efficiency, and accuracy in parallel code generation.&lt;SEP&gt;Performance metrics and leaderboards used to assess the effectiveness of code models like DeepSeek-coder and others.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ParEval">
  <data key="d0">ParEval</data>
  <data key="d1">Study Design</data>
  <data key="d2">A benchmark dataset used to evaluate the effectiveness of code LLMs in generating parallel code, providing performance metrics.&lt;SEP&gt;A benchmark dataset used to evaluate the performance of code LLMs in generating parallel code, providing quantitative performance metrics.&lt;SEP&gt;A benchmarking framework providing correctness metrics (pass@1) for code generation models across multiple problem types and models.&lt;SEP&gt;A benchmarking framework used to assess code generation performance, throughput, and resource efficiency across multiple models, facilitating comparison and analysis.&lt;SEP&gt;A benchmarking framework used to compare code generation performance, throughput, and resource requirements across different models.&lt;SEP&gt;ParEval is a benchmark designed to evaluate the performance of code LLMs specifically on parallel code generation tasks.&lt;SEP&gt;ParEval is a benchmarking framework that provides correctness results for code generation models across multiple problem types and execution modes, summarized in heatmaps and tables.&lt;SEP&gt;A benchmark designed to evaluate language models on 420 coding tasks related to scientific and parallel computing, incorporating novel metrics for assessing code quality and performance.&lt;SEP&gt;An evaluation framework or benchmark designed to assess large language models' ability to generate parallel code across multiple models and scenarios.&lt;SEP&gt;ParEval is a benchmark created to evaluate the performance of language models on 420 coding tasks related to scientific and parallel computing, incorporating novel metrics for assessing code effectiveness.&lt;SEP&gt;ParEval is a benchmark designed to evaluate LLMs' ability to generate and optimize parallel code, including metrics for runtime performance and scalability.&lt;SEP&gt;ParEval is a framework or methodology for evaluating language models' performance on prompt-based tasks, including code generation.&lt;SEP&gt;ParEval is a framework or methodology for systematically evaluating language models' capabilities on prompt-based tasks, including code generation and translation.&lt;SEP&gt;ParEval is an evaluation framework or benchmark designed to assess large language models' capabilities in generating parallel code across different models and execution scenarios.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-0263fe0a192189f09d40327b5d776e30&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Data Representation">
  <data key="d0">Data Representation</data>
  <data key="d1">Variables</data>
  <data key="d2">Data representation refers to how code and instruction data are formatted and structured, impacting the ability of LLMs to learn effectively from the data.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Training Parameters">
  <data key="d0">Training Parameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Training parameters include aspects such as learning rate, dataset size, and fine-tuning strategies, which influence the model's ability to learn and generate parallel code.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC Community">
  <data key="d0">HPC Community</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The HPC community involves researchers and developers focused on high-performance computing, benefiting from improved code generation tools for scientific and engineering applications.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-I NSTRUCT">
  <data key="d0">HPC-I NSTRUCT</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset created using synthetic data generated from large language models (LLMs) and open-source parallel code, designed for studying model fine-tuning in HPC code generation.&lt;SEP&gt;A large synthetic dataset of high-quality parallel code instruction data used for training and fine-tuning code language models to improve their ability to generate parallel code.&lt;SEP&gt;HPC-I NSTRUCT is a dataset of synthetic HPC code instruction samples used for fine-tuning models.&lt;SEP&gt;HPC-I NSTRUCT is a dataset used for training and evaluating high-performance computing code generation models.&lt;SEP&gt;HPC-I NSTRUCT is a large synthetic dataset of high-quality parallel code instruction data used for training and fine-tuning code language models.&lt;SEP&gt;HPC-I NSTRUCT is a synthetic dataset used for training and evaluating high-performance computing code generation models.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="parallel code generation">
  <data key="d0">parallel code generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Parallel code generation involves creating code that can execute tasks concurrently, which is important for optimizing computational efficiency and performance in software development.&lt;SEP&gt;Parallel code generation involves creating code that executes concurrently, improving computational efficiency and performance in software development.&lt;SEP&gt;The study explores how various factors such as model choice, data quality, and model size influence the effectiveness of code LLMs in generating parallel code.&lt;SEP&gt;The study investigates how various factors such as model choice, data quality, and model size impact the performance of code language models in generating parallel code.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="fine-tuning">
  <data key="d0">fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A training process where Codex is further trained on correctly implemented standalone functions to improve its ability to generate accurate and functional code solutions.&lt;SEP&gt;A training process where pre-trained code LLMs are further trained on specific datasets like HPC-I NSTRUCT with techniques such as instruction masking to improve their ability to generate parallel code.&lt;SEP&gt;Fine-tuning involves adjusting a pre-trained model on specific datasets to improve performance on targeted tasks such as code generation and translation.&lt;SEP&gt;Fine-tuning involves adjusting a pre-trained model on specific datasets to improve performance on targeted tasks, such as code generation.&lt;SEP&gt;Fine-tuning involves adjusting pre-trained code LLMs using specific datasets and techniques like instruction masking to improve their performance on parallel code tasks.&lt;SEP&gt;The process of adjusting the query encoder and generator parameters on task-specific data, while keeping the document encoder fixed.&lt;SEP&gt;Fine-tuning involves adjusting pre-trained models with curated datasets of high-quality, bug-free code to improve performance and alignment.&lt;SEP&gt;Fine-tuning involves training Codex on correctly implemented standalone functions to improve its ability to generate correct code solutions.&lt;SEP&gt;The process of adapting pre-trained GPT models, including models with up to 12B parameters, on code data to improve performance in code generation tasks like Codex.&lt;SEP&gt;The process of further training pre-trained language models on specific datasets, such as code repositories, to improve their performance in specific tasks like code generation.&lt;SEP&gt;Fine-tuning involves adapting a pre-trained LLM to specific tasks like HPC code modeling, improving task-specific performance.&lt;SEP&gt;The process of adapting a pre-trained language model to HPC-specific code tasks to enhance performance and accuracy.&lt;SEP&gt;The process of adapting a pre-trained language model to specific HPC code tasks to improve accuracy and performance.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-cfcd5a8798f30da73fdaa3033d579b42&lt;SEP&gt;chunk-acc067e535432960edbc682652b521e0&lt;SEP&gt;chunk-f37ccebb4e61f6d64cd2096830d27b04&lt;SEP&gt;chunk-20aafa58f3d7697ab6ba5015b31cda9b&lt;SEP&gt;chunk-c27a9a886dd19125bb1adb49ea7038f7&lt;SEP&gt;chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Transformer architecture">
  <data key="d0">Transformer architecture</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The foundational neural network architecture used in large language models, enabling modeling of text and code for tasks like code generation and understanding.&lt;SEP&gt;Transformers are the foundational architecture used in large language models for modeling text and code, enabling tasks like code generation and understanding.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="instruction masking">
  <data key="d0">instruction masking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A fine-tuning technique where instruction tokens are masked during training, preventing models from learning to generate instruction text and focusing on generating appropriate responses.&lt;SEP&gt;Instruction masking involves hiding or modifying parts of input data during fine-tuning to improve model understanding and generalization.&lt;SEP&gt;Instruction masking is a fine-tuning technique where tokens in instructions are masked during training to prevent models from learning to generate instruction text, focusing instead on generating appropriate responses.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="synthetic dataset">
  <data key="d0">synthetic dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Artificially created data collections, such as HPC-I NSTRUCT, used to train models when real data is limited or to target specific tasks like parallel code generation.&lt;SEP&gt;Synthetic datasets are artificially created collections of data, such as HPC-I NSTRUCT, used to train and evaluate models when real data is scarce or to target specific tasks.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="model size">
  <data key="d0">model size</data>
  <data key="d1">Variables</data>
  <data key="d2">Larger LLMs, such as GPT-4, tend to perform better on complex problem types like graph problems, indicating a positive correlation between model size and problem-solving capability.&lt;SEP&gt;Model size refers to the number of parameters in a language model, influencing its capacity to learn from data and generalize to tasks like parallel code generation.&lt;SEP&gt;The number of parameters in a language model, affecting its capacity to learn from data and its performance in tasks like parallel code generation.&lt;SEP&gt;The number of parameters in the model, affecting its capacity and performance in generating parallel code.&lt;SEP&gt;Model size impacts the capabilities and risks associated with the system, with larger models potentially exhibiting greater misalignment and bias issues.&lt;SEP&gt;The number of parameters in models like GPT-3, GPT-J, and Codex, which correlates with their performance in code generation tasks.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-eec372249525c58f53cd0e9c24744ffb&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="distillation">
  <data key="d0">distillation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Knowledge distillation is a process where a large, complex model (teacher) generates data or predictions to train a smaller, more efficient model (student), aiming to retain performance with less computational cost.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="software development tasks">
  <data key="d0">software development tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Software development tasks include code completion, summarization, translation, and generation, which are supported by code LLMs.&lt;SEP&gt;Tasks such as code completion, summarization, translation, and generation, supported by code LLMs.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="knowledge distillation">
  <data key="d0">knowledge distillation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A process where a large, complex teacher model generates data or predictions to train a smaller, more efficient student model, aiming to retain performance with less computational cost.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="training data">
  <data key="d0">training data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data used to train and fine-tune models, including synthetic datasets like HPC-I NSTRUCT, which impact model performance.&lt;SEP&gt;Training data encompasses the datasets used to train LLMs, affecting their ability to generate specific code patterns, especially for niche models like Kokkos.&lt;SEP&gt;Large datasets used to pre-train Codex, which may contain insecure code patterns that influence model outputs.&lt;SEP&gt;Large datasets used to pre-train Codex, which may include insecure code snippets that influence the model's outputs.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="performance">
  <data key="d0">performance</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Overall performance gains observed across benchmarks, especially for smaller applications like backprop, nn, and srad, due to reduction in static overhead.&lt;SEP&gt;Performance is assessed through metrics like speedup n@k and efficiency n@k, measuring how well the generated code scales and executes efficiently in parallel environments.&lt;SEP&gt;Performance is crucial for developers writing parallel code, emphasizing the need for benchmarks and metrics to evaluate the capabilities of Large Language Models (LLMs) in this domain.&lt;SEP&gt;Performance refers to the effectiveness and efficiency of developers in writing parallel code, emphasizing the importance of designing benchmarks and metrics to evaluate LLMs' capabilities in this domain.&lt;SEP&gt;Performance refers to the runtime efficiency and scalability of the generated parallel code, often measured by speedup and efficiency metrics.&lt;SEP&gt;The effectiveness of code LLMs in generating accurate and efficient parallel code, influenced by factors like data quality, model size, and training techniques.&lt;SEP&gt;The performance of language models in code generation is evaluated using pass@k, speedup n@k, and efficiency n@k metrics, providing insights into correctness and runtime performance.&lt;SEP&gt;Performance refers to the effectiveness and efficiency of code execution, especially in high-performance computing (HPC), and is the primary focus for modeling and improvement.&lt;SEP&gt;Performance refers to the effectiveness and efficiency of code execution, particularly in high-performance computing (HPC), and is a central focus of the study, aiming to improve and model code performance.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2&lt;SEP&gt;chunk-cfcd5a8798f30da73fdaa3033d579b42&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model training">
  <data key="d0">model training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of adjusting model parameters through exposure to training data, including fine-tuning on specialized datasets for specific tasks.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="performance evaluation">
  <data key="d0">performance evaluation</data>
  <data key="d1">Results</data>
  <data key="d2">Assessments of how well models generate parallel code, based on metrics and experimental results.&lt;SEP&gt;Performance evaluation involves measuring how well LLMs generate correct parallel code across different models and metrics like pass@1 and pass@k.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model capacity">
  <data key="d0">model capacity</data>
  <data key="d1">Variables</data>
  <data key="d2">The ability of a model to learn complex patterns, influenced by its size and architecture, affecting its performance in parallel code generation.&lt;SEP&gt;The size (number of parameters) of the model, impacting its learning ability and performance in parallel code tasks.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="dataset quality">
  <data key="d0">dataset quality</data>
  <data key="d1">Variables</data>
  <data key="d2">The quality and relevance of training data, such as HPC-I NSTRUCT, which directly impact model performance.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="model generalization">
  <data key="d0">model generalization</data>
  <data key="d1">Results</data>
  <data key="d2">The ability of a trained model to perform well on unseen parallel code tasks, affected by data diversity and model size.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="model efficiency">
  <data key="d0">model efficiency</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters like number of parameters and sampling strategies that influence the computational and performance efficiency of models.&lt;SEP&gt;The computational and performance efficiency of code LLMs, influenced by model size and distillation techniques.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="training techniques">
  <data key="d0">training techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods such as instruction masking and data augmentation used during fine-tuning to improve model performance.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code LLMs">
  <data key="d0">Code LLMs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code Large Language Models (LLMs) are advanced AI models trained on large datasets of source code to understand and generate programming code, particularly for parallel languages.&lt;SEP&gt;Large Language Models trained to understand and generate programming code, particularly for parallel languages, used to improve HPC code development.&lt;SEP&gt;Code Large Language Models are specialized LLMs trained on code datasets, capable of generating, predicting, or completing code snippets across programming languages.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Synthetic Dataset">
  <data key="d0">Synthetic Dataset</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A large, artificially generated collection of code samples, including instruction-response pairs, used for training and evaluation of code LLMs.&lt;SEP&gt;A large-scale artificially generated collection of code samples, including instruction-response pairs, used to improve model training and evaluation.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Parallel Code Samples">
  <data key="d0">Parallel Code Samples</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code snippets designed to perform computational tasks in parallel, sourced from open-source HPC codebases, used for training and evaluation.&lt;SEP&gt;Code snippets designed to perform tasks using multiple processors or cores, essential for training models in HPC contexts.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Size">
  <data key="d0">Model Size</data>
  <data key="d1">Variables</data>
  <data key="d2">Model size, referring to the number of parameters in a language model or code large language model (LLM), significantly influences its performance, capacity, and resource requirements. Larger models generally demonstrate better performance, improved ability to learn complex patterns, and enhanced scalability in tasks such as code synthesis and prompt tuning. For example, models with parameter counts ranging from hundreds of millions (e.g., 679 million) to tens of billions (e.g., 34 billion) show varying degrees of capacity and effectiveness, with larger models exhibiting superior performance in evaluation and fine-tuning tasks. 

However, increasing model size involves trade-offs, as it demands more computational resources and memory, and may lead to diminishing returns beyond a certain point. Moving from small to medium-sized models yields significant improvements, but further increases in size tend to produce progressively smaller gains. Additionally, the size of the model correlates with the severity of alignment issues, impacting the robustness and safety of generated outputs. Overall, model size is a critical factor that influences the performance, resource requirements, and practical deployment of large language models across various applications.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b&lt;SEP&gt;chunk-6f045498b0e63780c3aef4b9daf795b6&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-50450e84744379a5c4f059c7d4f84019&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Data Representation and Quality">
  <data key="d0">Data Representation and Quality</data>
  <data key="d1">Variables</data>
  <data key="d2">Attributes of how code data is formatted and its fidelity, influencing model learning effectiveness.&lt;SEP&gt;Attributes related to how code data is formatted and its fidelity, affecting the learning effectiveness of code LLMs.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Prompt Construction">
  <data key="d0">Prompt Construction</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Design strategies for prompts, including positioning (prepend, append, insert), length, and use of templates or discrete prompts to enhance task adaptation.&lt;SEP&gt;Refers to the design aspects of prompts, including positioning, length, and combination with templates or discrete prompts, to improve NLP task performance.&lt;SEP&gt;The design of input prompts used to generate diverse and high-quality code samples during synthetic data creation.&lt;SEP&gt;The way input prompts are designed to elicit diverse and high-quality code outputs from LLMs during data generation.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Ablation Studies">
  <data key="d0">Ablation Studies</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Ablation studies analyze the impact of different training configurations and data partitions on model performance, particularly in parallel code generation.&lt;SEP&gt;Ablation studies are experimental designs that systematically vary specific aspects of models, such as axes of fine-tuning, to assess their impact on performance, particularly in code generation tasks.&lt;SEP&gt;Ablation studies are experiments that systematically vary specific parameters, such as model axes, to understand their contribution to model performance, particularly in fine-tuning code language models (LLMs).&lt;SEP&gt;Experimental analyses that systematically remove or alter components of the training process to understand their impact on model performance.&lt;SEP&gt;Experimental procedures that systematically remove or modify components like data, model size, or prompts to assess their impact on model performance.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Performance Evaluation">
  <data key="d0">Performance Evaluation</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Assessment of fine-tuned models against benchmarks like ParEval to determine their accuracy and efficiency in parallel code generation.&lt;SEP&gt;Assessment of fine-tuned models against benchmarks like ParEval to determine their effectiveness in parallel code generation.&lt;SEP&gt;The process of measuring and analyzing the speedup and efficiency of generated code to determine the effectiveness of parallelization techniques.&lt;SEP&gt;Performance evaluation assesses the effectiveness of the optimization pipeline through benchmarks, simulations, or real-world applications.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc&lt;SEP&gt;chunk-3487322ee335c5f4b3b40717a7de46d1&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Model Comparison">
  <data key="d0">Model Comparison</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Analysis comparing different state-of-the-art HPC-capable code LLMs based on their performance on parallel code generation tasks.&lt;SEP&gt;Analysis comparing multiple state-of-the-art HPC-capable code LLMs based on their performance on the parallel code generation tasks.&lt;SEP&gt;Models like StarCoder2, Magicoder, and Phind-V2 are compared based on pass@k scores, memory requirements, throughput, and overall performance.&lt;SEP&gt;Models such as StarCoder2, Magicoder, and Phind-V2 are compared based on their performance metrics like pass@k, memory requirements, and throughput.&lt;SEP&gt;Comparative analysis of RAG-Token, RAG-Sequence, and BART demonstrating the strengths of retrieval-augmented models over traditional generative models.&lt;SEP&gt;Comparative analysis evaluates different models like GPT-Neo, GPT-J, Codex, and Tabnine to understand their relative coding capabilities and limitations.&lt;SEP&gt;Comparative analysis involves evaluating different models like GPT-Neo, GPT-J, Codex, and Tabnine to understand their relative strengths and limitations in code synthesis.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="HPC Languages">
  <data key="d0">HPC Languages</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Languages such as C, Fortran, CUDA, Chapel, and OpenCL used in high-performance computing, included in the dataset.&lt;SEP&gt;Programming languages such as C, Fortran, CUDA, Chapel, OpenCL, used in high-performance computing contexts and included in the dataset.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Open-source Codebases">
  <data key="d0">Open-source Codebases</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Public repositories like The Stack V2 from which seed code snippets are sourced to generate synthetic training data.&lt;SEP&gt;Publicly available repositories like The Stack V2 from which seed code snippets are sourced for data generation.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Generation of Synthetic Data">
  <data key="d0">Generation of Synthetic Data</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of creating artificial code samples using LLMs, inspired by seed snippets, to augment training datasets for HPC code models.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Data and Model Parameters">
  <data key="d0">Impact of Data and Model Parameters</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigations into how data quality, model size, and prompt design influence the ability of code LLMs to learn and generate parallel code effectively.&lt;SEP&gt;Investigations into how data quality, model size, and prompt design influence the ability of code LLMs to learn and generate parallel code.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Evaluation against Benchmarks">
  <data key="d0">Evaluation against Benchmarks</data>
  <data key="d1">Results</data>
  <data key="d2">Assessing the performance of fine-tuned models on standardized benchmarks like ParEval to validate improvements in parallel code generation.&lt;SEP&gt;Performance assessment of fine-tuned models on standardized datasets like ParEval to validate improvements in parallel code generation.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Diversity">
  <data key="d0">Data Diversity</data>
  <data key="d1">Variables</data>
  <data key="d2">Variety in generated code samples, achieved through multiple seed snippets and prompts, critical for robust model training.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Seed Snippets">
  <data key="d0">Seed Snippets</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code fragments extracted from open-source HPC codebases, used as inspiration to generate diverse synthetic data samples.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="generation">
  <data key="d0">generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Generation refers to the process of creating or producing outputs, in this context related to models and code data.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="model">
  <data key="d0">model</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model is a structured representation or system used to simulate or understand phenomena, here specifically referring to pre-trained and fine-tuned language models.&lt;SEP&gt;Large language models such as GPT-3.5, GPT-4, CodeLlama, and open-source models evaluated for their ability to generate correct parallel code.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30&lt;SEP&gt;chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Listing 1">
  <data key="d0">Listing 1</data>
  <data key="d1">Tools</data>
  <data key="d2">Listing 1 is an example data sample from the HPC-I NSTRUCT dataset illustrating the data format.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="small open-source models">
  <data key="d0">small open-source models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Small open-source models are pre-trained models available publicly, which can be further fine-tuned for specific tasks like code processing.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="DeepSeek-Coder">
  <data key="d0">DeepSeek-Coder</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">DeepSeek-Coder is a family of models selected for fine-tuning, known for their state-of-the-art performance in code modeling.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="parameters">
  <data key="d0">parameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters are the adjustable weights within a model; here, models with 1.3 billion, 6.7 billion, and 16 billion parameters are fine-tuned.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="dataset">
  <data key="d0">dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The HumanEval dataset contains 158 programming problems with descriptions, reference solutions, and tests used for evaluation.&lt;SEP&gt;The dataset used for fine-tuning comprises 87% code and 13% natural language samples, totaling 277,000 samples.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0&lt;SEP&gt;chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="architecture">
  <data key="d0">architecture</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The architecture refers to the structural design of the models, with the 1.3b and 6.7b based on llama, while the 16b uses a mixture-of-experts (MOE) architecture.&lt;SEP&gt;The architecture refers to the structural design of the models, with the 1.3b and 6.7b models based on llama, and the 16b model employing a mixture-of-experts (MOE</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="mixture-of-experts (MOE)">
  <data key="d0">mixture-of-experts (MOE)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">MOE is an architecture that enables scaling to larger model sizes while maintaining runtime performance.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="fine-tuning datasets">
  <data key="d0">fine-tuning datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Datasets like HPC-I NSTRUCT, Magicoder-OSS-Instruct-75K, and Evol-Instruct-Code-80k-v1 are used for fine-tuning, with a total of 277k samples.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="AxoNN">
  <data key="d0">AxoNN</data>
  <data key="d1">Tools</data>
  <data key="d2">AxoNN is a deep learning framework used to automate and parallelize the fine-tuning process across GPUs, built around PyTorch.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="prompt templates">
  <data key="d0">prompt templates</data>
  <data key="d1">Tools</data>
  <data key="d2">Prompt templates are structured instructions used to guide the LLMs in generating specific code or problem data.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="parallel deep learning">
  <data key="d0">parallel deep learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Parallel deep learning involves distributing model training across multiple GPUs or nodes to handle large models and datasets efficiently.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="hyperparameters">
  <data key="d0">hyperparameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Hyperparameters such as batch size, sequence length, and training epochs are tuned to optimize model fine-tuning performance.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="AdamW optimizer">
  <data key="d0">AdamW optimizer</data>
  <data key="d1">Tools</data>
  <data key="d2">AdamW is an optimization algorithm used to update model weights during training based on the fine-tuning loss.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="performance hyperparameters">
  <data key="d0">performance hyperparameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Hyperparameters like batch size and context window length are adjusted according to model size and hardware constraints.&lt;SEP&gt;Hyperparameters like batch size, context window size, and training epochs are adjusted based on model size and hardware constraints to optimize fine-tuning.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="ablation studies">
  <data key="d0">ablation studies</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Ablation studies systematically vary aspects of the fine-tuning process to understand their impact on model performance, such as model size and prompt formatting.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="choice of base model">
  <data key="d0">choice of base model</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates how selecting different base models (1.3b, 6.7b, 16b&lt;SEP&gt;Investigating how the selection of different base models affects fine-tuning outcomes in HPC code generation.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Choice of Base Model and Instruction Masking">
  <data key="d0">Choice of Base Model and Instruction Masking</data>
  <data key="d1">Variables</data>
  <data key="d2">Study investigates how the selection of base models and the use of instruction masking during fine-tuning affect code generation performance, finding that fine-tuning base models yields better results than fine-tuning instruction variants.&lt;SEP&gt;This methodology involves fine-tuning models with different base models and instruction masking settings to assess their impact on performance in generating code, using datasets like HPC-INSTRUCT, Magicoder-OSS-Instruct-75K, and Evol-Instruct-Code-80k-v1.&lt;SEP&gt;This research investigates how the selection of the base model and the use of instruction masking during fine-tuning affect code generation performance, highlighting that fine-tuning base models yields better results than fine-tuning instruction variants.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Instruction Masking">
  <data key="d0">Instruction Masking</data>
  <data key="d1">methodology</data>
  <data key="d2">A technique during fine-tuning where parts of user instructions are masked to prevent the model from learning undesirable patterns, aiming to improve response quality and reduce noise.&lt;SEP&gt;Instruction masking is a technique used during fine-tuning to prevent the model from learning undesirable patterns from user instructions, aiming to improve response quality and reduce noise but potentially limiting learning from instructions.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Data Quantity and Quality">
  <data key="d0">Impact of Data Quantity and Quality</data>
  <data key="d1">study_design</data>
  <data key="d2">This experiment evaluates how varying the amount of parallel code data (e.g., MPI code samples) and the quality of synthetic data affects the performance of fine-tuned models, with datasets created at different scales (0k to 12k MPI samples) and from different source models (Gemini-Pro, DBRX, Llama-3-70B, Mixtral-8x7B).</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Synthetic Data Quality">
  <data key="d0">Synthetic Data Quality</data>
  <data key="d1">variables</data>
  <data key="d2">Synthetic data quality refers to the authenticity and usefulness of artificially generated training data, which impacts the model’s ability to generate accurate parallel code, with proxies for quality assessed via the base models used to generate the synthetic data.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Model Size">
  <data key="d0">Impact of Model Size</data>
  <data key="d1">study_design</data>
  <data key="d2">The research investigates how increasing model size affects the ability to learn from synthetic data and the resulting performance.&lt;SEP&gt;This study investigates how the size of the language model (e.g., 1.3B, 6.7B) influences the performance of fine-tuned models, considering that larger models are hypothesized to have different capabilities and generalization abilities.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Choice of Base Model">
  <data key="d0">Choice of Base Model</data>
  <data key="d1">Variables</data>
  <data key="d2">The selection of the foundational language model (e.g., Deepseek-Coder 1.3B, 6.7B) used as the starting point for fine-tuning, influencing subsequent performance.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-INSTRUCT Dataset">
  <data key="d0">HPC-INSTRUCT Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset comprising instruction-following code samples used for fine-tuning models to improve code generation capabilities.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Magicoder-OSS-Instruct-75K Dataset">
  <data key="d0">Magicoder-OSS-Instruct-75K Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset containing 75,000 instruction-based code samples used for model fine-tuning.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Evol-Instruct-Code-80k-v1 Dataset">
  <data key="d0">Evol-Instruct-Code-80k-v1 Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset with 80,000 instruction-based code samples used for training models to enhance code generation.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="MPI Code Samples">
  <data key="d0">MPI Code Samples</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">MPI code samples are specific parallel programming code snippets identified by substrings like 'mpi.h' or 'MPI Init', used to study the impact of data quantity on model performance.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Synthetic Data">
  <data key="d0">Synthetic Data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data generated from LLMs and open-source parallel code, used for fine-tuning and evaluating HPC code models.&lt;SEP&gt;Synthetic data refers to artificially generated training data, whose quality and quantity are studied for their effects on model fine-tuning and performance.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Trade-off between Data Quantity and Quality">
  <data key="d0">Trade-off between Data Quantity and Quality</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The fundamental idea that increasing data quantity may improve model performance up to a point, beyond which data quality becomes more critical for further gains.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Base Model">
  <data key="d0">Base Model</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The initial pre-trained language model used as the starting point for further fine-tuning, impacting the final capabilities of the model.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Data Quantity">
  <data key="d0">Impact of Data Quantity</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The question of whether increasing the amount of parallel code data improves model performance or if it plateaus at some point.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Data Quality">
  <data key="d0">Impact of Data Quality</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">High-quality parallel code fine-tuning data significantly improves model performance.&lt;SEP&gt;The investigation into how the quality of synthetic data affects the performance of fine-tuned models in code generation.&lt;SEP&gt;The study hypothesizes that higher-quality synthetic data improves model performance in parallel code generation.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="High Computational Cost">
  <data key="d0">High Computational Cost</data>
  <data key="d1">Limitations</data>
  <data key="d2">The significant resource requirements, especially for large models (e.g., 16B), which limit the scope of experiments involving high-capacity models.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="RX">
  <data key="d0">RX</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">RX refers to the overall subject of the study, focusing on large language models (LLMs) used for code generation and their evaluation.&lt;SEP&gt;RX refers to the subject of the study, focusing on large language models (LLMs) used for code generation, evaluation, and their performance characteristics.</data>
  <data key="d3">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Llama-3-70B">
  <data key="d0">Llama-3-70B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Llama-3-70B is a large language model with 70 billion parameters used in the fine-tuning experiments.&lt;SEP&gt;Llama-3-70B is a large language model with 70 billion parameters, used for fine-tuning experiments and performance assessment.</data>
  <data key="d3">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Mixtral-8x7B">
  <data key="d0">Mixtral-8x7B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Mixtral-8x7B is another large language model with 8x7 billion parameters involved in the study.&lt;SEP&gt;Mixtral-8x7B is another large language model with 8x7 billion parameters, involved in the study for comparison.</data>
  <data key="d3">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data">
  <data key="d0">Data</data>
  <data key="d1">Variables</data>
  <data key="d2">Data includes all datasets used for fine-tuning the models, such as the combined data for RX, Llama-3-70B, and Mixtral-8x7B, influencing model performance.&lt;SEP&gt;The data used for fine-tuning includes all data combined from models RX, Llama-3-70B, and Mixtral-8x7B, impacting model performance.</data>
  <data key="d3">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Performance">
  <data key="d0">Performance</data>
  <data key="d1">&lt;|Core Concepts</data>
  <data key="d2">Model performance is evaluated based on accuracy, resource requirements, and efficiency in code generation.&lt;SEP&gt;Model performance is measured via metrics such as pass@k, accuracy, throughput, and resource consumption during code generation tasks.&lt;SEP&gt;Model performance varies based on the number of retrieved documents, with some models peaking at specific retrieval counts.&lt;SEP&gt;The measurable output of code execution, including correctness, efficiency, and scalability, used to evaluate LLM-generated code.&lt;SEP&gt;Refers to the efficiency and speed of executing code, which can be improved by reducing static overhead and optimizing compiler transformations.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HPC-I NSTRUCT Dataset">
  <data key="d0">HPC-I NSTRUCT Dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset used for fine-tuning models of varying sizes (1.3B, 6.7B, 16B) to assess performance across different model sizes.&lt;SEP&gt;A dataset used to fine-tune models of different sizes (1.3B, 6.7B, 16B) to evaluate performance across sizes and resource needs.</data>
  <data key="d3">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="ParEval Benchmark">
  <data key="d0">ParEval Benchmark</data>
  <data key="d1">Tools</data>
  <data key="d2">A benchmarking tool used to evaluate the performance of HPC code LLMs on parallel code generation tasks.&lt;SEP&gt;A standardized evaluation framework used to assess the problem-solving performance of models like GPT-4, HPC-Coder-V2-6.7B, HPC-Coder-V2-16B, and Phind-V2-34B across multiple problem types and execution models.&lt;SEP&gt;ParEval is a benchmark comprising 420 coding problems across 12 problem types and 7 execution models, used to evaluate model capabilities in parallel code generation.&lt;SEP&gt;ParEval is a benchmark with 420 coding problems across 12 problem types and 7 execution models used to evaluate the efficacy of models in parallel code generation.&lt;SEP&gt;The ParEval benchmark suite assesses the performance of code models across multiple problem types, providing standardized evaluation metrics.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-727ea750122a5bed30ad781918446611&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="pass@k">
  <data key="d0">pass@k</data>
  <data key="d1">Results</data>
  <data key="d2">A metric estimating the probability that a model generates a correct solution within k attempts for a given prompt, used to evaluate code correctness.&lt;SEP&gt;pass@k extends pass@1 to multiple attempts (k&gt;1), providing a broader measure of an LLM's ability to produce correct solutions over several tries.&lt;SEP&gt;pass@k extends pass@1 to multiple attempts (k&gt;1), providing a broader view of LLM performance in problem-solving across several tries.&lt;SEP&gt;pass@k is a metric estimating the probability that a model generates a correct solution within k attempts for a given prompt, used to evaluate code correctness.&lt;SEP&gt;pass@k is a probabilistic metric estimating the likelihood that a model generates at least one correct solution within k attempts, used for evaluating code correctness.&lt;SEP&gt;pass@k is a probabilistic metric used to estimate the likelihood that a model generates at least one correct solution within k attempts, used to evaluate code correctness.&lt;SEP&gt;A performance metric that measures the success rate of code generation models in producing correct code within the top k samples, used to evaluate model effectiveness.&lt;SEP&gt;pass@k is a performance metric used to evaluate the success rate of code generation models at generating correct code within the top k samples.&lt;SEP&gt;pass@k measures the percentage of problems solved correctly within the top k solutions generated by a model, serving as a key performance indicator in code generation tasks.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Trade-offs">
  <data key="d0">Trade-offs</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The balance between computational cost, ease of implementation, and performance or generalization capabilities across different domain adaptation strategies.&lt;SEP&gt;Trade-offs describe the balance between computational cost, ease of implementation, and performance or generalization capabilities among different domain adaptation approaches.&lt;SEP&gt;Trade-offs involve balancing model size, computational resources, and performance gains to optimize practical deployment.&lt;SEP&gt;Trade-offs involve balancing model size, resource consumption, and performance gains in practical applications.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Evaluation Metrics">
  <data key="d0">Evaluation Metrics</data>
  <data key="d1">Study Design</data>
  <data key="d2">Criteria and scoring systems used to assess the correctness, quality, and trade-offs of AI-generated kernels across various parameters.&lt;SEP&gt;Evaluation metrics are criteria and scoring systems used to assess the quality, correctness, and trade-offs of the generated kernels and outputs from AI models.&lt;SEP&gt;Evaluation metrics quantify the performance of AI-generated code, such as accuracy scores or quality assessments."|&gt;&lt;SEP&gt;Metrics are proposed to assess AI-generated code, emphasizing the need for a widely accepted, standardized approach.&lt;SEP&gt;Metrics like pass@k are used to evaluate models' effectiveness in generating correct code solutions.&lt;SEP&gt;Metrics used to assess model performance include accuracy, factual correctness, and ability to update knowledge without retraining.&lt;SEP&gt;Metrics such as pass@1 measure the success rate of models in generating correct code responses.&lt;SEP&gt;Metrics used to quantify the correctness and overall quality of AI-generated code, including a simple correctness score and correlation with language popularity indices.&lt;SEP&gt;Metrics used to quantify the correctness and quality of AI-generated code, including a simple correctness metric and correlation with language popularity.&lt;SEP&gt;Metrics such as accuracy, precision, recall used to assess the performance of LLMs on tasks with various prompting methods.&lt;SEP&gt;Metrics like pass@k and test loss measure the performance of Codex in code generation tasks, indicating accuracy and efficiency.&lt;SEP&gt;Metrics such as pass@k and BLEU scores are used to quantify model success and solution quality in code synthesis tasks.&lt;SEP&gt;Metrics such as pass@k and test loss measure the accuracy and efficiency of code generation by Codex, indicating its performance level.&lt;SEP&gt;Metrics such as success rate, pass rate, and performance drop ratios used to quantify Codex's capabilities and limitations.&lt;SEP&gt;Metrics such as pass@k and compilation success rate used to assess model performance in code correctness and syntactic validity.&lt;SEP&gt;Metrics such as perplexity and accuracy used to assess the performance of language models on downstream tasks like code generation.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-d25502af8737c59d857916af40cc4020&lt;SEP&gt;chunk-04aecdc2586d2c7966e70e02cac846b0&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482&lt;SEP&gt;chunk-daac5179ef8fa77fe775da37eb1276f3&lt;SEP&gt;chunk-5adc1bc605f86b4e3648d3a3ef16f8a3&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Models">
  <data key="d0">Models</data>
  <data key="d1">Variables</data>
  <data key="d2">Different large language models evaluated for code generation, translation accuracy, efficiency, and scalability.&lt;SEP&gt;Different large language models evaluated for code generation, translation, efficiency, and scalability.&lt;SEP&gt;Models such as RX, Llama-3-70B, Mixtral-8x7B, StarCoder2, Magicoder, and Phind-V2 are evaluated for code generation performance.&lt;SEP&gt;Models trained with either 5 or 10 retrieved latent documents to compare performance impacts.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Metrics for Comparison">
  <data key="d0">Metrics for Comparison</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Metrics such as pass@k are employed to compare models' effectiveness in code generation, considering correctness, resource use, and speed.</data>
  <data key="d3">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Evaluation Techniques">
  <data key="d0">Evaluation Techniques</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Evaluation involves benchmarking models using metrics like pass@k, analyzing their correctness, efficiency, and resource consumption.&lt;SEP&gt;State-of-the-art methods used to assess the correctness, performance, and quality of code generated by LLMs across multiple problems and models.&lt;SEP&gt;Evaluation techniques assess the effectiveness of domain adaptation methods, including performance metrics, benchmarks, and case studies.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Magicoder">
  <data key="d0">Magicoder</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A source code model that emphasizes the importance of source code for model training and performance.&lt;SEP&gt;Magicoder is a 6.7B model fine-tuned from DeepseekCoder-6.7B on synthetic data generated from open-source code, aimed at improving code modeling capabilities.&lt;SEP&gt;Magicoder is a 6.7B model fine-tuned from DeepseekCoder-6.7B on synthetic data generated from open-source code, used for code modeling.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Phind-V2">
  <data key="d0">Phind-V2</data>
  <data key="d1">Tools</data>
  <data key="d2">An AI tool evaluated for efficiency in executing MPI, OpenMP, and Kokkos prompts, indicating its performance in parallel environments.&lt;SEP&gt;An AI tool or model evaluated for efficiency in parallel prompts, especially in MPI, OpenMP, and Kokkos contexts.&lt;SEP&gt;Phind-V2 is a 34B model fine-tuned on a proprietary dataset from CodeLlama-34B, considered a state-of-the-art model on the BigCode leaderboard.&lt;SEP&gt;Phind-V2 is a 34B model fine-tuned on a proprietary dataset from CodeLlama-34B, recognized as the best performing model on the BigCode leaderboard at its release.&lt;SEP&gt;Phind-V2 is an open-source LLM that demonstrates high performance in code generation tasks but still lags behind some closed-source models in accuracy.&lt;SEP&gt;Phind-V2 is an open-source large language model that demonstrates strong performance in code generation tasks, but still trails behind some closed-source models in accuracy.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Gemini-1.5-flash">
  <data key="d0">Gemini-1.5-flash</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Gemini-1.5-flash is a commercial code model from Google accessible via API, used for code generation and related tasks.&lt;SEP&gt;Gemini-1.5-flash is a commercial model available via API from Google, used for code-related tasks.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="GPT-3.5, GPT-4">
  <data key="d0">GPT-3.5, GPT-4</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">GPT-3.5 and GPT-4 are state-of-the-art commercial large language models from OpenAI, accessible via API, used for advanced language understanding and generation.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Parallel Code Generation Performance">
  <data key="d0">Parallel Code Generation Performance</data>
  <data key="d1">Results</data>
  <data key="d2">Performance metrics such as Pass@1 scores used to evaluate the ability of models to generate code in parallel tasks, influenced by training strategies.&lt;SEP&gt;Performance metrics, such as Pass@1 scores, evaluate how well models generate code in parallel tasks, influenced by training choices.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Amount and Quality of Parallel Code Data">
  <data key="d0">Amount and Quality of Parallel Code Data</data>
  <data key="d1">Variables</data>
  <data key="d2">This examines how the volume of fine-tuning data, specifically for MPI code, impacts model performance, indicating diminishing returns for larger models with increased data.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="VI. Results of Ablation Studies">
  <data key="d0">VI. Results of Ablation Studies</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Section analyzing how different training configurations and data partitions impact model performance in parallel code generation, including effect of base model choice and instruction masking.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Fine-Tuning Data Volume">
  <data key="d0">Impact of Fine-Tuning Data Volume</data>
  <data key="d1">Variables</data>
  <data key="d2">Examines how the amount of fine-tuning data, especially for MPI code, influences model performance, showing diminishing returns for larger models with increased data.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="MPI Code">
  <data key="d0">MPI Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">MPI (Message Passing Interface) code is used as a benchmark for evaluating the models' ability to generate parallel code, with performance measured across different training data sizes.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Sizes">
  <data key="d0">Model Sizes</data>
  <data key="d1">Variables</data>
  <data key="d2">Model sizes (1.3B and 6.7B) are considered in the study to observe how size affects performance gains from increased training data.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Fine-Tuning Data Quality">
  <data key="d0">Fine-Tuning Data Quality</data>
  <data key="d1">Variables</data>
  <data key="d2">The quality of data used to fine-tune models affects their ability to generate accurate and efficient parallel code, with higher quality data leading to better performance.&lt;SEP&gt;The quality of fine-tuning data impacts the model's ability to learn effectively; higher quality data leads to better code generation performance.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Synthetic Data Sources">
  <data key="d0">Synthetic Data Sources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Synthetic data sources are artificially generated datasets used to train models, which can vary in quality and impact model performance in code generation tasks.&lt;SEP&gt;Synthetic data sources are artificially generated datasets used to train models, with their quality affecting the models' performance in parallel code generation.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Overfitting">
  <data key="d0">Overfitting</data>
  <data key="d1">Limitations</data>
  <data key="d2">A potential issue where a model becomes too tailored to training data, reducing its ability to generalize to new data in the domain.&lt;SEP&gt;Overfitting occurs when a model learns the training data too closely, including noise, leading to poor generalization, especially in smaller models.&lt;SEP&gt;Overfitting occurs when a model learns the training data too well, including noise, leading to poor generalization on new data, especially in smaller models.&lt;SEP&gt;When a model learns training data too closely, including noise, leading to poor generalization on new data.&lt;SEP&gt;Back-translation ranking method shows overfitting tendencies, leading to quick performance decline as models adapt too closely to training heuristics.&lt;SEP&gt;Overfitting occurs when a model learns the training data too closely, potentially reducing its ability to generalize to new, unseen code samples.&lt;SEP&gt;Overfitting occurs when models learn training data too closely, reducing their ability to generalize to new code snippets, thus impairing pragma generation performance.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b&lt;SEP&gt;chunk-d25502af8737c59d857916af40cc4020&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Knowledge Distillation">
  <data key="d0">Knowledge Distillation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Knowledge Distillation is a process where a smaller model learns from a larger, pre-trained model to transfer knowledge, reduce inference latency, and enhance domain-specific capabilities.&lt;SEP&gt;Knowledge Distillation is a process where a smaller, often more efficient model learns from a larger pre-trained model to transfer knowledge, reduce inference latency, and improve domain adaptation.&lt;SEP&gt;Knowledge distillation involves transferring knowledge from large, complex models to smaller, more efficient models while maintaining performance.&lt;SEP&gt;Knowledge distillation is a training process where a smaller 'student' model learns from a larger 'teacher' model, aiming to replicate its performance with fewer parameters.&lt;SEP&gt;Knowledge distillation is a training technique where a smaller model learns from a larger 'teacher' model, aiming to replicate its performance while reducing resource requirements.&lt;SEP&gt;Knowledge distillation transfers knowledge from a large, pre-trained model to a smaller, domain-specific model, enabling efficient knowledge updates.&lt;SEP&gt;Transferring knowledge from large models to smaller ones, enabling domain-specific updates and efficient deployment.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-ce8332c6d0b3d23f38189ff80650d4bc&lt;SEP&gt;chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Benchmark Suite">
  <data key="d0">Benchmark Suite</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Benchmark suites like ParEval are used to evaluate and compare the performance of different code generation models across various problem types and datasets.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="State-of-the-Art Models">
  <data key="d0">State-of-the-Art Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">State-of-the-art models are the most advanced and high-performing models in a specific domain, such as parallel code generation, often used as benchmarks or baselines.&lt;SEP&gt;State-of-the-art models are the most advanced models in a domain, such as parallel code generation, representing the current peak of performance and capability.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Pass@1">
  <data key="d0">Pass@1</data>
  <data key="d1">Results</data>
  <data key="d2">A performance metric indicating whether the model successfully solves a problem on the first attempt, used to compare the effectiveness of different models across problem types and execution models.&lt;SEP&gt;Pass@1 is an evaluation metric indicating the percentage of correct code samples generated on the first attempt during model testing.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Gains from Model Scaling">
  <data key="d0">Gains from Model Scaling</data>
  <data key="d1">Results</data>
  <data key="d2">Increasing model size from 1.3B to 6.7B yields significant performance improvements, but gains diminish beyond 6.7B.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Performance Plateau">
  <data key="d0">Performance Plateau</data>
  <data key="d1">Results</data>
  <data key="d2">The performance of smaller models plateaus or decreases after a certain amount of training data due to overfitting, whereas larger models maintain steady improvements.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Trade-offs in Model Deployment">
  <data key="d0">Trade-offs in Model Deployment</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Understanding how model size impacts performance and resource costs informs practical deployment decisions for high-performance code generation systems.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2-16B">
  <data key="d0">HPC-Coder-V2-16B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large language model (LLM) designed specifically for code generation in high-performance computing (HPC), evaluated on the ParEval benchmark suite to assess its performance across different problem types and execution models.&lt;SEP&gt;A large language model designed for code generation in high-performance computing (HPC), evaluated on the ParEval benchmark suite.&lt;SEP&gt;An even larger HPC code LLM with 16 billion parameters, fine-tuned for parallel code generation.&lt;SEP&gt;HPC-Coder-V2-16B is an advanced version of the HPC-Coder model, assessed similarly with performance metrics across multiple problem types and execution models.&lt;SEP&gt;HPC-Coder-V2-16B is another model version evaluated similarly, with detailed performance metrics across problem types and execution models.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="ParEval benchmark suite">
  <data key="d0">ParEval benchmark suite</data>
  <data key="d1">Study Design</data>
  <data key="d2">A benchmark suite used to evaluate the performance of code generation models across various problem types and execution models in HPC.&lt;SEP&gt;A comprehensive benchmark suite used to evaluate and compare the code generation performance of various LLMs across multiple problem types and parallel execution models in HPC.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code Generation Performance">
  <data key="d0">Code Generation Performance</data>
  <data key="d1">Results</data>
  <data key="d2">The performance metrics indicating how well HPC-Coder-V2 and other models generate code across different problem types and execution models, with higher performance noted for larger models and certain problem types.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2 Across Problem Types">
  <data key="d0">HPC-Coder-V2 Across Problem Types</data>
  <data key="d1">Results</data>
  <data key="d2">Performance of HPC-Coder-V2 varies across problem types, performing better on dense and structured problems, with performance decreasing on geometric problems as model size increases.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2 Across Execution Models">
  <data key="d0">HPC-Coder-V2 Across Execution Models</data>
  <data key="d1">Results</data>
  <data key="d2">Performance of HPC-Coder-V2 across serial, OpenMP, CUDA, HIP, Kokkos, MPI, and MPI+OpenMP models, with the best performance on serial and OpenMP, and struggles with MPI code.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Comparison with Other Models">
  <data key="d0">Comparison with Other Models</data>
  <data key="d1">Results</data>
  <data key="d2">HPC-Coder-V2 models outperform smaller and comparable models in parallel code generation, surpassing some larger models in efficiency and speed, but are still outperformed by certain models like Magicoder-6.7B in serial code generation.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Throughput, Memory, and Performance Metrics">
  <data key="d0">Throughput, Memory, and Performance Metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics used to evaluate the trade-offs between model size, speed, and accuracy, demonstrating HPC-Coder-V2's efficiency in generating high-quality parallel code with lower resource requirements.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Related Work on Code LLMs for HPC">
  <data key="d0">Related Work on Code LLMs for HPC</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A body of literature focusing on the design, fine-tuning, and application of code language models specifically for high-performance computing tasks.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code generation performance">
  <data key="d0">Code generation performance</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics indicating how effectively different models generate correct and efficient code across problem types and execution models, with performance varying by model size and problem complexity.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Problem types">
  <data key="d0">Problem types</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Different categories of computational problems (e.g., sparse linear algebra, dense linear algebra, geometric problems, stencil, data transformation</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Execution models">
  <data key="d0">Execution models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Various parallel programming models (serial, OpenMP, CUDA, HIP, Kokkos, MPI, MPI+OpenMP) used to assess the models' ability to generate code suited for different HPC parallelization paradigms.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model size">
  <data key="d0">Model size</data>
  <data key="d1">Variables</data>
  <data key="d2">Different sizes of the HPC-Coder-V2 models (1.3B, 6.7B, 16B</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Performance metrics">
  <data key="d0">Performance metrics</data>
  <data key="d1">Variables</data>
  <data key="d2">Quantitative measures such as throughput, required memory, and pass@1 scores used to evaluate model accuracy, speed, and resource efficiency in code generation.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Comparison with other models">
  <data key="d0">Comparison with other models</data>
  <data key="d1">Results</data>
  <data key="d2">Assessment of HPC-Coder-V2's performance relative to other state-of-the-art code LLMs, including models like StarCoder2, Phind, and Magicoder, highlighting strengths and weaknesses in parallel and serial code generation.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Trade-offs in model deployment">
  <data key="d0">Trade-offs in model deployment</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Discussion on balancing model size, speed, correctness, and resource requirements to optimize usability for developers in HPC environments.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Speed and resource efficiency">
  <data key="d0">Speed and resource efficiency</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Considerations for deploying models that generate high-quality code quickly and with minimal computational resources, emphasizing practical usability.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Parallel code correctness">
  <data key="d0">Parallel code correctness</data>
  <data key="d1">Results</data>
  <data key="d2">A key metric indicating how often the generated code is correct across different models and problem types, essential for HPC applications.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model comparison metrics">
  <data key="d0">Model comparison metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics used to compare the efficiency, accuracy, and resource consumption of different code LLMs across various benchmarks.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code LLMs for HPC">
  <data key="d0">Code LLMs for HPC</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Language models designed or adapted specifically to generate, understand, and optimize high-performance computing (HPC) and parallel code, often involving specialized training data and techniques.&lt;SEP&gt;Language models specialized in generating or understanding high-performance computing (HPC) code, tailored for parallel computing tasks.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder">
  <data key="d0">HPC-Coder</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A fine-tuned large language model designed specifically for modeling HPC and scientific codes, capable of code generation, labeling, and performance prediction.&lt;SEP&gt;A specialized large language model (LLM) designed for modeling and automating tasks related to parallel high-performance computing (HPC) codes, including function auto-completion, code decoration with OpenMP pragmas, and performance prediction.&lt;SEP&gt;A specialized large language model (LLM) fine-tuned on parallel high-performance computing (HPC) codes to automate tasks such as function auto-completion, code decoration with OpenMP pragmas, and performance modeling.&lt;SEP&gt;A specific code LLM designed for HPC code generation, fine-tuned using synthetic HPC data, with models like HPC-Coder-V2 evaluated for performance.&lt;SEP&gt;A specific family of code language models, such as HPC-Coder-V2, fine-tuned for HPC code generation, evaluated for performance metrics like pass@1, throughput, and memory efficiency.&lt;SEP&gt;HPC-Coder is a specialized large language model fine-tuned to understand, generate, and label high-performance computing (HPC) and scientific source code, outperforming other models on specific tasks.&lt;SEP&gt;HPC-Coder is the fine-tuned model (PolyCoder+HPC) selected for further analysis due to its superior training scores and code generation performance.&lt;SEP&gt;HPC-Coder refers to PolyCoder+HPC, the fine-tuned model selected for further evaluation due to its high training and code generation performance.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-c27a9a886dd19125bb1adb49ea7038f7&lt;SEP&gt;chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Fine-tuning Specialized Code LLMs">
  <data key="d0">Fine-tuning Specialized Code LLMs</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Approaches for customizing language models to domain-specific tasks, addressing data limitations, and enhancing code generation accuracy.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Synthetic HPC Data">
  <data key="d0">Synthetic HPC Data</data>
  <data key="d1">Tools</data>
  <data key="d2">Artificially generated datasets created using LLMs and open-source code to augment training data for HPC code models.&lt;SEP&gt;Artificially generated datasets created using language models and open-source parallel code, used to augment training data for HPC-specific models.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Quality">
  <data key="d0">Data Quality</data>
  <data key="d1">Variables</data>
  <data key="d2">Attributes of training data that impact model performance; emphasizes that high data quality is more critical than data quantity in HPC model fine-tuning.&lt;SEP&gt;Attributes of training data that influence the effectiveness of fine-tuning, emphasizing the importance of high-quality data over quantity in HPC contexts.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Performance Metrics">
  <data key="d0">Model Performance Metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics such as factuality percentage, diversity scores, and accuracy measures used to evaluate the effectiveness of models like RAG and BART in generation tasks.&lt;SEP&gt;Quantitative measures such as pass@1, throughput (tokens/sec), and memory requirements (GB) used to evaluate and compare the effectiveness of different HPC code models.&lt;SEP&gt;Quantitative measures such as pass@1, throughput, and memory efficiency used to evaluate the effectiveness of fine-tuned HPC models.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Synthetic Data Generation">
  <data key="d0">Synthetic Data Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques utilizing LLMs to produce synthetic data aimed at overcoming data scarcity issues for training specialized models.&lt;SEP&gt;The process of creating synthetic datasets from LLMs and open-source code to facilitate model training and evaluation.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Collection">
  <data key="d0">Data Collection</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Data collection involves gathering large datasets of HPC source code from GitHub repositories, filtering, deduplicating, and tokenizing the data to prepare it for training.&lt;SEP&gt;The process of gathering training data, including synthetic data creation, to improve model training for HPC code generation.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Architecture">
  <data key="d0">Model Architecture</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Structural design of large language models, including transformer-based architectures like Llama 2 and GPT.&lt;SEP&gt;The structural design of the language models (e.g., GPT-2, GPT-3.5), affecting capabilities and performance in HPC tasks.&lt;SEP&gt;The structural design or framework of the language models (e.g., GPT-2, GPT-3.5), affecting their capacity, efficiency, and suitability for HPC tasks.&lt;SEP&gt;The structure and design of the neural network underlying an LLM, including layers, attention mechanisms, etc.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2-1.3B">
  <data key="d0">HPC-Coder-V2-1.3B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A state-of-the-art HPC code language model (LLM) with 1.3 billion parameters, fine-tuned for parallel code generation.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2-6.7B">
  <data key="d0">HPC-Coder-V2-6.7B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A larger HPC code LLM with 6.7 billion parameters, fine-tuned for parallel code generation.&lt;SEP&gt;HPC-Coder-V2-6.7B is a computational model used for solving problems related to high-performance computing, evaluated via pass@1 scores across various problem types and execution models.&lt;SEP&gt;HPC-Coder-V2-6.7B is a specific model version used for computational tasks, with performance metrics such as pass@1 scores across various problem types and execution models.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Fine-Tuning">
  <data key="d0">Model Fine-Tuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">The process of training HPC code LLMs on specific datasets, such as HPC-I NSTRUCT, to improve their performance on parallel code generation.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data, Model, and Prompt Configuration">
  <data key="d0">Data, Model, and Prompt Configuration</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters studied to understand their impact on the ability of code LLMs to generate parallel code.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Performance of HPC Code LLMs">
  <data key="d0">Performance of HPC Code LLMs</data>
  <data key="d1">Results</data>
  <data key="d2">The fine-tuned models, especially HPC-Coder-V2-6.7B and 16B, are the best performing open-source models at generating parallel code, with faster speed and lower memory usage than similar models.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Insights on Fine-Tuning">
  <data key="d0">Insights on Fine-Tuning</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">How different training choices (e.g., instruction masking, data size, model size) impact the ability of code LLMs to generate parallel code.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Open-Source Models">
  <data key="d0">Open-Source Models</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study evaluates how open-source HPC code LLMs perform in parallel code generation compared to other models.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Impact">
  <data key="d0">Data Impact</data>
  <data key="d1">Results</data>
  <data key="d2">The quality and quantity of training data influence the performance of HPC code LLMs in parallel code generation.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Scaling">
  <data key="d0">Model Scaling</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Model scaling describes how increasing model size affects performance, often following a sigmoid pattern as observed in the results.&lt;SEP&gt;Moving from small to medium size models yields significant performance gains, with further increases offering diminishing returns.&lt;SEP&gt;Scaling models by increasing size (parameters, layers) or data enhances their capacity for complex tasks, improves performance, and supports better domain adaptation.&lt;SEP&gt;Scaling pre-trained language models by increasing model size or data size enhances their capacity for downstream tasks, contributing to improved performance and versatility in domain adaptation.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Benchmarking">
  <data key="d0">Benchmarking</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Benchmarking compares generated code against hand-tuned versions across multiple examples, measuring runtime and efficiency to evaluate performance.&lt;SEP&gt;Benchmarking compares the performance of generated code against hand-tuned versions across multiple examples, measuring runtime and efficiency.&lt;SEP&gt;Benchmarking refers to establishing standardized tests and comparisons to evaluate the performance, correctness, and efficiency of AI-generated HPC kernels across programming models and languages.&lt;SEP&gt;ParEval benchmark used to assess and compare the performance of different HPC code LLMs.&lt;SEP&gt;The process of systematically evaluating large language models' performance on the set of coding tasks using the ParEval benchmark and novel evaluation metrics.&lt;SEP&gt;The systematic process of evaluating models' performance on the coding tasks using ParEval and the associated metrics.&lt;SEP&gt;Systematic testing and comparison of AI-generated HPC kernels across different programming models, languages, and prompt inputs to evaluate performance.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Training Data Quality">
  <data key="d0">Training Data Quality</data>
  <data key="d1">Variables</data>
  <data key="d2">The quality of the parallel code fine-tuning data impacts model performance significantly.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code llama">
  <data key="d0">Code llama</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Open foundation models for code, a set of large language models designed specifically for programming tasks and code generation.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Gpt-4o system card">
  <data key="d0">Gpt-4o system card</data>
  <data key="d1">Tools</data>
  <data key="d2">A documentation or technical report describing the GPT-4O system, likely including its capabilities, architecture, and intended applications.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Knowledge distillation of large language models">
  <data key="d0">Knowledge distillation of large language models</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A survey exploring methods and effectiveness of knowledge distillation techniques applied to large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Big code models leaderboard">
  <data key="d0">Big code models leaderboard</data>
  <data key="d1">Tools</data>
  <data key="d2">A leaderboard hosted on Hugging Face showcasing the performance of various large code models.&lt;SEP&gt;A platform hosted on Hugging Face that ranks large code models based on performance metrics.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Deepseek-coder">
  <data key="d0">Deepseek-coder</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large language model focused on code intelligence, meeting the rise of AI in programming, described by Guo et al. in 2024.&lt;SEP&gt;A large language model specialized in code intelligence, integrating code understanding and generation capabilities.&lt;SEP&gt;Deepseek-coder is a large language model designed to enhance code intelligence, particularly in meeting programming challenges and advancing code understanding.&lt;SEP&gt;Deepseek-coder is a large language model focused on code intelligence, designed to enhance code understanding and generation.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Deepseek-coder-v2">
  <data key="d0">Deepseek-coder-v2</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An advanced version of Deepseek-coder aimed at breaking barriers of closed-source models in code intelligence.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Efficient large scale language modeling with mixtures of experts">
  <data key="d0">Efficient large scale language modeling with mixtures of experts</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique involving the use of mixture of experts to scale large language models efficiently by leveraging sparsity and specialized subnetworks.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Wizardcoder">
  <data key="d0">Wizardcoder</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large language model enhanced with evol-instruct techniques to improve code generation and understanding.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Exploiting sparsity in pruned neural networks to optimize large model training">
  <data key="d0">Exploiting sparsity in pruned neural networks to optimize large model training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A method focusing on leveraging sparsity in neural networks to reduce computational load and optimize training of large models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Fixing weight decay regularization in Adam">
  <data key="d0">Fixing weight decay regularization in Adam</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A research paper proposing modifications to weight decay regularization within the Adam optimizer to improve training stability and performance.&lt;SEP&gt;A technique or modification aimed at improving the Adam optimizer's regularization by addressing issues related to weight decay.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="J. Bitton">
  <data key="d0">J. Bitton</data>
  <data key="d1">Authors</data>
  <data key="d2">J. Bitton is a researcher involved in studies related to health and medical research.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="M. Bhatt">
  <data key="d0">M. Bhatt</data>
  <data key="d1">Authors</data>
  <data key="d2">M. Bhatt is a researcher contributing to scientific publications in health sciences.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. C. Ferrer">
  <data key="d0">C. C. Ferrer</data>
  <data key="d1">Authors</data>
  <data key="d2">C. C. Ferrer is a researcher participating in research publications in medical and health-related fields.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A. Grattafiori">
  <data key="d0">A. Grattafiori</data>
  <data key="d1">Authors</data>
  <data key="d2">A. Grattafiori is a researcher involved in scientific studies, likely in health or data science.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="W. Xiong">
  <data key="d0">W. Xiong</data>
  <data key="d1">Authors</data>
  <data key="d2">W. Xiong is a researcher contributing to the publication of scientific research.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A. D ´efossez">
  <data key="d0">A. D ´efossez</data>
  <data key="d1">Authors</data>
  <data key="d2">A. D ´efossez is a researcher involved in scientific publications, possibly in health sciences or data science.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="J. Copet">
  <data key="d0">J. Copet</data>
  <data key="d1">Authors</data>
  <data key="d2">J. Copet is a researcher contributing to scientific literature.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="F. Azhar">
  <data key="d0">F. Azhar</data>
  <data key="d1">Authors</data>
  <data key="d2">F. Azhar is a researcher involved in scientific research, likely in health or data science.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="H. Touvron">
  <data key="d0">H. Touvron</data>
  <data key="d1">Authors</data>
  <data key="d2">H. Touvron is a researcher contributing to research in machine learning or NLP.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="L. Martin">
  <data key="d0">L. Martin</data>
  <data key="d1">Authors</data>
  <data key="d2">L. Martin is a researcher involved in scientific publications, possibly in AI or health sciences.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="N. Usunier">
  <data key="d0">N. Usunier</data>
  <data key="d1">Authors</data>
  <data key="d2">N. Usunier is a researcher contributing to scientific research, likely in machine learning or NLP.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="T. Scialom">
  <data key="d0">T. Scialom</data>
  <data key="d1">Authors</data>
  <data key="d2">T. Scialom is a researcher involved in scientific publications, possibly in NLP or AI.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="G. Synnaeve">
  <data key="d0">G. Synnaeve</data>
  <data key="d1">Authors</data>
  <data key="d2">G. Synnaeve is a researcher contributing to research in AI, NLP, or related fields.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A. Hurst">
  <data key="d0">A. Hurst</data>
  <data key="d1">Authors</data>
  <data key="d2">A. Hurst is a researcher involved in system documentation or technical reports related to AI models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="System card">
  <data key="d0">System card</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The GPT-4O system card is a detailed documentation describing the architecture, capabilities, and features of the GPT-4O language model.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="X. Xu">
  <data key="d0">X. Xu</data>
  <data key="d1">Authors</data>
  <data key="d2">X. Xu is a researcher contributing to studies on large language models and knowledge distillation.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="M. Li">
  <data key="d0">M. Li</data>
  <data key="d1">Authors</data>
  <data key="d2">M. Li is a researcher involved in research on large language models and their training methods.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. Tao">
  <data key="d0">C. Tao</data>
  <data key="d1">Authors</data>
  <data key="d2">C. Tao is a researcher contributing to studies on knowledge distillation and model compression in NLP.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="T. Shen">
  <data key="d0">T. Shen</data>
  <data key="d1">Authors</data>
  <data key="d2">T. Shen is a researcher involved in research on large language models and knowledge transfer techniques.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="R. Cheng">
  <data key="d0">R. Cheng</data>
  <data key="d1">Authors</data>
  <data key="d2">R. Cheng is a researcher contributing to research on large language models and their training methodologies.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="J. Li">
  <data key="d0">J. Li</data>
  <data key="d1">Authors</data>
  <data key="d2">J. Li is a researcher involved in code model research and large language models.&lt;SEP&gt;J. Li is a researcher involved in studies on large language models and their applications.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. Xu">
  <data key="d0">C. Xu</data>
  <data key="d1">Authors</data>
  <data key="d2">C. Xu is a researcher contributing to research on large language models and knowledge distillation.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="D. Tao">
  <data key="d0">D. Tao</data>
  <data key="d1">Authors</data>
  <data key="d2">D. Tao is a researcher involved in research on large language models, model training, and knowledge transfer.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="T. Zhou">
  <data key="d0">T. Zhou</data>
  <data key="d1">Authors</data>
  <data key="d2">T. Zhou is a researcher contributing to studies on large language models and NLP techniques.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="arXiv">
  <data key="d0">arXiv</data>
  <data key="d1">Discipline</data>
  <data key="d2">A preprint repository for scientific papers in fields like AI, machine learning, and computer science.&lt;SEP&gt;A repository for preprints of research papers, including the delta tuning study.&lt;SEP&gt;Repository for preprints, including the study on prompt tuning.&lt;SEP&gt;Repository hosting preprints of research on delta tuning and related methods.&lt;SEP&gt;arXiv is an online preprint repository hosting research papers on large language models, NLP, and AI.&lt;SEP&gt;arXiv is an online repository for preprints in computer science, hosting research papers on large language models, NLP, and AI.&lt;SEP&gt;arXiv is an open-access repository for preprints in computer science and AI, hosting research papers and technical reports.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-00db2a825cc87520492b47392ed31c71&lt;SEP&gt;chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hugging Face">
  <data key="d0">Hugging Face</data>
  <data key="d1">Organization</data>
  <data key="d2">Hugging Face is an AI and machine learning community platform hosting models, datasets, and leaderboards.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Q. Zhu">
  <data key="d0">Q. Zhu</data>
  <data key="d1">Authors</data>
  <data key="d2">Q. Zhu is a researcher involved in developing Deepseek-coder and advancing code intelligence models.&lt;SEP&gt;Q. Zhu is a researcher involved in developing code intelligence models and advancing large language models for programming.&lt;SEP&gt;Q. Zhu is a researcher involved in the development of Deepseek-coder and related models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="D. Guo">
  <data key="d0">D. Guo</data>
  <data key="d1">Authors</data>
  <data key="d2">D. Guo is a researcher contributing to code intelligence and large language models in programming.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="D. Yang">
  <data key="d0">D. Yang</data>
  <data key="d1">Authors</data>
  <data key="d2">D. Yang is a researcher contributing to code intelligence models and large language model research.&lt;SEP&gt;D. Yang is a researcher contributing to code intelligence models and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="P. Wang">
  <data key="d0">P. Wang</data>
  <data key="d1">Authors</data>
  <data key="d2">P. Wang is a researcher involved in code model development and large language model applications.&lt;SEP&gt;P. Wang is a researcher involved in code model development and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="R. Xu">
  <data key="d0">R. Xu</data>
  <data key="d1">Authors</data>
  <data key="d2">R. Xu is a researcher contributing to code intelligence models and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. Wu">
  <data key="d0">Y. Wu</data>
  <data key="d1">Authors</data>
  <data key="d2">Y. Wu is a researcher involved in research on code models and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. Li">
  <data key="d0">Y. Li</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates the capabilities of AlphaCode in competition-level code generation, assessing its performance in solving programming challenges.&lt;SEP&gt;Y. Li is a researcher contributing to code intelligence and large language model research.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="H. Gao">
  <data key="d0">H. Gao</data>
  <data key="d1">Authors</data>
  <data key="d2">H. Gao is a researcher involved in code intelligence and large language model development.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="S. Ma">
  <data key="d0">S. Ma</data>
  <data key="d1">Authors</data>
  <data key="d2">S. Ma is a researcher contributing to code intelligence models and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="W. Zeng">
  <data key="d0">W. Zeng</data>
  <data key="d1">Authors</data>
  <data key="d2">W. Zeng is a researcher involved in code model research and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="X. Bi">
  <data key="d0">X. Bi</data>
  <data key="d1">Authors</data>
  <data key="d2">X. Bi is a researcher contributing to code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Z. Gu">
  <data key="d0">Z. Gu</data>
  <data key="d1">Authors</data>
  <data key="d2">Z. Gu is a researcher involved in code model development and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="H. Xu">
  <data key="d0">H. Xu</data>
  <data key="d1">Authors</data>
  <data key="d2">H. Xu is a researcher contributing to code intelligence models and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="D. Dai">
  <data key="d0">D. Dai</data>
  <data key="d1">Authors</data>
  <data key="d2">D. Dai is a researcher involved in code modeling and large language model research.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="K. Dong">
  <data key="d0">K. Dong</data>
  <data key="d1">Authors</data>
  <data key="d2">K. Dong is a researcher contributing to code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="L. Zhang">
  <data key="d0">L. Zhang</data>
  <data key="d1">Authors</data>
  <data key="d2">L. Zhang is a researcher involved in code models and large language model development.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. Piao">
  <data key="d0">Y. Piao</data>
  <data key="d1">Authors</data>
  <data key="d2">Y. Piao is a researcher contributing to code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Z. Gou">
  <data key="d0">Z. Gou</data>
  <data key="d1">Authors</data>
  <data key="d2">Z. Gou is a researcher involved in code model research and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Z. Xie">
  <data key="d0">Z. Xie</data>
  <data key="d1">Authors</data>
  <data key="d2">Z. Xie is a researcher contributing to code intelligence models and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Z. Hao">
  <data key="d0">Z. Hao</data>
  <data key="d1">Authors</data>
  <data key="d2">Z. Hao is a researcher involved in code model development and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="B. Wang">
  <data key="d0">B. Wang</data>
  <data key="d1">Authors</data>
  <data key="d2">B. Wang is a researcher contributing to code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="J. Song">
  <data key="d0">J. Song</data>
  <data key="d1">Authors</data>
  <data key="d2">J. Song is a researcher involved in code model research and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="D. Chen">
  <data key="d0">D. Chen</data>
  <data key="d1">Authors</data>
  <data key="d2">D. Chen is a researcher contributing to code intelligence models and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="X. Xie">
  <data key="d0">X. Xie</data>
  <data key="d1">Authors</data>
  <data key="d2">X. Xie is a researcher involved in code model research and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="K. Guan">
  <data key="d0">K. Guan</data>
  <data key="d1">Authors</data>
  <data key="d2">K. Guan is a researcher contributing to code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. You">
  <data key="d0">Y. You</data>
  <data key="d1">Authors</data>
  <data key="d2">Y. You is a researcher involved in code model development and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A. Liu">
  <data key="d0">A. Liu</data>
  <data key="d1">Authors</data>
  <data key="d2">A. Liu is a researcher contributing to code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Q. Du">
  <data key="d0">Q. Du</data>
  <data key="d1">Authors</data>
  <data key="d2">Q. Du is a researcher involved in code model research and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="W. Gao">
  <data key="d0">W. Gao</data>
  <data key="d1">Authors</data>
  <data key="d2">W. Gao is a researcher contributing to code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="X. Lu">
  <data key="d0">X. Lu</data>
  <data key="d1">Authors</data>
  <data key="d2">X. Lu is a researcher involved in code models and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Q. Chen">
  <data key="d0">Q. Chen</data>
  <data key="d1">Authors</data>
  <data key="d2">Q. Chen is a researcher contributing to code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. Wang">
  <data key="d0">Y. Wang</data>
  <data key="d1">Authors</data>
  <data key="d2">Y. Wang is a researcher involved in code model development and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. Deng">
  <data key="d0">C. Deng</data>
  <data key="d1">Authors</data>
  <data key="d2">C. Deng is a researcher contributing to code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. Zhao">
  <data key="d0">C. Zhao</data>
  <data key="d1">Authors</data>
  <data key="d2">C. Zhao is a researcher contributing to code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. Ruan">
  <data key="d0">C. Ruan</data>
  <data key="d1">Authors</data>
  <data key="d2">C. Ruan is a researcher involved in code model research and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="F. Luo">
  <data key="d0">F. Luo</data>
  <data key="d1">Authors</data>
  <data key="d2">F. Luo is a researcher contributing to code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="W. Liang">
  <data key="d0">W. Liang</data>
  <data key="d1">Authors</data>
  <data key="d2">W. Liang is a researcher involved in code model development and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="DeepSeek-AI">
  <data key="d0">DeepSeek-AI</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">DeepSeek-AI is a platform or research project focused on code intelligence, large language models, and advancing code understanding.&lt;SEP&gt;DeepSeek-AI is a research initiative or platform focused on code intelligence and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Z. Shao">
  <data key="d0">Z. Shao</data>
  <data key="d1">Authors</data>
  <data key="d2">Z. Shao is a researcher involved in code model research and large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Training Techniques">
  <data key="d0">Training Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods such as knowledge distillation, sparsity exploitation, and instruct tuning used to optimize large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Open foundation models">
  <data key="d0">Open foundation models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Open foundation models refer to openly accessible large language models that serve as base architectures for various NLP and code tasks.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code intelligence">
  <data key="d0">Code intelligence</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ability of models to understand, generate, and reason about source code, essential for programming assistance and automated coding.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Optimization">
  <data key="d0">Model Optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques aimed at improving the efficiency, accuracy, and scalability of large language models, including sparsity exploitation and regularization.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Knowledge Transfer">
  <data key="d0">Knowledge Transfer</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Knowledge transfer involves transferring learned information from large models to smaller models to improve efficiency, accuracy, and domain adaptation.&lt;SEP&gt;Techniques like knowledge distillation used to transfer knowledge from large models to smaller or more efficient models.&lt;SEP&gt;The process of applying knowledge from one domain or context to another, facilitating the adaptation of LLMs for domain-specific tasks.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Benchmarks">
  <data key="d0">Model Benchmarks</data>
  <data key="d1">Tools</data>
  <data key="d2">Platforms like Hugging Face's leaderboard that evaluate and compare large language models on standard datasets.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Applications">
  <data key="d0">Model Applications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Uses of large language models in coding, AI assistance, natural language understanding, and automation.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Pytorch">
  <data key="d0">Pytorch</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">An imperative style, high-performance deep learning library developed by Chilamkurthy et al. in 2019, used for building and training neural networks.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Weight Decay Regularization">
  <data key="d0">Weight Decay Regularization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A regularization technique that penalizes large weights during training to prevent overfitting, with recent improvements fixing issues in Adam optimizer.&lt;SEP&gt;A regularization technique used in training neural networks to prevent overfitting by penalizing large weights.&lt;SEP&gt;A technique to prevent overfitting in machine learning models, specifically addressed and fixed in Adam optimizer by Loshchilov and Hutter in 2017.&lt;SEP&gt;Weight decay regularization is a technique used to prevent overfitting in neural networks by penalizing large weights, with recent fixes proposed for Adam optimizer.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb&lt;SEP&gt;chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Large Language Models Trained on Code">
  <data key="d0">Large Language Models Trained on Code</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">AI models like Codex trained on large datasets of source code to assist in programming tasks and code generation.&lt;SEP&gt;Large language models like Codex are trained on code datasets to generate or assist with programming tasks.&lt;SEP&gt;Models designed to understand and generate programming code, evaluated for performance and capabilities in 2021.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Phind-codellama-34b-v2">
  <data key="d0">Phind-codellama-34b-v2</data>
  <data key="d1">Tools</data>
  <data key="d2">A specific large language model for code, available on Hugging Face, developed for code understanding and generation, as of 2023.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Gemini">
  <data key="d0">Gemini</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A family of highly capable multimodal models introduced by G. Team in 2023, capable of processing multiple data types including text and images.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Language Models as Few-Shot Learners">
  <data key="d0">Language Models as Few-Shot Learners</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A concept introduced by Brown et al. in 2020, indicating that large language models can perform tasks with minimal examples.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Gpt-4">
  <data key="d0">Gpt-4</data>
  <data key="d1">Tools</data>
  <data key="d2">A large multimodal language model developed by OpenAI, detailed in the 2023 technical report, capable of advanced language understanding and generation.&lt;SEP&gt;Gpt-4 is a state-of-the-art language model developed by OpenAI, designed for advanced natural language understanding and generation.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Mpirigen">
  <data key="d0">Mpirigen</data>
  <data key="d1">Tools</data>
  <data key="d2">A tool for MPI code generation using domain-specific language models, described by Schneider et al. in 2024, aimed at automating high-performance computing code development.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Llm4vv">
  <data key="d0">Llm4vv</data>
  <data key="d1">Tools</data>
  <data key="d2">A test suite developed for compiler validation driven by large language models, as per Munley et al. in 2023.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Race Detection Using Large Language Models">
  <data key="d0">Data Race Detection Using Large Language Models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique employing large language models to identify data races in software concurrent execution environments, aiming to improve software reliability.&lt;SEP&gt;A technique employing large language models to identify data races in software concurrent execution environments.&lt;SEP&gt;Investigates whether large language models can effectively detect data races in parallel programming, studied by Chen et al. in 2023.&lt;SEP&gt;Research employing language models to identify data races in concurrent programming environments.&lt;SEP&gt;Research employing large language models to identify data races in concurrent programming environments.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb&lt;SEP&gt;chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Scope is All You Need">
  <data key="d0">Scope is All You Need</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A transformation approach for adapting large language models for high-performance computing code, proposed by Kadosh et al. in 2023.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Modeling Parallel Programs Using Large Language Models">
  <data key="d0">Modeling Parallel Programs Using Large Language Models</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A study by Nichols et al. in 2024 exploring how large language models can simulate and analyze parallel computing programs.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Performance-Aligned LLMs for Fast Code Generation">
  <data key="d0">Performance-Aligned LLMs for Fast Code Generation</data>
  <data key="d1">Methods</data>
  <data key="d2">Techniques to optimize large language models for generating efficient code, discussed by Nichols et al. in 2024.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Chathpc">
  <data key="d0">Chathpc</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A framework that empowers high-performance computing users with large language models, as described by Yin et al. in 2025.&lt;SEP&gt;A framework that empowers high-performance computing users with large language models, described by Yin et al. in 2025.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Lassi">
  <data key="d0">Lassi</data>
  <data key="d1">Tools</data>
  <data key="d2">An LLM-based automated pipeline for translating parallel scientific codes, introduced by Dearing et al. in 2024.&lt;SEP&gt;An automated pipeline based on large language models for translating scientific codes, introduced by Dearing et al. in 2024.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Ompgpt">
  <data key="d0">Ompgpt</data>
  <data key="d1">Tools</data>
  <data key="d2">A generative pre-trained transformer model designed for OpenMP parallel programming, presented by Chen et al. in 2024.&lt;SEP&gt;A specialized transformer model for OpenMP parallel programming, facilitating code generation and optimization, presented by Chen et al. in 2024.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Biocoder">
  <data key="d0">Biocoder</data>
  <data key="d1">Tools</data>
  <data key="d2">A benchmark for bioinformatics code generation with contextual models, proposed by Tang et al. in 2024.&lt;SEP&gt;Biocoder is a benchmark dataset used for evaluating bioinformatics code generation capabilities of large language models, emphasizing contextual pragmatic knowledge.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Verilogeval">
  <data key="d0">Verilogeval</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Verilogeval is an evaluation framework for assessing large language models' performance in generating Verilog code, a hardware description language.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Knowledge transfer from high-resource to low-resource programming languages">
  <data key="d0">Knowledge transfer from high-resource to low-resource programming languages</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">This concept involves transferring knowledge from programming languages with abundant resources and data to those with fewer resources, aiming to improve code generation and understanding in low-resource languages.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-I NSTRUCT dataset">
  <data key="d0">HPC-I NSTRUCT dataset</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The HPC-I NSTRUCT dataset is a collection of problem statements and solutions used for training and evaluating high-performance computing code generation models, facilitating reproducibility and benchmarking.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2 models">
  <data key="d0">HPC-Coder-V2 models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">HPC-Coder-V2 models are advanced large language models tailored for high-performance computing code generation, evaluated on correctness and performance metrics.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="StarCoder2-3B&quot;, &quot;StarCoder2-7B&quot;, &quot;StarCoder2-15B&quot;, &quot;StarCoderBase&quot;, &quot;CodeLlama-7B&quot;, &quot;CodeLlama-13B&quot;, &quot;CodeLlama-34B&quot;, &quot;Gemini-Pro&quot;, &quot;GPT-3.5&quot;, &quot;GPT-4">
  <data key="d0">StarCoder2-3B", "StarCoder2-7B", "StarCoder2-15B", "StarCoderBase", "CodeLlama-7B", "CodeLlama-13B", "CodeLlama-34B", "Gemini-Pro", "GPT-3.5", "GPT-4</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">These are various large language models of different sizes and architectures used to generate code, with performance metrics such as pass@1 to evaluate their effectiveness.&lt;SEP&gt;Various large language models evaluated for code generation performance across different benchmarks.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2-1.3B&quot;, &quot;HPC-Coder-V2-6.7B&quot;, &quot;HPC-Coder-V2-16B">
  <data key="d0">HPC-Coder-V2-1.3B", "HPC-Coder-V2-6.7B", "HPC-Coder-V2-16B</data>
  <data key="d1">Results</data>
  <data key="d2">Different sizes of HPC-Coder-V2 models evaluated for code generation accuracy and performance.&lt;SEP&gt;These HPC-Coder-V2 models are evaluated for their code generation accuracy, with pass@1 scores indicating their correctness in different problem and execution settings.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Problem statement">
  <data key="d0">Problem statement</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The problem statement describes a task to optimize a critical component in high-performance computing by parallelizing a sequential aggregation process, testing the hypothesis that parallelization reduces processing time.&lt;SEP&gt;The problem statement hypothesizes that parallelizing a sequential aggregation process using OpenMP will significantly improve performance in high-performance computing applications.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Parallelization using OpenMP">
  <data key="d0">Parallelization using OpenMP</data>
  <data key="d1">Methodologies</data>
  <data key="d2">OpenMP is a parallel programming framework for shared-memory architectures, used here to parallelize the aggregation of statistical metrics in a data array.&lt;SEP&gt;OpenMP is a parallel programming framework used to distribute workload across multiple CPU cores to optimize the aggregation of large datasets.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Luo, Y">
  <data key="d0">Luo, Y</data>
  <data key="d1">Researchers</data>
  <data key="d2">Luo, Y, along with X. Xiong and W. Liang, are authors of a publication discussing advancements in code intelligence and large language models in programming.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="X. Tang">
  <data key="d0">X. Tang</data>
  <data key="d1">Researchers</data>
  <data key="d2">X. Tang is an author contributing to the development of bioinformatics code generation benchmarks, emphasizing contextual pragmatic knowledge.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="B. Qian">
  <data key="d0">B. Qian</data>
  <data key="d1">Researchers</data>
  <data key="d2">B. Qian is a co-author involved in bioinformatics code generation research, focusing on benchmarking and evaluation.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="R. Gao">
  <data key="d0">R. Gao</data>
  <data key="d1">Researchers</data>
  <data key="d2">R. Gao is a researcher contributing to bioinformatics code generation evaluation frameworks.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="J. Chen">
  <data key="d0">J. Chen</data>
  <data key="d1">Researchers</data>
  <data key="d2">J. Chen is involved in bioinformatics code generation research, focusing on benchmark development.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="X. Chen">
  <data key="d0">X. Chen</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Participates in research assessing AI-driven code generation systems in competitive environments.&lt;SEP&gt;X. Chen is a co-author working on bioinformatics code generation benchmarks with contextual knowledge.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="M. Gerstein">
  <data key="d0">M. Gerstein</data>
  <data key="d1">Researchers</data>
  <data key="d2">M. Gerstein is a researcher contributing to bioinformatics code generation and benchmarking.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="M. Liu">
  <data key="d0">M. Liu</data>
  <data key="d1">Researchers</data>
  <data key="d2">M. Liu is an author evaluating large language models for Verilog code generation, focusing on hardware description language tasks.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="N. Pinckney">
  <data key="d0">N. Pinckney</data>
  <data key="d1">Researchers</data>
  <data key="d2">N. Pinckney is involved in evaluating large language models' performance in hardware description code generation.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="B. Khailany">
  <data key="d0">B. Khailany</data>
  <data key="d1">Researchers</data>
  <data key="d2">B. Khailany is a researcher assessing model capabilities in hardware description languages like Verilog.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="H. Ren">
  <data key="d0">H. Ren</data>
  <data key="d1">Researchers</data>
  <data key="d2">H. Ren is a researcher contributing to the evaluation of large language models for Verilog code generation.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="F. Cassano">
  <data key="d0">F. Cassano</data>
  <data key="d1">Researchers</data>
  <data key="d2">F. Cassano is an author researching knowledge transfer between high-resource and low-resource programming languages for code LLMs.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="J. Gouwar">
  <data key="d0">J. Gouwar</data>
  <data key="d1">Researchers</data>
  <data key="d2">J. Gouwar is a co-author involved in studies on knowledge transfer and code language models.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="F. Lucchetti">
  <data key="d0">F. Lucchetti</data>
  <data key="d1">Researchers</data>
  <data key="d2">F. Lucchetti is a researcher contributing to knowledge transfer research in programming languages.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. Schlesinger">
  <data key="d0">C. Schlesinger</data>
  <data key="d1">Researchers</data>
  <data key="d2">C. Schlesinger is involved in research on code transfer and language models.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A. Freeman">
  <data key="d0">A. Freeman</data>
  <data key="d1">Researchers</data>
  <data key="d2">A. Freeman is a contributor to studies on knowledge transfer in code LLMs.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. J. Anderson">
  <data key="d0">C. J. Anderson</data>
  <data key="d1">Researchers</data>
  <data key="d2">C. J. Anderson is involved in evaluating code transfer techniques and language models.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="M. Q. Feldman">
  <data key="d0">M. Q. Feldman</data>
  <data key="d1">Researchers</data>
  <data key="d2">M. Q. Feldman is a researcher participating in knowledge transfer and code evaluation studies.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="M. Greenberg">
  <data key="d0">M. Greenberg</data>
  <data key="d1">Researchers</data>
  <data key="d2">M. Greenberg is involved in research on code transfer and language models.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A. Jangda">
  <data key="d0">A. Jangda</data>
  <data key="d1">Researchers</data>
  <data key="d2">A. Jangda is a researcher working on code transfer and language model evaluation.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A. Guha">
  <data key="d0">A. Guha</data>
  <data key="d1">Researchers</data>
  <data key="d2">A. Guha is a researcher contributing to knowledge transfer and code generation evaluation.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="https://github.com/parallelcodefoundry/HPC-Coder">
  <data key="d0">https://github.com/parallelcodefoundry/HPC-Coder</data>
  <data key="d1">Tools</data>
  <data key="d2">Repository hosting scripts used for reproducibility of HPC code generation experiments.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="https://huggingface.co/datasets/hpcgroup/hpc-instruct">
  <data key="d0">https://huggingface.co/datasets/hpcgroup/hpc-instruct</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The HPC-INSTRUCT dataset contains problem statements and solutions for high-performance computing code generation tasks.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="https://huggingface.co/collections/hpcgroup/hpc-coder-v2-66b681a3a8a5a1978e163a5d">
  <data key="d0">https://huggingface.co/collections/hpcgroup/hpc-coder-v2-66b681a3a8a5a1978e163a5d</data>
  <data key="d1">Tools</data>
  <data key="d2">Model repository hosting the HPC-Coder-V2 models for code generation.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="heatmap">
  <data key="d0">heatmap</data>
  <data key="d1">Results</data>
  <data key="d2">A visualization in ParEval showing model performance and correctness across problem types and execution modes.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Table I">
  <data key="d0">Table I</data>
  <data key="d1">Results</data>
  <data key="d2">A summary table presenting pass@1 scores for various models and configurations.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="compute_metric">
  <data key="d0">compute_metric</data>
  <data key="d1">Methodology</data>
  <data key="d2">A function that performs a complex metric computation on individual data points, remaining unchanged during parallelization.&lt;SEP&gt;A function that performs a specific, complex calculation on individual data points, remains unchanged during parallelization.&lt;SEP&gt;The compute_metric function performs complex calculations on individual data points to generate metrics, forming the basis of the aggregation task.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="aggregate_metrics">
  <data key="d0">aggregate_metrics</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A function that sums metrics over a 2D dataset, which can be parallelized using OpenMP for efficiency.&lt;SEP&gt;The aggregate_metrics function computes the sum of metrics over a 2D dataset, which is to be optimized via parallelization.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="data">
  <data key="d0">data</data>
  <data key="d1">Variables</data>
  <data key="d2">A 2D array of data points used for metric computation.&lt;SEP&gt;A 2D array of size ROWS x COLS containing data points used for statistical metric calculation.&lt;SEP&gt;A two-dimensional array containing data points to be processed for metric calculation.&lt;SEP&gt;Data encompasses information such as source, destination, and amount, which are critical variables in the optimization context.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c&lt;SEP&gt;chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="ROWS&quot;, &quot;COLS">
  <data key="d0">ROWS", "COLS</data>
  <data key="d1">Variables</data>
  <data key="d2">Dimensions of the data array, representing the number of rows and columns in the dataset.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="sum">
  <data key="d0">sum</data>
  <data key="d1">Variables</data>
  <data key="d2">Accumulator variable that holds the total sum of computed metrics across the dataset.&lt;SEP&gt;Accumulator variable used to store the total sum of computed metrics during aggregation.&lt;SEP&gt;An accumulator variable that holds the total sum of metrics calculated across the dataset, updated during iteration.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="sequential code">
  <data key="d0">sequential code</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The original code performs aggregation sequentially, serving as the baseline for parallelization.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="parallel code">
  <data key="d0">parallel code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Parallel code is designed to run concurrently across multiple processors or cores, enabling high-performance computing.&lt;SEP&gt;Parallel code refers to code designed to run concurrently across multiple processing units, crucial for high-performance computing tasks.&lt;SEP&gt;The parallelized version employs OpenMP directives to distribute computation across multiple threads, aiming to reduce runtime.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="for-loop">
  <data key="d0">for-loop</data>
  <data key="d1">Methodology</data>
  <data key="d2">A control flow statement that iterates over a range of indices, used here to process data rows and columns for metric computation.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="rows">
  <data key="d0">rows</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of data entries or data points along the first dimension of the dataset.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="cols">
  <data key="d0">cols</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of data points along the second dimension of the dataset.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="OpenMP">
  <data key="d0">OpenMP</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A parallel programming API used to enable multi-threaded processing of loops, facilitating the parallelization of the aggregate_metrics function.&lt;SEP&gt;OpenMP is a parallel programming model used as an object of study to assess how well models generate code for parallel execution.&lt;SEP&gt;OpenMP is a widely used parallel programming API that simplifies parallelization of serial code through pragmas, making it more accessible for LLM translation.&lt;SEP&gt;OpenMP is a widely used parallel programming model that simplifies the addition of parallelism to serial code through pragmas, making it similar to serial code for LLM translation.&lt;SEP&gt;OpenMP is an API for parallel programming in shared memory systems, enabling translation of serial code into parallel code to improve performance.&lt;SEP&gt;OpenMP is an API that supports multi-platform shared memory multiprocessing programming in C, C++, and Fortran, enabling parallelization of serial code to improve performance.&lt;SEP&gt;A parallel programming model that supports multi-platform shared memory multiprocessing programming in C, C++, and Fortran.&lt;SEP&gt;A portable, scalable model that provides support for multi-platform shared memory multiprocessing programming in C, C++, and Fortran, enabling parallel execution of code segments.&lt;SEP&gt;OpenMP is a parallel programming model used to improve computational performance, particularly in scientific computing."|&gt;&lt;SEP&gt;OpenMP is a parallel programming model used to improve performance in scientific and high-performance computing applications."|&gt;&lt;SEP&gt;OpenMP is a widely used API for multi-platform shared-memory parallel programming in C, C++, and Fortran, with version 5.2 released in 2021.&lt;SEP&gt;OpenMP is a widely used API for shared-memory parallel programming, with version 5.2 released in 2021.&lt;SEP&gt;A parallel programming model that uses directives to simplify multi-threaded programming on shared-memory architectures.&lt;SEP&gt;OpenMP is a widely used parallel programming model for shared-memory architectures, providing directives for multi-threaded execution.&lt;SEP&gt;OpenMP is an API that supports multi-platform shared memory multiprocessing programming in C, C++, and Fortran, enabling parallelization of code through pragmas.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-0e2888ba86c90678f67636c1c02fe25c&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="parallel for">
  <data key="d0">parallel for</data>
  <data key="d1">Methodology</data>
  <data key="d2">An OpenMP directive that distributes loop iterations across multiple threads to improve processing speed.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="reduction">
  <data key="d0">reduction</data>
  <data key="d1">Methodology</data>
  <data key="d2">An OpenMP clause that safely combines partial results from multiple threads into a final result, used here for the sum variable.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Phind-V2-34B">
  <data key="d0">Phind-V2-34B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Phind-V2-34B is a large language model evaluated on the same benchmark, with pass@1 scores indicating its problem-solving performance across different problem types and parallel execution models.&lt;SEP&gt;Phind-V2-34B is a model evaluated on the same benchmark, with pass@1 scores indicating its problem-solving capabilities across different problem types and execution models.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Problem Types">
  <data key="d0">Problem Types</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">Different types of computational problems, such as serial, omp, kokkos, cuda, hip, mpi, and mpi+omp, used to evaluate the performance of various models.&lt;SEP&gt;Twelve different computational problem categories (e.g., Sort, Scan, Dense Linear Algebra, Sparse Linear Algebra, Search, Reduce, Histogram, Stencil, Graph, Geometry, Fourier Transform, Transform) used in ParEval to test various aspects of parallel code generation.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Execution Models">
  <data key="d0">Execution Models</data>
  <data key="d1">Variables</data>
  <data key="d2">Execution models specify the programming paradigms used for code generation, including serial, OpenMP, MPI, CUDA, HIP, etc.&lt;SEP&gt;Seven different programming models (e.g., sequential, parallel with OpenMP, CUDA, MPI, etc.) used to generate prompts for testing LLMs across diverse computational paradigms.&lt;SEP&gt;Various parallel computing execution frameworks like serial, omp, kokkos, cuda, hip, mpi, and mpi+omp, which influence model performance metrics.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-727ea750122a5bed30ad781918446611&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="smaller model">
  <data key="d0">smaller model</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d2">Knowledge distillation involves using a large model to generate data for training smaller models, aiming to preserve performance while reducing complexity.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Selecting a Pre-trained Model">
  <data key="d0">Selecting a Pre-trained Model</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d2">Choosing an appropriate pre-trained model influences the success of subsequent fine-tuning on HPC code tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Fine-tuning Data">
  <data key="d0">Fine-tuning Data</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d2">Magicoder is a fine-tuned version of DeepseekCoder-6.7B on synthetic data from open-source code, used to improve code modeling capabilities."|&lt;SEP&gt;Magicoder is fine-tuned on synthetic open-source code data to enhance code modeling capabilities."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Commercial Model">
  <data key="d0">Commercial Model</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d2">Gemini-1.5-flash is available via API from Google for code generation and related tasks."|&lt;SEP&gt;Gemini-1.5-flash provides API access for code generation from Google."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="State-of-the-art Models">
  <data key="d0">State-of-the-art Models</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d2">GPT-3.5 and GPT-4 are advanced models from OpenAI, used for high-level language understanding and generation."|&lt;SEP&gt;RAG models achieve new state-of-the-art performance across multiple open-domain QA tasks.</data>
  <data key="d1">Results</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Impact Analysis">
  <data key="d0">Impact Analysis</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d2">Ablation studies analyze how different training configurations affect model performance, including the impact of base model choice and instruction masking."|&lt;SEP&gt;Ablation studies analyze how different training configurations and data volumes affect model performance, especially in parallel code generation."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Training Data Impact">
  <data key="d0">Training Data Impact</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d2">Increasing MPI fine-tuning samples improves the performance of smaller models with diminishing returns for larger models."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Size and Performance">
  <data key="d0">Model Size and Performance</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d2">Smaller HPC-Coder-V2 models like 1.3B are faster and more memory-efficient while still outperforming similar-sized models, whereas larger models excel in certain areas but require more resources.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Performance on geometric problems">
  <data key="d0">Performance on geometric problems</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d2">Model performance decreases on geometric problems as size increases, indicating a challenge in this problem domain.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Fine-tuning strategies">
  <data key="d0">Fine-tuning strategies</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d2">Fine-tuning improves models' ability to generate correct and efficient parallel code, contributing to performance gains.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="High-Quality Data">
  <data key="d0">High-Quality Data</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d2">The quality of parallel code fine-tuning data significantly influences model performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Insights">
  <data key="d0">Insights</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d2">Fine-tuning choices such as data quality and instruction masking influence model performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Open foundation and fine-tuned chat models">
  <data key="d0">Open foundation and fine-tuned chat models</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d2">Llama 2 models are part of open foundation models, providing a basis for various applications including chat and code tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Exploiting sparsity in pruned neural networks">
  <data key="d0">Exploiting sparsity in pruned neural networks</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d2">Both techniques aim to optimize large language model training by reducing computational resources and increasing efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Large language models">
  <data key="d0">Large language models</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d2">The technique aims to improve the training stability and performance of large language models using Adam optimizer.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Deep Learning Library">
  <data key="d0">Deep Learning Library</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">Pytorch is a high-performance deep learning library used for developing neural network models, as described by Chilamkurthy et al. in 2019.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Loshchilov and Hutter">
  <data key="d0">Loshchilov and Hutter</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">They fixed issues related to weight decay regularization in Adam optimizer, enhancing model training stability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code Model">
  <data key="d0">Code Model</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">This tool is a specific large language model designed for code tasks, available publicly for use in 2023.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Multimodal Models">
  <data key="d0">Multimodal Models</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">Gemini models are capable of processing multiple data modalities, such as text and images, indicating their high versatility.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Learning Capability">
  <data key="d0">Learning Capability</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">This theory explains that large language models can perform new tasks effectively with minimal examples, demonstrating their few-shot learning ability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Advanced Language Model">
  <data key="d0">Advanced Language Model</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">Gpt-4 is a state-of-the-art large language model capable of complex understanding and generation tasks, as detailed in the 2023 report.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="MPI Code Generation Tool">
  <data key="d0">MPI Code Generation Tool</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">Mpirigen automates MPI code generation using domain-specific language models, streamlining parallel programming development.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Compiler Validation">
  <data key="d0">Compiler Validation</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">Llm4vv uses large language models to create test suites that validate compiler correctness and performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code Analysis">
  <data key="d0">Code Analysis</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">Using large language models to detect data races in parallel code aims to improve debugging and code reliability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Race Detection">
  <data key="d0">Data Race Detection</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">Techniques and models used to identify data races in parallel computing environments to ensure program correctness.&lt;SEP&gt;Techniques used to identify data races in parallel programs to ensure correctness and reliability.&lt;SEP&gt;Using large language models to detect data races in parallel code aims to improve debugging and code reliability.</data>
  <data key="d1">Applications/Implications</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Model Transformation">
  <data key="d0">Model Transformation</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">This approach transforms large language models to better handle high-performance computing code, enhancing their applicability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Modeling Parallel Programs">
  <data key="d0">Modeling Parallel Programs</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">Frameworks and approaches for representing and analyzing parallel programs in high-performance computing environments.&lt;SEP&gt;Frameworks and conceptual models used to represent, analyze, and understand the behavior and structure of parallel programs in HPC environments.&lt;SEP&gt;This study explores how large language models can simulate, analyze, and optimize parallel programs.</data>
  <data key="d1">Theories/Models</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Research Study">
  <data key="d0">Research Study</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">This study explores how large language models can simulate, analyze, and optimize parallel programs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code Generation">
  <data key="d0">Code Generation</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-96b489f22f60397ff887486ccf77f457&lt;SEP&gt;chunk-3487322ee335c5f4b3b40717a7de46d1&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb&lt;SEP&gt;chunk-10b08670a9cf75866c6b05fa5b5cfc12&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-bf1121c44634b616af61c49cd3adf29a&lt;SEP&gt;chunk-735818e62b066d03c2144cdb5db162c1&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc&lt;SEP&gt;chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d2">Code generation involves AI models producing source code based on prompts, with potential biases affecting the outputs.&lt;SEP&gt;Code generation involves automatically producing programming code from natural language prompts or problem descriptions, central to the evaluation of models like Codex.&lt;SEP&gt;Code generation refers to AI models producing programming code, raising questions about originality, copyright, and safety risks.&lt;SEP&gt;Code generation refers to AI models producing programming code, raising questions about originality, copyright, and safety.&lt;SEP&gt;Code generation refers to using models like Codex to automatically produce source code, potentially increasing productivity and enabling new software development capabilities.&lt;SEP&gt;Techniques for aligning large language models with performance goals to generate faster, more efficient code.&lt;SEP&gt;The activity of automatically producing source code from specifications or natural language prompts.&lt;SEP&gt;The research investigates the ability of large language models (LLMs) to generate parallel code based on structured prompts.&lt;SEP&gt;The final stage generates optimized C++ code from the AMT, incorporating inlining and loop unrolling for performance enhancement.&lt;SEP&gt;The process of producing code that can react to different levels of uncertainty and dynamic workloads, possibly using frameworks like Legion or StarPU.&lt;SEP&gt;The process by which Codex produces code snippets, which can be used benignly or maliciously, depending on intent.&lt;SEP&gt;The process of automatically producing computer code, which can reflect societal stereotypes and biases.&lt;SEP&gt;The task of automatically generating computer code, used here to evaluate the models' ability to produce valid and correct code snippets.&lt;SEP&gt;The task of automatically producing computer code, used here to evaluate the models' capabilities in generating correct and functional HPC code.&lt;SEP&gt;Using the trained HPC-specific language model to automatically generate source code, assist in programming, or automate coding tasks in HPC environments.</data>
  <data key="d1">Methodology</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Performance-Aligned LLMs">
  <data key="d0">Performance-Aligned LLMs</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">Techniques for aligning large language models with performance goals to generate faster, more efficient code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Framework">
  <data key="d0">Framework</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d2">A structured process comprising stages like Definition, Augmentation, Optimization, and Evaluation to guide domain-specific adaptation of LLMs.&lt;SEP&gt;A structured process consisting of Definition, Augmentation, Optimization, and Evaluation stages guiding domain specialization of LLMs.&lt;SEP&gt;Chathpc is an AI framework that leverages large language models to assist HPC users, enhancing productivity and code understanding.&lt;SEP&gt;The structured approach or architecture that guides the development and application of domain-specific LLMs, including classification schemas and methodological guidelines.</data>
  <data key="d1">Core Concepts</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="ParEval benchmark">
  <data key="d0">ParEval benchmark</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d2">GPT-4 is evaluated on the ParEval benchmark, with pass@1 scores indicating its effectiveness in solving problems across different parallel execution models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Pre-trained language models">
  <data key="d0">Pre-trained language models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Pre-trained language models are models trained on large datasets to learn language representations and knowledge, capable of performing various NLP tasks with fine-tuning.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Factual Knowledge">
  <data key="d0">Factual Knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Factual knowledge encompasses verified, real-world information that models utilize to generate truthful responses and avoid hallucinations.&lt;SEP&gt;Factual knowledge refers to accurate, real-world information used by models to generate truthful responses, reducing hallucination.&lt;SEP&gt;Factual knowledge refers to verified information stored within models or accessible via external memory, essential for knowledge-intensive NLP tasks.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Explicit non-parametric memory">
  <data key="d0">Explicit non-parametric memory</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Explicit non-parametric memory is an external, accessible storage of information (e.g., Wikipedia index) that models can retrieve to enhance factual accuracy.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Neural retriever">
  <data key="d0">Neural retriever</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural retriever is a pre-trained neural network component used to access relevant passages from a dense vector index, facilitating retrieval in RAG models.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Seq2Seq model">
  <data key="d0">Seq2Seq model</data>
  <data key="d1">Tools</data>
  <data key="d2">A sequence-to-sequence (seq2seq) model is a pre-trained architecture used for language generation tasks, serving as the parametric memory in RAG.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge-intensive NLP tasks">
  <data key="d0">Knowledge-intensive NLP tasks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Tasks that require models to access, manipulate, and generate based on factual knowledge, such as open-domain QA.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open domain QA">
  <data key="d0">Open domain QA</data>
  <data key="d1">Results</data>
  <data key="d2">A type of knowledge-intensive NLP task where RAG models outperform traditional parametric models and retrieve-and-extract architectures, setting state-of-the-art performance.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="State-of-the-art results">
  <data key="d0">State-of-the-art results</data>
  <data key="d1">Results</data>
  <data key="d2">The highest performance achieved by models on specific tasks, here referring to improved accuracy in knowledge-intensive NLP tasks by RAG models.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model fine-tuning">
  <data key="d0">Model fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Process of adapting LLMs with domain-specific datasets to improve accuracy and relevance in finance and law.&lt;SEP&gt;The process of adjusting model parameters on specific datasets to optimize performance for particular tasks, as applied to RAG models.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb&lt;SEP&gt;chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge manipulation">
  <data key="d0">Knowledge manipulation</data>
  <data key="d1">Limitations</data>
  <data key="d2">Refers to the challenge of accessing, updating, and providing provenance for the knowledge stored within models.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Provenance">
  <data key="d0">Provenance</data>
  <data key="d1">Limitations</data>
  <data key="d2">Provenance involves tracking the origin and reasoning behind model decisions, which remains an open research problem in RAG.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge access">
  <data key="d0">Knowledge access</data>
  <data key="d1">Variables</data>
  <data key="d2">Knowledge access refers to the ability of models to retrieve and utilize external information, critical for improving model performance on knowledge-intensive tasks.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model performance">
  <data key="d0">Model performance</data>
  <data key="d1">Results</data>
  <data key="d2">The effectiveness of RAG models demonstrated through superior results on multiple NLP tasks, indicating improved knowledge utilization.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wikipedia index">
  <data key="d0">Wikipedia index</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dense vector index of Wikipedia used as external non-parametric memory in RAG models.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval-augmented generation (RAG)">
  <data key="d0">Retrieval-augmented generation (RAG)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model architecture that combines parametric and non-parametric memory components for improved language generation.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Provenance tracking">
  <data key="d0">Provenance tracking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods for tracking the origin and reasoning behind model outputs, an open research area for transparency.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge updating">
  <data key="d0">Knowledge updating</data>
  <data key="d1">Limitations</data>
  <data key="d2">The challenge of revising or updating the stored knowledge in models to reflect new information.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Sequence-to-Sequence Models">
  <data key="d0">Sequence-to-Sequence Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Sequence-to-sequence (seq2seq) models are a class of neural network architectures used for tasks involving input-to-output sequence transformation, such as translation, summarization, and question answering.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval-Augmented Generation (RAG)">
  <data key="d0">Retrieval-Augmented Generation (RAG)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A framework that integrates retrieval mechanisms with generative models, allowing models to access external knowledge during answer generation.&lt;SEP&gt;A general-purpose fine-tuning approach that combines parametric memory (pre-trained seq2seq transformer) with non-parametric memory (dense vector index accessed via neural retriever) to enhance knowledge-intensive tasks.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Parametric Memory">
  <data key="d0">Parametric Memory</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Parametric memory refers to the internal knowledge stored within pre-trained models like transformers, which can generate responses based on learned parameters.&lt;SEP&gt;Refers to knowledge stored within the model parameters, enabling the model to complete titles and facts without external documents.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Non-parametric Memory">
  <data key="d0">Non-parametric Memory</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Non-parametric memory involves external knowledge sources, such as dense vector indices of Wikipedia, accessed via retrievers, providing additional context for generation.&lt;SEP&gt;Non-parametric memory refers to a type of memory in models that does not assume a fixed parametric form, allowing dynamic updates and retrievals.&lt;SEP&gt;Refers to external retrieval components that supply specific knowledge to guide generation.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb&lt;SEP&gt;chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Dense Passage Retriever (DPR)">
  <data key="d0">Dense Passage Retriever (DPR)</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural retriever model that provides latent documents conditioned on input queries, enabling retrieval of relevant external knowledge for RAG models.&lt;SEP&gt;A neural retriever that fetches relevant text passages from large corpora conditioned on input queries, enabling external knowledge access in RAG.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="BART">
  <data key="d0">BART</data>
  <data key="d1">Tools</data>
  <data key="d2">A pre-trained sequence-to-sequence transformer used as the generator component in RAG models, capable of producing contextually relevant outputs.&lt;SEP&gt;A pre-trained sequence-to-sequence transformer used as the generator component in RAG models, conditioning on retrieved documents and input to generate outputs.&lt;SEP&gt;A transformer-based language model used for text generation, serving as a comparison point for RAG models.&lt;SEP&gt;BART (Bidirectional and Auto-Regressive Transformers) is a sequence-to-sequence model used for text generation, known for generating fluent and coherent text.&lt;SEP&gt;BART is a transformer-based model used for text generation, compared with RAG models.&lt;SEP&gt;BART is a denoising sequence-to-sequence pre-training method used to improve performance in NLP tasks such as language generation, translation, and comprehension.&lt;SEP&gt;BART is a transformer-based language model architecture used as the basis for DeepDevPERF.&lt;SEP&gt;BART is a transformer-based language model architecture used as the foundation for DeepDevPERF.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0&lt;SEP&gt;chunk-cfcd5a8798f30da73fdaa3033d579b42&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb&lt;SEP&gt;chunk-02a741669060d492fb68529287d315dd&lt;SEP&gt;chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Top-K Approximation">
  <data key="d0">Top-K Approximation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique that considers only the top K retrieved documents to approximate the distribution over possible source documents, improving computational efficiency.&lt;SEP&gt;A technique to marginalize over a subset (top-K) of retrieved documents, used to approximate the distribution over latent documents in RAG models.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge-Intensive Tasks">
  <data key="d0">Knowledge-Intensive Tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Experiments conducted to evaluate RAG across various knowledge-intensive natural language processing tasks, using Wikipedia as the knowledge source.&lt;SEP&gt;Tasks requiring external knowledge sources for accurate responses, such as open-domain QA, fact verification, and question generation.&lt;SEP&gt;Tasks that require external knowledge sources for accurate performance, such as open question answering, fact verification, and generation of factual responses.&lt;SEP&gt;Tasks that require external knowledge sources, such as Wikipedia, to perform effectively, including question answering and fact verification.&lt;SEP&gt;NLP tasks that require access to external knowledge, often enhanced with retrieval mechanisms.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb&lt;SEP&gt;chunk-20aafa58f3d7697ab6ba5015b31cda9b&lt;SEP&gt;chunk-99d4d675d4565ed5a3ce6fb12d24e2ee&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="State-of-the-Art Results">
  <data key="d0">State-of-the-Art Results</data>
  <data key="d1">Results</data>
  <data key="d2">RAG models achieve leading performance on datasets like Natural Questions, WebQuestions, CuratedTrec, and outperform approaches on TriviaQA, FEVER, and other knowledge-intensive benchmarks.&lt;SEP&gt;The highest levels of performance achieved on benchmark datasets, indicating the effectiveness of models like RAG in knowledge-intensive tasks.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Unconstrained Generation">
  <data key="d0">Unconstrained Generation</data>
  <data key="d1">Results</data>
  <data key="d2">Generation methods that do not restrict responses to extractive outputs, producing more factual, specific, and diverse responses compared to baseline models like BART.&lt;SEP&gt;Generation of responses without strict extraction constraints, leading to more factual, specific, and diverse answers.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="FEVER">
  <data key="d0">FEVER</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A benchmark dataset and evaluation framework for fact verification, involving claim classification and evidence retrieval.&lt;SEP&gt;A dataset and benchmark for fact verification tasks, involving classification of claims based on evidence.&lt;SEP&gt;A dataset for fact verification, containing claims and evidence, used to assess models' ability to verify facts using external knowledge.&lt;SEP&gt;A fact verification dataset used to evaluate models' ability to verify claims against external knowledge sources, with RAG models achieving results within 4.3% of the best pipeline models.&lt;SEP&gt;FEVER is a dataset and benchmark for fact verification, involving document retrieval and claim classification.&lt;SEP&gt;FEVER is a dataset and task designed for fact verification, requiring classification of claims supported, refuted, or unverifiable based on evidence from Wikipedia.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb&lt;SEP&gt;chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge Updating">
  <data key="d0">Knowledge Updating</data>
  <data key="d1">Variables</data>
  <data key="d2">The ability to hot-swap retrieval indices allows models to update knowledge dynamically without retraining, enabling more adaptable systems.&lt;SEP&gt;The non-parametric memory in RAG models can be replaced or updated to reflect changing world knowledge, enabling models to stay current without retraining from scratch.&lt;SEP&gt;The process of replacing or modifying the non-parametric memory component to reflect new or changing world knowledge, enabling models to stay current.&lt;SEP&gt;Updating knowledge in LLMs involves strategies to incorporate new information post-training, which is computationally expensive and complex due to the models' size and architecture.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-bb9f9f9e90a0c162892181da55ffb7b4&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open-Domain Extractive Question Answering">
  <data key="d0">Open-Domain Extractive Question Answering</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A type of question answering system that retrieves relevant information from a large corpus to answer questions, focusing on extracting relevant text segments.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Hybrid Parametric and Non-Parametric Memory">
  <data key="d0">Hybrid Parametric and Non-Parametric Memory</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A combined memory approach that leverages both internal (parametric) knowledge within models and external (non-parametric) knowledge sources for enhanced performance.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Sequence-to-Sequence (Seq2Seq) Models">
  <data key="d0">Sequence-to-Sequence (Seq2Seq) Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Neural network architectures that convert input sequences into output sequences, fundamental to many NLP tasks including question answering.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Pre-trained Models">
  <data key="d0">Pre-trained Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Models trained on large datasets prior to task-specific fine-tuning, providing a foundation of extensive knowledge.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Probabilistic Model">
  <data key="d0">Probabilistic Model</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A model that incorporates randomness and probability distributions to handle uncertainty, used in RAG to marginalize over retrieved documents.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Latent Documents">
  <data key="d0">Latent Documents</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Unobserved or hidden documents retrieved during the model's process, which influence the generated output.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open Natural Questions">
  <data key="d0">Open Natural Questions</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset comprising real user questions and answers used to evaluate open-domain QA systems, including RAG.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="WebQuestions">
  <data key="d0">WebQuestions</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset of questions and answers from the web, used for benchmarking question answering models.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="CuratedTrec">
  <data key="d0">CuratedTrec</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset derived from TREC QA tracks, used for evaluating retrieval and question answering systems.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="TriviaQA">
  <data key="d0">TriviaQA</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset of trivia questions with associated evidence, used to test knowledge retrieval and generation capabilities.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="MS-MARCO">
  <data key="d0">MS-MARCO</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A large-scale dataset for machine reading comprehension and question answering based on real-world web data.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jeopardy Question Generation">
  <data key="d0">Jeopardy Question Generation</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A dataset comprising questions inspired by the Jeopardy game show, used for evaluating question generation models.&lt;SEP&gt;A task of generating fact-based questions in the style of Jeopardy, conditioned on answer entities, to evaluate knowledge-intensive question generation capabilities.&lt;SEP&gt;A task of generating factual questions in the style of Jeopardy, conditioned on answer entities, to assess knowledge-intensive question generation abilities.&lt;SEP&gt;The study includes generating questions in the style of Jeopardy to evaluate RAG models.&lt;SEP&gt;The task of generating questions for the game show Jeopardy, used here as a benchmark for evaluating generative models.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-99d4d675d4565ed5a3ce6fb12d24e2ee&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb&lt;SEP&gt;chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG-Token Model">
  <data key="d0">RAG-Token Model</data>
  <data key="d1">Methodology</data>
  <data key="d2">A retrieval-augmented generation approach that allows the generator to select content from multiple documents for each token, enabling flexible and contextually relevant answer generation.&lt;SEP&gt;The RAG-Token model is a retrieval-augmented generative model that retrieves multiple documents for each target token and marginalizes over them during answer generation, allowing for flexible content selection from several documents.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retriever">
  <data key="d0">Retriever</data>
  <data key="d1">Tools</data>
  <data key="d2">The retriever component, based on DPR, uses a bi-encoder architecture with BERT to produce dense document representations and retrieve relevant documents via Maximum Inner Product Search (MIPS).</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generator">
  <data key="d0">Generator</data>
  <data key="d1">Tools</data>
  <data key="d2">The generator component, modeled using BART-large, is a pre-trained sequence-to-sequence transformer that combines input and retrieved content to generate output sequences.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="DPR (Dense Passage Retrieval)">
  <data key="d0">DPR (Dense Passage Retrieval)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A bi-encoder architecture that encodes documents and queries into dense vectors for efficient retrieval based on similarity, trained on datasets like TriviaQA and Natural Questions.&lt;SEP&gt;A bi-encoder architecture that encodes documents and queries into dense vectors using BERT, facilitating efficient retrieval via Maximum Inner Product Search (MIPS), trained on datasets like TriviaQA and Natural Questions.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="BART-large">
  <data key="d0">BART-large</data>
  <data key="d1">Tools</data>
  <data key="d2">A pre-trained large transformer model for text generation, used as the generator component in RAG for diverse generation tasks.&lt;SEP&gt;A pre-trained seq2seq transformer with 400 million parameters, used as the generator in the RAG model for text generation tasks.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Sequence Classification Tasks">
  <data key="d0">Sequence Classification Tasks</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The RAG model can be adapted for sequence classification by considering the target class as a sequence of length one, making RAG-Sequence and RAG-Token equivalent for such tasks.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Training">
  <data key="d0">Training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process involves jointly training the retriever and generator components using stochastic gradient descent to minimize the negative marginal log-likelihood of target outputs, with fixed document encoder and fine-tuned query encoder and generator.&lt;SEP&gt;Training involves optimizing large AI models like Codex-12B on datasets, including internet sources such as GitHub, to enable code generation capabilities.&lt;SEP&gt;Training involves using large-scale compute resources to optimize AI models like Codex-12B on datasets, including internet data such as GitHub repositories.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b&lt;SEP&gt;chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Decoding">
  <data key="d0">Decoding</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Two decoding strategies are described: RAG-Token, which uses autoregressive beam search for each document, and RAG-Sequence, which runs beam search for each document and performs marginalization via additional forward passes, including approximations for efficiency.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wikipedia Dump">
  <data key="d0">Wikipedia Dump</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A large-scale knowledge source used as the non-parametric memory for retrieval in the RAG experiments.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="z2top-k(p(·|x))p⌘(z|x)NY">
  <data key="d0">z2top-k(p(·|x))p⌘(z|x)NY</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Mathematical expressions and probabilistic models defining the retrieval-augmented generation process, including top-k document selection, marginalization, and sequence modeling.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="ip✓(yi|x, z, y 1:i1)">
  <data key="d0">ip✓(yi|x, z, y 1:i1)</data>
  <data key="d1">Variables</data>
  <data key="d2">A variable representing the probability of the ith output token conditioned on input x, retrieved documents z, and previous output tokens y 1:i-1, used in sequence modeling.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="retriever">
  <data key="d0">retriever</data>
  <data key="d1">Tools</data>
  <data key="d2">Component based on DPR that retrieves relevant documents by encoding documents and queries into dense vectors and performing similarity search.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="generator">
  <data key="d0">generator</data>
  <data key="d1">Tools</data>
  <data key="d2">The BART-large sequence-to-sequence transformer used to generate output sequences conditioned on input and retrieved documents, pre-trained with denoising objectives.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="sequence classiﬁcation tasks">
  <data key="d0">sequence classiﬁcation tasks</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The RAG model can be adapted to sequence classification by treating the target class as a sequence of length one, making RAG-Sequence and RAG-Token models equivalent for classification purposes.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="training">
  <data key="d0">training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Joint training of retriever and generator components using stochastic gradient descent to minimize negative marginal log-likelihood, with fixed document encoder and fine-tuned query encoder and generator.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="decoding">
  <data key="d0">decoding</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Strategies for generating output include RAG-Token's autoregressive beam search for each document and RAG-Sequence's document-wise beam search with marginalization, employing approximations like 'Thorough' and 'Fast' decoding for efficiency.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="knowledge-intensive tasks">
  <data key="d0">knowledge-intensive tasks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Experiments conducted across various NLP tasks utilizing Wikipedia as the knowledge source to evaluate RAG's performance.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wikipedia dump">
  <data key="d0">Wikipedia dump</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A large-scale dump of Wikipedia used as the external knowledge base for retrieval in RAG experiments.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="target token">
  <data key="d0">target token</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The individual output units in sequence generation, which are conditioned on input, retrieved documents, and previous tokens in RAG models.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="top-k documents">
  <data key="d0">top-k documents</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The set of the top k retrieved documents used by the model to generate each token, critical for the retrieval process.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="marginalization">
  <data key="d0">marginalization</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">A statistical method used in RAG to combine probabilities over multiple documents to produce a final output distribution.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="sequence modeling">
  <data key="d0">sequence modeling</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of generating sequences of tokens based on input, retrieved documents, and previous tokens, central to RAG's architecture.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="state-of-the-art results">
  <data key="d0">state-of-the-art results</data>
  <data key="d1">Results</data>
  <data key="d2">Performance metrics indicating the high effectiveness of BART and RAG models on diverse generation tasks.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="denoising objective">
  <data key="d0">denoising objective</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Pre-training objective used for BART, involving corrupting input sequences and training the model to reconstruct original data.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Maximum Inner Product Search (MIPS)">
  <data key="d0">Maximum Inner Product Search (MIPS)</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">A method for efficiently retrieving top-k documents based on maximum inner product similarity between query and document vectors.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="document encoder">
  <data key="d0">document encoder</data>
  <data key="d1">Tools</data>
  <data key="d2">A BERT-based encoder that produces dense representations of documents for retrieval.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="query encoder">
  <data key="d0">query encoder</data>
  <data key="d1">Tools</data>
  <data key="d2">A BERT-based encoder that produces dense representations of queries for document retrieval.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="document index">
  <data key="d0">document index</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An index built from encoded documents used for fast retrieval during inference.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Thorough decoding">
  <data key="d0">Thorough decoding</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A decoding approach that runs beam search for each document and marginalizes over hypotheses, providing more accurate but computationally intensive outputs.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Fast decoding">
  <data key="d0">Fast decoding</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An approximation method that reduces computation by ignoring hypotheses not generated during initial beam search, trading some accuracy for efficiency.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="training corpus">
  <data key="d0">training corpus</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The dataset of input/output pairs used to train the RAG model in a supervised manner.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="negative marginal log-likelihood">
  <data key="d0">negative marginal log-likelihood</data>
  <data key="d1">Results</data>
  <data key="d2">The loss function minimized during training to improve the model's output probabilities.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Fast Decoding">
  <data key="d0">Fast Decoding</data>
  <data key="d1">Methodology</data>
  <data key="d2">A decoding procedure designed to avoid additional forward passes during generation by utilizing information from prior steps, thus improving efficiency in knowledge-intensive tasks.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG">
  <data key="d0">RAG</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Retrieval-Augmented Generation (RAG) is a framework that combines retrieval of documents with generative models to improve performance on knowledge-intensive NLP tasks.&lt;SEP&gt;Retrieval-Augmented Generation (RAG) is a model combining document retrieval with text generation to improve factuality and specificity.&lt;SEP&gt;Retrieval-Augmented Generation (RAG) models combine retrieval of evidence with generative capabilities for question answering.&lt;SEP&gt;Retrieval-Augmented Generation is a framework combining document retrieval with text generation to improve factual accuracy.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-99d4d675d4565ed5a3ce6fb12d24e2ee&lt;SEP&gt;chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge-intensive tasks">
  <data key="d0">Knowledge-intensive tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Tasks that require access to external knowledge sources, such as Wikipedia, to generate accurate responses or perform reasoning.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wikipedia dump (December 2018)">
  <data key="d0">Wikipedia dump (December 2018)</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A large-scale dataset comprising 21 million documents split into 100-word chunks, used as the non-parametric knowledge source for experiments.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document encoder">
  <data key="d0">Document encoder</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural component that computes embeddings for each Wikipedia document, enabling efficient retrieval via similarity search.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="MIPS index with FAISS">
  <data key="d0">MIPS index with FAISS</data>
  <data key="d1">Tools</data>
  <data key="d2">A high-performance similarity search index built using FAISS, employing Hierarchical Navigable Small World graphs for fast retrieval of relevant documents.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open-domain Question Answering (QA)">
  <data key="d0">Open-domain Question Answering (QA)</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Can RAG improve the accuracy of question answering by leveraging retrieval from large knowledge sources compared to extractive or parametric approaches?&lt;SEP&gt;Can retrieval-augmented models like RAG outperform extractive and parametric models in knowledge-intensive question answering tasks?</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Exact Match (EM) scores">
  <data key="d0">Exact Match (EM) scores</data>
  <data key="d1">Results</data>
  <data key="d2">Performance metric used to evaluate the accuracy of answers in open-domain QA datasets, indicating how closely generated answers match ground truth.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Abstractive Question Answering">
  <data key="d0">Abstractive Question Answering</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A form of QA where models generate free-form answers, testing RAG's capacity for natural language generation beyond span extraction.&lt;SEP&gt;A form of question answering where the model generates free-form, natural language answers rather than extracting spans from documents, testing RAG's generative capabilities.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="MSMARCO NLG task v2.1">
  <data key="d0">MSMARCO NLG task v2.1</data>
  <data key="d1">Study Design</data>
  <data key="d2">A benchmark for evaluating natural language generation in a knowledge-intensive setting, involving questions, retrieved passages, and annotated full-sentence answers.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="SearchQA dataset">
  <data key="d0">SearchQA dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset containing examples for training and evaluating question generation models, with splits for train, dev, and test sets.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Q-BLEU-1">
  <data key="d0">Q-BLEU-1</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">A variant of BLEU score emphasizing entity matching, used to evaluate the factuality and quality of generated questions in question generation tasks.&lt;SEP&gt;An evaluation metric emphasizing entity matching in generated questions, correlating with human judgment of factuality and quality.&lt;SEP&gt;Q-BLEU-1 is a metric used to evaluate the quality of generated questions by measuring n-gram overlap with reference questions.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Human evaluation">
  <data key="d0">Human evaluation</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">A qualitative assessment involving human judges comparing generated questions for factuality and specificity to determine the better output.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Fact Veriﬁcation (FEVER)">
  <data key="d0">Fact Veriﬁcation (FEVER)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A task that involves retrieving evidence from Wikipedia and reasoning to classify claims as supported, refuted, or unverifiable, testing retrieval and reasoning capabilities.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Y">
  <data key="d0">Y</data>
  <data key="d1">Variables</data>
  <data key="d2">Y is a variable involved in the decoding process, specifically related to whether y was generated during beam search, impacting the decoding efficiency.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Decoding Procedure">
  <data key="d0">Decoding Procedure</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A specific decoding approach called 'Fast Decoding' designed to improve efficiency by avoiding additional forward passes after candidate set generation.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wikipedia Dump (December 2018)">
  <data key="d0">Wikipedia Dump (December 2018)</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A large dataset consisting of 21 million documents split into 100-word chunks, used as the non-parametric knowledge source for experiments.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document Encoder">
  <data key="d0">Document Encoder</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural component that encodes Wikipedia documents into embeddings for retrieval purposes.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="FAISS Hierarchical Navigable Small World (HNSW) Index">
  <data key="d0">FAISS Hierarchical Navigable Small World (HNSW) Index</data>
  <data key="d1">Tools</data>
  <data key="d2">A fast approximate nearest neighbor search index used with FAISS to retrieve relevant documents efficiently during experiments.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Exact Match (EM) Score">
  <data key="d0">Exact Match (EM) Score</data>
  <data key="d1">Results</data>
  <data key="d2">A metric used to evaluate the accuracy of generated answers by measuring the percentage of answers that exactly match the ground truth.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="MSMARCO NLG Task v2.1">
  <data key="d0">MSMARCO NLG Task v2.1</data>
  <data key="d1">Study Design</data>
  <data key="d2">A benchmark dataset for evaluating natural language generation in a knowledge-intensive setting, involving questions, retrieved passages, and full-sentence answers.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="SearchQA Dataset">
  <data key="d0">SearchQA Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset containing examples for training and evaluating question generation models, with splits for train, dev, and test sets.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Human Evaluation">
  <data key="d0">Human Evaluation</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">A qualitative assessment involving human evaluators comparing the factuality and specificity of generated texts from different models.&lt;SEP&gt;A qualitative assessment where human judges compare generated questions for factuality and specificity to determine which is better.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Fact Verification (FEVER)">
  <data key="d0">Fact Verification (FEVER)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A task involving retrieving evidence from Wikipedia and reasoning to classify claims as supported, refuted, or unverifiable.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Reasoning">
  <data key="d0">Reasoning</data>
  <data key="d1">Tools</data>
  <data key="d2">The cognitive process of analyzing retrieved evidence to support classification decisions in FEVER.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Natural Language Claim">
  <data key="d0">Natural Language Claim</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A natural language claim is a statement that needs to be verified for support or refutation using evidence.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wikipedia">
  <data key="d0">Wikipedia</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Wikipedia is a comprehensive online encyclopedia used as a source for factual information.&lt;SEP&gt;Wikipedia is a large, open-source online encyclopedia used as a factual knowledge base for training and grounding NLP models like RAG.&lt;SEP&gt;Wikipedia serves as a primary external knowledge source for grounding information in RAG models, providing a vast repository of factual content.&lt;SEP&gt;Wikipedia serves as the evidence source for classifying claims in the FEVER task.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Evidence">
  <data key="d0">Evidence</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data, models, evaluation results, and datasets used to support research findings in NLP.&lt;SEP&gt;Evidence in this context includes datasets, models, and evaluation metrics used to support NLP research findings.&lt;SEP&gt;Evidence refers to the information retrieved from Wikipedia used to support or refute claims in FEVER.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval Problem">
  <data key="d0">Retrieval Problem</data>
  <data key="d1">Methodologies</data>
  <data key="d2">FEVER involves retrieving relevant evidence from Wikipedia to support claim verification.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Entailment Reasoning">
  <data key="d0">Entailment Reasoning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">FEVER includes reasoning over retrieved evidence to classify claims as supported, refuted, or unverifiable.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Class Labels">
  <data key="d0">Class Labels</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The task explores whether claims are supported, refuted, or lack enough information, corresponding to specific class labels.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Label Accuracy">
  <data key="d0">Label Accuracy</data>
  <data key="d1">Results</data>
  <data key="d2">The performance metric used in FEVER to evaluate how accurately the model classifies claims.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open-domain Question Answering">
  <data key="d0">Open-domain Question Answering</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study investigates the effectiveness of RAG models in open-domain question answering tasks.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="DPR">
  <data key="d0">DPR</data>
  <data key="d1">Tools</data>
  <data key="d2">Dense Passage Retriever (DPR) is used to initialize the retriever component of RAG, providing retrieval supervision.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generation and Classification Scores">
  <data key="d0">Generation and Classification Scores</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics such as Bleu and Rouge-L are used to evaluate the quality of generated answers and classification accuracy.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG models">
  <data key="d0">RAG models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Retrieval-Augmented Generation (RAG) models combine retrieval of relevant documents with generative language modeling to improve factual accuracy and diversity.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Fact Veriﬁcation">
  <data key="d0">Fact Veriﬁcation</data>
  <data key="d1">Study Design</data>
  <data key="d2">The process of assessing the factual correctness of generated content, exemplified here by the FEVER dataset for claim verification.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document Posterior p(zi|x, yi)">
  <data key="d0">Document Posterior p(zi|x, yi)</data>
  <data key="d1">Variables</data>
  <data key="d2">A probability distribution indicating the relevance of each document in the retrieval process during question generation, influenced by the input and generated tokens.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document 1: his works are considered classics of American literature...">
  <data key="d0">Document 1: his works are considered classics of American literature...</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An example document providing background information on literary works and authors.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document 2: ... artists of the 1920s 'Lost Generation' expatriate community...">
  <data key="d0">Document 2: ... artists of the 1920s 'Lost Generation' expatriate community...</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An example document with historical and literary context.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document Relevance">
  <data key="d0">Document Relevance</data>
  <data key="d1">Variables</data>
  <data key="d2">The relevance scores assigned to documents during retrieval, influencing the quality and specificity of generated responses.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generation Quality">
  <data key="d0">Generation Quality</data>
  <data key="d1">Results</data>
  <data key="d2">Assessment of generated text based on factual correctness, specificity, and diversity, comparing models like RAG and BART.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document Retrieval">
  <data key="d0">Document Retrieval</data>
  <data key="d1">Tools</data>
  <data key="d2">The process of fetching relevant documents to support generation, critical for models like RAG.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document Context">
  <data key="d0">Document Context</data>
  <data key="d1">Variables</data>
  <data key="d2">The contextual information provided by retrieved documents that guides the generation process.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Training Data">
  <data key="d0">Model Training Data</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The datasets used to train models like BART and RAG, including examples from Wikipedia and other corpora.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Purgatorio">
  <data key="d0">Purgatorio</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Purgatorio is the second cantica of Dante Alighieri's Divine Comedy, depicting the poet's journey through purgatory.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Paradiso">
  <data key="d0">Paradiso</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Paradiso is the third cantica of Dante Alighieri's Divine Comedy, representing the ascent through heaven.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Thorne">
  <data key="d0">Thorne</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Thorne's model refers to a classification approach used as a benchmark for claim verification tasks.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Vlachos">
  <data key="d0">Vlachos</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Vlachos's model is a classification system used to evaluate claim truthfulness based on evidence sentences.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RoBERTa">
  <data key="d0">RoBERTa</data>
  <data key="d1">Tools</data>
  <data key="d2">RoBERTa is a transformer-based language model used for classifying claims as true or false.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="gold evidence sentence">
  <data key="d0">gold evidence sentence</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A sentence used as the authoritative evidence supporting claim verification in the FEVER dataset.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="top k documents">
  <data key="d0">top k documents</data>
  <data key="d1">Variables</data>
  <data key="d2">The top k retrieved documents are the most relevant articles retrieved for evidence in the RAG system.&lt;SEP&gt;The top k retrieved documents for a claim, used to evaluate retrieval performance.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="article titles">
  <data key="d0">article titles</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Titles of documents retrieved by RAG, used to assess overlap with gold evidence.&lt;SEP&gt;Titles of documents retrieved by RAG, used to measure overlap with gold evidence.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="accuracy">
  <data key="d0">accuracy</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric indicating the proportion of correct claim classifications or retrievals by models.&lt;SEP&gt;Accuracy measures the proportion of correct classifications or retrievals made by the models.&lt;SEP&gt;Accuracy assesses whether the generated code correctly implements the desired parallel algorithms and passes correctness tests.&lt;SEP&gt;Metrics used to evaluate the correctness of code generation, labeling, and performance predictions, with high reported percentages.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="generation diversity">
  <data key="d0">generation diversity</data>
  <data key="d1">Variables</data>
  <data key="d2">A measure of the variety in generated text, based on distinct n-grams, indicating diversity and factuality.&lt;SEP&gt;Generation diversity quantifies the variety in generated text, measured by distinct n-grams.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="retrieval ablations">
  <data key="d0">retrieval ablations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Ablation studies where the retrieval component is frozen or replaced to assess its impact on performance.&lt;SEP&gt;Experimental setups where the retrieval component is frozen or replaced to assess its impact on model performance.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="BM25">
  <data key="d0">BM25</data>
  <data key="d1">Tools</data>
  <data key="d2">A traditional keyword-based retrieval system used as a baseline to compare against learned retrieval methods like RAG.&lt;SEP&gt;An algorithm based on the probabilistic relevance framework used for ranking documents in information retrieval systems.&lt;SEP&gt;BM25 is a traditional keyword-based retrieval system used as a baseline for comparison with learned retrieval methods.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="index">
  <data key="d0">index</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A non-parametric memory structure built from a Wikipedia dump, used for document retrieval in RAG.&lt;SEP&gt;An index is a non-parametric memory structure built from a Wikipedia dump, used for document retrieval in RAG.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="world leaders">
  <data key="d0">world leaders</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A list of 82 world leaders used to evaluate the accuracy of RAG with different indices.&lt;SEP&gt;A list of 82 world leaders used to evaluate the effectiveness of RAG's knowledge updating with different indices.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="knowledge update">
  <data key="d0">knowledge update</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The process of updating RAG's knowledge base by replacing its index, enabling current information incorporation without retraining.&lt;SEP&gt;Updating RAG's knowledge base by replacing its index allows for current information integration without retraining.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="claim">
  <data key="d0">claim</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A statement or assertion that is evaluated for truthfulness or validity in the claim verification task.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="document retrieval">
  <data key="d0">document retrieval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of fetching relevant documents or evidence to support or refute a claim, used within RAG and other models.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="gold evidence">
  <data key="d0">gold evidence</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The authoritative evidence sentences annotated as correct support or refute claims in datasets like FEVER.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="retrieval mechanism">
  <data key="d0">retrieval mechanism</data>
  <data key="d1">Variables</data>
  <data key="d2">The process or system used by RAG to retrieve relevant documents, impacting overall performance.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="performance metrics">
  <data key="d0">performance metrics</data>
  <data key="d1">Variables</data>
  <data key="d2">Performance metrics include runtime measures such as execution time, pass@1 scores, and other evaluation statistics used to assess code quality.&lt;SEP&gt;Quantitative measures such as exact match, F1, B-1, QB-1, R-L, used to evaluate model performance across tasks.&lt;SEP&gt;Quantitative measures such as pass@1 scores, runtime durations, and success rates used to evaluate code quality and model performance.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30&lt;SEP&gt;chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="diversity-promoting decoding">
  <data key="d0">diversity-promoting decoding</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques used to increase the variety of generated outputs, such as sampling strategies.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="index from 2016">
  <data key="d0">index from 2016</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A Wikipedia dump snapshot from December 2016 used as an index for RAG to answer questions about 2016 world leaders.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="index from 2018">
  <data key="d0">index from 2018</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A Wikipedia dump snapshot from December 2018 used as an index for RAG to answer questions about 2018 world leaders.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="test time knowledge update">
  <data key="d0">test time knowledge update</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using different indices at test time to assess how well RAG can update its knowledge without retraining.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="2016 Index">
  <data key="d0">2016 Index</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The 2016 index is used to evaluate the accuracy of matching world leaders across different years, serving as a reference metric for comparison.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="2018 Index">
  <data key="d0">2018 Index</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The 2018 index is used similarly to the 2016 index for matching world leaders, providing a basis for evaluating changes over time.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="World Leaders">
  <data key="d0">World Leaders</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">World leaders refer to prominent political figures whose identification accuracy is assessed using indices.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Accuracy">
  <data key="d0">Accuracy</data>
  <data key="d1">Results</data>
  <data key="d2">Accuracy indicates the correctness of the model's predictions, contrasting with confidence measures like perplexity.&lt;SEP&gt;Accuracy measures how well models predict correct pragmas and performance outcomes, with high percentages indicating strong performance.&lt;SEP&gt;Accuracy measures the correctness of matching world leaders across indices, with low percentages indicating poor matching performance.&lt;SEP&gt;Accuracy measures the proportion of correct pragma generations by the models, both in syntax and functionality, serving as a key performance indicator.&lt;SEP&gt;Accuracy measures the proportion of correctly generated pragmas by the model, evaluated both syntactically and functionally, as an indicator of model performance.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Indices Mismatch">
  <data key="d0">Indices Mismatch</data>
  <data key="d1">Variables</data>
  <data key="d2">Mismatch between indices (2016 vs. 2018) affects the accuracy of leader matching, highlighting issues in data consistency.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieving More Documents">
  <data key="d0">Retrieving More Documents</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Retrieving more documents involves fetching additional relevant information during model operation, which can influence performance.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Test Time Adjustment">
  <data key="d0">Test Time Adjustment</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Adjusting the number of retrieved documents at test time to optimize performance and runtime.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open-domain QA">
  <data key="d0">Open-domain QA</data>
  <data key="d1">Study Design</data>
  <data key="d2">Open-domain question answering is a task where models answer questions using broad knowledge sources, evaluated here with retrieval strategies.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Rouge-L and Bleu-1">
  <data key="d0">Rouge-L and Bleu-1</data>
  <data key="d1">Results</data>
  <data key="d2">Evaluation metrics used to assess model performance, with retrieval affecting these scores differently.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval Recall Performance">
  <data key="d0">Retrieval Recall Performance</data>
  <data key="d1">Results</data>
  <data key="d2">Retrieval recall performance indicates how effectively relevant documents are fetched, impacting downstream task accuracy.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Related Work">
  <data key="d0">Related Work</data>
  <data key="d1">Discipline</data>
  <data key="d2">A review of existing optimization approaches, code generators, and frameworks for parallel programming, providing context for the PPL development.&lt;SEP&gt;A review of existing parallel code optimization techniques, code generators, and frameworks, providing context and benchmarks for PPL development.&lt;SEP&gt;Previous research on retrieval-enhanced NLP tasks, demonstrating the benefits of retrieval in various applications.&lt;SEP&gt;Research involving machine learning and large language models applied to source code analysis, generation, and performance modeling.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Single-Task Retrieval">
  <data key="d0">Single-Task Retrieval</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Approach where retrieval improves performance across individual NLP tasks such as question answering, fact checking, and translation.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="General-Purpose Architectures">
  <data key="d0">General-Purpose Architectures</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models designed to handle multiple NLP tasks without retrieval, exemplified by architectures like GPT-2, BART, and T5.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Learned Retrieval">
  <data key="d0">Learned Retrieval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques involving training models to optimize document retrieval for specific tasks using neural language models, reinforcement learning, or latent variables.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Memory-based Architectures">
  <data key="d0">Memory-based Architectures</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Architectures that incorporate external memory components, allowing models to attend to retrieved text or embeddings for improved factual accuracy.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieve-and-Edit">
  <data key="d0">Retrieve-and-Edit</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approach where relevant retrieved content is edited or aggregated to produce the final output, used in translation and semantic parsing.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Discussion">
  <data key="d0">Discussion</data>
  <data key="d1">Results</data>
  <data key="d2">Discussion on the hybrid models integrating parametric and non-parametric memory, emphasizing their interpretability and capacity for dynamic updates.&lt;SEP&gt;The discussion interprets how kernel complexity impacts AI-generated code quality, noting that simpler kernels tend to produce more accurate results, and that targeted keywords can enhance performance.&lt;SEP&gt;The discussion interprets the impact of kernel complexity on AI-generated code quality, highlighting that simpler kernels tend to yield more accurate results and that targeted keywords can enhance proficiency.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieving more documents">
  <data key="d0">Retrieving more documents</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Retrieving more documents involves fetching additional relevant information during model operation, which can influence performance.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Test time adjustment">
  <data key="d0">Test time adjustment</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Adjusting the number of retrieved documents at test time to optimize performance and runtime.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval recall performance">
  <data key="d0">Retrieval recall performance</data>
  <data key="d1">Results</data>
  <data key="d2">Retrieval recall performance indicates how effectively relevant documents are fetched, impacting downstream task accuracy.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Related work">
  <data key="d0">Related work</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Previous research on retrieval-enhanced NLP tasks, demonstrating the benefits of retrieval in various applications.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Single-task retrieval">
  <data key="d0">Single-task retrieval</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Approach where retrieval improves performance across individual NLP tasks such as question answering, fact checking, and translation.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="General-purpose architectures for NLP">
  <data key="d0">General-purpose architectures for NLP</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models designed to handle multiple NLP tasks without retrieval, exemplified by architectures like GPT-2, BART, and T5.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Learned retrieval">
  <data key="d0">Learned retrieval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques involving training models to optimize document retrieval for specific tasks using neural language models, reinforcement learning, or latent variables.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Memory-based architectures">
  <data key="d0">Memory-based architectures</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Architectures that incorporate external memory components, allowing models to attend to retrieved text or embeddings for improved factual accuracy and interpretability.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieve-and-edit">
  <data key="d0">Retrieve-and-edit</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approach where relevant retrieved content is edited or aggregated to produce the final output, used in translation and semantic parsing.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Semantic Parsing">
  <data key="d0">Semantic Parsing</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Semantic Parsing is a computational approach that converts natural language into formal representations to facilitate understanding and reasoning in NLP systems.&lt;SEP&gt;Semantic Parsing is a computational approach to interpret natural language by converting it into formal representations, often used in NLP to understand and process language meaning.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Latent Retrieval">
  <data key="d0">Latent Retrieval</data>
  <data key="d1">Methods</data>
  <data key="d2">Latent retrieval refers to learning implicit representations to identify relevant information without explicit indexing, enhancing retrieval efficiency and accuracy.&lt;SEP&gt;Latent retrieval refers to learning implicit representations to retrieve relevant information without explicit indexing, enhancing the retrieval process in models.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG Techniques">
  <data key="d0">RAG Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Retrieval-Augmented Generation (RAG) combines parametric and non-parametric memory to improve factual correctness and interpretability in NLP tasks.&lt;SEP&gt;Retrieval-Augmented Generation (RAG) combines retrieval mechanisms with generative models, leveraging external knowledge to produce more factual and contextually relevant outputs.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="State of the Art Results">
  <data key="d0">State of the Art Results</data>
  <data key="d1">Results</data>
  <data key="d2">Achieved by RAG models in open-domain question answering, indicating superior performance over previous models.&lt;SEP&gt;The RAG models have achieved leading performance in open-domain question answering tasks, surpassing previous models in accuracy and factual correctness.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Effectiveness">
  <data key="d0">Model Effectiveness</data>
  <data key="d1">Results</data>
  <data key="d2">The effectiveness of the retrieval component was validated by showing that the retrieval index can be updated or swapped without retraining the entire model, demonstrating flexibility.&lt;SEP&gt;The effectiveness of the retrieval component was validated, showing that the retrieval index can be hot-swapped to update the model without retraining.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Pre-training">
  <data key="d0">Pre-training</data>
  <data key="d1">Methodology</data>
  <data key="d2">Pre-training involves training models from scratch with objectives like denoising, which could be applied to jointly pre-train parametric and non-parametric components.&lt;SEP&gt;Pre-training involves training models from scratch with objectives such as denoising, which can be extended to jointly pre-train parametric and non-parametric components for better integration.&lt;SEP&gt;Pre-training involves training models on large datasets before fine-tuning for specific tasks, exemplified by BART's denoising sequence-to-sequence approach.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Interaction of Memories">
  <data key="d0">Interaction of Memories</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Explores how parametric (learned weights) and non-parametric (retrieval-based) memories interact within models, opening new research directions.&lt;SEP&gt;This explores how parametric (learned weights) and non-parametric (retrieval-based) memories interact within models, informing future research on their combined use.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Societal Benefits">
  <data key="d0">Societal Benefits</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">More factual, controllable, and interpretable NLP systems can benefit society, e.g., in medical information retrieval or enhancing productivity.&lt;SEP&gt;More factually grounded, controllable, and interpretable models can be employed in domains like healthcare, education, and information dissemination to benefit society.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Bias and Misinformation">
  <data key="d0">Bias and Misinformation</data>
  <data key="d1">Limitations</data>
  <data key="d2">External knowledge sources like Wikipedia may contain biases or inaccuracies, posing risks of misinformation, misuse, or bias amplification.&lt;SEP&gt;External sources like Wikipedia may contain biases or inaccuracies, leading to risks of misinformation, bias amplification, or misuse in generated content.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Automation of Jobs">
  <data key="d0">Automation of Jobs</data>
  <data key="d1">Implications</data>
  <data key="d2">Advanced NLP models, including RAG, have the potential to automate tasks across various industries, impacting employment and economic structures.&lt;SEP&gt;Advanced language models, including RAG, could automate various jobs, raising societal and economic concerns.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Mitigation Strategies">
  <data key="d0">Mitigation Strategies</data>
  <data key="d1">Methods/Tools</data>
  <data key="d2">Employing AI systems to detect, counteract, and reduce misinformation, spam, and bias, promoting responsible deployment and societal safety.&lt;SEP&gt;Employing AI to combat misinformation and spam, and ensuring responsible deployment of models to mitigate risks.&lt;SEP&gt;Methods such as rate-limiting, abuse monitoring, and code review to prevent misuse and improve security.&lt;SEP&gt;Techniques such as rate-limiting, abuse monitoring, and code review processes designed to manage security risks associated with code generation models.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge Base">
  <data key="d0">Knowledge Base</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A structured repository of factual information, such as Wikipedia, used to ground language models and improve factual accuracy.&lt;SEP&gt;Structured repositories like Wikidata or Wikipedia that store domain-specific information used for retrieval and augmentation in language models.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Components">
  <data key="d0">Model Components</data>
  <data key="d1">Variables</data>
  <data key="d2">The parametric component refers to learned weights within the model, while the non-parametric component involves external retrieval mechanisms, both contributing to model knowledge.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Future Research Directions">
  <data key="d0">Future Research Directions</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploration of efficient adaptation techniques, scalable knowledge updating, and domain-specific training strategies to overcome current bottlenecks and improve LLM utility.&lt;SEP&gt;Investigating joint pre-training of parametric and non-parametric components, improving retrieval mechanisms, and understanding their interaction for enhanced NLP performance.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Societal Risks">
  <data key="d0">Societal Risks</data>
  <data key="d1">Limitations</data>
  <data key="d2">Potential misuse, bias propagation, and misinformation pose societal risks associated with deploying large language models grounded in imperfect external sources.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Training Objectives">
  <data key="d0">Training Objectives</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Denoising and other objectives used during pre-training help models learn robust representations, applicable to joint training of different memory types.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Interpretability">
  <data key="d0">Interpretability</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Interpretability refers to how well humans can understand the decision-making process of models, which is enhanced by grounding models in factual knowledge.&lt;SEP&gt;The ability to understand and explain the content, structure, and meaning of prompts or model behaviors, which is often limited in soft prompt tuning.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open-Domain QA">
  <data key="d0">Open-Domain QA</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Open-domain question answering involves retrieving and generating answers from a broad knowledge base, testing models' factual grounding and retrieval capabilities.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Association for Computational Linguistics">
  <data key="d0">Association for Computational Linguistics</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A professional organization dedicated to advancing research in computational linguistics and natural language processing.&lt;SEP&gt;A professional organization focused on advancing the scientific study of language and computational linguistics.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Eunsol Choi">
  <data key="d0">Eunsol Choi</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in question answering for long documents, contributing to methodologies in NLP.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Daniel Hewlett">
  <data key="d0">Daniel Hewlett</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher collaborating on question answering research and methodologies.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jakob Uszkoreit">
  <data key="d0">Jakob Uszkoreit</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in NLP models for understanding long documents.&lt;SEP&gt;A researcher involved in NLP research, contributing to models for understanding long documents.&lt;SEP&gt;Jakob Uszkoreit is involved in machine learning and NLP model research.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Illia Polosukhin">
  <data key="d0">Illia Polosukhin</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on NLP models, notably in question answering and language understanding.&lt;SEP&gt;Illia Polosukhin is an author involved in advancing question answering research and neural network methodologies.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Alexandre Lacoste">
  <data key="d0">Alexandre Lacoste</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to NLP research in question answering.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Proceedings of the 10th Annual Meeting of the Association for Computational Linguistics">
  <data key="d0">Proceedings of the 10th Annual Meeting of the Association for Computational Linguistics</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference volume presenting research papers on computational linguistics and NLP.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Christopher Clark">
  <data key="d0">Christopher Clark</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on multi-paragraph reading comprehension models.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Matt Gardner">
  <data key="d0">Matt Gardner</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to NLP models for understanding multiple paragraphs.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="arXiv:1710.10723">
  <data key="d0">arXiv:1710.10723</data>
  <data key="d1">Study Design</data>
  <data key="d2">A preprint paper describing methods for multi-paragraph reading comprehension.&lt;SEP&gt;Preprint paper describing NLP methodologies for multi-paragraph comprehension.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kristina Toutanova">
  <data key="d0">Kristina Toutanova</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on NLP models for language understanding.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics">
  <data key="d0">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference volume presenting research on NLP and language models.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Emily Dinan">
  <data key="d0">Emily Dinan</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in developing knowledge-powered conversational agents.&lt;SEP&gt;A researcher involved in knowledge-powered conversational agents.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Stephen Roller">
  <data key="d0">Stephen Roller</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to conversational AI and NLP.&lt;SEP&gt;A researcher working on conversational AI and dialogue systems.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kurt Shuster">
  <data key="d0">Kurt Shuster</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to neural conversational models.&lt;SEP&gt;A researcher working on dialogue systems and NLP methodologies.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Angela Fan">
  <data key="d0">Angela Fan</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher focusing on hierarchical neural story generation and long-form question answering.&lt;SEP&gt;A researcher focusing on neural story generation and question answering models.&lt;SEP&gt;A researcher working on augmenting transformers with KNN-based memory for NLP.&lt;SEP&gt;A researcher working on augmenting transformers with memory for NLP tasks.&lt;SEP&gt;A researcher working on hierarchical neural story generation.&lt;SEP&gt;A researcher working on neural story generation models.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Michael Auli">
  <data key="d0">Michael Auli</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in NLP language modeling and story generation.&lt;SEP&gt;A researcher involved in NLP research, especially in language modeling.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jason Weston">
  <data key="d0">Jason Weston</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to neural conversation models and long-form QA.&lt;SEP&gt;A researcher specializing in conversational agents and NLP.&lt;SEP&gt;A researcher working on conversational AI and NLP.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics">
  <data key="d0">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference volume featuring NLP research papers.&lt;SEP&gt;Conference proceedings showcasing NLP research in story generation and question answering.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Yacine Jernite">
  <data key="d0">Yacine Jernite</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher collaborating on NLP models and long-form question answering.&lt;SEP&gt;A researcher collaborating on long-form question answering research.&lt;SEP&gt;Yacine Jernite works on datasets and models related to source code analysis.&lt;SEP&gt;Yacine Jernite works on datasets related to source code and machine learning models.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Ethan Perez">
  <data key="d0">Ethan Perez</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to NLP research in question answering and language modeling.&lt;SEP&gt;A researcher working on NLP methodologies for long-form QA.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="David Grangier">
  <data key="d0">David Grangier</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in NLP methodologies for language understanding.&lt;SEP&gt;A researcher involved in NLP models for long-form question answering.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="ELI5: Long form question answering">
  <data key="d0">ELI5: Long form question answering</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A dataset and task focused on long-form question answering, emphasizing knowledge integration in NLP.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics">
  <data key="d0">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference volume presenting research on long-form question answering and NLP methodologies.&lt;SEP&gt;Conference proceedings presenting research on long-form question answering and NLP models.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Claire Gardent">
  <data key="d0">Claire Gardent</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher collaborating on NLP models and question answering.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Chloe Braud">
  <data key="d0">Chloe Braud</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in NLP research, especially in language modeling.&lt;SEP&gt;A researcher involved in NLP story generation and question answering.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Antoine Bordes">
  <data key="d0">Antoine Bordes</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to NLP methodologies and models.&lt;SEP&gt;A researcher contributing to NLP models with memory augmentation.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="H1gx1CNKPH">
  <data key="d0">H1gx1CNKPH</data>
  <data key="d1">Tools</data>
  <data key="d2">A reference to a specific model or tool related to augmenting transformers with memory in NLP.&lt;SEP&gt;Identifier for a specific model or system related to transformer augmentation with KNN in NLP.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="abs/2004.07202">
  <data key="d0">abs/2004.07202</data>
  <data key="d1">Study Design</data>
  <data key="d2">An arXiv preprint describing entities as experts and sparse memory access with entity supervision in NLP.&lt;SEP&gt;ArXiv preprint discussing entities as experts and sparse memory access with entity supervision in NLP.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Marjan Ghazvininejad">
  <data key="d0">Marjan Ghazvininejad</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on knowledge-grounded neural conversation models.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Chris Brockett">
  <data key="d0">Chris Brockett</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in NLP and conversational AI.&lt;SEP&gt;A researcher involved in neural conversation and grounded NLP models.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jianfeng Gao">
  <data key="d0">Jianfeng Gao</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to NLP models and knowledge-grounded conversations.&lt;SEP&gt;A researcher contributing to knowledge-grounded NLP systems.&lt;SEP&gt;Author involved in research on language model fine-tuning and instruction alignment.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wen Yih">
  <data key="d0">Wen Yih</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on NLP and knowledge-grounded dialogue systems.&lt;SEP&gt;A researcher working on grounded dialogue systems in NLP.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Michel Galley">
  <data key="d0">Michel Galley</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in NLP research on grounded conversational models.&lt;SEP&gt;A researcher involved in neural conversation models and grounded NLP.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="AAAI Conference on Artificial Intelligence">
  <data key="d0">AAAI Conference on Artificial Intelligence</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference presenting research on AI, including NLP and conversational systems.&lt;SEP&gt;Conference presenting AI and NLP research, including grounded dialogue models.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="abs/1705.08807">
  <data key="d0">abs/1705.08807</data>
  <data key="d1">Study Design</data>
  <data key="d2">An arXiv paper discussing when AI might exceed human performance, including evidence and hypotheses.&lt;SEP&gt;ArXiv paper discussing when AI might surpass human performance, with evidence and hypotheses.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="arxiv.org/abs/1705.08807">
  <data key="d0">arxiv.org/abs/1705.08807</data>
  <data key="d1">Study Design</data>
  <data key="d2">The URL of the paper analyzing AI performance relative to humans.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jiatao Gu">
  <data key="d0">Jiatao Gu</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on search engine guided neural machine translation.&lt;SEP&gt;Jiatao Gu is a researcher involved in neural machine translation and search-guided language models, contributing to advancements in AI translation systems.&lt;SEP&gt;Jiatao Gu is an author associated with research on search engine guided neural machine translation, contributing to advancements in neural translation methods.&lt;SEP&gt;Author of research on IDPG for prompt generation.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Yong Wang">
  <data key="d0">Yong Wang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to search engine guided neural translation models.&lt;SEP&gt;A researcher involved in NLP translation models.&lt;SEP&gt;Yong Wang is an author contributing to research on neural machine translation and related AI methodologies.&lt;SEP&gt;Yong Wang is an author involved in research related to neural machine translation and artificial intelligence applications.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kyunghyun Cho">
  <data key="d0">Kyunghyun Cho</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to neural machine translation and NLP models.&lt;SEP&gt;A researcher involved in neural machine translation and NLP models.&lt;SEP&gt;Kyunghyun Cho is a researcher contributing to neural machine translation and deep learning methodologies.&lt;SEP&gt;Kyunghyun Cho is a researcher known for contributions to neural network models and machine translation frameworks.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Victor O.K. Li">
  <data key="d0">Victor O.K. Li</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on NLP translation systems.&lt;SEP&gt;Victor O.K. Li is an academic involved in AI and natural language processing research, especially in neural translation.&lt;SEP&gt;Victor O.K. Li is an author engaged in research on neural machine translation and AI systems.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="AAAI 2018">
  <data key="d0">AAAI 2018</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference where research on search engine guided neural machine translation was presented.&lt;SEP&gt;Conference where the research on search engine guided neural machine translation was presented.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="pages 5133–5140">
  <data key="d0">pages 5133–5140</data>
  <data key="d1">Study Design</data>
  <data key="d2">Page range of the conference paper detailing search engine guided translation models.&lt;SEP&gt;Page range of the translation research paper in conference proceedings.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="doi: 10.18653/v1/P17-1171">
  <data key="d0">doi: 10.18653/v1/P17-1171</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A digital object identifier (DOI) referencing a specific research publication related to NLP.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="https://www.aclweb.org/anthology/P17-1171">
  <data key="d0">https://www.aclweb.org/anthology/P17-1171</data>
  <data key="d1">Tools</data>
  <data key="d2">URL link to the research paper or publication by the Association for Computational Linguistics.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Proceedings of the 10th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)">
  <data key="d0">Proceedings of the 10th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</data>
  <data key="d1">Study Design</data>
  <data key="d2">Conference proceedings presenting research on NLP, especially question answering and long document comprehension.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="pages 209–220">
  <data key="d0">pages 209–220</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Page range of the paper within the conference proceedings.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Vancouver, Canada">
  <data key="d0">Vancouver, Canada</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Location where the conference was held.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="July 2017">
  <data key="d0">July 2017</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Date when the conference paper was published or presented.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="URL http://arxiv.org/abs/1710.10723">
  <data key="d0">URL http://arxiv.org/abs/1710.10723</data>
  <data key="d1">Tools</data>
  <data key="d2">URL link to the preprint paper on arXiv.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="The 2019 Conference of the North American Chapter of the Association for Computational Linguistics">
  <data key="d0">The 2019 Conference of the North American Chapter of the Association for Computational Linguistics</data>
  <data key="d1">Study Design</data>
  <data key="d2">Conference proceedings presenting NLP research, including models like BERT.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Minneapolis, Minnesota">
  <data key="d0">Minneapolis, Minnesota</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Location of the conference.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="June 2019">
  <data key="d0">June 2019</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Date of the conference publication.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Yann Dauphin">
  <data key="d0">Yann Dauphin</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on NLP models and neural architectures.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="pages 889–898">
  <data key="d0">pages 889–898</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Page range of the paper within the conference.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Melbourne, Australia">
  <data key="d0">Melbourne, Australia</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Location of the conference.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="July 2018">
  <data key="d0">July 2018</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Date of the conference publication.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="pages 3558–3567">
  <data key="d0">pages 3558–3567</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Page range of the paper within the conference.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Florence, Italy">
  <data key="d0">Florence, Italy</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Location of the conference.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="July 2019">
  <data key="d0">July 2019</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Date of the conference publication.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="URL https://arxiv.org/abs/2004.07202">
  <data key="d0">URL https://arxiv.org/abs/2004.07202</data>
  <data key="d1">Tools</data>
  <data key="d2">URL link to the preprint on arXiv.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="http://arxiv.org/abs/1705.08807">
  <data key="d0">http://arxiv.org/abs/1705.08807</data>
  <data key="d1">Tools</data>
  <data key="d2">URL link to the arXiv paper analyzing AI exceeding human capabilities.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Search engine guided neural machine translation">
  <data key="d0">Search engine guided neural machine translation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model integrating search engine techniques with neural machine translation to improve translation accuracy and efficiency.&lt;SEP&gt;This is a model combining search engine techniques with neural machine translation to improve translation accuracy.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="32nd AAAI Conference on Artificial Intelligence">
  <data key="d0">32nd AAAI Conference on Artificial Intelligence</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An academic conference where research on AI and neural translation models is presented and discussed.&lt;SEP&gt;An academic conference where research papers on artificial intelligence, including neural machine translation, are presented.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="generating sentences by editing prototypes">
  <data key="d0">generating sentences by editing prototypes</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A natural language generation methodology that involves editing existing prototype sentences to produce new sentences, improving natural language synthesis.&lt;SEP&gt;This methodology involves creating sentences through editing existing prototypes, advancing natural language generation techniques.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="REALM: Retrieval-augmented language model pre-training">
  <data key="d0">REALM: Retrieval-augmented language model pre-training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A pre-training methodology that incorporates retrieval mechanisms to enhance language model performance on various NLP tasks.&lt;SEP&gt;REALM is a pre-training methodology that incorporates retrieval mechanisms to enhance language model performance.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="retrieve-and-edit framework">
  <data key="d0">retrieve-and-edit framework</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A framework for predicting structured outputs by retrieving relevant information and editing it accordingly.&lt;SEP&gt;A framework for structured output prediction that retrieves relevant information and edits it to generate accurate outputs.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Simple and effective retrieve-edit-rerank text generation">
  <data key="d0">Simple and effective retrieve-edit-rerank text generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A text generation approach that retrieves relevant data, edits it, and reranks outputs for better quality and relevance.&lt;SEP&gt;A text generation approach that retrieves relevant data, edits it, and reranks outputs for improved quality.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="billion-scale similarity search with gpus">
  <data key="d0">billion-scale similarity search with gpus</data>
  <data key="d1">Tools</data>
  <data key="d2">A computational tool utilizing GPUs for large-scale similarity search, enabling efficient retrieval in high-dimensional data spaces.&lt;SEP&gt;A tool utilizing GPUs to perform large-scale similarity searches efficiently.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension">
  <data key="d0">TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A dataset designed for evaluating reading comprehension models using distant supervision at scale.&lt;SEP&gt;A large-scale dataset designed for training and evaluating reading comprehension models using distant supervision techniques.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Inferring algorithmic patterns with stack-augmented recurrent nets">
  <data key="d0">Inferring algorithmic patterns with stack-augmented recurrent nets</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A method employing stack-augmented recurrent neural networks to infer and model algorithmic patterns in data.&lt;SEP&gt;A neural network methodology employing stack-augmented recurrent nets to infer and learn algorithmic patterns in data sequences.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Dense passage retrieval for open-domain question answering">
  <data key="d0">Dense passage retrieval for open-domain question answering</data>
  <data key="d1">Tools</data>
  <data key="d2">A retrieval system that efficiently fetches relevant passages to support open-domain question answering tasks.&lt;SEP&gt;A retrieval tool that enables efficient passage retrieval to support open-domain question answering systems.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generalization through memorization: Nearest neighbor language models">
  <data key="d0">Generalization through memorization: Nearest neighbor language models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A language modeling approach that enhances generalization by memorizing training data and employing nearest neighbor retrieval.&lt;SEP&gt;A model that leverages memorization and nearest neighbor techniques to improve language model generalization.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Adam: A method for stochastic optimization">
  <data key="d0">Adam: A method for stochastic optimization</data>
  <data key="d1">Tools</data>
  <data key="d2">Adam is an optimization algorithm used to train neural networks effectively by adapting learning rates.&lt;SEP&gt;An optimization algorithm widely used for training neural networks, adapting learning rates for efficient convergence.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Natural Questions: a Benchmark for Question Answering Research">
  <data key="d0">Natural Questions: a Benchmark for Question Answering Research</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A benchmark dataset and research framework for evaluating question answering systems.&lt;SEP&gt;A benchmark dataset for evaluating question answering systems, facilitating research in natural language understanding and QA models.&lt;SEP&gt;A benchmark dataset for evaluating question answering systems, promoting research in natural language understanding.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Danielle Epstein">
  <data key="d0">Danielle Epstein</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Danielle Epstein is an author contributing to research in natural language processing and question answering.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Matthew Kelcey">
  <data key="d0">Matthew Kelcey</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Matthew Kelcey is a researcher contributing to natural language processing and machine learning studies.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kristina N. Toutanova">
  <data key="d0">Kristina N. Toutanova</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Kristina N. Toutanova is an expert in natural language processing and model development for question answering.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Llion Jones">
  <data key="d0">Llion Jones</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Llion Jones is involved in research on neural network architectures and NLP models.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Andrew Dai">
  <data key="d0">Andrew Dai</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Andrew Dai contributes to neural network models and NLP research.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Slav Petrov">
  <data key="d0">Slav Petrov</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Slav Petrov works on language understanding and model evaluation in NLP.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Transactions of the Association of Computational Linguistics">
  <data key="d0">Transactions of the Association of Computational Linguistics</data>
  <data key="d1">Discipline</data>
  <data key="d2">A scholarly journal publishing research in computational linguistics and NLP.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Large memory layers with product keys">
  <data key="d0">Large memory layers with product keys</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A neural network architecture that utilizes large memory layers with product key mechanisms to improve model capacity and performance.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Advances in Neural Information Processing Systems 32">
  <data key="d0">Advances in Neural Information Processing Systems 32</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A conference proceeding presenting research on neural information processing and machine learning techniques.&lt;SEP&gt;A conference proceedings volume compiling research papers and advancements in neural information processing systems.&lt;SEP&gt;A conference proceedings volume that compiles research papers and advancements in neural information processing.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Latent retrieval for weakly supervised open domain question answering">
  <data key="d0">Latent retrieval for weakly supervised open domain question answering</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A retrieval method that leverages latent representations to improve open domain question answering performance.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension">
  <data key="d0">BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A pre-training model designed for sequence-to-sequence tasks to enhance language understanding and generation.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="A diversity-promoting objective function for neural conversation models">
  <data key="d0">A diversity-promoting objective function for neural conversation models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An objective function aimed at increasing diversity in neural conversational AI outputs.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons">
  <data key="d0">Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An evaluation framework that uses optimized questions and multi-turn comparisons to better assess dialogue systems.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Robust neural machine translation with joint textual and phonetic embedding">
  <data key="d0">Robust neural machine translation with joint textual and phonetic embedding</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A translation approach combining textual and phonetic embeddings to improve robustness in neural machine translation.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generating Wikipedia by summarizing long sequences">
  <data key="d0">Generating Wikipedia by summarizing long sequences</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique for automatic Wikipedia article generation by summarizing lengthy sequences of text.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs">
  <data key="d0">Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An algorithm for fast and accurate nearest neighbor search using hierarchical graph structures.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="The next decade in AI: four steps towards robust artificial intelligence">
  <data key="d0">The next decade in AI: four steps towards robust artificial intelligence</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A research hypothesis outlining steps to achieve robust artificial intelligence in the coming decade.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="How decoding strategies affect the verifiability of generated text">
  <data key="d0">How decoding strategies affect the verifiability of generated text</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A research question investigating the impact of decoding strategies on the quality and verifiability of generated language.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Background knowledge for building conversation systems">
  <data key="d0">Background knowledge for building conversation systems</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research exploring the utilization of background knowledge to improve conversational AI systems.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kuchaiev">
  <data key="d0">Kuchaiev</data>
  <data key="d1">Researcher</data>
  <data key="d2">Kuchaiev is a researcher associated with the development of mixed precision training methods.&lt;SEP&gt;Kuchaiev is a researcher involved in developing techniques related to mixed precision training in neural networks.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Ganesh Venkatesh">
  <data key="d0">Ganesh Venkatesh</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ganesh Venkatesh contributed to research on mixed precision training, collaborating on related publications.&lt;SEP&gt;Ganesh Venkatesh contributed to research on mixed precision training, collaborating on related scientific publications.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Hao Wu">
  <data key="d0">Hao Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hao Wu is a researcher who co-authored work on mixed precision training presented at ICLR 2018.&lt;SEP&gt;Hao Wu is involved in research on mixed precision training, contributing to the publication in ICLR 2018.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Mixed Precision Training">
  <data key="d0">Mixed Precision Training</data>
  <data key="d1">Core Concept</data>
  <data key="d2">Mixed precision training is a methodology that employs both 16-bit and 32-bit floating point formats to accelerate neural network training and reduce memory usage.&lt;SEP&gt;Mixed precision training is a methodology that utilizes both 16-bit and 32-bit floating-point types to improve computational efficiency in neural network training.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Background Knowledge">
  <data key="d0">Background Knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Background knowledge refers to prior information or data used to enhance the performance of conversation systems in NLP applications.&lt;SEP&gt;Background knowledge refers to prior information used to enhance the performance of conversation systems.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Conversation Systems">
  <data key="d0">Conversation Systems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Conversation systems are computational frameworks designed to engage in natural language interactions with users.&lt;SEP&gt;Conversation systems are computational frameworks designed to interact with users through natural language.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Better Metric for Evaluating Question Generation Systems">
  <data key="d0">Better Metric for Evaluating Question Generation Systems</data>
  <data key="d1">Methodology</data>
  <data key="d2">This is an improved evaluation metric aimed at more accurately assessing the quality and effectiveness of question generation models in NLP.&lt;SEP&gt;This refers to an improved evaluation metric aimed at assessing the quality of question generation in NLP tasks.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Question Generation Systems">
  <data key="d0">Question Generation Systems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Question generation systems automatically produce questions from text, and their evaluation metrics are studied for improvement.&lt;SEP&gt;Systems that automatically generate questions from textual data, whose performance is evaluated using specific metrics.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="MS MARCO Dataset">
  <data key="d0">MS MARCO Dataset</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">A large-scale, human-generated dataset used for machine reading comprehension and passage retrieval tasks.&lt;SEP&gt;MS MARCO is a large-scale dataset created for machine reading comprehension, containing human-generated questions and passages.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Passage Re-ranking with BERT">
  <data key="d0">Passage Re-ranking with BERT</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique that uses BERT to re-rank passages in information retrieval to improve relevance and accuracy.&lt;SEP&gt;This methodology involves using BERT to improve the ranking of passages relevant to a query in information retrieval.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="fairseq Toolkit">
  <data key="d0">fairseq Toolkit</data>
  <data key="d1">Tools</data>
  <data key="d2">An open-source sequence modeling toolkit designed for efficient training and evaluation of neural models in NLP.&lt;SEP&gt;fairseq is a sequence modeling toolkit designed for efficient training of neural models, supporting various NLP tasks.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Language Models as Knowledge Bases">
  <data key="d0">Language Models as Knowledge Bases</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The hypothesis that large-scale language models can function as repositories of factual knowledge, enabling retrieval of information without explicit databases.&lt;SEP&gt;This theory explores the potential of large language models to serve as repositories of factual knowledge.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Contextual Influence on Language Models">
  <data key="d0">Contextual Influence on Language Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The concept that the context in which language models operate significantly affects their factual predictions and responses.&lt;SEP&gt;This concept examines how different contexts affect the factual predictions made by language models.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generative Pre-Training (GPT)">
  <data key="d0">Generative Pre-Training (GPT)</data>
  <data key="d1">Methodology</data>
  <data key="d2">A pre-training approach for language models that involves unsupervised learning on large corpora to improve language understanding and generation.&lt;SEP&gt;GPT is a pre-training approach for language models that enables unsupervised learning and improves language understanding.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Unsupervised Multitask Learning">
  <data key="d0">Unsupervised Multitask Learning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A training paradigm where language models learn multiple tasks simultaneously without explicit supervision, enhancing their generalization capabilities.&lt;SEP&gt;This methodology involves training language models on diverse tasks without explicit supervision to enhance their general capabilities.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge Base Construction">
  <data key="d0">Knowledge Base Construction</data>
  <data key="d1">Study Design</data>
  <data key="d2">Automated Knowledge Base Construction involves creating structured repositories of information using NLP techniques, often leveraging language models.&lt;SEP&gt;The process of automatically extracting, organizing, and storing factual information from text to build structured knowledge bases using NLP techniques.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Unsupervised Multitask Learners">
  <data key="d0">Unsupervised Multitask Learners</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A framework where language models are trained to perform multiple tasks without explicit supervision, enabling versatile language understanding.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Transfer Learning">
  <data key="d0">Transfer Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A machine learning approach where knowledge gained from one task or domain is applied to improve performance on another, often used to enhance language models.&lt;SEP&gt;Using prompts trained on source domains or multiple tasks to improve performance on new, unseen target domains or tasks, demonstrating transferability of prompt representations.&lt;SEP&gt;Using prompts trained on source domains or tasks to improve performance on unseen target domains or tasks, demonstrating transferability of prompt representations.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Text-to-Text Transformer">
  <data key="d0">Text-to-Text Transformer</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A neural network architecture that converts various NLP tasks into a text-to-text format, facilitating transfer learning and multitask training.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Parameters">
  <data key="d0">Model Parameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters are the internal weights of a language model that encode learned knowledge, capacity, and complexity of the model.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge Packing">
  <data key="d0">Knowledge Packing</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates how much information or knowledge can be embedded within the parameters of a language model.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Probabilistic Relevance Framework">
  <data key="d0">Probabilistic Relevance Framework</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A theoretical framework for information retrieval that models the relevance of documents based on probabilistic measures, exemplified by BM25.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Relevance Framework">
  <data key="d0">Relevance Framework</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A set of principles and models used to determine the relevance of documents or information in response to queries.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Release Strategies">
  <data key="d0">Release Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Protocols and policies for deploying language models to the public or specific communities, considering social impacts.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Social Impacts">
  <data key="d0">Social Impacts</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The effects that releasing language models can have on society, including ethical, social, and economic consequences.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Memory Networks">
  <data key="d0">Memory Networks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Neural architectures that incorporate memory components to enhance reasoning and contextual understanding.&lt;SEP&gt;Neural network architectures designed to incorporate external memory components, enabling models to retain and manipulate information over long sequences.&lt;SEP&gt;Neural networks that utilize memory components to enhance reasoning and contextual understanding.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Fact Extraction and Verification Dataset (FEVER)">
  <data key="d0">Fact Extraction and Verification Dataset (FEVER)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large-scale dataset created to evaluate systems' ability to extract facts and verify information, used to train and benchmark NLP models.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Catastrophic Forgetting">
  <data key="d0">Catastrophic Forgetting</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A challenge in neural network training where models forget previously learned information when trained on new data, mitigated by techniques like elastic weight consolidation.&lt;SEP&gt;A challenge where models lose previously acquired knowledge when trained on new data, impacting continual learning.&lt;SEP&gt;A phenomenon where fine-tuning LLMs causes loss of previously learned knowledge, impacting model stability across tasks.&lt;SEP&gt;A phenomenon where fine-tuning on new tasks causes the model to forget previously learned information, impacting continual learning.&lt;SEP&gt;Catastrophic forgetting is a challenge where models lose previously acquired knowledge when learning new information, especially during fine-tuning.&lt;SEP&gt;A phenomenon where a model loses previously learned information during further training, leading to decreased performance on earlier tasks or data.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-ce8332c6d0b3d23f38189ff80650d4bc&lt;SEP&gt;chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Elastic Weight Consolidation">
  <data key="d0">Elastic Weight Consolidation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to prevent catastrophic forgetting by selectively slowing down learning on important weights during training.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Attention Mechanism">
  <data key="d0">Attention Mechanism</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A neural network component that allows models to focus on relevant parts of input data, foundational for transformer architectures.&lt;SEP&gt;A neural network component that allows models to focus on relevant parts of the input, significantly improving performance in NLP tasks.&lt;SEP&gt;A neural network component that enables models to focus on relevant parts of the input, foundational to transformer architectures and used as a basis for tiny-attention adapters.&lt;SEP&gt;A neural network component that allows models to focus on relevant parts of input data, foundational to models like 'Attention is all you need' (Vaswani et al., 2017).</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d&lt;SEP&gt;chunk-861fc8218eac993fbe13b418ec4b837c&lt;SEP&gt;chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Attention Is All You Need">
  <data key="d0">Attention Is All You Need</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A foundational paper introducing the Transformer architecture, emphasizing the role of attention mechanisms in neural networks.&lt;SEP&gt;A seminal paper introducing the Transformer architecture emphasizing attention mechanisms for neural networks.&lt;SEP&gt;A seminal paper proposing the transformer architecture, emphasizing the importance of attention mechanisms over recurrent structures.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Diverse Beam Search">
  <data key="d0">Diverse Beam Search</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A decoding strategy that promotes diversity in generated sequences, improving the description of complex scenes in NLP applications.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="GLUE Benchmark">
  <data key="d0">GLUE Benchmark</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A multi-task benchmark for evaluating the general language understanding capabilities of models, used to compare different systems.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="SuperGLUE">
  <data key="d0">SuperGLUE</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An advanced benchmark building upon GLUE, designed to be more challenging and comprehensive for evaluating language understanding.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Large-Scale Dataset">
  <data key="d0">Large-Scale Dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Datasets like FEVER used to train, evaluate, and benchmark NLP models on tasks like fact verification and information extraction.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Bias">
  <data key="d0">Model Bias</data>
  <data key="d1">Limitations</data>
  <data key="d2">Systematic errors or prejudices inherent in models, which can be mitigated through various training and fine-tuning strategies.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Alché-Buc, E. Fox, and R. Garnett">
  <data key="d0">Alché-Buc, E. Fox, and R. Garnett</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Editors associated with a publication on neural information processing systems, contributing to foundational ideas in neural information processing.&lt;SEP&gt;Editors associated with a publication on neural information processing systems, contributing to the dissemination of foundational ideas in neural information processing.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, Jing Jiang">
  <data key="d0">Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, Jing Jiang</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers involved in developing models and methods for open-domain question answering, advancing AI question-answering capabilities.&lt;SEP&gt;Researchers involved in developing models and methods for open-domain question answering, contributing to advancements in AI question-answering systems.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="R3: Reinforced ranker-reader for open-domain question answering">
  <data key="d0">R3: Reinforced ranker-reader for open-domain question answering</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A model architecture combining reinforcement learning with ranker and reader components to improve open-domain question answering.&lt;SEP&gt;A specific model architecture that combines reinforcement learning with ranker and reader components to improve open-domain question answering performance.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Evidence aggregation for answer re-ranking in open-domain question answering">
  <data key="d0">Evidence aggregation for answer re-ranking in open-domain question answering</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique that combines multiple pieces of evidence to improve the accuracy of answer re-ranking in question answering tasks.&lt;SEP&gt;Techniques for aggregating evidence to enhance answer re-ranking accuracy in open-domain QA.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jason Weston, Sumit Chopra, and Antoine Bordes">
  <data key="d0">Jason Weston, Sumit Chopra, and Antoine Bordes</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers known for developing memory networks and sequence generation models for dialogue and reasoning tasks.&lt;SEP&gt;Researchers known for developing memory networks and sequence generation models that enhance conversational AI and natural language understanding.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Memory networks">
  <data key="d0">Memory networks</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A neural network architecture designed to store and retrieve information over long sequences, facilitating reasoning and question answering.&lt;SEP&gt;Neural network architecture designed to store, retrieve, and utilize information over long sequences, facilitating reasoning and question answering.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieve and refine: Improved sequence generation models for dialogue">
  <data key="d0">Retrieve and refine: Improved sequence generation models for dialogue</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research focused on enhancing sequence generation models to produce more accurate and contextually relevant dialogue responses.&lt;SEP&gt;Research on enhancing dialogue systems through sequence generation models that improve response quality.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush">
  <data key="d0">Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Huggingface’s transformers&lt;SEP&gt;Researchers involved in developing Huggingface’s transformers, a state-of-the-art toolkit for natural language processing tasks, advancing NLP methodologies.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Huggingface’s transformers">
  <data key="d0">Huggingface’s transformers</data>
  <data key="d1">Tools</data>
  <data key="d2">A library providing pre-trained transformer models for various NLP tasks, enabling researchers and developers to implement cutting-edge language models.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Shiyue Zhang and Mohit Bansal">
  <data key="d0">Shiyue Zhang and Mohit Bansal</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers focused on addressing semantic drift in question generation, improving the stability and accuracy of semi-supervised question answering systems.&lt;SEP&gt;Researchers working on addressing semantic drift in question generation to improve semi-supervised question answering systems.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Addressing semantic drift in question generation for semi-supervised question answering">
  <data key="d0">Addressing semantic drift in question generation for semi-supervised question answering</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research approach aimed at mitigating semantic drift issues in question generation models to enhance semi-supervised QA performance.&lt;SEP&gt;Research approach aimed at reducing semantic drift issues to enhance the stability and accuracy of question generation models.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, and Jian Yin">
  <data key="d0">Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, and Jian Yin</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers focused on reasoning over semantic-level graphs to improve fact-checking and knowledge verification in NLP.&lt;SEP&gt;Researchers working on reasoning over semantic-level graphs to improve fact-checking capabilities in NLP.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Reasoning over semantic-level graph for fact checking">
  <data key="d0">Reasoning over semantic-level graph for fact checking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A reasoning technique utilizing semantic graphs to verify factual correctness and support fact-checking processes.&lt;SEP&gt;A technique that employs semantic graphs to facilitate reasoning processes for verifying factual information.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval-augmented generation">
  <data key="d0">Retrieval-augmented generation</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d2">The Wikipedia index is used as a dense vector external memory that RAG retrieves from to generate accurate responses.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG Models">
  <data key="d0">RAG Models</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d2">RAG models are built upon seq2seq architectures, integrating retrieval mechanisms to enhance knowledge-based generation.&lt;SEP&gt;RAG models are built upon seq2seq architectures, integrating retrieval mechanisms to improve knowledge-based answer generation."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG Model">
  <data key="d0">RAG Model</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d2">The RAG model can be used for sequence classification by considering the target as a single-token sequence, enabling its application in classification scenarios.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG Components">
  <data key="d0">RAG Components</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d2">The retriever and generator are trained jointly to optimize performance, with the document encoder kept fixed and the query encoder and generator fine-tuned.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG-Token and RAG-Sequence">
  <data key="d0">RAG-Token and RAG-Sequence</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d2">Different decoding strategies are used for RAG-Token and RAG-Sequence, involving beam search and approximation techniques to balance accuracy and efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="FAISS MIPS index">
  <data key="d0">FAISS MIPS index</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d2">The document encoder's embeddings are used to build a FAISS MIPS index for fast document retrieval.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="MSMARCO NLG task">
  <data key="d0">MSMARCO NLG task</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d2">RAG is evaluated for abstractive QA by generating answers to questions in the MSMARCO dataset, testing its natural language generation capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jeopardy question generation">
  <data key="d0">Jeopardy question generation</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d2">The task uses the SearchQA dataset splits to train and evaluate models generating Jeopardy-style questions, focusing on factuality and specificity.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Question generation evaluation">
  <data key="d0">Question generation evaluation</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d2">Q-BLEU-1 scores are used to quantitatively assess the quality of generated questions, emphasizing entity matching and factual correctness.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Question generation">
  <data key="d0">Question generation</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d2">Human judges compare questions generated by different models to assess factuality and specificity, providing qualitative insights into model performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval and reasoning">
  <data key="d0">Retrieval and reasoning</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d2">FEVER involves retrieving evidence from Wikipedia and reasoning over it to classify claims, exemplifying retrieval-augmented reasoning capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Question Generation Evaluation">
  <data key="d0">Question Generation Evaluation</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d2">Q-BLEU-1 scores quantify the quality of generated questions, emphasizing entity matching and factual correctness, correlating with human judgments.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Question Generation">
  <data key="d0">Question Generation</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d2">Human judges compare generated questions for factuality and specificity, providing qualitative assessment of model performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval and Reasoning">
  <data key="d0">Retrieval and Reasoning</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d2">FEVER involves retrieving evidence from Wikipedia and reasoning to classify claims as supported, refuted, or unverifiable, demonstrating retrieval and reasoning capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Claim">
  <data key="d0">Claim</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d2">Claims are supported or refuted by evidence retrieved from Wikipedia in FEVER.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Claims and Evidence">
  <data key="d0">Claims and Evidence</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d2">FEVER involves reasoning over evidence to determine if claims are supported or refuted.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG-Token">
  <data key="d0">RAG-Token</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d2">RAG-Token model performs better than RAG-Sequence in generating Jeopardy questions, as shown by evaluation metrics.&lt;SEP&gt;RAG-Token outperforms RAG-Sequence in generating more accurate and specific Jeopardy questions, as shown by evaluation metrics.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Question Generation and Fact Verification">
  <data key="d0">Question Generation and Fact Verification</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d2">Parametric memory enables the models to complete titles and facts, indicating stored knowledge within the model parameters.&lt;SEP&gt;Parametric memory supports the models in completing titles and facts internally, reflecting stored knowledge within the model parameters.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="applications">
  <data key="d0">applications</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d2">Replacing indices at test time allows RAG to incorporate up-to-date information without retraining.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Previous Work">
  <data key="d0">Previous Work</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d2">Prior research demonstrates that incorporating retrieval improves NLP task performance, supporting the current work's premise.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Implications">
  <data key="d0">Implications</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d2">Advanced NLP models could automate tasks, influencing employment and economic structures.&lt;SEP&gt;Advanced NLP models could automate various tasks, influencing employment patterns and economic sectors.&lt;SEP&gt;Understanding alignment issues informs safe deployment of AI models, highlights limitations in current evaluation methods, and emphasizes the need for improved alignment techniques.&lt;SEP&gt;Automating complex code tasks in HPC can increase productivity, reduce errors, and optimize performance in scientific applications.</data>
  <data key="d1">Applications/Implications</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="URL https://openreview.net/forum?id=r1l73iRqKm">
  <data key="d0">URL https://openreview.net/forum?id=r1l73iRqKm</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Dinan contributed to conversational AI research, focusing on knowledge-powered agents.&lt;SEP&gt;Dinan contributed to knowledge-powered conversational agents in NLP research.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Matthew Dunn">
  <data key="d0">Matthew Dunn</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Dunn introduced SearchQA, a dataset augmented with search engine context for Q&amp;A tasks.&lt;SEP&gt;Dunn's SearchQA dataset augmented with search engine context advances NLP question answering.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="arXiv:1704.05179">
  <data key="d0">arXiv:1704.05179</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Dunn introduced SearchQA, a dataset augmented with search engine context for Q&amp;A tasks.&lt;SEP&gt;Dunn's SearchQA dataset augmented with search engine context advances NLP question answering.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="https://arxiv.org/abs/1705.08807">
  <data key="d0">https://arxiv.org/abs/1705.08807</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">The paper discusses when AI might exceed human performance, providing evidence and hypotheses.&lt;SEP&gt;The paper discusses when AI might surpass human performance, providing evidence and hypotheses.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Better Metric">
  <data key="d0">Better Metric</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d2">The improved metric provides a more accurate assessment of question generation systems' quality, guiding better system development.&lt;SEP&gt;The new metric aims to improve the evaluation of question generation systems, making assessments more accurate and meaningful.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Contextual Influence">
  <data key="d0">Contextual Influence</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d2">The influence of context on language models' factual predictions highlights the importance of context in NLP applications.&lt;SEP&gt;The influence of context on language models' predictions highlights the importance of contextual information in NLP applications.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="GPT">
  <data key="d0">GPT</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d2">GPT employs unsupervised multitask learning to enhance language understanding capabilities.&lt;SEP&gt;GPT employs unsupervised multitask learning to improve its language understanding and generation capabilities.&lt;SEP&gt;GPT models are autoregressive language models that generate the next token based on previous tokens, producing contextually relevant text.&lt;SEP&gt;GPT models are autoregressive language models that generate the next word in a sequence based on previous words, mapping token sequences to vectors and generating contextually relevant content.</data>
  <data key="d1">Core Concepts</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Transformers">
  <data key="d0">Transformers</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-861fc8218eac993fbe13b418ec4b837c&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d2">A neural network architecture relying solely on attention mechanisms, revolutionizing sequence modeling tasks.&lt;SEP&gt;A neural network architecture used for generating unit test cases from source code and context.&lt;SEP&gt;The attention mechanism is fundamental to the transformer architecture, enabling models to weigh input features dynamically.&lt;SEP&gt;A neural network architecture utilizing self-attention mechanisms, foundational for modern NLP models like GPT and BERT.&lt;SEP&gt;Transformers are a deep learning architecture that utilizes self-attention mechanisms to process sequential data efficiently, foundational for modern NLP models.</data>
  <data key="d1">Methodologies</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Scene Description">
  <data key="d0">Scene Description</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d2">Diverse beam search improves the generation of complex scene descriptions by encouraging varied outputs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu Chang, Zhiguo Wang, Tim Klinger, Gerald Tesauro, Murray Campbell">
  <data key="d0">Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu Chang, Zhiguo Wang, Tim Klinger, Gerald Tesauro, Murray Campbell</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d2">Research on evidence aggregation techniques to improve answer ranking accuracy.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jason Weston, Emily Dinan, and Alexander Miller">
  <data key="d0">Jason Weston, Emily Dinan, and Alexander Miller</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d2">Research on improving dialogue response generation through sequence refinement techniques.&lt;SEP&gt;Research on improving dialogue response generation through sequence refinement.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Code Completion, Summarization, Translation, Lookup">
  <data key="d0">Code Completion, Summarization, Translation, Lookup</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Tasks commonly performed by LLMs in software development, demonstrating their ability to understand and generate code in various contexts.&lt;SEP&gt;These are common tasks for LLMs in software development, demonstrating their versatility in understanding and generating code across different activities.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Scientific and Parallel Computing Tasks">
  <data key="d0">Scientific and Parallel Computing Tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The specific set of 420 coding tasks in ParEval designed to test models' abilities in scientific and parallel computing contexts.&lt;SEP&gt;The specific set of 420 coding tasks used in ParEval to test models' capabilities in scientific and parallel programming.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Open-source and Closed-source Language Models">
  <data key="d0">Open-source and Closed-source Language Models</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The collection of various state-of-the-art language models evaluated using the ParEval benchmark, including both open- and closed-source models.&lt;SEP&gt;The models evaluated using the ParEval benchmark, including various state-of-the-art language models, both open- and closed-source.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Programming Models">
  <data key="d0">Parallel Programming Models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Different computational models such as MPI, OpenMP, CUDA, etc., used to assess the models' ability to generate code suitable for various parallel computing paradigms.&lt;SEP&gt;Different models such as MPI, OpenMP, CUDA, etc., used to assess the models' ability to generate code suitable for various parallel computing paradigms.&lt;SEP&gt;Models such as OpenMP, MPI, CUDA, and others used to evaluate Copilot's ability to generate parallel code in C++, Fortran, Python, and Julia.&lt;SEP&gt;Parallel programming models in C++, Fortran, Python, and Julia are targeted by the study to evaluate AI-generated code effectiveness.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-5adc1bc605f86b4e3648d3a3ef16f8a3&lt;SEP&gt;chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Generation Effectiveness">
  <data key="d0">Code Generation Effectiveness</data>
  <data key="d1">Results</data>
  <data key="d2">The outcomes measuring how well each language model produces correct, efficient, and high-quality parallel code across different problem types and models.&lt;SEP&gt;The study reports on how effectively each language model generates correct and performant parallel code across multiple problem types and models.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Reasoning and Planning in AI">
  <data key="d0">Reasoning and Planning in AI</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Theoretical frameworks explaining how LLMs approach complex tasks like parallel code generation, involving reasoning about data, algorithms, and models.&lt;SEP&gt;Underlying theoretical frameworks that explain how LLMs approach complex tasks such as parallel code generation.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Performance Bugs, Race Conditions, Deadlocks">
  <data key="d0">Performance Bugs, Race Conditions, Deadlocks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Common issues in parallel programming that pose challenges for code correctness and reliability, highlighting the complexity of generating bug-free parallel code.&lt;SEP&gt;Common issues in parallel programming, highlighting the challenges LLMs face when generating reliable parallel code.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Implications for Software Development">
  <data key="d0">Implications for Software Development</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Findings suggest how LLMs can assist developers in writing complex parallel code, potentially improving productivity and reducing errors in high-performance computing environments.&lt;SEP&gt;Findings suggest potential for LLMs to assist developers in writing complex parallel code, improving productivity, and reducing errors in high-performance computing environments.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="benchmarks">
  <data key="d0">benchmarks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Benchmarks are standardized problem sets designed to evaluate the ability of LLMs to generate correct, efficient, and scalable parallel code across various models, algorithms, and environments.&lt;SEP&gt;Benchmarks are standardized sets of problems or tasks designed to evaluate the performance of LLMs in generating parallel code across different models, algorithms, and environments.&lt;SEP&gt;The set of computational tasks or applications evaluated to measure performance improvements.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="metrics">
  <data key="d0">metrics</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Metrics are quantitative measures used to assess the correctness, performance, and scalability of code generated by LLMs, including novel metrics like speedup n@k and efficiency n@k.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Code Generation Evaluation (ParEval)">
  <data key="d0">Parallel Code Generation Evaluation (ParEval)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A benchmark designed to evaluate the ability of LLMs to generate parallel code across various problem types and execution models using standardized prompts and evaluation techniques.&lt;SEP&gt;ParEval is a benchmark designed to evaluate how well LLMs generate parallel code across various computational problem types and execution models, providing a comprehensive assessment framework.&lt;SEP&gt;ParEval is a benchmark designed to evaluate the ability of large language models (LLMs) to generate parallel code and assess the runtime performance and scalability of the generated code.&lt;SEP&gt;ParEval is a comprehensive benchmark designed to evaluate LLMs' ability to generate parallel code across twelve computational problem types and seven execution models, providing a standardized framework for assessment.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="computational problem types">
  <data key="d0">computational problem types</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The twelve different computational problem types are specific problem categories used to evaluate the versatility and correctness of LLM-generated parallel code, covering diverse algorithms and problem structures.&lt;SEP&gt;The twelve different computational problem types are specific types of problems used to evaluate LLMs' ability to generate parallel code, covering a range of algorithms and problem structures.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="execution models">
  <data key="d0">execution models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Execution models refer to different paradigms or frameworks (serial, OpenMP, CUDA/HIP, MPI) used in parallel programming, impacting how code is generated and its performance.&lt;SEP&gt;The seven execution models (serial, OpenMP, Kokkos, MPI, MPI+OpenMP, CUDA, HIP) represent different paradigms of parallel programming tested to assess LLMs' adaptability and performance across various environments.&lt;SEP&gt;The seven execution models (serial, OpenMP, Kokkos, MPI, MPI+OpenMP, CUDA, HIP) represent different parallel programming paradigms tested to assess LLMs' versatility and performance in generating code.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="state-of-the-art LLMs">
  <data key="d0">state-of-the-art LLMs</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study evaluates multiple leading LLMs, both open- and closed-source, to determine their proficiency and limitations in generating parallel code, with GPT-3.5 performing best among tested models.&lt;SEP&gt;The study evaluates several advanced language models, both open- and closed-source, to determine their effectiveness and limitations in parallel code generation, including GPT-3.5.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="performance and scalability">
  <data key="d0">performance and scalability</data>
  <data key="d1">Results</data>
  <data key="d2">The generated parallel code by LLMs often exhibits poor speedup and efficiency, indicating limitations in current models' ability to produce performant and scalable parallel code.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="translation between execution models">
  <data key="d0">translation between execution models</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study investigates how effectively LLMs can translate code between different parallel execution models, finding that correct implementations in one model can improve performance in others, especially for smaller models.&lt;SEP&gt;The study investigates how well LLMs can translate code between different parallel execution models and how this affects correctness, performance, and scalability, finding that correct implementations in one model can improve translation to others.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="research questions">
  <data key="d0">research questions</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The paper explores key questions about the capabilities, challenges, and limitations of current LLMs in generating and translating parallel code, focusing on correctness, performance, and scalability.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="transformer-based models">
  <data key="d0">transformer-based models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Transformer models, introduced in 2017, are the foundational architecture for most large language models, relying on self-attention mechanisms to model sequential data like text and code.&lt;SEP&gt;Transformer models, introduced in 2017, form the basis for most large language models, utilizing self-attention mechanisms to model sequential data like text and code.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="self-attention mechanism">
  <data key="d0">self-attention mechanism</data>
  <data key="d1">Tools</data>
  <data key="d2">A core component of transformer architectures, self-attention allows models to weigh the importance of different tokens in a sequence, enabling modeling of long-range dependencies.&lt;SEP&gt;Self-attention is a core component of transformer architectures, enabling the model to weigh the importance of different tokens in a sequence, facilitating modeling of long-range dependencies.&lt;SEP&gt;A core component of transformer models that allows the network to weigh different parts of the input sequence adaptively, improving modeling of long-range dependencies.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="large corpus of code">
  <data key="d0">large corpus of code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A vast collection of source code used to train LLMs, enabling them to learn patterns and structures necessary for code generation.&lt;SEP&gt;A vast dataset of source code used to train LLMs, allowing them to learn patterns, syntax, and structures necessary for code generation.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="code generation">
  <data key="d0">code generation</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">Generating code capable of reacting to runtime uncertainties, possibly using frameworks like Legion or StarPU.&lt;SEP&gt;The activity focuses on evaluating the ability of LLMs to generate correct, efficient, and scalable parallel code across various programming models and problem types.&lt;SEP&gt;The primary activity examined is the ability of LLMs to generate correct, efficient, and scalable parallel code across different models and programming paradigms.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="correctness and performance metrics">
  <data key="d0">correctness and performance metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics such as pass@k, speedup n@k, and efficiency n@k are used to quantify the accuracy and performance of generated code.&lt;SEP&gt;Metrics to evaluate generated code include correctness (pass@k) and performance indicators like speedup and efficiency, providing quantitative assessments.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="limitations">
  <data key="d0">limitations</data>
  <data key="d1">Limitations</data>
  <data key="d2">Current LLMs struggle with generating high-quality parallel code, especially for complex or unstructured problems, and exhibit limited scalability and performance in generated code.&lt;SEP&gt;Current LLMs struggle with generating high-quality parallel code, especially for complex, unstructured problems, and often produce code with poor scalability and performance.&lt;SEP&gt;Most current LLMs exhibit difficulty in producing high-quality, performant parallel code, especially for unstructured or complex problems, and often lack scalability.&lt;SEP&gt;Limitations refer to the constraints and shortcomings associated with the new technology, including issues related to code quality, dataset requirements, and overreliance on AI suggestions.&lt;SEP&gt;Current issues include improving MPI utilization, reducing memory overhead, enhancing scalability, supporting C/C++, and addressing dynamic applications.&lt;SEP&gt;Current limitations include improving MPI utilization, reducing memory overhead, enhancing scalability, supporting C/C++, and addressing dynamic applications.&lt;SEP&gt;Current models are constrained by dataset quality, model size, and the inherent difficulty of programming tasks, and they may not fully capture complex or nuanced programming requirements.&lt;SEP&gt;Current models have limitations in fully capturing complex programming tasks, and their performance depends on dataset quality, model size, and the number of samples generated.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="correctness">
  <data key="d0">correctness</data>
  <data key="d1">Results</data>
  <data key="d2">Correctness assesses whether the generated parallel code functions as intended, matching expected outputs and behaviors.&lt;SEP&gt;Correctness evaluates whether the generated parallel code functions as intended and produces correct outputs.&lt;SEP&gt;Correctness of generated code is evaluated using pass@k metrics, indicating whether the models produce valid code solutions for given prompts.&lt;SEP&gt;The accuracy of generated code is measured by pass@k, indicating how often models produce correct solutions within multiple attempts.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="scalability">
  <data key="d0">scalability</data>
  <data key="d1">Results</data>
  <data key="d2">Scalability assesses how well the parallel code performs as problem size or hardware resources increase, reflecting its practical utility.&lt;SEP&gt;Scalability measures how well the parallel code performs as the computational load or hardware resources increase.&lt;SEP&gt;Scalability refers to how well the generated parallel code performs as problem size or hardware resources increase, indicating the code's effectiveness in real-world parallel applications.&lt;SEP&gt;Scalability refers to the ability of the generated parallel code to effectively utilize increased computational resources, measured by speedup and efficiency metrics.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Token in a sequence">
  <data key="d0">Token in a sequence</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A token in a sequence refers to a basic unit of text processed by language models, representing parts of words, words, or subwords, used in modeling text data.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Transformer-based models">
  <data key="d0">Transformer-based models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Transformer-based models are neural network architectures that utilize self-attention mechanisms to model sequential data effectively, especially in NLP tasks.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Large Language Models for Code">
  <data key="d0">Large Language Models for Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Large Language Models (LLMs) trained on extensive code corpora to generate or understand programming code, often fine-tuned for specific tasks.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Pre-training corpus">
  <data key="d0">Pre-training corpus</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The pre-training corpus is the large dataset of text or code used to initially train LLMs, including sources like The Stack or The Pile, covering diverse programming languages and natural language.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Nucleus Sampling">
  <data key="d0">Nucleus Sampling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A sampling technique that selects tokens based on cumulative probability, promoting diversity and quality in generated code outputs.&lt;SEP&gt;A sampling technique used during code generation to select tokens based on cumulative probability, promoting diversity in outputs.&lt;SEP&gt;Nucleus sampling, also called top-p sampling, is a token selection strategy that samples from the smallest set of tokens whose cumulative probability exceeds a threshold p, promoting diverse and representative outputs.&lt;SEP&gt;Nucleus sampling (top-p) involves selecting tokens from the smallest set whose cumulative probability exceeds p, balancing diversity and relevance in generated text.&lt;SEP&gt;Nucleus sampling selects tokens based on a cumulative probability threshold p, enabling more meaningful cut-offs and diverse outputs by considering the distribution's tail.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Model Temperature">
  <data key="d0">Model Temperature</data>
  <data key="d1">Variables</data>
  <data key="d2">Model temperature is a scaling parameter applied to logits before softmax, controlling the randomness and creativity of generated outputs; lower temperatures produce more conservative results, higher temperatures more varied ones.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Benchmarking LLMs for code-related tasks">
  <data key="d0">Benchmarking LLMs for code-related tasks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Benchmarking involves evaluating LLMs on standardized datasets like HumanEval, MBPP, or DS-1000 to assess their code generation capabilities across different tasks and languages.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Applying LLMs to parallel and HPC code">
  <data key="d0">Applying LLMs to parallel and HPC code</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research focusing on adapting, fine-tuning, or evaluating LLMs specifically for parallel and high-performance computing code, including creating specialized models like HPCCoder.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HPCCoder">
  <data key="d0">HPCCoder</data>
  <data key="d1">Tools</data>
  <data key="d2">A model fine-tuned on HPC code designed to generate HPC-specific code, evaluate its ability to generate HPC code, label OpenMP pragmas, and predict performance.&lt;SEP&gt;HPCCoder is a fine-tuned LLM designed specifically for generating and understanding HPC code, including labeling pragmas and predicting performance.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HPC code">
  <data key="d0">HPC code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">High-Performance Computing (HPC) code refers to programming code designed for parallel processing and optimized performance in supercomputing environments.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel code">
  <data key="d0">Parallel code</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Code designed for concurrent execution across CPU and GPU resources to improve performance.&lt;SEP&gt;Code designed to execute multiple computations simultaneously across CPU and GPU resources, used for performance evaluation.&lt;SEP&gt;Parallel code involves programming techniques that enable multiple computations to be executed simultaneously, often used in HPC contexts.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code generation tasks">
  <data key="d0">Code generation tasks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Code generation tasks are benchmarked activities where models produce code snippets or functions based on prompts, used to evaluate their programming capabilities.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HPC-specific tokenizer">
  <data key="d0">HPC-specific tokenizer</data>
  <data key="d1">Tools</data>
  <data key="d2">A tokenizer designed specifically for HPC code, such as TOKOMPILER, to improve tokenization accuracy and model training effectiveness in HPC contexts.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Training datasets">
  <data key="d0">Training datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Datasets like The Stack and The Pile are large corpora of code and natural language used for training LLMs, covering multiple programming languages and applications.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="TOKOMPILER">
  <data key="d0">TOKOMPILER</data>
  <data key="d1">Tools</data>
  <data key="d2">A tokenizer specifically designed for HPC tasks, used to train models like COMPCODER on C, C++, and Fortran code.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="COMPCODER">
  <data key="d0">COMPCODER</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A model trained on C, C++, and Fortran code aimed at HPC code generation and analysis.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="LLMs">
  <data key="d0">LLMs</data>
  <data key="d1">Tools</data>
  <data key="d2">Large Language Models (LLMs) are AI models capable of understanding and generating human-like text, applied here to generate parallel HPC code.&lt;SEP&gt;Large Language Models (LLMs) are advanced AI models capable of generating code, including parallel programming code, but face challenges in accuracy and performance.&lt;SEP&gt;Large Language Models (LLMs) are advanced AI models designed for understanding and generating code, with varying performance across different parallel programming models and problem types.&lt;SEP&gt;Large Language Models (LLMs) are advanced AI models trained to understand, generate, and reason about code, including modeling complex parallel programming models like Kokkos, CUDA, HIP, MPI, and others.&lt;SEP&gt;Large Language Models (LLMs) are AI systems trained on extensive corpora to generate human-like text, but face challenges in staying current and domain-specific knowledge acquisition.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HPC tasks">
  <data key="d0">HPC tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Computational tasks related to High-Performance Computing that are targeted for code generation and verification by LLMs.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Prompts for Parallel Code Generation (4PAREVAL)">
  <data key="d0">Prompts for Parallel Code Generation (4PAREVAL)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A set of 420 carefully designed prompts covering twelve computational problem types and seven execution models, used to systematically evaluate LLMs' code generation capabilities in HPC contexts.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Problems">
  <data key="d0">Problems</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Problems are structured tasks designed to evaluate core computational functionalities through variations, testing understanding and performance.&lt;SEP&gt;Specific instances within each problem type designed to test core functionality and variation, totaling 60 distinct problems (5 per type) for evaluation.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Benchmark">
  <data key="d0">Benchmark</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The collection of prompts, problems, execution models, and evaluation methods constituting the ParEval benchmark to systematically assess LLMs.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Evaluation Framework">
  <data key="d0">Evaluation Framework</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The structured approach combining prompts, problems, execution models, and assessment techniques to evaluate LLMs' ability to generate parallel HPC code.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Discipline">
  <data key="d0">Discipline</data>
  <data key="d1">Disciplines</data>
  <data key="d2">High-Performance Computing, Artificial Intelligence, Programming Languages, Software Engineering, Computational Science</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Correctness">
  <data key="d0">Code Correctness</data>
  <data key="d1">Results</data>
  <data key="d2">The extent to which generated code produces the correct output according to problem specifications, used as a primary evaluation metric.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Efficiency">
  <data key="d0">Code Efficiency</data>
  <data key="d1">Results</data>
  <data key="d2">Assessment of the runtime and resource utilization of generated code, indicating performance quality.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Scalability">
  <data key="d0">Code Scalability</data>
  <data key="d1">Results</data>
  <data key="d2">Evaluation of how well generated code performs as problem size or computational resources increase.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="component counting">
  <data key="d0">component counting</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Component counting involves quantifying elements within a system or dataset, often used in computational and analytical contexts.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Geometry">
  <data key="d0">Geometry</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Geometry involves the study of shapes, sizes, and properties of space, including the computation of geometric properties like convex hulls.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Convex Hull">
  <data key="d0">Convex Hull</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The convex hull is the smallest convex polygon that contains all points in a given set, used in computational geometry.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Fourier Transform">
  <data key="d0">Fourier Transform</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Fourier Transform is a mathematical technique to analyze the frequency components of signals, with applications in standard and inverse transforms.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Transform">
  <data key="d0">Transform</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Transform refers to mapping a constant function to each element of an array, used in data processing and signal analysis.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Problem Variations">
  <data key="d0">Problem Variations</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Variations of problems are small modifications designed to assess the robustness of problem-solving capabilities in models.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Prompt">
  <data key="d0">Prompt</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A prompt is a structured instruction or description provided to a language model to generate code or responses, tailored for different execution models.&lt;SEP&gt;A sequence of tokens or instructions designed to guide the LLM's output for a specific task, either as a task description alone or with additional examples.&lt;SEP&gt;Prompts are carefully crafted inputs designed to elicit specific responses from LLMs, especially in grey-box domain adaptation.&lt;SEP&gt;Natural language descriptions provided to the model to generate code, such as function headers and comments.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-daac5179ef8fa77fe775da37eb1276f3&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="C++&quot;, ">
  <data key="d0">C++", </data>
  <data key="d1">Tools</data>
  <data key="d2">C++ is a programming language used in prompts for serial, OpenMP, MPI, and MPI+OpenMP models, utilizing standard data structures.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CUDA&quot;, ">
  <data key="d0">CUDA", </data>
  <data key="d1">Tools</data>
  <data key="d2">CUDA is a parallel computing platform and programming model for GPU programming, used in prompts for GPU-based code generation.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HIP&quot;, ">
  <data key="d0">HIP", </data>
  <data key="d1">Tools</data>
  <data key="d2">HIP is a GPU programming platform similar to CUDA, used in prompts for GPU code generation in different models.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Kokkos">
  <data key="d0">Kokkos</data>
  <data key="d1">Tools</data>
  <data key="d2">A C++ library aimed at performance portability across diverse hardware architectures, providing abstractions for parallel execution and memory management.&lt;SEP&gt;A C++ library aimed at performance portability across diverse hardware architectures, supporting parallel execution and memory management.&lt;SEP&gt;A C++ library designed to enable performance portability across manycore architectures through polymorphic memory access patterns.&lt;SEP&gt;Kokkos is a high-level performance portability library that enables writing parallel code compatible across diverse hardware architectures."|&gt;&lt;SEP&gt;Kokkos is a high-level programming model aimed at performance portability across different hardware architectures."|&gt;&lt;SEP&gt;Kokkos is a high-level, cross-platform parallel programming library that abstracts hardware details, facilitating parallel code development across architectures.&lt;SEP&gt;Kokkos is a high-level, shared memory parallel programming model that abstracts hardware-specific details to facilitate parallel code development.&lt;SEP&gt;Kokkos is a parallel programming model designed to enable performance portability across different hardware architectures, and is used as a benchmark for LLMs' ability to model such code.&lt;SEP&gt;Kokkos is a parallel programming model designed to enable performance portability across hardware architectures, used here as a benchmark for LLMs' ability to model such code.&lt;SEP&gt;Kokkos is a performance portability library evaluated for code generation and translation capabilities.&lt;SEP&gt;Kokkos is a performance portability library for writing parallel code that can run efficiently across different hardware architectures, used for translating code between models.&lt;SEP&gt;Kokkos is a performance portability library for writing portable parallel code across different hardware architectures, used here for translating code between execution models.&lt;SEP&gt;Kokkos is a performance portability library providing data structures like Kokkos::View for parallel computations.&lt;SEP&gt;A performance portability library that allows code to run efficiently across different hardware architectures, aligned with PPL's goals.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Kokkos::View">
  <data key="d0">Kokkos::View</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Kokkos::View is a data structure used for parallel array management in Kokkos, facilitating high-performance computing.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Array">
  <data key="d0">Array</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Arrays are data structures used to store sequences of elements, fundamental in programming and computational tasks.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Partial Minimums">
  <data key="d0">Partial Minimums</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Partial minimums refer to computing the minimum value up to each index in an array, a common operation in algorithms.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Programming">
  <data key="d0">Parallel Programming</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Parallel programming involves executing multiple computations simultaneously to improve efficiency, utilizing models like CUDA, HIP, MPI, etc.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Component Counting">
  <data key="d0">Component Counting</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Component counting involves quantifying elements within a system or dataset, often used in computational and analytical contexts.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Prompts">
  <data key="d0">Prompts</data>
  <data key="d1">Tools</data>
  <data key="d2">A prompt is a structured instruction or description provided to a language model to generate code or responses, tailored for different execution models.&lt;SEP&gt;The input prompts used to generate code samples, serving as the basis for performance measurement and comparison.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="C++">
  <data key="d0">C++</data>
  <data key="d1">The C++ programming language</data>
  <data key="d2">A widely used high-performance programming language supporting procedural, object-oriented, and generic programming paradigms, commonly used in systems and high-performance computing.&lt;SEP&gt;A widely used programming language known for its performance and system-level capabilities, used in various high-performance computing applications.&lt;SEP&gt;C++ is a general-purpose programming language known for performance and system-level programming, authored by Bjarne Stroustrup in 2013.&lt;SEP&gt;C++ is a programming language used in prompts for serial, OpenMP, MPI, and MPI+OpenMP models, utilizing standard data structures.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CUDA">
  <data key="d0">CUDA</data>
  <data key="d1">Tools</data>
  <data key="d2">A parallel computing platform and API developed by NVIDIA, enabling developers to harness GPU acceleration for general-purpose computing tasks.&lt;SEP&gt;A parallel computing platform and API model created by NVIDIA, enabling developers to use GPUs for general purpose processing.&lt;SEP&gt;CUDA is a parallel computing platform and API created by NVIDIA, used as a benchmark object to evaluate LLM performance in modeling GPU-accelerated code.&lt;SEP&gt;CUDA is a parallel computing platform and API evaluated for code translation and generation by language models.&lt;SEP&gt;CUDA is a parallel computing platform and API model created by NVIDIA, used here to evaluate LLM performance in modeling GPU-accelerated code.&lt;SEP&gt;CUDA is a parallel computing platform and API model created by Nvidia, used for developing GPU-accelerated applications, with translation from CUDA to Kokkos examined in the study.&lt;SEP&gt;CUDA is a parallel computing platform and programming model for GPU programming, used in prompts for GPU-based code generation.&lt;SEP&gt;CUDA is a parallel computing platform for Nvidia GPUs, used here for translating code from CUDA to other models like Kokkos.&lt;SEP&gt;CUDA is a parallel computing platform and programming model developed by NVIDIA for GPU acceleration in scientific computing."|&gt;&lt;SEP&gt;CUDA is a parallel computing platform and programming model developed by NVIDIA for GPU acceleration."|&gt;&lt;SEP&gt;A parallel computing platform and API for NVIDIA GPUs, serving as a reference for GPU-specific optimization patterns.&lt;SEP&gt;A parallel computing platform and API for leveraging GPU acceleration, enabling offloading of computations to GPUs for high parallel throughput.&lt;SEP&gt;A parallel computing platform and API model created by NVIDIA, enabling developers to utilize GPU acceleration for computational tasks.&lt;SEP&gt;A parallel computing platform and API model for NVIDIA GPUs, mentioned as a model for GPU optimization patterns.&lt;SEP&gt;CUDA is a parallel computing platform and API developed by NVIDIA that enables direct access to GPU hardware for accelerating computations.&lt;SEP&gt;CUDA is a parallel computing platform and API model created by NVIDIA, enabling direct access to GPU hardware for accelerating computations.&lt;SEP&gt;CUDA is a parallel computing platform and API model for leveraging GPU acceleration, enabling offloading computations to GPUs.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482&lt;SEP&gt;chunk-b943bff32a36cd0ce9ab43893da92b5b&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HIP">
  <data key="d0">HIP</data>
  <data key="d1">Heterogeneous-compute Interface for Portability</data>
  <data key="d2">A C++ Runtime API and Kernel language developed by AMD for writing portable code across AMD and NVIDIA GPUs.&lt;SEP&gt;An API developed by AMD to write portable code that can run efficiently on AMD and NVIDIA GPUs, facilitating cross-platform GPU programming.&lt;SEP&gt;HIP (Heterogeneous-compute Interface for Portability) is a programming model evaluated for code translation tasks.&lt;SEP&gt;HIP is a GPU programming API developed by AMD, similar to CUDA, and used as a comparative object for LLM code modeling performance.&lt;SEP&gt;HIP is a GPU programming API developed by AMD, similar to CUDA, used to assess LLMs' ability to generate correct HIP code.&lt;SEP&gt;HIP is a GPU programming platform similar to CUDA, used in prompts for GPU code generation in different models.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Large Language Models (LLMs)">
  <data key="d0">Large Language Models (LLMs)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Large Language Models (LLMs) are advanced artificial intelligence systems, primarily based on transformer neural network architectures, trained on extensive datasets comprising large-scale text and code corpora. These models are capable of understanding, generating, translating, and summarizing human language and source code with high proficiency. They are utilized across a wide range of natural language processing (NLP) tasks, including semantic parsing, credibility assessment, reasoning, and language understanding, as well as code-related tasks such as code generation, translation, and evaluation of correctness. LLMs like GPT-3 and GPT-4 are prediction-based models that leverage vast amounts of data to produce human-like text and code, influencing various fields such as software engineering and high-performance computing (HPC). These models can be fine-tuned or adapted using prompt tuning techniques to enhance their domain-specific and task-specific capabilities. Their performance is often measured using metrics like pass@1 and pass@k, reflecting their effectiveness in generating accurate solutions. Overall, Large Language Models are extensive neural networks trained on large textual and coding datasets, enabling them to perform a diverse array of language and code understanding and generation tasks with high accuracy and versatility.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-18f91435491c87cd10d4cbb056061eda&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-8184ca90cae86b58652f2117d440bd17&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b&lt;SEP&gt;chunk-6f045498b0e63780c3aef4b9daf795b6&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-04aecdc2586d2c7966e70e02cac846b0&lt;SEP&gt;chunk-4068ec6ee794d8ae5ed33ac825ff37d4&lt;SEP&gt;chunk-c27a9a886dd19125bb1adb49ea7038f7&lt;SEP&gt;chunk-861fc8218eac993fbe13b418ec4b837c&lt;SEP&gt;chunk-fbc178ca51bae28816d191153e754f68&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Llama">
  <data key="d0">Code Llama</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An open foundation model designed for code-related tasks, supporting code generation, understanding, and summarization, developed in 2023.&lt;SEP&gt;Code Llama is an open-source large language model optimized for code generation, with variants of different sizes.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Models Comparison">
  <data key="d0">Models Comparison</data>
  <data key="d1">Results</data>
  <data key="d2">Models are compared based on metrics like pass@1 for code correctness, with details on size and licensing.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="3">
  <data key="d0">3</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The number 3 is a fundamental concept used in various contexts, often representing a quantity, a position in a sequence, or a classification label.&lt;SEP&gt;The number 3 is a fundamental concept used in various contexts, representing quantity, position, or classification.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="MBPP results">
  <data key="d0">MBPP results</data>
  <data key="d1">Results</data>
  <data key="d2">MBPP results are the outcomes obtained from the MBPP benchmark, which evaluates the performance of language models in code generation tasks.&lt;SEP&gt;MBPP results refer to the outcomes obtained from the MBPP benchmark, which assesses code generation capabilities of language models.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Section 7">
  <data key="d0">Section 7</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Section 7 likely refers to a specific part of a report or paper where the evaluation metrics and results are detailed.&lt;SEP&gt;Section 7 refers to a specific part of the document where evaluation metrics, results, and analysis are detailed.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenMP, MPI, MPI+OpenMP, Kokkos, CUDA, HIP">
  <data key="d0">OpenMP, MPI, MPI+OpenMP, Kokkos, CUDA, HIP</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">These are different execution models used as variables to assess the ability of language models to generate or translate code between them.&lt;SEP&gt;These are various parallel execution models and programming frameworks used to evaluate the performance of code generation and translation by language models.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="serial, OpenMP, MPI, CUDA, Kokkos">
  <data key="d0">serial, OpenMP, MPI, CUDA, Kokkos</data>
  <data key="d1">Variables</data>
  <data key="d2">Different execution models used as variables to assess the model's ability to generate or translate parallel code.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Experiment 2">
  <data key="d0">Experiment 2</data>
  <data key="d1">Study Design</data>
  <data key="d2">A specific experiment evaluating how well large language models (LLMs) translate code between different execution models and their performance/scalability.&lt;SEP&gt;An experiment evaluating LLMs' ability to translate code between execution models and assess the scalability and performance of the translated code.&lt;SEP&gt;The second experiment focuses on the ability of language models to translate code from one execution model to another, testing translation effectiveness and accuracy.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Listing 2">
  <data key="d0">Listing 2</data>
  <data key="d1">Tools</data>
  <data key="d2">Listing 2 is an example prompt used to instruct the language model to translate code from one execution model to another.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="sumOfMinimumElements">
  <data key="d0">sumOfMinimumElements</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">sumOfMinimumElements is a function that computes the sum of the minimum elements between two vectors, used here as an example for code translation evaluation.&lt;SEP&gt;sumOfMinimumElements is a sample function used to evaluate code translation accuracy, computing the sum of element-wise minima between vectors.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CodeLlama">
  <data key="d0">CodeLlama</data>
  <data key="d1">Tools</data>
  <data key="d2">CodeLlama models are fine-tuned variants of Llama 2, specialized for code generation, supporting multiple programming languages and infilling.&lt;SEP&gt;CodeLlama models are variants of Llama 2 fine-tuned specifically for code, designed to generate and support code-related tasks.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="StarCoderBase">
  <data key="d0">StarCoderBase</data>
  <data key="d1">Tools</data>
  <data key="d2">A base version of the StarCoder language model used for code generation and translation tasks.&lt;SEP&gt;A base version of the StarCoder language model used for code generation and translation, serving as a benchmark for performance.&lt;SEP&gt;An open-source language model supporting code infilling and custom tokens, based on SantaCoder architecture, with a context length of 8K tokens, used for code generation and comparison.&lt;SEP&gt;StarCoderBase is a 15.5 billion parameter code-focused language model trained on extensive datasets, supporting multiple languages and infilling functionalities.&lt;SEP&gt;StarCoderBase is a 15.5 billion parameter code-focused language model trained on extensive datasets, supporting multiple programming languages and infilling.&lt;SEP&gt;StarCoderBase is a language model supporting code infilling and custom tokens, based on the SantaCoder architecture, with a context length of 8K tokens, and used for code generation tasks.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="MPI">
  <data key="d0">MPI</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">MPI (Message Passing Interface) is a parallel programming framework evaluated in the study for code translation and generation.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized and portable message-passing system designed to function on parallel computing architectures, and is used to assess LLMs' ability to generate correct MPI code.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized and portable message-passing system designed to function on parallel computing architectures, facilitating translation from serial to parallel code.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized message-passing system for parallel computing architectures, and is used to evaluate LLMs' capacity to model MPI code.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized protocol for parallel computing across distributed systems, facilitating translation from serial to MPI-based parallel code.&lt;SEP&gt;Message Passing Interface, a standardized and portable message-passing system designed to function on parallel computing architectures, supporting data transfers and synchronization.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized and portable message-passing system designed to function on parallel computing architectures, enabling processes to communicate and coordinate during computation.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized protocol for communication among processes in parallel computing environments, enabling scalable message passing across distributed systems.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-b943bff32a36cd0ce9ab43893da92b5b&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="MPI+OpenMP">
  <data key="d0">MPI+OpenMP</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A hybrid parallel programming model combining Message Passing Interface and OpenMP for high-performance computing.&lt;SEP&gt;MPI (Message Passing Interface) combined with OpenMP (Open Multi-Processing) is a hybrid programming model for parallel applications.&lt;SEP&gt;MPI+OpenMP is a combined parallel programming model used as an object of study for code translation tasks.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="serial">
  <data key="d0">serial</data>
  <data key="d1">Variables</data>
  <data key="d2">Serial refers to sequential code execution, used as a variable to compare against parallel models in evaluation.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="code translation">
  <data key="d0">code translation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study hypothesizes that language models can effectively translate code between different parallel execution frameworks, and evaluates their performance accordingly.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="The Stack">
  <data key="d0">The Stack</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large dataset comprising 1 trillion tokens, including code from over 80 programming languages, natural language in git commits, and Jupyter notebooks, used for training large language models.&lt;SEP&gt;The Stack is a large dataset comprising 1 trillion tokens, including code from over 80 programming languages, natural language in git commits, and Jupyter notebooks, used for training language models.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Phind-CodeLlama-V2">
  <data key="d0">Phind-CodeLlama-V2</data>
  <data key="d1">Tools</data>
  <data key="d2">A fine-tuned CodeLlama-34B model trained on over 1.5 billion tokens of code data, evaluated on the BigCode leaderboard with a pass@1 score of 71.95, used for code generation and benchmarking.&lt;SEP&gt;Phind-CodeLlama-V2 is a fine-tuned CodeLlama-34B model trained on over 1.5 billion tokens of code data, evaluated on the BigCode Models Leaderboard with a pass@1 score of 71.95, used for code generation and comparison.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="EVALUATION METRICS">
  <data key="d0">EVALUATION METRICS</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Metrics designed to quantify the correctness and performance of language models in code generation, including pass@k and new metrics like speedup and efficiency.&lt;SEP&gt;The evaluation metrics are designed to quantify the correctness and performance of language models in code generation, including pass@k and new metrics like speedup and efficiency.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="speedup n@k">
  <data key="d0">speedup n@k</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric measuring the expected performance speedup of generated code relative to a sequential baseline when using k attempts and n processes or threads, assessing code execution performance.&lt;SEP&gt;speedup n@k measures the expected performance improvement of generated code relative to a sequential baseline when using k attempts and n processes or threads, assessing code execution efficiency.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="efficiency n@k">
  <data key="d0">efficiency n@k</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric evaluating the runtime efficiency of code generated by language models when executed with n processes or threads, relative to a baseline, in parallel or HPC contexts.&lt;SEP&gt;efficiency n@k evaluates the runtime efficiency of code generated by language models when executed with n processes or threads, relative to a baseline.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="benchmarking">
  <data key="d0">benchmarking</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Benchmarking involves systematically testing LLMs on standardized tasks and datasets to compare their performance across different metrics and problem types.&lt;SEP&gt;The process of comparing different language models' code generation capabilities using standardized metrics like pass@k and performance metrics.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="runtime performance">
  <data key="d0">runtime performance</data>
  <data key="d1">Results</data>
  <data key="d2">The efficiency and speedup metrics assess how well the generated code performs in execution, especially in parallel computing environments.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="parallel execution">
  <data key="d0">parallel execution</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The context in which code is executed, particularly in parallel or high-performance computing settings, affecting performance metrics.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="training dataset">
  <data key="d0">training dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The collection of code problems, function signatures, reference solutions, and docstrings used to train models like Codex and Codex-D for code and docstring generation tasks.&lt;SEP&gt;The datasets used to train the models, including the 1 trillion token dataset from The Stack and other code corpora.&lt;SEP&gt;The training dataset comprises code problems, function signatures, reference solutions, and docstrings used to train models like Codex and Codex-D for code and docstring generation.&lt;SEP&gt;The primary dataset used to fine-tune the models, comprising the majority of the data.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="training methodology">
  <data key="d0">training methodology</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of training models on large datasets with specific architectures and fine-tuning procedures to optimize code generation capabilities.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model architecture">
  <data key="d0">model architecture</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Underlying design of models such as SantaCoder and CodeLlama-34B, defining how models process and generate code.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model evaluation">
  <data key="d0">model evaluation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Assessing models like Codex and Codex-D through human grading, automated metrics, and sampling techniques to determine effectiveness.&lt;SEP&gt;The systematic assessment of model performance using metrics like pass@k, speedup, and efficiency across different models and datasets.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model comparison">
  <data key="d0">model comparison</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Comparative analysis of models such as StarCoderBase, Phind-CodeLlama-V2, GPT-3.5, and GPT-4 based on correctness and performance metrics.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sequential Baseline">
  <data key="d0">Sequential Baseline</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A reference performance measure representing the performance of a simple, step-by-step approach used as a comparison for evaluating improvements in model-generated code.&lt;SEP&gt;A reference point representing the performance of a straightforward, step-by-step process used to compare against more advanced or optimized models.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Speedup">
  <data key="d0">Speedup</data>
  <data key="d1">Results</data>
  <data key="d2">A metric that quantifies how much faster a model's code runs compared to a baseline, indicating efficiency gains from parallelization.&lt;SEP&gt;A performance metric quantifying the ratio of execution time between the baseline and the model-generated code, indicating efficiency gains from parallelization.&lt;SEP&gt;A performance metric indicating the ratio of execution time reduction achieved through optimization techniques, with reported speedups ranging from 1.20 to 12.43.&lt;SEP&gt;Performance gains achieved by the PPL approach, with specific examples like the lavaMD benchmark reaching up to 3.5 times speedup due to compiler optimizations.&lt;SEP&gt;Performance improvement metrics comparing different code versions, with specific percentage improvements or slowdowns for kernels.&lt;SEP&gt;Quantitative measure of performance improvement or slowdown between code versions for specific kernels.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2&lt;SEP&gt;chunk-aebb652b359c14534612e14559754bbc&lt;SEP&gt;chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Speedupmax@𝑘">
  <data key="d0">Speedupmax@𝑘</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric estimating the maximum achievable speedup over all resource counts, indicating the peak performance potential of generated code across different hardware configurations.&lt;SEP&gt;A variant of the speedup metric estimating the maximum speedup over all resource counts, providing an upper bound of performance improvement.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Equation (2)">
  <data key="d0">Equation (2)</data>
  <data key="d1">Theoretical Model</data>
  <data key="d2">An equation defining the expected best speedup relative to a sequential baseline for a given prompt, considering multiple samples and resources.&lt;SEP&gt;An equation defining the expected maximum speedup for a specific prompt, considering multiple samples and resources, based on the ratio of the baseline runtime to sample runtimes.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Equation (4)">
  <data key="d0">Equation (4)</data>
  <data key="d1">Theoretical Model</data>
  <data key="d2">An equation estimating the maximum speedup over all resource counts, accounting for different levels of parallel resources.&lt;SEP&gt;An equation estimating the maximum speedup over all resource counts, considering different levels of parallelism, to assess scalability.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Speedup𝑛@𝑘">
  <data key="d0">Speedup𝑛@𝑘</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric that averages the maximum speedup over multiple prompts and samples for a fixed number of resources, reflecting overall model performance in parallel code generation.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Efficiency𝑛@𝑘">
  <data key="d0">Efficiency𝑛@𝑘</data>
  <data key="d1">Variables</data>
  <data key="d2">A measure of how effectively the generated code utilizes parallel resources, calculated as speedup divided by the number of resources, ranging from 0 to 1.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Equation (3)">
  <data key="d0">Equation (3)</data>
  <data key="d1">Theoretical Model</data>
  <data key="d2">An equation that computes the average maximum speedup across all prompts, providing a comprehensive performance metric for the model's code generation capabilities.&lt;SEP&gt;An equation used to define the efficiency𝑛@𝑘, modified to account for the number of attempts and resource utilization in parallel code generation.&lt;SEP&gt;An equation used to define the efficiency𝑛@𝑘, relating the performance and resource utilization in parallel code generation, serving as the basis for calculating efficiency metrics.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc&lt;SEP&gt;chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Equation (5)">
  <data key="d0">Equation (5)</data>
  <data key="d1">Theoretical Model</data>
  <data key="d2">An equation defining efficiency as the ratio of speedup to resources, used to evaluate how well the generated code scales with increasing parallel resources.&lt;SEP&gt;An equation expressing efficiency𝑛@𝑘 as a function of performance, number of processes, and execution time, used to calculate efficiency metrics.&lt;SEP&gt;An explicit formula expressing efficiency𝑛@𝑘 as a function of performance, number of processes, and execution time, operationalizing the efficiency metric.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc&lt;SEP&gt;chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Resources">
  <data key="d0">Resources</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The computing resources, such as processes or threads, over which the speedup and efficiency are measured, impacting the performance evaluation of parallel code.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Samples">
  <data key="d0">Samples</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The individual code samples generated for each prompt, used to assess performance metrics like speedup and efficiency.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Hardware">
  <data key="d0">Hardware</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The physical computing environment, including cores and resources, on which the code is run to assess performance metrics.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Code">
  <data key="d0">Parallel Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Parallel code refers to programs designed to execute multiple computations simultaneously, represented hierarchically in the APT.&lt;SEP&gt;The code generated by models intended to execute tasks in parallel, whose performance is evaluated using speedup and efficiency metrics.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc&lt;SEP&gt;chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="performance of the generated code">
  <data key="d0">performance of the generated code</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The performance of generated code is evaluated using the efficiency𝑛@𝑘 metric, which measures expected best performance efficiency (speedup per process or thread) when given 𝑘 attempts to generate code. It helps understand how well the generated code utilizes parallel resources.&lt;SEP&gt;The performance of generated code is evaluated using the efficiency𝑛@𝑘 metric, which measures the expected best performance efficiency (speedup per process or thread) if the model is given 𝑘 attempts to generate the code. This metric helps understand how well the generated code utilizes parallel resources and its scalability.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="efficiency𝑛@𝑘">
  <data key="d0">efficiency𝑛@𝑘</data>
  <data key="d1">Metrics</data>
  <data key="d2">A performance metric that quantifies the efficiency of generated code in parallel computing environments, normalized by the number of attempts, with values between 0 and 1.0, where 1.0 indicates perfect scaling.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="efficiencymax@𝑘">
  <data key="d0">efficiencymax@𝑘</data>
  <data key="d1">Metrics</data>
  <data key="d2">A related metric to efficiency𝑛@𝑘, representing the maximum achievable efficiency at attempt 𝑘, used to assess the best possible performance of generated code.&lt;SEP&gt;A related performance metric representing the maximum achievable efficiency at attempt 𝑘, used to assess the optimal performance of generated code under given conditions.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel resources">
  <data key="d0">Parallel resources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Resources such as processes or threads that are utilized by generated code, whose efficient use is measured by the efficiency metrics.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sequential code generation">
  <data key="d0">Sequential code generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of generating code that runs sequentially, which can also be evaluated using the same performance metrics as parallel code.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Benchmarks (HumanEval, MBPP, DS-1000)">
  <data key="d0">Benchmarks (HumanEval, MBPP, DS-1000)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Benchmark datasets used to evaluate the performance of generated Python code, specifically examining speedup1@𝑘 to understand efficiency.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="LLMs (Large Language Models)">
  <data key="d0">LLMs (Large Language Models)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Advanced AI models trained on large datasets to analyze, predict, and assist in biological and medical tasks, including structure prediction and natural language processing.&lt;SEP&gt;Models like GPT-3.5, GPT-4, and open-source models used to generate code outputs, with inference performed via HuggingFace or OpenAI API, configured with nucleus sampling and specific token limits.&lt;SEP&gt;Models such as GPT-3.5, GPT-4, and open-source models used to generate code outputs, with inference performed via HuggingFace or OpenAI API, configured with specific sampling parameters.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd&lt;SEP&gt;chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HuggingFace library">
  <data key="d0">HuggingFace library</data>
  <data key="d1">Tools</data>
  <data key="d2">A Python library used to load, run, and manage inference of open-source large language models for code generation tasks.&lt;SEP&gt;A library used with PyTorch to load and run large language models for code generation inference.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenAI API">
  <data key="d0">OpenAI API</data>
  <data key="d1">Tools</data>
  <data key="d2">An API interface used to generate code outputs from GPT-3.5 and GPT-4 models, facilitating large-scale inference with specific sampling settings.&lt;SEP&gt;An API used to generate outputs from GPT-3.5 and GPT-4 models for code generation.&lt;SEP&gt;OpenAI API enables programmatic access to GPT-4 and other models for various AI applications.&lt;SEP&gt;OpenAI API provides programmatic access to models like GPT-4 for various AI applications.&lt;SEP&gt;The OpenAI API provides access to Codex models for code generation and related tasks, enabling developers to integrate AI-powered coding assistance.&lt;SEP&gt;The OpenAI API provides programmatic access to Codex models, enabling developers to incorporate AI code generation capabilities into their applications and workflows.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-d1ed35f0489d99675c43fbbee04d61fd&lt;SEP&gt;chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Nucleus sampling">
  <data key="d0">Nucleus sampling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A probabilistic sampling method used during code generation with p=0.95 to produce diverse outputs while controlling repetitiveness.&lt;SEP&gt;A sampling technique used during code generation with a probability p=0.95 to produce diverse outputs while limiting repetitive generation.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Maximum tokens (1024)">
  <data key="d0">Maximum tokens (1024)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A limit on the number of tokens generated per output to balance completeness and computational cost during code generation.&lt;SEP&gt;The limit on the number of tokens generated in code outputs to balance completeness and computational cost.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Generation configurations (20 samples at temperature 0.2, 200 samples at temperature 0.8)">
  <data key="d0">Generation configurations (20 samples at temperature 0.2, 200 samples at temperature 0.8)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Different sampling settings used to evaluate code performance and accuracy, with the number of samples and temperature affecting diversity and cost.&lt;SEP&gt;Different sampling settings used to generate multiple outputs for evaluation, affecting diversity and cost, with specific parameters for each scenario.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Evaluation of generated code">
  <data key="d0">Evaluation of generated code</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of assessing code correctness, compile status, and execution time using a test harness, involving compilation with GCC, running test scripts, and comparing outputs to baseline implementations.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="ParEval test harness">
  <data key="d0">ParEval test harness</data>
  <data key="d1">Tools</data>
  <data key="d2">A comprehensive suite of scripts that compile, run, and evaluate generated code against correctness and performance benchmarks, recording results for analysis.&lt;SEP&gt;A set of scripts that compile, run, and evaluate generated code against correctness and performance benchmarks, recording results for analysis.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="GCC (version 9.4.0)">
  <data key="d0">GCC (version 9.4.0)</data>
  <data key="d1">Tools</data>
  <data key="d2">A compiler used to compile generated C++ code with optimization flags for correctness and performance testing.&lt;SEP&gt;The compiler used for compiling generated C++ code, with specific flags for optimization and parallelism.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenMPI (version 4.1.1)">
  <data key="d0">OpenMPI (version 4.1.1)</data>
  <data key="d1">Tools</data>
  <data key="d2">An MPI implementation used to compile and run parallel code with MPI during evaluation, supporting distributed execution.&lt;SEP&gt;MPI implementation used for compiling and running MPI-based parallel code in evaluation.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="nvcc (CUDA 12.1.1)">
  <data key="d0">nvcc (CUDA 12.1.1)</data>
  <data key="d1">Tools</data>
  <data key="d2">A compiler for CUDA code used to compile GPU-accelerated programs during evaluation.&lt;SEP&gt;Compiler for CUDA programs used during evaluation to compile GPU-accelerated code.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="hipcc (ROCm 5.7.0)">
  <data key="d0">hipcc (ROCm 5.7.0)</data>
  <data key="d1">Tools</data>
  <data key="d2">A compiler for HIP code, enabling compilation of GPU-accelerated code on AMD hardware for evaluation purposes.&lt;SEP&gt;Compiler used for HIP (Heterogeneous-compute Interface for Portability) programs in evaluation.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="the efficiency𝑛@𝑘">
  <data key="d0">the efficiency𝑛@𝑘</data>
  <data key="d1">Variables</data>
  <data key="d2">A performance metric that quantifies the expected best efficiency of generated code when given 𝑘 attempts, normalized by the number of processes or threads, with values between 0 and 1.0, where 1.0 indicates perfect scaling.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="parallel resources">
  <data key="d0">parallel resources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Resources such as processes or threads that are utilized by generated code, whose effective use is measured by the efficiency metrics to evaluate scalability and resource utilization.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="sequential code generation">
  <data key="d0">sequential code generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of generating code that executes sequentially, which can be evaluated using the same efficiency metrics to compare performance with parallel code.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="benchmarks (HumanEval, MBPP, DS-1000)">
  <data key="d0">benchmarks (HumanEval, MBPP, DS-1000)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Benchmark datasets used to evaluate the performance and efficiency of generated Python code, particularly through metrics like speedup1@𝑘 to compare with human baseline performance.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="evaluation of generated code">
  <data key="d0">evaluation of generated code</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of assessing code correctness, compile success, and runtime performance using the ParEval test harness, involving compilation, execution, and comparison to baseline solutions.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="output">
  <data key="d0">output</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The output includes correctness status, runtime metrics, and evaluation results of generated code, used to assess the performance and accuracy of models in parallel code generation.&lt;SEP&gt;The output refers to the results produced by the program, including correctness, runtime metrics, and performance evaluation in the context of parallel code generation.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="the prompt">
  <data key="d0">the prompt</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The prompt is an instruction or guideline used to generate or evaluate code, serving as a methodological tool for the task.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="generated code">
  <data key="d0">generated code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The code produced by language models during the evaluation, which is analyzed for correctness, adherence to models, and performance.&lt;SEP&gt;The generated code is the primary object of study, assessed for correctness, performance, and adherence to parallel programming models.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="test harness">
  <data key="d0">test harness</data>
  <data key="d1">Tools</data>
  <data key="d2">A test harness is a testing framework that executes the generated code, checks correctness against baselines, and measures runtime performance.&lt;SEP&gt;A testing framework that executes generated code, verifies correctness against baselines, and measures performance metrics.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="sequential baseline">
  <data key="d0">sequential baseline</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A handcrafted, optimal implementation of the task used as a standard for correctness and performance comparison.&lt;SEP&gt;The sequential baseline is a handwritten, optimal implementation used as a standard for correctness and performance comparison.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="parallel programming model">
  <data key="d0">parallel programming model</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A conceptual framework like OpenMP or MPI that defines how code should be structured to run in parallel on multiple cores or nodes.&lt;SEP&gt;A parallel programming model specifies how code should be written to utilize multiple processing cores or nodes, such as OpenMP or MPI.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CPU">
  <data key="d0">CPU</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The CPU is the hardware platform used for executing code, with specifications including AMD EPYC 7763, 2.45 GHz, 64 cores, and 512 GB RAM.&lt;SEP&gt;The central processing unit used for executing code, with specifications including AMD EPYC 7763, 2.45 GHz, 64 cores, and 512 GB RAM, influencing performance.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="GPU">
  <data key="d0">GPU</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Graphics Processing Unit, a specialized processor designed for high parallelism and throughput, used here as a single execution unit for offloading computations.&lt;SEP&gt;Graphics processing units such as NVIDIA A100 80GB and AMD MI50, used for parallel computation, impacting execution speed.&lt;SEP&gt;The GPU is used for parallel computation, with examples including NVIDIA A100 80GB and AMD MI50 GPUs.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b&lt;SEP&gt;chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="pass@1 score">
  <data key="d0">pass@1 score</data>
  <data key="d1">Results</data>
  <data key="d2">A metric indicating the percentage of generated code samples that pass correctness tests on the first attempt, used to evaluate model performance.&lt;SEP&gt;A performance metric indicating the percentage of generated code samples passing correctness tests on the first attempt, used to evaluate model accuracy.&lt;SEP&gt;The pass@1 score measures the probability that the LLM generates a correct code solution on the first attempt, serving as a performance metric across models and problem types.&lt;SEP&gt;The pass@1 score measures the probability that the LLM generates a correct code solution on the first attempt, used to evaluate performance across models and problem types.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="prompt">
  <data key="d0">prompt</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The prompt is an instruction or set of instructions provided to guide code generation or evaluation processes, serving as a methodological tool.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model performance">
  <data key="d0">model performance</data>
  <data key="d1">Results</data>
  <data key="d2">The success rates and pass@1 scores of different models on serial and parallel code generation tasks, indicating their capabilities.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="execution scenario">
  <data key="d0">execution scenario</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Different hardware and software configurations, including CPU, GPU, and threading setups, used to evaluate model outputs.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="timing">
  <data key="d0">timing</data>
  <data key="d1">Variables</data>
  <data key="d2">Measurement of runtime durations during code execution, influencing performance assessment.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="pass@1">
  <data key="d0">pass@1</data>
  <data key="d1">Results</data>
  <data key="d2">A metric indicating the probability that the model's top prediction is correct, used here to evaluate code generation and translation accuracy.&lt;SEP&gt;A metric indicating the probability that the top generated code is correct, used to evaluate code generation and translation accuracy.&lt;SEP&gt;pass@1 is a metric used to evaluate the correctness of code generated by large language models (LLMs) based on multiple attempts, indicating the probability of obtaining a correct answer within a certain number of tries.&lt;SEP&gt;pass@1 is a performance metric measuring the probability that an LLM generates a correct answer on its first attempt, used to evaluate code generation accuracy.&lt;SEP&gt;The success rate of the model generating correct code in the top one sample, indicating precision of the model.&lt;SEP&gt;pass@1 measures the success rate of generating correct code in the top one sample, indicating the model's precision.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Open-source models">
  <data key="d0">Open-source models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Open-source models are LLMs whose source code is publicly available, allowing for community-driven development, customization, and evaluation.&lt;SEP&gt;Open-source models are LLMs with publicly available source code, enabling community development, customization, and comparative evaluation.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Closed-source models">
  <data key="d0">Closed-source models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Closed-source models are proprietary LLMs whose source code is not publicly accessible, often leading to different performance and usage constraints.&lt;SEP&gt;Closed-source models are proprietary LLMs whose source code is not publicly accessible, often resulting in different performance characteristics and access constraints.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CUDA/HIP">
  <data key="d0">CUDA/HIP</data>
  <data key="d1">Tools</data>
  <data key="d2">CUDA and HIP are GPU programming platforms and APIs used to develop parallel code optimized for graphics processing units.&lt;SEP&gt;CUDA and HIP are parallel computing platforms and APIs for GPU programming, with models like CUDA/HIP used to generate GPU-accelerated code.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="MPI/MPI+OpenMP">
  <data key="d0">MPI/MPI+OpenMP</data>
  <data key="d1">Tools</data>
  <data key="d2">MPI (Message Passing Interface) combined with OpenMP enables distributed and shared memory parallel programming, often more complex for LLM code generation.&lt;SEP&gt;MPI (Message Passing Interface) combined with OpenMP supports distributed and shared memory parallel programming, often more complex for LLM code generation.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="cost of generation">
  <data key="d0">cost of generation</data>
  <data key="d1">Variables</data>
  <data key="d2">The cost associated with generating multiple samples or attempts with large models influences the evaluation of pass@k and model selection.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="performance plateau">
  <data key="d0">performance plateau</data>
  <data key="d1">Results</data>
  <data key="d2">A performance plateau indicates the point at which increasing attempts (k) no longer significantly improve the accuracy of generated code, suggesting an upper limit of model capability.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="parallelism">
  <data key="d0">parallelism</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Parallelism involves executing multiple computations simultaneously to improve performance, especially within dynamic control flow structures like loops and branches.&lt;SEP&gt;Parallelism refers to executing multiple computations simultaneously, intrinsic to certain programming models like CUDA/HIP, and influences how easily LLMs can generate correct code.&lt;SEP&gt;Parallelism refers to executing multiple computations simultaneously, intrinsic to models like CUDA/HIP and a challenge for LLMs in modeling complex parallel code.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="structured, dense problems">
  <data key="d0">structured, dense problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Types of computational problems that are data-parallel and easier for LLMs to generate solutions for, such as transform, reduce, and search problems.&lt;SEP&gt;Types of computational problems that are data-parallel and easier for LLMs to solve, including transform, reduce, and search problems.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="unstructured, sparse problems">
  <data key="d0">unstructured, sparse problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Complex computational problems such as sparse linear algebra, FFT, and geometry that are more difficult for LLMs to model due to their irregular data patterns.&lt;SEP&gt;Types of computational problems that are more complex and difficult for LLMs to model accurately, including sparse linear algebra, FFT, geometry, and sort.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="transform problems">
  <data key="d0">transform problems</data>
  <data key="d1">Results</data>
  <data key="d2">Transform problems are the easiest for LLMs to generate correct code for, as they are completely data-parallel, resulting in higher pass@1 scores.&lt;SEP&gt;Transform problems are the simplest for LLMs to generate correct code for because they are fully data-parallel, leading to higher pass@1 scores.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="sparse linear algebra">
  <data key="d0">sparse linear algebra</data>
  <data key="d1">Results</data>
  <data key="d2">Sparse linear algebra is the most challenging problem type for LLMs due to the difficulty in parallelizing sparse computations.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="FFT, geometry, sort, scan">
  <data key="d0">FFT, geometry, sort, scan</data>
  <data key="d1">Results</data>
  <data key="d2">These problem types are generally difficult for LLMs to model correctly, with FFT and geometry being notably problematic due to their complexity in parallelization.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="performance trends">
  <data key="d0">performance trends</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">LLMs perform better on structured, dense problems and struggle with unstructured, sparse problems; larger models tend to handle complex problems like graphs better.&lt;SEP&gt;LLMs perform better on structured, dense problems and worse on unstructured, sparse problems; larger models show improved performance on complex problems like graphs.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model difficulty">
  <data key="d0">model difficulty</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The more a parallel programming model's code differs from its serial counterpart, the more difficult it is for LLMs to generate correct code, especially for models like MPI and MPI+OpenMP.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="reduction problems">
  <data key="d0">reduction problems</data>
  <data key="d1">Results</data>
  <data key="d2">Reduction problems, which involve combining data elements, are generally easier for LLMs to model, reflected in relatively high scores.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="search problems">
  <data key="d0">search problems</data>
  <data key="d1">Results</data>
  <data key="d2">Search problems, which require exploring data structures, are also easier for LLMs, showing better performance.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="stencil, histogram, dense linear algebra">
  <data key="d0">stencil, histogram, dense linear algebra</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">These are structured, dense problems that Phind-V2 and GPT models perform well on, indicating their relative ease for LLMs to model.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="graph problems">
  <data key="d0">graph problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Graph-related problems are among the top types for StarCoder-Base and CodeLlama models, suggesting larger models handle complex graph structures better.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="sparse linear algebra, scan, fft, geometry, sort">
  <data key="d0">sparse linear algebra, scan, fft, geometry, sort</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">These are complex, often unstructured problems that are difficult for LLMs to model accurately, with sparse linear algebra being the most challenging.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="problem type and performance">
  <data key="d0">problem type and performance</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The difficulty of generating correct code increases as the code's divergence from the serial version grows, especially for models like MPI and MPI+OpenMP.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Taxonomies">
  <data key="d0">Taxonomies</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">Classifications and categorizations used to organize concepts, entities, or data within the study.</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Across Thread Counts">
  <data key="d0">Across Thread Counts</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The concept of across thread counts pertains to evaluating the performance and efficiency of parallel computing models and prompts across different numbers of threads and ranks.&lt;SEP&gt;The concept of across thread counts refers to evaluating the performance and efficiency of parallel computing models and prompts across different numbers of threads and ranks, highlighting how resource utilization impacts model performance.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CL-7B">
  <data key="d0">CL-7B</data>
  <data key="d1">Models</data>
  <data key="d2">A specific language model or system named CL-7B used in the experiments.&lt;SEP&gt;A specific language model used in experiments to evaluate parallel code generation and translation performance across different thread counts.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CL-13B">
  <data key="d0">CL-13B</data>
  <data key="d1">Models</data>
  <data key="d2">A language model evaluated for efficiency and scalability in parallel code tasks, part of the set of models tested.&lt;SEP&gt;A specific language model or system named CL-13B used in the experiments.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CL-34B">
  <data key="d0">CL-34B</data>
  <data key="d1">Models</data>
  <data key="d2">A larger version of the CL-34B language model used in the experiments.&lt;SEP&gt;A larger, more capable language model used in the experiments to assess parallel code performance and efficiency.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Figure 7">
  <data key="d0">Figure 7</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A graph illustrating efficiency@1 for MPI, OpenMP, and Kokkos prompts across different ranks and thread counts, comparing model performance.&lt;SEP&gt;A graphical representation showing efficiency@1 for MPI, OpenMP, and Kokkos prompts across rank and thread counts, illustrating model performance.&lt;SEP&gt;Figure 7 illustrates the performance comparison between Poly-Coder and PolyCoder+HPC models, highlighting their sample compilation correctness percentages and build rate correlation.&lt;SEP&gt;Figure 7 presents a performance comparison of different code generation models, highlighting their accuracy in compiling samples and the correlation between build success and correctness rates.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Figure 6">
  <data key="d0">Figure 6</data>
  <data key="d1">Results</data>
  <data key="d2">A graph showing pass@1 scores and speedup metrics for GPT and CodeLlama models across parallel prompts, indicating performance trends.&lt;SEP&gt;A graph showing pass@1 scores and speedup metrics for GPT-3.5, GPT-4, and CodeLlama models on parallel prompts, indicating performance differences.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="speedup 𝑛@1">
  <data key="d0">speedup 𝑛@1</data>
  <data key="d1">Results</data>
  <data key="d2">A measure of how much faster parallel code runs compared to sequential baseline, with GPT-4 achieving 20.28x speedup.&lt;SEP&gt;The ratio of parallel code runtime to sequential baseline, with GPT-4 achieving 20.28x speedup, reflecting performance gains.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="efficiency 𝑛@1">
  <data key="d0">efficiency 𝑛@1</data>
  <data key="d1">Results</data>
  <data key="d2">A measure of resource utilization efficiency in parallel code, with GPT-4 reaching 13% efficiency, indicating room for improvement.&lt;SEP&gt;A measure of resource utilization efficiency in parallel code, with GPT-4 reaching 13%, indicating room for optimization.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Figure 8">
  <data key="d0">Figure 8</data>
  <data key="d1">Results</data>
  <data key="d2">A graph depicting expected maximum speedup and efficiency across resource counts 𝑛, illustrating scalability and resource use.&lt;SEP&gt;A graph showing maximum expected speedup and efficiency across resource counts, illustrating scalability and performance trends.&lt;SEP&gt;Shows the expected maximum speedup and efficiency across resource counts for various models and translation tasks, indicating scalability.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="RQ4">
  <data key="d0">RQ4</data>
  <data key="d1">Research Question</data>
  <data key="d2">How effectively can LLMs translate code between execution models and how scalable is such translated code?&lt;SEP&gt;How well can LLMs translate between execution models, and how performant and scalable is the resulting code?</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Figure 9">
  <data key="d0">Figure 9</data>
  <data key="d1">Results</data>
  <data key="d2">A graph showing pass@1 scores for various LLMs translating serial code to OpenMP, MPI, and CUDA to Kokkos, assessing translation accuracy.&lt;SEP&gt;A graphical comparison of pass@1 scores for various LLMs when translating serial code to OpenMP, MPI, and CUDA to Kokkos, assessing translation accuracy.&lt;SEP&gt;Displays pass@1 scores for models translating between different execution models, highlighting the impact of correct examples on translation accuracy.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="pass@1 for Translation">
  <data key="d0">pass@1 for Translation</data>
  <data key="d1">Results</data>
  <data key="d2">A performance metric indicating the correctness of translated code, used to evaluate translation success.&lt;SEP&gt;Performance metric indicating the correctness of code translation by LLMs for different model and translation pairs.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="serial ⇒ omp">
  <data key="d0">serial ⇒ omp</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code translation from serial to OpenMP, evaluating how well models can generate parallel code from sequential code.&lt;SEP&gt;Code translation from serial to OpenMP, testing models' ability to generate parallel code from sequential code.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="serial ⇒ mpi">
  <data key="d0">serial ⇒ mpi</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code translation from serial to MPI, assessing the models' ability to parallelize serial code.&lt;SEP&gt;Code translation from serial to MPI, evaluating models' ability to produce MPI parallel code.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="cuda ⇒ kokkos">
  <data key="d0">cuda ⇒ kokkos</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code translation from CUDA to Kokkos, assessing models' ability to translate code between different parallel frameworks.&lt;SEP&gt;Code translation from CUDA to Kokkos, testing translation capabilities between different parallel execution models.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Code Translation">
  <data key="d0">Parallel Code Translation</data>
  <data key="d1">Methodology</data>
  <data key="d2">The process of converting code between different parallel execution models using LLMs, evaluated for correctness and performance.&lt;SEP&gt;The process of converting code from one parallel execution model to another using LLMs, evaluated for correctness and performance.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Efficiency@1">
  <data key="d0">Efficiency@1</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric measuring how efficiently models utilize parallel resources, with values ranging from 0 to 1, indicating resource utilization effectiveness.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Speedup 𝑛@1">
  <data key="d0">Speedup 𝑛@1</data>
  <data key="d1">Variables</data>
  <data key="d2">A measure of performance gain of parallel code over sequential baseline, with higher values indicating better scalability.&lt;SEP&gt;A performance measure indicating how much faster parallel code runs compared to the sequential baseline, with higher values indicating better scalability.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Efficiency 𝑛@1">
  <data key="d0">Efficiency 𝑛@1</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric measuring resource utilization efficiency of models in parallel code, values range from 0 to 1, higher indicating better resource use.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="pass@1 scores">
  <data key="d0">pass@1 scores</data>
  <data key="d1">Results</data>
  <data key="d2">Pass@1 scores indicate the likelihood that the first generated code attempt is correct, used here to evaluate code translation and generation accuracy.&lt;SEP&gt;Pass@1 scores measure the likelihood that an LLM's generated code is correct on the first attempt, used here to evaluate code translation and generation quality.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="speedup@1">
  <data key="d0">speedup@1</data>
  <data key="d1">Results</data>
  <data key="d2">Speedup@1 evaluates the performance gain of parallel code over serial code, indicating scalability and effectiveness.&lt;SEP&gt;Speedup@1 evaluates the performance improvement of generated parallel code over serial code, assessing the efficiency of LLM-generated code.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="serial code">
  <data key="d0">serial code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Serial code is sequential code executed on a single processing unit, serving as the baseline for translation and comparison in the study.&lt;SEP&gt;Serial code refers to sequential programming code executed on a single processor, serving as the baseline for translation to parallel models.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="efficiency@1">
  <data key="d0">efficiency@1</data>
  <data key="d1">Results</data>
  <data key="d2">Efficiency@1 measures the runtime performance of generated parallel code relative to serial code, assessing how well the code performs.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="correct implementations">
  <data key="d0">correct implementations</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Correct implementations refer to code that accurately performs the intended parallel computation, which improves LLMs' ability to generate correct parallel code.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="National Energy Research Scientific Computing Center">
  <data key="d0">National Energy Research Scientific Computing Center</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A U.S. Department of Energy Office of Science User Facility providing high-performance computing resources for research activities.&lt;SEP&gt;A U.S. Department of Energy Office of Science User Facility providing high-performance computing resources for scientific research activities.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="NERSC">
  <data key="d0">NERSC</data>
  <data key="d1">Tools</data>
  <data key="d2">A high-performance computing facility used to support scientific research projects.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="DDR-ERCAP0025593">
  <data key="d0">DDR-ERCAP0025593</data>
  <data key="d1">Variables</data>
  <data key="d2">A specific award identifier associated with the use of NERSC resources for research evaluation.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Big Code Models Leaderboard">
  <data key="d0">Big Code Models Leaderboard</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A benchmarking platform to evaluate the performance of large code models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HIP Documentation">
  <data key="d0">HIP Documentation</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Official documentation providing technical details about HIP (Heterogeneous-compute Interface for Portability) framework.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Zero-Shot Replication Framework">
  <data key="d0">Zero-Shot Replication Framework</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A framework designed to facilitate replication of experiments without prior training on specific datasets.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang">
  <data key="d0">Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Researchers investigating transformer-based approaches for source code summarization.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Transformer-based Approach">
  <data key="d0">Transformer-based Approach</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model architecture utilizing transformer technology to generate source code summaries.&lt;SEP&gt;A model utilizing transformer architecture to generate summaries of source code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Source Code Summarization">
  <data key="d0">Source Code Summarization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The activity of generating concise descriptions of source code functionality, often using machine learning models.&lt;SEP&gt;The activity of generating concise descriptions of source code to explain functionality, often using machine learning models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Toufique Ahmed and Prem Devanbu">
  <data key="d0">Toufique Ahmed and Prem Devanbu</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Researchers exploring learning techniques for code summarization from limited datasets.&lt;SEP&gt;Researchers exploring methods for learning code summarization from small and local datasets.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Learning from Small and Local Datasets">
  <data key="d0">Learning from Small and Local Datasets</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A strategy to train models effectively using limited and localized data sources.&lt;SEP&gt;An approach to training models effectively with limited and localized data sources.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="SantaCoder">
  <data key="d0">SantaCoder</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A neural code generation model designed to generate code snippets, emphasizing not reaching for overly ambitious goals.&lt;SEP&gt;A neural network-based code generation model that emphasizes modest goals rather than reaching for overly ambitious performance.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jacob Austin, Augustus Odena, Maxwell I. Nye, Maarten Bosma, Henryk Michalewski, et al.">
  <data key="d0">Jacob Austin, Augustus Odena, Maxwell I. Nye, Maarten Bosma, Henryk Michalewski, et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Researchers studying program synthesis capabilities of large language models to generate code.&lt;SEP&gt;Researchers studying program synthesis using large language models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Program Synthesis with Large Language Models">
  <data key="d0">Program Synthesis with Large Language Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of automatically generating programs or code snippets based on specifications using advanced language models.&lt;SEP&gt;The process of automatically generating programs or code snippets from specifications using advanced language models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Language Models are Few-Shot Learners">
  <data key="d0">Language Models are Few-Shot Learners</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A foundational paper demonstrating the ability of large language models to perform tasks with minimal examples.&lt;SEP&gt;A foundational theory demonstrating that large language models can perform tasks with minimal examples, highlighting few-shot learning capabilities.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="MultiPL-E">
  <data key="d0">MultiPL-E</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark suite for evaluating neural code generation across multiple programming languages.&lt;SEP&gt;A comprehensive benchmark designed to evaluate neural code generation across multiple programming languages.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="LM4HPC">
  <data key="d0">LM4HPC</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Applying language models to high-performance computing environments to improve parallel code correctness and efficiency.&lt;SEP&gt;Applying language models to high-performance computing to improve efficiency and correctness in parallel programming.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Evaluating Large Language Models Trained on Code">
  <data key="d0">Evaluating Large Language Models Trained on Code</data>
  <data key="d1">Study Design</data>
  <data key="d2">A comprehensive evaluation framework assessing the performance of language models like Codex, GPT-Neo, TabNine, and GPT-J on code synthesis tasks, including various metrics and experimental setups.&lt;SEP&gt;A research framework assessing the performance of language models like Codex, GPT-Neo, and TabNine on code generation tasks, including evaluation metrics and experimental setup.&lt;SEP&gt;A study investigating the challenges and effectiveness of benchmarking large language models specifically trained on programming code.&lt;SEP&gt;Research assessing the performance and capabilities of large language models specifically trained on source code.&lt;SEP&gt;Research assessing the performance, accuracy, and capabilities of large language models trained specifically on source code datasets.&lt;SEP&gt;The activity of systematically assessing the performance of language models in code generation tasks.&lt;SEP&gt;Research discipline focused on assessing the performance and accuracy of language models trained on code datasets.&lt;SEP&gt;Research discipline focusing on the evaluation of language models trained on code datasets.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879&lt;SEP&gt;chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-758b1575f8afe059a0beaf2570df4bd6&lt;SEP&gt;chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, et al.">
  <data key="d0">Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Researchers evaluating the effectiveness of large language models trained on code datasets.&lt;SEP&gt;Researchers investigating the effectiveness of large language models trained on code for various code-related tasks.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2107.03374">
  <data key="d0">arXiv:2107.03374</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint report presenting evaluations of large language models trained on code datasets.&lt;SEP&gt;An arXiv preprint reporting on the evaluation of large language models trained on code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="High-Performance Computing">
  <data key="d0">High-Performance Computing</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A field focused on maximizing computational performance for scientific and engineering applications.&lt;SEP&gt;A scientific discipline focused on developing and utilizing computational systems for large-scale scientific computations.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Language Model Application in HPC">
  <data key="d0">Language Model Application in HPC</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using language models to enhance code correctness, detect concurrency issues, and optimize performance in high-performance computing environments.&lt;SEP&gt;Using language models to enhance productivity and correctness in high-performance computing tasks.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Language Models in Code Tasks">
  <data key="d0">Language Models in Code Tasks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The activity of applying large language models to tasks such as code generation, summarization, and code analysis.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jan Leike">
  <data key="d0">Jan Leike</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jan Leike is a researcher involved in evaluating large language models trained on code, contributing to advancements in AI model assessment.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Josh Achiam">
  <data key="d0">Josh Achiam</data>
  <data key="d1">Researcher</data>
  <data key="d2">Josh Achiam is a researcher contributing to studies on large language models, specifically in evaluating their capabilities.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Vedant Misra">
  <data key="d0">Vedant Misra</data>
  <data key="d1">Researcher</data>
  <data key="d2">Vedant Misra is a researcher working on language model evaluation and related methodologies.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Evan Morikawa">
  <data key="d0">Evan Morikawa</data>
  <data key="d1">Researcher</data>
  <data key="d2">Evan Morikawa is involved in research on large language models and their applications.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Matthew Knight">
  <data key="d0">Matthew Knight</data>
  <data key="d1">Researcher</data>
  <data key="d2">Matthew Knight is a researcher engaged in evaluating language models on code and other tasks.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Miles Brundage">
  <data key="d0">Miles Brundage</data>
  <data key="d1">Researcher</data>
  <data key="d2">Miles Brundage conducts research on AI safety, evaluation, and model robustness.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Mira Murati">
  <data key="d0">Mira Murati</data>
  <data key="d1">Researcher</data>
  <data key="d2">Mira Murati is involved in AI research focusing on large language models and their deployment.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Katie Mayer">
  <data key="d0">Katie Mayer</data>
  <data key="d1">Researcher</data>
  <data key="d2">Katie Mayer is a researcher contributing to studies on AI model evaluation.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Peter Welinder">
  <data key="d0">Peter Welinder</data>
  <data key="d1">Researcher</data>
  <data key="d2">Peter Welinder works on AI evaluation methodologies and large-scale language models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Bob McGrew">
  <data key="d0">Bob McGrew</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bob McGrew is involved in AI research, particularly in language model training and assessment.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Dario Amodei">
  <data key="d0">Dario Amodei</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dario Amodei is a leading figure in AI research, focusing on model safety and evaluation.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sam McCandlish">
  <data key="d0">Sam McCandlish</data>
  <data key="d1">Researcher</data>
  <data key="d2">Sam McCandlish contributes to research on large language models and their capabilities.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Wojciech Zaremba">
  <data key="d0">Wojciech Zaremba</data>
  <data key="d1">Researcher</data>
  <data key="d2">Wojciech Zaremba is a researcher specializing in AI models, contributing to large language model research.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:arXiv:2107.03374">
  <data key="d0">arXiv:arXiv:2107.03374</data>
  <data key="d1">Study Design</data>
  <data key="d2">A preprint publication presenting evaluation methods for large language models trained on code, providing a basis for assessing model performance.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Christopher Hesse">
  <data key="d0">Christopher Hesse</data>
  <data key="d1">Researcher</data>
  <data key="d2">Christopher Hesse contributes to AI research on language models and mathematical reasoning.&lt;SEP&gt;Christopher Hesse works on AI systems, natural language processing, and human feedback integration.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="John Schulman">
  <data key="d0">John Schulman</data>
  <data key="d1">Researcher</data>
  <data key="d2">John Schulman is a key figure in reinforcement learning and AI model training.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2110.14168">
  <data key="d0">arXiv:2110.14168</data>
  <data key="d1">Study Design</data>
  <data key="d2">A preprint focusing on training verifiers to solve math word problems, evaluating reasoning and problem-solving abilities of models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Xueying Du">
  <data key="d0">Xueying Du</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xueying Du is involved in creating benchmarks for evaluating language models on code generation at the class level.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Mingwei Liu">
  <data key="d0">Mingwei Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Mingwei Liu contributes to research on language model evaluation and code generation benchmarks.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Kaixin Wang">
  <data key="d0">Kaixin Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Kaixin Wang works on datasets and evaluation methodologies for language models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Hanlin Wang">
  <data key="d0">Hanlin Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hanlin Wang is involved in evaluating language models on code generation tasks.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Junwei Liu">
  <data key="d0">Junwei Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Junwei Liu contributes to benchmarking and evaluation of language models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Yixuan Chen">
  <data key="d0">Yixuan Chen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yixuan Chen works on language model evaluation datasets and metrics.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jiayi Feng">
  <data key="d0">Jiayi Feng</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiayi Feng contributes to benchmarking language models for code and language understanding.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Chaofeng Sha">
  <data key="d0">Chaofeng Sha</data>
  <data key="d1">Researcher</data>
  <data key="d2">Chaofeng Sha is involved in evaluating language models on code generation tasks.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Xin Peng">
  <data key="d0">Xin Peng</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xin Peng works on datasets and evaluation strategies for language models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Yiling Lou">
  <data key="d0">Yiling Lou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yiling Lou contributes to research on language model benchmarking and evaluation.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2308.01861">
  <data key="d0">arXiv:2308.01861</data>
  <data key="d1">Study Design</data>
  <data key="d2">A manually-crafted benchmark for evaluating language models on class-level code generation, assessing their accuracy and capabilities.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Leo Gao">
  <data key="d0">Leo Gao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Leo Gao is involved in creating large datasets for language modeling, such as The Pile.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Stella Biderman">
  <data key="d0">Stella Biderman</data>
  <data key="d1">Researcher</data>
  <data key="d2">Stella Biderman contributes to dataset development for language model training.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sid Black">
  <data key="d0">Sid Black</data>
  <data key="d1">Researcher</data>
  <data key="d2">Sid Black works on datasets and evaluation in language modeling.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Laurence Golding">
  <data key="d0">Laurence Golding</data>
  <data key="d1">Researcher</data>
  <data key="d2">Laurence Golding is involved in dataset curation for language models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Travis Hoppe">
  <data key="d0">Travis Hoppe</data>
  <data key="d1">Researcher</data>
  <data key="d2">Travis Hoppe contributes to large-scale data collection for language modeling.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Charles Foster">
  <data key="d0">Charles Foster</data>
  <data key="d1">Researcher</data>
  <data key="d2">Charles Foster works on datasets and evaluation methodologies for language models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jason Phang">
  <data key="d0">Jason Phang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jason Phang is involved in language model dataset compilation and evaluation.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Horace He">
  <data key="d0">Horace He</data>
  <data key="d1">Researcher</data>
  <data key="d2">Horace He contributes to dataset development for language modeling.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Anish Thite">
  <data key="d0">Anish Thite</data>
  <data key="d1">Researcher</data>
  <data key="d2">Anish Thite works on datasets for training and evaluating language models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Noa Nabeshima">
  <data key="d0">Noa Nabeshima</data>
  <data key="d1">Researcher</data>
  <data key="d2">Noa Nabeshima contributes to dataset curation for language model research.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Shawn Presser">
  <data key="d0">Shawn Presser</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shawn Presser is involved in dataset development for language models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Connor Leahy">
  <data key="d0">Connor Leahy</data>
  <data key="d1">Researcher</data>
  <data key="d2">Connor Leahy works on large datasets for language modeling.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2101.00027">
  <data key="d0">arXiv:2101.00027</data>
  <data key="d1">Dataset</data>
  <data key="d2">The Pile is an 800GB diverse text dataset used for training large language models, covering multiple domains and sources.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Luyu Gao">
  <data key="d0">Luyu Gao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Luyu Gao is involved in developing program-aided language models (PAL) that integrate code understanding into language modeling.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Aman Madaan">
  <data key="d0">Aman Madaan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Aman Madaan contributes to research on program-aided language models, enhancing code-related capabilities.&lt;SEP&gt;Aman Madaan is an author working on language models as few-shot learners for commonsense reasoning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Shuyan Zhou">
  <data key="d0">Shuyan Zhou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shuyan Zhou contributed to research on code language models and commonsense learning.&lt;SEP&gt;Shuyan Zhou contributed to research on language models of code and few-shot learning for commonsense.&lt;SEP&gt;Shuyan Zhou works on integrating programming tasks into language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Uri Alon">
  <data key="d0">Uri Alon</data>
  <data key="d1">Researcher</data>
  <data key="d2">Uri Alon involved in language models of code and reasoning studies.&lt;SEP&gt;Uri Alon involved in research on language models of code and reasoning.&lt;SEP&gt;Uri Alon is involved in research on language models and code understanding.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Pengfei Liu">
  <data key="d0">Pengfei Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Pengfei Liu contributes to program-aided language modeling and code generation.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jamie Callan">
  <data key="d0">Jamie Callan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jamie Callan contributes to information retrieval and evaluation techniques in language modeling.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Graham Neubig">
  <data key="d0">Graham Neubig</data>
  <data key="d1">Researcher</data>
  <data key="d2">Graham Neubig contributed to research on code language models and reasoning capabilities.&lt;SEP&gt;Graham Neubig is an author involved in studies on transfer learning and NLP methodologies.&lt;SEP&gt;Graham Neubig participated in research on language models of code and reasoning.&lt;SEP&gt;Graham Neubig specializes in NLP, especially in program synthesis and language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e&lt;SEP&gt;chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2211.10435">
  <data key="d0">arXiv:2211.10435</data>
  <data key="d1">Study Design</data>
  <data key="d2">A preprint describing PAL: Program-aided Language Models, which incorporate code understanding to improve language model performance in programming tasks.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Spandan Garg">
  <data key="d0">Spandan Garg</data>
  <data key="d1">Researcher</data>
  <data key="d2">Spandan Garg works on deep learning approaches to software performance optimization.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Roshanak Zilouchian Moghaddam">
  <data key="d0">Roshanak Zilouchian Moghaddam</data>
  <data key="d1">Researcher</data>
  <data key="d2">Roshanak Zilouchian Moghaddam contributes to software engineering and performance improvement using deep learning.&lt;SEP&gt;Roshanak Zilouchian Moghaddam is a researcher contributing to studies on bug detection and software analysis.&lt;SEP&gt;Roshanak Zilouchian Moghaddam is a researcher involved in software analysis and bug detection methodologies.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Colin B. Clement">
  <data key="d0">Colin B. Clement</data>
  <data key="d1">Researcher</data>
  <data key="d2">Colin B. Clement is a researcher in machine learning and software analysis methodologies.&lt;SEP&gt;Colin B. Clement researches deep learning applications in software engineering.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Neel Sundaresan">
  <data key="d0">Neel Sundaresan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Neel Sundaresan is involved in research on software engineering and analytic bug detectors.&lt;SEP&gt;Neel Sundaresan works on AI-based bug detection and software analysis.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Chen Wu">
  <data key="d0">Chen Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Chen Wu specializes in software performance and deep learning techniques for software engineering.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering">
  <data key="d0">Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference where research on deep learning for software performance and engineering is presented.&lt;SEP&gt;This is a conference proceeding documenting research studies, including the development and evaluation of Deepdev-perf.&lt;SEP&gt;This is a conference proceedings document that reports on research, including the development and evaluation of Deepdev-perf.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="William Godoy">
  <data key="d0">William Godoy</data>
  <data key="d1">Researcher</data>
  <data key="d2">William Godoy is involved in evaluating AI models for high-performance computing (HPC) applications.&lt;SEP&gt;William Godoy is involved in evaluating AI models for high-performance computing.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Pedro Valero-Lara">
  <data key="d0">Pedro Valero-Lara</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Pedro Valero-Lara is a researcher assessing high-level programming models such as Julia, Python/Numba, and Kokkos on exascale hardware.&lt;SEP&gt;Pedro Valero-Lara is a researcher contributing to the study of AI-generated kernels in HPC contexts.&lt;SEP&gt;Pedro Valero-Lara is a researcher involved in performance evaluation of programming models for high-performance computing.&lt;SEP&gt;Pedro Valero-Lara works on HPC performance analysis and AI model evaluation.&lt;SEP&gt;Pedro Valero-Lara works on HPC performance and AI models.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-8184ca90cae86b58652f2117d440bd17&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Keita Teranishi">
  <data key="d0">Keita Teranishi</data>
  <data key="d1">Authors</data>
  <data key="d2">Keita Teranishi contributes to HPC and AI model evaluation.&lt;SEP&gt;Keita Teranishi contributes to HPC and AI research, focusing on kernel generation and parallel programming.&lt;SEP&gt;Keita Teranishi is a researcher involved in the evaluation of AI tools for parallel programming.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Prasanna Balaprakash">
  <data key="d0">Prasanna Balaprakash</data>
  <data key="d1">Authors</data>
  <data key="d2">Prasanna Balaprakash is a researcher assessing the effectiveness of AI in generating numerical kernels for HPC.&lt;SEP&gt;Prasanna Balaprakash specializes in HPC performance bugs and AI evaluation.&lt;SEP&gt;Prasanna Balaprakash specializes in HPC performance optimization and AI evaluation.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jeffrey Vetter">
  <data key="d0">Jeffrey Vetter</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jeffrey Vetter researches HPC systems and AI applications in high-performance environments.&lt;SEP&gt;Jeffrey Vetter researches HPC systems and AI applications.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Proceedings of the 52nd International Conference on Parallel Processing Workshops">
  <data key="d0">Proceedings of the 52nd International Conference on Parallel Processing Workshops</data>
  <data key="d1">Conference</data>
  <data key="d2">A conference where research on AI for HPC and parallel programming models is presented.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jian Gu">
  <data key="d0">Jian Gu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jian Gu works on automatic code summarization and AI models for software engineering.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Pasquale Salza">
  <data key="d0">Pasquale Salza</data>
  <data key="d1">Researcher</data>
  <data key="d2">Pasquale Salza specializes in software analysis and AI-based code understanding.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Harald C. Gall">
  <data key="d0">Harald C. Gall</data>
  <data key="d1">Researcher</data>
  <data key="d2">Harald C. Gall contributes to software analysis and AI-driven code summarization.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)">
  <data key="d0">IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)</data>
  <data key="d1">Conference</data>
  <data key="d2">A conference focusing on software analysis and AI techniques for code understanding.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sakib Haque">
  <data key="d0">Sakib Haque</data>
  <data key="d1">Researcher</data>
  <data key="d2">Sakib Haque researches semantic metrics for evaluating source code summaries.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Zachary Eberhart">
  <data key="d0">Zachary Eberhart</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zachary Eberhart works on software comprehension and evaluation metrics.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Aakash Bansal">
  <data key="d0">Aakash Bansal</data>
  <data key="d1">Researcher</data>
  <data key="d2">Aakash Bansal contributes to semantic similarity metrics for source code evaluation.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Collin McMillan">
  <data key="d0">Collin McMillan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Collin McMillan specializes in software engineering and code understanding metrics.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2022.XXXX">
  <data key="d0">arXiv:2022.XXXX</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research on semantic similarity metrics for evaluating source code summaries, aiming to improve code comprehension evaluation.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Anant Kharkar">
  <data key="d0">Anant Kharkar</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Anant Kharkar is a researcher focused on software engineering methodologies aimed at reducing false positives in analytic bug detectors, contributing to improving software reliability.&lt;SEP&gt;Anant Kharkar is an author involved in research on reducing false positives in analytic bug detectors, contributing to the understanding of software engineering methodologies.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Matthew Jin">
  <data key="d0">Matthew Jin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Matthew Jin is a researcher engaged in developing techniques to improve bug detection accuracy.&lt;SEP&gt;Matthew Jin is a researcher working on techniques to improve bug detection accuracy and reduce false positives in software engineering.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Xiaoyu Liu">
  <data key="d0">Xiaoyu Liu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Xiaoyu Liu contributes to research on software analysis tools and bug detection methodologies.&lt;SEP&gt;Xiaoyu Liu is involved in research related to software engineering and bug detection.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Xin Shi">
  <data key="d0">Xin Shi</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Xin Shi contributes to research on reducing false positives in analytic tools for software engineering.&lt;SEP&gt;Xin Shi is involved in developing and evaluating analytic bug detectors to minimize false positives in software engineering.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Denis Kocetkov">
  <data key="d0">Denis Kocetkov</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Denis Kocetkov is an author providing a dataset of permissively licensed source code for research.&lt;SEP&gt;Denis Kocetkov provides a large dataset of permissively licensed source code to facilitate research on software analysis and machine learning models.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Raymond Li">
  <data key="d0">Raymond Li</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Investigates how datasets can improve the evaluation and development of bug detection and code generation models.&lt;SEP&gt;Investigates how to improve the accuracy of bug detection tools and reduce false positives.&lt;SEP&gt;Provides a dataset of permissively licensed source code for research purposes.&lt;SEP&gt;Raymond Li contributes to datasets of source code for use in software engineering research and machine learning.&lt;SEP&gt;Raymond Li is a researcher contributing to datasets and studies on source code analysis.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Loubna Ben Allal">
  <data key="d0">Loubna Ben Allal</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Loubna Ben Allal is involved in research on source code datasets and software engineering.&lt;SEP&gt;Loubna Ben Allal works on datasets involving source code and software analysis.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jia Li">
  <data key="d0">Jia Li</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Jia Li is a researcher working on source code datasets and software analysis methodologies.&lt;SEP&gt;Jia Li is involved in curating and analyzing source code datasets for software engineering research.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Chenghao Mou">
  <data key="d0">Chenghao Mou</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Chenghao Mou contributes to datasets involving source code and software engineering.&lt;SEP&gt;Chenghao Mou contributes to datasets of source code for software analysis and machine learning.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Carlos Muñoz Ferrandis">
  <data key="d0">Carlos Muñoz Ferrandis</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Carlos Muñoz Ferrandis is involved in source code dataset research.&lt;SEP&gt;Carlos Muñoz Ferrandis provides datasets of source code for research purposes.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Margaret Mitchell">
  <data key="d0">Margaret Mitchell</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Margaret Mitchell contributes to research on datasets and ethical considerations in AI and software engineering.&lt;SEP&gt;Margaret Mitchell researches datasets and ethical considerations in AI and software engineering.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sean Hughes">
  <data key="d0">Sean Hughes</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Sean Hughes is involved in software datasets and analysis methodologies.&lt;SEP&gt;Sean Hughes studies datasets and methodologies for source code analysis in software engineering.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Dzmitry Bahdanau">
  <data key="d0">Dzmitry Bahdanau</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dzmitry Bahdanau is involved in developing models and datasets for machine learning in software engineering.&lt;SEP&gt;Dzmitry Bahdanau works on models and datasets in machine learning for software engineering.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Leandro von Werra">
  <data key="d0">Leandro von Werra</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Leandro von Werra is involved in datasets related to source code and software analysis.&lt;SEP&gt;Leandro von Werra works on datasets related to source code and software analysis methodologies.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Harm de Vries">
  <data key="d0">Harm de Vries</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Harm de Vries contributes to datasets and models for AI-driven software engineering research.&lt;SEP&gt;Harm de Vries contributes to datasets and research on AI models for software engineering.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Yuhang Lai">
  <data key="d0">Yuhang Lai</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Develops a benchmark dataset for data science code generation, enhancing evaluation reliability.&lt;SEP&gt;Focuses on creating reliable benchmarks for data science code generation.&lt;SEP&gt;Focuses on establishing reliable benchmarks for data science code generation to enhance model evaluation.&lt;SEP&gt;Yuhang Lai develops benchmarks and datasets for data science code generation and evaluation.&lt;SEP&gt;Yuhang Lai researches benchmarks and datasets for data science code generation.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Chengxi Li">
  <data key="d0">Chengxi Li</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Chengxi Li focuses on creating datasets and benchmarks for data science code generation.&lt;SEP&gt;Chengxi Li works on data science benchmarks and code generation datasets.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Yiming Wang">
  <data key="d0">Yiming Wang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Yiming Wang contributes to datasets for data science and code generation.&lt;SEP&gt;Yiming Wang works on datasets for evaluating data science code generation models.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Tianyi Zhang">
  <data key="d0">Tianyi Zhang</data>
  <data key="d1">Authors</data>
  <data key="d2">Tianyi Zhang contributed to the 2022 study on code generation tools usability.&lt;SEP&gt;Tianyi Zhang contributes to data science benchmarks and datasets for code generation evaluation.&lt;SEP&gt;Tianyi Zhang is involved in data science benchmarks and code generation research.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Ruiqi Zhong">
  <data key="d0">Ruiqi Zhong</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ruiqi Zhong develops datasets for data science and machine learning code generation.&lt;SEP&gt;Ruiqi Zhong works on datasets for data science code generation.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Scott Wenta Yih">
  <data key="d0">Scott Wenta Yih</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Scott Wenta Yih is involved in developing benchmarks and datasets for data science code generation.&lt;SEP&gt;Scott Wenta Yih is involved in research on data science benchmarks and code generation tools.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Daniel Fried">
  <data key="d0">Daniel Fried</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Daniel Fried researches datasets and models for code generation and AI in software engineering.&lt;SEP&gt;Daniel Fried researches datasets and models for data science and AI-driven code generation.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sida Wang">
  <data key="d0">Sida Wang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Sida Wang contributes to datasets and models for data science code generation.&lt;SEP&gt;Sida Wang is involved in datasets and models for data science code generation.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Tao Yu">
  <data key="d0">Tao Yu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Tao Yu contributes to datasets and research on data science and code generation.&lt;SEP&gt;Tao Yu works on datasets for data science and machine learning code generation evaluation.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Mingjie Liu">
  <data key="d0">Mingjie Liu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Mingjie Liu researches large language models for Verilog HDL code generation, focusing on hardware description language automation.&lt;SEP&gt;Mingjie Liu researches large language models for Verilog code generation, focusing on hardware description languages.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Nathaniel Pinckney">
  <data key="d0">Nathaniel Pinckney</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Nathaniel Pinckney evaluates large language models for hardware description language code generation, especially Verilog.&lt;SEP&gt;Nathaniel Pinckney works on evaluating large language models for hardware description code generation.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Brucek Khailany">
  <data key="d0">Brucek Khailany</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Brucek Khailany develops and evaluates models for Verilog HDL code generation using large language models.&lt;SEP&gt;Brucek Khailany is involved in research on evaluating language models for Verilog code.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Haoxing Ren">
  <data key="d0">Haoxing Ren</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Haoxing Ren contributes to research on large language models for hardware description languages.&lt;SEP&gt;Haoxing Ren researches large language models for Verilog and hardware description language code synthesis.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Christian Munley">
  <data key="d0">Christian Munley</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Christian Munley develops testing suites for compiler validation using language models.&lt;SEP&gt;Christian Munley develops testing suites for compiler validation using large language models.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Aaron Jarmusch">
  <data key="d0">Aaron Jarmusch</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Aaron Jarmusch works on compiler validation and testing methodologies involving language models.&lt;SEP&gt;Aaron Jarmusch works on compiler validation and testing methodologies.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sunita Chandrasekaran">
  <data key="d0">Sunita Chandrasekaran</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Sunita Chandrasekaran researches compiler validation and software testing using AI tools.&lt;SEP&gt;Sunita Chandrasekaran researches compiler validation and testing using AI tools.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Daniel Nichols">
  <data key="d0">Daniel Nichols</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Daniel Nichols models parallel programs using large language models to improve software performance.&lt;SEP&gt;Daniel Nichols models parallel programs using large language models to optimize performance and correctness.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Aniruddha Marathe">
  <data key="d0">Aniruddha Marathe</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Aniruddha Marathe develops models for parallel program analysis using AI techniques.&lt;SEP&gt;Aniruddha Marathe investigates modeling parallel programs with AI methods.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Harshitha Menon">
  <data key="d0">Harshitha Menon</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Harshitha Menon applies large language models to parallel program modeling and validation.&lt;SEP&gt;Harshitha Menon develops models for parallel program analysis using language models.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Todd Gamblin">
  <data key="d0">Todd Gamblin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Todd Gamblin contributes to modeling parallel programs and computational efficiency.&lt;SEP&gt;Todd Gamblin researches modeling of parallel programs and high-performance computing using AI.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Abhinav Bhatele">
  <data key="d0">Abhinav Bhatele</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Abhinav Bhatele develops models for parallel program analysis and optimization using large language models.&lt;SEP&gt;Abhinav Bhatele works on parallel program modeling and high-performance computing.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="NVIDIA">
  <data key="d0">NVIDIA</data>
  <data key="d1">Discipline</data>
  <data key="d2">NVIDIA develops CUDA, a parallel computing platform and API for GPU programming.&lt;SEP&gt;NVIDIA is a technology company known for developing CUDA, a parallel computing platform and API for GPU programming.&lt;SEP&gt;NVIDIA is a technology company that develops GPU hardware and related software, including the CUDA Toolkit and Thrust library.&lt;SEP&gt;NVIDIA is a technology corporation specializing in GPU hardware and software development, including CUDA and Thrust libraries.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Péter Vingelmann">
  <data key="d0">Péter Vingelmann</data>
  <data key="d1">Tools</data>
  <data key="d2">Péter Vingelmann is involved in developing and documenting CUDA toolkits for GPU computing.&lt;SEP&gt;Péter Vingelmann is involved in developing and supporting CUDA toolkits for GPU-accelerated parallel computing.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Frank H.P. Fitzek">
  <data key="d0">Frank H.P. Fitzek</data>
  <data key="d1">Tools</data>
  <data key="d2">Frank H.P. Fitzek collaborates on CUDA and GPU hardware acceleration research.&lt;SEP&gt;Frank H.P. Fitzek collaborates on CUDA-related research and hardware acceleration.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenAI Python API library">
  <data key="d0">OpenAI Python API library</data>
  <data key="d1">Tools</data>
  <data key="d2">OpenAI Python API library allows integration of OpenAI models into Python applications for AI development.&lt;SEP&gt;OpenAI Python API library facilitates integration of OpenAI models into Python applications.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenMP4">
  <data key="d0">OpenMP4</data>
  <data key="d1">Tools</data>
  <data key="d2">OpenMP 4.0 is an API for multi-platform shared-memory parallel programming in C, C++, and Fortran.&lt;SEP&gt;OpenMP 4.0 is an API standard for shared-memory parallel programming in C, C++, and Fortran, enabling multi-core CPU parallelism.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Adam Paszke">
  <data key="d0">Adam Paszke</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Adam Paszke is a researcher involved in developing PyTorch, a high-performance deep learning library.&lt;SEP&gt;Adam Paszke is a researcher who contributed to the development of PyTorch, an imperative style, high-performance deep learning library.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Phind">
  <data key="d0">Phind</data>
  <data key="d1">Tools</data>
  <data key="d2">Phind is an AI-powered coding assistant or platform that supports code generation, debugging, and developer assistance, as referenced in its 2023 release.&lt;SEP&gt;Phind is an AI-powered coding assistant or tool that supports code generation and debugging, as referenced in its 2023 release.&lt;SEP&gt;Phind-CodeLlama-34B-v2 is a large language model optimized for code understanding and generation tasks.&lt;SEP&gt;Phind-CodeLlama-34B-v2 is a large language model tailored for code understanding and generation.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9&lt;SEP&gt;chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Cedric Richter">
  <data key="d0">Cedric Richter</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Cedric Richter researches bug localization and repair techniques based on real bug fixes, aiming to improve software maintenance.&lt;SEP&gt;Cedric Richter researches bug localization and repair techniques from real bug fixes.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Heike Wehrheim">
  <data key="d0">Heike Wehrheim</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Heike Wehrheim studies software reliability, bug localization, and repair methodologies in software engineering.&lt;SEP&gt;Heike Wehrheim studies software reliability, bug localization, and repair methods.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Performance Deep Learning">
  <data key="d0">Performance Deep Learning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Performance Deep Learning refers to the application of deep learning techniques to enhance performance in various computational tasks, often involving neural network architectures and large datasets.&lt;SEP&gt;Performance Deep Learning refers to the application of deep learning techniques to improve performance in various computational tasks, involving neural networks, large datasets, and model optimization strategies.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:1912.01703 [cs.LG]">
  <data key="d0">arXiv:1912.01703 [cs.LG]</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint identifier indicating a research paper on deep learning performance, likely involving experimental or theoretical analysis.&lt;SEP&gt;A preprint research paper presenting studies on deep learning performance, including experiments, methodologies, and theoretical analysis.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Cedric Richter and Heike Wehrheim">
  <data key="d0">Cedric Richter and Heike Wehrheim</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors who conducted a study on learning from developer mistakes, focusing on bug localization and repair from real bug fixes.&lt;SEP&gt;Authors who conducted research on learning from developer mistakes, focusing on bug localization and repair from real bug fixes.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Learning to localize and repair real bugs from real bug fixes">
  <data key="d0">Learning to localize and repair real bugs from real bug fixes</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">Investigates whether models can effectively learn from actual developer mistakes to improve bug localization and automated repair.&lt;SEP&gt;Investigates whether models can learn from actual developer mistakes to improve bug localization and repair capabilities.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv abs/2207.00301">
  <data key="d0">arXiv abs/2207.00301</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint detailing research on bug localization and repair using real bug fix data, providing experimental results and analysis.&lt;SEP&gt;A preprint identifier for the study by Richter and Wehrheim providing preliminary or ongoing research findings.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Baptiste Rozière, Jonas Gehring, et al.">
  <data key="d0">Baptiste Rozière, Jonas Gehring, et al.</data>
  <data key="d1">Researcher Team</data>
  <data key="d2">Authors of the 2023 paper on Code Llama, a foundation model for code generation, indicating development and evaluation of large language models for coding tasks.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Llama: Open Foundation Models for Code">
  <data key="d0">Code Llama: Open Foundation Models for Code</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A set of foundational models designed specifically for code understanding and generation, based on large-scale training and architecture design.&lt;SEP&gt;A set of large-scale foundational models designed to generate, understand, and assist in coding tasks, based on transformer architectures and extensive training.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2308.12950 [cs.CL]">
  <data key="d0">arXiv:2308.12950 [cs.CL]</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Preprint describing the development, capabilities, and evaluation of Code Llama models.&lt;SEP&gt;Preprint documenting the development and capabilities of Code Llama models.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="M. Snir">
  <data key="d0">M. Snir</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of the comprehensive MPI core reference, providing foundational knowledge on Message Passing Interface for parallel computing.&lt;SEP&gt;Author of the comprehensive MPI–the Complete Reference, which explains the Message Passing Interface (MPI) standard for parallel computing.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="MPI–the Complete Reference: The MPI core">
  <data key="d0">MPI–the Complete Reference: The MPI core</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A detailed reference book on MPI core concepts, methods, and applications in high-performance parallel computing.&lt;SEP&gt;A detailed reference book on MPI, a standard for parallel programming in high-performance computing.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Xiangru Tang, Bill Qian, Rick Gao, et al.">
  <data key="d0">Xiangru Tang, Bill Qian, Rick Gao, et al.</data>
  <data key="d1">Researcher Team</data>
  <data key="d2">Authors of a study introducing BioCoder, a benchmark for bioinformatics code generation incorporating domain-specific pragmatic knowledge.&lt;SEP&gt;Authors of a study on BioCoder, a benchmark for bioinformatics code generation, emphasizing pragmatic knowledge in specialized domains.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge">
  <data key="d0">BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A benchmarking framework designed to evaluate code generation models specifically in bioinformatics, incorporating domain-specific contextual knowledge.&lt;SEP&gt;A domain-specific benchmark framework designed to evaluate code generation models in bioinformatics, emphasizing pragmatic and contextual understanding.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2308.16458 [cs.LG]">
  <data key="d0">arXiv:2308.16458 [cs.LG]</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Preprint presenting the BioCoder benchmark, its methodology, and evaluation results in bioinformatics code generation.&lt;SEP&gt;Preprint presenting the bioinformatics code generation benchmark and evaluation results.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Hugo Touvron et al.">
  <data key="d0">Hugo Touvron et al.</data>
  <data key="d1">Researcher Team</data>
  <data key="d2">Authors of the 2023 paper on Llama 2, an open foundation and fine-tuned chat model, advancing large language models for general and conversational AI.&lt;SEP&gt;Authors of the 2023 paper on Llama 2, an open foundation and fine-tuned chat model, indicating advancements in large language models.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Llama 2: Open Foundation and Fine-Tuned Chat Models">
  <data key="d0">Llama 2: Open Foundation and Fine-Tuned Chat Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A set of large language models designed for open-domain conversation, code understanding, and general AI tasks, trained with extensive datasets and fine-tuning techniques.&lt;SEP&gt;A set of large language models optimized for conversational AI, developed through extensive training and fine-tuning.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2307.09288 [cs.CL]">
  <data key="d0">arXiv:2307.09288 [cs.CL]</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Preprint detailing the architecture, training process, and evaluation results of Llama 2 models.&lt;SEP&gt;Preprint detailing the architecture, training, and evaluation of Llama 2 models.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Christian R. Trott, Damien Lebrun-Grandié, et al.">
  <data key="d0">Christian R. Trott, Damien Lebrun-Grandié, et al.</data>
  <data key="d1">Researcher Team</data>
  <data key="d2">Authors of the 2022 paper on Kokkos 3, focusing on programming model extensions for exascale computing.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Kokkos 3: Programming Model Extensions for the Exascale Era">
  <data key="d0">Kokkos 3: Programming Model Extensions for the Exascale Era</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Development of programming model extensions and libraries to support exascale hardware, emphasizing scalable performance and portability in HPC environments.&lt;SEP&gt;Development of programming model extensions to support exascale hardware, emphasizing performance portability and parallelism.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="IEEE Transactions on Parallel and Distributed Systems 33, 4 (2022)">
  <data key="d0">IEEE Transactions on Parallel and Distributed Systems 33, 4 (2022)</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Journal article documenting the design, implementation, and validation of Kokkos 3 extensions for high-performance computing.&lt;SEP&gt;Journal publication documenting the Kokkos 3 extensions and their application in high-performance computing.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Pedro Valero-Lara, Alexis Huante, Mustafa Al Lail, et al.">
  <data key="d0">Pedro Valero-Lara, Alexis Huante, Mustafa Al Lail, et al.</data>
  <data key="d1">Researcher Team</data>
  <data key="d2">Authors comparing Llama 2 and GPT-3 large language models for high-performance computing kernel generation, analyzing efficiency and accuracy.&lt;SEP&gt;Authors comparing Llama-2 and GPT-3 LLMs for HPC kernel generation, exploring model performance in specialized computational tasks.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation">
  <data key="d0">Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">Evaluates which large language model performs better in generating HPC kernels, focusing on quality, speed, and domain adaptation.&lt;SEP&gt;Examines the relative effectiveness of Llama-2 versus GPT-3 in generating high-performance computing kernels.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2309.07103 [cs.SE]">
  <data key="d0">arXiv:2309.07103 [cs.SE]</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Preprint presenting comparative analysis of large language models for HPC applications.&lt;SEP&gt;Preprint presenting experimental results comparing Llama 2 and GPT-3 in HPC kernel generation tasks.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Hao Yu, Bo Shen, Dezhi Ran, et al.">
  <data key="d0">Hao Yu, Bo Shen, Dezhi Ran, et al.</data>
  <data key="d1">Researcher Team</data>
  <data key="d2">Authors of the 2023 paper on CoderEval, a benchmark for pragmatic code generation with generative pre-trained models, assessing real-world code synthesis.&lt;SEP&gt;Authors of the 2023 paper on CoderEval, a benchmark suite for pragmatic code generation evaluation, assessing real-world coding performance of generative models.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models">
  <data key="d0">CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Design and implementation of a benchmarking suite to evaluate the pragmatic performance of code generation models in practical scenarios.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv preprint arXiv:2302.00288 (2023)">
  <data key="d0">arXiv preprint arXiv:2302.00288 (2023)</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Preprint providing evaluation results and benchmarks for code generation models.&lt;SEP&gt;Preprint with evaluation results of various code generation models on pragmatic benchmarks.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, et al.">
  <data key="d0">Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, et al.</data>
  <data key="d1">Researcher Team</data>
  <data key="d2">Authors of the 2023 paper on Code Llama, a large foundation model for code understanding and generation, highlighting advances in model architecture and training.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Christian R. Trott, Damien Lebrun-Grandié, Daniel Arndt, et al.">
  <data key="d0">Christian R. Trott, Damien Lebrun-Grandié, Daniel Arndt, et al.</data>
  <data key="d1">Researcher Team</data>
  <data key="d2">Authors of the 2022 paper on Kokkos 3, a programming model extension supporting exascale computing, focusing on performance portability and parallelism.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-Trained Models">
  <data key="d0">CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-Trained Models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Designing and implementing a benchmarking framework to evaluate code generation models on pragmatic, real-world coding tasks.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Benchmarking datasets">
  <data key="d0">Benchmarking datasets</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d2">Code generation tasks are assessed using benchmarks like HumanEval, MBPP, DS-1000, which evaluate models' ability to produce correct code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HPC code generation and analysis">
  <data key="d0">HPC code generation and analysis</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d2">COMPCODER is trained on C, C++, and Fortran code to generate and evaluate HPC programs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CodeLlama, StarCoderBase">
  <data key="d0">CodeLlama, StarCoderBase</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d2">Tools</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Prompt Samples">
  <data key="d0">Prompt Samples</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d2">This metric averages the maximum speedup over all generated samples for each prompt, representing overall model efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Resource Counts">
  <data key="d0">Resource Counts</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d2">This metric estimates the maximum achievable speedup across different resource counts, indicating potential peak performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="equation (3)">
  <data key="d0">equation (3)</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d2">Equation (3) defines the efficiency𝑛@𝑘 metric, which measures expected performance based on attempts, linking the core concept of code efficiency to the theoretical model.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Generation configurations">
  <data key="d0">Generation configurations</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d2">Different sampling parameters (number of samples, temperature) are used to evaluate code performance, linking configuration choices to the methodology."|"&lt;methodology&lt;SEP&gt;Different sampling settings (number of samples, temperature) are used to evaluate code performance, linking configuration choices to the overall methodology."|"&lt;methodology</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="GCC">
  <data key="d0">GCC</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d2">GCC compiles generated code for correctness and performance testing, linking the compiler to the evaluation methodology."|"&lt;tool-functionality</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenMPI">
  <data key="d0">OpenMPI</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d2">OpenMPI is used for compiling and executing MPI-based parallel code during evaluation, connecting the tool to the testing process."|"&lt;tool-application&lt;SEP&gt;OpenMPI is used to compile and run MPI-based parallel code during evaluation, supporting distributed execution."|"&lt;tool-application</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="nvcc">
  <data key="d0">nvcc</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d2">nvcc compiles CUDA code for GPU execution during evaluation, linking the compiler to GPU performance assessment."|"&lt;tool-application&lt;SEP&gt;nvcc compiles CUDA code, enabling GPU-accelerated code evaluation, linking the tool to the performance assessment process."|"&lt;tool-application</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="hipcc">
  <data key="d0">hipcc</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d2">hipcc compiles HIP code for GPU execution, integral to the evaluation pipeline for heterogeneous computing."|"&lt;tool-application&lt;SEP&gt;hipcc compiles HIP code for GPU execution, supporting heterogeneous computing evaluation."|"&lt;tool-application</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="structured problems">
  <data key="d0">structured problems</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d2">LLMs perform better on structured, dense problems like transform, reduce, and search, which are simpler to parallelize."|&lt;SEP&gt;LLMs perform better on structured, dense problems such as transform, reduce, and search, which are simpler to parallelize."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="sparse problems">
  <data key="d0">sparse problems</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d2">Sparse linear algebra, FFT, and geometry are difficult for LLMs due to their unstructured nature and complexity in parallelization."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="complexity and difficulty">
  <data key="d0">complexity and difficulty</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d2">The more a parallel programming model's code differs from its serial version, the more difficult it is for LLMs to generate correct code, especially for MPI and MPI+OpenMP."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Speedup and Efficiency">
  <data key="d0">Speedup and Efficiency</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d2">Figure 8 illustrates the maximum expected speedup and efficiency across resource counts, demonstrating how models scale with resources.&lt;SEP&gt;Figure 8 illustrates the maximum expected speedup and efficiency across resource counts, demonstrating scalability and resource utilization.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Translation Performance">
  <data key="d0">Translation Performance</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d2">Figure 9 shows that models perform better when given correct examples, especially for translating serial code to parallel models like OpenMP and MPI.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Translation Tasks">
  <data key="d0">Translation Tasks</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d2">Different LLMs are evaluated for their ability to translate code between execution models and generate correct parallel code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="paralle code">
  <data key="d0">paralle code</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d2">Providing correct implementations in one execution model helps LLMs generate correct code in another, as shown by improved pass@1 scores.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="parEval">
  <data key="d0">parEval</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d2">The ParEval benchmark evaluates LLMs' capacity to generate parallel code and assess its performance and scalability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Evaluation Tool">
  <data key="d0">Evaluation Tool</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d2">Used for evaluating language models' performance in the research.&lt;SEP&gt;Utilized for evaluating the performance of language models in the research context.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Benchmarking Platform">
  <data key="d0">Benchmarking Platform</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d2">Provides a platform for assessing code models' performance.&lt;SEP&gt;Serves as a platform to benchmark and compare large code models' performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Technical Resource">
  <data key="d0">Technical Resource</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d2">Offers technical details about HIP framework.&lt;SEP&gt;Provides technical details and official guidance on HIP framework used in research.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Researchers">
  <data key="d0">Researchers</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d2">Investigate transformer-based approaches for source code summarization.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Core Concept">
  <data key="d0">Core Concept</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d2">A model architecture used for source code summarization.&lt;SEP&gt;A model architecture utilizing transformers to generate source code summaries.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Theory">
  <data key="d0">Theory</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d2">Demonstrates models' ability to perform tasks with minimal examples.&lt;SEP&gt;Theory demonstrating that large language models can perform tasks with minimal examples, highlighting few-shot learning ability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Application">
  <data key="d0">Application</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d2">Applying language models to detect data races in concurrent programming environments.&lt;SEP&gt;Using language models to detect data races in concurrent code.&lt;SEP&gt;The use of HPC-Coder to automate code development tasks, improve parallelization, and predict performance impacts in scientific computing.</data>
  <data key="d1">Applications/Implications</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenAI Codex">
  <data key="d0">OpenAI Codex</data>
  <data key="d1">Tools</data>
  <data key="d2">An advanced AI model derived from GPT-3, specialized in understanding and generating programming code, used to assist in scientific kernel development.&lt;SEP&gt;OpenAI Codex is a generative AI model used for code generation across multiple programming languages and models, enabling automation and assistance in high-performance computing tasks.&lt;SEP&gt;OpenAI Codex is an AI language model capable of generating code snippets and solutions based on natural language prompts, applied here to generate kernels in various languages.&lt;SEP&gt;OpenAI Codex is an AI language model capable of generating code snippets and solutions based on natural language prompts, used here to produce kernels in various languages.&lt;SEP&gt;OpenAI Codex is an AI language model descended from GPT-3, designed for code generation and understanding, used in conjunction with tools like GitHub Copilot for scientific kernel development.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17&lt;SEP&gt;chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HPC (High-Performance Computing)">
  <data key="d0">HPC (High-Performance Computing)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">HPC involves large-scale computational systems that require optimized kernels and advanced programming models for efficient performance.&lt;SEP&gt;HPC involves the use of supercomputers and parallel processing techniques to perform complex computations efficiently, often requiring specialized kernels and programming models.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Numerical Kernels">
  <data key="d0">Numerical Kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Numerical kernels like AXPY, GEMV, GEMM, SpMV, JacobiStencil, and CG are fundamental routines used to benchmark and optimize performance in HPC systems.&lt;SEP&gt;Numerical kernels such as AXPY, GEMV, GEMM, SpMV, JacobiStencil, and CG are fundamental computational routines in HPC used to benchmark and evaluate performance and correctness.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Programming Models">
  <data key="d0">Programming Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Models like OpenMP, MPI, CUDA, and others used to generate parallel code prompts for evaluation.&lt;SEP&gt;Programming models like OpenMP, OpenACC, Kokkos, SyCL, CUDA, HIP, Numba, CuPy, Julia's Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl provide frameworks and abstractions for developing parallel code across different hardware architectures.&lt;SEP&gt;Programming models such as OpenMP, OpenACC, Kokkos, SyCL, CUDA, HIP, Numba, CuPy, Julia's Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl provide frameworks for developing parallel code compatible with diverse hardware architectures.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17&lt;SEP&gt;chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GitHub Copilot">
  <data key="d0">GitHub Copilot</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">An AI-powered code completion tool based on OpenAI Codex, integrated into Visual Studio Code, facilitating automatic generation of HPC kernels and scientific code.&lt;SEP&gt;An AI-powered code completion tool that suggests code snippets to programmers, with security evaluations conducted in 2022.&lt;SEP&gt;An AI-powered code generation tool used to assist programmers in solving coding problems.&lt;SEP&gt;An AI-powered coding assistant that helps programmers by generating code snippets and solutions based on prompts.&lt;SEP&gt;GitHub Copilot is an AI-powered code assistant whose effectiveness and suggestions are empirically studied.&lt;SEP&gt;GitHub Copilot is an AI-powered code completion tool based on OpenAI Codex, facilitating automatic code generation within Visual Studio Code for HPC and scientific computing tasks.&lt;SEP&gt;GitHub Copilot is an AI-powered code completion tool that assists programmers by suggesting code snippets, with recent security assessments conducted in 2022.&lt;SEP&gt;GitHub Copilot is an AI-powered code completion tool that leverages OpenAI Codex to generate code suggestions and implementations based on prompts, facilitating development in HPC contexts.&lt;SEP&gt;GitHub Copilot is an AI-powered code completion tool whose suggestions and effectiveness are empirically studied.&lt;SEP&gt;GitHub Copilot is an AI-powered code suggestion tool evaluated for its effectiveness as a programming assistant.&lt;SEP&gt;GitHub Copilot is an AI-powered code suggestion tool whose effectiveness and impact are empirically studied.&lt;SEP&gt;GitHub Copilot, powered by OpenAI Codex, is used to generate code suggestions and implementations based on prompts for HPC kernels.&lt;SEP&gt;GitHub Copilot is an AI-powered code completion tool that utilizes Codex to assist programmers by suggesting code snippets and functions within development environments.&lt;SEP&gt;GitHub Copilot uses Codex to assist programmers by suggesting code snippets and completions during software development.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-8184ca90cae86b58652f2117d440bd17&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-26eb2867fee2b7e0f5aa834b5b5d9096&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Proficiency Metric">
  <data key="d0">Proficiency Metric</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A metric designed to evaluate the quality, relevance, and correctness of AI-generated code suggestions based on initial outputs.&lt;SEP&gt;A metric designed to quantify the quality and relevance of AI-generated code suggestions, based on the initial 10 suggestions per prompt, to evaluate the effectiveness of the code generation process.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Language-Supported Programming Models">
  <data key="d0">Language-Supported Programming Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Various programming languages (C++, Fortran, Python, Julia) support different models and frameworks, which influence the quality and applicability of AI-generated kernels.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="AI-Assisted Generative Capabilities">
  <data key="d0">AI-Assisted Generative Capabilities</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ability of AI models like GPT-3 and Codex to generate, suggest, or complete code snippets for numerical kernels in multiple programming languages and models.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Evaluation of Kernel Generation">
  <data key="d0">Evaluation of Kernel Generation</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A systematic assessment of AI-generated code for various kernels across different programming models, measuring performance, accuracy, and compatibility.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Societal Questions">
  <data key="d0">Societal Questions</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring how AI and large language models influence software development, human-computer interaction, and the evolution of HPC practices.&lt;SEP&gt;The study explores societal implications of AI in software development, automation, and human-computer interaction in HPC contexts.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Exascale Computing Era">
  <data key="d0">Exascale Computing Era</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The current era characterized by extremely large and heterogeneous computing systems requiring advanced, AI-assisted programming approaches.&lt;SEP&gt;The current era characterized by extremely large-scale computing systems with heterogeneous hardware, demanding advanced programming models and AI-assisted development.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Evaluation of OpenAI Codex for HPC Parallel Programming">
  <data key="d0">Evaluation of OpenAI Codex for HPC Parallel Programming</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study aims to evaluate the capabilities and limitations of OpenAI Codex in generating high-performance computing (HPC) kernels across various programming models and languages.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="William F. Godoy">
  <data key="d0">William F. Godoy</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">William F. Godoy is a researcher evaluating performance and portability of high-level programming models on exascale computing nodes.&lt;SEP&gt;William F. Godoy is a researcher evaluating the performance and portability of high-level programming models on exascale computing nodes.&lt;SEP&gt;William F. Godoy is a researcher involved in evaluating AI-assisted code generation for HPC applications.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Jeffrey S. Vetter">
  <data key="d0">Jeffrey S. Vetter</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Jeffrey S. Vetter analyzes performance, efficiency, and portability of programming frameworks on exascale systems.&lt;SEP&gt;Jeffrey S. Vetter is a researcher analyzing programming models for exascale computing.&lt;SEP&gt;Jeffrey S. Vetter is a researcher leading the study on AI-assisted HPC kernel generation.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Oak Ridge National Laboratory">
  <data key="d0">Oak Ridge National Laboratory</data>
  <data key="d1">Organization</data>
  <data key="d2">A U.S. national laboratory conducting research on high-performance computing and AI applications.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Kernel Generation">
  <data key="d0">Kernel Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of creating optimized computational kernels using AI tools like OpenAI Codex across various programming models and languages.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Language-supported Programming Models">
  <data key="d0">Language-supported Programming Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Programming languages such as C++, Fortran, Python, and Julia support various models which influence the effectiveness of AI-generated kernels.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="AI-Generated Kernel Results">
  <data key="d0">AI-Generated Kernel Results</data>
  <data key="d1">Results</data>
  <data key="d2">The outputs from AI models like Codex are evaluated for correctness, efficiency, and compatibility with different programming models.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Model Maturity">
  <data key="d0">Model Maturity</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The maturity and adoption level of programming models (e.g., OpenMP, CUDA, HIP) influence the quality of AI-generated kernels.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Language Prompts">
  <data key="d0">Language Prompts</data>
  <data key="d1">Variables</data>
  <data key="d2">Prompts provided to AI models, including optional keywords, influence the quality and relevance of generated code for different languages.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="potential">
  <data key="d0">potential</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Potential encompasses the capabilities and future possibilities of the new technology, highlighting its prospects for advancing scientific computing and HPC kernel generation.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPT-3">
  <data key="d0">GPT-3</data>
  <data key="d1">Tools</data>
  <data key="d2">A large language model evaluated as a baseline, which solved 0% of HumanEval problems, demonstrating limited code synthesis capability in this context.&lt;SEP&gt;A large language model that was evaluated and found to solve 0% of the problems in the HumanEval dataset, serving as a baseline for comparison.&lt;SEP&gt;A state-of-the-art autoregressive language model with 175 billion parameters, capable of few-shot, one-shot, and zero-shot learning.&lt;SEP&gt;A state-of-the-art language model developed by OpenAI, capable of NLP tasks and code generation, serving as the foundation for Codex and related tools.&lt;SEP&gt;GPT-3 is a state-of-the-art language model developed by OpenAI, capable of performing NLP tasks and generating code snippets, which serves as the foundation for Codex.&lt;SEP&gt;GPT-3 is an advanced language model whose characteristics, capabilities, and limitations are studied in the referenced paper.&lt;SEP&gt;GPT-3 is an advanced language model whose nature, scope, limits, and consequences are analyzed in the referenced paper.&lt;SEP&gt;GPT-3 is a large language model developed by OpenAI, known for generating human-like text and serving as a benchmark in natural language processing.&lt;SEP&gt;GPT-3 is a large language model developed by OpenAI, notable for its broad language understanding but not specifically trained for code generation.&lt;SEP&gt;GPT-3 is a large language model that was not explicitly trained for code generation but has shown success in various modalities, including code-related tasks.&lt;SEP&gt;A state-of-the-art autoregressive language model capable of few-shot learning and natural language tasks, demonstrating advanced AI capabilities.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-54d0e5495bc4b24b68d3cbc1c13d835e&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-bf1121c44634b616af61c49cd3adf29a&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b&lt;SEP&gt;chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HPC Kernels">
  <data key="d0">HPC Kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">High-Performance Computing (HPC) kernels are optimized computational routines such as AXPY, GEMV, GEMM, SpMV, 3D Jacobi, and conjugate gradients, used to evaluate AI's effectiveness in scientific computing.&lt;SEP&gt;High-Performance Computing kernels such as AXPY, GEMV, GEMM, SpMV, 3D Jacobi, and conjugate gradients, used as benchmarks to evaluate AI-generated code quality.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Prompt Input Pattern Methodology">
  <data key="d0">Prompt Input Pattern Methodology</data>
  <data key="d1">Methodologies</data>
  <data key="d2">This methodology involves structured input prompts designed to improve the relevance and correctness of AI-generated scientific kernels, including keyword inputs and structured instructions.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Copilot">
  <data key="d0">Copilot</data>
  <data key="d1">Methodology</data>
  <data key="d2">An AI-powered code suggestion tool trained on public repositories, designed to assist programmers by generating code snippets based on prompts in multiple programming languages.&lt;SEP&gt;Copilot is an AI-powered code suggestion tool trained on public repositories, used to generate code snippets based on prompts in multiple programming languages.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Genetic Programming">
  <data key="d0">Genetic Programming</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A field focusing on evolutionary algorithms that emphasize code reuse, automatic architecture, and broad applicability, relevant for synthesis techniques.&lt;SEP&gt;An evolutionary algorithm-based methodology that automatically generates programs, used here as a benchmark to compare with Copilot in code synthesis tasks.&lt;SEP&gt;Genetic programming is an evolutionary algorithm-based methodology used to automatically generate programs, applied here as a comparison to Copilot in code generation tasks.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3&lt;SEP&gt;chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="PSB2 Program Synthesis Benchmarks">
  <data key="d0">PSB2 Program Synthesis Benchmarks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A set of benchmarks used to evaluate program synthesis methods, including genetic programming and AI code generators like Copilot.&lt;SEP&gt;A set of standardized benchmarks used to evaluate program synthesis methods, including genetic programming and AI code generators like Copilot.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HumanEval Dataset">
  <data key="d0">HumanEval Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset designed to evaluate the correctness, validity, and efficiency of code generated by AI tools such as Copilot.&lt;SEP&gt;A dataset used to assess correctness, validity, and efficiency of code generated by AI tools like Copilot.&lt;SEP&gt;The HumanEval dataset contains programming problems with associated unit tests, used to benchmark the coding performance of language models.&lt;SEP&gt;The HumanEval dataset contains programming problems with unit tests used to benchmark language models' coding capabilities.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Quality">
  <data key="d0">Code Quality</data>
  <data key="d1">Results</data>
  <data key="d2">An assessment metric evaluating correctness, validity, and efficiency of AI-generated code snippets in programming tasks.&lt;SEP&gt;Evaluation metric assessing correctness, validity, and efficiency of AI-generated code in programming tasks.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Educational Perspective">
  <data key="d0">Educational Perspective</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The examination of how AI tools like Copilot can generate programming exercises, explanations, and support pedagogical activities in education.&lt;SEP&gt;The use of AI tools like Copilot in education to generate programming exercises, explanations, and support pedagogical activities.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Security Vulnerability">
  <data key="d0">Security Vulnerability</data>
  <data key="d1">Results</data>
  <data key="d2">An evaluation of security issues in AI-generated code, revealing relatively high vulnerability rates in Copilot's outputs.&lt;SEP&gt;Assessment of security aspects of Copilot's code contributions, highlighting relatively high vulnerability rates in generated code.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="AI Code-Generation Capabilities">
  <data key="d0">AI Code-Generation Capabilities</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates how well current AI tools like Copilot can generate correct, secure, and pedagogically valuable code across various languages and contexts.&lt;SEP&gt;The extent to which current AI tools like Copilot can generate correct, secure, and pedagogically valuable code across different programming languages and contexts.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Language Popularity Indices">
  <data key="d0">Language Popularity Indices</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics such as GitHub repositories and TIOBE index used to estimate the availability and relevance of programming languages for AI code generation.&lt;SEP&gt;Metrics such as GitHub repositories count and TIOBE index used to estimate the availability and relevance of programming languages for AI code generation.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Prompt Structure">
  <data key="d0">Prompt Structure</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The structured prompt format used to query Copilot, including kernel and programming model specifications, to evaluate code generation in different languages.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Evaluation Setup">
  <data key="d0">Evaluation Setup</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The experimental setup involving selection of prompts, languages, and metrics to systematically evaluate Copilot's code outputs.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code Suggestion Generation">
  <data key="d0">Code Suggestion Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of generating code snippets from prompts in different languages and models using Copilot.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Correctness Evaluation">
  <data key="d0">Correctness Evaluation</data>
  <data key="d1">Results</data>
  <data key="d2">The assessment of the correctness of AI-generated code snippets based on predefined metrics and benchmarks.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Language">
  <data key="d0">Language</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The programming languages C++, Fortran, Python, and Julia used in the evaluation of Copilot's code generation capabilities.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Prompt Keywords">
  <data key="d0">Prompt Keywords</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Keywords such as function, subroutine, def used in prompts to influence Copilot's code suggestions across languages.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="OpenACC">
  <data key="d0">OpenACC</data>
  <data key="d1">The OpenACC API</data>
  <data key="d2">A high-level programming model designed to simplify parallel programming for heterogeneous CPU/GPU systems, allowing directives to offload computations to accelerators in C, C++, and Fortran.&lt;SEP&gt;A high-level programming model designed to simplify parallel programming of heterogeneous CPU/GPU systems in C, C++, and Fortran.&lt;SEP&gt;OpenACC is a programming standard for parallel computing, enabling accelerators like GPUs with version 3.1 released in 2020.&lt;SEP&gt;OpenACC is a programming standard for parallel computing, providing an API for accelerators like GPUs, with version 3.1 released in 2020.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Thrust">
  <data key="d0">Thrust</data>
  <data key="d1">Tools</data>
  <data key="d2">A C++ template library for parallel algorithms optimized for NVIDIA GPUs.&lt;SEP&gt;A C++ template library providing parallel algorithms optimized for execution on NVIDIA GPUs.&lt;SEP&gt;A CUDA C++ template library that simplifies parallel programming on GPUs, developed by NVIDIA.&lt;SEP&gt;A parallel algorithms library in C++ optimized for CUDA, providing high-level abstractions similar to the C++ STL for GPU-accelerated algorithms.&lt;SEP&gt;A parallel algorithms library in C++ that resembles the C++ Standard Template Library (STL), optimized for CUDA.&lt;SEP&gt;Thrust is a C++ template library for CUDA, providing parallel algorithms and data structures to simplify GPU programming.&lt;SEP&gt;Thrust is a parallel algorithms library for GPU programming, providing high-level abstractions for efficient parallel execution."|&gt;&lt;SEP&gt;Thrust is a parallel algorithms library resembling the C++ Standard Template Library, used for GPU programming."|&gt;</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="SyCL">
  <data key="d0">SyCL</data>
  <data key="d1">The SyCL standard</data>
  <data key="d2">A royalty-free, cross-platform abstraction layer that enables single-source C++ development for heterogeneous hardware, supporting device selection and parallel execution.&lt;SEP&gt;A royalty-free, cross-platform abstraction layer that enables single-source development for heterogeneous systems, supporting C++.&lt;SEP&gt;SyCL is a high-level programming abstraction for heterogeneous computing, allowing code portability across CPUs, GPUs, and other accelerators."|&gt;&lt;SEP&gt;SyCL is a high-level programming abstraction layer that enables code portability across heterogeneous computing platforms."|&gt;</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Post fix function">
  <data key="d0">Post fix function</data>
  <data key="d1">A code pattern where functions are specified after the main kernel or model name</data>
  <data key="d2">A coding style used in CUDA, OpenMP, and other models where functions are defined following the kernel or main function name, influencing code structure and execution flow.&lt;SEP&gt;A coding style used in some programming models like CUDA and OpenMP to define functions following the kernel name, affecting code structure and execution.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Kernel">
  <data key="d0">Kernel</data>
  <data key="d1">A fundamental unit of execution in GPU programming</data>
  <data key="d2">A kernel is a core computational unit, especially in GPU programming, representing a function executed across many parallel threads."|&gt;&lt;SEP&gt;A kernel is a function executed on the GPU across many threads in parallel, essential for parallel computation in CUDA, OpenMP, and similar models.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Function">
  <data key="d0">Function</data>
  <data key="d1">A reusable block of code that performs a specific task</data>
  <data key="d2">A function in programming, particularly in prompt engineering, used to invoke specific code snippets or behaviors."|&gt;&lt;SEP&gt;Functions can be invoked within kernels or main programs, and their naming and placement (such as post fix) affect code correctness and model sensitivity.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code correctness">
  <data key="d0">Code correctness</data>
  <data key="d1">The degree to which generated code performs as intended without errors</data>
  <data key="d2">A measure to evaluate the accuracy and reliability of code produced by models like Copilot.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Model sensitivity">
  <data key="d0">Model sensitivity</data>
  <data key="d1">The responsiveness of a code generation model to different prompts or code patterns</data>
  <data key="d2">An attribute indicating how variations in prompts influence the correctness and quality of generated code.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HecBench">
  <data key="d0">HecBench</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">HecBench is a benchmark repository containing high-performance computing workloads used for evaluating code and models."|&gt;&lt;SEP&gt;HecBench is a benchmark repository containing high-performance computing workloads used for evaluating code performance and models."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Fortran">
  <data key="d0">Fortran</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Fortran is a programming language widely used in scientific and high-performance computing due to its efficiency in numerical computations and legacy codebases."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="AXPY">
  <data key="d0">AXPY</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">AXPY is a basic linear algebra operation (a vector-scalar multiplication and addition) used as a benchmark for evaluating computational kernels."|&gt;&lt;SEP&gt;AXPY is a fundamental linear algebra operation (vector-scalar multiplication and addition) used as a benchmark for evaluating computational kernels."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GEMV">
  <data key="d0">GEMV</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">GEMV (General Matrix-Vector multiplication) is a core linear algebra operation used in scientific computing and benchmarking."|&gt;&lt;SEP&gt;GEMV (General Matrix-Vector multiplication) is a fundamental linear algebra operation used in scientific computing."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GEMM">
  <data key="d0">GEMM</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">GEMM (General Matrix to Matrix Multiplication) is a fundamental operation in linear algebra used extensively in scientific computing and machine learning for multiplying matrices.&lt;SEP&gt;GEMM (General Matrix-Matrix multiplication) is a core operation in linear algebra, critical in many scientific and engineering applications."|&gt;&lt;SEP&gt;GEMM (General Matrix-Matrix multiplication) is a key operation in linear algebra, essential for many scientific and engineering applications."|&gt;</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="SpMV">
  <data key="d0">SpMV</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">SpMV (Sparse Matrix-Vector multiplication) is a critical operation in sparse linear algebra, often used in large-scale scientific computations."|&gt;&lt;SEP&gt;SpMV (Sparse Matrix-Vector multiplication) is a key computational kernel in sparse linear algebra, involving multiplication of a sparse matrix with a vector.&lt;SEP&gt;SpMV (Sparse Matrix-Vector multiplication) is a key computational kernel in sparse linear algebra, involving the multiplication of a sparse matrix with a vector, often used in scientific simulations.&lt;SEP&gt;SpMV (Sparse Matrix-Vector multiplication) is a key operation in sparse linear algebra, often used in large-scale scientific computations."|&gt;</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Jacobi">
  <data key="d0">Jacobi</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Jacobi is an iterative algorithm used to solve systems of linear equations, common in numerical analysis."|&gt;&lt;SEP&gt;Jacobi is an iterative numerical method for solving systems of linear equations, widely used in scientific computing."|&gt;&lt;SEP&gt;Jacobi method is an iterative algorithm for solving systems of linear equations, relying on successive approximations to converge to the solution.&lt;SEP&gt;Jacobi method is an iterative algorithm for solving systems of linear equations, relying on successive approximations.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="CG">
  <data key="d0">CG</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Conjugate Gradient (CG) is an iterative method for solving large systems of linear equations, especially useful in scientific computing."|&gt;&lt;SEP&gt;Conjugate Gradient (CG) is an iterative method for solving large systems of linear equations, important in scientific simulations."|&gt;&lt;SEP&gt;Conjugate Gradient (CG) is an iterative method for solving large, sparse, symmetric positive-definite linear systems efficiently, commonly used in scientific computing.&lt;SEP&gt;Conjugate Gradient (CG) is an iterative method for solving large, sparse, symmetric positive-definite systems of linear equations efficiently.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Python">
  <data key="d0">Python</data>
  <data key="d1">Variables</data>
  <data key="d2">A widely used programming language, dominant in education and industry, known for high readability and active growth, heavily utilized in conjunction with code generation tools.&lt;SEP&gt;Python is a dominant programming language used widely in education and professional coding, known for its high readability and active growth in use.&lt;SEP&gt;Python is a high-level programming language known for its readability and extensive libraries, foundational to many computational tools and frameworks.&lt;SEP&gt;Python is a versatile high-level programming language extensively used in scientific computing, AI, education, and data analysis."|&gt;&lt;SEP&gt;Python is a widely used high-level programming language known for its simplicity and versatility in various domains including AI and scientific computing."|&gt;</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="numpy">
  <data key="d0">numpy</data>
  <data key="d1">Tools</data>
  <data key="d2">NumPy is a Python library providing support for large multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.&lt;SEP&gt;NumPy is a fundamental library for numerical computations in Python, providing support for large multi-dimensional arrays and matrices."|&gt;&lt;SEP&gt;NumPy is a fundamental library in Python for numerical computations, providing support for large multi-dimensional arrays and matrices."|&gt;</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="cuPy">
  <data key="d0">cuPy</data>
  <data key="d1">Tools</data>
  <data key="d2">cuPy is a GPU-accelerated array library for Python, compatible with NumPy, enabling high-performance computations on NVIDIA GPUs."|&gt;&lt;SEP&gt;cuPy is a GPU-accelerated array library in Python, compatible with NumPy, enabling high-performance GPU computations."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="pyCUDA">
  <data key="d0">pyCUDA</data>
  <data key="d1">Tools</data>
  <data key="d2">pyCUDA allows direct access to CUDA APIs from Python, enabling custom GPU kernel development."|&gt;&lt;SEP&gt;pyCUDA allows direct access to CUDA functions from Python, enabling custom GPU kernel development."|&gt;&lt;SEP&gt;pyCUDA is a Python interface to CUDA, allowing direct access to GPU programming and kernel execution for high-performance computing.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Numba">
  <data key="d0">Numba</data>
  <data key="d1">Tools</data>
  <data key="d2">Numba is a JIT compiler for Python that accelerates numerical functions, but shows limitations with GPU support, especially for AMD hardware."|&gt;&lt;SEP&gt;Numba is a JIT compiler for Python that accelerates numerical functions, primarily on CPUs, with limited support for GPU acceleration."|&gt;&lt;SEP&gt;Numba is a JIT compiler for Python that translates a subset of Python and NumPy code into fast machine code, facilitating performance improvements in numerical computations.&lt;SEP&gt;Numba is an LLVM-based Just-In-Time compiler for Python, used to accelerate numerical computations.&lt;SEP&gt;Numba is an LLVM-based Python JIT compiler used to accelerate numerical and scientific computations.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPU kernels">
  <data key="d0">GPU kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">GPU kernels are specialized functions executed on GPUs, critical for high-performance parallel computations in scientific computing."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="CUDA kernels">
  <data key="d0">CUDA kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">CUDA kernels are GPU functions written in CUDA C/C++ that perform parallel computations."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code Generation Quality">
  <data key="d0">Code Generation Quality</data>
  <data key="d1">Results</data>
  <data key="d2">Code generation quality refers to the accuracy, correctness, and usefulness of code produced by AI models in response to prompts."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Community Size">
  <data key="d0">Community Size</data>
  <data key="d1">Variables</data>
  <data key="d2">Community size refers to the number of users or developers involved with a particular high-level programming abstraction, affecting the quality and correctness of responses."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Benchmark Repositories">
  <data key="d0">Benchmark Repositories</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Benchmark repositories like HecBench provide standardized workloads for evaluating HPC code and AI code generation performance."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Legacy Code">
  <data key="d0">Legacy Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Legacy code refers to existing, often older, codebases that continue to be used in scientific and high-performance computing."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Parallelization">
  <data key="d0">Parallelization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Parallelization involves executing multiple computations simultaneously to improve performance in scientific computing."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code Availability">
  <data key="d0">Code Availability</data>
  <data key="d1">Variables</data>
  <data key="d2">Code availability refers to the accessibility of source code for scientific applications, influencing AI model training and code synthesis."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Maturity">
  <data key="d0">Maturity</data>
  <data key="d1">Variables</data>
  <data key="d2">Maturity indicates how developed and stable a programming model or solution is, impacting its effectiveness and AI response quality."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Response Trends">
  <data key="d0">Response Trends</data>
  <data key="d1">Results</data>
  <data key="d2">Response trends describe observed patterns in AI-generated code, such as correctness or errors, across different kernels and models."|&gt;</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="CuPy">
  <data key="d0">CuPy</data>
  <data key="d1">Tools</data>
  <data key="d2">CuPy is a GPU-accelerated library compatible with NumPy, enabling high-performance array computations on NVIDIA GPUs.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="&lt;kernel&gt;">
  <data key="d0">&lt;kernel&gt;</data>
  <data key="d1">Methodology</data>
  <data key="d2">The &lt;kernel&gt; pattern indicates code or computational kernels used in performance benchmarking and analysis of different programming models and languages.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="def">
  <data key="d0">def</data>
  <data key="d1">Methodology</data>
  <data key="d2">The 'def' pattern signifies function definitions in programming, used here to specify code implementations for various kernels.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Table 4">
  <data key="d0">Table 4</data>
  <data key="d1">Study Design</data>
  <data key="d2">A table presenting metric assessments for Copilot’s outputs across different kernels and programming models, comparing their correctness and performance.&lt;SEP&gt;A table presenting metric assessments for Copilot’s outputs across various kernels and programming models, comparing correctness and performance metrics.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Figure 4">
  <data key="d0">Figure 4</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">A graphical representation showing results for Python kernels and programming models, illustrating performance and correctness across different kernels.&lt;SEP&gt;Graphical representation showing results for Python kernels and programming models, illustrating performance and correctness.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Julia">
  <data key="d0">Julia</data>
  <data key="d1">Discipline</data>
  <data key="d2">Julia is a high-level programming language used in scientific and GPU computing, supporting packages like JuliaGPU/AMDGPU.&lt;SEP&gt;Julia is a high-level, high-performance programming language designed for scientific computing, emphasizing mathematical and numerical applications, built on LLVM.&lt;SEP&gt;Julia is a high-level, high-performance programming language designed for technical computing, emphasizing mathematical and scientific applications.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="CUDA.jl">
  <data key="d0">CUDA.jl</data>
  <data key="d1">Tools</data>
  <data key="d2">CUDA.jl is a Julia package providing support for NVIDIA CUDA GPU programming, enabling kernel development and GPU acceleration within Julia.&lt;SEP&gt;CUDA.jl is a Julia package providing support for NVIDIA GPU programming, enabling kernel execution and GPU acceleration within Julia.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="AMDGPU.jl">
  <data key="d0">AMDGPU.jl</data>
  <data key="d1">Tools</data>
  <data key="d2">AMDGPU.jl is a Julia package designed to facilitate GPU programming on AMD hardware, expanding Julia's applicability to non-NVIDIA GPUs.&lt;SEP&gt;AMDGPU.jl is a Julia package that facilitates GPU programming on AMD hardware, expanding Julia's applicability to different GPU architectures.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="KernelAbstractions.jl">
  <data key="d0">KernelAbstractions.jl</data>
  <data key="d1">Tools</data>
  <data key="d2">KernelAbstractions.jl is a Julia package that offers a portable abstraction layer for writing GPU kernels across multiple hardware vendors.&lt;SEP&gt;KernelAbstractions.jl provides a hardware-agnostic interface for writing portable GPU kernels in Julia, supporting multiple vendors.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="V GEMM">
  <data key="d0">V GEMM</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">V GEMM refers to a vectorized implementation of the General Matrix to Matrix Multiplication operation, a fundamental linear algebra routine used in high-performance computing and machine learning.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Prefix &lt;kernel&gt;">
  <data key="d0">Prefix &lt;kernel&gt;</data>
  <data key="d1">Methodology</data>
  <data key="d2">The prefix &lt;kernel&gt; indicates the beginning of a code or computational kernel, used as a pattern to identify specific GPU or CPU code segments in the analysis.&lt;SEP&gt;The prefix &lt;kernel&gt; pattern indicates code segments representing computational kernels used in performance benchmarking and analysis.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Post fix def">
  <data key="d0">Post fix def</data>
  <data key="d1">Methodology</data>
  <data key="d2">Post fix def indicates the end of a function or code block definition, used to identify code structures in analysis.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code Complexity">
  <data key="d0">Code Complexity</data>
  <data key="d1">Variables</data>
  <data key="d2">Code complexity refers to the intricacy of programming code, impacting the difficulty of obtaining acceptable results.&lt;SEP&gt;The complexity of code, measured by length of docstrings and chained operations, directly impacts model performance and success rates.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020&lt;SEP&gt;chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Multistep or Multikernel Codes">
  <data key="d0">Multistep or Multikernel Codes</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Multistep or multikernel codes, such as CG, are advanced programming constructs that present challenges in generation and implementation.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Keywords">
  <data key="d0">Keywords</data>
  <data key="d1">Variables</data>
  <data key="d2">Keywords are specific and sensitive words used to improve the proficiency of answers in programming, requiring careful selection for effectiveness.&lt;SEP&gt;Keywords are specific terms used to improve answer proficiency, requiring careful selection to be language-specific and community-sensitive.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Popularity or Accessibility of Programming Languages">
  <data key="d0">Popularity or Accessibility of Programming Languages</data>
  <data key="d1">Variables</data>
  <data key="d2">The popularity or accessibility of a programming language influences its results, but less popular languages can also be effective due to their targeted nature.&lt;SEP&gt;The popularity or ease of access to programming languages influences their utility, but less popular languages can also be effective due to their targeted nature.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="OpenAI Codex via Copilot">
  <data key="d0">OpenAI Codex via Copilot</data>
  <data key="d1">Tools</data>
  <data key="d2">OpenAI Codex via Copilot is an AI tool evaluated for generating HPC numerical kernels in various programming languages, assessing its capacity in this domain.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HPC Numerical Kernels">
  <data key="d0">HPC Numerical Kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">HPC numerical kernels are specialized code components designed for high-performance computing applications, targeted by the study for generation and evaluation.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Taxonomy">
  <data key="d0">Taxonomy</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A taxonomy is a structured classification system proposed to evaluate the accuracy, trustworthiness, and overall quality of AI-generated HPC code.&lt;SEP&gt;A taxonomy is a structured classification system, proposed here to evaluate the accuracy and trustworthiness of AI-generated HPC code.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Metrics for Evaluation">
  <data key="d0">Metrics for Evaluation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Metrics are proposed to assess the accuracy and trustworthiness of AI-generated code, emphasizing the need for standardization.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="LLM Technologies">
  <data key="d0">LLM Technologies</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Large Language Models (LLMs) like GPT-3 are advanced AI systems with significant implications for HPC software development.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Human-in-the-Loop and Compiler">
  <data key="d0">Human-in-the-Loop and Compiler</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Questions regarding integrating human oversight and compiler refinement into LLM suggestions to improve HPC software development.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Metadata-Rich Suggestions">
  <data key="d0">Metadata-Rich Suggestions</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The potential for incorporating metadata-rich suggestions to facilitate human decision-making in AI-assisted HPC coding.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HPC Software Modernization Initiatives">
  <data key="d0">HPC Software Modernization Initiatives</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Major initiatives like DARPA’s High Productivity Computing Systems and DOE’s Exascale Computing Project aim to modernize HPC software, potentially integrating AI tools.&lt;SEP&gt;Major programs like DARPA’s High Productivity Computing Systems and US Department of Energy’s Exascale Computing Project aim to modernize HPC infrastructure, potentially incorporating AI tools.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Ecosystem Features Automation">
  <data key="d0">Ecosystem Features Automation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Automating building systems, packaging, validation, verification, and CI/CD pipelines can significantly impact HPC workflows and education.&lt;SEP&gt;Automating features such as building systems, packaging, validation, verification, and CI/CD pipelines could significantly impact HPC community workflows and education.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="High-Quality Multistep or Multikernel Codes">
  <data key="d0">High-Quality Multistep or Multikernel Codes</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Complex coding strategies like CG that require advanced generation techniques and present challenges in code development.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Programming Languages">
  <data key="d0">Programming Languages</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Languages such as C++, Fortran, Python, and Julia are targeted for HPC kernel generation and evaluation.&lt;SEP&gt;Languages such as Python that are used in coding, with their adoption influenced by tools like Codex.&lt;SEP&gt;Languages such as Python, used in coding, with their adoption patterns affected by tools like Codex.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b&lt;SEP&gt;chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generative AI">
  <data key="d0">Generative AI</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Generative AI refers to artificial intelligence systems capable of creating code, with potential applications and implications for HPC software development.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPT-3 and Other LLMs">
  <data key="d0">GPT-3 and Other LLMs</data>
  <data key="d1">Tools</data>
  <data key="d2">GPT-3 and similar models are tools used for code generation, raising questions about their integration into HPC workflows.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Human-in-the-Loop">
  <data key="d0">Human-in-the-Loop</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A question about whether human oversight can improve AI-generated code quality in HPC contexts.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Revolutionary Capabilities in HPC">
  <data key="d0">Revolutionary Capabilities in HPC</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Leveraging AI capabilities could redefine educational approaches and domain progress in HPC, enabling new methodologies and efficiencies.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Information Processing Systems">
  <data key="d0">Information Processing Systems</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A collection of scholarly works and research papers related to information processing, machine learning, and high-performance computing, edited by H. Larochelle et al.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="H. Larochelle">
  <data key="d0">H. Larochelle</data>
  <data key="d1">Researcher</data>
  <data key="d2">Editor of the volume containing information processing and machine learning research papers.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="M. Ranzato">
  <data key="d0">M. Ranzato</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-editor involved in compiling research on information processing systems.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="R. Hadsell">
  <data key="d0">R. Hadsell</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-editor contributing to the scholarly volume on information processing.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="M.F. Balcan">
  <data key="d0">M.F. Balcan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Editor involved in the compilation of information processing literature.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="H. Lin">
  <data key="d0">H. Lin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Editor of the scholarly proceedings on information processing.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Vol. 33">
  <data key="d0">Vol. 33</data>
  <data key="d1">Study Design</data>
  <data key="d2">A specific volume of the proceedings, indicating the edition of the collection.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Curran Associates, Inc.">
  <data key="d0">Curran Associates, Inc.</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Publisher of the conference proceedings and research compilation.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf">
  <data key="d0">https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</data>
  <data key="d1">Tools</data>
  <data key="d2">URL link to a research paper, serving as a digital resource for accessing the study.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="H. Carter Edwards">
  <data key="d0">H. Carter Edwards</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of a paper on performance portability in manycore computing, contributing to high-performance computing methodologies.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Christian R. Trott">
  <data key="d0">Christian R. Trott</data>
  <data key="d1">Researcher</data>
  <data key="d2">Christian R. Trott is an author contributing to research on programming model extensions for exascale computing, including Kokkos 3.&lt;SEP&gt;Christian R. Trott is an author contributing to research on programming model extensions for exascale computing.&lt;SEP&gt;Co-author of a paper on high-performance computing frameworks and languages.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Daniel Sunderland">
  <data key="d0">Daniel Sunderland</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in research on high-performance computing and domain-specific languages.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Domain-Specific Languages and High-Level Frameworks for High-Performance Computing">
  <data key="d0">Domain-Specific Languages and High-Level Frameworks for High-Performance Computing</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A research area focusing on specialized languages and frameworks that facilitate high-performance computing applications.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al.">
  <data key="d0">Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors of a study evaluating large language models trained on code, contributing to AI model assessment methodologies.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Evaluating large language models trained on code">
  <data key="d0">Evaluating large language models trained on code</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A research study assessing the performance and capabilities of large language models trained specifically on programming code.&lt;SEP&gt;Research assessing the performance of large language models specifically trained on programming code, including evaluation methodologies.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Valentin Churavy, Dilum Aluthge, Lucas C Wilcox, James Schloss, Simon Byrne, Maciej Waruszewski, Julian Samaroo, Ali Ramadhan, Meredith, Simeon Schaub, Jake Bolewski, Anton Smirnov, Charles Kawczynski, Chris Hill, Jinguo Liu, Oliver Schulz, Oscar, Páll Haraldsson, Takafumi Arakaki, and Tim Besard">
  <data key="d0">Valentin Churavy, Dilum Aluthge, Lucas C Wilcox, James Schloss, Simon Byrne, Maciej Waruszewski, Julian Samaroo, Ali Ramadhan, Meredith, Simeon Schaub, Jake Bolewski, Anton Smirnov, Charles Kawczynski, Chris Hill, Jinguo Liu, Oliver Schulz, Oscar, Páll Haraldsson, Takafumi Arakaki, and Tim Besard</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors of a systematic review on code generation using machine learning, contributing to computational methods and AI research.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code Generation Using Machine Learning: A Systematic Review">
  <data key="d0">Code Generation Using Machine Learning: A Systematic Review</data>
  <data key="d1">Study Design</data>
  <data key="d2">A comprehensive review analyzing machine learning approaches for automatic code generation and their effectiveness.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Paul Denny, Viraj Kumar, Nasser Giacaman">
  <data key="d0">Paul Denny, Viraj Kumar, Nasser Giacaman</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors exploring prompt engineering and natural language processing for solving computer science problems, relevant to AI-assisted programming.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language">
  <data key="d0">Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language</data>
  <data key="d1">Study Design</data>
  <data key="d2">A study investigating how natural language prompts can be used with AI tools like Copilot to assist in introductory programming tasks.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Jack Dongarra, Robert Graybill, William Harrod, Robert Lucas, Ewing Lusk, Piotr Luszczek, Janice Mcmahon, Allan Snavely, Jeffrey Vetter, Katherine Yelick, Sadaf Alam, Roy Campbell, Laura Carrington, Tzu-Yi Chen, Omid Khalili, Jeremy Meredith, Mustafa Tikir">
  <data key="d0">Jack Dongarra, Robert Graybill, William Harrod, Robert Lucas, Ewing Lusk, Piotr Luszczek, Janice Mcmahon, Allan Snavely, Jeffrey Vetter, Katherine Yelick, Sadaf Alam, Roy Campbell, Laura Carrington, Tzu-Yi Chen, Omid Khalili, Jeremy Meredith, Mustafa Tikir</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors of a report on DARPA’s HPCS Program, detailing models, tools, and languages for high-performance computing.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="DARPA’s HPCS Program: History, Models, Tools, Languages">
  <data key="d0">DARPA’s HPCS Program: History, Models, Tools, Languages</data>
  <data key="d1">Study Design</data>
  <data key="d2">A comprehensive overview of high-performance computing systems, models, and software tools developed in the HPCS program.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Jack Dongarra et al.">
  <data key="d0">Jack Dongarra et al.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors of the International Exascale Software Project roadmap, outlining future directions for exascale computing.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="The International Exascale Software Project roadmap">
  <data key="d0">The International Exascale Software Project roadmap</data>
  <data key="d1">Study Design</data>
  <data key="d2">A strategic plan detailing software development and performance goals for exascale supercomputing.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Li Fei-Fei, R. Fergus, and P. Perona">
  <data key="d0">Li Fei-Fei, R. Fergus, and P. Perona</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors of a study on one-shot learning in object recognition, contributing to machine learning and computer vision methodologies.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="One-shot learning of object categories">
  <data key="d0">One-shot learning of object categories</data>
  <data key="d1">Study Design</data>
  <data key="d2">A research study on training models to recognize objects from a single example, relevant to few-shot learning techniques.&lt;SEP&gt;Research on training models to recognize objects from a single example, relevant to few-shot learning techniques.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Michael Fink">
  <data key="d0">Michael Fink</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of work on object classification from a single example, focusing on relevance metrics in neural networks.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Object Classification from a Single Example Utilizing Class Relevance Metrics">
  <data key="d0">Object Classification from a Single Example Utilizing Class Relevance Metrics</data>
  <data key="d1">Study Design</data>
  <data key="d2">A research paper exploring methods for classifying objects with minimal training data.&lt;SEP&gt;Research on class relevance metrics for object classification from minimal examples.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="James Finnie-Ansley, Paul Denny, Brett A. Becker, Andrew Luxton-Reilly, and James Prather">
  <data key="d0">James Finnie-Ansley, Paul Denny, Brett A. Becker, Andrew Luxton-Reilly, and James Prather</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors exploring the impact of OpenAI Codex on programming education.&lt;SEP&gt;Authors investigating the implications of OpenAI Codex on introductory programming education.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming">
  <data key="d0">The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming</data>
  <data key="d1">Study Design</data>
  <data key="d2">A study analyzing how AI code generation tools like Codex impact teaching and learning programming.&lt;SEP&gt;A study on how AI tools like Codex influence teaching and learning introductory programming.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Luciano Floridi and Massimo Chiriatti">
  <data key="d0">Luciano Floridi and Massimo Chiriatti</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors analyzing GPT-3's nature, limits, and societal impact.&lt;SEP&gt;Authors discussing the nature, scope, and consequences of GPT-3, contributing to AI ethics and understanding.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPT-3: Its nature, scope, limits, and consequences">
  <data key="d0">GPT-3: Its nature, scope, limits, and consequences</data>
  <data key="d1">Study Design</data>
  <data key="d2">An analysis of GPT-3's capabilities, limitations, and societal implications.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Association for Computing Machinery">
  <data key="d0">Association for Computing Machinery</data>
  <data key="d1">organization</data>
  <data key="d2">The ACM is a professional organization that publishes research proceedings and organizes conferences in the field of computing.&lt;SEP&gt;The Association for Computing Machinery (ACM) is a professional organization that publishes conference proceedings and research in computing.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="ACE ’22">
  <data key="d0">ACE ’22</data>
  <data key="d1">event</data>
  <data key="d2">ACE ’22 is a conference organized by the ACM, focusing on computing research, held in New York, NY, USA, from October 10 to 19.&lt;SEP&gt;The ACE ’22 is a conference organized by ACM, held in New York, NY, USA, from October 10–19, 2022, focusing on computing research.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Luciano Floridi">
  <data key="d0">Luciano Floridi</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Luciano Floridi is a philosopher known for his work on the nature, scope, limits, and consequences of artificial intelligence and information ethics.&lt;SEP&gt;Luciano Floridi is a philosopher specializing in information ethics, focusing on the nature, scope, limits, and consequences of AI and information technology.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Massimo Chiriatti">
  <data key="d0">Massimo Chiriatti</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Massimo Chiriatti is a researcher who co-authored a paper analyzing GPT-3's nature, scope, limits, and societal implications.&lt;SEP&gt;Massimo Chiriatti is a researcher who co-authored a paper with Floridi on GPT-3, discussing its attributes and implications.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="T. Elise Dettling">
  <data key="d0">T. Elise Dettling</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">T. Elise Dettling is a researcher contributing to performance assessments of programming models.&lt;SEP&gt;T. Elise Dettling is involved in performance evaluation of programming models for high-performance computing.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Christian Trefftz">
  <data key="d0">Christian Trefftz</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Christian Trefftz is involved in research on high-level programming models for exascale computing.&lt;SEP&gt;Christian Trefftz researches performance and efficiency of high-level programming frameworks on exascale systems.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Ian Jorquera">
  <data key="d0">Ian Jorquera</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ian Jorquera contributes to evaluating programming models' performance on exascale hardware.&lt;SEP&gt;Ian Jorquera is a researcher evaluating programming model performance.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Thomas Sheehy">
  <data key="d0">Thomas Sheehy</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Thomas Sheehy is a researcher in high-performance computing performance evaluation.&lt;SEP&gt;Thomas Sheehy works on performance benchmarking and evaluation of high-level programming models.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Ross G. Miller">
  <data key="d0">Ross G. Miller</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ross G. Miller evaluates the performance and scalability of programming models on exascale computing platforms.&lt;SEP&gt;Ross G. Miller is a researcher assessing performance of programming models on exascale systems.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Marc Gonzalez-Tallada">
  <data key="d0">Marc Gonzalez-Tallada</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Marc Gonzalez-Tallada is a researcher involved in high-level programming model performance studies.&lt;SEP&gt;Marc Gonzalez-Tallada researches performance metrics and optimization of high-level programming models.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Valentin Churavy">
  <data key="d0">Valentin Churavy</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Valentin Churavy is a researcher contributing to performance evaluation of high-level programming models.&lt;SEP&gt;Valentin Churavy studies performance and optimization of programming models in high-performance computing.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Julia, Python/Numba, Kokkos">
  <data key="d0">Julia, Python/Numba, Kokkos</data>
  <data key="d1">Tools</data>
  <data key="d2">High-level programming tools and frameworks evaluated for performance and portability on exascale nodes.&lt;SEP&gt;Julia, Python/Numba, and Kokkos are high-level programming tools and frameworks evaluated for performance and portability on exascale nodes.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Thomas Helmuth">
  <data key="d0">Thomas Helmuth</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Thomas Helmuth develops and evaluates program synthesis benchmarks such as PSB2 for high-performance computing.&lt;SEP&gt;Thomas Helmuth is a researcher involved in the development and assessment of program synthesis benchmarks.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Peter Kelly">
  <data key="d0">Peter Kelly</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Peter Kelly contributes to the development and assessment of program synthesis benchmark suites.&lt;SEP&gt;Peter Kelly is a researcher working on program synthesis benchmarks and performance evaluation.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="PSB2">
  <data key="d0">PSB2</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">PSB2 is a benchmark suite used for evaluating program synthesis techniques.&lt;SEP&gt;PSB2 is a benchmark suite used to evaluate program synthesis and performance in high-performance computing contexts.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Julia Hirschberg">
  <data key="d0">Julia Hirschberg</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Julia Hirschberg is a researcher in natural language processing, focusing on advances in the field.&lt;SEP&gt;Julia Hirschberg is a researcher specializing in natural language processing, focusing on advances in NLP techniques.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Advances in natural language processing">
  <data key="d0">Advances in natural language processing</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">The research explores recent progress and breakthroughs in natural language processing techniques and applications.&lt;SEP&gt;The research explores recent progress, challenges, and innovations in NLP technologies and applications.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Saki Imai">
  <data key="d0">Saki Imai</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Saki Imai conducted an empirical study evaluating GitHub Copilot as a substitute for human pair-programming.&lt;SEP&gt;Saki Imai conducted an empirical study on GitHub Copilot as a substitute for human pair-programming.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Zheming Jin">
  <data key="d0">Zheming Jin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Zheming Jin developed the Rodinia benchmarks implemented in SYCL for performance benchmarking of heterogeneous systems.&lt;SEP&gt;Zheming Jin developed the Rodinia benchmarks implemented in SYCL for performance evaluation of heterogeneous computing.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Zhemin Jin">
  <data key="d0">Zhemin Jin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Zhemin Jin created Hecbench, a benchmark suite for high-performance computing performance assessment.&lt;SEP&gt;Zhemin Jin created Hecbench, a benchmark suite for high-performance computing performance evaluation.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Srinath Kailasa">
  <data key="d0">Srinath Kailasa</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Srinath Kailasa and colleagues designed PyExaFMM, a high-performance software exercise framework using Python and Numba.&lt;SEP&gt;Srinath Kailasa and colleagues designed PyExaFMM, a high-performance software exercise using Python and Numba.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="PyExaFMM">
  <data key="d0">PyExaFMM</data>
  <data key="d1">Tools</data>
  <data key="d2">PyExaFMM is a high-performance software framework designed for exercises and benchmarking in HPC using Python and Numba.&lt;SEP&gt;PyExaFMM is a software framework for high-performance computing exercises implemented in Python and Numba.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Andreas Klöckner">
  <data key="d0">Andreas Klöckner</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Andreas Klöckner developed pycuda, a Python library for GPU runtime code generation and execution.&lt;SEP&gt;Andreas Klöckner is a researcher developing and documenting pycuda, a library for GPU computations.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="pycuda">
  <data key="d0">pycuda</data>
  <data key="d1">Tools</data>
  <data key="d2">pycuda is a Python library enabling GPU programming and runtime code generation for CUDA-enabled GPUs.&lt;SEP&gt;pycuda is a Python library for GPU runtime code generation and execution.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Nvidia">
  <data key="d0">Nvidia</data>
  <data key="d1">Organization</data>
  <data key="d2">Nvidia is a leading technology company providing GPU hardware and software, including the CUDA Toolkit.&lt;SEP&gt;Nvidia is a technology company providing GPU hardware and software, including CUDA Toolkit.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="CUDA Toolkit">
  <data key="d0">CUDA Toolkit</data>
  <data key="d1">Tools</data>
  <data key="d2">CUDA Toolkit is Nvidia's suite of software tools for developing GPU-accelerated applications.&lt;SEP&gt;CUDA Toolkit is Nvidia's suite of tools for GPU programming and high-performance computing.&lt;SEP&gt;The CUDA Toolkit is a software development kit provided by NVIDIA for programming and optimizing computations on NVIDIA GPUs, currently at version 11.7.0.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Tobias Knopp">
  <data key="d0">Tobias Knopp</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Tobias Knopp researched multi-threading support for Julia in high-performance computing environments.&lt;SEP&gt;Tobias Knopp researched multi-threading support support for Julia in high-performance computing contexts.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Douglas Kothe">
  <data key="d0">Douglas Kothe</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Douglas Kothe is involved in research on exascale computing in the United States.&lt;SEP&gt;Douglas Kothe is involved in research on exascale computing infrastructure and its deployment in the United States.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Stephen Lee">
  <data key="d0">Stephen Lee</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Stephen Lee contributes to exascale computing research and infrastructure development.&lt;SEP&gt;Stephen Lee is a researcher contributing to exascale computing studies.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Irene Qualters">
  <data key="d0">Irene Qualters</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Irene Qualters is a researcher engaged in exascale computing initiatives and infrastructure analysis.&lt;SEP&gt;Irene Qualters is a researcher involved in exascale computing research.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Exascale Computing in the United States">
  <data key="d0">Exascale Computing in the United States</data>
  <data key="d1">Study Design</data>
  <data key="d2">The study examines the current state, challenges, and progress of exascale computing in the US.&lt;SEP&gt;The study explores the current state, challenges, and developments in exascale computing infrastructure in the U.S.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Siu Kwan Lam">
  <data key="d0">Siu Kwan Lam</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Siu Kwan Lam analyzed the popularity and trends of programming languages in open source software communities.&lt;SEP&gt;Siu Kwan Lam is a researcher analyzing the popularity of programming languages in open source communities.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Antoine Pitrou">
  <data key="d0">Antoine Pitrou</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Antoine Pitrou is a researcher involved in performance analysis and development of Python JIT compilers like Numba.&lt;SEP&gt;Antoine Pitrou is a researcher involved in the development and analysis of performance tools like Numba.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Stanley Seibert">
  <data key="d0">Stanley Seibert</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Stanley Seibert is a researcher working on high-performance computing and performance analysis tools.&lt;SEP&gt;Stanley Seibert works on high-performance computing performance analysis and optimization.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Dongdong Lu">
  <data key="d0">Dongdong Lu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dongdong Lu and colleagues analyzed the popularity trends of programming languages in open source communities.&lt;SEP&gt;Dongdong Lu and colleagues studied the popularity and trends of programming languages in open source communities.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Yongxiang Sheng">
  <data key="d0">Yongxiang Sheng</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Yongxiang Sheng contributed to research on programming language usage and community dynamics.&lt;SEP&gt;Yongxiang Sheng is a researcher involved in programming languages and software community studies.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Peng Liu">
  <data key="d0">Peng Liu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Peng Liu analyzed programming language popularity and trends in open source software.&lt;SEP&gt;Peng Liu is a researcher contributing to analyses of programming language popularity.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Mengmeng Yang">
  <data key="d0">Mengmeng Yang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Mengmeng Yang is a researcher involved in programming language trend analysis.&lt;SEP&gt;Mengmeng Yang is involved in studies of programming language trends and software community analysis.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Nhan Nguyen">
  <data key="d0">Nhan Nguyen</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Nhan Nguyen conducted an empirical evaluation of GitHub Copilot's code suggestions and effectiveness.&lt;SEP&gt;Nhan Nguyen conducted an empirical evaluation of GitHub Copilot's code suggestions.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Sarah Nadi">
  <data key="d0">Sarah Nadi</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Sarah Nadi collaborated on evaluating GitHub Copilot's code suggestions and AI-assisted programming.&lt;SEP&gt;Sarah Nadi is a researcher collaborating on the evaluation of AI code suggestion tools.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Royud Nishino">
  <data key="d0">Royud Nishino</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Royud Nishino developed CuPy, a numpy-compatible GPU computing library for NVIDIA GPUs.&lt;SEP&gt;Royud Nishino developed CuPy, a numpy-compatible library for GPU calculations.&lt;SEP&gt;Royud Nishino is a researcher who contributed to the development of CuPy, a GPU-compatible numerical library.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Shohei Hido Crissman Loomis">
  <data key="d0">Shohei Hido Crissman Loomis</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Shohei Hido Crissman Loomis co-authored the paper on CuPy, contributing to GPU computing research.&lt;SEP&gt;Shohei Hido Crissman Loomis contributed to CuPy's development and GPU computation research.&lt;SEP&gt;Shohei Hido Crissman Loomis contributed to CuPy's development and GPU computing research.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Cupy">
  <data key="d0">Cupy</data>
  <data key="d1">Tools</data>
  <data key="d2">Cupy is a numpy-compatible library designed for GPU calculations, facilitating high-performance numerical computations on NVIDIA GPUs.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="JuliaGPU/AMDGPU">
  <data key="d0">JuliaGPU/AMDGPU</data>
  <data key="d1">Tools</data>
  <data key="d2">A Julia package enabling GPU programming on AMD hardware, supporting high-performance computing, version 0.4.1.&lt;SEP&gt;JuliaGPU/AMDGPU is a Julia package providing GPU programming capabilities for AMD hardware, version 0.4.1, facilitating high-performance computations.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GitHub Copilot Performance">
  <data key="d0">GitHub Copilot Performance</data>
  <data key="d1">Results</data>
  <data key="d2">Studies comparing GitHub Copilot and genetic programming have evaluated their performance in code synthesis, with results published in 2022 indicating varying effectiveness.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="NumPy">
  <data key="d0">NumPy</data>
  <data key="d1">Tools</data>
  <data key="d2">NumPy is a fundamental Python library for efficient numerical computation, providing array structures and mathematical functions, as detailed in 2011 by Van Der Walt et al.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Programming Exercises Generation">
  <data key="d0">Programming Exercises Generation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Research explores automated generation of programming exercises and explanations using large language models, with studies published in 2022 assessing usability and effectiveness.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Extreme Heterogeneity">
  <data key="d0">Extreme Heterogeneity</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Extreme Heterogeneity refers to computational environments with diverse hardware architectures, as reported in 2018 to promote productive scientific computing.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Security of GitHub Copilot">
  <data key="d0">Security of GitHub Copilot</data>
  <data key="d1">Results</data>
  <data key="d2">Research assessing the security implications of AI code contributions from GitHub Copilot found vulnerabilities or security concerns, published in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="10.1145/3524842.3528470">
  <data key="d0">10.1145/3524842.3528470</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset identifier associated with a publication, possibly referencing a digital library or conference proceedings.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Conference on Neural Information Processing Systems">
  <data key="d0">Conference on Neural Information Processing Systems</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A major conference where research on neural networks and related fields is presented, including the CuPy library publication.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="CUDA Toolkit Documentation">
  <data key="d0">CUDA Toolkit Documentation</data>
  <data key="d1">Tools</data>
  <data key="d2">Official documentation provided by NVIDIA for the CUDA Toolkit, detailing GPU programming APIs and features, version 11.7.0.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Hammond Pearce">
  <data key="d0">Hammond Pearce</data>
  <data key="d1">Authors</data>
  <data key="d2">Hammond Pearce and colleagues conducted research assessing the security of GitHub Copilot's code contributions in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Baleegh Ahmad">
  <data key="d0">Baleegh Ahmad</data>
  <data key="d1">Authors</data>
  <data key="d2">Baleegh Ahmad contributed to the security assessment of GitHub Copilot in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Benjamin Tan">
  <data key="d0">Benjamin Tan</data>
  <data key="d1">Authors</data>
  <data key="d2">Benjamin Tan contributed to the security assessment of GitHub Copilot in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Brendan Dolan-Gavitt">
  <data key="d0">Brendan Dolan-Gavitt</data>
  <data key="d1">Authors</data>
  <data key="d2">Brendan Dolan-Gavitt contributed to the security assessment of GitHub Copilot in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Ramesh Karri">
  <data key="d0">Ramesh Karri</data>
  <data key="d1">Authors</data>
  <data key="d2">Ramesh Karri contributed to the security assessment of GitHub Copilot in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Preferred Networks">
  <data key="d0">Preferred Networks</data>
  <data key="d1">Organizations</data>
  <data key="d2">Preferred Networks is a company involved in GPU computing and AI research, associated with CuPy and infrastructure projects.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Preferred Infrastructure">
  <data key="d0">Preferred Infrastructure</data>
  <data key="d1">Organizations</data>
  <data key="d2">Preferred Infrastructure is related to infrastructure projects by Preferred Networks, possibly involving GPU or AI deployments.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Sami Sarsa">
  <data key="d0">Sami Sarsa</data>
  <data key="d1">Authors</data>
  <data key="d2">Sami Sarsa and colleagues conducted research in 2022 on automatic generation of programming exercises and explanations using large language models.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Paul Denny">
  <data key="d0">Paul Denny</data>
  <data key="d1">Authors</data>
  <data key="d2">Paul Denny contributed to the research on automated programming exercises using large language models in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Arto Hellas">
  <data key="d0">Arto Hellas</data>
  <data key="d1">Authors</data>
  <data key="d2">Arto Hellas contributed to the research on automated code explanations and exercises in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Juho Leinonen">
  <data key="d0">Juho Leinonen</data>
  <data key="d1">Authors</data>
  <data key="d2">Juho Leinonen contributed to the research on automated programming exercises and code explanations in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Dominik Sobania">
  <data key="d0">Dominik Sobania</data>
  <data key="d1">Authors</data>
  <data key="d2">Dominik Sobania and colleagues compared the performance of GitHub Copilot and genetic programming in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Martin Briesch">
  <data key="d0">Martin Briesch</data>
  <data key="d1">Authors</data>
  <data key="d2">Martin Briesch contributed to the comparative study of code synthesis performance in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Franz Rothlauf">
  <data key="d0">Franz Rothlauf</data>
  <data key="d1">Authors</data>
  <data key="d2">Franz Rothlauf contributed to the comparison of program synthesis techniques in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Bjarne Stroustrup">
  <data key="d0">Bjarne Stroustrup</data>
  <data key="d1">Authors</data>
  <data key="d2">Bjarne Stroustrup authored "The C++ Programming Language" in 2013, foundational for C++ programming.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="The C++ Programming Language">
  <data key="d0">The C++ Programming Language</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A comprehensive book by Bjarne Stroustrup detailing C++ language features and usage.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Priyan Vaithilingam">
  <data key="d0">Priyan Vaithilingam</data>
  <data key="d1">Authors</data>
  <data key="d2">Priyan Vaithilingam, Tianyi Zhang, and Elena L. Glassman studied usability of code generation tools powered by large language models in 2022.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Elena L. Glassman">
  <data key="d0">Elena L. Glassman</data>
  <data key="d1">Authors</data>
  <data key="d2">Elena L. Glassman contributed to the 2022 usability study of code generation tools.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Stefan Van Der Walt">
  <data key="d0">Stefan Van Der Walt</data>
  <data key="d1">Authors</data>
  <data key="d2">Stefan Van Der Walt, S Chris Colbert, and Gael Varoquaux explained the NumPy array in 2011 as an efficient structure for numerical computation.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="S Chris Colbert">
  <data key="d0">S Chris Colbert</data>
  <data key="d1">Authors</data>
  <data key="d2">S Chris Colbert contributed to the explanation of NumPy arrays in 2011.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Gael Varoquaux">
  <data key="d0">Gael Varoquaux</data>
  <data key="d1">Authors</data>
  <data key="d2">Gael Varoquaux contributed to the NumPy array explanation in 2011.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Yaqing Wang">
  <data key="d0">Yaqing Wang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on parameter-efficient tuning methods, such as mixture-of-adapters.&lt;SEP&gt;Yaqing Wang and colleagues conducted research in 2022, likely related to AI or scientific computing, based on context.&lt;SEP&gt;Yaqing Wang is an author of a survey on few-shot learning, exploring generalization from limited examples.&lt;SEP&gt;Yaqing Wang is an author of a survey on few-shot learning, focusing on methods for generalization from limited examples.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-26eb2867fee2b7e0f5aa834b5b5d9096&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Quanming Yao">
  <data key="d0">Quanming Yao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Quanming Yao co-authored the survey on few-shot learning, emphasizing approaches to learning from few data points.&lt;SEP&gt;Quanming Yao contributed to the 2022 research involving AI or scientific methods.&lt;SEP&gt;Quanming Yao contributed to the survey on few-shot learning, focusing on learning from few examples.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="James">
  <data key="d0">James</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">James is included in the author list of the 2022 research, possibly related to AI or scientific computing.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="T. Peterka">
  <data key="d0">T. Peterka</data>
  <data key="d1">Researcher</data>
  <data key="d2">T. Peterka is an author involved in a report on extreme heterogeneity in computational science, contributing to understanding challenges in productive computational science.&lt;SEP&gt;T. Peterka is an author involved in a report on extreme heterogeneity in computational science.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="M. Strout">
  <data key="d0">M. Strout</data>
  <data key="d1">Researcher</data>
  <data key="d2">M. Strout is an author contributing to the report on productive computational science.&lt;SEP&gt;M. Strout is an author of the report, focusing on computational science in the context of extreme heterogeneity.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="J. Wilke">
  <data key="d0">J. Wilke</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Wilke contributed to the report on extreme heterogeneity, emphasizing scientific productivity in complex computational environments.&lt;SEP&gt;J. Wilke is an author associated with the report for the DOE ASCR Workshop.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Extreme Heterogeneity 2018">
  <data key="d0">Extreme Heterogeneity 2018</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A comprehensive report discussing the challenges, methodologies, and scientific approaches to addressing extreme heterogeneity in computational science.&lt;SEP&gt;A report discussing the challenges and productivity in computational science amidst extreme heterogeneity.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="DOE ASCR Workshop on Extreme Heterogeneity">
  <data key="d0">DOE ASCR Workshop on Extreme Heterogeneity</data>
  <data key="d1">Study Design</data>
  <data key="d2">A workshop organized by the DOE Office of Science to address issues related to extreme heterogeneity in computational science.&lt;SEP&gt;A workshop organized by the Department of Energy's Advanced Scientific Computing Research program to explore issues related to extreme heterogeneity in computational systems.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Technical Report">
  <data key="d0">Technical Report</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A formal document presenting research findings, discussions, and recommendations regarding productive computational science under extreme heterogeneity conditions.&lt;SEP&gt;A formal document summarizing research findings and discussions on extreme heterogeneity in computational science.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="USDOE Office of Science (SC)">
  <data key="d0">USDOE Office of Science (SC)</data>
  <data key="d1">Discipline</data>
  <data key="d2">A U.S. government agency overseeing scientific research, including the report on extreme heterogeneity.&lt;SEP&gt;A U.S. government agency supporting scientific research, including funding and oversight of the report on extreme heterogeneity.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="James T. Kwok">
  <data key="d0">James T. Kwok</data>
  <data key="d1">Researcher</data>
  <data key="d2">James T. Kwok contributed to the survey on few-shot learning, exploring methods for effective generalization from small datasets.&lt;SEP&gt;James T.. Kwok is a co-author of the few-shot learning survey, contributing to the understanding of generalization.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Lionel M. Ni">
  <data key="d0">Lionel M. Ni</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lionel M. Ni is an author involved in the survey on few-shot learning, analyzing techniques for rapid adaptation from minimal data.&lt;SEP&gt;Lionel M. Ni is an author of the survey on few-shot learning, examining methods for learning from limited data.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Generalizing from a Few Examples">
  <data key="d0">Generalizing from a Few Examples</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">A research survey investigating how machine learning models can effectively generalize from limited labeled data, specifically in few-shot learning scenarios.&lt;SEP&gt;A survey exploring how machine learning models can generalize from limited training data, specifically few-shot learning.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="ACM Comput. Surv.">
  <data key="d0">ACM Comput. Surv.</data>
  <data key="d1">Study Design</data>
  <data key="d2">A scholarly journal publishing comprehensive surveys and reviews in computer science, including the survey on few-shot learning.&lt;SEP&gt;A scholarly journal publishing surveys and comprehensive reviews in computer science.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Michel Wermelinger">
  <data key="d0">Michel Wermelinger</data>
  <data key="d1">Researcher</data>
  <data key="d2">Michel Wermelinger authored a study on using GitHub Copilot to solve programming problems, focusing on AI-assisted coding.&lt;SEP&gt;Michel Wermelinger authored a study on using GitHub Copilot to solve simple programming problems, focusing on AI-assisted code generation.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Using GitHub Copilot to Solve Simple Programming Problems">
  <data key="d0">Using GitHub Copilot to Solve Simple Programming Problems</data>
  <data key="d1">Study Title</data>
  <data key="d2">A research study evaluating the effectiveness of GitHub Copilot in generating code solutions for programming tasks.&lt;SEP&gt;A research study examining the effectiveness of GitHub Copilot in generating solutions for programming tasks.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Proceedings of the 54th ACM Technical Symposium on Computer Science Education">
  <data key="d0">Proceedings of the 54th ACM Technical Symposium on Computer Science Education</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Conference proceedings documenting research on computer science education and tools like GitHub Copilot.&lt;SEP&gt;Conference proceedings documenting research on computer science education tools, including GitHub Copilot.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Toronto, ON, Canada">
  <data key="d0">Toronto, ON, Canada</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Location where the ACM symposium took place, providing context for the study.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Burak Yetistiren">
  <data key="d0">Burak Yetistiren</data>
  <data key="d1">Researcher</data>
  <data key="d2">Burak Yetistiren evaluated the quality of GitHub Copilot's code generation capabilities, focusing on correctness and usefulness.&lt;SEP&gt;Burak Yetistiren is an author assessing the quality of GitHub Copilot's code generation capabilities.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Assessing the Quality of GitHub Copilot’s Code Generation">
  <data key="d0">Assessing the Quality of GitHub Copilot’s Code Generation</data>
  <data key="d1">Study Title</data>
  <data key="d2">A study assessing how well GitHub Copilot produces reliable and high-quality code solutions.&lt;SEP&gt;A study evaluating how well GitHub Copilot produces correct and useful code.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="PROMISE 2022">
  <data key="d0">PROMISE 2022</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference focused on predictive models and data analytics in software engineering, where the study was presented.&lt;SEP&gt;A conference on predictive models and data analytics in software engineering, where the study was presented.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Singapore, Singapore">
  <data key="d0">Singapore, Singapore</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Location of the PROMISE 2022 conference where the study was presented.&lt;SEP&gt;Location of the conference where the study was presented.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Reproducibility and Replicability">
  <data key="d0">Reproducibility and Replicability</data>
  <data key="d1">Limitations</data>
  <data key="d2">The report discusses challenges in reproducing and replicating results in rapidly evolving AI and software engineering research, emphasizing transparency and detailed documentation.&lt;SEP&gt;The report discusses challenges in reproducing and replicating results in rapidly evolving AI technologies, emphasizing the importance of transparency and detailed documentation.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Evaluation of OpenAI Codex">
  <data key="d0">Evaluation of OpenAI Codex</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d2">William F. Godoy is a lead researcher evaluating the capabilities of OpenAI Codex in generating HPC kernels.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code Generation Method">
  <data key="d0">Code Generation Method</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d2">Genetic programming is used as a benchmark for automatic code synthesis, compared to AI tools like Copilot.&lt;SEP&gt;Genetic programming is used as a benchmark for automatic program synthesis, compared to AI tools like Copilot.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Evaluation Dataset">
  <data key="d0">Evaluation Dataset</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d2">PSB2 benchmarks are used to evaluate the correctness and efficiency of code generated by Copilot and genetic programming.&lt;SEP&gt;The benchmarks are used to evaluate the correctness and efficiency of code generated by Copilot and genetic programming.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="The main research question concerns the capabilities and limitations of AI code generation tools like Copilot in various contexts.">
  <data key="d0">The main research question concerns the capabilities and limitations of AI code generation tools like Copilot in various contexts.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d2">research focus, capabilities</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="The study explores the capabilities and limitations of AI code generation tools like Copilot across languages and contexts.">
  <data key="d0">The study explores the capabilities and limitations of AI code generation tools like Copilot across languages and contexts.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d2">research focus, capabilities</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="C++ and CUDA">
  <data key="d0">C++ and CUDA</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d2">Using post fix functions like 'function' in prompts improves the correctness and quality of generated code for kernels.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code pattern">
  <data key="d0">Code pattern</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d2">Using post fix functions like 'function' in prompts influences the model's sensitivity, leading to more correct and higher-quality generated code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPU acceleration">
  <data key="d0">GPU acceleration</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">CUDA enables GPU-based acceleration for scientific computing kernels, improving performance."|&gt;"GPU computing, acceleration</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="High-level programming model">
  <data key="d0">High-level programming model</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">Kokkos offers a performance-portable abstraction layer to write code that runs efficiently across different hardware architectures."|&gt;"performance portability</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPU programming library">
  <data key="d0">GPU programming library</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">Thrust provides high-level parallel algorithms for GPU programming, simplifying development."|&gt;"parallel algorithms, GPU</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Heterogeneous computing">
  <data key="d0">Heterogeneous computing</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">SyCL allows writing portable code for heterogeneous systems, including CPUs and GPUs."|&gt;"portability, heterogeneity</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Benchmark repository">
  <data key="d0">Benchmark repository</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">HecBench provides a collection of high-performance computing workloads for evaluating models and code performance."|&gt;"benchmarking, evaluation</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Legacy HPC code">
  <data key="d0">Legacy HPC code</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">Fortran remains important in scientific computing due to its extensive legacy codebases and domain-specific applications."|&gt;"legacy code, scientific computing</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Linear algebra benchmark">
  <data key="d0">Linear algebra benchmark</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">AXPY is used as a benchmark operation to evaluate the performance of linear algebra kernels."|&gt;"benchmarking, kernels</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Linear algebra">
  <data key="d0">Linear algebra</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">GEMV is a fundamental operation in linear algebra, critical for scientific computations."|&gt;"core computational kernel</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Sparse linear algebra">
  <data key="d0">Sparse linear algebra</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">SpMV is essential for computations involving sparse matrices, common in large-scale scientific problems."|&gt;"sparse matrices, efficiency</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Numerical method">
  <data key="d0">Numerical method</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">Jacobi is an iterative numerical method for solving linear systems, widely used in scientific computing."|&gt;"algorithm, iterative method</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Scientific computing">
  <data key="d0">Scientific computing</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">Python is extensively used in scientific computing, AI, and education, with libraries like NumPy and CuPy."|&gt;"programming language, scientific applications</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Numerical library">
  <data key="d0">Numerical library</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">NumPy provides core numerical operations in Python, enabling scientific computing."|&gt;"numerical computations</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPU kernel development">
  <data key="d0">GPU kernel development</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">pyCUDA allows custom CUDA kernel development from Python, facilitating GPU programming."|&gt;"GPU kernels, Python</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="JIT compiler">
  <data key="d0">JIT compiler</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">Numba accelerates Python functions via JIT compilation, mainly for CPU, with limited GPU support."|&gt;"performance optimization, Python</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HPC Development">
  <data key="d0">HPC Development</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d2">Generative AI, including LLMs, has the potential to significantly impact HPC software development, maintenance, and education."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HPC Modernization Initiatives">
  <data key="d0">HPC Modernization Initiatives</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d2">Major modernization efforts aim to incorporate AI tools to automate and improve HPC development pipelines."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Revolutionary Capabilities">
  <data key="d0">Revolutionary Capabilities</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d2">Advanced AI capabilities could revolutionize HPC education, software development, and domain-specific methodologies."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Researcher Group">
  <data key="d0">Researcher Group</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d2">Authors of a study evaluating large language models trained on code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Researcher">
  <data key="d0">Researcher</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d2">Author of work on object classification from a single example.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Rodinia Benchmarks">
  <data key="d0">Rodinia Benchmarks</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d2">A set of benchmark applications used to evaluate high-performance computing systems and compiler optimizations, demonstrating significant speedups when using the generated code.&lt;SEP&gt;A suite of benchmark applications used to evaluate high-performance computing systems and compiler optimizations, demonstrating significant speedups with the tool.&lt;SEP&gt;Jin developed the Rodinia benchmarks implemented in SYCL for performance benchmarking of heterogeneous systems."|"&lt;performance benchmarking, heterogeneous systems&lt;SEP&gt;Jin developed the Rodinia benchmarks implemented in SYCL for performance testing.</data>
  <data key="d1">Objects of Study</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hecbench">
  <data key="d0">Hecbench</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d2">Jin created Hecbench, a benchmark suite for high-performance computing performance evaluation."|"&lt;benchmark suite, high-performance computing&lt;SEP&gt;Jin created Hecbench, a benchmark suite for high-performance computing.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="programming languages">
  <data key="d0">programming languages</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d2">Lam analyzed the popularity and usage trends of programming languages in open source communities."|"&lt;software community, language popularity&lt;SEP&gt;Lam analyzed the popularity of programming languages in open source communities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Security">
  <data key="d0">Security</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d2">Concerns regarding vulnerabilities, malicious use, and security implications of generated code.&lt;SEP&gt;Studies in 2022 evaluated the security of GitHub Copilot’s code contributions, highlighting potential vulnerabilities.</data>
  <data key="d1">Applications/Implications</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Research">
  <data key="d0">Research</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d2">Large Language Models are used to automate code generation and explanations, with research in 2022 assessing their usability and effectiveness.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Authors">
  <data key="d0">Authors</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d2">Hammond Pearce and colleagues assessed the security of GitHub Copilot in 2022, highlighting security concerns related to AI code contributions.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Organizations">
  <data key="d0">Organizations</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d2">Preferred Networks is involved in GPU and AI research, including projects related to CuPy and infrastructure.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Parallel Pattern Language Code Generation">
  <data key="d0">Parallel Pattern Language Code Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A high-level language and associated code generator designed to facilitate the development and optimization of parallel scientific software by defining parallelism through patterns and applying static global optimizations.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Adrian Schmitz">
  <data key="d0">Adrian Schmitz</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher affiliated with RWTH Aachen University involved in the development of the Parallel Pattern Language Code Generation project.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Julian Miller">
  <data key="d0">Julian Miller</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher associated with RWTH Aachen University contributing to the project on parallel code generation.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Semih Burak">
  <data key="d0">Semih Burak</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher at RWTH Aachen University working on the implementation of the code generator for parallel patterns.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Matthias S. Müller">
  <data key="d0">Matthias S. Müller</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher at RWTH Aachen University involved in the development and evaluation of the code generation tool.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory and Power Constraints">
  <data key="d0">Memory and Power Constraints</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Limitations related to hardware resources such as memory capacity and power consumption that impact high-performance computing system scalability.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Heterogeneity in HPC Systems">
  <data key="d0">Heterogeneity in HPC Systems</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The diversity of hardware components like CPUs, GPUs, and NUMA architectures within high-performance computing systems, complicating software development and optimization.&lt;SEP&gt;The presence of diverse hardware components like CPUs, GPUs, and NUMA architectures in high-performance computing systems, increasing complexity in software development.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Non-Uniform Memory Architecture (NUMA)">
  <data key="d0">Non-Uniform Memory Architecture (NUMA)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A hardware architecture where memory access time varies depending on the memory location relative to the processor, affecting performance and software optimization.&lt;SEP&gt;A hardware architecture where memory access times vary depending on the processor and memory location, affecting performance and requiring specific optimization strategies.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Accelerator Offloading">
  <data key="d0">Accelerator Offloading</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Accelerator offloading involves transferring computation tasks from the CPU to GPUs to exploit their high parallelism capabilities.&lt;SEP&gt;The process of transferring computational tasks from CPUs to accelerators like GPUs to improve performance and energy efficiency.&lt;SEP&gt;The process of transferring computational tasks from CPUs to accelerators such as GPUs to improve performance, energy efficiency, and leverage heterogeneous hardware.&lt;SEP&gt;Transferring computational tasks from CPU to GPUs or other accelerators to exploit their high parallelism and speed up processing.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d&lt;SEP&gt;chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Code Generator">
  <data key="d0">Code Generator</data>
  <data key="d1">Tools</data>
  <data key="d2">A code generator automates the creation of optimized parallel code based on high-level specifications and optimization strategies.&lt;SEP&gt;A software component that automates the creation of source code based on high-level specifications, enabling optimized parallel code for heterogeneous architectures.&lt;SEP&gt;A software component that automatically produces code based on input specifications, used here to generate optimized code for the PPL prototype.&lt;SEP&gt;A software component that automatically produces optimized source code based on high-level descriptions, enabling efficient parallel code for shared memory, distributed memory, and GPU offloading architectures.&lt;SEP&gt;A software component that automatically produces source code based on high-level specifications, enabling optimized code creation for the PPL prototype.&lt;SEP&gt;A software component that automatically produces source code tailored to specific hardware architectures and optimization goals, significantly influencing system performance.&lt;SEP&gt;Component that produces optimized code for CPU and GPU, balancing performance with overhead, and supporting various kernels like batch, jacobi, and monte.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-e6eb755f9f73ae3f7c76aff0920fdfae&lt;SEP&gt;chunk-b943bff32a36cd0ce9ab43893da92b5b&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Patterns">
  <data key="d0">Parallel Patterns</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Abstractions that encapsulate parallelism, removing boilerplate code and improving programmer productivity and code maintainability.&lt;SEP&gt;High-level abstractions that define parallelism in code, facilitating static global optimizations and effective mapping to heterogeneous hardware architectures.&lt;SEP&gt;High-level abstractions used to define parallelism in code, facilitating static global optimization and efficient mapping to hardware architectures.&lt;SEP&gt;Parallel patterns are high-level abstractions used to represent common computational structures, facilitating analysis and optimization in the PPL approach.&lt;SEP&gt;Parallel patterns are structures within the APT that define fixed computations and control flow, enabling static data dependency analysis and optimization.&lt;SEP&gt;Parallel patterns define structured parallel control-flow constructs within the code, enabling static analysis and optimization of data dependencies.&lt;SEP&gt;Parallel patterns describe structured approaches to executing tasks concurrently across multiple processing units, such as GPUs, to improve performance.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-3487322ee335c5f4b3b40717a7de46d1&lt;SEP&gt;chunk-e6eb755f9f73ae3f7c76aff0920fdfae&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Static Global Optimizations">
  <data key="d0">Static Global Optimizations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Compiler techniques applied across entire applications during compile time to optimize workload distribution, resource utilization, and performance.&lt;SEP&gt;Compiler techniques applied across the entire application code to improve performance by optimizing workload distribution and resource utilization.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Assignment of Tasklets to Heterogeneous Architecture">
  <data key="d0">Assignment of Tasklets to Heterogeneous Architecture</data>
  <data key="d1">Variables</data>
  <data key="d2">The process of mapping small computational units (tasklets) to specific hardware components (CPUs, GPUs, memory nodes) during compile time to optimize execution.&lt;SEP&gt;The process of mapping small computational units (tasklets) to specific hardware components (CPUs, GPUs, memory nodes) during compile time to optimize performance.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Source Code Generation">
  <data key="d0">Source Code Generation</data>
  <data key="d1">Tools</data>
  <data key="d2">The process of creating optimized source code from high-level descriptions, supporting shared memory, distributed memory, and GPU offloading.&lt;SEP&gt;The process of producing optimized source code from high-level descriptions, tailored for shared memory, distributed memory, and GPU offloading.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Heterogeneous Cluster Architecture">
  <data key="d0">Heterogeneous Cluster Architecture</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A hardware configuration combining CPUs, GPUs, and other accelerators to enable high-performance, scalable computing.&lt;SEP&gt;A hardware setup combining CPUs, GPUs, and other accelerators designed for high-performance, scalable computing.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Compile-Time Optimization">
  <data key="d0">Compile-Time Optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process where code is analyzed and optimized during compilation, before execution, to improve runtime performance and resource utilization.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Speedups in Rodinia Benchmarks">
  <data key="d0">Speedups in Rodinia Benchmarks</data>
  <data key="d1">Results</data>
  <data key="d2">Significant performance improvements observed in multiple benchmark applications using the generated code, demonstrating the effectiveness of the approach.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance Speedups">
  <data key="d0">Performance Speedups</data>
  <data key="d1">Results</data>
  <data key="d2">Significant improvements in execution time observed in multiple Rodinia benchmarks when using the generated code, demonstrating the effectiveness of the approach.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Linear Programming (LP)">
  <data key="d0">Linear Programming (LP)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A mathematical optimization technique for solving problems with linear constraints and objectives, used here to address global optimization issues in the prototype.&lt;SEP&gt;LP is an optimization technique used for solving linear problems, here applied to global optimization issues in the prototype.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Abstract Pattern Tree (APT)">
  <data key="d0">Abstract Pattern Tree (APT)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A data structure representing code patterns used for inlining and loop unrolling within the PPL's optimization processes.&lt;SEP&gt;A data structure representing patterns in code used for inlining and loop unrolling optimizations in the prototype.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rodinia Benchmark Suite">
  <data key="d0">Rodinia Benchmark Suite</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A collection of benchmark kernels used to evaluate the performance and scalability of parallel programming tools and frameworks.&lt;SEP&gt;A collection of benchmarks designed to evaluate performance and energy efficiency of heterogeneous computing architectures.&lt;SEP&gt;A comprehensive set of benchmark kernels used to evaluate the performance, scalability, and correctness of parallel programming frameworks.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="LULESH Proxy-App">
  <data key="d0">LULESH Proxy-App</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A hydrodynamics simulation application ported to the PPL to assess scalability and performance.&lt;SEP&gt;A proxy application modeling hydrodynamics, ported to the PPL for scalability testing.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPL (Parallel Pattern Library)">
  <data key="d0">PPL (Parallel Pattern Library)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A framework aimed at generating optimized parallel code across diverse hardware, supporting shared and distributed memory systems.&lt;SEP&gt;A framework designed to generate portable, optimized parallel code for diverse hardware architectures, supporting shared and distributed memory systems.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPLtoolchain">
  <data key="d0">PPLtoolchain</data>
  <data key="d1">Tools</data>
  <data key="d2">A collection of software tools, including code generators and analyzers, that facilitate transforming high-level parallel patterns into executable code.&lt;SEP&gt;A set of software tools that facilitate the translation of high-level parallel patterns into executable code, including code generators and optimization modules.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Future Work">
  <data key="d0">Future Work</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring solutions for current issues in the PPL prototype and planning for a productized release.&lt;SEP&gt;Investigations aimed at resolving current issues in the PPL prototype and enabling a stable product release.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Polyhedral Compilers">
  <data key="d0">Polyhedral Compilers</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A class of advanced compiler techniques that optimize nested loop structures using polyhedral models, relevant as a comparison to PPL's optimization strategies.&lt;SEP&gt;A class of compilers that optimize nested loop structures using polyhedral models, relevant for comparison with PPL's optimization techniques.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="LLVM and gcc">
  <data key="d0">LLVM and gcc</data>
  <data key="d1">Tools</data>
  <data key="d2">Compiler infrastructures used for code generation, contrasted with PPL's source-to-source approach.&lt;SEP&gt;Popular compiler infrastructures used for low-level code generation, contrasted with PPL's source-to-source compilation approach.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Domain Specific Language (DSL)">
  <data key="d0">Domain Specific Language (DSL)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A specialized language designed to enable targeted optimizations within the PPL framework.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="YASK">
  <data key="d0">YASK</data>
  <data key="d1">Tools</data>
  <data key="d2">A code generator focused on optimized stencil kernels, representing a related approach to pattern-based code generation.&lt;SEP&gt;A code generator focused on producing optimized stencil kernels, similar to PPL's support for stencil patterns.&lt;SEP&gt;YASK (Yet Another Stencil Kernel) is a framework for generating and tuning high-performance stencil codes for HPC applications.&lt;SEP&gt;YASK (Yet Another Stencil Kernel) is a framework for generating, tuning, and optimizing stencil codes for high-performance computing applications.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kokkos and Raja">
  <data key="d0">Kokkos and Raja</data>
  <data key="d1">Tools</data>
  <data key="d2">Libraries that provide performance portability and support for parallel applications across hardware architectures.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="SDFGs and DaCe">
  <data key="d0">SDFGs and DaCe</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Rule-based optimization strategies for applying transformations to hotspots in computation, offering an alternative to PPL's approach.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="DSL (Domain Specific Language)">
  <data key="d0">DSL (Domain Specific Language)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A specialized programming language designed within PPL to enable targeted and efficient optimizations tailored to specific patterns.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Raja">
  <data key="d0">Raja</data>
  <data key="d1">Tools</data>
  <data key="d2">A performance portability library similar to Kokkos, supporting multi-platform parallel applications.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="SDFGs (Stateful DataFlow Graphs)">
  <data key="d0">SDFGs (Stateful DataFlow Graphs)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A detailed dependency analysis framework that enables aliasing elimination and dependency chain extraction during compile time.&lt;SEP&gt;A detailed dependency analysis model that enables aliasing elimination and variable dependency chain extraction during compile time.&lt;SEP&gt;A rule-based optimization framework that applies transformations to hotspots in computation graphs, offering an alternative to PPL's optimization approach.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="DaCe (Data-Centric Parallel Programming)">
  <data key="d0">DaCe (Data-Centric Parallel Programming)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A tool that employs SDFGs for optimizing and mapping computational hotspots, facilitating semi-automatic optimization.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Distributed Memory">
  <data key="d0">Distributed Memory</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A computing architecture where each node has its own private memory, requiring explicit data transfer and synchronization mechanisms for parallel processing.&lt;SEP&gt;Distributed memory refers to a computing architecture where each node has its own private memory, requiring explicit data transfer and synchronization mechanisms.&lt;SEP&gt;Distributed memory refers to a system architecture where memory is physically distributed across multiple nodes, requiring explicit data communication between nodes during computation.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="SDFG">
  <data key="d0">SDFG</data>
  <data key="d1">Tools</data>
  <data key="d2">SDFG (Stateful DataFlow Graph) is a representation used to optimize and manage computations, focusing on hotspots and enabling rule-based optimizations in high-performance computing.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="DaCe">
  <data key="d0">DaCe</data>
  <data key="d1">Tools</data>
  <data key="d2">DaCe (Data-Centric parallel programming Environment) is a tool that employs SDFGs to facilitate optimization strategies for high-performance applications, allowing automatic or semi-automatic transformations.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rule-based Optimization Strategy">
  <data key="d0">Rule-based Optimization Strategy</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A rule-based optimization strategy involves applying predefined rules to improve computational hotspots, often requiring expert input for defining optimization rules.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hotspots">
  <data key="d0">Hotspots</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Hotspots are critical regions in code that consume significant computational resources and are targeted for optimization in high-performance computing.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPL (Parallel Pattern Language)">
  <data key="d0">PPL (Parallel Pattern Language)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A programming approach that facilitates static code optimization, abstraction of parallelism through patterns, and support for heterogeneous architectures from a single source.&lt;SEP&gt;A programming paradigm that abstracts parallelism into patterns, enabling static, automatic, and global code optimization across heterogeneous architectures from a single source.&lt;SEP&gt;PPL is a pattern-based approach for representing algorithms in parallel programming, enabling global optimizations through a full toolchain.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Application Wide Optimizations">
  <data key="d0">Application Wide Optimizations</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Application wide optimizations refer to strategies that improve performance across entire applications, as opposed to local optimizations, and are explored as potential solutions in PPL.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Local Optimizations">
  <data key="d0">Local Optimizations</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Local optimizations focus on specific code regions or functions, with PPL emphasizing more on global optimization strategies.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Legion Framework">
  <data key="d0">Legion Framework</data>
  <data key="d1">Framework</data>
  <data key="d2">The Legion framework is a system targeting similar hardware configurations as PPL, supporting CPUs, GPUs, and distributed memory, with a focus on enabling user-defined mappings.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Automatic Global Optimizations">
  <data key="d0">Automatic Global Optimizations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Automatic global optimizations are techniques that enable the system to optimize across the entire application without manual intervention, contrasting with user-defined mappings.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Pattern Language Prototype">
  <data key="d0">Parallel Pattern Language Prototype</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The PPL prototype is a complete toolchain designed to verify pattern-based approaches in real-world environments, utilizing a modular source-to-source compiler with multiple stages.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pattern-based Approach">
  <data key="d0">Pattern-based Approach</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A pattern-based approach involves representing algorithms using predefined parallel patterns to facilitate optimization and code generation.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Source-to-Source Compiler">
  <data key="d0">Source-to-Source Compiler</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A source-to-source compiler translates high-level parallel patterns into optimized C++ code through multiple stages, including parsing, optimization, and code generation.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parsing">
  <data key="d0">Parsing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Parsing is the initial stage where user input, written in a domain-specific language (DSL), is evaluated to understand the application's structure.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="DSL (Domain-Specific Language)">
  <data key="d0">DSL (Domain-Specific Language)</data>
  <data key="d1">Tools</data>
  <data key="d2">A custom DSL is used to represent applications with parallel patterns, inspired by CUDA notation, focusing on element-wise operations and enabling static array size definitions.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="APT (Hierarchical Representation)">
  <data key="d0">APT (Hierarchical Representation)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">APT is a hierarchical data structure representing the algorithm's parallel pattern composition, generated during the optimization process.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Optimization">
  <data key="d0">Optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Adjusting the model or its inputs/outputs to improve performance on domain-specific tasks, using techniques like gradient descent or prompt refinement.&lt;SEP&gt;Optimization encompasses techniques like loop fusion, data flow adjustments, and task reordering to improve performance and resource utilization.&lt;SEP&gt;Optimization involves applying global transformations such as reordering and hardware mapping to improve performance based on the APT.&lt;SEP&gt;Optimization involves selecting the best parameters and code transformations to maximize parallel efficiency while respecting semantics.&lt;SEP&gt;Techniques aimed at enhancing code efficiency, speed, and resource utilization on hardware platforms.&lt;SEP&gt;Techniques aimed at improving the performance and efficiency of code execution on hardware.&lt;SEP&gt;Techniques used to improve the model's performance after augmentation, including gradient descent, prompt refinement, or post-processing.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Abstract Mapping Tree (AMT)">
  <data key="d0">Abstract Mapping Tree (AMT)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">AMT is generated from the optimized APT, representing synchronization and data transfer requirements for code generation.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Array Element-wise Operations">
  <data key="d0">Array Element-wise Operations</data>
  <data key="d1">Results</data>
  <data key="d2">Operations like multiply and subtract are performed element-wise on arrays, as exemplified in the provided code snippets.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hardware Language (HWL)">
  <data key="d0">Hardware Language (HWL)</data>
  <data key="d1">Tools</data>
  <data key="d2">HWL describes target hardware configurations in JSON format, specifying execution units like CPU cores for code mapping.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global View on Application">
  <data key="d0">Global View on Application</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A global view enables comprehensive optimization strategies, contrasting with local or isolated approaches, and is central to the pattern-based methodology.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="System Configuration">
  <data key="d0">System Configuration</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">System configuration includes hardware details such as CPU, GPU, and distributed memory setups, influencing optimization strategies.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Algorithm">
  <data key="d0">Algorithm</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Algorithms are formal procedures or formulas implemented in parallel patterns within the PPL framework to solve computational problems.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance Results">
  <data key="d0">Performance Results</data>
  <data key="d1">Results</data>
  <data key="d2">Performance results measure the effectiveness of optimizations, such as execution speedup or resource utilization improvements.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hardware Targets">
  <data key="d0">Hardware Targets</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Hardware targets specify the computing devices (CPUs, GPUs, clusters) for which code is generated and optimized.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Patterns Library (PPL)">
  <data key="d0">Parallel Patterns Library (PPL)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The Parallel Pattern Library is a collection of patterns and tools designed for automatic optimization and code generation in parallel programming environments.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pattern Application">
  <data key="d0">Pattern Application</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Applying patterns involves defining algorithm structures in the DSL, which are then used for optimization and code generation.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Algorithm Representation">
  <data key="d0">Algorithm Representation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Algorithms are represented as hierarchical APTs, capturing the structure for optimization.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Optimization Goals">
  <data key="d0">Optimization Goals</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Goals include improving performance, enabling automatic transformations, and supporting application-wide optimizations.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Expert-defined Mappings">
  <data key="d0">Expert-defined Mappings</data>
  <data key="d1">Variables</data>
  <data key="d2">Expert-defined mappings involve manual specification of hardware and data placement strategies, contrasting with automatic approaches.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Semi-automatic Optimization">
  <data key="d0">Semi-automatic Optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Semi-automatic optimization combines automated processes with expert input to refine performance improvements.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="TheHWL">
  <data key="d0">TheHWL</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The Hardware Layer (TheHWL) defines execution units as cores, allowing flexible division of device resources for parallel processing.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="APTT Generation">
  <data key="d0">APTT Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">APTT Generation involves creating a hierarchical high-level representation of parallel code, including nodes for expressions and statements, facilitating analysis and optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="TheAPT">
  <data key="d0">TheAPT</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The Abstract Pattern Tree (APT) is a hierarchical structure representing parallel code, capturing dependencies, control flow, and data access patterns for optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Dependencies">
  <data key="d0">Data Dependencies</data>
  <data key="d1">Variables</data>
  <data key="d2">Data dependencies describe relationships between expressions within the APT, essential for ensuring correct execution order and enabling static analysis.&lt;SEP&gt;Data dependencies describe relationships between expressions, indicating data flow and constraints necessary for correct parallel execution.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global Optimization">
  <data key="d0">Global Optimization</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A comprehensive approach considering all system components—memory, computation, communication—to maximize overall performance.&lt;SEP&gt;Global optimization considers the entire computational process, including memory management and kernel execution, to maximize performance across hardware components.&lt;SEP&gt;Global optimization involves applying techniques like loop fusion, data flow optimizations, and reordering nodes in the APT to improve performance and resource utilization during compilation.&lt;SEP&gt;Global optimization involves techniques to find the best solution across an entire problem space, often used in high-performance computing to optimize code execution patterns.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Synchronization Efficiency">
  <data key="d0">Synchronization Efficiency</data>
  <data key="d1">Variables</data>
  <data key="d2">Synchronization efficiency measures how well dependency-based synchronization is minimized within the dataflow, optimizing parallel execution.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Inter-processor Dataflow Efficiency">
  <data key="d0">Inter-processor Dataflow Efficiency</data>
  <data key="d1">Variables</data>
  <data key="d2">This efficiency assesses the minimization of network and execution costs across devices by optimizing data transfer and task mapping.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intra-processor Dataflow Efficiency">
  <data key="d0">Intra-processor Dataflow Efficiency</data>
  <data key="d1">Variables</data>
  <data key="d2">This efficiency maximizes data reuse within the same execution unit, reducing cache misses and improving performance.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Optimization Pipeline">
  <data key="d0">Optimization Pipeline</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The optimization pipeline orders nodes to maximize parallelism, reduce dependencies, and improve data reuse, utilizing a sequence of steps based on data dependencies.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MILP (Mixed Integer Linear Program)">
  <data key="d0">MILP (Mixed Integer Linear Program)</data>
  <data key="d1">Tools</data>
  <data key="d2">A mathematical model used to optimize task mapping and data transfer by solving linear programming problems with integer constraints, implemented via the Gurobi solver.&lt;SEP&gt;A mathematical modeling technique used to formulate and solve optimization problems involving task assignment, data transfer, and synchronization constraints.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Gurobi Solver">
  <data key="d0">Gurobi Solver</data>
  <data key="d1">Tools</data>
  <data key="d2">A proprietary optimization solver used to solve MILP formulations during global optimization to determine optimal task mappings and data transfers.&lt;SEP&gt;A proprietary solver for linear programming problems, used to solve the MILP formulations during global optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="AMT (Heterogeneous Application Mapping Tree)">
  <data key="d0">AMT (Heterogeneous Application Mapping Tree)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The AMT extends the APT by including optimization and mapping data, representing distributed, heterogeneous, and concurrent execution, including tasklet assignments and synchronization nodes.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tasklets">
  <data key="d0">Tasklets</data>
  <data key="d1">Variables</data>
  <data key="d2">Tasklets are small units of work derived from parallel patterns, assigned during optimization to specific cores or GPU groups to enhance performance.&lt;SEP&gt;Tasklets are small units of work derived from parallel patterns, assigned to specific cores or GPU groups, and optimized for performance and resource utilization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Mapping">
  <data key="d0">Mapping</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Mapping refers to assigning tasklets to specific hardware units (cores, GPU groups), optimizing utilization, synchronization, and data transfer.&lt;SEP&gt;Mapping refers to the assignment of tasklets to hardware resources like cores or GPU groups, aiming to optimize utilization and reduce synchronization overhead.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Transfer and Synchronization">
  <data key="d0">Data Transfer and Synchronization</data>
  <data key="d1">Tools</data>
  <data key="d2">Extensions in the AMT structure that model data movement and synchronization requirements based on data flow and task mapping, derived iteratively.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="ARRAY">
  <data key="d0">ARRAY</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An array is a data structure consisting of a collection of elements, which are accessed by index and used as the basic unit for parallel processing in the described system.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Execution Units">
  <data key="d0">Execution Units</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Execution units are hardware cores or processors that perform computations, and can be arbitrarily divided or combined to optimize parallel execution.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Expression">
  <data key="d0">Expression</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Expressions define fixed computations within the code, such as arithmetic operations, and are nodes in the APT that perform actual calculations.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Statement">
  <data key="d0">Statement</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Statements define control flow structures like loops and scope boundaries in the code, and are nodes in the APT that manage execution control.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Function Calls">
  <data key="d0">Function Calls</data>
  <data key="d1">Variables</data>
  <data key="d2">Data captured during program execution, including inputs and outputs, which are used for creating problems and evaluating solutions.&lt;SEP&gt;Function calls are special expressions referencing sub-APTs of functions, used to include function logic within the hierarchical representation without expanding fully.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda&lt;SEP&gt;chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pattern Calls">
  <data key="d0">Pattern Calls</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Pattern calls are statements that define parallel control-flow constructs, enabling the compiler to analyze and optimize parallel execution patterns.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dataflow">
  <data key="d0">Dataflow</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Dataflow refers to the movement and transformation of data between tasks and across devices, critical for optimizing parallel execution and minimizing communication costs.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Synchronization">
  <data key="d0">Synchronization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Synchronization ensures coordinated execution among threads or processes, employing barriers and MPI blocking calls to maintain data consistency.&lt;SEP&gt;Synchronization ensures correct execution order of GPU operations, typically using CUDA streams and memory barriers to coordinate data transfers and kernel launches.&lt;SEP&gt;Synchronization ensures correct ordering of memory operations and kernel launches, using mechanisms like cudaStreamSynchronize and memory barriers.&lt;SEP&gt;Synchronization involves coordinating tasks or data access to prevent conflicts, often minimized through efficiency measures during global optimization.&lt;SEP&gt;Synchronization is a process used to coordinate data access and execution order among different computational units, ensuring data consistency and correct program behavior.&lt;SEP&gt;Techniques such as barriers and MPI blocking calls that coordinate thread or process execution to ensure data consistency and proper sequencing.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b&lt;SEP&gt;chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Transfer">
  <data key="d0">Data Transfer</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data transfer involves moving data between memory, devices, or processing units, modeled explicitly in the AMT for efficient communication.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hardware Language">
  <data key="d0">Hardware Language</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The hardware language defines the hardware architecture, including cores, memory hierarchies, and device groups, used for task mapping and optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Optimization Algorithms">
  <data key="d0">Optimization Algorithms</data>
  <data key="d1">Tools</data>
  <data key="d2">Algorithms like MILP and solvers such as Gurobi are used to solve complex optimization problems related to task mapping, data transfer, and synchronization.&lt;SEP&gt;Algorithms such as stochastic gradient descent (SGD) used to train and optimize prompt embeddings during tuning processes.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Heterogeneous System">
  <data key="d0">Heterogeneous System</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A system composed of multiple types of processing units (e.g., CPU, GPU), requiring specialized mapping and data management strategies, represented by the AMT.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Transfer and Synchronization Nodes">
  <data key="d0">Data Transfer and Synchronization Nodes</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Nodes in the AMT that model data movement and synchronization events between tasklets and hardware units, derived iteratively based on data flow.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Static Array Accesses">
  <data key="d0">Static Array Accesses</data>
  <data key="d1">Variables</data>
  <data key="d2">Restrictions on array access patterns within parallel patterns that facilitate static data dependency analysis for optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Size of Partitioned Patterns">
  <data key="d0">Size of Partitioned Patterns</data>
  <data key="d1">Variables</data>
  <data key="d2">The size of tasklet partitions (tasklets) is a static parameter defined by the user, influencing granularity and performance.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dependency Analysis">
  <data key="d0">Dependency Analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Dependency analysis involves examining data dependencies within the APT to determine safe execution order and opportunities for parallelism.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Code Optimization">
  <data key="d0">Code Optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Code optimization encompasses techniques applied at the application level, such as loop fusion, data flow optimization, and task reordering, to improve performance.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Task Mapping">
  <data key="d0">Task Mapping</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Task mapping refers to assigning tasklets to specific hardware units, optimizing resource utilization, communication, and synchronization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dataflow Optimization">
  <data key="d0">Dataflow Optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Dataflow optimization aims to minimize data transfer costs and improve data reuse across processing units, based on data dependencies and hardware topology.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Cost Estimation">
  <data key="d0">Cost Estimation</data>
  <data key="d1">Tools</data>
  <data key="d2">Cost estimation models evaluate network and execution costs based on bandwidth, latency, and hardware characteristics to guide optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global Optimization Pipeline">
  <data key="d0">Global Optimization Pipeline</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A sequence of steps applying synchronization, dataflow, and other optimizations to improve overall application performance.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Pattern Expansion">
  <data key="d0">Parallel Pattern Expansion</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Expanding parallel patterns within the APT allows for detailed analysis, partitioning, and optimization of parallel code structures.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tasklet Grouping">
  <data key="d0">Tasklet Grouping</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Grouping tasklets into GPU or core groups improves utilization and reduces synchronization overhead during optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tasklet Assignments">
  <data key="d0">Tasklet Assignments</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Assignments specify which hardware units execute each tasklet, critical for mapping and performance tuning.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dataflow and Mapping Information">
  <data key="d0">Dataflow and Mapping Information</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data structures that store the results of data flow analysis and task mapping, used to derive data transfer and synchronization nodes.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Iterative Derivation">
  <data key="d0">Iterative Derivation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of deriving data transfer and synchronization nodes from data flow and task mapping iteratively, refining the model for accurate communication handling.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Access Distance">
  <data key="d0">Data Access Distance</data>
  <data key="d1">Variables</data>
  <data key="d2">The distance between execution units in terms of data access, influencing synchronization and data transfer strategies.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Shared Memory System">
  <data key="d0">Shared Memory System</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A hardware architecture where multiple processing units share memory, allowing local dependencies to be resolved with synchronization alone.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Remote Write Access">
  <data key="d0">Remote Write Access</data>
  <data key="d1">Variables</data>
  <data key="d2">Remote write accesses are data writes to remote devices that do not require synchronization, reducing overhead in distributed systems.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="synchronization">
  <data key="d0">synchronization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Synchronization is a process used to coordinate data access and execution order among different computational units, ensuring data consistency and correct program behavior.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="data flow">
  <data key="d0">data flow</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Data flow refers to the movement and processing of data between different components or modules within a computational system, fundamental for understanding dependencies and execution order.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Device local dependencies">
  <data key="d0">Device local dependencies</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Dependencies that can be resolved through synchronization in shared memory systems, assuming shared memory architecture, enabling pattern-independent read/write accesses.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Remote write accesses">
  <data key="d0">Remote write accesses</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Access type where data is written to remote device memory without requiring synchronization, as they do not cause write-after-write data races, provided data copies are invalidated appropriately.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Remote read accesses">
  <data key="d0">Remote read accesses</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Access type requiring synchronization and data transfer between device owner and requesting device, often involving creating data copies on different devices to optimize access.&lt;SEP&gt;Access type requiring synchronization and data transfer to ensure data consistency across devices, often involving creating data copies on different devices to optimize access.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Pattern Language PMAM ’24">
  <data key="d0">Parallel Pattern Language PMAM ’24</data>
  <data key="d1">Discipline</data>
  <data key="d2">A formal language designed to specify parallel programming patterns, supporting the development of portable and optimized parallel code.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Shared Memory">
  <data key="d0">Shared Memory</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A programming model where multiple processors access a common memory space, enabling direct communication and synchronization among threads or processes.&lt;SEP&gt;Shared memory is a fast, on-chip memory accessible by all threads within a block, used for communication and reduction operations.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Thread Pool">
  <data key="d0">Thread Pool</data>
  <data key="d1">Tools</data>
  <data key="d2">A collection of pre-instantiated threads used to execute tasks efficiently, facilitating task assignment and synchronization in parallel programming.&lt;SEP&gt;A thread pool manages a collection of threads to perform multiple tasks concurrently, optimizing resource utilization in parallel processing.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Synchronization between execution units">
  <data key="d0">Synchronization between execution units</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques to coordinate tasks and data exchanges among different hardware components, including intra-device, intra-node, and inter-device synchronization.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data transfers">
  <data key="d0">Data transfers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Movement of data between CPU and GPU or among distributed GPUs, essential for maintaining data consistency and optimizing performance.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance optimization">
  <data key="d0">Performance optimization</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">How to improve the efficiency of heterogeneous systems through code generation, data movement, and synchronization strategies.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory footprint">
  <data key="d0">Memory footprint</data>
  <data key="d1">Variables</data>
  <data key="d2">The amount of memory used by data copies and buffers during computation, which can impact network traffic and resource utilization.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intra-device synchronization">
  <data key="d0">Intra-device synchronization</data>
  <data key="d1">Methods</data>
  <data key="d2">Synchronization mechanisms within a single device, such as a GPU, to coordinate parallel tasks without additional data transfer.&lt;SEP&gt;Synchronization within a single device, such as a GPU, to coordinate parallel tasks without involving data transfer across devices.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intra-node synchronization">
  <data key="d0">Intra-node synchronization</data>
  <data key="d1">Methods</data>
  <data key="d2">Synchronization among all accelerators and the host within a node, ensuring data consistency and task coordination.&lt;SEP&gt;Synchronization of all accelerators with the host within a single node to coordinate data and task execution.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Optimization patterns">
  <data key="d0">Optimization patterns</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Predefined strategies supported by the code generator to optimize execution across different hardware architectures.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data flow">
  <data key="d0">Data flow</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Data flow refers to the movement and processing of data between different components or modules within a computational system, fundamental for understanding dependencies and execution order.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hardware architecture">
  <data key="d0">Hardware architecture</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The underlying physical and logical structure of computational systems, including CPUs, GPUs, and memory hierarchies, influencing optimization strategies.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tasklet">
  <data key="d0">Tasklet</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A small unit of work or task assigned to an execution unit, such as a thread or core, in parallel processing.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Workload pinning">
  <data key="d0">Workload pinning</data>
  <data key="d1">Variables</data>
  <data key="d2">The process of binding specific tasks or tasklets to particular hardware cores or execution units to optimize performance.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dynamic load balancing">
  <data key="d0">Dynamic load balancing</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigating strategies to distribute computational workload dynamically across hardware resources to improve efficiency and resource utilization.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Heterogeneous system">
  <data key="d0">Heterogeneous system</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A computing environment composed of different types of processing units (CPUs, GPUs, accelerators) working together to perform computations.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Source-to-source compiler">
  <data key="d0">Source-to-source compiler</data>
  <data key="d1">Tools</data>
  <data key="d2">A compiler that translates high-level code into optimized code for different hardware architectures, supporting performance improvements and hardware utilization.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pinning of workload">
  <data key="d0">Pinning of workload</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Assigning specific tasks to particular hardware units to optimize execution and reduce overhead.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Implementation">
  <data key="d0">Implementation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The actual code and system setup supporting the features of shared memory, data movement, synchronization, and workload assignment.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Explicit synchronization">
  <data key="d0">Explicit synchronization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Synchronization explicitly coded in the system to coordinate tasks and data movement across hardware units.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Implicit synchronization">
  <data key="d0">Implicit synchronization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Synchronization handled automatically by hardware or runtime, such as implicit GPU synchronization during reduction patterns.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pattern support">
  <data key="d0">Pattern support</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The ability of the code generator to implement various parallel execution patterns, such as reduction, data movement, and workload distribution.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Shared Memory Parallelism">
  <data key="d0">Shared Memory Parallelism</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A programming approach where multiple threads execute concurrently within a shared memory space, enabling efficient parallel processing.&lt;SEP&gt;Shared memory parallelism refers to a programming approach where multiple threads run concurrently within a shared memory space, enabling parallel execution to improve performance.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="POSIX Threads">
  <data key="d0">POSIX Threads</data>
  <data key="d1">Tools</data>
  <data key="d2">A standardized API for creating, managing, and synchronizing threads in a shared memory environment, supporting parallel task execution.&lt;SEP&gt;POSIX threads are a standardized API for creating and managing threads in a shared memory environment, supporting parallel task execution.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="HWL">
  <data key="d0">HWL</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Hardware Layer (HWL) specifies the number of cores and configuration for thread pinning, directly influencing parallel execution capabilities.&lt;SEP&gt;Hardware Layer (HWL) specifies the number of cores and the configuration for thread pinning, directly influencing parallel execution.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hyper-threading">
  <data key="d0">Hyper-threading</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A hardware feature that allows a single CPU core to handle multiple threads simultaneously, but it is currently disregarded in the execution context.&lt;SEP&gt;Hyper-threading is a technology that allows a single CPU core to handle multiple threads, but it is currently disregarded in this context.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Thread Pinning">
  <data key="d0">Thread Pinning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of binding threads to specific CPU cores using functions like pthread_setaffinity_np to optimize performance and reduce context switches.&lt;SEP&gt;Thread pinning involves binding threads to specific CPU cores to optimize performance and reduce context switching.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Lambda Functions">
  <data key="d0">Lambda Functions</data>
  <data key="d1">Tools</data>
  <data key="d2">Anonymous functions used for deferred execution in parallel programming, allowing flexible task scheduling and data encapsulation.&lt;SEP&gt;Lambda functions are anonymous functions used for deferred execution in parallel programming, enabling flexible task scheduling.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Race">
  <data key="d0">Data Race</data>
  <data key="d1">Results</data>
  <data key="d2">A condition where multiple threads access shared data concurrently without proper synchronization, leading to inconsistent or erroneous results.&lt;SEP&gt;Data races are conflicts that occur when multiple threads access shared data simultaneously without proper synchronization, leading to inconsistent results.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="pthread_setaffinity_np">
  <data key="d0">pthread_setaffinity_np</data>
  <data key="d1">Tools</data>
  <data key="d2">A POSIX function that sets thread affinity, pinning threads to specific cores for performance optimization.&lt;SEP&gt;This is a POSIX function used to set thread affinity, pinning threads to specific CPU cores for performance optimization.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MPI (Message Passing Interface)">
  <data key="d0">MPI (Message Passing Interface)</data>
  <data key="d1">Tools</data>
  <data key="d2">A standardized API for message passing in distributed memory systems, enabling explicit data transfer and synchronization across nodes.&lt;SEP&gt;MPI is a standardized and portable message-passing system designed to function on parallel computing architectures, supporting distributed memory models.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MPI Communication">
  <data key="d0">MPI Communication</data>
  <data key="d1">Methods</data>
  <data key="d2">MPI communication involves explicit data transfers between nodes using collective operations like reduction, facilitating synchronization across distributed systems.&lt;SEP&gt;MPI functions facilitate explicit data transfers and collective operations like reduction, enabling synchronization among distributed nodes.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Barrier Tasks">
  <data key="d0">Barrier Tasks</data>
  <data key="d1">Tools</data>
  <data key="d2">Barrier tasks are synchronization points where threads or processes wait until all participants reach the barrier, ensuring coordinated progress.&lt;SEP&gt;Synchronization points where threads or processes wait until all participants reach the barrier, ensuring coordinated progress.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pattern Implementation">
  <data key="d0">Pattern Implementation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Decomposition of algorithms into map, stencil, and reduction steps, with synchronization and atomic operations in reduction for correctness.&lt;SEP&gt;Pattern decomposition into map, stencil, and reduction steps enables structured parallel execution, with reduction involving synchronization and atomic operations.&lt;SEP&gt;Pattern implementation involves defining how computational patterns are mapped onto GPU threads, including workload splitting and handling remainders to optimize parallel execution.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory Locality">
  <data key="d0">Memory Locality</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Memory locality refers to accessing data stored close together in memory to improve cache performance and reduce latency during parallel computations.&lt;SEP&gt;Memory locality refers to optimizing data placement and movement across memory hierarchies to improve computational efficiency during offloading.&lt;SEP&gt;Strategies to optimize data placement and movement across memory hierarchies during offloading, reducing latency and increasing throughput.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="CUDA Calls">
  <data key="d0">CUDA Calls</data>
  <data key="d1">Tools</data>
  <data key="d2">CUDA calls are specific function calls within the CUDA API used to allocate, free, and transfer data on the GPU, essential for managing GPU memory and execution.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Execution Range">
  <data key="d0">Execution Range</data>
  <data key="d1">Variables</data>
  <data key="d2">The execution range defines how many iterations each thread performs in parallel, crucial for workload distribution in GPU kernels.&lt;SEP&gt;The execution range specifies how many iterations each thread performs, balancing workload and optimizing execution.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Shared Memory Threads">
  <data key="d0">Shared Memory Threads</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Shared memory threads are threads that share access to certain memory regions, facilitating intra-block communication and synchronization in GPU programming.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Inlining">
  <data key="d0">Inlining</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Inlining replaces function calls with the function's body to enable further optimizations like loop unrolling and parallelization, crucial in code flattening for GPU kernels.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Loop Unrolling">
  <data key="d0">Loop Unrolling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Loop unrolling involves repeating the loop body multiple times to reduce loop overhead, with considerations to avoid including loops with break or continue statements to maintain correctness.&lt;SEP&gt;Loop unrolling is an optimization technique that expands loops to reduce iteration overhead and improve instruction-level parallelism in GPU code.&lt;SEP&gt;Loop unrolling repeats loop bodies multiple times to reduce overhead, avoiding loops with break or continue statements to preserve correctness.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Atomic Operations">
  <data key="d0">Atomic Operations</data>
  <data key="d1">Tools</data>
  <data key="d2">Atomic operations perform read-modify-write actions atomically, preventing race conditions during concurrent updates to shared variables in GPU parallel code.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MILP Specification">
  <data key="d0">MILP Specification</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The MILP (Mixed-Integer Linear Programming) specification defines the semantics and constraints for global optimization problems, ensuring correctness during parallel pattern optimization.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hierarchical Structure">
  <data key="d0">Hierarchical Structure</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Hierarchical structure refers to nested code or function calls, which require flattening through inlining and unrolling to enable effective parallel optimization.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Function Call">
  <data key="d0">Function Call</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A function call invokes a subroutine or function within code, which can be inlined to optimize performance and facilitate parallelization.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Return Statement">
  <data key="d0">Return Statement</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A return statement marks the end of a function's execution and returns control and data to the caller, important for control flow analysis.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Jump Label">
  <data key="d0">Jump Label</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A jump label is a marker associated with function calls that facilitates control flow, enabling referencing during return statements and managing code execution paths.&lt;SEP&gt;A jump label is a marker associated with function calls that facilitates control flow, especially for implementing return statements and managing code execution paths.&lt;SEP&gt;A jump label marks a position in code to facilitate control transfer during inlining and return processing.&lt;SEP&gt;A jump label marks a specific position in code for control transfer, used in implementing non-linear control flow such as function returns.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Scope">
  <data key="d0">Scope</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Scope defines the visibility and lifetime of variables and functions within code blocks, critical for avoiding conflicts during inlining and code transformation.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Work-sharing">
  <data key="d0">Work-sharing</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Work-sharing involves dividing tasks among multiple threads or processing units to perform computations in parallel efficiently.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Replacer">
  <data key="d0">Replacer</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A replacer is a data structure used during inlining to store nodes that replace function calls, facilitating code flattening.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Arguments">
  <data key="d0">Arguments</data>
  <data key="d1">Variables</data>
  <data key="d2">Arguments are input parameters passed to functions, which are copied during inlining to maintain data integrity and enable concurrency.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Local Array">
  <data key="d0">Local Array</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A local array is a data structure used within functions to store temporary data, which must be written to a new local array to prevent write-after-write and write-after-read dependencies.&lt;SEP&gt;A local array is a temporary copy of data created within a function to avoid conflicts and dependencies during nested parallel patterns.&lt;SEP&gt;A local array is a temporary data structure used within functions to store intermediate results, which must be written to a new local array to avoid write-after-write and write-after-read conflicts.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Index">
  <data key="d0">Index</data>
  <data key="d1">Variables</data>
  <data key="d2">Index in CUDA typically refers to thread or block indices used to determine work assignment in parallel kernels.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Iteration">
  <data key="d0">Iteration</data>
  <data key="d1">Variables</data>
  <data key="d2">An iteration refers to a single cycle of a loop or pattern execution, which is distributed across threads in parallel processing.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Remainder">
  <data key="d0">Remainder</data>
  <data key="d1">Variables</data>
  <data key="d2">The remainder is the leftover amount when dividing total work among threads, handled specially to ensure all data is processed.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Indexing Formula">
  <data key="d0">Indexing Formula</data>
  <data key="d1">Variables</data>
  <data key="d2">The formula INDEX = t*r + i + n calculates the current data element a thread processes, accounting for remainders and thread IDs.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intra-Block Reduction">
  <data key="d0">Intra-Block Reduction</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Intra-block reduction combines partial results within a GPU thread block, often using shared memory and atomic operations.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Inter-Block Reduction">
  <data key="d0">Inter-Block Reduction</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Inter-block reduction combines results across different thread blocks, often involving multiple kernel launches or global memory operations.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Movement">
  <data key="d0">Data Movement</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Data movement involves transferring data between host and device or within device memory, critical for performance and correctness in GPU computations.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Transfer Functions">
  <data key="d0">Data Transfer Functions</data>
  <data key="d1">Tools</data>
  <data key="d2">Functions like cudaMalloc, cudaFree, and cudaMemcpy manage GPU memory allocation, deallocation, and data transfers.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Concurrency">
  <data key="d0">Concurrency</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Concurrency allows multiple computations to occur simultaneously, such as data transfers and kernel executions, improving throughput.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pattern Assignment">
  <data key="d0">Pattern Assignment</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Pattern assignment defines how iterations are distributed to threads, considering workload balance and remainders for optimal performance.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Semantic Preservation">
  <data key="d0">Semantic Preservation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Semantic preservation ensures that code transformations like inlining and unrolling do not alter the intended behavior of the program.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Flattening">
  <data key="d0">Flattening</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Flattening converts hierarchical, nested code structures into linear sequences suitable for parallel execution.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Code Flattening">
  <data key="d0">Code Flattening</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Code flattening involves transforming nested functions and loops into a single-level structure for easier optimization and parallelization.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Inlining Algorithm">
  <data key="d0">Inlining Algorithm</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The inlining algorithm replaces a function call with the function's body, handling parameters, jump labels, and return values to optimize code execution.&lt;SEP&gt;The inlining algorithm replaces function calls with their bodies, handling parameters, jump labels, and return values to optimize code execution.&lt;SEP&gt;The inlining algorithm replaces function calls with their bodies, managing variable scopes and arguments to enable parallel pattern recognition.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Scope Extension">
  <data key="d0">Scope Extension</data>
  <data key="d1">Variables</data>
  <data key="d2">Scope extension involves modifying variable names with hashes during inlining to prevent conflicts and maintain correctness.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Arguments Copying">
  <data key="d0">Arguments Copying</data>
  <data key="d1">Variables</data>
  <data key="d2">Arguments are copied during inlining to preserve data integrity and enable nested parallel patterns.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Return Handling">
  <data key="d0">Return Handling</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Handling return statements involves creating jump labels and control flow adjustments to maintain correct execution flow after inlining.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Control Flow">
  <data key="d0">Control Flow</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Control flow dictates the order of execution in a program, which must be preserved during code transformations like inlining and flattening.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Replacers">
  <data key="d0">Replacers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Replacers store nodes that replace original function calls during inlining, enabling code flattening and optimization.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Function Arguments">
  <data key="d0">Function Arguments</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Function arguments are the inputs passed to functions, which can be nested and involve parallel patterns, requiring careful handling to prevent dependencies.&lt;SEP&gt;Function arguments refer to the inputs passed to functions, which can be nested and involve parallel patterns, requiring careful handling to avoid dependencies.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Nested Parallel Patterns">
  <data key="d0">Nested Parallel Patterns</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Nested parallel patterns involve executing multiple parallel operations within other parallel operations, necessitating specific strategies to manage dependencies and data flow.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Write-After-Write Dependencies">
  <data key="d0">Write-After-Write Dependencies</data>
  <data key="d1">Limitations</data>
  <data key="d2">These dependencies occur when a write operation overwrites data that has not yet been read, which can cause incorrect program behavior if not properly managed.&lt;SEP&gt;Write-after-write dependencies occur when a write operation overwrites data that has not yet been read, potentially causing incorrect behavior if not properly managed.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Write-After-Read Dependencies">
  <data key="d0">Write-After-Read Dependencies</data>
  <data key="d1">Limitations</data>
  <data key="d2">These dependencies occur when a write operation occurs after a read of the same data, potentially leading to data inconsistency if dependencies are not handled properly.&lt;SEP&gt;Write-after-read dependencies occur when a write operation follows a read of the same data, risking data inconsistency if dependencies are not handled.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Return Node">
  <data key="d0">Return Node</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A ReturnNode is a node in the code structure that signifies a return statement within a function, used to control flow and deallocate local data.&lt;SEP&gt;A ReturnNode signifies a return statement in the code, used to control flow and deallocate local data during function execution.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hashing of Variables">
  <data key="d0">Hashing of Variables</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Hashing variables involves creating a unique identifier for variables to replace references during deep copying and variable replacement processes, ensuring consistency in inlined code.&lt;SEP&gt;Hashing variables involves creating unique identifiers for variables to replace references during code transformations, ensuring consistency in inlined code.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Deep Copying">
  <data key="d0">Deep Copying</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Deep copying creates an exact duplicate of data structures or code nodes to prevent side effects during transformations, maintaining data integrity.&lt;SEP&gt;Deep copying involves creating an exact duplicate of data structures or code nodes to prevent side effects and maintain integrity during transformations.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="ReplaceVars Function">
  <data key="d0">ReplaceVars Function</data>
  <data key="d1">Methodologies</data>
  <data key="d2">ReplaceVars is a process that substitutes variable references in code with their hashed or transformed versions, facilitating inlining and code optimization.&lt;SEP&gt;ReplaceVars substitutes variable references with hashed or transformed versions, facilitating code inlining and optimization.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Function Call Replacer">
  <data key="d0">Function Call Replacer</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The call.replacer variable encapsulates return values of functions, used to replace original function calls with inlined code or variables during code generation.&lt;SEP&gt;The call.replacer variable encapsulates the return values of a function, used to replace the original function call with inlined code or variables during code generation.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenMP Rodinia Benchmark Suite">
  <data key="d0">OpenMP Rodinia Benchmark Suite</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark suite used to evaluate parallel programming tools and code generation performance, covering diverse computational patterns.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hardware Environment">
  <data key="d0">Hardware Environment</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The evaluation is performed on CLAIX18 systems with Xeon Platinum 8160 CPUs, 24 cores per socket, and 192 GB RAM, providing context for performance results.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Environment">
  <data key="d0">Environment</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The environment describes the technical setup including systems, hardware, and software used for measurements and computations.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="CLAIX18 systems">
  <data key="d0">CLAIX18 systems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">High-performance computing systems used for experiments, equipped with CPUs, GPUs, network fabric, and running specific OS.&lt;SEP&gt;The CLAIX18 systems are high-performance computing systems equipped with multiple processors, memory, network fabric, and GPUs used for performing measurements and computations.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="RWTH Aachen University">
  <data key="d0">RWTH Aachen University</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Academic institution hosting the systems and conducting the research.&lt;SEP&gt;The RWTH Aachen University is an academic institution where the systems are located and where the experiments are conducted.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Xeon Platinum 8160 24C 2.1GHz">
  <data key="d0">Xeon Platinum 8160 24C 2.1GHz</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A specific CPU model used in the systems, featuring 24 cores, for high-performance processing.&lt;SEP&gt;High-performance CPU model used in the systems, with 24 cores for intensive computation.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intel Omni-Path 100G">
  <data key="d0">Intel Omni-Path 100G</data>
  <data key="d1">Tools</data>
  <data key="d2">High-speed network fabric enabling fast data transfer between system nodes.&lt;SEP&gt;The Intel Omni-Path 100G network fabric connects nodes in the system, enabling high-speed data transfer.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rocky 8.9">
  <data key="d0">Rocky 8.9</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An operating system running on the nodes, providing the environment for computations and software execution.&lt;SEP&gt;Operating system on the nodes, providing the environment for software execution.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="NVIDIA V100 GPUs">
  <data key="d0">NVIDIA V100 GPUs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">GPU hardware used for acceleration in computations.&lt;SEP&gt;High-performance graphics processing units used for GPU-accelerated computations in the system.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intel OneAPI C/C++ Compiler 2022.1.0">
  <data key="d0">Intel OneAPI C/C++ Compiler 2022.1.0</data>
  <data key="d1">Tools</data>
  <data key="d2">Software compiler used for code compilation with high optimization levels.&lt;SEP&gt;Software tool used for compiling code with high optimization levels to improve performance.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="IntelMPI 2021.6.0">
  <data key="d0">IntelMPI 2021.6.0</data>
  <data key="d1">Tools</data>
  <data key="d2">MPI implementation used for parallel process communication.&lt;SEP&gt;MPI implementation used for parallel programming and communication between processes.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="CUDA 11.8">
  <data key="d0">CUDA 11.8</data>
  <data key="d1">Tools</data>
  <data key="d2">GPU programming platform used for developing GPU-accelerated applications.&lt;SEP&gt;GPU programming platform used for developing and running GPU-accelerated applications.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global optimizations">
  <data key="d0">Global optimizations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Optimization approach that avoids artificial synchronization points to ensure measurement accuracy by reducing dependencies and dependencies-induced artifacts.&lt;SEP&gt;Optimization approach that avoids synchronization points to improve measurement accuracy by reducing dependencies.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Wall-clock times">
  <data key="d0">Wall-clock times</data>
  <data key="d1">Results</data>
  <data key="d2">Average execution durations measured over multiple repetitions, used to assess performance.&lt;SEP&gt;Average measurement of execution durations across multiple repetitions, used to evaluate performance.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Gurobi">
  <data key="d0">Gurobi</data>
  <data key="d1">Tools</data>
  <data key="d2">A mathematical optimization solver that introduces instabilities due to its random seed, affecting scheduling outcomes in optimization processes.&lt;SEP&gt;Optimization solver that introduces potential instability due to stochastic initial solutions, used in scheduling and optimization tasks.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Random seeds">
  <data key="d0">Random seeds</data>
  <data key="d1">Variables</data>
  <data key="d2">Different initializations used in Gurobi to mitigate solution instability and variability in results.&lt;SEP&gt;Different initializations used in Gurobi to mitigate solution variability and improve stability.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Generator test cases">
  <data key="d0">Generator test cases</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specific test scenarios used to evaluate code generation and optimization processes, showing variability with different seeds.&lt;SEP&gt;Specific test scenarios used to evaluate the optimization and code generation processes, showing variability in results with different seeds.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kernels">
  <data key="d0">Kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Individual computational tasks such as batch classification, jacobi solver, monte-carlo estimation, multi-filter convolution, and neural network forward pass used in performance testing.&lt;SEP&gt;Individual computational tasks such as classification, solvers, estimation, convolution, neural network passes used in performance evaluation.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Baseline">
  <data key="d0">Baseline</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Naive CPU parallelization of kernels serving as a reference point for performance comparison.&lt;SEP&gt;Naive CPU parallelization serving as a reference point for performance comparison.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Handwritten implementation">
  <data key="d0">Handwritten implementation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Manually optimized code used as benchmark for evaluating generated code performance.&lt;SEP&gt;Optimized manually by developers, representing a benchmark for evaluating generated code performance.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Generated code">
  <data key="d0">Generated code</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Code automatically produced by the PPL toolchain, evaluated for performance and stability.&lt;SEP&gt;Code produced automatically by the PPL toolchain, assessed for efficiency and stability across kernels.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rodinia benchmark suite">
  <data key="d0">Rodinia benchmark suite</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A comprehensive set of benchmarks designed to evaluate HPC applications based on the Berkeley dwarfs, used for testing code applicability and coverage.&lt;SEP&gt;Benchmark suite designed to evaluate HPC application performance based on the Berkeley dwarfs.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Berkeley dwarfs">
  <data key="d0">Berkeley dwarfs</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A classification of computational patterns and applications that guide benchmark design, aiming to cover a broad range of HPC workloads.&lt;SEP&gt;Classification framework for computational patterns in HPC, guiding benchmark design.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenMP benchmarks">
  <data key="d0">OpenMP benchmarks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Parallel benchmarks within Rodinia, used to evaluate multi-threaded performance.&lt;SEP&gt;Parallel programming benchmarks using OpenMP, part of the Rodinia suite, used to evaluate parallel code performance.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Port">
  <data key="d0">Port</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Adapted versions of benchmarks for the PPL environment, ensuring correct execution and comparability.&lt;SEP&gt;Ported versions of benchmarks adapted for the PPL environment, ensuring comparability and correct execution.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="5.953">
  <data key="d0">5.953</data>
  <data key="d1">Results</data>
  <data key="d2">Numerical data points and measurements, possibly representing performance metrics or experimental results.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="0.072">
  <data key="d0">0.072</data>
  <data key="d1">Results</data>
  <data key="d2">Additional numerical value, potentially related to measurement accuracy or specific experimental data.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="0.236">
  <data key="d0">0.236</data>
  <data key="d1">Results</data>
  <data key="d2">Another numerical value, possibly indicating a measurement or parameter in the study.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Generated">
  <data key="d0">Generated</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Code or data generated by an automated process, specifically referring to code produced by the PPL toolchain.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="0.913">
  <data key="d0">0.913</data>
  <data key="d1">Results</data>
  <data key="d2">Measurement value, likely representing runtime or performance metric for a specific kernel or process.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="1.590">
  <data key="d0">1.590</data>
  <data key="d1">Results</data>
  <data key="d2">Additional measurement value, possibly an execution time or performance indicator.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="21.919">
  <data key="d0">21.919</data>
  <data key="d1">Results</data>
  <data key="d2">Another numerical result, potentially a runtime or computational metric.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="0.043">
  <data key="d0">0.043</data>
  <data key="d1">Results</data>
  <data key="d2">Measurement value, possibly indicating a specific performance measurement or error margin.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="0.162">
  <data key="d0">0.162</data>
  <data key="d1">Results</data>
  <data key="d2">Additional performance-related value, possibly related to timing or accuracy.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="5.1 Environment">
  <data key="d0">5.1 Environment</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The overall computational environment setup, including hardware, software, and configuration details for experiments.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="All measurements">
  <data key="d0">All measurements</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The process of performing measurements across the system to collect data for analysis.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Measurement">
  <data key="d0">Measurement</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The process of recording execution times and other metrics to evaluate performance.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPLin">
  <data key="d0">PPLin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A programming paradigm or approach designed to optimize and adapt code for parallel execution, particularly in benchmarking and performance tuning contexts.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rodinia">
  <data key="d0">Rodinia</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark suite for evaluating heterogeneous architectures and optimization techniques.&lt;SEP&gt;A benchmark suite used for evaluating parallel computing performance across various applications and kernels.&lt;SEP&gt;Rodinia is a benchmark suite for evaluating heterogeneous computing architectures and optimization techniques.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2&lt;SEP&gt;chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPLport">
  <data key="d0">PPLport</data>
  <data key="d1">Tools</data>
  <data key="d2">A version or adaptation of code tailored to fit specific dataset sizes and optimize parallel execution within the Rodinia benchmarks.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kmeans">
  <data key="d0">Kmeans</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A clustering algorithm benchmark optimized for parallel execution, used to evaluate performance improvements.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="nnbenchmarks">
  <data key="d0">nnbenchmarks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Neural network benchmarks that have been optimized for better utilization of parallel hardware resources.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dynamic control-flow">
  <data key="d0">Dynamic control-flow</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A challenge in code optimization where nested or dynamic control structures hinder static analysis and optimization, exemplified by benchmarks like bfs and streamcluster.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Large search space">
  <data key="d0">Large search space</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A complexity factor in optimization where the vast number of potential scheduling or execution paths (e.g., in cfd, nw, pathfinder) makes optimization computationally infeasible within reasonable time.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory overhead">
  <data key="d0">Memory overhead</data>
  <data key="d1">Limitations</data>
  <data key="d2">A constraint where excessive memory requirements per thread (as in myocyte kernel) limit scalability and performance.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Static control-flow">
  <data key="d0">Static control-flow</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An approach that simplifies kernel structure by eliminating branches, as done in hotspot benchmark, to improve parallel execution.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global optimization">
  <data key="d0">Global optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A comprehensive scheduling and resource allocation process that may choose to utilize only a subset of hardware resources based on cost-benefit analysis of data transfer and synchronization overhead.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="port for the PPLin">
  <data key="d0">port for the PPLin</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A specific implementation or version of PPL designed to adapt and optimize code for performance measurement and benchmarking in parallel computing.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="previous work">
  <data key="d0">previous work</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Refers to earlier research or implementations related to PPLin, providing context or baseline for current work.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="errors">
  <data key="d0">errors</data>
  <data key="d1">Results</data>
  <data key="d2">Errors detected by the compiler that prompted code modifications and optimizations in the benchmarks.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="timing measurements">
  <data key="d0">timing measurements</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics added to benchmarks to evaluate performance and speedup after modifications.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="data set/configuration">
  <data key="d0">data set/configuration</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The largest dataset/configuration provided by the scripts shipped with Rodinia, used as standard for all benchmarks.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="original code">
  <data key="d0">original code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The initial implementation of benchmarks before optimization, used as a comparison baseline.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="optimized code">
  <data key="d0">optimized code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The modified version of benchmarks after applying PPL and other optimizations, aimed at improved performance.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="kernels">
  <data key="d0">kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Core computational components within benchmarks, such as kmeans and nnbenchmarks, optimized for better parallelism.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="runtime">
  <data key="d0">runtime</data>
  <data key="d1">Results</data>
  <data key="d2">Execution time of benchmarks, used to calculate speedups and performance improvements.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="speedup">
  <data key="d0">speedup</data>
  <data key="d1">Results</data>
  <data key="d2">A measure of performance improvement, with up to 12.43x speedup achieved through optimizations.&lt;SEP&gt;Performance improvement metrics, with the lavaMD benchmark achieving over two times speedup due to compiler optimizations from Intel OneAPI.&lt;SEP&gt;Quantitative measure of performance gain, calculated as ratio of original to optimized runtime, with observed values up to 57 times faster.&lt;SEP&gt;Speedup measures how much faster a program runs after optimization compared to a baseline, with up to 12.43x achieved in this context.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2&lt;SEP&gt;chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="support">
  <data key="d0">support</data>
  <data key="d1">Limitations</data>
  <data key="d2">Benchmark codes not supported in PPL due to porting issues or significant kernel alterations, including b+tree, mummerGPU, and others.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dynamic control-flow">
  <data key="d0">dynamic control-flow</data>
  <data key="d1">Limitations</data>
  <data key="d2">Structural challenge where nested or dynamic control structures like in bfs and streamcluster hinder optimization due to inability to represent them with the current mapping algorithm.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="large search space">
  <data key="d0">large search space</data>
  <data key="d1">Limitations</data>
  <data key="d2">Optimization challenge where applications like cfd, nw, and pathfinder have a huge number of interdependent tasks, making scheduling infeasible within reasonable time.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dynamic workload">
  <data key="d0">dynamic workload</data>
  <data key="d1">Limitations</data>
  <data key="d2">Specific issue exemplified by the lud benchmark, where the creation of a triangular matrix with branches leads to load imbalance and analysis difficulty.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="memory overhead">
  <data key="d0">memory overhead</data>
  <data key="d1">Limitations</data>
  <data key="d2">Constraint where high memory requirements per thread (as in myocyte kernel) restrict scalability and performance gains.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="tiling">
  <data key="d0">tiling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique used in the original hotspot code that was not supported in the DSL, leading to code rewriting for element-wise iteration.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="extraction of corner cases">
  <data key="d0">extraction of corner cases</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A static analysis approach used to avoid branches by isolating edge cases, improving parallel execution in hotspot.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="static reduction">
  <data key="d0">static reduction</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process where the code is simplified to eliminate branches and branches, reducing runtime and improving parallelism, as in hotspot.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="global optimization">
  <data key="d0">global optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An overarching scheduling process that may choose to utilize only a subset of hardware resources based on transfer and synchronization costs, impacting overall speedup.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="compiler optimizations">
  <data key="d0">compiler optimizations</data>
  <data key="d1">Tools</data>
  <data key="d2">Optimizations from Intel OneAPI that contributed to the speedup in lavaMD, enabling more aggressive code improvements.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Static Overhead">
  <data key="d0">Static Overhead</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Refers to the fixed costs associated with program execution, which can be reduced to improve performance, especially in smaller applications.&lt;SEP&gt;The fixed costs associated with executing static code, which can be minimized to enhance performance, especially in small applications.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Backprop, nn, srad benchmarks">
  <data key="d0">Backprop, nn, srad benchmarks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Benchmark applications used to evaluate performance improvements in the PPL approach.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="lavaMD benchmark">
  <data key="d0">lavaMD benchmark</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A specific benchmark used to demonstrate the potential of the PPL to enable aggressive compiler optimizations, achieving speedups of up to 3.5 times.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Workflow">
  <data key="d0">Workflow</data>
  <data key="d1">Methodology</data>
  <data key="d2">The process by which PPL performs automatic, global optimization of static codes across different hardware architectures, requiring minimal source code changes.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Single Source">
  <data key="d0">Single Source</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A programming model where code is written once and deployed on multiple architectures, enhancing productivity and maintainability.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hardware Description">
  <data key="d0">Hardware Description</data>
  <data key="d1">Tools</data>
  <data key="d2">Describes the target system hardware, which can be modified to tune performance without changing the source code.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Porting Applications">
  <data key="d0">Porting Applications</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The process of adapting existing applications written in C/C++ or Fortran to new architectures, which is often effort-intensive; the PPL aims to simplify this.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Annotations">
  <data key="d0">Annotations</data>
  <data key="d1">Tools</data>
  <data key="d2">Annotations similar to OpenMP used to identify parallel patterns in source code, aiding in porting and reusability.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance Slowdown">
  <data key="d0">Performance Slowdown</data>
  <data key="d1">Results</data>
  <data key="d2">A 17% slowdown observed for the batch kernel compared to hand-optimized code, indicating room for optimization.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kernel Fusion">
  <data key="d0">Kernel Fusion</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An optimization technique yet to be implemented for the jacobi kernel to improve performance.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Reduction Implementation">
  <data key="d0">Reduction Implementation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Custom reduction strategies for the monte kernel to address shared, distributed memory, and offloading challenges.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dynamic Behavior">
  <data key="d0">Dynamic Behavior</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Refers to applications with workloads that change during runtime, such as b+tree and bfs, which are less suited for static optimization approaches.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Dependency Analysis">
  <data key="d0">Data Dependency Analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Analysis to identify dynamic workloads at compile time, potentially enabling more adaptive static optimization.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dependency Chain">
  <data key="d0">Dependency Chain</data>
  <data key="d1">Variables</data>
  <data key="d2">Sequences of dependencies among variables that can be extracted to identify runtime arguments and control flow structures.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Compatibility Layer">
  <data key="d0">Compatibility Layer</data>
  <data key="d1">Tools</data>
  <data key="d2">A proposed interface or layer to connect SDFGs with the APT for enhanced dependency analysis in the PPL framework.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Runtime-Dependent Applications">
  <data key="d0">Runtime-Dependent Applications</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Applications whose behavior depends on runtime conditions, requiring dynamic code adaptations.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Legion">
  <data key="d0">Legion</data>
  <data key="d1">Tools</data>
  <data key="d2">A runtime system supporting execution of patterns and tasklets of unknown size, facilitating dynamic load balancing and GPU support.&lt;SEP&gt;A runtime system supporting execution of tasklets with unknown sizes, enabling dynamic load balancing and GPU support.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="StarPU">
  <data key="d0">StarPU</data>
  <data key="d1">Tools</data>
  <data key="d2">A runtime system enabling migration of tasklets in distributed memory during runtime, supporting dynamic applications and GPU execution.&lt;SEP&gt;A runtime system that allows migration of tasklets during execution across distributed memory, supporting dynamic workloads and GPU offloading.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tasklet Scheduling">
  <data key="d0">Tasklet Scheduling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of assigning computational tasks to resources; scalability issues arise with exponential search spaces, as seen in some Rodinia benchmarks.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Variable Names">
  <data key="d0">Variable Names</data>
  <data key="d1">Variables</data>
  <data key="d2">Influenced by random seeds, affecting the duration and stability of solving processes in scheduling problems.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Beam Search">
  <data key="d0">Beam Search</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A search algorithm used as an alternative to LP-solvers for creating predictable, stable, and reproducible solutions by pruning the search space.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pruning Strategies">
  <data key="d0">Pruning Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques like n-best to limit search space during beam search, controlling compile-time and ensuring stability.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallelism in Dynamic Control Flow">
  <data key="d0">Parallelism in Dynamic Control Flow</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ability to execute parallel patterns within loops and branches, enabled by approaches like beam search and advanced scheduling.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory Model">
  <data key="d0">Memory Model</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The structure and management of memory during code generation, with an emphasis on avoiding local memory copies to improve efficiency.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="backprop">
  <data key="d0">backprop</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">A benchmark application used to evaluate performance improvements in neural network training.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="nn">
  <data key="d0">nn</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">Neural network benchmark used to assess performance in the context of the PPL approach.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="srad">
  <data key="d0">srad</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">Benchmark application used to measure performance gains in the PPL framework.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="lavaMD">
  <data key="d0">lavaMD</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">A molecular dynamics benchmark used to demonstrate the impact of the PPL on compiler optimizations and speedups.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="workflow">
  <data key="d0">workflow</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">The process by which PPL performs static code optimization, involving source code analysis and transformation to target multiple architectures efficiently.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="single source">
  <data key="d0">single source</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">A programming approach where code is written once and deployed across multiple hardware architectures, improving productivity and maintainability.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="hardware description">
  <data key="d0">hardware description</data>
  <data key="d1">&lt;|Tools</data>
  <data key="d2">Describes hardware characteristics of target systems, which can be modified to tune performance without changing source code.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="parallel patterns">
  <data key="d0">parallel patterns</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Abstractions that encapsulate parallelism, eliminating boilerplate code, and improving programming productivity and code maintainability.&lt;SEP&gt;Common structures or strategies used to implement parallelism, such as loops, task farms, and pipelines.&lt;SEP&gt;Parallel patterns are common structures or strategies used to implement parallelism in programs, such as loops and task farms.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="porting applications">
  <data key="d0">porting applications</data>
  <data key="d1">&lt;|Study Designs</data>
  <data key="d2">Adapting existing applications, often written in C/C++ or Fortran, to new architectures; a process that can be simplified by PPL with annotations.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="annotations">
  <data key="d0">annotations</data>
  <data key="d1">&lt;|Tools</data>
  <data key="d2">Annotations similar to OpenMP used to identify parallel patterns in source code, facilitating porting and reusability.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="code generator">
  <data key="d0">code generator</data>
  <data key="d1">Tools</data>
  <data key="d2">A code generator automates the creation of optimized code, enabling performance portability across architectures.&lt;SEP&gt;A software tool that automates the creation of optimized code, facilitating performance portability across hardware architectures.&lt;SEP&gt;Component that produces optimized code for CPU and GPU, balancing performance with overhead, supporting kernels like batch, jacobi, and monte.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="performance slowdown">
  <data key="d0">performance slowdown</data>
  <data key="d1">&lt;|Results</data>
  <data key="d2">A 17% slowdown observed for the batch kernel compared to hand-optimized code, indicating optimization challenges.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="kernel fusion">
  <data key="d0">kernel fusion</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">An optimization technique yet to be implemented for the jacobi kernel to improve performance.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="reduction implementation">
  <data key="d0">reduction implementation</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">Strategies for optimizing reduction operations, especially for the monte kernel, to improve runtime efficiency.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dynamic behavior">
  <data key="d0">dynamic behavior</data>
  <data key="d1">&lt;|Core Concepts</data>
  <data key="d2">Applications with workloads that change during runtime, such as b+tree and bfs, which are less suited for static optimization.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="data dependency analysis">
  <data key="d0">data dependency analysis</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">Analysis techniques to identify dynamic workloads at compile time, enabling more adaptive static optimization.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="aliasing elimination">
  <data key="d0">aliasing elimination</data>
  <data key="d1">&lt;|Theories/Models</data>
  <data key="d2">A process enabled by SDFGs to remove redundant memory aliasing during compile time, improving dependency analysis.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dependency chain">
  <data key="d0">dependency chain</data>
  <data key="d1">&lt;|Variables</data>
  <data key="d2">Sequences of variable dependencies that can be extracted to identify control flow and parallel patterns, aiding static analysis of dynamic workloads.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="compatibility layer">
  <data key="d0">compatibility layer</data>
  <data key="d1">&lt;|Tools</data>
  <data key="d2">A software layer that facilitates interaction between SDFGs and the APT, enabling enhanced dependency analysis for the PPL.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="runtime-dependent applications">
  <data key="d0">runtime-dependent applications</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">Applications whose behavior depends on runtime conditions, requiring dynamic code adaptation.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="tasklet scheduling">
  <data key="d0">tasklet scheduling</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">The process of assigning computational units to resources; scalability issues arise with exponential search spaces, as seen in some benchmarks.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="variable names">
  <data key="d0">variable names</data>
  <data key="d1">&lt;|Variables</data>
  <data key="d2">Names influenced by random seeds, which can significantly impact the duration and stability of scheduling and solving processes.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="beam search">
  <data key="d0">beam search</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">A search algorithm used to limit search space with pruning strategies like n-best, creating more predictable and stable solutions.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="pruning strategies">
  <data key="d0">pruning strategies</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">Techniques such as n-best that reduce the search space during beam search to control compile time and improve stability.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="parallelism in dynamic control flow">
  <data key="d0">parallelism in dynamic control flow</data>
  <data key="d1">&lt;|Core Concepts</data>
  <data key="d2">Executing parallel patterns within loops and branches, supported by approaches like beam search and advanced scheduling for dynamic workloads.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="memory model">
  <data key="d0">memory model</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">The architecture and management of memory during code generation, with an emphasis on reducing local copies to improve efficiency.&lt;SEP&gt;The memory model defines how data is stored, accessed, and managed in code generation, impacting performance and correctness.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="source">
  <data key="d0">source</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The source refers to the origin of data used during optimization, including its attributes like location, volume, and availability.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="destination">
  <data key="d0">destination</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The destination pertains to the target or endpoint in data transfer or processing within the optimization process.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dynamic control flow">
  <data key="d0">dynamic control flow</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dynamic control flow refers to program structures such as loops and branches that can change execution paths during runtime, influencing optimization strategies.&lt;SEP&gt;Program structures such as loops and branches that can change execution paths during runtime, influencing optimization strategies.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="loop unrolling">
  <data key="d0">loop unrolling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An optimization technique that expands loops to reduce overhead and enable better parallel execution.&lt;SEP&gt;Loop unrolling is an optimization technique that expands loops to reduce overhead and improve parallel execution.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="streamcluster">
  <data key="d0">streamcluster</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Streamcluster is a benchmark application used to evaluate parallel processing capabilities and optimization techniques.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="cfd">
  <data key="d0">cfd</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">cfd (Computational Fluid Dynamics) is a class of simulation applications modeling fluid flows, often used to test optimization approaches.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="local memory copies">
  <data key="d0">local memory copies</data>
  <data key="d1">Variables</data>
  <data key="d2">Duplicate data stored locally to reduce access latency, but potentially introduce overhead and complicate optimization.&lt;SEP&gt;Local memory copies are duplicate data stored locally to reduce access latency but can introduce overhead and complicate optimization.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="global optimization step">
  <data key="d0">global optimization step</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process aimed at eliminating unnecessary local copies by analyzing data access patterns to improve memory efficiency.&lt;SEP&gt;A process designed to eliminate redundant local copies by analyzing data access patterns to improve efficiency.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="data size">
  <data key="d0">data size</data>
  <data key="d1">Variables</data>
  <data key="d2">The size of data influences the choice between local copies and reference access, affecting performance and memory usage.&lt;SEP&gt;The size of data influences the choice between local copies and reference access, impacting performance and memory use.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="potential parallelism">
  <data key="d0">potential parallelism</data>
  <data key="d1">Variables</data>
  <data key="d2">Potential parallelism refers to the extent to which tasks or data can be processed simultaneously to improve performance.&lt;SEP&gt;The extent to which tasks or data can be processed simultaneously, affecting optimization strategies.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="LULESH">
  <data key="d0">LULESH</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A physical simulation proxy application modeling wave propagation, used to evaluate parallelization and optimization techniques.&lt;SEP&gt;LULESH is a mini-application simulating wave propagation for performance testing and analysis of parallelization techniques.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="physical simulation">
  <data key="d0">physical simulation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Physical simulation models real-world phenomena, such as wave propagation, using computational algorithms.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="weak scaling">
  <data key="d0">weak scaling</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An evaluation method to assess how effectively a parallel application handles increasing problem sizes proportionally with resources.&lt;SEP&gt;Weak scaling evaluates how efficiently a parallel application handles increasing problem sizes with proportional resource scaling.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="iterative solvers">
  <data key="d0">iterative solvers</data>
  <data key="d1">Tools</data>
  <data key="d2">Algorithms that approximate solutions to complex equations, fundamental in physics-based simulations like LULESH.&lt;SEP&gt;Iterative solvers are algorithms used to approximate solutions to complex equations, fundamental in physics-based simulations like LULESH.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="intermediate representation">
  <data key="d0">intermediate representation</data>
  <data key="d1">Tools</data>
  <data key="d2">An abstracted code form used in compilation and optimization to enable transformations and target multiple architectures.&lt;SEP&gt;An intermediate representation is an abstracted code form used by compilers and tools to optimize and translate programs.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="performance portability">
  <data key="d0">performance portability</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Performance portability ensures that code performs efficiently across different hardware architectures without modification.&lt;SEP&gt;The ability of code to achieve efficient performance across diverse hardware architectures without modification.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="concurrency">
  <data key="d0">concurrency</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Concurrency refers to the ability to execute multiple computations simultaneously, revealing additional parallelism.&lt;SEP&gt;The ability to execute multiple computations simultaneously, revealing additional parallelism in the code.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="speedup in kmeans and hotspot3D">
  <data key="d0">speedup in kmeans and hotspot3D</data>
  <data key="d1">Results</data>
  <data key="d2">Increased concurrency led to speedups of 1.20 and 2.72 respectively in specific benchmarks.&lt;SEP&gt;Optimizations revealed increased concurrency, leading to speedups of 1.20 and 2.72 respectively.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="future work">
  <data key="d0">future work</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Future directions involve refining code generation, optimizing memory use, developing advanced scheduling, supporting more languages, and extending to dynamic load balancing.&lt;SEP&gt;Planned improvements involve better MPI integration, memory management, scheduling strategies, language support, and dynamic load balancing.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="optimization">
  <data key="d0">optimization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of improving code performance and efficiency through various techniques such as parallelization, memory management, and global analysis.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="parallelization">
  <data key="d0">parallelization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Executing multiple computations simultaneously to enhance performance, especially within dynamic control flow structures like loops and branches.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance Portability on Heterogeneous Architectures">
  <data key="d0">Performance Portability on Heterogeneous Architectures</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This refers to the ability of software to run efficiently across diverse hardware architectures without modification, emphasizing portability and performance consistency.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Proceedings of the ACM Digital Library">
  <data key="d0">Proceedings of the ACM Digital Library</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A collection of scholarly articles and conference papers related to high-performance computing, serving as a source of research data and literature.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PMAM ’24">
  <data key="d0">PMAM ’24</data>
  <data key="d1">Event</data>
  <data key="d2">An international conference held in March 2024 in Edinburgh, focusing on high-performance computing, networking, storage, and analysis.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tal Ben-Nun et al.">
  <data key="d0">Tal Ben-Nun et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">A group of researchers who authored a technical report on Data Centric Parallel Programming, contributing to methodologies for parallel computing.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="DaCe-Data Centric Parallel Programming">
  <data key="d0">DaCe-Data Centric Parallel Programming</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A programming model and framework designed to facilitate data-centric parallelism, optimizing execution on heterogeneous architectures.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Ernesto G Birgin et al.">
  <data key="d0">Ernesto G Birgin et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers who developed a filtered beam search method to optimize permutation flowshop scheduling, minimizing penalties and waiting times.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Filtered Beam Search Method">
  <data key="d0">Filtered Beam Search Method</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An optimization algorithm that employs beam search with filtering to efficiently solve complex scheduling problems.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pradip Bose">
  <data key="d0">Pradip Bose</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of work discussing the Power Wall, a concept related to the limitations of power consumption in computing hardware.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Power Wall">
  <data key="d0">Power Wall</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A phenomenon describing the physical and economic limitations on increasing computing performance due to power consumption constraints.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Shuai Che et al.">
  <data key="d0">Shuai Che et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers who created Rodinia, a benchmark suite for evaluating heterogeneous computing systems.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Philipp Ciechanowicz et al.">
  <data key="d0">Philipp Ciechanowicz et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers who provided an overview of the Münster Skeleton Library Muesli, a software tool for parallel computation.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Münster Skeleton Library Muesli">
  <data key="d0">Münster Skeleton Library Muesli</data>
  <data key="d1">Tools</data>
  <data key="d2">A comprehensive library that supports structured management of parallel computations, facilitating development of high-performance applications.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Murray Cole">
  <data key="d0">Murray Cole</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of "Algorithmic Skeletons," a foundational work on structured parallel programming models.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Algorithmic Skeletons">
  <data key="d0">Algorithmic Skeletons</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A conceptual framework for structuring parallel programs using high-level patterns to manage complexity and improve portability.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Massimiliano Fatica">
  <data key="d0">Massimiliano Fatica</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author who discussed CUDA toolkit and libraries, essential for GPU programming.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="CUDA Toolkit and Libraries">
  <data key="d0">CUDA Toolkit and Libraries</data>
  <data key="d1">Tools</data>
  <data key="d2">A suite of software tools and libraries for developing high-performance GPU-accelerated applications.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Free Software Foundation">
  <data key="d0">Free Software Foundation</data>
  <data key="d1">Organization</data>
  <data key="d2">Maintains and provides access to GCC, a widely used compiler system supporting various programming languages.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="GCC 13.2 Manual">
  <data key="d0">GCC 13.2 Manual</data>
  <data key="d1">Tools</data>
  <data key="d2">Official documentation for the GNU Compiler Collection, detailing compiler features and usage.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Prometeus GmbH">
  <data key="d0">Prometeus GmbH</data>
  <data key="d1">Organization</data>
  <data key="d2">Provider of the Top500 List, which ranks supercomputers worldwide based on performance.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Top500 List">
  <data key="d0">Top500 List</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A ranking dataset of the world's most powerful supercomputers, updated semiannually.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Maxime Gonthier et al.">
  <data key="d0">Maxime Gonthier et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers who studied locality-aware scheduling for runtime systems to improve task execution efficiency.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Locality-Aware Scheduling">
  <data key="d0">Locality-Aware Scheduling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A scheduling approach that optimizes task placement based on data locality to enhance performance on modern architectures.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tobias Grosser et al.">
  <data key="d0">Tobias Grosser et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers who developed Polly, a tool for performing polyhedral optimizations on low-level intermediate representations.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Polly">
  <data key="d0">Polly</data>
  <data key="d1">Tools</data>
  <data key="d2">A polyhedral optimization framework integrated into compiler infrastructures to enable advanced loop transformations and optimizations.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Gurobi Optimization, LLC">
  <data key="d0">Gurobi Optimization, LLC</data>
  <data key="d1">Organization</data>
  <data key="d2">Provider of the Gurobi Optimizer, a high-performance mathematical programming solver.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Gurobi Optimizer Reference Manual">
  <data key="d0">Gurobi Optimizer Reference Manual</data>
  <data key="d1">Tools</data>
  <data key="d2">Official documentation detailing the features and usage of the Gurobi optimization software.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Jeff R. Hammond et al.">
  <data key="d0">Jeff R. Hammond et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers who implemented OpenSHMEM using MPI-3 one-sided communication for parallel programming.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenSHMEM Using MPI-3">
  <data key="d0">OpenSHMEM Using MPI-3</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to implement shared memory programming models on top of MPI-3's one-sided communication, enabling efficient parallel data exchange.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Mark Harris et al.">
  <data key="d0">Mark Harris et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers who optimized parallel reduction algorithms in CUDA for improved GPU performance.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Reduction in CUDA">
  <data key="d0">Parallel Reduction in CUDA</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">A method to efficiently compute reductions (like sums, maxima) on GPU architectures using CUDA programming.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Torsten Hoefler et al.">
  <data key="d0">Torsten Hoefler et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers who designed scalable communication protocols for dynamic sparse data exchange in distributed systems.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Scalable Communication Protocols">
  <data key="d0">Scalable Communication Protocols</data>
  <data key="d1">Tools</data>
  <data key="d2">Protocols that facilitate efficient data exchange in large-scale, dynamic sparse data scenarios across distributed architectures.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intel Corporation">
  <data key="d0">Intel Corporation</data>
  <data key="d1">Organization</data>
  <data key="d2">Developer of oneAPI Threading Building Blocks (TBB), a library for parallel programming.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="oneAPI Threading Building Blocks">
  <data key="d0">oneAPI Threading Building Blocks</data>
  <data key="d1">Tools</data>
  <data key="d2">A C++ library that simplifies parallel programming and task-based parallelism.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="I Karlin et al.">
  <data key="d0">I Karlin et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers who updated LULESH 2.0, a hydrodynamics simulation code for high-performance computing.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="LULESH 2.0">
  <data key="d0">LULESH 2.0</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A hydrodynamics simulation code used for testing and benchmarking supercomputers.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dominic Kempf et al.">
  <data key="d0">Dominic Kempf et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers who worked on automatic code generation for high-performance discontinuous Galerkin methods on modern architectures.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Automatic Code Generation">
  <data key="d0">Automatic Code Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques to automatically produce optimized code for complex numerical methods tailored to modern, many-core architectures.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Chris Lattner and Vikram Adve">
  <data key="d0">Chris Lattner and Vikram Adve</data>
  <data key="d1">Researcher</data>
  <data key="d2">Creators of LLVM, a compilation framework supporting program analysis and transformation.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="LLVM">
  <data key="d0">LLVM</data>
  <data key="d1">Tools</data>
  <data key="d2">A compiler infrastructure enabling advanced program analysis, optimization, and code generation.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Lawrence Livermore National Laboratory">
  <data key="d0">Lawrence Livermore National Laboratory</data>
  <data key="d1">Organization</data>
  <data key="d2">Research institution maintaining RAJA, a performance portability layer for high-performance computing.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="RAJA">
  <data key="d0">RAJA</data>
  <data key="d1">Tools</data>
  <data key="d2">A performance portability layer that abstracts hardware-specific details to enable portable code across architectures.&lt;SEP&gt;RAJA is a performance portability library designed to enable high-performance computations across different hardware architectures, facilitating code portability and optimization.&lt;SEP&gt;RAJA is a programming interface or library designed to facilitate portable performance and productivity in high-performance computing applications.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Mingzhen Li et al.">
  <data key="d0">Mingzhen Li et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers who developed automatic code generation and optimization techniques for large-scale stencil computations on many-core processors.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Automatic Code Generation and Optimization of Large-Scale Stencil Computation">
  <data key="d0">Automatic Code Generation and Optimization of Large-Scale Stencil Computation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for generating efficient code to perform stencil computations on modern many-core architectures, improving performance and portability.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="performance portability on heterogeneous architectures">
  <data key="d0">performance portability on heterogeneous architectures</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ability of software to run efficiently across diverse hardware architectures without modification, emphasizing portability and performance consistency.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="github.com/LLNL/">
  <data key="d0">github.com/LLNL/</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A platform or repository associated with LLNL, likely hosting code, projects, or research outputs.&lt;SEP&gt;A platform or repository associated with LLNL, likely hosting research code, projects, or publications.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Mingzhen Li, Yi Liu, Hailong Yang, Yongmin Hu, Qingxiao Sun, Bangduo Chen, Xin You, Xiaoyan Liu, Zhongzhi Luan, Depei Qian">
  <data key="d0">Mingzhen Li, Yi Liu, Hailong Yang, Yongmin Hu, Qingxiao Sun, Bangduo Chen, Xin You, Xiaoyan Liu, Zhongzhi Luan, Depei Qian</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a study on automatic code generation and optimization for large-scale stencil computations on many-core processors.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2021">
  <data key="d0">2021</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Development and application of OpenSBLI for computational fluid dynamics on structured grids.&lt;SEP&gt;Development and application of OpenSBLI for simulating compressible fluid flows on structured grids using automated code generation.&lt;SEP&gt;Development and evaluation of Polygeist as a compiler tool for transforming C code into Polyhedral MLIR for high-level optimization.&lt;SEP&gt;Development and publication of OpenMP 5.1 specification for shared-memory parallel programming.&lt;SEP&gt;Development of PPIR as an IR framework to represent and optimize hierarchical parallel patterns in exascale systems.&lt;SEP&gt;Development of PPIR for hierarchical parallelism in exascale computing.&lt;SEP&gt;Development of Polygeist as a compiler optimization tool for C code targeting polyhedral representations.&lt;SEP&gt;Research involving the development and evaluation of methods for automatic code generation and optimization tailored for large-scale stencil computations on many-core processors.&lt;SEP&gt;Specification and updates of OpenMP 5.1 for parallel programming.&lt;SEP&gt;The research involves developing methods for automatic code generation and optimization applied to large-scale stencil computations on many-core processors.&lt;SEP&gt;The year the research was published.&lt;SEP&gt;The year the study was published.&lt;SEP&gt;The year this research was published.&lt;SEP&gt;The year this study was published.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Large-scale stencil computation">
  <data key="d0">Large-scale stencil computation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A computational pattern used in scientific computing, optimized for performance on many-core processors.&lt;SEP&gt;A computational pattern used in scientific simulations, targeted for optimization on many-core processors.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Many-core processors">
  <data key="d0">Many-core processors</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Hardware architecture characterized by numerous cores designed for high parallelism in scientific and engineering computations.&lt;SEP&gt;Hardware architecture characterized by numerous processing cores designed for high parallelism.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Automatic code generation">
  <data key="d0">Automatic code generation</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique for automatically producing optimized code tailored to specific hardware architectures.&lt;SEP&gt;A technique that automatically produces optimized code for specific hardware architectures to improve performance.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="International Conference on Parallel Processing">
  <data key="d0">International Conference on Parallel Processing</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference where research related to parallel computing, including the study, was presented.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Andrea Lodi, Andrea Tramontani">
  <data key="d0">Andrea Lodi, Andrea Tramontani</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a study on performance variability in mixed-integer programming.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="202x">
  <data key="d0">202x</data>
  <data key="d1">Study Design</data>
  <data key="d2">Documentation and standardization effort for MPI: a message-passing interface standard, version 3.1.&lt;SEP&gt;Documentation and standardization of MPI: a message-passing interface standard, version 3.1.&lt;SEP&gt;Research analyzing performance variability in mixed-integer programming, possibly with experimental or theoretical components.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance Variability in Mixed-Integer Programming">
  <data key="d0">Performance Variability in Mixed-Integer Programming</data>
  <data key="d1">Results</data>
  <data key="d2">Findings related to the factors affecting performance variability in mixed-integer programming problems.&lt;SEP&gt;Findings related to the factors influencing performance fluctuations in solving mixed-integer programming problems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Mixed-Integer Programming">
  <data key="d0">Mixed-Integer Programming</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A class of optimization problems involving both integer and continuous variables, analyzed for performance issues.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance Variability">
  <data key="d0">Performance Variability</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The phenomenon where performance of algorithms or systems varies due to multiple factors, critically analyzed in the study.&lt;SEP&gt;The phenomenon where the performance of algorithms or solvers varies due to multiple factors, impacting solution times and reliability.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="David J Lusher, Satya P Jammy, Neil D Sandham">
  <data key="d0">David J Lusher, Satya P Jammy, Neil D Sandham</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a study on OpenSBLI, an automated code-generation framework for heterogeneous computing architectures applied to compressible fluid dynamics.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenSBLI">
  <data key="d0">OpenSBLI</data>
  <data key="d1">Tools</data>
  <data key="d2">An automated code-generation framework designed for heterogeneous computing architectures, applied to fluid dynamics simulations.&lt;SEP&gt;An automated code-generation framework designed to facilitate high-performance simulations of compressible fluid dynamics on heterogeneous computing architectures.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Compressible Fluid Dynamics">
  <data key="d0">Compressible Fluid Dynamics</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A field of fluid mechanics dealing with flows where density changes are significant, simulated using OpenSBLI.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Heterogeneous Computing Architectures">
  <data key="d0">Heterogeneous Computing Architectures</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Computing systems composed of different types of processors or accelerators used in fluid dynamics simulations.&lt;SEP&gt;Computing systems composed of different types of processors or accelerators used in high-performance fluid dynamics simulations.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sergio M Martin, Daniel Wälchli, Georgios Arampatzis, Petros Koumoutsakos">
  <data key="d0">Sergio M Martin, Daniel Wälchli, Georgios Arampatzis, Petros Koumoutsakos</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a study on Korali, a high-performance computing framework for stochastic optimization and Bayesian uncertainty quantification.&lt;SEP&gt;Authors of a study on Korali, a high-performance framework for stochastic optimization and Bayesian uncertainty quantification.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2020">
  <data key="d0">2020</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Development and evaluation of Korali for stochastic optimization and Bayesian uncertainty quantification in high-performance computing environments.&lt;SEP&gt;Development and evaluation of Korali for stochastic optimization and uncertainty quantification in high-performance computing.&lt;SEP&gt;The year CodeBERT was introduced.&lt;SEP&gt;The year Jukebox was published or released.&lt;SEP&gt;The year Jukebox was published.&lt;SEP&gt;The year The Pile was released or made available.&lt;SEP&gt;The year The Pile was released.&lt;SEP&gt;The year the book was published.&lt;SEP&gt;The year the discussion or publication on AI alignment was made available.&lt;SEP&gt;The year the research was published, indicating recent developments in NLP.&lt;SEP&gt;The year the research was published, indicating recent progress in NLP and code translation.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Korali">
  <data key="d0">Korali</data>
  <data key="d1">Tools</data>
  <data key="d2">A high-performance computing framework designed for stochastic optimization and Bayesian uncertainty quantification tasks.&lt;SEP&gt;A high-performance computing framework for stochastic optimization and Bayesian uncertainty quantification.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Stochastic Optimization">
  <data key="d0">Stochastic Optimization</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">The study explores how Korali can improve stochastic optimization processes in HPC environments.&lt;SEP&gt;The study investigates how Korali can improve stochastic optimization processes in HPC settings.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Bayesian Uncertainty Quantification">
  <data key="d0">Bayesian Uncertainty Quantification</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">The framework aims to efficiently perform Bayesian uncertainty quantification in computational modeling.&lt;SEP&gt;The framework aims to efficiently perform Bayesian uncertainty quantification in computational models.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sally A. McKee, Robert W. Wisniewski">
  <data key="d0">Sally A. McKee, Robert W. Wisniewski</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a book chapter discussing the Memory Wall, a concept describing the bottleneck caused by memory access latency in high-performance computing.&lt;SEP&gt;Authors of a book chapter on Memory Wall, discussing memory bottlenecks in computing.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2011">
  <data key="d0">2011</data>
  <data key="d1">Study Design</data>
  <data key="d2">Analysis of memory bottlenecks and their impact on high-performance computing.&lt;SEP&gt;Analysis of the Memory Wall phenomenon and its impact on high-performance computing systems.&lt;SEP&gt;Research on the OpenSHMEM communication model and its implementation.&lt;SEP&gt;Research on the OpenSHMEM library and its role in parallel communication and RMA models.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory Wall">
  <data key="d0">Memory Wall</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A phenomenon where the disparity between CPU processing speed and memory access latency causes performance bottlenecks in computing systems.&lt;SEP&gt;A phenomenon where the speed gap between CPU processing and memory access causes performance bottlenecks in computing systems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sanyam Mehta, Pen-Chung Yew">
  <data key="d0">Sanyam Mehta, Pen-Chung Yew</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a study on compiler scalability and optimization of large programs.&lt;SEP&gt;Authors of a study on improving compiler scalability for large programs by optimizing compilation techniques at small cost.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2015">
  <data key="d0">2015</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research on methods to improve compiler scalability for large-scale software systems.&lt;SEP&gt;Research on methods to improve compiler scalability for large-scale software.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Improving Compiler Scalability">
  <data key="d0">Improving Compiler Scalability</data>
  <data key="d1">Methodology</data>
  <data key="d2">Techniques and strategies for optimizing compiler performance when handling large programs at minimal resource cost.&lt;SEP&gt;Techniques for optimizing large programs at minimal cost to enhance compiler performance.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Large Programs">
  <data key="d0">Large Programs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Complex software systems that require scalable and efficient compilation techniques.&lt;SEP&gt;Complex software systems that require scalable compilation techniques.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Julian Miller, Lukas Trümper, Christian Terboven, Matthias S. Müller">
  <data key="d0">Julian Miller, Lukas Trümper, Christian Terboven, Matthias S. Müller</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a poster on efficiency of algorithmic structures and a theoretical model for global optimization of parallel algorithms.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2019-2021">
  <data key="d0">2019-2021</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research on algorithmic efficiency and optimization models for parallel algorithms.&lt;SEP&gt;Research on the analysis of algorithmic efficiency and development of a theoretical model for optimizing parallel algorithms.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Efficiency of Algorithmic Structures">
  <data key="d0">Efficiency of Algorithmic Structures</data>
  <data key="d1">Results</data>
  <data key="d2">Insights into the performance characteristics and efficiencies of various algorithmic structures used in high-performance computing.&lt;SEP&gt;Insights into the performance characteristics of various algorithmic structures for high-performance computing.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Theoretical Model for Global Optimization of Parallel Algorithms">
  <data key="d0">Theoretical Model for Global Optimization of Parallel Algorithms</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A formal model designed to optimize parallel algorithms on a global scale for better efficiency.&lt;SEP&gt;A formal model designed to optimize the performance of parallel algorithms on a global scale, enabling better resource utilization and efficiency.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="William S. Moses, Lorenzo Chelini, Ruizhe Zhao, Oleksandr Zinenko">
  <data key="d0">William S. Moses, Lorenzo Chelini, Ruizhe Zhao, Oleksandr Zinenko</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a study on Polygeist, a compiler transformation tool that raises C code to Polyhedral MLIR for advanced optimization.&lt;SEP&gt;Authors of a study on Polygeist, a tool for raising C code to Polyhedral MLIR for compiler optimization.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Polygeist">
  <data key="d0">Polygeist</data>
  <data key="d1">Tools</data>
  <data key="d2">A compiler tool that transforms C code into Polyhedral MLIR to enable advanced optimization techniques.&lt;SEP&gt;A compiler transformation tool that converts C code into Polyhedral MLIR to enable advanced polyhedral optimizations.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="C to Polyhedral MLIR">
  <data key="d0">C to Polyhedral MLIR</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A compilation framework that facilitates high-level optimization of C code using polyhedral techniques.&lt;SEP&gt;A compilation framework that facilitates high-level optimization of C code via polyhedral techniques.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MPI Forum">
  <data key="d0">MPI Forum</data>
  <data key="d1">Organization</data>
  <data key="d2">The MPI Forum is responsible for developing and maintaining the MPI standard, including the MPI 3.1 version.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MPI: A Message-Passing Interface Standard, Version 3.1">
  <data key="d0">MPI: A Message-Passing Interface Standard, Version 3.1</data>
  <data key="d1">Tools</data>
  <data key="d2">The MPI standard provides a set of library routines and protocols for message passing in parallel distributed systems.&lt;SEP&gt;The MPI standard provides a set of library routines for parallel programming in distributed systems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Ravi Teja Mullapudi, Andrew Adams, Dillon Sharlet, Jonathan Ragan-Kelley, Kayvon Fatahalian">
  <data key="d0">Ravi Teja Mullapudi, Andrew Adams, Dillon Sharlet, Jonathan Ragan-Kelley, Kayvon Fatahalian</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a study on automatic scheduling of Halide image processing pipelines.&lt;SEP&gt;Authors of a study on automatic scheduling techniques for Halide image processing pipelines.&lt;SEP&gt;Authors of a study on automatically scheduling Halide image processing pipelines.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2016">
  <data key="d0">2016</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research on automatic scheduling techniques for image processing pipelines using Halide.&lt;SEP&gt;Research on compiler techniques for optimizing graph algorithms for GPU execution.&lt;SEP&gt;Research on compiler techniques to improve throughput of graph algorithms on GPU hardware.&lt;SEP&gt;Research on methods to automatically schedule and optimize Halide pipelines for performance.&lt;SEP&gt;Research on techniques for automatic scheduling of image processing pipelines in Halide.&lt;SEP&gt;Research on techniques for automatically scheduling Halide pipelines for performance and resource efficiency.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Automatically scheduling Halide pipelines">
  <data key="d0">Automatically scheduling Halide pipelines</data>
  <data key="d1">Methodology</data>
  <data key="d2">Techniques for optimizing the execution order and resources for image processing pipelines in Halide.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Halide">
  <data key="d0">Halide</data>
  <data key="d1">Tools</data>
  <data key="d2">A domain-specific language and compiler framework for image processing pipelines, supporting automatic scheduling and optimization.&lt;SEP&gt;A domain-specific language and compiler framework for image processing pipelines, supporting automatic scheduling.&lt;SEP&gt;A domain-specific language and compiler framework for image processing, supporting automatic scheduling and performance optimization.&lt;SEP&gt;A programming language and compiler framework for image processing pipelines, supporting automatic scheduling.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Bradford Nichols, Dick Buttlar, Jacqueline Proulx Farrell">
  <data key="d0">Bradford Nichols, Dick Buttlar, Jacqueline Proulx Farrell</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a book on Pthreads programming, a POSIX standard for multiprocessing.&lt;SEP&gt;Authors of a book on Pthreads, a POSIX standard library for multi-threaded programming.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="1996">
  <data key="d0">1996</data>
  <data key="d1">Study Design</data>
  <data key="d2">Documentation of Pthreads as a standard for portable multi-threaded programming in C/C++.&lt;SEP&gt;Documentation of Pthreads programming as a standard for multiprocessing in software development.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pthreads">
  <data key="d0">Pthreads</data>
  <data key="d1">Tools</data>
  <data key="d2">A POSIX-compliant threading library enabling multi-threaded programming in C and C++ for parallel execution.&lt;SEP&gt;A POSIX-compliant threading library for parallel programming in C and C++.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="NVIDIA Corporation">
  <data key="d0">NVIDIA Corporation</data>
  <data key="d1">Organization</data>
  <data key="d2">Developer of Thrust, a C++ parallel algorithms library for GPU programming.&lt;SEP&gt;Developer of Thrust, a C++ template library for parallel algorithms optimized for NVIDIA GPUs.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="n. d.">
  <data key="d0">n. d.</data>
  <data key="d1">Study Design</data>
  <data key="d2">Development and documentation of Thrust library for GPU acceleration.&lt;SEP&gt;Development and documentation of Thrust library for GPU-based parallel algorithms.&lt;SEP&gt;Research analyzing performance variability in mixed-integer programming, possibly involving empirical or theoretical approaches.&lt;SEP&gt;Standardization and adoption of OpenCL for heterogeneous computing environments.&lt;SEP&gt;Standardization and adoption of OpenCL for heterogeneous computing.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenCL">
  <data key="d0">OpenCL</data>
  <data key="d1">Tools</data>
  <data key="d2">A cross-platform API for parallel programming of heterogeneous systems.&lt;SEP&gt;A cross-platform framework and API for writing parallel code that runs efficiently on various hardware architectures.&lt;SEP&gt;An open standard API for parallel programming of heterogeneous systems, enabling portability and performance across diverse hardware.&lt;SEP&gt;An open standard for parallel programming across heterogeneous systems, enabling code portability and performance.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenMP Architecture Review Board">
  <data key="d0">OpenMP Architecture Review Board</data>
  <data key="d1">Organization</data>
  <data key="d2">Maintains and updates the OpenMP standard for shared-memory parallel programming in C, C++, and Fortran.&lt;SEP&gt;Maintains the OpenMP standard for shared-memory parallel programming.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenMP 5.1">
  <data key="d0">OpenMP 5.1</data>
  <data key="d1">Tools</data>
  <data key="d2">A version of the OpenMP standard supporting directives and APIs for parallel programming in C, C++, and Fortran.&lt;SEP&gt;A version of the OpenMP standard supporting directives and APIs for parallel programming in shared-memory systems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Peng Si Ow, Thomas E Morton">
  <data key="d0">Peng Si Ow, Thomas E Morton</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a study on filtered beam search scheduling algorithms in production systems.&lt;SEP&gt;Authors of a study on filtered beam search scheduling in production systems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="1988">
  <data key="d0">1988</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research on scheduling algorithms, specifically filtered beam search, for optimizing production schedules.&lt;SEP&gt;Research on scheduling algorithms, specifically filtered beam search, in production environments.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Filtered Beam Search in Scheduling">
  <data key="d0">Filtered Beam Search in Scheduling</data>
  <data key="d1">Methodology</data>
  <data key="d2">A scheduling algorithm that uses beam search with filtering criteria to improve scheduling efficiency.&lt;SEP&gt;A scheduling method that uses beam search with filtering to optimize production schedules.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sreepathi Pai, Keshav Pingali">
  <data key="d0">Sreepathi Pai, Keshav Pingali</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a study on a compiler for throughput optimization of graph algorithms on GPUs.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="A Compiler for Throughput Optimization of Graph Algorithms">
  <data key="d0">A Compiler for Throughput Optimization of Graph Algorithms</data>
  <data key="d1">Methodology</data>
  <data key="d2">A compiler framework designed to optimize the throughput of graph algorithms executing on GPUs.&lt;SEP&gt;A compiler framework designed to optimize throughput for graph algorithms running on GPUs.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Graph Algorithms">
  <data key="d0">Graph Algorithms</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Algorithms that operate on graph data structures, targeted for high-performance execution on GPUs.&lt;SEP&gt;Algorithms that operate on graph data structures, targeted for optimization on GPUs.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="GPUs">
  <data key="d0">GPUs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Graphics Processing Units used as hardware targets for optimized graph algorithm execution.&lt;SEP&gt;Graphics Processing Units used as hardware targets for optimized graph algorithms.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Stephen W. Poole, Oscar Hernandez, Jeffery A. Kuehn, Galen M. Shipman, Anthony Curtis, Karl Feind">
  <data key="d0">Stephen W. Poole, Oscar Hernandez, Jeffery A. Kuehn, Galen M. Shipman, Anthony Curtis, Karl Feind</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a work on OpenSHMEM, a communication library for parallel systems.&lt;SEP&gt;Authors of a work on OpenSHMEM, a communication library supporting remote memory access and one-sided communication in parallel systems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenSHMEM">
  <data key="d0">OpenSHMEM</data>
  <data key="d1">Tools</data>
  <data key="d2">A library for parallel programming providing a Partitioned Global Address Space (PGAS) model and support for one-sided communication.&lt;SEP&gt;A library providing a Partitioned Global Address Space (PGAS) programming model for parallel systems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Adrian Schmitz, Julian Miller, Lukas Trümper, Matthias S Müller">
  <data key="d0">Adrian Schmitz, Julian Miller, Lukas Trümper, Matthias S Müller</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a study presenting PPIR, a Parallel Pattern Intermediate Representation for hierarchical parallelism in exascale computing.&lt;SEP&gt;Authors of a study presenting PPIR, a Parallel Pattern Intermediate Representation for hierarchical parallelism.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPIR">
  <data key="d0">PPIR</data>
  <data key="d1">Tools</data>
  <data key="d2">Parallel Pattern Intermediate Representation, a compiler IR designed for hierarchical parallelism in exascale high-performance computing.&lt;SEP&gt;Parallel Pattern Intermediate Representation, a framework for representing and optimizing parallel patterns.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Michel Steuwer, Toomas Remmelg, Christophe Dubach">
  <data key="d0">Michel Steuwer, Toomas Remmelg, Christophe Dubach</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of a paper on Lift, a functional data-parallel IR for GPU code generation.&lt;SEP&gt;Authors of a paper on Lift, a functional data-parallel IR for high-performance GPU code generation.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Lift">
  <data key="d0">Lift</data>
  <data key="d1">Tools</data>
  <data key="d2">A functional data-parallel intermediate representation designed to facilitate high-performance GPU code generation.&lt;SEP&gt;A functional, data-parallel intermediate representation aimed at enabling high-performance GPU code generation from high-level functional descriptions.&lt;SEP&gt;Lift is a functional data-parallel intermediate representation (IR) designed for high-performance GPU code generation, facilitating efficient parallel computation.&lt;SEP&gt;Lift is a functional data-parallel intermediate representation (IR) designed to facilitate high-performance GPU code generation, enabling efficient parallel execution.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="C2Rust Development Team">
  <data key="d0">C2Rust Development Team</data>
  <data key="d1">Organization</data>
  <data key="d2">A team responsible for developing C2Rust, a tool for translating C code to Rust, and providing related documentation.&lt;SEP&gt;A team responsible for developing C2Rust, a tool for translating C code to Rust, with a manual documenting its usage.&lt;SEP&gt;Developers of C2Rust, a tool for translating C code into Rust for safety, modernization, and analysis.&lt;SEP&gt;Developers of C2Rust, a tool for translating C code to Rust for safety and modernization.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2023">
  <data key="d0">2023</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Development and documentation of C2Rust manual for C to Rust translation.&lt;SEP&gt;The publication year of the article discussing ChatGPT's role in environmental research, indicating the temporal context of the research.&lt;SEP&gt;The year indicating the publication date of the ChatGPT environmental research article.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="C2Rust">
  <data key="d0">C2Rust</data>
  <data key="d1">Tools</data>
  <data key="d2">A compiler and toolchain for automatically translating C code into Rust, improving safety and code quality.&lt;SEP&gt;A toolchain for automatically translating C code into Rust, enhancing safety and modernization.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Automatically Scheduling Halide Pipelines">
  <data key="d0">Automatically Scheduling Halide Pipelines</data>
  <data key="d1">Methodology</data>
  <data key="d2">Techniques for automatically determining efficient execution schedules for image processing pipelines written in Halide.&lt;SEP&gt;Techniques for automatically determining optimal execution schedules for image processing pipelines in Halide.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Proceedings of the 50th International Conference on Parallel Processing">
  <data key="d0">Proceedings of the 50th International Conference on Parallel Processing</data>
  <data key="d1">Study Venue</data>
  <data key="d2">Conference where the research was presented, focusing on parallel processing and high-performance computing.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Julian Miller, Lukas Trümper, Christian Terboven, Matthias S Müller">
  <data key="d0">Julian Miller, Lukas Trümper, Christian Terboven, Matthias S Müller</data>
  <data key="d1">Research Team</data>
  <data key="d2">Authors of research on the efficiency of algorithmic structures and a theoretical model for global optimization of parallel algorithms.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="IEEE">
  <data key="d0">IEEE</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">IEEE is a professional organization that publishes standards, research papers, and proceedings related to electrical, electronic, and computer engineering.&lt;SEP&gt;IEEE is a professional organization that publishes standards, research, and proceedings related to electrical and electronic engineering and computer science.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="30–40">
  <data key="d0">30–40</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The range 30–40 likely refers to a numerical or temporal measurement relevant to the context, possibly data size, time span, or parameter range.&lt;SEP&gt;The range 30–40 likely refers to a numerical or temporal parameter relevant to the context, possibly related to data size, time span, or measurement units.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Michel Steuwer">
  <data key="d0">Michel Steuwer</data>
  <data key="d1">Researcher</data>
  <data key="d2">Michel Steuwer is an author who contributed to research on GPU code generation and data-parallel IR.&lt;SEP&gt;Michel Steuwer is an author who contributed to research on GPU code generation and data-parallel intermediate representations (IR) for high-performance computing.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Toomas Remmelg">
  <data key="d0">Toomas Remmelg</data>
  <data key="d1">Researcher</data>
  <data key="d2">Toomas Remmelg is an author involved in research on high-performance GPU code generation and IR design.&lt;SEP&gt;Toomas Remmelg is an author involved in research on high-performance GPU code generation.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Christophe Dubach">
  <data key="d0">Christophe Dubach</data>
  <data key="d1">Researcher</data>
  <data key="d2">Christophe Dubach is an author associated with research on data-parallel IR for GPU code generation.&lt;SEP&gt;Christophe Dubach is an author associated with research on data-parallel IR for GPUs.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)">
  <data key="d0">2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference where research on code generation and optimization was presented, including the Lift IR.&lt;SEP&gt;A conference where research on code generation, optimization, and IR design such as Lift was presented.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="C2Rust Manual">
  <data key="d0">C2Rust Manual</data>
  <data key="d1">Tools</data>
  <data key="d2">A comprehensive manual providing instructions and guidelines for using the C2Rust tool for code translation.&lt;SEP&gt;A manual that provides instructions and guidelines for using the C2Rust tool to translate C code into Rust, supporting software development and code migration.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Damien Lebrun-Grandié">
  <data key="d0">Damien Lebrun-Grandié</data>
  <data key="d1">Researcher</data>
  <data key="d2">Damien Lebrun-Grandié is involved in research on programming model extensions, focusing on exascale era support, such as Kokkos 3.&lt;SEP&gt;Damien Lebrun-Grandié is involved in research on programming models for high-performance computing.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Daniel Arndt">
  <data key="d0">Daniel Arndt</data>
  <data key="d1">Researcher</data>
  <data key="d2">Daniel Arndt is a researcher contributing to exascale programming models.&lt;SEP&gt;Daniel Arndt is an author contributing to research on programming models and their extensions for high-performance and exascale computing.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kokkos 3">
  <data key="d0">Kokkos 3</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Kokkos 3 extends programming models for exascale computing, facilitating performance portability and scalability in parallel applications.&lt;SEP&gt;Kokkos 3 is a programming model extension designed for the exascale era, enabling scalable performance portability across architectures.&lt;SEP&gt;Kokkos 3 is a programming model extension designed to support exascale computing, enabling performance portability across diverse architectures.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="IEEE Transactions on Parallel and Distributed Systems">
  <data key="d0">IEEE Transactions on Parallel and Distributed Systems</data>
  <data key="d1">Discipline</data>
  <data key="d2">A peer-reviewed journal publishing research on parallel and distributed systems, including programming models and HPC techniques.&lt;SEP&gt;An academic journal publishing peer-reviewed research on parallel, distributed, and high-performance computing systems.&lt;SEP&gt;An academic journal publishing research on parallel and distributed computing systems.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Vinh Dang">
  <data key="d0">Vinh Dang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Vinh Dang is an author involved in research on programming models and high-performance computing architectures.&lt;SEP&gt;Vinh Dang is an author involved in research on programming models and high-performance computing.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Nathan Ellingwood">
  <data key="d0">Nathan Ellingwood</data>
  <data key="d1">Researcher</data>
  <data key="d2">Nathan Ellingwood is a contributor to research on programming models and exascale computing.&lt;SEP&gt;Nathan Ellingwood is a researcher contributing to studies on programming models and exascale computing.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rahulkumar Gayatri">
  <data key="d0">Rahulkumar Gayatri</data>
  <data key="d1">Researcher</data>
  <data key="d2">Rahulkumar Gayatri is involved in research on programming models, performance portability, and exascale systems.&lt;SEP&gt;Rahulkumar Gayatri is involved in research related to high-performance computing and programming models.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Evan Harvey">
  <data key="d0">Evan Harvey</data>
  <data key="d1">Researcher</data>
  <data key="d2">Evan Harvey is an author contributing to research on programming models for exascale systems.&lt;SEP&gt;Evan Harvey is an author working on programming model extensions and their applications in exascale computing.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Daisy S. Hollman">
  <data key="d0">Daisy S. Hollman</data>
  <data key="d1">Researcher</data>
  <data key="d2">Daisy S. Hollman contributes to research on programming models and high-performance computing frameworks.&lt;SEP&gt;Daisy S. Hollman is involved in research on exascale programming models.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dan Ibanez">
  <data key="d0">Dan Ibanez</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dan Ibanez is a researcher contributing to high-performance computing research.&lt;SEP&gt;Dan Ibanez is involved in research on programming models, code optimization, and exascale system support.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Nevin Liber">
  <data key="d0">Nevin Liber</data>
  <data key="d1">Researcher</data>
  <data key="d2">Nevin Liber is an author contributing to research on programming models and scalable HPC architectures.&lt;SEP&gt;Nevin Liber is an author involved in research on programming models and HPC.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Jonathan Madsen">
  <data key="d0">Jonathan Madsen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jonathan Madsen is a researcher contributing to parallel computing models.&lt;SEP&gt;Jonathan Madsen works on parallel algorithms and programming models for high-performance systems.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Jeff Miles">
  <data key="d0">Jeff Miles</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jeff Miles is involved in research on programming models for high-performance systems.&lt;SEP&gt;Jeff Miles is involved in research on programming models, performance tuning, and exascale HPC.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="David Poliakoff">
  <data key="d0">David Poliakoff</data>
  <data key="d1">Researcher</data>
  <data key="d2">David Poliakoff contributes to research on programming models, software frameworks, and performance portability.&lt;SEP&gt;David Poliakoff is an author contributing to research on HPC programming models.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Amy Powell">
  <data key="d0">Amy Powell</data>
  <data key="d1">Researcher</data>
  <data key="d2">Amy Powell is an author involved in research on parallel programming frameworks and high-performance computing.&lt;SEP&gt;Amy Powell is involved in research on parallel and distributed systems.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sivasankaran Rajamanickam">
  <data key="d0">Sivasankaran Rajamanickam</data>
  <data key="d1">Researcher</data>
  <data key="d2">Sivasankaran Rajamanickam is a researcher working on high-performance computing.&lt;SEP&gt;Sivasankaran Rajamanickam works on scalable HPC architectures and programming models.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Mikael Simberg">
  <data key="d0">Mikael Simberg</data>
  <data key="d1">Researcher</data>
  <data key="d2">Mikael Simberg contributes to research on programming models and performance portability for exascale systems.&lt;SEP&gt;Mikael Simberg is an author contributing to research on programming models for exascale systems.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dan Sunderland">
  <data key="d0">Dan Sunderland</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dan Sunderland is involved in research on exascale computing and programming models.&lt;SEP&gt;Dan Sunderland is involved in research on high-performance computing, programming models, and exascale architectures.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Bruno Turcksin">
  <data key="d0">Bruno Turcksin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bruno Turcksin is a researcher working on HPC and exascale systems.&lt;SEP&gt;Bruno Turcksin works on HPC simulation, programming models, and exascale computing support.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Jeremiah Wilke">
  <data key="d0">Jeremiah Wilke</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jeremiah Wilke contributes to research on high-performance computing and scalable programming models.&lt;SEP&gt;Jeremiah Wilke is an author contributing to research on high-performance computing.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Programming Model Extensions">
  <data key="d0">Programming Model Extensions</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Extensions to existing programming models designed to support exascale architectures, enabling performance portability and scalability.&lt;SEP&gt;Extensions to existing programming models designed to support exascale computing architectures.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Samuel Williams">
  <data key="d0">Samuel Williams</data>
  <data key="d1">Researcher</data>
  <data key="d2">Samuel Williams is an author who contributed to the development of the Roofline performance model for multicore architectures.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Andrew Waterman">
  <data key="d0">Andrew Waterman</data>
  <data key="d1">Researcher</data>
  <data key="d2">Andrew Waterman is a researcher involved in performance modeling and high-performance computing.&lt;SEP&gt;Andrew Waterman is an author involved in research on performance modeling and the development of the Roofline model.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="David Patterson">
  <data key="d0">David Patterson</data>
  <data key="d1">Researcher</data>
  <data key="d2">David Patterson contributed to the conceptualization and development of the Roofline performance model.&lt;SEP&gt;David Patterson is an author known for contributions to computer architecture and performance modeling.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Roofline">
  <data key="d0">Roofline</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Roofline is a visual performance model that provides insights into the computational throughput and memory bandwidth of multicore architectures.&lt;SEP&gt;The Roofline model is a visual performance analysis tool that illustrates the relationship between computational throughput and memory bandwidth in multicore architectures.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Charles Yount">
  <data key="d0">Charles Yount</data>
  <data key="d1">Researcher</data>
  <data key="d2">Charles Yount is an author involved in research on HPC stencil code-generation frameworks.&lt;SEP&gt;Charles Yount is an author involved in research on stencil code frameworks like YASK for HPC.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Josh Tobin">
  <data key="d0">Josh Tobin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Josh Tobin contributed to the development, tuning, and application of the YASK stencil code framework.&lt;SEP&gt;Josh Tobin is a researcher working on stencil kernels and high-performance code generation.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Alexander Breuer">
  <data key="d0">Alexander Breuer</data>
  <data key="d1">Researcher</data>
  <data key="d2">Alexander Breuer is involved in research on stencil code optimization and HPC frameworks.&lt;SEP&gt;Alexander Breuer is involved in research on stencil kernel optimization and high-performance code generation frameworks like YASK.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Alejandro Duran">
  <data key="d0">Alejandro Duran</data>
  <data key="d1">Researcher</data>
  <data key="d2">Alejandro Duran is a researcher working on HPC stencil code generation and performance tuning.&lt;SEP&gt;Alejandro Duran works on performance tuning and code generation for stencil kernels within frameworks like YASK.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="WOLFHPC">
  <data key="d0">WOLFHPC</data>
  <data key="d1">Study Design</data>
  <data key="d2">The Sixth International Workshop on Domain-Specific Languages and High-Level Frameworks for High Performance Computing, where research on stencil frameworks like YASK was presented.&lt;SEP&gt;The Sixth International Workshop on Domain-Specific Languages and High-Level Frameworks for High Performance Computing, where research on stencil frameworks such as YASK was presented.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPL">
  <data key="d0">PPL</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">The PPL is evaluated against the kernels in the Rodinia suite to demonstrate its applicability and performance."|&gt;"performance evaluation&lt;SEP&gt;The PPL's evaluation against the Rodinia suite demonstrates its applicability across various kernels."|&gt;"performance evaluation</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="DSL">
  <data key="d0">DSL</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">The custom DSL in PPL enables specific optimization strategies, differentiating it from general-purpose code generators."|&gt;"programming language</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global Optimizations">
  <data key="d0">Global Optimizations</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d2">Application wide optimizations aim to improve overall application performance, as contrasted with local optimization approaches.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="APT Generation">
  <data key="d0">APT Generation</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d2">APT is generated from the hierarchical representation of the algorithm, reflecting optimization results.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Operations">
  <data key="d0">Operations</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d2">Parallel patterns define element-wise operations like multiply and subtract, which are fundamental to the pattern-based approach.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global View">
  <data key="d0">Global View</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d2">A global view on applications enables comprehensive optimization strategies, central to the pattern-based methodology.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="The APT is created by analyzing the hierarchical structure of parallel code, including expressions and statements, to facilitate dependency analysis and optimization.">
  <data key="d0">The APT is created by analyzing the hierarchical structure of parallel code, including expressions and statements, to facilitate dependency analysis and optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d2">code analysis, hierarchical representation</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="APTT">
  <data key="d0">APTT</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d2">Data dependencies link expressions within the APT, ensuring correct execution order and enabling static analysis for optimization.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="AMT">
  <data key="d0">AMT</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d2">The AMT extends the APT by including optimization and mapping data, representing a distributed and concurrent execution model.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Disregarded">
  <data key="d0">Disregarded</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d2">Hyper-threading is currently disregarded in the model, meaning it does not influence thread management or performance optimization here.&lt;SEP&gt;Hyper-threading technology is currently disregarded in the execution model, meaning it does not influence thread management or performance in this context.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Techniques">
  <data key="d0">Parallel Techniques</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d2">Decomposition into map, stencil, and reduction patterns allows structured parallel execution with proper synchronization and atomic operations in reduction.&lt;SEP&gt;Decomposition of patterns into map, stencil, and reduction enables structured parallel execution with synchronization mechanisms.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pattern Decomposition">
  <data key="d0">Pattern Decomposition</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d2">Decomposition into map, stencil, and reduction enables structured parallel execution, with reduction involving synchronization and atomic operations.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pattern implementation and data movement strategies aim to optimize memory locality to enhance performance.">
  <data key="d0">Pattern implementation and data movement strategies aim to optimize memory locality to enhance performance.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d2">memory optimization, performance</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hardware and software components">
  <data key="d0">Hardware and software components</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d2">The CLAIX18 systems include CPUs, GPUs, network fabric, and operating systems used for high-performance computing.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Systems">
  <data key="d0">Systems</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d2">The CLAIX18 systems include CPUs, GPUs, network fabric, and operating systems used for high-performance computing.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Measurement accuracy">
  <data key="d0">Measurement accuracy</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d2">Global optimizations are performed to avoid synchronization points that could influence measurement results, ensuring accuracy.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Coverage">
  <data key="d0">Coverage</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d2">The benchmarks are used to assess the applicability and coverage of the generated and optimized code in HPC scenarios.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rodinia benchmarks">
  <data key="d0">Rodinia benchmarks</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d2">The benchmarks are used to assess the applicability and coverage of the generated and optimized code in HPC scenarios.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hotspot Benchmark">
  <data key="d0">Hotspot Benchmark</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d2">The hotspot benchmark's static code restructuring led to a speedup of 2.72 by enabling parallel execution of stencil borders and edge cases.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="optimized kernels">
  <data key="d0">optimized kernels</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d2">Kernels like kmeans and nnbenchmarks are optimized to better utilize parallel hardware, achieving significant speedups.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="unsupported codes">
  <data key="d0">unsupported codes</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d2">Certain benchmark codes are unsupported in PPL due to porting or kernel alteration issues.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="hotspot benchmark">
  <data key="d0">hotspot benchmark</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d2">The static reduction approach eliminated branches in hotspot, leading to a speedup of 2.72.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="overall performance">
  <data key="d0">overall performance</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d2">Performance improvements are most significant in small applications like backprop, nn, and srad due to reduced static overhead.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="small applications">
  <data key="d0">small applications</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d2">Performance improvements are most significant in small applications like backprop, nn, and srad due to reduced static overhead.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="benchmark suite">
  <data key="d0">benchmark suite</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d2">The benchmarks are part of the Rodinia suite, used to evaluate the effectiveness of PPL optimizations.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Static Codes">
  <data key="d0">Static Codes</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">The PPL approach enables automatic, global optimization for static codes, improving performance across architectures.&lt;SEP&gt;The PPL enables automatic, global optimization of static codes, improving performance across architectures."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Heterogeneous Architectures">
  <data key="d0">Heterogeneous Architectures</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">The PPL workflow supports optimization for heterogeneous hardware from a single source, simplifying deployment.&lt;SEP&gt;The PPL workflow supports optimization for heterogeneous hardware from a single source, simplifying deployment."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Code Reusability">
  <data key="d0">Code Reusability</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">Abstracting parallelism into patterns reduces boilerplate and enhances code reuse and maintainability."|&lt;SEP&gt;Abstracting parallelism into patterns removes boilerplate code, enhancing reusability and maintainability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Jacobi Kernel">
  <data key="d0">Jacobi Kernel</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">Implementing kernel fusion could improve the performance of the jacobi kernel.&lt;SEP&gt;Implementing kernel fusion could improve the performance of the jacobi kernel."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Monte Kernel">
  <data key="d0">Monte Kernel</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">Enhancing reduction strategies for the monte kernel can lead to better runtime performance."|&lt;SEP&gt;Improving reduction strategies for the monte kernel can enhance runtime efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Reduction">
  <data key="d0">Reduction</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">Enhancing reduction strategies for the monte kernel can lead to better runtime performance."|&lt;SEP&gt;Improving reduction strategies for the monte kernel can enhance runtime efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dynamic Workloads">
  <data key="d0">Dynamic Workloads</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">Advanced analysis like SDFGs can identify dynamic workloads at compile time to enable better static optimization.&lt;SEP&gt;Advanced dependency analysis like SDFGs can identify dynamic workloads at compile time to enable better static optimization."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Alias Elimination">
  <data key="d0">Alias Elimination</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">SDFGs enable aliasing elimination during compile time, improving dependency analysis and optimization.&lt;SEP&gt;SDFGs enable aliasing elimination during compile time, reducing dependency complexity."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="SDFGs">
  <data key="d0">SDFGs</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">SDFGs enable aliasing elimination during compile time, improving dependency analysis and optimization.&lt;SEP&gt;SDFGs enable aliasing elimination during compile time, reducing dependency complexity."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Runtime Arguments">
  <data key="d0">Runtime Arguments</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">Extracted dependency chains can identify variables influencing control flow and parallel patterns, aiding in static analysis of dynamic applications.&lt;SEP&gt;Extracted dependency chains can identify variables influencing control flow and parallel patterns, aiding static analysis of dynamic applications."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dynamic Load Balancing">
  <data key="d0">Dynamic Load Balancing</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">Legion enables execution of tasklets with unknown sizes and supports dynamic load balancing across resources, including GPUs.&lt;SEP&gt;Legion enables execution of tasklets with unknown sizes and supports dynamic load balancing across resources, including GPUs."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Distributed Memory Migration">
  <data key="d0">Distributed Memory Migration</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">StarPU allows migration of tasklets during runtime in distributed memory environments, supporting dynamic workloads.&lt;SEP&gt;StarPU allows migration of tasklets during runtime in distributed memory environments, supporting dynamic workloads."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Random Seed">
  <data key="d0">Random Seed</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">Changes in variable names influenced by random seeds can drastically affect the duration of solving processes, impacting scalability."|&lt;SEP&gt;Changes in variable names influenced by random seeds can drastically affect the duration of solving processes, impacting scalability."|&gt;"randomness, scalability&lt;SEP&gt;Random seed influences variable naming, which impacts the duration and stability of search processes in optimization."|&lt;SEP&gt;Random seed influences variable naming, which impacts the duration and stability of search processes in optimization."|&gt;"random seed, process duration</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Search Space Pruning">
  <data key="d0">Search Space Pruning</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">Applying beam search with pruning strategies like n-best can create more predictable, stable, and reproducible scheduling results.&lt;SEP&gt;Applying beam search with pruning strategies like n-best can create more predictable, stable, and reproducible scheduling results."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Scheduling Problems">
  <data key="d0">Scheduling Problems</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">Beam search is used as a more stable alternative to LP-solvers for complex scheduling problems, facilitating control over search space and solution stability."|&lt;SEP&gt;Beam search is used as a more stable alternative to LP-solvers for complex scheduling problems, facilitating control over search space and solution stability."|&gt;"optimization, stability</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="streamcluster and cfd">
  <data key="d0">streamcluster and cfd</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d2">Loop unrolling is used to optimize the execution of large loops in applications like streamcluster and cfd by reducing overhead."|&gt;"loop optimization, performance enhancement&lt;SEP&gt;Loop unrolling optimizes large loops in applications like streamcluster and cfd by reducing overhead and improving parallelism."|&gt;"loop optimization, performance improvement</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="local copies">
  <data key="d0">local copies</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d2">A global optimization step aims to eliminate redundant local memory copies, thereby enhancing performance."|&gt;"optimization, memory efficiency&lt;SEP&gt;A global optimization step aims to eliminate unnecessary local memory copies, improving performance."|&gt;"optimization technique, memory efficiency</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="parallel applications">
  <data key="d0">parallel applications</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d2">LULESH demonstrates how larger applications can benefit from the global optimization approach, despite limited detailed gains."|&gt;"application scalability, analysis&lt;SEP&gt;LULESH demonstrates the applicability of global optimization techniques to larger applications, despite limited detailed performance gains."|&gt;"application scalability, analysis</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rodinia and LULESH">
  <data key="d0">Rodinia and LULESH</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d2">Parallel patterns are used in applications like Rodinia and LULESH to reduce analysis complexity and enable larger application support."|&gt;"parallel programming, analysis&lt;SEP&gt;Parallel patterns are used to reduce analysis complexity and support larger applications in heterogeneous computing."|&gt;"parallel programming, analysis</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="performance improvements">
  <data key="d0">performance improvements</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d2">The code generator's implementation enables global optimizations, leading to significant speedups and better workload distribution."|&gt;"optimization, compiler technology&lt;SEP&gt;The implementation of the code generator enables global optimizations and better workload distribution, leading to significant speedups."|&gt;"optimization, compiler technology</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Andrea Lodi and Andrea Tramontani">
  <data key="d0">Andrea Lodi and Andrea Tramontani</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The authors investigate factors influencing performance variability in mixed-integer programming.&lt;SEP&gt;The authors investigate the causes and effects of performance variability in mixed-integer programming solvers.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="David J Lusher et al.">
  <data key="d0">David J Lusher et al.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The study presents OpenSBLI as a tool for automated code generation for fluid dynamics on heterogeneous architectures.&lt;SEP&gt;The study presents OpenSBLI as a tool for automated code generation targeting heterogeneous architectures for fluid dynamics simulations.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sergio M Martin et al.">
  <data key="d0">Sergio M Martin et al.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The study introduces Korali as a framework for stochastic optimization and Bayesian uncertainty quantification.&lt;SEP&gt;The study introduces Korali as a tool for stochastic optimization and Bayesian uncertainty quantification in HPC.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sally A. McKee and Robert W. Wisniewski">
  <data key="d0">Sally A. McKee and Robert W. Wisniewski</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The authors discuss the concept of Memory Wall and its implications for high-performance computing.&lt;SEP&gt;The authors explain the concept of Memory Wall and analyze its implications for system performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sanyam Mehta and Pen-Chung Yew">
  <data key="d0">Sanyam Mehta and Pen-Chung Yew</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The authors propose methods to enhance compiler scalability for large programs, focusing on efficiency and performance." ,&lt;SEP&gt;The study proposes methods to optimize large programs efficiently for better compiler scalability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Julian Miller et al.">
  <data key="d0">Julian Miller et al.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The study evaluates different algorithmic structures for their efficiency in high-performance parallel computing." ,&lt;SEP&gt;The study investigates the efficiency of different algorithmic structures for high-performance computing.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Algorithms">
  <data key="d0">Parallel Algorithms</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The model aims to optimize parallel algorithms globally to enhance performance and efficiency.&lt;SEP&gt;The model aims to optimize parallel algorithms globally to improve overall performance and resource efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Theoretical Model for Global Optimization">
  <data key="d0">Theoretical Model for Global Optimization</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The model aims to optimize parallel algorithms globally to enhance performance and efficiency.&lt;SEP&gt;The model aims to optimize parallel algorithms globally to improve overall performance and resource efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="William S. Moses et al.">
  <data key="d0">William S. Moses et al.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The study introduces Polygeist as a tool for transforming C code into Polyhedral MLIR for compiler optimization.&lt;SEP&gt;The study introduces Polygeist as a tool for transforming C code into Polyhedral MLIR to enable high-level code optimization.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Ravi Teja Mullapudi et al.">
  <data key="d0">Ravi Teja Mullapudi et al.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The study develops methods for automatic scheduling to improve performance of Halide image processing pipelines.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Image processing pipelines">
  <data key="d0">Image processing pipelines</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">Halide is used to define and compile image processing pipelines, with focus on automatic scheduling.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Bradford Nichols et al.">
  <data key="d0">Bradford Nichols et al.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The authors document Pthreads as a standard for multiprocessing programming." ,&lt;SEP&gt;The authors document Pthreads as a standardized API for portable multi-threaded programming." ,</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Peng Si Ow and Thomas E Morton">
  <data key="d0">Peng Si Ow and Thomas E Morton</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The study evaluates filtered beam search as a scheduling technique.&lt;SEP&gt;The study evaluates the effectiveness of filtered beam search as a scheduling method." ,</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sreepathi Pai and Keshav Pingali">
  <data key="d0">Sreepathi Pai and Keshav Pingali</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The authors develop a compiler to enhance throughput of graph algorithms on GPUs.&lt;SEP&gt;The authors develop a compiler to improve throughput of graph algorithms on GPUs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Stephen W. Poole et al.">
  <data key="d0">Stephen W. Poole et al.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The authors discuss OpenSHMEM as a unified RMA (Remote Memory Access) model for parallel communication." ,&lt;SEP&gt;The authors discuss OpenSHMEM as a unified RMA model for parallel communication.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Adrian Schmitz et al.">
  <data key="d0">Adrian Schmitz et al.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The study introduces PPIR as a tool for representing and optimizing parallel patterns in hierarchical parallel systems." ,&lt;SEP&gt;The study introduces PPIR as a tool for representing parallel patterns in hierarchical parallelism contexts.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Michel Steuwer et al.">
  <data key="d0">Michel Steuwer et al.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">The authors develop Lift as an IR for generating efficient GPU code from high-level functional descriptions.&lt;SEP&gt;The authors develop Lift as an IR to generate efficient GPU code from functional programs." ,</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Image Processing Pipelines">
  <data key="d0">Image Processing Pipelines</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d2">Halide is used to define and compile image processing pipelines, with a focus on automatic scheduling techniques.&lt;SEP&gt;Halide is used to define, compile, and optimize image processing pipelines, with a focus on automatic scheduling techniques.&lt;SEP&gt;Halide is used to define, compile, and optimize image processing pipelines, with a focus on automatic scheduling.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Domain Specialization">
  <data key="d0">Domain Specialization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Domain specialization involves tailoring LLMs to specific application domains by addressing data heterogeneity, domain knowledge complexity, objectives, and constraints to enhance their effectiveness and disruptiveness.&lt;SEP&gt;Domain specialization refers to techniques and approaches used to adapt LLMs for specific application domains, addressing challenges such as data heterogeneity, domain knowledge complexity, and domain-specific constraints to enhance their effectiveness and impact.&lt;SEP&gt;The concept that tailoring models specifically to certain domains can enhance their performance and disrupt traditional large language models.&lt;SEP&gt;The idea that tailoring models to specific domains can make large language models more effective and disruptive.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Specification Techniques">
  <data key="d0">Domain Specification Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A set of techniques and methods designed to tailor large language models to particular domains, including data adaptation, model fine-tuning, and prompt engineering, to overcome heterogeneity and domain-specific constraints.&lt;SEP&gt;Techniques designed to adapt and customize LLMs for particular domains, addressing challenges related to data heterogeneity, social norms, cultural, religious, and ethical constraints.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Taxonomy of Domain-Specialization Techniques">
  <data key="d0">Taxonomy of Domain-Specialization Techniques</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">A systematic categorization of various domain specialization methods based on accessibility to LLMs, illustrating their frameworks, relations, and differences.&lt;SEP&gt;A systematic classification framework that categorizes various domain specialization methods based on their accessibility to LLMs, their frameworks, relations, and differences, aiding in understanding and selecting appropriate techniques.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Application Domains">
  <data key="d0">Application Domains</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Critical application areas that significantly benefit from specialized LLMs, such as healthcare, finance, legal, and social sciences, highlighting their practical importance and challenges.&lt;SEP&gt;Critical areas where specialized LLMs can be applied, such as healthcare, finance, legal, social sciences, and others, highlighting their practical significance and the open challenges faced in deploying domain-specific models.&lt;SEP&gt;Major fields such as healthcare, finance, legal, and social media where domain-specific LLMs are applied to enhance performance and utility.&lt;SEP&gt;Major fields where domain-specific LLMs are applied, such as healthcare, finance, or legal sectors, each with unique challenges.&lt;SEP&gt;Various fields such as natural sciences, social sciences, and formal sciences where domain-specific LLMs are applied to improve task performance.&lt;SEP&gt;Various fields such as natural sciences, social sciences, and formal sciences where domain-specific LLMs can be applied to improve tasks and outcomes.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4&lt;SEP&gt;chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Research Status and Future Trends">
  <data key="d0">Research Status and Future Trends</data>
  <data key="d1">Results</data>
  <data key="d2">Current research indicates increasing focus on domain-specific adaptation of LLMs, with ongoing challenges and promising future directions for enhancing their impact.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Research Status">
  <data key="d0">Research Status</data>
  <data key="d1">Results</data>
  <data key="d2">Current research indicates increasing efforts to develop and refine domain-specific LLMs, with ongoing challenges related to data heterogeneity, ethical constraints, and domain knowledge integration, and future trends focusing on systematic approaches.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Future Trends">
  <data key="d0">Future Trends</data>
  <data key="d1">Results</data>
  <data key="d2">Emerging directions in LLM domain adaptation, such as improved knowledge integration, interpretability, and cross-disciplinary approaches.&lt;SEP&gt;Emerging directions in LLM domain specialization, including new methodologies, hybrid approaches, and application expansion.&lt;SEP&gt;Emerging directions in domain specialization include more systematic taxonomy development, broader application of domain-specific models, and improved techniques for handling domain constraints and norms.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4&lt;SEP&gt;chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Heterogeneity of Domain Data">
  <data key="d0">Heterogeneity of Domain Data</data>
  <data key="d1">Variables</data>
  <data key="d2">The diversity and variability in data across different domains, which pose challenges for training and adapting LLMs effectively.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Knowledge">
  <data key="d0">Domain Knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A comprehensive understanding of a specific field, including concepts, facts, and principles, used to inform model augmentation.&lt;SEP&gt;A comprehensive understanding of a specific field, including concepts, principles, facts, and patterns, used to inform model performance.&lt;SEP&gt;Domain knowledge encompasses the specialized information, concepts, and data relevant to a particular field or discipline.&lt;SEP&gt;Structured information, concepts, and facts relevant to a specific field or discipline that can be integrated into LLMs to improve performance.&lt;SEP&gt;The accumulated facts, principles, and information that underpin a specific field or area of expertise, used to inform understanding and decision-making in models and applications.&lt;SEP&gt;The specialized knowledge and information unique to specific application domains, requiring incorporation into LLMs for effective performance.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-1c77a184d805ecadcb8dd5b0d1057e7c&lt;SEP&gt;chunk-4068ec6ee794d8ae5ed33ac825ff37d4&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Social Norms, Cultural Conformity, Religious Beliefs, Ethical Standards">
  <data key="d0">Social Norms, Cultural Conformity, Religious Beliefs, Ethical Standards</data>
  <data key="d1">Variables</data>
  <data key="d2">Constraints and norms that influence how LLMs are applied in specific domains, affecting model outputs and deployment practices.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Open Challenges">
  <data key="d0">Open Challenges</data>
  <data key="d1">Limitations</data>
  <data key="d2">Challenges include sensitivity of adapter performance to architecture and hyperparameters, increased resource demands, and memory consumption during training, especially for large models.&lt;SEP&gt;Current challenges include lack of standardization, cross-domain applicability, resource constraints, and difficulty in systematic evaluation of techniques.&lt;SEP&gt;Current issues include inaccessibility of model architecture, high computational costs for knowledge updates, and risks of inaccuracies when deploying generic models in specialized domains.&lt;SEP&gt;Current limitations include architecture inaccessibility, high computational costs for knowledge updates, and risks of inaccuracies when applying generic models to specialized domains.&lt;SEP&gt;Current obstacles include lack of standardization, cross-domain applicability, and resource constraints, hindering progress in LLM domain adaptation.&lt;SEP&gt;Remaining issues in domain specialization of LLMs, such as data privacy, ethical considerations, transferability, and scalability of domain-specific models.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556&lt;SEP&gt;chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-bb9f9f9e90a0c162892181da55ffb7b4&lt;SEP&gt;chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Natural Language Processing">
  <data key="d0">Natural Language Processing</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A field of AI focused on the interaction between computers and human language, encompassing tasks like entailment, classification, and reasoning.&lt;SEP&gt;Natural Language Processing (NLP) is a field of artificial intelligence focused on enabling computers to understand, interpret, and generate human language.&lt;SEP&gt;An interdisciplinary field combining linguistics, computer science, and artificial intelligence to analyze human language data.&lt;SEP&gt;The field studying language models and their societal impacts, including bias and representation issues.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3&lt;SEP&gt;chunk-130e4012ca037ccaf70ac4ffd0928777&lt;SEP&gt;chunk-96b489f22f60397ff887486ccf77f457&lt;SEP&gt;chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Transformer-based neural network architecture">
  <data key="d0">Transformer-based neural network architecture</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Transformer architecture employs self-attention mechanisms to improve the modeling of sequential data, significantly advancing NLP capabilities.&lt;SEP&gt;Transformers utilize self-attention mechanisms to process sequential data efficiently, forming the backbone of many large language models.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pre-trained Language Models (PLMs)">
  <data key="d0">Pre-trained Language Models (PLMs)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">PLMs are models pretrained on large corpora in an unsupervised manner, enabling transfer learning for various NLP tasks without training from scratch.&lt;SEP&gt;PLMs are models pretrained on large unlabeled corpora using self-supervised learning, enabling transfer learning for various NLP tasks without retraining from scratch.&lt;SEP&gt;PLMs are neural network models pre-trained on extensive text corpora to learn linguistic patterns, serving as foundational components for building LLMs and enabling transfer learning in NLP.&lt;SEP&gt;PLMs are neural network models trained on large text datasets to learn linguistic patterns, structures, and semantics, forming the foundation for LLMs and enabling downstream NLP tasks.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4&lt;SEP&gt;chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scaling law">
  <data key="d0">Scaling law</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The scaling law describes how increasing model size and training data can lead to improved model capacity and performance in LLMs.&lt;SEP&gt;The scaling law describes how increasing model size and training data size leads to improved performance in neural language models.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain specialization of LLMs">
  <data key="d0">Domain specialization of LLMs</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of customizing general-purpose LLMs with domain-specific data, knowledge, objectives, and constraints to enhance performance in specific fields.&lt;SEP&gt;The process of customizing general-purpose large language models with domain-specific data, knowledge, and constraints to enhance their effectiveness within specialized fields.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge cut-off">
  <data key="d0">Knowledge cut-off</data>
  <data key="d1">Variables</data>
  <data key="d2">Knowledge cut-off refers to the fixed point in time after which an LLM's training data no longer includes new information, limiting its access to the latest knowledge.&lt;SEP&gt;Knowledge cut-off refers to the fixed temporal boundary after which an LLM's training data no longer includes new information, limiting its current knowledge.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Open challenges">
  <data key="d0">Open challenges</data>
  <data key="d1">Results</data>
  <data key="d2">Key challenges include maintaining up-to-date knowledge, addressing proprietary and ethical constraints, and adapting models to social and cultural norms.&lt;SEP&gt;Open challenges include keeping LLMs updated with the latest knowledge, addressing proprietary and ethical constraints, and adapting to social and cultural norms.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Future trends">
  <data key="d0">Future trends</data>
  <data key="d1">Research Directions</data>
  <data key="d2">Future research focuses on developing continuous learning, better domain adaptation, and mechanisms to keep models current with evolving knowledge.&lt;SEP&gt;Future trends involve developing continuous learning mechanisms, better domain adaptation techniques, and methods to keep models current with evolving knowledge.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Artificial Intelligence">
  <data key="d0">Artificial Intelligence</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Artificial Intelligence (AI) encompasses the development of computer systems capable of performing tasks that typically require human intelligence, such as understanding language, recognizing patterns, and decision-making.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Self-attention">
  <data key="d0">Self-attention</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Self-attention is a mechanism allowing models to weigh the importance of different parts of input data dynamically, significantly improving sequence modeling in NLP.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge updating mechanisms">
  <data key="d0">Knowledge updating mechanisms</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques designed to enable LLMs to incorporate new information post-training, such as continual learning or retrieval-augmented generation.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Open challenges in knowledge updating">
  <data key="d0">Open challenges in knowledge updating</data>
  <data key="d1">Limitations</data>
  <data key="d2">The difficulty of keeping LLMs updated with the latest information due to static training data and knowledge cut-offs.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Proprietary knowledge resources">
  <data key="d0">Proprietary knowledge resources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Proprietary knowledge resources are exclusive data or information assets held by organizations, critical for domain-specific LLM training but often confidential.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Social norms, cultural conformity, legal requirements, ethical practices">
  <data key="d0">Social norms, cultural conformity, legal requirements, ethical practices</data>
  <data key="d1">Variables</data>
  <data key="d2">These are societal and legal parameters that influence how LLMs should be adapted or constrained in different contexts.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model scaling">
  <data key="d0">Model scaling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Scaling involves increasing model size and training data to improve performance, following the scaling law.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Interdisciplinary collaboration">
  <data key="d0">Interdisciplinary collaboration</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Large language models can facilitate collaboration across scientific disciplines by providing advanced literature analysis and hypothesis generation.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Discoveries">
  <data key="d0">Discoveries</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Discoveries refer to new findings, regulations, and best practices that continuously emerge across specialized domains, impacting knowledge growth and application.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Regulations">
  <data key="d0">Regulations</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Regulations are rules and standards that govern practices within various domains, influencing compliance and operational procedures.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Best Practices">
  <data key="d0">Best Practices</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Best practices are established methods and procedures considered most effective within specific fields, guiding practitioners towards optimal outcomes.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Extraction">
  <data key="d0">Knowledge Extraction</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Knowledge extraction involves retrieving relevant information from training data to inform model outputs, critical for maintaining LLM relevance.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Re-Training">
  <data key="d0">Re-Training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Re-training is the process of updating LLMs with new data to improve accuracy and relevance, often resource-intensive.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Continuous Learning">
  <data key="d0">Continuous Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Continuous learning mechanisms enable LLMs to adapt over time by incorporating new knowledge without complete retraining.&lt;SEP&gt;Continuous learning mechanisms enable LLMs to adapt over time by incorporating new knowledge without needing full re-training, helping to maintain model relevance.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Resource-Intensive Processes">
  <data key="d0">Resource-Intensive Processes</data>
  <data key="d1">Limitations</data>
  <data key="d2"> Maintaining and updating LLMs through re-training or continuous learning requires substantial computational resources, making it costly and challenging.&lt;SEP&gt;Re-training and continuous learning require substantial computational resources, making maintenance costly and complex.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-Specific Knowledge">
  <data key="d0">Domain-Specific Knowledge</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Domain-specific knowledge encompasses specialized information, principles, and facts relevant to a particular field, used to augment or inform model performance.&lt;SEP&gt;Domain-specific knowledge refers to specialized information and terminology unique to particular fields, often underrepresented in general LLM training.&lt;SEP&gt;Knowledge that is specific to a particular field, including concepts, facts, and principles, used to enhance model performance in that domain.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Over-Representation">
  <data key="d0">Knowledge Over-Representation</data>
  <data key="d1">Variables</data>
  <data key="d2">Some topics are over-represented in training data, leading to biases, while niche domains are under-represented, affecting model performance.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hallucination">
  <data key="d0">Hallucination</data>
  <data key="d1">Results</data>
  <data key="d2">Hallucination describes the phenomenon where LLMs generate plausible-sounding but incorrect or unsupported information, especially in complex domains.&lt;SEP&gt;Hallucination refers to instances where LLMs generate plausible but incorrect or unsupported information, often due to gaps in domain knowledge or overgeneralization.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task-Specific Guidance">
  <data key="d0">Task-Specific Guidance</data>
  <data key="d1">Tools</data>
  <data key="d2">Providing task-specific demonstrations or instructions helps guide LLMs to produce more relevant and accurate responses in specialized tasks.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Token Limit">
  <data key="d0">Token Limit</data>
  <data key="d1">Variables</data>
  <data key="d2">LLMs have a finite context window (e.g., 4097 tokens in ChatGPT), limiting the amount of information processed at once, affecting complex task handling.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Downstream Task Learning">
  <data key="d0">Downstream Task Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Downstream task learning involves adapting LLMs to specific applications using high-quality, task-specific data, but poses challenges like catastrophic forgetting and hyperparameter tuning.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hyperparameters">
  <data key="d0">Hyperparameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Hyperparameters such as learning rate and training duration significantly influence the effectiveness of domain adaptation in LLMs.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Computational Power">
  <data key="d0">Computational Power</data>
  <data key="d1">Tools</data>
  <data key="d2">Training and fine-tuning large-scale LLMs require substantial computational resources, including high-performance GPUs or TPUs.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Specialization Techniques">
  <data key="d0">Domain Specialization Techniques</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Methods designed to adapt LLMs for specific domains, involving various approaches categorized systematically in this review.&lt;SEP&gt;Techniques aimed at customizing LLMs for specific domains, such as medical or financial sectors, to improve relevance, accuracy, and performance in targeted applications.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Taxonomy of Techniques">
  <data key="d0">Taxonomy of Techniques</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">A structured classification of domain adaptation methods based on accessibility levels (black-box, grey-box, white-box) and their characteristics.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Evaluation Methods">
  <data key="d0">Evaluation Methods</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Methods used to assess the effectiveness of domain specialization techniques, including performance metrics and benchmarks.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Specialized Domains">
  <data key="d0">Specialized Domains</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specialized domains refer to specific fields or areas of knowledge, such as medicine, law, finance, or social media analysis, where new discoveries, regulations, and best practices emerge continuously.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Update">
  <data key="d0">Knowledge Update</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Knowledge update involves mechanisms like re-training and continuous learning to keep LLMs relevant with current domain-specific information.&lt;SEP&gt;Knowledge update involves modifying the internal parameters or training data of an LLM to incorporate new domain-specific information.&lt;SEP&gt;Knowledge update refers to methods for modifying or expanding the knowledge base of language models, either through explicit instructions or partial parameter editing.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-ce8332c6d0b3d23f38189ff80650d4bc&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Re-Training">
  <data key="d0">Model Re-Training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Re-training is the process of updating large language models with new data to improve their accuracy and relevance in specific domains, often resource-intensive.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-Specific Tasks">
  <data key="d0">Domain-Specific Tasks</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Domain-specific tasks are particular problem sets within specialized fields that require tailored approaches and understanding, often challenging for general models.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Representation">
  <data key="d0">Knowledge Representation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Knowledge representation involves structuring domain knowledge in a way that models can utilize effectively, such as ontologies or structured databases.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Over-Representation of Topics">
  <data key="d0">Over-Representation of Topics</data>
  <data key="d1">Variables</data>
  <data key="d2">Some topics are over-represented in training data, leading to biases, whereas niche or less common topics are under-represented, affecting model performance.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Under-Representation of Topics">
  <data key="d0">Under-Representation of Topics</data>
  <data key="d1">Variables</data>
  <data key="d2">Certain specialized topics may be under-represented in training data, leading to gaps in knowledge and potential inaccuracies.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Taxonomy of Domain Specialization Techniques">
  <data key="d0">Taxonomy of Domain Specialization Techniques</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">A systematic classification of methods for domain adaptation of LLMs, organized by accessibility levels such as black-box, grey-box, and white-box approaches.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Systematic Review">
  <data key="d0">Systematic Review</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A comprehensive analysis summarizing current methods, challenges, and future directions in LLM domain specialization.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bottlenecks and Open Problems">
  <data key="d0">Bottlenecks and Open Problems</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Key unresolved issues in domain adaptation of LLMs, including technical, resource, and standardization challenges.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Transformer Architecture">
  <data key="d0">Transformer Architecture</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Transformer architecture is a neural network design based on attention mechanisms that underpins most modern LLMs, facilitating effective modeling of long-range dependencies in text.&lt;SEP&gt;Transformer architecture is a neural network model based on attention mechanisms that underpins most modern LLMs, facilitating effective modeling of long-range dependencies and contextual information in text.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Adaptation and Generalization">
  <data key="d0">Domain Adaptation and Generalization</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research on methods to adapt general LLMs to specific domains, often involving adding layers or updating parameters, though challenges exist due to architecture inaccessibility.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Risks of Generic LLMs">
  <data key="d0">Risks of Generic LLMs</data>
  <data key="d1">Results</data>
  <data key="d2">Applying generic LLMs to specialized fields like medicine or law can lead to inaccuracies and lack of originality, highlighting the need for domain-specific tuning.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Financial Sector LLMs">
  <data key="d0">Financial Sector LLMs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Development of finance-specific LLMs that enhance performance on financial NLP tasks without compromising general benchmarks.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Future Directions">
  <data key="d0">Future Directions</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploration of efficient adaptation, knowledge updating, and domain-specific training strategies to overcome existing bottlenecks and enhance LLM applicability.&lt;SEP&gt;Future research aims to measure Codex's economic value, impact on worker productivity, barriers to entry, and broader societal effects of AI in coding.&lt;SEP&gt;Future research aims to measure the economic value of code generation, impacts on worker productivity, barriers to entry, societal effects, and biases in Codex's suggestions.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4&lt;SEP&gt;chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Fundamental Overview of PLMs and LLMs">
  <data key="d0">Fundamental Overview of PLMs and LLMs</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Survey and review articles that examine the basic principles, architectures, and components of pre-trained language models and large language models, highlighting differences and similarities.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="History and Applications of Generative AI">
  <data key="d0">History and Applications of Generative AI</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The history and potential applications of generative AI, including LLMs, focusing on their evolution, capabilities, and impact across sectors.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Enhancing LLMs with Reasoning Capabilities">
  <data key="d0">Enhancing LLMs with Reasoning Capabilities</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Research efforts aimed at improving LLMs by integrating reasoning abilities to enhance their understanding and problem-solving skills.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Adaptation Techniques">
  <data key="d0">Domain Adaptation Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods used to adapt general LLMs to specific domains, such as adding layers, fine-tuning, or updating parameters, despite challenges posed by architecture inaccessibility.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Generalization of LLMs">
  <data key="d0">Generalization of LLMs</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research focused on enabling LLMs to perform well across various domains without extensive retraining, emphasizing robustness and transferability.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Challenges in Knowledge Updating">
  <data key="d0">Challenges in Knowledge Updating</data>
  <data key="d1">Limitations</data>
  <data key="d2">Difficulties in updating or incorporating new knowledge into large-scale LLMs due to high computational costs and architectural constraints.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Risks of Applying Generic LLMs">
  <data key="d0">Risks of Applying Generic LLMs</data>
  <data key="d1">Results</data>
  <data key="d2">Using non-specialized LLMs in sensitive or domain-specific areas like medicine or law can lead to inaccuracies, lack of originality, and potential harm, underscoring the need for domain-specific models.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Finance-Specific LLMs">
  <data key="d0">Finance-Specific LLMs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Development and evaluation of LLMs tailored for financial tasks, showing improved performance in finance-related NLP applications.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ms">
  <data key="d0">Ms</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ms refers to language models used for sequence-to-sequence tasks like machine translation and summarization, exemplified by models such as T5.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="T5">
  <data key="d0">T5</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">T5 is a notable example of a sequence-to-sequence transformer model used for various NLP tasks.&lt;SEP&gt;T5 is a transformer-based model designed for sequence-to-sequence NLP tasks, notable for its versatility in translation, summarization, and more.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Autoregressive Language Models">
  <data key="d0">Autoregressive Language Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Autoregressive language models generate text by predicting the next token based on prior tokens, suitable for text-generation tasks.&lt;SEP&gt;Autoregressive models generate text sequentially by predicting the next token conditioned on prior tokens, suitable for text generation.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Specialization of LLMs">
  <data key="d0">Domain Specialization of LLMs</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Domain specialization involves adapting large language models (LLMs) to perform optimally within specific fields or domains through various techniques.&lt;SEP&gt;Domain specialization involves tailoring large language models (LLMs) to perform optimally within specific fields or domains by employing various techniques.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="External Augmentation">
  <data key="d0">External Augmentation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">External augmentation incorporates external domain knowledge or tools into LLMs without modifying their internal structure, often via external resources or APIs.&lt;SEP&gt;External augmentation involves incorporating external domain knowledge or tools into LLMs, often without internal model modifications, to improve domain-specific performance.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Crafting">
  <data key="d0">Prompt Crafting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Prompt crafting is a grey-box approach where carefully designed prompts guide LLMs to better utilize domain knowledge during inference.&lt;SEP&gt;Prompt crafting is a grey-box approach where designing specific prompts guides LLMs to better utilize domain knowledge during inference.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Black Box">
  <data key="d0">Black Box</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A domain adaptation approach where the internal model parameters remain unchanged, and external tools or resources are used to influence outputs.&lt;SEP&gt;A modeling approach where internal workings are not modified, and external tools or resources are used to influence outputs.&lt;SEP&gt;Black box assumption indicates only API access to the LLM, with no internal details available, relying on external augmentation and prompt engineering for domain adaptation.&lt;SEP&gt;Black box assumption means only API access to the LLM without internal knowledge, relying on external augmentation for domain adaptation.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Grey Box">
  <data key="d0">Grey Box</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">An approach that involves prompt engineering and gradient-based methods to steer model behavior without changing internal parameters.&lt;SEP&gt;An approach that involves prompt engineering and gradient-based techniques to steer model behavior without modifying internal parameters.&lt;SEP&gt;Grey box assumption indicates limited internal information, allowing prompt crafting and limited gradient-based adjustments for domain specialization.&lt;SEP&gt;Grey box assumption provides limited internal information, allowing techniques like prompt crafting and limited gradient-based adjustments for domain adaptation.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="White Box">
  <data key="d0">White Box</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">An approach involving fine-tuning the model's internal parameters with domain-specific data to deeply adapt its behavior.&lt;SEP&gt;White box assumption entails full access to the LLM's parameters and architecture, enabling direct fine-tuning and internal modifications.&lt;SEP&gt;White box assumption means full access to the LLM's architecture and parameters, enabling internal modifications such as fine-tuning.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Training Strategies">
  <data key="d0">Training Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Training strategies for domain specialization include fine-tuning existing models, training from scratch, or employing mixed strategies to incorporate domain-specific knowledge.&lt;SEP&gt;Training strategies include fine-tuning existing models, training from scratch, or mixed approaches for domain-specific adaptation.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Intervention Level">
  <data key="d0">Intervention Level</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Intervention levels encompass pre-training modifications, fine-tuning adjustments, and inference-time modifications to tailor LLM outputs for specific domains.&lt;SEP&gt;Intervention levels refer to pre-training, fine-tuning, or inference-time modifications to adapt LLMs for specific domains.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Evaluation and Feedback Mechanisms">
  <data key="d0">Evaluation and Feedback Mechanisms</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Evaluation approaches include fixed benchmarks, dynamic assessments, and user feedback to guide domain adaptation of LLMs.&lt;SEP&gt;Evaluation methods include fixed benchmarks, dynamic performance assessment, and user feedback to guide domain-specific model tuning.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge">
  <data key="d0">Knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">External knowledge refers to domain-specific information, tools, or instructions used to enhance LLM performance in specialized fields.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Tools">
  <data key="d0">Domain Tools</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Domain tools are external resources or software used to augment LLMs with specialized domain knowledge or functionalities.&lt;SEP&gt;Specialized software or datasets designed to augment large language models, especially in biomedical contexts.&lt;SEP&gt;Specialized software or hardware components used within LLM-based systems to perform specific functions, such as theorem proving or task execution.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameters">
  <data key="d0">Parameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters are adjustable internal settings of a model that influence its behavior and outputs, modified during processes like fine-tuning to adapt the model to specific domains.&lt;SEP&gt;Parameters are internal model weights that can be adjusted during fine-tuning to encode domain-specific knowledge.&lt;SEP&gt;Parameters refer to the adjustable internal settings of a model that influence its behavior and outputs, and are modified during processes like fine-tuning to adapt the model to specific domains.&lt;SEP&gt;Parameters are the model's weights or coefficients, with sizes up to 12 billion in GPT models, influencing model capacity and performance.&lt;SEP&gt;The number of model parameters (e.g., 12B, 679M) influences the capacity and performance of GPT models and Codex in understanding and generating code.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Approaches">
  <data key="d0">Approaches</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Different strategies for domain adaptation of LLMs, including black box, grey box, and white box methods, each with distinct mechanisms and trade-offs.&lt;SEP&gt;Relations between approaches in different categories, such as black box, grey box, and white box methods, and their interactions in domain adaptation.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Complementary Methods">
  <data key="d0">Complementary Methods</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The approaches (augmentation, fine-tuning, prompt engineering) can be combined or used independently to optimize domain-specific performance.&lt;SEP&gt;The idea that different domain adaptation approaches can be combined or used independently to optimize performance.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Definition">
  <data key="d0">Definition</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The initial stage where the domain, objectives, and constraints are clearly specified to guide subsequent adaptation steps.&lt;SEP&gt;The initial stage where the specific domain, objectives, and constraints are clearly defined to inform subsequent adaptation steps.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="External Knowledge Augmentation">
  <data key="d0">External Knowledge Augmentation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using external domain knowledge sources to enhance the depth and accuracy of LLM responses without modifying internal parameters.&lt;SEP&gt;Using external sources of domain knowledge to improve the depth and accuracy of LLM responses without altering internal model parameters.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Explicit Knowledge">
  <data key="d0">Explicit Knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Information source containing task-relevant, domain-specific data that can be retrieved to refine model predictions.&lt;SEP&gt;Structured, clearly defined information that can be directly retrieved and used by LLMs for domain-specific tasks.&lt;SEP&gt;Structured, clearly defined information that can be directly retrieved and used by LLMs to enhance domain-specific responses.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Implicit Knowledge">
  <data key="d0">Implicit Knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Latent, non-explicit knowledge embedded within data or systems, influencing responses in a non-obvious way.&lt;SEP&gt;Latent, non-obvious information embedded within data or models, represented as vectorized embeddings learned during pre-training, capturing complex data patterns.&lt;SEP&gt;Latent, non-obvious knowledge embedded within data or systems, not directly expressed but influencing model responses.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Retrieval">
  <data key="d0">Knowledge Retrieval</data>
  <data key="d1">Tools</data>
  <data key="d2">Methods and systems used to fetch relevant external domain-specific information to inform or augment model outputs.&lt;SEP&gt;Systems and methods used to extract relevant information from external sources to assist language models in generating accurate responses.&lt;SEP&gt;Systems designed to retrieve relevant information to assist language models in generating accurate responses.&lt;SEP&gt;Systems or methods used to fetch relevant external domain-specific information to augment model responses.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fine-Tuning">
  <data key="d0">Fine-Tuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">Adjusting a pre-trained model on smaller, task-specific datasets to improve its performance on particular tasks.&lt;SEP&gt;Adjusting pre-trained models on smaller datasets to improve performance on specific tasks.&lt;SEP&gt;Adjusting the internal parameters of a model using domain-specific data to achieve deeper adaptation.&lt;SEP&gt;Fine-tuning is a process of adapting a pre-trained language model by additional training on specific data to improve performance on targeted tasks, such as code generation.&lt;SEP&gt;Fine-tuning refers to the process of adapting a pre-trained language model, such as GPT, to specific tasks or datasets by additional training, enhancing its performance on targeted activities like code generation.&lt;SEP&gt;Fine-tuning involves adjusting a pre-trained language model on specific datasets to improve performance on targeted tasks such as reducing model size and accelerating training on hardware like A100 GPUs.&lt;SEP&gt;Fine-tuning involves adjusting a pre-trained language model on specific datasets to improve performance on targeted tasks, such as reducing model size and accelerating training on hardware like A100 GPUs.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-50450e84744379a5c4f059c7d4f84019&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Post-Processing">
  <data key="d0">Post-Processing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques applied after model output generation to refine or filter responses for domain relevance.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Graphs">
  <data key="d0">Knowledge Graphs</data>
  <data key="d1">Tools</data>
  <data key="d2">Structured representations of domain knowledge that can be used to inform model responses or augment inputs.&lt;SEP&gt;Structured representations of knowledge that encode entities and their relationships, used to augment model understanding.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Behavior">
  <data key="d0">Model Behavior</data>
  <data key="d1">Results</data>
  <data key="d2">The observable actions and outputs of a model, which can be modified through training, prompting, or external tools.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Generalization">
  <data key="d0">Generalization</data>
  <data key="d1">Limitations</data>
  <data key="d2">The ability of LLMs to apply learned knowledge to new, unseen tasks or domains through prompting.&lt;SEP&gt;The model's ability to perform well on unseen data within the domain, which can be compromised by overfitting or limited training data.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Explicit Knowledge with LLM">
  <data key="d0">Explicit Knowledge with LLM</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A method that involves retrieving domain-specific information from external sources to improve language model performance on specialized tasks.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neural Retriever">
  <data key="d0">Neural Retriever</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique employing neural networks to vectorize queries and knowledge sources for relevant information retrieval based on similarity metrics.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Attention Mechanisms">
  <data key="d0">Attention Mechanisms</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Components in LLMs that focus on relevant parts of input, used to localize and understand internal knowledge representations.&lt;SEP&gt;Methods that enable models to retrieve task-related information from implicit knowledge by calculating attention scores between query vectors and knowledge entries.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc&lt;SEP&gt;chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Latent Embeddings">
  <data key="d0">Latent Embeddings</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Vector representations of data or knowledge entries that encode domain-specific information in an abstract form for retrieval and inference.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instruction Cycle">
  <data key="d0">Instruction Cycle</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process involving retrieving implicit knowledge, parsing model outputs, and storing variable assignments back into memory to process large inputs and solve complex problems.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="External Knowledge">
  <data key="d0">External Knowledge</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Additional information sources outside the language model, including explicit (retrieved data) and implicit (embedded knowledge), used to enhance model performance and adaptability.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Seamless Integration">
  <data key="d0">Seamless Integration</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The challenge of incorporating external knowledge into LLMs effectively, allowing acceptance or rejection of retrieved information based on relevance and consistency.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scalability and Adaptability">
  <data key="d0">Scalability and Adaptability</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Design considerations for systems to handle large domain-specific datasets and adapt to evolving information without excessive computational costs.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Tool">
  <data key="d0">Domain Tool</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specialized software, libraries, or frameworks developed for specific domains (e.g., genomics APIs, theorem provers, social simulation environments) to perform domain-specific tasks.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-Specific Tools">
  <data key="d0">Domain-Specific Tools</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Tools designed to provide specialized functionalities and knowledge in specific domains, which can be integrated with LLMs to overcome their limitations and enhance task performance.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Collaborative Integration Approach">
  <data key="d0">Collaborative Integration Approach</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A methodological framework that combines the strengths of LLMs and domain-specific tools to address complex, domain-specific tasks by leveraging both AI language understanding and specialized functionalities.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multi-stage Pipeline">
  <data key="d0">Multi-stage Pipeline</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A procedural approach involving multiple steps where LLMs generate commands, execute domain tools, and post-process outputs to solve specific problems, such as arithmetic or data retrieval tasks.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Executable Commands">
  <data key="d0">Executable Commands</data>
  <data key="d1">Tools</data>
  <data key="d2">Commands generated by LLMs to invoke domain-specific tools, such as scripts or API calls, enabling automation and precise execution of complex tasks.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Python Script for Arithmetic Problem">
  <data key="d0">Python Script for Arithmetic Problem</data>
  <data key="d1">Tools</data>
  <data key="d2">A sample executable Python code generated by an LLM to solve the problem of determining the number of rabbits and chickens based on heads and feet counts.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="API Calling Scripts">
  <data key="d0">API Calling Scripts</data>
  <data key="d1">Tools</data>
  <data key="d2">Scripts generated by LLMs that invoke specific APIs of domain tools for tasks like search, database queries, or automation, often created through zero-shot or few-shot prompting.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task Planning and Coordination">
  <data key="d0">Task Planning and Coordination</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A framework describing how LLMs can serve as controllers to decompose complex tasks and coordinate multiple domain tools to achieve desired outcomes.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multi-tool Coordination">
  <data key="d0">Multi-tool Coordination</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A conceptual approach where LLMs coordinate multiple domain tools, managing task decomposition and execution flow to solve complex problems effectively.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Integration">
  <data key="d0">Knowledge Integration</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The conceptual process of combining general language understanding from LLMs with specialized domain knowledge from tools to improve accuracy and efficiency in task execution.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Result Post-processing">
  <data key="d0">Result Post-processing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of refining and converting raw outputs from domain tools into usable, human-readable results, often guided by LLMs.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-Shot or Few-Shot Prompting Techniques">
  <data key="d0">Zero-Shot or Few-Shot Prompting Techniques</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Prompting techniques that enable large language models (LLMs) to perform tasks with minimal or no task-specific training data, utilizing task instructions or examples to guide responses.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task Planners">
  <data key="d0">Task Planners</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models conceptualizing LLMs as controllers or API selectors that decompose complex tasks into subtasks and coordinate multiple domain tools.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Automated Theorem Proving Frameworks">
  <data key="d0">Automated Theorem Proving Frameworks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Frameworks like DSP that utilize LLMs and formal tools to draft, sketch, and prove mathematical conjectures.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="High-Level Solution Outlines">
  <data key="d0">High-Level Solution Outlines</data>
  <data key="d1">Variables</data>
  <data key="d2">Structured plans generated by LLMs to guide the execution of domain-specific tasks, matching subtasks to appropriate models or systems.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LLMs Embodied in Robots">
  <data key="d0">LLMs Embodied in Robots</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Large Language Models integrated into robots to serve as decision-making modules for physical tasks and human-robot interaction.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Human-Robot Interaction">
  <data key="d0">Human-Robot Interaction</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Field studying how robots equipped with LLMs communicate, plan, and collaborate with humans in real-world environments.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Physics Engines">
  <data key="d0">Physics Engines</data>
  <data key="d1">Tools</data>
  <data key="d2">Simulation software used alongside LLMs to provide grounded rationale and physics-based reasoning for tasks.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multi-Agent Collaboration">
  <data key="d0">Multi-Agent Collaboration</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models describing how multiple AI agents, including LLMs, communicate and work together to solve complex problems in shared environments.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Open Challenges in LLM Tool Augmentation">
  <data key="d0">Open Challenges in LLM Tool Augmentation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Key issues such as automated integration of domain tools and the development of AGI models that do not rely on external tools.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Crafting for Domain Specialization">
  <data key="d0">Prompt Crafting for Domain Specialization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques involving discrete and continuous prompts to adapt LLMs for specific domains, improving accuracy and adherence to user intentions.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="zero-shot or few-shot prompting techniques">
  <data key="d0">zero-shot or few-shot prompting techniques</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Techniques that utilize minimal or no task-specific data to enable large language models (LLMs) to perform diverse tasks by providing instructions or examples.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="complex tasks">
  <data key="d0">complex tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Tasks that require multiple steps, tools, or reasoning processes, often involving decomposition into subtasks.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="domain tools">
  <data key="d0">domain tools</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Software or hardware components specialized for particular domains, used by LLMs to execute specific functions within complex tasks.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="task planners">
  <data key="d0">task planners</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models conceptualizing LLMs as controllers or API selectors that decompose complex tasks into subtasks and coordinate multiple domain tools.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="API selectors">
  <data key="d0">API selectors</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models that describe how LLMs or systems select and invoke domain tools or APIs to accomplish tasks.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="decompose complex tasks">
  <data key="d0">decompose complex tasks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Processes or techniques used by LLMs or systems to break down intricate tasks into manageable subtasks for execution.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="coordinate between multiple tools">
  <data key="d0">coordinate between multiple tools</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for managing interactions and data flow among various tools or modules to ensure task completion.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="TaskMatrix.AI">
  <data key="d0">TaskMatrix.AI</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A framework that uses LLMs to generate high-level solution outlines for domain-specific tasks and match subtasks to appropriate models or systems for execution.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Qin et al. framework">
  <data key="d0">Qin et al. framework</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A general tool-augmented LLM framework that decomposes tasks, dynamically adjusts plans, and utilizes suitable tools for each subtask.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="decision-making module">
  <data key="d0">decision-making module</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Component within embodied LLM systems that enables autonomous decisions and action planning based on perception and prompts.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="artificial general intelligence (AGI)">
  <data key="d0">artificial general intelligence (AGI)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A highly autonomous, versatile AI system capable of performing any intellectual task without external tools, representing an ultimate goal for LLM development.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="prompt engineering">
  <data key="d0">prompt engineering</data>
  <data key="d1">Tools</data>
  <data key="d2">Techniques and tools used to create effective prompts for guiding LLM outputs.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Discrete Prompt">
  <data key="d0">Discrete Prompt</data>
  <data key="d1">Methodology</data>
  <data key="d2">A framework that uses specific instructions or examples to elicit the reasoning abilities of large language models (LLMs) without updating their inner parameters, applicable in zero-shot and few-shot settings.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot Discrete Prompts">
  <data key="d0">Zero-shot Discrete Prompts</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompting approach where only task descriptions are provided to LLMs, enabling them to perform unseen tasks without illustrative examples, often requiring post-processing of raw outputs.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Few-shot Discrete Prompts">
  <data key="d0">Few-shot Discrete Prompts</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompting approach where a small number of annotated examples accompany task descriptions, helping LLMs perform better on domain-specific tasks with limited data.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LLM">
  <data key="d0">LLM</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Large Language Models, such as GPT-3, which are pre-trained neural network models capable of understanding and generating human-like text.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Discrete Prompt Framework">
  <data key="d0">Discrete Prompt Framework</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A formal framework that defines how prompts are used to elicit specific outputs from LLMs without modifying their internal parameters.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task Description">
  <data key="d0">Task Description</data>
  <data key="d1">Tools</data>
  <data key="d2">Natural language instructions provided to LLMs to specify the task they need to perform, such as entailment classification.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Test Query">
  <data key="d0">Test Query</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A specific input or question posed to an LLM to evaluate its response based on the given prompt.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instruction Alignment Pre-training">
  <data key="d0">Instruction Alignment Pre-training</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A pre-training strategy that enables LLMs to better follow instructions and perform zero-shot tasks effectively.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Adaptation">
  <data key="d0">Domain Adaptation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Domain Adaptation refers to techniques that enable models trained in one domain to perform effectively in another, often using adapters for efficiency.&lt;SEP&gt;Techniques used to improve the performance of LLMs on specific domains or tasks by leveraging prompts or additional training.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Reasoning Ability">
  <data key="d0">Reasoning Ability</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The capacity of LLMs to perform multi-step logical or symbolic reasoning, often enhanced through specialized prompting techniques like Zero-shot-CoT.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot-CoT">
  <data key="d0">Zero-shot-CoT</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompting technique where adding 'Let's think step by step' encourages LLMs to produce reasoning chains before giving final answers, improving performance on reasoning tasks.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="PADA">
  <data key="d0">PADA</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompting approach that generates domain-related features and domain names as part of the prompt to facilitate domain adaptation in LLMs.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Semantic Segmentation">
  <data key="d0">Semantic Segmentation</data>
  <data key="d1">Study Design</data>
  <data key="d2">A task in computer vision where an image is partitioned into regions with semantic labels, often used as an application of zero-shot prompting in AI.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Arithmetic and Logical Reasoning Tasks">
  <data key="d0">Arithmetic and Logical Reasoning Tasks</data>
  <data key="d1">Results</data>
  <data key="d2">Tasks used to evaluate the reasoning capabilities of LLMs, where techniques like Zero-shot-CoT have demonstrated significant performance improvements.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Natural Language Sentences">
  <data key="d0">Natural Language Sentences</data>
  <data key="d1">Variables</data>
  <data key="d2">Sequences of tokens representing textual data used as inputs or outputs in prompting and evaluation.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Unseen Domains">
  <data key="d0">Unseen Domains</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Domains or areas not encountered during the initial training of LLMs, targeted by zero-shot and domain adaptation techniques.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot Learning">
  <data key="d0">Zero-shot Learning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A learning paradigm where models are evaluated on tasks or domains they have not been explicitly trained on, often enabled by prompting techniques.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Few-shot Learning">
  <data key="d0">Few-shot Learning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A learning paradigm where models are trained or adapted using only a small number of examples, often via prompting in LLMs.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Template">
  <data key="d0">Template</data>
  <data key="d1">Tools</data>
  <data key="d2">A predefined structure used to automatically generate prompts for LLMs, especially in zero-shot or few-shot settings.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task Performance">
  <data key="d0">Task Performance</data>
  <data key="d1">Results</data>
  <data key="d2">The output or accuracy of LLMs on specific tasks when using different prompting strategies.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multi-step Reasoning">
  <data key="d0">Multi-step Reasoning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of performing a sequence of logical steps to arrive at a conclusion, often enhanced by techniques like Zero-shot-CoT.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="APGAR Scores">
  <data key="d0">APGAR Scores</data>
  <data key="d1">Results</data>
  <data key="d2">APGAR scores are a measure used to assess the health of newborns immediately after birth, with low scores indicating potential health concerns.</data>
  <data key="d3">chunk-03fe9b9ee91cb6d7d1e6d86d23f22ae9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hypothesis">
  <data key="d0">Hypothesis</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A statement predicting that she had low APGAR scores, used to guide investigation into neonatal health outcomes.</data>
  <data key="d3">chunk-03fe9b9ee91cb6d7d1e6d86d23f22ae9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Tuning">
  <data key="d0">Prompt Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A parameter-efficient approach to adapt large language models (LLMs) and pre-trained language models (PLMs) by optimizing continuous prompts for specific tasks, including task-dependent and instance-dependent strategies, leveraging techniques like prompt content enhancement, initialization, and transfer learning.&lt;SEP&gt;A technique to adapt large language models by adjusting prompts to improve performance on specific tasks or domains, often involving soft prompts or discrete prompts.&lt;SEP&gt;Adjusting prompts to efficiently steer model outputs with minimal training.&lt;SEP&gt;Adjusting prompts to improve model performance on specific tasks by optimizing prompt content, position, and structure.&lt;SEP&gt;Prompt tuning is a parameter-efficient method to adapt pre-trained language models (PLMs) and large language models (LLMs) for specific tasks by optimizing continuous prompts, which can be task-dependent or instance-dependent, and involves techniques like prompt content enhancement, initialization strategies, and transfer learning.&lt;SEP&gt;Techniques for efficiently adapting large language models to specific tasks by adjusting prompts rather than retraining entire models.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-d3bbf812d2ef1f847454ee16a672e8f9&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task-dependent Prompt Tuning">
  <data key="d0">Task-dependent Prompt Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A category of prompt tuning that involves creating a shared prompt optimized for all instances within a specific task, capturing task-specific information from large datasets, but may face challenges in convergence and optimization.&lt;SEP&gt;A category of prompt tuning that optimizes a shared prompt for all instances within a specific task, capturing extensive dataset information, but may face convergence challenges.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Content Enhancement">
  <data key="d0">Prompt Content Enhancement</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Enhancement strategies for prompt embeddings, including task-specific initialization and prior knowledge transfer, to improve prompt optimization effectiveness.&lt;SEP&gt;Focuses on learning joint, adaptive representations of tasks and instance context, including techniques like additional perceptrons and attention-based prompt aggregation.&lt;SEP&gt;Improves prompts by learning joint representations of task and instance context, including additional knowledge and adaptive positioning.&lt;SEP&gt;Strategies to improve prompt embeddings through task-specific initialization, prior knowledge transfer, and embedding design to enhance training efficiency and performance.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9&lt;SEP&gt;chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Initialization Strategies">
  <data key="d0">Initialization Strategies</data>
  <data key="d1">Methods</data>
  <data key="d2">Approaches such as embedding of special tokens like '[MASK]', aggregated label word representations, or random initialization, used to set initial prompt embeddings for better training convergence.&lt;SEP&gt;Approaches such as using embeddings of special tokens like '[MASK]', aggregated label words, or random initialization to set the starting point for prompt optimization, affecting convergence and effectiveness.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Self-supervised Learning">
  <data key="d0">Self-supervised Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A learning paradigm where models are trained to predict parts of the input data without labeled supervision, enabling large-scale pre-training of language models.&lt;SEP&gt;A training approach where models learn from unlabeled data by predicting parts of the input, enabling pre-training of language models.&lt;SEP&gt;Pre-training prompts on large unlabeled corpora to generate effective initial prompts for downstream tasks, improving transferability and convergence.&lt;SEP&gt;Pre-training prompts on unlabeled corpora to generate effective initial prompts for downstream tasks, enhancing prompt transferability and convergence.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9&lt;SEP&gt;chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Transferability">
  <data key="d0">Prompt Transferability</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The ability of prompts trained on certain tasks or domains to be adapted and reused in different tasks or domains, enhancing efficiency and generalization.&lt;SEP&gt;The ability of prompts trained on certain tasks or domains to be effectively adapted to new tasks or domains, improving training efficiency and model performance.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Initialization">
  <data key="d0">Prompt Initialization</data>
  <data key="d1">Variables</data>
  <data key="d2">The starting embeddings or parameters used to initialize prompts before training, significantly influencing convergence and performance.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Pre-training">
  <data key="d0">Prompt Pre-training</data>
  <data key="d1">Methods</data>
  <data key="d2">Pre-training prompts using self-supervised learning to initialize prompts for downstream tasks.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Transferability of Prompts">
  <data key="d0">Transferability of Prompts</data>
  <data key="d1">Results</data>
  <data key="d2">Demonstrates that well-initialized prompts can significantly accelerate training convergence across tasks and models.&lt;SEP&gt;Well-initialized prompts can be transferred across tasks and models, significantly accelerating training and improving performance.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lifelong Learning with Soft Prompts">
  <data key="d0">Lifelong Learning with Soft Prompts</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Employs soft prompts that are trained continuously to solve current tasks and retain knowledge from previous tasks, overcoming catastrophic forgetting.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Progressive Prompts">
  <data key="d0">Progressive Prompts</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Introduce prompt tuning into continual learning by concatenating prompts optimized on previous tasks with current prompts.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Template-based Prompting">
  <data key="d0">Template-based Prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Reformulating NLP tasks into masked word prediction by employing predefined templates, leveraging pre-training knowledge.&lt;SEP&gt;Uses predefined templates to reformulate tasks, such as converting sentence classification into masked word prediction, to leverage language model pre-training.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Soft Prompts">
  <data key="d0">Soft Prompts</data>
  <data key="d1">Tools</data>
  <data key="d2">Trainable prompt embeddings that can be optimized during training to adapt models to specific tasks, supporting continual learning.&lt;SEP&gt;Trainable prompts that can be inserted into input sentences or attention mechanisms to adapt models flexibly to specific tasks.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="KnowPrompt">
  <data key="d0">KnowPrompt</data>
  <data key="d1">Tools</data>
  <data key="d2">A prompt design that appends templates with '[MASK]' tokens and incorporates trainable 'virtual type words' to improve relation extraction by aligning entity types with target relations.&lt;SEP&gt;A prompt discovery method that identifies prompt tokens near domain-related terms, improving interpretability and relevance.&lt;SEP&gt;A prompt discovery method where prompt tokens are close to domain-related terms, used to enhance interpretability.&lt;SEP&gt;Designs prompts with a '[MASK]' token inserted between subject and object, incorporating trainable 'virtual type words' for relation extraction.&lt;SEP&gt;KnowPrompt is a prompt-tuning framework that leverages knowledge to improve relation extraction and other NLP tasks.&lt;SEP&gt;KnowPrompt is a prompt-tuning method that incorporates knowledge-aware optimization to improve relation extraction tasks.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-d3bbf812d2ef1f847454ee16a672e8f9&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="KiPT">
  <data key="d0">KiPT</data>
  <data key="d1">Tools</data>
  <data key="d2">A knowledge extractor that identifies trigger words for event detection based on semantic similarity, reformulating sequence tagging into generative tasks.&lt;SEP&gt;A trigger word extractor for event detection, identifying trigger words based on semantic similarity and reformulating sequence tagging as generative tasks.&lt;SEP&gt;Knowledge-injected Prompt Tuning, a methodology for improving event detection in NLP.&lt;SEP&gt;Knowledge-injected Prompt Tuning, a methodology to enhance event detection performance in NLP by injecting knowledge into prompts.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9&lt;SEP&gt;chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instance-dependent Prompt Tuning">
  <data key="d0">Instance-dependent Prompt Tuning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A method that generates prompts tailored to individual instances, considering contextual and task-specific information for finer granularity.&lt;SEP&gt;A prompt tuning approach that generates prompts tailored to individual input instances, considering their specific context and knowledge.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="IDPG">
  <data key="d0">IDPG</data>
  <data key="d1">Tools</data>
  <data key="d2">Proposes an additional perceptron to generate adaptive soft prompts based on sentence embeddings.&lt;SEP&gt;Uses an additional perceptron to generate adaptive soft prompts based on sentence embeddings, capturing instance nuances.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ATTEMPT">
  <data key="d0">ATTEMPT</data>
  <data key="d1">Tools</data>
  <data key="d2">Employs an attention network to aggregate multiple prompts from large-scale source tasks, creating a final instance-specific prompt.&lt;SEP&gt;Uses an attention network to aggregate multiple prompts from large-scale source tasks, creating a final instance-specific prompt.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Construction Enhancement">
  <data key="d0">Prompt Construction Enhancement</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Refers to strategies for improving prompt design by adding instance-related knowledge or adjusting position and length dynamically.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="OntoPrompt">
  <data key="d0">OntoPrompt</data>
  <data key="d1">Tools</data>
  <data key="d2">Enriches prompts with external ontology knowledge and dynamically tunes prompt position, length, and content for better task performance.&lt;SEP&gt;Enriches prompts with external ontology knowledge and tunes prompts around '[MASK]' tokens for better prediction.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dynamic Prompting">
  <data key="d0">Dynamic Prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A framework for adaptively tuning prompts to improve language model performance across tasks, including a unified approach for prompt tuning.&lt;SEP&gt;A framework for prompt tuning that adapts prompts dynamically for improved language model performance.&lt;SEP&gt;A unified framework that learns prompt position, length, and values dynamically for each instance, enhancing prompt effectiveness.&lt;SEP&gt;Learns prompt parameters dynamically for each instance, optimizing position, length, and content to adapt to specific input features.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pre-training of Prompts">
  <data key="d0">Pre-training of Prompts</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Initializing prompts through self-supervised learning on unlabeled corpora to serve as a starting point for downstream tasks.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lifelong Learning">
  <data key="d0">Lifelong Learning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A learning approach where models continuously acquire knowledge over time, using mechanisms like soft prompts to retain and adapt to new tasks.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Discreet Prompts">
  <data key="d0">Discreet Prompts</data>
  <data key="d1">Tools</data>
  <data key="d2">Explicitly designed prompts with specific language phrases or templates to guide model behavior.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Continuous Prompts">
  <data key="d0">Continuous Prompts</data>
  <data key="d1">Tools</data>
  <data key="d2">Learned prompt embeddings that can be prepended, appended, or inserted into input sequences without explicit language templates.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="WARP">
  <data key="d0">WARP</data>
  <data key="d1">Tools</data>
  <data key="d2">A prompt method that uses all three intersections with a '[MASK]' token for classification tasks, enabling flexible prompt placement.&lt;SEP&gt;A study that analyzed the interpretability of soft prompts, finding them to be non-interpretable and lacking meaningful content.&lt;SEP&gt;A study that found soft prompts to be non-interpretable, with domain-related terms near optimal prompts.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prefix-tuning">
  <data key="d0">Prefix-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Prepending tunable prompts to sentence embeddings and attention activations to influence language model output efficiently.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Continuous Prompt Tuning">
  <data key="d0">Continuous Prompt Tuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A streamlined method to utilize the broad language understanding capacity of Large Language Models (LLMs) for specific tasks across different domains, addressing issues like reliance on prompts, computational complexity, and manual instruction design.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Discreet Prompt Methods">
  <data key="d0">Discreet Prompt Methods</data>
  <data key="d1">Methodology</data>
  <data key="d2">Techniques that depend heavily on prompt wording or templates, which can significantly influence LLM performance.&lt;SEP&gt;Techniques that rely on carefully crafted prompt templates or wording, which can significantly influence LLM outputs and performance.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Interpretability of Soft Prompt Tuning">
  <data key="d0">Interpretability of Soft Prompt Tuning</data>
  <data key="d1">Limitations</data>
  <data key="d2">A weakness where soft prompt tuning prompts are non-interpretable and lack meaningful content, raising concerns about understanding what the prompts encode.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt-tuning">
  <data key="d0">Prompt-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique involving training prompts close to domain-specific terms, such as science or engineering, to enhance task relevance.&lt;SEP&gt;A technique that discovers prompt tokens near domain-specific terms, such as science, technology, and engineering, to improve task performance.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="OPTIMA">
  <data key="d0">OPTIMA</data>
  <data key="d1">Methodology</data>
  <data key="d2">A domain adaptation approach that regularizes decision boundaries using adversarial learning to improve prompt effectiveness.&lt;SEP&gt;An approach that adapts domain data with prompt tuning by regularizing the decision boundary via adversarial learning.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Limited Access to LLMs">
  <data key="d0">Limited Access to LLMs</data>
  <data key="d1">Limitations</data>
  <data key="d2">A challenge where models with immense sizes or only API access restrict differential optimization on continuous embeddings.&lt;SEP&gt;Restrictions on model access (e.g., API-only or massive size) hinder gradient-based optimization, prompting the development of alternative tuning methods.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Derivative-free Prompt Tuning">
  <data key="d0">Derivative-free Prompt Tuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">An approach that optimizes soft prompts without relying on gradients, suitable for black-box models.&lt;SEP&gt;Optimization approaches that do not rely on gradient information, suitable for black-box models or limited access scenarios.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Black-box Tuning (BBT)">
  <data key="d0">Black-box Tuning (BBT)</data>
  <data key="d1">Methodology</data>
  <data key="d2">A derivative-free optimization method that employs Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to find optimal prompts without gradient access.&lt;SEP&gt;A gradient-free approach using Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to search for optimal prompts without gradient access.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Clip-Tuning">
  <data key="d0">Clip-Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A method that uses deterministic clipping of the target language model to optimize an agent learning intrinsic prompt embeddings.&lt;SEP&gt;A technique that uses deterministic clipping to optimize prompts by learning intrinsic prompt embeddings in models with restricted access.&lt;SEP&gt;Clip-Tuning is a technique for prompt learning that aims to optimize models without derivatives, using a mixture of rewards to improve prompt effectiveness.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Discrete Prompt Search">
  <data key="d0">Discrete Prompt Search</data>
  <data key="d1">Methodology</data>
  <data key="d2">A promising direction involving derivative-free approaches for discrete prompt optimization, especially when only textual queries are allowed.&lt;SEP&gt;Approaches that seek optimal prompts in a discrete space without gradient information, especially useful when only textual queries are permissible.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Fine-tuning for Domain Specialization">
  <data key="d0">Model Fine-tuning for Domain Specialization</data>
  <data key="d1">Methodology</data>
  <data key="d2">Techniques to adapt large language models to specific domains or tasks by adjusting model parameters through fine-tuning.&lt;SEP&gt;Techniques to adapt large language models to specific domains via additional training, either through adapter-based or task-oriented approaches.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapter-based Fine-tuning">
  <data key="d0">Adapter-based Fine-tuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A domain adaptation approach that adds small trainable modules (adapters) into the existing LLM architecture, enabling efficient specialization.&lt;SEP&gt;A strategy that adds small, trainable modules (adapters) into the existing LLM architecture to improve domain-specific performance without major modifications.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task-oriented Fine-tuning">
  <data key="d0">Task-oriented Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A method that involves modifying the inner parameters of an LLM to better align with specific tasks, often requiring selective updates.&lt;SEP&gt;A process of updating LLMs' parameters on specific high-quality domain datasets to improve performance on targeted tasks.&lt;SEP&gt;A technique that involves modifying or updating the core parameters of an LLM to improve performance on specific tasks or domains.&lt;SEP&gt;The process of updating LLMs' parameters on specific, high-quality domain datasets to enhance performance on targeted tasks.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapters">
  <data key="d0">Adapters</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Adapters are modules inserted into language models to facilitate domain adaptation or task-specific tuning without retraining the entire model.&lt;SEP&gt;Adapters are modules integrated into models to facilitate efficient domain adaptation, allowing models to adjust to new tasks or data distributions without retraining from scratch.&lt;SEP&gt;Adapters are trainable modules inserted between layers of pre-trained models, designed to enable parameter-efficient fine-tuning and domain adaptation, often involving domain-specific and task-specific modules.&lt;SEP&gt;Modules added to pre-trained language models to enable domain adaptation and task-specific fine-tuning without retraining the entire model.&lt;SEP&gt;Modules integrated into pre-trained language models to enable efficient domain adaptation and task-specific fine-tuning without retraining the entire model.&lt;SEP&gt;Trainable modules inserted between layers of a pre-trained language model to facilitate efficient domain adaptation without retraining the entire model.&lt;SEP&gt;Trainable modules inserted between layers of a pre-trained language model to facilitate efficient domain adaptation.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d&lt;SEP&gt;chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neural Adapters">
  <data key="d0">Neural Adapters</data>
  <data key="d1">Tools</data>
  <data key="d2">Adapters with neural network architectures that are inserted into transformer layers, such as bottleneck or serial adapters, designed for domain adaptation and downstream task performance.&lt;SEP&gt;Modular components that can be added to LLMs to allow for task-specific tuning with minimal parameter updates.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter-efficient Fine-tuning">
  <data key="d0">Parameter-efficient Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A set of techniques, including adapters, that aim to adapt large models with minimal additional parameters, reducing computational costs.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter-Efficient Fine-Tuning">
  <data key="d0">Parameter-Efficient Fine-Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A training approach that enables adapting large language models to new domains or tasks with minimal additional parameters, often utilizing adapters to share parameters across multiple domains and tasks.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Unsupervised Domain Adaptation (UDA)">
  <data key="d0">Unsupervised Domain Adaptation (UDA)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique aimed at improving a model's performance across different domains without labeled data, often using adapters to learn domain-invariant representations.&lt;SEP&gt;A training strategy that adapts models to new domains without requiring labeled data, often employing adapters to learn domain-invariant features.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="AdapterFusion">
  <data key="d0">AdapterFusion</data>
  <data key="d1">Tools</data>
  <data key="d2">AdapterFusion is a framework for combining multiple adapters in transfer learning, enabling non-destructive task composition in transformer models.&lt;SEP&gt;AdapterFusion is a framework for non-destructive task composition in transfer learning, enabling flexible adaptation of models to multiple tasks.&lt;SEP&gt;AdapterFusion trains multiple adapters on different tasks and combines their embeddings using a fusion layer to improve multi-task learning performance.&lt;SEP&gt;An architecture that combines multiple domain adapters by learning to fuse their outputs, enhancing multi-domain adaptation capabilities.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-bc782afdd6c18f4e206e464038047556&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LLaMA-adapter">
  <data key="d0">LLaMA-adapter</data>
  <data key="d1">Tools</data>
  <data key="d2">A specialized adapter architecture designed for large language models, enabling efficient instruction-following and multi-modal reasoning using self-instruct demonstrations.&lt;SEP&gt;An adaptation framework for large language models (LLaMAs) utilizing self-instruct demonstrations and specialized adapter architectures for instruction-following and multi-modal reasoning.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Low-Rank Adapters">
  <data key="d0">Low-Rank Adapters</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Adapters that utilize low-rank matrix approximations to reduce parameter count while maintaining performance, often based on hypercomplex multiplication layers or pruning techniques.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Autoencoder">
  <data key="d0">Autoencoder</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Autoencoders are neural network models used for learning efficient codings of data, inspiring invertible adapters that can be inverted to mimic autoencoder behavior.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kronecker Products">
  <data key="d0">Kronecker Products</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Kronecker products are mathematical operations used to construct parameter-efficient modules in neural networks, especially in low-rank adapters, by combining smaller matrices to form larger ones.&lt;SEP&gt;Kronecker products are mathematical operations used to construct parameter-efficient modules in neural networks, particularly in low-rank adapters, by combining smaller matrices to form larger ones.&lt;SEP&gt;Mathematical operations used in parameterized hypercomplex multiplication layers within parameter-efficient adapters, allowing for compact representations.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter-sharing">
  <data key="d0">Parameter-sharing</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Parameter-sharing refers to the strategy of using the same parameters across different parts of a model or multiple models to improve efficiency and generalization.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sequential Training">
  <data key="d0">Sequential Training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Sequential training is a process where models are trained on one domain or task at a time, often used in domain adaptation to incrementally improve performance across multiple domains.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-specific Task Performance">
  <data key="d0">Domain-specific Task Performance</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric (𝜙𝐷) that measures how well a model performs on a specific domain or task, higher values indicate better performance.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="General Input Data">
  <data key="d0">General Input Data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data (𝑋) representing the inputs to the language models, used to evaluate model performance and adaptation.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Frozen Parameters">
  <data key="d0">Frozen Parameters</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Parameters of a model that are kept unchanged during fine-tuning, enabling stable sharing across multiple tasks or domains.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapter Modules">
  <data key="d0">Adapter Modules</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Insertable components within models that facilitate domain-specific and task-specific learning, often used in parameter-efficient fine-tuning.&lt;SEP&gt;Modules inserted into pre-trained models to enable efficient domain and task adaptation without retraining the entire model.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapter Fusion">
  <data key="d0">Adapter Fusion</data>
  <data key="d1">Tools</data>
  <data key="d2">A technique that combines multiple adapters to improve multi-domain or multi-task performance by learning to integrate their outputs.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Invertible Adapters">
  <data key="d0">Invertible Adapters</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Adapters that can be inverted to reconstruct inputs or mimic autoencoders, used to enhance model flexibility and interpretability.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Residual Connection">
  <data key="d0">Residual Connection</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A neural network connection that adds the input of a layer to its output, improving gradient flow and model performance, used in residual adapters.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tiny-Attention Adapter">
  <data key="d0">Tiny-Attention Adapter</data>
  <data key="d1">Tools</data>
  <data key="d2">A lightweight attention module that emphasizes contextual importance, designed to improve model performance with minimal parameters.&lt;SEP&gt;A lightweight attention-based module that emphasizes contextual importance over parameter quantity in models.&lt;SEP&gt;An adapter that employs attention mechanisms with reduced per-head dimensionality to improve efficiency in model adaptation.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hypercomplex Multiplication Layers">
  <data key="d0">Hypercomplex Multiplication Layers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Parameterization method used in some adapters to learn complex transformations efficiently by utilizing Kronecker products or similar structures.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pruning">
  <data key="d0">Pruning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to reduce model size and complexity by removing redundant or less important parameters, applied in SparseAdapter and similar approaches.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="SparseAdapter">
  <data key="d0">SparseAdapter</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An adapter that uses pruning techniques to reduce the number of trainable parameters, enhancing efficiency and scalability.&lt;SEP&gt;SparseAdapter is a technique that reduces training parameters by pruning at initialization, applicable to neural adapters to improve parameter efficiency in language models.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter-efficient Layers">
  <data key="d0">Parameter-efficient Layers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Layers designed to minimize parameters while maintaining performance, such as hypercomplex layers or pruned layers.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Pruning">
  <data key="d0">Model Pruning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process of reducing model complexity by removing unnecessary parameters to improve efficiency and deployment.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Self-instruct Demonstrations">
  <data key="d0">Self-instruct Demonstrations</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data or techniques used to teach models to follow instructions by providing examples during training, especially in large language models.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Network Pruning">
  <data key="d0">Network Pruning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Network pruning involves reducing the number of parameters in neural networks by removing less important weights or structures, inspired here by the SparseAdapter technique to achieve parameter efficiency.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Low-rank Adaptation (LoRA)">
  <data key="d0">Low-rank Adaptation (LoRA)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">LoRA is a model that uses low-rank matrices to adapt large language models efficiently by inserting learnable SVD blocks, reducing parameters and inference latency.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kronecker Adapter (KronA)">
  <data key="d0">Kronecker Adapter (KronA)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">KronA replaces low-rank SVD modules with Kronecker product modules composed of smaller matrices, addressing representation power limitations of low-rank adapters.&lt;SEP&gt;KronA replaces low-rank SVD modules with Kronecker product modules composed of smaller matrices, addressing the limited representation power of low-rank adapters.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dynamic Search">
  <data key="d0">Dynamic Search</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Dynamic search in DyLora involves searching for the optimal rank and fixed block size in low-rank adaptation modules to improve performance.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Integrated Adapter Frameworks">
  <data key="d0">Integrated Adapter Frameworks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Frameworks like AdapterFusion, UniPELT, and AdaMix combine multiple adapters through fusion, gating, or stacking to enhance performance across tasks and domains.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="UniPELT">
  <data key="d0">UniPELT</data>
  <data key="d1">Methodologies</data>
  <data key="d2">UniPELT activates different combinations of adapter methods via a gating mechanism to adapt to current data or task setups efficiently.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="AdaMix">
  <data key="d0">AdaMix</data>
  <data key="d1">Methodologies</data>
  <data key="d2">AdaMix stacks multiple adapters of the same type and uses stochastic routing to reduce computational costs while enabling multi-adapter integration.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Routing Function">
  <data key="d0">Routing Function</data>
  <data key="d1">Variables</data>
  <data key="d2">A routing function determines how to dynamically select or weight adapters in multi-adapter frameworks, enabling flexible adaptation to various tasks.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multi-task Learning">
  <data key="d0">Multi-task Learning</data>
  <data key="d1">Study Design</data>
  <data key="d2">Multi-task learning involves training models simultaneously on multiple tasks, often utilizing multiple adapters and routing mechanisms to share knowledge.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapter Libraries">
  <data key="d0">Adapter Libraries</data>
  <data key="d1">Tools</data>
  <data key="d2">Libraries like AdapterHub and LLM-adapters provide implementations and frameworks for integrating various adapters into language models, supporting domain-specific and multi-model adaptation.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Backpropagation">
  <data key="d0">Backpropagation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A fundamental algorithm used to train neural networks by propagating errors backward through the network to update weights.&lt;SEP&gt;A fundamental training algorithm for neural networks that involves propagating errors backward through the model to update weights.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stability and Universality">
  <data key="d0">Stability and Universality</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates whether adapters consistently perform well across different architectures, hyperparameters, and tasks, and whether their effectiveness is universally applicable.&lt;SEP&gt;The inquiry into whether adapters consistently perform well across different architectures, hyperparameters, and tasks, and whether their effectiveness is universally applicable.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Computational Resources">
  <data key="d0">Computational Resources</data>
  <data key="d1">Variables</data>
  <data key="d2">Factors such as number of adapter parameters, training memory, and computational cost that influence the feasibility and efficiency of fine-tuning LLMs.&lt;SEP&gt;Factors such as the number of adapter parameters and training memory that influence the computational cost of fine-tuning LLMs.&lt;SEP&gt;High-performance GPUs and specialized hardware are critical variables affecting the feasibility and efficiency of fine-tuning large models, often limiting smaller organizations.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fine-tuning Strategies">
  <data key="d0">Fine-tuning Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques such as instruction-based fine-tuning and partial knowledge updates used to enhance LLM capabilities.&lt;SEP&gt;Various techniques such as instruction-based fine-tuning, partial knowledge updates, and reinforcement learning to improve LLM performance.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instruction-based Fine-tuning">
  <data key="d0">Instruction-based Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A method where LLMs are trained on diverse tasks with explicit instructions to improve zero-shot and few-shot performance.&lt;SEP&gt;Fine-tuning LLMs on datasets with explicit instructions or prompts across diverse tasks to improve zero-shot and few-shot performance.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Reinforcement Learning from Human Feedback (RLHF)">
  <data key="d0">Reinforcement Learning from Human Feedback (RLHF)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique that aligns LLM outputs with human preferences by iterative feedback, ranking generated content, and updating models via reinforcement learning.&lt;SEP&gt;A technique to align LLM outputs with human preferences by iterative feedback, ranking, and policy updates.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot Performance">
  <data key="d0">Zero-shot Performance</data>
  <data key="d1">Results</data>
  <data key="d2">The ability of LLMs to perform well on tasks without prior specific training, often improved through instruction tuning.&lt;SEP&gt;The ability of LLMs to successfully perform tasks without prior specific training, often enhanced through instruction tuning and large-scale training.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Few-shot Performance">
  <data key="d0">Few-shot Performance</data>
  <data key="d1">Results</data>
  <data key="d2">The ability of LLMs to perform well on tasks with limited examples, improved through fine-tuning and instruction-based methods.&lt;SEP&gt;The capability of LLMs to perform tasks with limited examples, enhanced via fine-tuning and instruction methods.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Training Memory">
  <data key="d0">Training Memory</data>
  <data key="d1">Variables</data>
  <data key="d2">The amount of memory required during training or fine-tuning, influencing computational feasibility and strategies for optimization.&lt;SEP&gt;The amount of memory required during training, which can be optimized through architectural or strategy innovations.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task-specific Datasets">
  <data key="d0">Task-specific Datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">High-quality, domain-specific data used to fine-tune LLMs for particular applications.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Safety and Alignment">
  <data key="d0">Safety and Alignment</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Ensuring LLM outputs are safe, truthful, and aligned with human values, often achieved via techniques like RLHF.&lt;SEP&gt;Ensuring that LLM outputs are safe, truthful, and aligned with human values, often achieved through human-in-the-loop techniques like RLHF.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="High-quality Domain-specific Datasets">
  <data key="d0">High-quality Domain-specific Datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Curated datasets tailored for specific domains used to fine-tune LLMs for improved task performance.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Generalization">
  <data key="d0">Model Generalization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ability of an LLM to perform well on unseen tasks or data, reflecting its robustness and adaptability.&lt;SEP&gt;The capability of a model to perform well on unseen data or outside its training domain, balancing specificity and broad applicability.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task-specific Knowledge">
  <data key="d0">Task-specific Knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The specialized information within an LLM relevant to particular tasks or domains, which can be updated or preserved during fine-tuning.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instruction Templates">
  <data key="d0">Instruction Templates</data>
  <data key="d1">Tools</data>
  <data key="d2">Predefined natural language prompts used to guide the fine-tuning process and improve model performance on diverse tasks.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Reward Model">
  <data key="d0">Reward Model</data>
  <data key="d1">Tools</data>
  <data key="d2">An external model that evaluates generated content to guide reinforcement learning updates in RLHF.&lt;SEP&gt;An external reward model assigns scores to content based on rankings, capturing evaluator preferences, and is used to guide reinforcement learning processes.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Policy">
  <data key="d0">Model Policy</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Model policy refers to the strategy or set of rules that guide the behavior of the model, which is updated using reinforcement learning techniques to maximize expected reward.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Reinforcement Learning Techniques">
  <data key="d0">Reinforcement Learning Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques such as reinforcement learning are employed to update the model policy, aiming to align model outputs with human preferences.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Content Generation">
  <data key="d0">Content Generation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Content generation is the process of producing text outputs by the language model, which is evaluated and refined through ranking and reward modeling.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ranking">
  <data key="d0">Ranking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Ranking involves ordering generated content based on certain criteria, often guided by the reward model, to determine quality or relevance.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Reward Modeling">
  <data key="d0">Reward Modeling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Reward modeling is the process of creating a function that assigns scores to content, reflecting evaluator preferences, used to optimize model behavior.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Complex Reasoning Tasks">
  <data key="d0">Complex Reasoning Tasks</data>
  <data key="d1">Results</data>
  <data key="d2">Applying reinforcement learning with human feedback (RLHF) successfully improves LLM performance on complex reasoning tasks.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Explicit Instructions">
  <data key="d0">Explicit Instructions</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Explicit instruction-based knowledge update relies on providing specific directives to guide model learning, effective for simpler tasks but limited in adaptability.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="High-Confidence Rationale-Augmented Answers">
  <data key="d0">High-Confidence Rationale-Augmented Answers</data>
  <data key="d1">Methods/Techniques</data>
  <data key="d2">A recent approach uses pre-trained LLMs to generate high-confidence, rationale-augmented answers for unlabeled questions, enhancing reasoning capabilities without ground truth labels.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Continual Learning via Rehearsal">
  <data key="d0">Continual Learning via Rehearsal</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to expand LLM knowledge and abilities without forgetting previous skills by fine-tuning across tasks and rehearsing previous data.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Partial Knowledge Update">
  <data key="d0">Partial Knowledge Update</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Partial knowledge update involves editing or updating only specific parts of an LLM's parameters to incorporate new information or correct outdated knowledge.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter-Efficient Knowledge Update">
  <data key="d0">Parameter-Efficient Knowledge Update</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods that modify only a small subset of model parameters to update knowledge efficiently, avoiding full retraining.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Editing">
  <data key="d0">Knowledge Editing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Knowledge editing aims to locate and modify specific parameters within an LLM to update facts or add domain-specific knowledge, often using hyper-networks or internal mechanisms.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Gradient Masking">
  <data key="d0">Gradient Masking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Gradient Masking is a technique used during model training to selectively prevent certain parameters from updating, focusing training on specific parts of the model to improve efficiency and performance.&lt;SEP&gt;Gradient Masking is a technique used during model training to selectively prevent certain parameters from updating, thereby focusing training on specific parts of the model.&lt;SEP&gt;Gradient masking involves selectively zeroing out gradients during back-propagation to update only relevant parts of the model, reducing computational load and mitigating catastrophic forgetting.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc&lt;SEP&gt;chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Content-Based Reinforcement Learning">
  <data key="d0">Content-Based Reinforcement Learning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A method that incorporates content evaluation and ranking to guide reinforcement learning processes, aiming to improve model outputs based on evaluator preferences.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Evaluator Preferences">
  <data key="d0">Evaluator Preferences</data>
  <data key="d1">Variables</data>
  <data key="d2">Preferences expressed by human evaluators that influence the reward model and content ranking, reflecting human judgments.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Content Ranking">
  <data key="d0">Content Ranking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of ordering generated content based on scores from the reward model, used to select higher-quality outputs.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Expansion">
  <data key="d0">Knowledge Expansion</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of increasing a model's knowledge base, either through explicit instruction, parameter editing, or other methods, without losing prior knowledge.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pre-trained LLMs">
  <data key="d0">Pre-trained LLMs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Large language models trained on vast corpora, serving as the base for knowledge updates and reasoning improvements.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="High-confidence Reasoning">
  <data key="d0">High-confidence Reasoning</data>
  <data key="d1">Results</data>
  <data key="d2">Generating high-confidence, rationale-augmented answers enhances the model's reasoning capabilities, especially in unlabeled or complex tasks.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Continual Learning">
  <data key="d0">Continual Learning</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A learning paradigm where models are trained across multiple tasks sequentially, aiming to retain previous knowledge while acquiring new skills.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rehearsal Techniques">
  <data key="d0">Rehearsal Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods like rehearsal or replay that help mitigate catastrophic forgetting by revisiting previous data during training.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Editing Methods">
  <data key="d0">Knowledge Editing Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for directly updating specific facts or knowledge within an LLM's parameters, such as hyper-networks or retrieval-based approaches.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hyper-Network">
  <data key="d0">Hyper-Network</data>
  <data key="d1">Tools</data>
  <data key="d2">A network trained to efficiently update specific parameters or facts in an LLM, avoiding full retraining.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Retrieval-Based Methods">
  <data key="d0">Retrieval-Based Methods</data>
  <data key="d1">Tools</data>
  <data key="d2">Approaches that store edits or knowledge explicitly and retrieve relevant information to reason or update model predictions.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Internal Mechanisms of LLMs">
  <data key="d0">Internal Mechanisms of LLMs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Understanding how LLMs internally represent and process knowledge, crucial for targeted editing and updates.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neuron Activation Analysis">
  <data key="d0">Neuron Activation Analysis</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Methods to identify crucial neurons responsible for specific predictions, aiding knowledge editing.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Causal Interventions">
  <data key="d0">Causal Interventions</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Methods to manipulate internal model components to study their effect on predictions, facilitating knowledge editing.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Textual Queries to Fact Encodings">
  <data key="d0">Textual Queries to Fact Encodings</data>
  <data key="d1">Tools</data>
  <data key="d2">Approach to map textual inputs to internal fact representations in LLMs, enabling knowledge editing and probing.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter Masking">
  <data key="d0">Parameter Masking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to selectively update or freeze parts of the model's parameters during fine-tuning, reducing resource use and preserving prior knowledge.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Efficiency in Fine-tuning">
  <data key="d0">Efficiency in Fine-tuning</data>
  <data key="d1">Variables</data>
  <data key="d2">Strategies like parameter masking or editing that make knowledge updates computationally feasible and resource-efficient.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Update Process">
  <data key="d0">Model Update Process</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The Model Update Process involves selectively updating parts of a large language model (LLM) by masking gradients for certain parameters, based on criteria like relevance, importance, or contribution to loss, to improve training efficiency and effectiveness.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fine-tuning of LLMs">
  <data key="d0">Fine-tuning of LLMs</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Fine-tuning of Large Language Models involves adjusting model parameters on domain-specific data to improve performance on particular tasks, often requiring significant computational resources.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-specific Knowledge">
  <data key="d0">Domain-specific Knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Domain-specific Knowledge refers to specialized information within a particular field such as biomedicine, finance, or law, which can be distilled from large models to improve task performance.&lt;SEP&gt;Domain-specific Knowledge refers to specialized information within particular fields such as biomedicine, finance, law, etc., which can be distilled from large models to enhance task-specific performance.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Application of LLMs in Social Sciences">
  <data key="d0">Application of LLMs in Social Sciences</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">In social sciences, LLMs are used for tasks like information extraction, text generation, predictions, conversational agents, and code analysis, tailored to domains like education, finance, and law.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Application of LLMs in Natural Sciences">
  <data key="d0">Application of LLMs in Natural Sciences</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">In natural sciences, LLMs assist in biomedical research, drug discovery, protein structure prediction, and understanding cellular processes, leveraging vast domain-specific data.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Application of LLMs in Formal Sciences">
  <data key="d0">Application of LLMs in Formal Sciences</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">In formal sciences, LLMs are used for automated code generation, analysis, bug detection, and software engineering tasks, improving efficiency and accuracy in technical domains.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Regulatory Compliance">
  <data key="d0">Regulatory Compliance</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Ensuring LLMs meet data protection laws and industry standards through fine-tuning and alignment processes is a key challenge, especially in rapidly evolving domains.&lt;SEP&gt;Ensuring LLMs meet data protection laws, industry standards, and guidelines during fine-tuning is a key challenge, involving model alignment and regulation adherence.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Applications in Social Sciences">
  <data key="d0">Applications in Social Sciences</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">LLMs are applied to social sciences for tasks like advanced information extraction, text generation, prediction, recommendations, and conversational agents tailored to domains like education, finance, and law.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Applications in Natural Sciences">
  <data key="d0">Applications in Natural Sciences</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">In natural sciences, LLMs support biomedical research, drug discovery, protein structure prediction, and cellular process understanding by analyzing vast domain-specific data.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Applications in Formal Sciences">
  <data key="d0">Applications in Formal Sciences</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">In formal sciences, LLMs are used for automated code generation, code analysis, bug detection, and software engineering tasks, improving efficiency and accuracy.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-specific Tasks">
  <data key="d0">Domain-specific Tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Domain-specific Tasks include entity recognition, relationship detection, event extraction, summarization, prediction, and code analysis within specific fields.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Efficiency">
  <data key="d0">Model Efficiency</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Model Efficiency encompasses techniques like gradient masking and knowledge distillation aimed at reducing computational costs and improving training and inference performance.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Low-resource Scenarios">
  <data key="d0">Low-resource Scenarios</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Low-resource scenarios refer to settings with limited data or computational power, where methods like dynamic parameter selection are employed to optimize model performance.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Useful in the field of biology">
  <data key="d0">Useful in the field of biology</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This refers to the application of large language models (LLMs) across various aspects of biological research and healthcare support, including analyzing biological functions, disease mechanisms, and medical record processing.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fundamental biomedical research">
  <data key="d0">Fundamental biomedical research</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Basic scientific investigations aiming to understand biological processes at a fundamental level, utilizing data such as genomic and proteomic information.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Clinical healthcare support">
  <data key="d0">Clinical healthcare support</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Application of LLMs in analyzing medical records, diagnosing, providing personalized treatments, and assisting in medical image analysis to improve healthcare outcomes.&lt;SEP&gt;Utilizes LLMs to assist in medical record analysis, diagnosis, personalized treatment, and medical image analysis, thereby improving healthcare outcomes.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Genomic data">
  <data key="d0">Genomic data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Genomic data refers to DNA sequence information used by LLMs to analyze biological functions and disease pathways.&lt;SEP&gt;Genomic data refers to the complete set of DNA sequences in an organism, used by LLMs to analyze biological functions and disease mechanisms.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Proteomic data">
  <data key="d0">Proteomic data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Proteomic data encompasses the full set of proteins expressed in a cell or organism, utilized by LLMs for understanding cellular processes.&lt;SEP&gt;Proteomic data encompasses the full set of proteins expressed in cells, analyzed by LLMs for understanding cellular processes and interactions.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Protein structures and interactions">
  <data key="d0">Protein structures and interactions</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Critical biological aspects that LLMs can predict to aid in understanding diseases and drug discovery.&lt;SEP&gt;Critical biological entities that LLMs can predict to aid in understanding diseases and drug design.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Medical records">
  <data key="d0">Medical records</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Clinical data containing patient health information, analyzed by LLMs for pattern recognition, diagnosis, and personalized treatment.&lt;SEP&gt;Clinical data used to identify patterns, support diagnoses, and recommend personalized treatments via LLMs.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Medical image analysis">
  <data key="d0">Medical image analysis</data>
  <data key="d1">Tools</data>
  <data key="d2">Application of LLMs in interpreting medical images like X-rays and MRI scans, often via multi-modality learning.&lt;SEP&gt;Application of LLMs in interpreting medical images such as X-rays and MRI scans, often through multi-modality learning techniques.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Earth science">
  <data key="d0">Earth science</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An interdisciplinary domain studying physical and human systems interactions across spatial and temporal scales, involving climate change, land-use, natural disasters, and urbanization.&lt;SEP&gt;An interdisciplinary field examining interactions between physical and human systems across diverse spatial and temporal scales, including climate change, land-use, natural disasters, and urbanization.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Earth observation">
  <data key="d0">Earth observation</data>
  <data key="d1">Tools</data>
  <data key="d2">Remote sensing and satellite data collection methods used to monitor environmental phenomena.&lt;SEP&gt;Remote sensing technologies and satellite data collection methods used to monitor environmental phenomena and support earth science research.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Spatial analysis">
  <data key="d0">Spatial analysis</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Methods involving GIS and spatial data analysis to investigate environmental and geographic phenomena.&lt;SEP&gt;Methods involving geographic information systems (GIS) and spatial data to investigate environmental and geographic phenomena.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Complexity theory">
  <data key="d0">Complexity theory</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A framework for understanding complex systems and their interactions within earth science, used in modeling climate, ecosystems, and urban systems.&lt;SEP&gt;Framework for understanding complex systems and interactions within Earth science, often used in simulation modeling.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Simulation modeling">
  <data key="d0">Simulation modeling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Computational approaches to simulate environmental processes and scenarios, aiding in understanding climate change and urbanization.&lt;SEP&gt;Computational approaches to simulate environmental processes, climate scenarios, and urban development.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Geographic information science tools">
  <data key="d0">Geographic information science tools</data>
  <data key="d1">Tools</data>
  <data key="d2">Software and methodologies for analyzing geographic and spatial data, essential for interdisciplinary earth science studies.&lt;SEP&gt;Software and methodologies for analyzing spatial data, essential for interdisciplinary Earth science studies.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Large language models like ChatGPT">
  <data key="d0">Large language models like ChatGPT</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">AI models capable of answering questions, providing code examples, and assisting in Earth Science research by processing large datasets and generating insights.&lt;SEP&gt;AI models capable of processing large datasets, answering questions, generating code, and assisting in earth science research and knowledge dissemination.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Earth Science-related downstream tasks">
  <data key="d0">Earth Science-related downstream tasks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Fine-tuning, few-shot, or zero-shot learning approaches to adapt LLMs for specific earth science applications such as data processing, climate modeling, and environmental analysis.&lt;SEP&gt;Specific applications of LLMs such as fine-tuning, few-shot, or zero-shot learning to enhance research and data analysis.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Finance and Law">
  <data key="d0">Finance and Law</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Domains requiring specialized language understanding for accurate content generation, risk assessment, and legal interpretation, with emphasis on ethical considerations.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Financial domain">
  <data key="d0">Financial domain</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The financial domain involves markets, economic trends, and regulatory norms, which LLMs must comprehend for report generation and analysis.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Legal domain">
  <data key="d0">Legal domain</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Legal language, laws, court rulings, and legal codes that require precise understanding and generation by LLMs.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model specialization">
  <data key="d0">Model specialization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Fine-tuning with domain-specific datasets, incorporating explicit domain knowledge, and optimizing for compliance and accuracy in finance and law.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ethical guardrails">
  <data key="d0">Ethical guardrails</data>
  <data key="d1">Limitations</data>
  <data key="d2">Mechanisms to ensure AI models adhere to ethical standards, especially critical in high-stakes financial and legal decision-making.&lt;SEP&gt;Mechanisms to ensure AI models operate within ethical standards, especially critical in high-stakes domains like finance and law.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Human-Computer Interaction (HCI)">
  <data key="d0">Human-Computer Interaction (HCI)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Field dedicated to designing user interfaces and interactions that improve usability, responsiveness, and effectiveness of AI systems.&lt;SEP&gt;Field focused on designing effective interfaces and interactions between humans and computers, improving usability and responsiveness of AI systems.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Software engineering">
  <data key="d0">Software engineering</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Discipline focused on developing, maintaining, and improving software systems, with LLMs aiding code generation, bug detection, and documentation.&lt;SEP&gt;Discipline involving the development, maintenance, and improvement of software systems, with LLMs aiding in code generation, bug detection, and documentation.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Code generation, bug detection, code review, documentation">
  <data key="d0">Code generation, bug detection, code review, documentation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Tasks in software engineering that LLMs can assist with by leveraging large codebases and issue trackers.&lt;SEP&gt;Tasks in software engineering where LLMs assist by analyzing large codebases, automating coding tasks, and improving software quality.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Open challenges in domain specialization">
  <data key="d0">Open challenges in domain specialization</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Questions about how to model complex domain knowledge, balance general and specialized knowledge, and effectively adapt LLMs to diverse fields.&lt;SEP&gt;Questions regarding how to effectively model complex domain knowledge, balance general and specific knowledge, and address domain intricacies in LLMs.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain complexity">
  <data key="d0">Domain complexity</data>
  <data key="d1">Limitations</data>
  <data key="d2">The challenge of capturing highly specialized vocabularies, terminologies, and knowledge structures across various domains.&lt;SEP&gt;The challenge of modeling highly specialized vocabularies, terminologies, and knowledge structures within various fields.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Balancing general and domain knowledge">
  <data key="d0">Balancing general and domain knowledge</data>
  <data key="d1">Limitations</data>
  <data key="d2">Ensuring LLMs maintain broad contextual understanding while being sufficiently specialized for specific domains.&lt;SEP&gt;Ensuring LLMs maintain broad contextual understanding while being sufficiently specialized for specific fields.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Biomedical research">
  <data key="d0">Biomedical research</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Fundamental scientific investigations in biology that utilize domain-specific data such as genomic and proteomic datasets to understand biological functions and disease mechanisms.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Law">
  <data key="d0">Law</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A discipline involving the interpretation and application of legal language, laws, court rulings, and legal codes, requiring precise understanding and generation by LLMs.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Balancing General and Domain Knowledge">
  <data key="d0">Balancing General and Domain Knowledge</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This concept involves maintaining a balance between general knowledge and domain-specific knowledge within large language models (LLMs) to ensure contextually appropriate responses without over-specialization or dilution of expertise.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Explainability and Trust">
  <data key="d0">Explainability and Trust</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This concept addresses the importance of making LLM decision-making processes transparent and understandable to users, especially in high-stakes domains, to build trust and ensure responsible AI usage.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapting to Domain Evolution">
  <data key="d0">Adapting to Domain Evolution</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This concept pertains to the necessity for LLMs to continuously update and adapt to evolving terminologies, concepts, and trends within a domain to stay relevant and effective over time.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scalability">
  <data key="d0">Scalability</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This concept highlights the challenges associated with scaling domain-specific training or fine-tuning of LLMs across many or complex domains, considering resource availability and data requirements.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hybrid Approaches">
  <data key="d0">Hybrid Approaches</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Combining multiple domain specialization techniques (black-box, grey-box, white-box) to optimize performance and resource use depending on specific needs and stages.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Meta-Learning or AutoML Techniques">
  <data key="d0">Meta-Learning or AutoML Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Automated strategies that learn to select optimal domain adaptation methods, data, prompts, or model layers based on previous experience, reducing resource needs and improving effectiveness.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Incorporating More Explicit World Knowledge">
  <data key="d0">Incorporating More Explicit World Knowledge</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Utilizing structured knowledge sources like knowledge graphs and ontologies to enhance the understanding and reasoning capabilities of LLMs in specific domains.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Human-in-the-loop Learning">
  <data key="d0">Human-in-the-loop Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Continuous interaction with human experts to guide, correct, and update the model, ensuring it evolves with domain expertise and user needs.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Active Learning">
  <data key="d0">Active Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique where models actively query users or sources for information on uncertain or unfamiliar concepts to improve understanding.&lt;SEP&gt;Model actively queries for clarification or additional information when encountering unfamiliar or low-confidence domain-specific concepts, improving understanding and responses.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Future Techniques in Domain Specialization">
  <data key="d0">Future Techniques in Domain Specialization</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Innovative approaches such as hybrid methods, meta-learning, structured knowledge integration, human-in-the-loop, and active learning designed to push the boundaries of current domain adaptation strategies for LLMs.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Explainability">
  <data key="d0">Model Explainability</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The degree to which a model's internal mechanisms and decision processes are understandable by humans, crucial for trust and transparency.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Complexity">
  <data key="d0">Model Complexity</data>
  <data key="d1">Variables</data>
  <data key="d2">The intricacy of LLM architectures that impacts their interpretability, training, and deployment in specialized domains.&lt;SEP&gt;The level of intricacy in a model's structure, which impacts both its performance and interpretability.&lt;SEP&gt;The structural intricacy and size of LLM architectures, which influence their interpretability, training difficulty, and suitability for domain-specific tasks.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Transparency">
  <data key="d0">Model Transparency</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The extent to which the workings of a model are open and interpretable, facilitating understanding and trust.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ontology">
  <data key="d0">Ontology</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A formal representation of domain-specific concepts and their relationships, providing a structured framework for knowledge integration.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Structured Knowledge Sources">
  <data key="d0">Structured Knowledge Sources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Databases or frameworks like ontologies and knowledge graphs that organize information in a structured manner for enhanced reasoning.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Human-in-the-loop">
  <data key="d0">Human-in-the-loop</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An approach involving human feedback and interaction during the training or updating process of models to improve accuracy and relevance.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Black-box Methods">
  <data key="d0">Black-box Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Model training or adaptation approaches where internal workings are not transparent or interpretable, often relying on external resources.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Grey-box Methods">
  <data key="d0">Grey-box Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Hybrid approaches that combine elements of black-box and white-box techniques, balancing performance and interpretability.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="White-box Methods">
  <data key="d0">White-box Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Model training or adaptation approaches that emphasize transparency and interpretability of internal mechanisms.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Meta-Learning">
  <data key="d0">Meta-Learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A technique where models learn to optimize their own learning process, enabling automatic selection of the best strategies for domain adaptation.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="AutoML">
  <data key="d0">AutoML</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Automated machine learning techniques that automate the process of model selection, hyperparameter tuning, and feature engineering to improve efficiency.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scaling">
  <data key="d0">Scaling</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ability to extend domain-specific model training or fine-tuning across multiple or complex domains while managing resources and data availability.&lt;SEP&gt;The process of increasing the capacity or scope of machine learning models to handle extensive datasets, enabling emergence of biological structure and function understanding.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Domain Evolution">
  <data key="d0">Domain Evolution</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ongoing change and development of terminology, concepts, and trends within a domain, requiring models to adapt to stay relevant.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Adaptation">
  <data key="d0">Model Adaptation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques and processes used to update models in response to evolving domain knowledge, trends, and data.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Medical Ontology">
  <data key="d0">Medical Ontology</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A structured framework that represents medical knowledge, including concepts, categories, and relationships, to facilitate understanding, data sharing, and reasoning in healthcare.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-Specific Techniques">
  <data key="d0">Domain-Specific Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods tailored to adapt large language models (LLMs) for specialized fields, addressing challenges like limited domain expertise and knowledge elicitation.&lt;SEP&gt;Specialized methods designed to adapt and optimize LLMs for particular fields, addressing challenges such as limited domain knowledge and model interpretability.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Future Research">
  <data key="d0">Future Research</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Explores how domain-specific techniques can enhance LLM performance, address current limitations, and foster interdisciplinary collaboration.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Challenges and Limitations">
  <data key="d0">Challenges and Limitations</data>
  <data key="d1">Limitations</data>
  <data key="d2">Current obstacles in applying LLMs to domain-specific tasks, including knowledge gaps, model complexity, and black-box nature.&lt;SEP&gt;Current obstacles in applying LLMs to domain-specific tasks, including knowledge gaps, model opacity, and resource constraints.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Elicitation">
  <data key="d0">Knowledge Elicitation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques to extract, incorporate, and refine domain knowledge within LLMs to improve accuracy, relevance, and effectiveness in specific fields.&lt;SEP&gt;Techniques used to extract, incorporate, and optimize domain knowledge within language models to improve accuracy and relevance.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Interdisciplinary Collaboration">
  <data key="d0">Interdisciplinary Collaboration</data>
  <data key="d1">Discipline</data>
  <data key="d2">Cross-field cooperation among researchers and practitioners to develop, evaluate, and implement effective domain-specific LLM solutions.&lt;SEP&gt;Cross-field cooperation to advance research, share insights, and develop more effective domain-specific AI solutions.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Gaps">
  <data key="d0">Knowledge Gaps</data>
  <data key="d1">Limitations</data>
  <data key="d2">Insufficient or incomplete domain knowledge that hampers the effective adaptation of LLMs to specific fields.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Black-Box Methods">
  <data key="d0">Black-Box Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approaches that treat LLMs as opaque systems, focusing on input-output behavior without interpretability, often limiting understanding of internal processes.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Grey-Box Methods">
  <data key="d0">Grey-Box Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Hybrid approaches that combine interpretability and performance, offering some insight into model internals while maintaining effectiveness.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="White-Box Methods">
  <data key="d0">White-Box Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Fully interpretable approaches that allow understanding and modification of internal model workings, facilitating transparency and trust.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multi-Head Adapter Routing for Data-Efficient Fine-Tuning">
  <data key="d0">Multi-Head Adapter Routing for Data-Efficient Fine-Tuning</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">This study proposes a method called Multi-Head Adapter Routing aimed at improving data-efficient fine-tuning of models, exploring how adapter routing strategies impact model performance and resource utilization.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2211.03831">
  <data key="d0">arXiv preprint arXiv:2211.03831</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">This is a preprint document presenting research findings on adapter routing techniques in machine learning.&lt;SEP&gt;This preprint presents a research study on adapter routing methods to improve model fine-tuning efficiency.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yihan Cao">
  <data key="d0">Yihan Cao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yihan Cao is an author of a comprehensive survey on AI-generated content, exploring the history and development of generative AI.&lt;SEP&gt;Yihan Cao is one of the authors conducting research on generative AI and related topics.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Siyu Li">
  <data key="d0">Siyu Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Siyu Li contributed to the survey, analyzing various generative AI models from GANs to ChatGPT.&lt;SEP&gt;Siyu Li is an author involved in the comprehensive survey of AI-generated content.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yixin Liu">
  <data key="d0">Yixin Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yixin Liu contributed to the survey of generative AI technologies.&lt;SEP&gt;Yixin Liu helped compile the history and evolution of generative AI technologies in the survey.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhiling Yan">
  <data key="d0">Zhiling Yan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zhiling Yan participated in summarizing the development of AI-generated content in the survey.&lt;SEP&gt;Zhiling Yan participated in the survey of AI-generated content and its history.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yutong Dai">
  <data key="d0">Yutong Dai</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yutong Dai contributed insights on the development and trends in generative AI models.&lt;SEP&gt;Yutong Dai contributed to the survey of generative AI and its development.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Philip S Yu">
  <data key="d0">Philip S Yu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Philip S Yu discussed applications and implications of AI-generated content in the survey.&lt;SEP&gt;Philip S Yu is involved in research on AI-generated content and its applications.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lichao Sun">
  <data key="d0">Lichao Sun</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lichao Sun contributed to the comprehensive survey of AI-generated content.&lt;SEP&gt;Lichao Sun reviewed the history and future promises of generative AI in the survey.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="A comprehensive survey of ai-generated content (aigc)">
  <data key="d0">A comprehensive survey of ai-generated content (aigc)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">This survey reviews the evolution of generative AI from GANs to ChatGPT, covering technological advances, methodologies, and applications.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Conference on Empirical Methods in Natural Language Processing">
  <data key="d0">Conference on Empirical Methods in Natural Language Processing</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A conference where NLP methodologies like RLPrompt are discussed.&lt;SEP&gt;A conference where NLP prompt optimization methods like RLPrompt are discussed.&lt;SEP&gt;An academic conference where research papers related to empirical methods in NLP are presented.&lt;SEP&gt;An academic conference where researchers present empirical NLP methods and findings, serving as a platform for disseminating new techniques.&lt;SEP&gt;This conference hosts research presentations on empirical NLP methods, including Clip-Tuning and prompt learning.&lt;SEP&gt;This is a conference where research on empirical NLP methods, including Clip-Tuning, is presented.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-00db2a825cc87520492b47392ed31c71&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LEGAL-BERT">
  <data key="d0">LEGAL-BERT</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">LEGAL-BERT is a Transformer-based language model specialized for legal language, designed to improve NLP tasks in the legal domain.&lt;SEP&gt;LEGAL-BERT is a domain-specific language model adapted for legal language understanding, used for legal NLP tasks.&lt;SEP&gt;LEGAL-BERT is based on BERT architecture, fine-tuned on legal texts to improve domain-specific performance.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LEGAl-BERT">
  <data key="d0">LEGAl-BERT</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">LEGAL-BERT adapts BERT architecture specifically for legal language understanding, incorporating domain-specific training data.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Recall and learn">
  <data key="d0">Recall and learn</data>
  <data key="d1">Methodologies</data>
  <data key="d2">This approach involves fine-tuning language models with minimal forgetting, improving knowledge retention during training.&lt;SEP&gt;This study explores fine-tuning deep pretrained language models with less forgetting, aiming to improve retention of knowledge during training.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Program of Thoughts Prompting">
  <data key="d0">Program of Thoughts Prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">This prompting technique disentangles computation from reasoning, enhancing models' numerical reasoning abilities.&lt;SEP&gt;This technique disentangles computation from reasoning in models, enhancing numerical reasoning capabilities.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Binding Language Models in Symbolic Languages">
  <data key="d0">Binding Language Models in Symbolic Languages</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">This approach involves integrating language models with symbolic languages to enhance reasoning and interpretability.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Deep reinforcement learning from human preferences">
  <data key="d0">Deep reinforcement learning from human preferences</data>
  <data key="d1">Study Designs</data>
  <data key="d2">This study explores reinforcement learning techniques guided by human preferences to improve model alignment and behavior.&lt;SEP&gt;This study investigates reinforcement learning techniques that incorporate human feedback to guide model training.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="AdapterSoup">
  <data key="d0">AdapterSoup</data>
  <data key="d1">Tools</data>
  <data key="d2">AdapterSoup is a technique for weight averaging across models to improve generalization and robustness of pretrained language models.&lt;SEP&gt;AdapterSoup is a technique for weight averaging in pretrained language models to improve their generalization capabilities.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scaling instruction-finetuned language models">
  <data key="d0">Scaling instruction-finetuned language models</data>
  <data key="d1">Study Designs</data>
  <data key="d2">This research examines methods to enhance instruction tuning of language models to improve task performance.&lt;SEP&gt;This research investigates scaling instruction tuning techniques to enhance model versatility and performance across tasks.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="A Survey on Knowledge Graphs for Healthcare">
  <data key="d0">A Survey on Knowledge Graphs for Healthcare</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">This survey reviews datasets, resources, and applications of knowledge graphs specifically within healthcare contexts.&lt;SEP&gt;This survey reviews resources, applications, and promises of knowledge graphs specifically within the healthcare domain.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge neurons in pretrained transformers">
  <data key="d0">Knowledge neurons in pretrained transformers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">This research identifies and analyzes neurons in transformers that encode factual knowledge, contributing to interpretability.&lt;SEP&gt;This research identifies specific neurons in transformers that encode factual knowledge, aiding interpretability and understanding of models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Promptagator">
  <data key="d0">Promptagator</data>
  <data key="d1">Tools</data>
  <data key="d2">Promptagator is a dense retrieval system that uses few-shot examples to improve information retrieval performance.&lt;SEP&gt;Promptagator is a dense retrieval system that uses few-shot examples to improve retrieval accuracy for information access.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Collaborating with language models for embodied reasoning">
  <data key="d0">Collaborating with language models for embodied reasoning</data>
  <data key="d1">Study Title</data>
  <data key="d2">A research paper exploring methods for effective collaboration with language models to enhance embodied reasoning capabilities.&lt;SEP&gt;A research publication presenting methods for collaborating with language models to enhance embodied reasoning capabilities.&lt;SEP&gt;This explores how language models can be used to support embodied reasoning tasks, impacting AI interaction, robotics, and cognition.&lt;SEP&gt;This work explores how language models can be used to support embodied reasoning tasks, impacting AI interaction and cognition.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Editing Factual Knowledge in Language Models">
  <data key="d0">Editing Factual Knowledge in Language Models</data>
  <data key="d1">Study Title</data>
  <data key="d2">A research paper discussing methods for modifying and improving factual knowledge stored in language models.&lt;SEP&gt;Research on techniques for modifying and updating factual information stored within language models.&lt;SEP&gt;This study investigates methods for editing and updating factual knowledge within large language models to reduce hallucinations and improve accuracy.&lt;SEP&gt;This study investigates techniques for editing and updating factual knowledge within large language models to improve accuracy and reduce hallucinations.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lucas Caccia">
  <data key="d0">Lucas Caccia</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Lucas Caccia is an author of a study on multi-head adapter routing, contributing to research on data-efficient model fine-tuning.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Edoardo Ponti">
  <data key="d0">Edoardo Ponti</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Edoardo Ponti is an author involved in research on adapter routing strategies for efficient fine-tuning of neural networks.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lucas Liu">
  <data key="d0">Lucas Liu</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Lucas Liu contributed to the study on adapter routing, focusing on improving data-efficient training methods.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Matheus Pereira">
  <data key="d0">Matheus Pereira</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Matheus Pereira is involved in research related to adapter techniques in machine learning models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Nicolas Le Roux">
  <data key="d0">Nicolas Le Roux</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Nicolas Le Roux is a researcher contributing to the development of efficient model fine-tuning strategies.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alessandro Sordoni">
  <data key="d0">Alessandro Sordoni</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Alessandro Sordoni co-authored the paper on multi-head adapter routing for data-efficient fine-tuning.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2303.04226">
  <data key="d0">arXiv preprint arXiv:2303.04226</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">This preprint documents a survey of generative AI models, their history, and applications.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yekun Chai">
  <data key="d0">Yekun Chai</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Yekun Chai is an author of a study on clip-tuning, focusing on prompt learning without derivatives using rewards.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shuohuan Wang">
  <data key="d0">Shuohuan Wang</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Shuohuan Wang contributed to research on derivative-free prompt learning methods like Clip-Tuning.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yu Sun">
  <data key="d0">Yu Sun</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Yu Sun collaborated on research regarding prompt learning strategies and reward-based methods.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hao Tian">
  <data key="d0">Hao Tian</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Hao Tian participated in studies on prompt learning and derivative-free optimization techniques.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hua Wu">
  <data key="d0">Hua Wu</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Hua Wu contributed to research on prompt learning methodologies for language models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Haifeng Wang">
  <data key="d0">Haifeng Wang</data>
  <data key="d1">&lt;|Researcher</data>
  <data key="d2">Haifeng Wang is involved in research on prompt learning and model optimization techniques.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Gupta, Christine Kaeser-Chen, Kenneth Marino, Arun Ahuja, Sheila Babayan, Felix Hill, and Rob Fergus">
  <data key="d0">Gupta, Christine Kaeser-Chen, Kenneth Marino, Arun Ahuja, Sheila Babayan, Felix Hill, and Rob Fergus</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">A group of researchers involved in publications related to language models, embodied reasoning, and NLP methodologies.&lt;SEP&gt;A list of authors involved in research publications related to language models and embodied reasoning.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Second Workshop on Language and Reinforcement Learning">
  <data key="d0">Second Workshop on Language and Reinforcement Learning</data>
  <data key="d1">Study Design/Conference</data>
  <data key="d2">A conference where research on language and reinforcement learning is presented.&lt;SEP&gt;An academic workshop focused on language and reinforcement learning research, where related studies are presented.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Nicola De Cao, Wilker Aziz, and Ivan Titov">
  <data key="d0">Nicola De Cao, Wilker Aziz, and Ivan Titov</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study focused on editing factual knowledge in language models.&lt;SEP&gt;Authors of a study on editing factual knowledge in language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="2021 Conference on Empirical Methods in Natural Language Processing">
  <data key="d0">2021 Conference on Empirical Methods in Natural Language Processing</data>
  <data key="d1">Study Design/Conference</data>
  <data key="d2">A major NLP conference where research on knowledge editing and related topics is presented.&lt;SEP&gt;A prominent conference where NLP research, including knowledge editing, is presented.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric P. Xing, and Zhiting Hu">
  <data key="d0">Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric P. Xing, and Zhiting Hu</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study proposing RLPrompt, a reinforcement learning-based approach for optimizing discrete text prompts.&lt;SEP&gt;Authors of a study proposing RLPrompt, an approach for optimizing text prompts using reinforcement learning.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="RLPrompt">
  <data key="d0">RLPrompt</data>
  <data key="d1">Methodology/Technique</data>
  <data key="d2">A method that employs reinforcement learning to optimize discrete text prompts for language models.&lt;SEP&gt;A technique employing reinforcement learning to optimize text prompts for language models, improving task performance.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova">
  <data key="d0">Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of BERT, a pre-trained deep bidirectional transformer model for language understanding.&lt;SEP&gt;Authors of the BERT model, a foundational deep bidirectional transformer for language understanding.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="BERT">
  <data key="d0">BERT</data>
  <data key="d1">Tools</data>
  <data key="d2">A foundational transformer-based language model pre-trained for various NLP tasks.&lt;SEP&gt;A pre-trained deep bidirectional transformer model designed for natural language understanding tasks.&lt;SEP&gt;A pre-trained deep bidirectional transformer model that significantly advances natural language understanding tasks.&lt;SEP&gt;A pre-trained language model that uses deep bidirectional transformers to understand context in text, widely used in NLP tasks.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71&lt;SEP&gt;chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="arXiv preprint arXiv:1810.04805">
  <data key="d0">arXiv preprint arXiv:1810.04805</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">A preprint publication detailing the architecture and training of BERT.&lt;SEP&gt;A preprint publication providing technical details about BERT.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al.">
  <data key="d0">Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al.</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a comprehensive study on delta tuning, a parameter-efficient method for pre-trained language models.&lt;SEP&gt;Authors of a study on delta tuning, a parameter-efficient method for fine-tuning pre-trained language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Delta Tuning">
  <data key="d0">Delta Tuning</data>
  <data key="d1">Methodology/Technique</data>
  <data key="d2">A study exploring parameter-efficient fine-tuning methods for language models, aiming to improve efficiency and performance.&lt;SEP&gt;A technique for efficiently adapting large language models to new tasks or domains by tuning a small set of parameters.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, and Denny Zhou">
  <data key="d0">Andrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, and Denny Zhou</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study on compositional semantic parsing using large language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Compositional Semantic Parsing with Large Language Models">
  <data key="d0">Compositional Semantic Parsing with Large Language Models</data>
  <data key="d1">Study Title</data>
  <data key="d2">A research paper discussing methods for semantic parsing by leveraging large language models.&lt;SEP&gt;Research on parsing complex language inputs into structured meaning representations using large models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="The Eleventh International Conference on Learning Representations">
  <data key="d0">The Eleventh International Conference on Learning Representations</data>
  <data key="d1">Study Design/Conference</data>
  <data key="d2">A conference where advanced NLP techniques like semantic parsing are presented.&lt;SEP&gt;A leading conference where advanced NLP techniques like semantic parsing are presented.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt Gardner">
  <data key="d0">Dheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt Gardner</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study on successive prompting for decomposing complex questions.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Successive Prompting for Decomposing Complex Questions">
  <data key="d0">Successive Prompting for Decomposing Complex Questions</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique for breaking down complex questions into simpler parts using iterative prompting.&lt;SEP&gt;An iterative prompting technique that breaks down complex questions into simpler sub-questions for better comprehension.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="2022 Conference on Empirical Methods in Natural Language Processing">
  <data key="d0">2022 Conference on Empirical Methods in Natural Language Processing</data>
  <data key="d1">Study Design/Conference</data>
  <data key="d2">A conference where NLP prompting techniques are discussed.&lt;SEP&gt;An NLP conference where prompting and question decomposition techniques are showcased.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ali Edalati, Marzieh Tahaei, Ivan Kobyzev, Vahid Partovi Nia, James J Clark, and Mehdi Rezagholizadeh">
  <data key="d0">Ali Edalati, Marzieh Tahaei, Ivan Kobyzev, Vahid Partovi Nia, James J Clark, and Mehdi Rezagholizadeh</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study on KronA, a parameter-efficient tuning method using Kronecker adapters.&lt;SEP&gt;Authors of a study on KronA, a parameter-efficient tuning method utilizing Kronecker adapters.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="KronA">
  <data key="d0">KronA</data>
  <data key="d1">Methodology/Technique</data>
  <data key="d2">A parameter-efficient fine-tuning approach that employs Kronecker product-based adapters to enhance model adaptability.&lt;SEP&gt;A parameter-efficient tuning approach employing Kronecker adapters for language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2212.10650">
  <data key="d0">arXiv preprint arXiv:2212.10650</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">A preprint describing the KronA tuning method.&lt;SEP&gt;A preprint documenting the KronA technique.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick Pérez, and Raoul de Charette">
  <data key="d0">Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick Pérez, and Raoul de Charette</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study on P ODA, a prompt-driven zero-shot domain adaptation method.&lt;SEP&gt;Authors of a study on P ODA, a prompt-driven zero-shot domain adaptation technique.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="P ODA">
  <data key="d0">P ODA</data>
  <data key="d1">Methodology/Technique</data>
  <data key="d2">A zero-shot domain adaptation approach driven by prompts to adapt language models to new domains.&lt;SEP&gt;A zero-shot domain adaptation method that uses prompts to adapt models to new domains without additional training.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2212.03241">
  <data key="d0">arXiv preprint arXiv:2212.03241</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">A preprint describing the P ODA method.&lt;SEP&gt;A preprint detailing the P ODA approach.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yang Feng, Shiyue Zhang, Andi Zhang, Dong Wang, and Andrew Abel">
  <data key="d0">Yang Feng, Shiyue Zhang, Andi Zhang, Dong Wang, and Andrew Abel</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study on memory-augmented neural machine translation.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Memory-augmented Neural Machine Translation">
  <data key="d0">Memory-augmented Neural Machine Translation</data>
  <data key="d1">Core Concept/Model</data>
  <data key="d2">A neural translation model enhanced with memory mechanisms to improve translation quality.&lt;SEP&gt;A neural translation system enhanced with memory modules to improve translation accuracy and context retention.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing">
  <data key="d0">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</data>
  <data key="d1">Study Design/Conference</data>
  <data key="d2">A conference where research on neural machine translation models is presented.&lt;SEP&gt;An NLP conference where models like memory-augmented translation are discussed.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig">
  <data key="d0">Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of PAL, Program-Aided Language Models, integrating programming into language models for enhanced NLP performance.&lt;SEP&gt;Authors of PAL, program-aided language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="PAL (Program-Aided Language Models)">
  <data key="d0">PAL (Program-Aided Language Models)</data>
  <data key="d1">Methodology/Tools</data>
  <data key="d2">A framework integrating programming and language models to enhance NLP tasks.&lt;SEP&gt;A framework that combines programming and language models to improve task performance and reasoning.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2211.10435">
  <data key="d0">arXiv preprint arXiv:2211.10435</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">A preprint describing the PAL framework.&lt;SEP&gt;A preprint detailing PAL methodology.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chunjiang Ge, Rui Huang, Mixue Xie, Zihang Lai, Shiji Song, Shuang Li, and Gao Huang">
  <data key="d0">Chunjiang Ge, Rui Huang, Mixue Xie, Zihang Lai, Shiji Song, Shuang Li, and Gao Huang</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study on domain adaptation via prompt learning.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Adaptation via Prompt Learning">
  <data key="d0">Domain Adaptation via Prompt Learning</data>
  <data key="d1">Methodology</data>
  <data key="d2">Techniques for adapting language models to specific domains using prompt-based approaches.&lt;SEP&gt;Techniques for adapting language models to specific domains using prompt-based methods.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2202.06687">
  <data key="d0">arXiv preprint arXiv:2202.06687</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">A preprint describing domain adaptation techniques.&lt;SEP&gt;A preprint on domain adaptation techniques using prompt learning.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Edouard Grave, Armand Joulin, and Nicolas Usunier">
  <data key="d0">Edouard Grave, Armand Joulin, and Nicolas Usunier</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of work on improving neural language models with a continuous cache.&lt;SEP&gt;Authors of work on neural language models with a continuous cache.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Improving Neural Language Models with a Continuous Cache">
  <data key="d0">Improving Neural Language Models with a Continuous Cache</data>
  <data key="d1">Methodology/Technique</data>
  <data key="d2">An approach that enhances language models by incorporating a continuous cache for better context retention.&lt;SEP&gt;An approach that enhances language models by incorporating a continuous cache to improve context retention and prediction.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="International Conference on Learning Representations">
  <data key="d0">International Conference on Learning Representations</data>
  <data key="d1">Study Design/Platform</data>
  <data key="d2">A conference where advances in neural language modeling are presented.&lt;SEP&gt;A venue where advancements in neural language modeling, including cache mechanisms, are presented.&lt;SEP&gt;A conference where research on learning representations and machine learning models is presented, serving as a platform for dissemination of research findings.&lt;SEP&gt;A conference where research on learning representations and models like code2seq are presented.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71&lt;SEP&gt;chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Yuxian Gu, Xu Han, Zhiyuan Liu, and Minlie Huang">
  <data key="d0">Yuxian Gu, Xu Han, Zhiyuan Liu, and Minlie Huang</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of PPT, Pre-trained Prompt Tuning for Few-shot Learning.&lt;SEP&gt;Authors of PPT, Pre-trained Prompt Tuning, aimed at few-shot learning scenarios.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="PPT (Pre-trained Prompt Tuning)">
  <data key="d0">PPT (Pre-trained Prompt Tuning)</data>
  <data key="d1">Methodology/Technique</data>
  <data key="d2">A prompt tuning approach designed for few-shot learning scenarios in NLP.&lt;SEP&gt;A prompt-based tuning method designed to improve few-shot learning performance by leveraging pre-trained models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics">
  <data key="d0">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</data>
  <data key="d1">Study Design/Conference</data>
  <data key="d2">A major NLP conference where PPT and related prompt tuning techniques are presented.&lt;SEP&gt;A major NLP conference where PPT and related techniques are presented.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xu Guo, Boyang Li, and Han Yu">
  <data key="d0">Xu Guo, Boyang Li, and Han Yu</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study on improving sample efficiency of prompt tuning through domain adaptation.&lt;SEP&gt;Authors of a study on improving sample efficiency of prompt tuning via domain adaptation.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sample Efficiency of Prompt Tuning with Domain Adaptation">
  <data key="d0">Sample Efficiency of Prompt Tuning with Domain Adaptation</data>
  <data key="d1">Study Title</data>
  <data key="d2">Research on enhancing prompt tuning performance across different domains by applying domain adaptation techniques.&lt;SEP&gt;Research on enhancing prompt tuning performance across domains through adaptation techniques.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May">
  <data key="d0">Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of WARP, Word-level Adversarial ReProgramming.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="WARP (Word-level Adversarial ReProgramming)">
  <data key="d0">WARP (Word-level Adversarial ReProgramming)</data>
  <data key="d1">Methodology/Technique</data>
  <data key="d2">A method for adversarial reprogramming at the word level to improve NLP model robustness.&lt;SEP&gt;An adversarial reprogramming method that manipulates word-level inputs to improve model robustness and flexibility.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Annual Meeting of the Association for Computational Linguistics">
  <data key="d0">Annual Meeting of the Association for Computational Linguistics</data>
  <data key="d1">Study Design/Conference</data>
  <data key="d2">A conference where adversarial reprogramming techniques like WARP are presented.&lt;SEP&gt;A leading conference where WARP and related adversarial techniques are discussed.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hangfeng He, Hongming Zhang, and Dan Roth">
  <data key="d0">Hangfeng He, Hongming Zhang, and Dan Roth</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study on Rethinking with Retrieval, a method to improve large language model inference faithfulness.&lt;SEP&gt;Authors of work on Rethinking with Retrieval for faithful large language model inference.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rethinking with Retrieval">
  <data key="d0">Rethinking with Retrieval</data>
  <data key="d1">Methodology/Technique</data>
  <data key="d2">A retrieval-augmented inference approach that enhances the faithfulness and accuracy of large language models.&lt;SEP&gt;An approach that incorporates retrieval mechanisms to improve the faithfulness of large language model inferences.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2301.00303">
  <data key="d0">arXiv preprint arXiv:2301.00303</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">A preprint describing retrieval-based inference methods for large models.&lt;SEP&gt;A preprint detailing retrieval-based inference methods.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig">
  <data key="d0">Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study on a unified perspective of parameter-efficient transfer learning.&lt;SEP&gt;Authors of a study on unified views of parameter-efficient transfer learning.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Unified View of Parameter-efficient Transfer Learning">
  <data key="d0">Unified View of Parameter-efficient Transfer Learning</data>
  <data key="d1">Study Title</data>
  <data key="d2">A comprehensive framework proposing a unified understanding of transfer learning efficiency across models.&lt;SEP&gt;A research work proposing a comprehensive perspective on transfer learning efficiency.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2110.04366">
  <data key="d0">arXiv preprint arXiv:2110.04366</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">A preprint discussing parameter-efficient transfer learning methods.&lt;SEP&gt;A preprint discussing theoretical and practical aspects of parameter-efficient transfer learning.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shwai He, Liang Ding, Daize Dong, Miao Zhang, and Dacheng Tao">
  <data key="d0">Shwai He, Liang Ding, Daize Dong, Miao Zhang, and Dacheng Tao</data>
  <data key="d1">Researcher Names</data>
  <data key="d2">Authors of a study on Sparseadapter, a simple approach to improve parameter efficiency of adapters in neural models.&lt;SEP&gt;Authors of a study on Sparseadapter, an approach for improving parameter efficiency of adapters.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sparseadapter">
  <data key="d0">Sparseadapter</data>
  <data key="d1">Methodology/Technique</data>
  <data key="d2">An efficient adapter mechanism designed to improve parameter efficiency and model performance in transfer learning.&lt;SEP&gt;An efficient adapter method designed to enhance parameter efficiency in neural models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2210">
  <data key="d0">arXiv preprint arXiv:2210</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">A preprint describing Sparseadapter methodology.&lt;SEP&gt;A preprint detailing the Sparseadapter technique.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ma">
  <data key="d0">Ma</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ma is a foundational work discussing transfer learning in machine learning models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Taylor Berg-Kirkpatrick">
  <data key="d0">Taylor Berg-Kirkpatrick</data>
  <data key="d1">Researcher</data>
  <data key="d2">Taylor Berg-Kirkpatrick is an author contributing to research on parameter-efficient transfer learning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shwai He">
  <data key="d0">Shwai He</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shwai He is an author of work on improving parameter efficiency of adapters in machine learning models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Liang Ding">
  <data key="d0">Liang Ding</data>
  <data key="d1">Researcher</data>
  <data key="d2">Liang Ding contributed to research on sparse adapters for model efficiency.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Daize Dong">
  <data key="d0">Daize Dong</data>
  <data key="d1">Researcher</data>
  <data key="d2">Daize Dong is involved in studies on model optimization techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Miao Zhang">
  <data key="d0">Miao Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Miao Zhang contributed to research on parameter-efficient transfer learning approaches.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dacheng Tao">
  <data key="d0">Dacheng Tao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dacheng Tao is an author of work on improving transfer learning methods.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dan Hendrycks">
  <data key="d0">Dan Hendrycks</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dan Hendrycks is an author of work on Gaussian error linear units (GELUs) for neural networks.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kevin Gimpel">
  <data key="d0">Kevin Gimpel</data>
  <data key="d1">Researcher</data>
  <data key="d2">Kevin Gimpel co-authored research on GELUs and neural activation functions.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Evan Hernandez">
  <data key="d0">Evan Hernandez</data>
  <data key="d1">Researcher</data>
  <data key="d2">Evan Hernandez is involved in research on measuring and manipulating knowledge representations in language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Belinda Z Li">
  <data key="d0">Belinda Z Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Belinda Z Li contributed to studies on knowledge representation in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jacob Andreas">
  <data key="d0">Jacob Andreas</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jacob Andreas is an author researching in language models and their knowledge structures.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neil Houlsby">
  <data key="d0">Neil Houlsby</data>
  <data key="d1">Researcher</data>
  <data key="d2">Neil Houlsby is an author of work on parameter-efficient transfer learning for NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andrei Giurgiu">
  <data key="d0">Andrei Giurgiu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Andrei Giurgiu contributed to research on transfer learning techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stanislaw Jastrzebski">
  <data key="d0">Stanislaw Jastrzebski</data>
  <data key="d1">Researcher</data>
  <data key="d2">Stanislaw Jastrzebski is involved in studies on NLP transfer learning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bruna Morrone">
  <data key="d0">Bruna Morrone</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bruna Morrone contributed to research on NLP transfer techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Quentin De Laroussilhe">
  <data key="d0">Quentin De Laroussilhe</data>
  <data key="d1">Researcher</data>
  <data key="d2">Quentin De Laroussilhe is involved in transfer learning research.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andrea Gesmundo">
  <data key="d0">Andrea Gesmundo</data>
  <data key="d1">Researcher</data>
  <data key="d2">Andrea Gesmundo contributed to studies on NLP models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mona Attariyan">
  <data key="d0">Mona Attariyan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Mona Attariyan is involved in research on NLP transfer methods.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sylvain Gelly">
  <data key="d0">Sylvain Gelly</data>
  <data key="d1">Researcher</data>
  <data key="d2">Sylvain Gelly contributed to transfer learning research in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jermey Howard">
  <data key="d0">Jermey Howard</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jeremy Howard is known for work on universal language model fine-tuning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sebastian Ruder">
  <data key="d0">Sebastian Ruder</data>
  <data key="d1">Researcher</data>
  <data key="d2">Sebastian Ruder contributed to NLP transfer learning and model fine-tuning techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Cheng-Yu Hsieh">
  <data key="d0">Cheng-Yu Hsieh</data>
  <data key="d1">Researcher</data>
  <data key="d2">Cheng-Yu Hsieh is involved in research on distilling large language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yasuhisa Fujii">
  <data key="d0">Yasuhisa Fujii</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yasuhisa Fujii contributed to NLP research, including model training data efficiency.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alexander Ratner">
  <data key="d0">Alexander Ratner</data>
  <data key="d1">Researcher</data>
  <data key="d2">Alexander Ratner is involved in NLP research, especially in data and model optimization.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tomas Pfister">
  <data key="d0">Tomas Pfister</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tomas Pfister contributed to studies on NLP model performance.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Edward J Hu">
  <data key="d0">Edward J Hu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Edward J Hu is an author on low-rank adaptation techniques for large language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Phillip Wallis">
  <data key="d0">Phillip Wallis</data>
  <data key="d1">Researcher</data>
  <data key="d2">Phillip Wallis is involved in NLP transfer learning studies.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zeyuan Allen-Zhu">
  <data key="d0">Zeyuan Allen-Zhu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zeyuan Allen-Zhu contributed to research on model adaptation and training efficiency.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuanzhi Li">
  <data key="d0">Yuanzhi Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuanzhi Li is involved in theoretical and applied research in NLP models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shean Wang">
  <data key="d0">Shean Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shean Wang contributed to NLP model adaptation techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lu Wang">
  <data key="d0">Lu Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lu Wang is involved in NLP research on model training and fine-tuning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shengding Hu">
  <data key="d0">Shengding Hu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shengding Hu is involved in knowledge prompt-tuning and NLP classification.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ning Ding">
  <data key="d0">Ning Ding</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ning Ding contributed to NLP research focusing on knowledge and prompt tuning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Huadong Wang">
  <data key="d0">Huadong Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Huadong Wang is involved in NLP model training and optimization.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhiyuan Liu">
  <data key="d0">Zhiyuan Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zhiyuan Liu contributed to NLP research, especially in knowledge and language understanding.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jingang Wang">
  <data key="d0">Jingang Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jingang Wang is involved in NLP model research and applications.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Juanzi Li">
  <data key="d0">Juanzi Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Juanzi Li contributed to NLP research on knowledge integration.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wei Wu">
  <data key="d0">Wei Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Wei Wu is involved in NLP data and model research.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Maosong Sun">
  <data key="d0">Maosong Sun</data>
  <data key="d1">Researcher</data>
  <data key="d2">Maosong Sun contributed to NLP knowledge and model research.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhiqiang Hu">
  <data key="d0">Zhiqiang Hu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zhiqiang Hu is involved in NLP model adaptation and fine-tuning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yihuai Lan">
  <data key="d0">Yihuai Lan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yihuai Lan contributed to NLP research on large language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lei Wang">
  <data key="d0">Lei Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lei Wang is involved in NLP model training and adaptation.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wanyu Xu">
  <data key="d0">Wanyu Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Wanyu Xu contributed to NLP research on model efficiency.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ee-Peng Lim">
  <data key="d0">Ee-Peng Lim</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ee-Peng Lim is involved in NLP research, especially in language understanding.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Roy Ka-Wei Lee">
  <data key="d0">Roy Ka-Wei Lee</data>
  <data key="d1">Researcher</data>
  <data key="d2">Roy Ka-Wei Lee contributed to NLP model adaptation.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lidong Bing">
  <data key="d0">Lidong Bing</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lidong Bing is involved in NLP research related to knowledge and models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Soujanya Poria">
  <data key="d0">Soujanya Poria</data>
  <data key="d1">Researcher</data>
  <data key="d2">Soujanya Poria contributed to NLP research on language understanding and models.&lt;SEP&gt;Soujanya Poria involved in research on domain adaptation and adapter-based models.&lt;SEP&gt;Soujanya Poria participated in domain adaptation research using adapters.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e&lt;SEP&gt;chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ziwei Ji">
  <data key="d0">Ziwei Ji</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ziwei Ji contributed to research on hallucination in natural language generation.&lt;SEP&gt;Ziwei Ji's survey addresses hallucination issues in natural language generation.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Nayeon Lee">
  <data key="d0">Nayeon Lee</data>
  <data key="d1">Researcher</data>
  <data key="d2">Nayeon Lee is involved in NLP research, particularly in language model hallucinations.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rita Frieske">
  <data key="d0">Rita Frieske</data>
  <data key="d1">Researcher</data>
  <data key="d2">Rita Frieske contributed to studies on hallucination in language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tiezheng Yu">
  <data key="d0">Tiezheng Yu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tiezheng Yu is involved in NLP research, especially in hallucination and model reliability.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dan Su">
  <data key="d0">Dan Su</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dan Su contributed to NLP research on hallucination issues.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yan Xu">
  <data key="d0">Yan Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yan Xu is involved in NLP studies related to hallucination in language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Etsuko Ishii">
  <data key="d0">Etsuko Ishii</data>
  <data key="d1">Researcher</data>
  <data key="d2">Etsuko Ishii contributed to NLP research, including hallucination phenomena.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ye Jin Bang">
  <data key="d0">Ye Jin Bang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ye Jin Bang is involved in NLP research on model hallucinations.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andrea Madotto">
  <data key="d0">Andrea Madotto</data>
  <data key="d1">Researcher</data>
  <data key="d2">Andrea Madotto contributed to NLP research, especially in hallucination and model accuracy.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pascale Fung">
  <data key="d0">Pascale Fung</data>
  <data key="d1">Researcher</data>
  <data key="d2">Pascale Fung is involved in NLP research, including hallucination in language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chen Jia">
  <data key="d0">Chen Jia</data>
  <data key="d1">Researcher</data>
  <data key="d2">Chen Jia contributed to NLP research on domain generalization.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yue Zhang">
  <data key="d0">Yue Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yue Zhang is involved in NLP research, especially in prompt-based techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt-based Distribution Alignment for Domain Generalization in Text Classification">
  <data key="d0">Prompt-based Distribution Alignment for Domain Generalization in Text Classification</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This research introduces a method called Prompt-based Distribution Alignment aimed at improving the ability of models to generalize across different domains in text classification tasks.&lt;SEP&gt;This work discusses a method called Prompt-based Distribution Alignment aimed at improving domain generalization in text classification tasks.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Manuscript">
  <data key="d0">Manuscript</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A research paper submitted to ACM detailing the proposed method for domain generalization in NLP.&lt;SEP&gt;A submitted document to ACM detailing research on domain generalization in NLP.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ACM">
  <data key="d0">ACM</data>
  <data key="d1">Organization</data>
  <data key="d2">The Association for Computing Machinery, publisher and organizer of the conference and publication.&lt;SEP&gt;The Association for Computing Machinery, publisher of the manuscript.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Theorem Provers">
  <data key="d0">Theorem Provers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Automated systems designed to validate mathematical proofs, guided here by informal proofs.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Informal Proofs">
  <data key="d0">Informal Proofs</data>
  <data key="d1">Tools</data>
  <data key="d2">Non-formal reasoning methods used to guide formal theorem proving.&lt;SEP&gt;Non-formal reasoning or argumentation used to guide the formal verification process in theorem proving.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Regularized Optimization">
  <data key="d0">Regularized Optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A training approach that incorporates regularization to enhance model robustness and efficiency.&lt;SEP&gt;Training strategies that incorporate regularization terms to improve model robustness and prevent overfitting.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Learning">
  <data key="d0">Prompt Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques involving the use of prompts to guide language model outputs, including instance-aware prompt learning.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Language Understanding and Generation">
  <data key="d0">Language Understanding and Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Fundamental NLP tasks involving comprehension of text and producing coherent language outputs.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Biomedical Information">
  <data key="d0">Biomedical Information</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Domain-specific data related to health and medicine, augmented here with domain tools.&lt;SEP&gt;Domain-specific knowledge related to health, medicine, and biology, which can be accessed and augmented by domain tools.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="GeneGPT">
  <data key="d0">GeneGPT</data>
  <data key="d1">Tools</data>
  <data key="d2">A domain tool aimed at enhancing large language models' access to biomedical information for research and clinical applications.&lt;SEP&gt;A domain tool designed to enhance large language models' access to biomedical information.&lt;SEP&gt;A large language model augmented with domain tools to access biomedical data effectively.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scaling Laws">
  <data key="d0">Scaling Laws</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Principles describing how the size and capacity of neural language models relate to their performance.&lt;SEP&gt;Principles describing how the size and capacity of neural models relate to their performance, guiding model development.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neural Language Models">
  <data key="d0">Neural Language Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Models based on neural network architectures trained on large text corpora for NLP tasks.&lt;SEP&gt;Models based on neural network architectures trained on large text corpora to perform NLP tasks.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapter Layers">
  <data key="d0">Adapter Layers</data>
  <data key="d1">Tools</data>
  <data key="d2">Low-rank hypercomplex layers integrated into models to enable efficient fine-tuning and adaptation.&lt;SEP&gt;Low-rank hypercomplex layers used to make models more efficient and adaptable.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Internet-Augmented Dialogue Generation">
  <data key="d0">Internet-Augmented Dialogue Generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Enhancing dialogue systems with internet access for more informed responses.&lt;SEP&gt;Enhancing dialogue systems with internet access to provide more accurate and informed responses.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Clinical Language Models">
  <data key="d0">Clinical Language Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Language models specialized for clinical and medical NLP applications.&lt;SEP&gt;Language models specifically trained or adapted for clinical and medical NLP applications.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Financial Sentiment">
  <data key="d0">Financial Sentiment</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Analyzing and attacking financial market sentiment using advanced language models like GPT-3.&lt;SEP&gt;Analyzing and manipulating financial market sentiment using large language models like GPT-3 for research or strategic purposes.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter-Efficient Prompt Tuning">
  <data key="d0">Parameter-Efficient Prompt Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques designed to optimize prompt tuning with fewer parameters, making the process more efficient and scalable.&lt;SEP&gt;Techniques to optimize prompt tuning with fewer parameters, improving efficiency.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Giant Frozen Language Models">
  <data key="d0">Giant Frozen Language Models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Extremely large pre-trained language models characterized by extensive parameters and training data, with societal and technological implications.&lt;SEP&gt;Large-scale pre-trained models with extensive training data and parameters.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Controllable Working Memory">
  <data key="d0">Controllable Working Memory</data>
  <data key="d1">Variables</data>
  <data key="d2">A feature in models that allows explicit control over the amount of memory used during processing, affecting performance and efficiency.&lt;SEP&gt;A model feature allowing explicit control over the amount of memory used during processing.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Society of Large Scale Language Models">
  <data key="d0">Society of Large Scale Language Models</data>
  <data key="d1">Disciplines</data>
  <data key="d2">An interdisciplinary research community studying the development, societal impact, and ethical considerations of large-scale language models.&lt;SEP&gt;Research area focused on the societal impacts and development of large-scale language models.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter Scaling Laws">
  <data key="d0">Parameter Scaling Laws</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Frameworks describing how increasing model size affects performance.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Language Model Society">
  <data key="d0">Language Model Society</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A multidisciplinary field examining societal, ethical, and technological impacts of large language models.&lt;SEP&gt;Interdisciplinary study of the societal, ethical, and technological aspects of large language models.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="NLP Tasks">
  <data key="d0">NLP Tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Various natural language processing tasks such as classification, generation, question-answering, and understanding.&lt;SEP&gt;Various tasks in natural language processing such as classification, generation, and understanding.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Disruptive Technology">
  <data key="d0">Disruptive Technology</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Innovative approaches or models that significantly impact and transform existing technological paradigms, such as large language models in NLP.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Formal Theorem Provers">
  <data key="d0">Formal Theorem Provers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Automated systems used to verify mathematical proofs, guided here by informal proofs to improve their effectiveness.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Guiding Formal Theorem Provers">
  <data key="d0">Guiding Formal Theorem Provers</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques involving the use of informal proofs to assist and direct formal theorem proving processes.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sketching, Drafting, and Proving">
  <data key="d0">Sketching, Drafting, and Proving</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A framework or process for constructing, visualizing, and validating formal proofs, possibly with AI assistance.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instance-aware Prompt Learning">
  <data key="d0">Instance-aware Prompt Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique that incorporates specific prompts tailored to individual instances to improve language understanding and generation.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Language Understanding">
  <data key="d0">Language Understanding</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ability of models to comprehend and interpret natural language accurately.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Language Generation">
  <data key="d0">Language Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process by which models produce coherent and contextually appropriate natural language outputs.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Attacking Financial Sentiment">
  <data key="d0">Attacking Financial Sentiment</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using GPT-3 to analyze, influence, or manipulate financial sentiment, possibly for research or strategic insights.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scaling Laws for Neural Language Models">
  <data key="d0">Scaling Laws for Neural Language Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Frameworks that describe how changes in model size and data affect performance, guiding model scaling strategies.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge-Intensive NLP Tasks">
  <data key="d0">Knowledge-Intensive NLP Tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">NLP tasks that require external knowledge access, often enhanced through retrieval mechanisms for improved performance.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Guohao Li">
  <data key="d0">Guohao Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Guohao Li is an author involved in a study about large-scale language models and their societal implications.&lt;SEP&gt;Guohao Li is an author involved in research on large-scale language models and their societal impacts, contributing to understanding AI's societal implications.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hasan Abed Al Kader Hammoud">
  <data key="d0">Hasan Abed Al Kader Hammoud</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hasan Abed Al Kader Hammoud contributed to research on communicative agents for exploring large language models and their societal effects.&lt;SEP&gt;Hassan Abed Al Kader Hammoud contributed to research on communicative agents for exploring large language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hani Itani">
  <data key="d0">Hani Itani</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hani Itani is a researcher involved in studies related to language models, communication, and societal impact analysis.&lt;SEP&gt;Hani Itani is a researcher involved in the study of language models and their societal impacts.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dmitrii Khizbullin">
  <data key="d0">Dmitrii Khizbullin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dmitrii Khizbullin contributed to research on large language models, their architectures, and societal considerations.&lt;SEP&gt;Dmitrii Khizbullin contributed to the research on large language models and their applications.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bernard Ghanem">
  <data key="d0">Bernard Ghanem</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bernard Ghanem participated in research exploring societal impacts of large-scale language models and AI communication agents.&lt;SEP&gt;Bernard Ghanem participated in the study focusing on societal exploration through language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="CAMEL">
  <data key="d0">CAMEL</data>
  <data key="d1">Core Concept</data>
  <data key="d2">Communicative Agents for 'Mind' Exploration of Large Scale Language Model Society, a framework for studying AI societal influence and agent communication.&lt;SEP&gt;Communicative Agents for 'Mind' Exploration of Large Scale Language Model Society, a framework or approach to understanding societal impacts of language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2303.17760">
  <data key="d0">arXiv:2303.17760</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Preprint publication containing research findings on large-scale language models and societal implications.&lt;SEP&gt;Preprint publication presenting research on societal exploration through communicative agents and large language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Haochen Li">
  <data key="d0">Haochen Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Haochen Li is an author of work on knowledge-injected prompt tuning for event detection in NLP.&lt;SEP&gt;Haochen Li is an author of work on knowledge-injected prompt tuning for event detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tong Mo">
  <data key="d0">Tong Mo</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tong Mo contributed to research on knowledge-injected prompt tuning techniques for event detection.&lt;SEP&gt;Tong Mo contributed to research on prompt tuning techniques for event detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hongcheng Fan">
  <data key="d0">Hongcheng Fan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hongcheng Fan participated in developing prompt tuning methodologies for event detection tasks.&lt;SEP&gt;Hongcheng Fan participated in research on knowledge-injected prompt tuning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jingkun Wang">
  <data key="d0">Jingkun Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jingkun Wang contributed to the study on prompt tuning methodologies.&lt;SEP&gt;Jingkun Wang was involved in research on prompt tuning for event detection in NLP.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiaxi Wang">
  <data key="d0">Jiaxi Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiaxi Wang contributed to the study on prompt tuning methods for event detection.&lt;SEP&gt;Jiaxi Wang was involved in research on event detection using prompt tuning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fuhao Zhang">
  <data key="d0">Fuhao Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Fuhao Zhang contributed to the development of prompt tuning techniques for NLP tasks.&lt;SEP&gt;Fuhao Zhang worked on knowledge-injected prompt tuning approaches for NLP applications.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Weiping Li">
  <data key="d0">Weiping Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Weiping Li participated in research on knowledge-injected prompt tuning.&lt;SEP&gt;Weiping Li participated in research on prompt tuning for event detection using knowledge injection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ICCL Conference 2022">
  <data key="d0">ICCL Conference 2022</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Conference publication presenting research on prompt tuning for event detection.&lt;SEP&gt;Conference where research on prompt tuning for event detection was presented.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jinyang Li">
  <data key="d0">Jinyang Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jinyang Li is an author of research on large-scale database grounded text-to-SQL models using language models.&lt;SEP&gt;Jinyang Li is an author of research on large-scale database grounded text-to-SQL models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Binyuan Hui">
  <data key="d0">Binyuan Hui</data>
  <data key="d1">Researcher</data>
  <data key="d2">Binyuan Hui contributed to research on database interface models based on large language models.&lt;SEP&gt;Binyuan Hui contributed to research on serving as a database interface with large language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ge Qu">
  <data key="d0">Ge Qu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ge Qu participated in developing text-to-SQL models grounded in large language models.&lt;SEP&gt;Ge Qu participated in the study on serving as a database interface with large language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiaxi Yang">
  <data key="d0">Jiaxi Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiaxi Yang was involved in research on large-scale database interface tasks using language models.&lt;SEP&gt;Jiaxi Yang was involved in research on text-to-SQL tasks grounded in large language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bowen Li">
  <data key="d0">Bowen Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bowen Li contributed to research on database interface capabilities of large language models.&lt;SEP&gt;Bowen Li contributed to research on large language models serving as database interfaces.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bailin Wang">
  <data key="d0">Bailin Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bailin Wang participated in the study on large-scale database grounded language models.&lt;SEP&gt;Bailin Wang participated in the study on text-to-SQL tasks grounded in large language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bowen Qin">
  <data key="d0">Bowen Qin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bowen Qin contributed to research on large language models for database query interfaces.&lt;SEP&gt;Bowen Qin contributed to research on large language models serving as database interfaces.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rongyu Cao">
  <data key="d0">Rongyu Cao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Rongyu Cao involved in research on large-scale database grounded text-to-SQL models.&lt;SEP&gt;Rongyu Cao involved in the text-to-SQL research using large language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruiying Geng">
  <data key="d0">Ruiying Geng</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ruiying Geng contributed to the study on database-grounded language models.&lt;SEP&gt;Ruiying Geng participated in the study on large language models as database interfaces.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2305.03111">
  <data key="d0">arXiv:2305.03111</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Preprint detailing large-scale database grounded text-to-SQL models using language models.&lt;SEP&gt;Preprint publication detailing large-scale database grounded text-to-SQL models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xiang Lisa Li">
  <data key="d0">Xiang Lisa Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xiang Lisa Li is an author researching prompt tuning strategies for language generation.&lt;SEP&gt;Xiang Lisa Li is an author working on prompt tuning strategies for language generation and model optimization.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Proceedings of ACL 2021">
  <data key="d0">Proceedings of ACL 2021</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Conference proceedings presenting research on prompt optimization for language models.&lt;SEP&gt;Conference proceedings presenting research on prompt tuning for language generation.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jacky Liang">
  <data key="d0">Jacky Liang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jacky Liang is involved in research on language models for embodied control and robotics.&lt;SEP&gt;Jacky Liang is involved in research on language models for embodied control.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wenlong Huang">
  <data key="d0">Wenlong Huang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Wenlong Huang contributed to research on language model programs for embodied AI and robotics.&lt;SEP&gt;Wenlong Huang contributed to research on language model programs for robotics.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fei Xia">
  <data key="d0">Fei Xia</data>
  <data key="d1">Researcher</data>
  <data key="d2">Fei Xia participated in studies on language models applied to embodied control.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Peng Xu">
  <data key="d0">Peng Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Peng Xu contributed to research on language model control for robotics and embodied systems.&lt;SEP&gt;Peng Xu contributed to research on language models and robotics.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Karol Hausman">
  <data key="d0">Karol Hausman</data>
  <data key="d1">Researcher</data>
  <data key="d2">Karol Hausman involved in research on language models for embodied AI control.&lt;SEP&gt;Karol Hausman involved in research on language models for embodied control.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pete Florence">
  <data key="d0">Pete Florence</data>
  <data key="d1">Researcher</data>
  <data key="d2">Pete Florence contributed to research on language and robotics integration.&lt;SEP&gt;Pete Florence contributed to research on language models in robotics contexts.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andy Zeng">
  <data key="d0">Andy Zeng</data>
  <data key="d1">Researcher</data>
  <data key="d2">Andy Zeng participated in language model research for embodied AI.&lt;SEP&gt;Andy Zeng participated in research on language and robotics for embodied control.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Language and Robotics Workshop at CoRL 2022">
  <data key="d0">Language and Robotics Workshop at CoRL 2022</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Conference workshop presenting research on language models for embodied control.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yaobo Liang">
  <data key="d0">Yaobo Liang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yaobo Liang is an author working on task completion connecting foundation models with APIs.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chenfei Wu">
  <data key="d0">Chenfei Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Chenfei Wu contributed to research on TaskMatrix for task completion using foundation models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ting Song">
  <data key="d0">Ting Song</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ting Song participated in research on connecting models with APIs for task execution.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wenshan Wu">
  <data key="d0">Wenshan Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Wenshan Wu involved in research on task completion frameworks.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yan Xia">
  <data key="d0">Yan Xia</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yan Xia contributed to research on connecting foundation models with APIs.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yu Liu">
  <data key="d0">Yu Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yu Liu participated in the development of TaskMatrix for AI task completion.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yang Ou">
  <data key="d0">Yang Ou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yang Ou contributed to connecting models with APIs for task execution.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shuai Lu">
  <data key="d0">Shuai Lu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shuai Lu involved in research on API integration for AI tasks.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lei Ji">
  <data key="d0">Lei Ji</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lei Ji contributed to research on connecting foundation models with APIs.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shaoguang Mao">
  <data key="d0">Shaoguang Mao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shaoguang Mao participated in research on task completion via foundation models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2303.16434">
  <data key="d0">arXiv:2303.16434</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Preprint detailing TaskMatrix framework for AI task completion.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hongzhan Lin">
  <data key="d0">Hongzhan Lin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hongzhan Lin is an author working on zero-shot rumor detection using prompt learning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pengyao Yi">
  <data key="d0">Pengyao Yi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Pengyao Yi contributed to research on rumor detection with propagation structures.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jing Ma">
  <data key="d0">Jing Ma</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jing Ma participated in research on prompt learning for rumor detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Haiyun Jiang">
  <data key="d0">Haiyun Jiang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Haiyun Jiang involved in rumor detection studies using prompt learning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ziyang Luo">
  <data key="d0">Ziyang Luo</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ziyang Luo contributed to research on propagation-based rumor detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shuming Shi">
  <data key="d0">Shuming Shi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shuming Shi participated in studies on rumor detection with propagation structures.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruifang Liu">
  <data key="d0">Ruifang Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ruifang Liu contributed to research on zero-shot rumor detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2212.01117">
  <data key="d0">arXiv:2212.01117</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Preprint publication on rumor detection using propagation structure and prompt learning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Qi Liu">
  <data key="d0">Qi Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Qi Liu is an author researching relational memory-augmented language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dani Yogatama">
  <data key="d0">Dani Yogatama</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dani Yogatama contributed to research on relational memory in language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Phil Blunsom">
  <data key="d0">Phil Blunsom</data>
  <data key="d1">Researcher</data>
  <data key="d2">Phil Blunsom involved in the study of relational memory-augmented language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Transactions of the ACL 2022">
  <data key="d0">Transactions of the ACL 2022</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Conference publication presenting research on relational memory in language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruibo Liu">
  <data key="d0">Ruibo Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ruibo Liu is an author working on grounded language model reasoning through simulation.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Te-Yen Wu">
  <data key="d0">Te-Yen Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Te-Yen Wu involved in research on grounded language model reasoning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Soroush Vosoughi">
  <data key="d0">Soroush Vosoughi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Soroush Vosoughi contributed to grounded reasoning research.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Claire Cui">
  <data key="d0">Claire Cui</data>
  <data key="d1">Researcher</data>
  <data key="d2">Claire Cui participated in grounded language model reasoning studies.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andrew M Dai">
  <data key="d0">Andrew M Dai</data>
  <data key="d1">Researcher</data>
  <data key="d2">Andrew M Dai involved in grounded reasoning research.&lt;SEP&gt;Author involved in research on zero-shot and few-shot learning in large language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2210.05359">
  <data key="d0">arXiv:2210.05359</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Preprint detailing grounded language model reasoning through simulation.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xiangyang Liu">
  <data key="d0">Xiangyang Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xiangyang Liu is an author working on late prompt tuning strategies.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tianxiang Sun">
  <data key="d0">Tianxiang Sun</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tianxiang Sun contributed to research on late prompt tuning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xuanjing Huang">
  <data key="d0">Xuanjing Huang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on knowledge infusion into pre-trained models using adapters.&lt;SEP&gt;Xuanjing Huang participated in prompt tuning research.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xipeng Qiu">
  <data key="d0">Xipeng Qiu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xipeng Qiu involved in prompt tuning methodologies.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Findings of EMNLP 2022">
  <data key="d0">Findings of EMNLP 2022</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Conference proceedings presenting research on late prompt tuning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yiheng Liu">
  <data key="d0">Yiheng Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yiheng Liu is an author summarizing GPT-4 and ChatGPT research.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tianle Han">
  <data key="d0">Tianle Han</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tianle Han contributed to GPT research summaries.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Siyuan Ma">
  <data key="d0">Siyuan Ma</data>
  <data key="d1">Researcher</data>
  <data key="d2">Siyuan Ma participated in GPT-4 and ChatGPT research summaries.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiayue Zhang">
  <data key="d0">Jiayue Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiayue Zhang involved in GPT research trend analysis.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuanyuan Yang">
  <data key="d0">Yuanyuan Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuanyuan Yang contributed to GPT-4 research summaries.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiaming Tian">
  <data key="d0">Jiaming Tian</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiaming Tian participated in GPT-4 research analysis.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hao He">
  <data key="d0">Hao He</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hao He contributed to GPT research summaries.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Antong Li">
  <data key="d0">Antong Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Antong Li involved in GPT-4 research review.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mengshen He">
  <data key="d0">Mengshen He</data>
  <data key="d1">Researcher</data>
  <data key="d2">Mengshen He contributed to GPT-4 research summaries.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhengliang Liu">
  <data key="d0">Zhengliang Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zhengliang Liu participated in GPT-4 research analysis.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2304.01852">
  <data key="d0">arXiv:2304.01852</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Preprint summarizing GPT-4 and ChatGPT research and future perspectives.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alejandro Lopez-Lira">
  <data key="d0">Alejandro Lopez-Lira</data>
  <data key="d1">Researcher</data>
  <data key="d2">Alejandro Lopez-Lira is an author investigating ChatGPT's ability to forecast stock prices.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuehua Tang">
  <data key="d0">Yuehua Tang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuehua Tang contributed to research on ChatGPT and stock return predictability.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2304.07619">
  <data key="d0">arXiv:2304.07619</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Preprint on ChatGPT's stock forecasting capabilities.&lt;SEP&gt;Preprint on biomedical knowledge fusion via prompt hierarchy.&lt;SEP&gt;Preprint on prompt order sensitivity and few-shot biomedical knowledge fusion.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiaying Lu">
  <data key="d0">Jiaying Lu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiaying Lu is an author working on few-shot biomedical knowledge fusion using prompts.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiaming Shen">
  <data key="d0">Jiaming Shen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiaming Shen contributed to biomedical knowledge fusion research.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bo Xiong">
  <data key="d0">Bo Xiong</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bo Xiong participated in prompt-based biomedical knowledge fusion.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wengjing Ma">
  <data key="d0">Wengjing Ma</data>
  <data key="d1">Researcher</data>
  <data key="d2">Wengjing Ma involved in biomedical prompt learning studies.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Staab Steffen">
  <data key="d0">Staab Steffen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Staab Steffen contributed to biomedical knowledge fusion research.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Carl Yang">
  <data key="d0">Carl Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Carl Yang participated in biomedical knowledge fusion research.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yao Lu">
  <data key="d0">Yao Lu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yao Lu is an author working on prompt order sensitivity in language models.&lt;SEP&gt;Yao Lu is an author working on task completion by connecting foundation models with APIs.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Max Bartolo">
  <data key="d0">Max Bartolo</data>
  <data key="d1">Researcher</data>
  <data key="d2">Max Bartolo contributed to research on few-shot prompt learning for biomedical knowledge fusion.&lt;SEP&gt;Max Bartolo contributed to research on prompt ordering in few-shot learning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alastair Moore">
  <data key="d0">Alastair Moore</data>
  <data key="d1">Researcher</data>
  <data key="d2">Alastair Moore involved in prompt order sensitivity studies.&lt;SEP&gt;Alastair Moore participated in research on prompt hierarchy and few-shot learning.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pontus Stenetorp">
  <data key="d0">Pontus Stenetorp</data>
  <data key="d1">Researcher</data>
  <data key="d2">Pontus Stenetorp contributed to prompt sensitivity research.&lt;SEP&gt;Pontus Stenetorp contributed to research on prompt order sensitivity in language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Proceedings of ACL 2022">
  <data key="d0">Proceedings of ACL 2022</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Conference proceedings on prompt order sensitivity.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2210.07128">
  <data key="d0">arXiv:2210.07128</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Preprint on language models of code as few-shot learners for commonsense reasoning.&lt;SEP&gt;Preprint on language models of code as few-shot learners for commonsense.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Babak Mahjour">
  <data key="d0">Babak Mahjour</data>
  <data key="d1">Researcher</data>
  <data key="d2">Babak Mahjour is an author working on chemical reaction array design using AI and ChatGPT.&lt;SEP&gt;Babak Mahjour is an author working on chemical reaction array design using AI tools and ChatGPT.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jillian Hoffstadt">
  <data key="d0">Jillian Hoffstadt</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jillian Hoffstadt contributed to chemical reaction array design research.&lt;SEP&gt;Jillian Hoffstadt contributed to research on chemical reaction array design with AI.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tim Cernak">
  <data key="d0">Tim Cernak</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tim Cernak participated in chemical reaction array design research using AI.&lt;SEP&gt;Tim Cernak participated in research on chemical reaction arrays using AI.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2023">
  <data key="d0">arXiv:2023</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Preprint detailing chemical reaction array design with AI tools.&lt;SEP&gt;Preprint detailing the design of chemical reaction arrays using AI and ChatGPT.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bhavitvya Malik">
  <data key="d0">Bhavitvya Malik</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bhavitvya Malik is an author working on domain adaptation in NLP using adapters.&lt;SEP&gt;Bhavitvya Malik is an author working on domain adaptation using adapters.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Abhinav Ramesh Kashyap">
  <data key="d0">Abhinav Ramesh Kashyap</data>
  <data key="d1">Researcher</data>
  <data key="d2">Abhinav Ramesh Kashyap contributed to efficient domain adaptation research.&lt;SEP&gt;Abhinav Ramesh Kashyap contributed to efficient domain adaptation techniques using adapters.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Min-Yen Kan">
  <data key="d0">Min-Yen Kan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Min-Yen Kan involved in domain adaptation studies.&lt;SEP&gt;Min-Yen Kan participated in research on domain adaptation and adapters in NLP.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2302.03194">
  <data key="d0">arXiv:2302.03194</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Preprint on domain adaptation using adapters in NLP.&lt;SEP&gt;Preprint on domain adaptation with adapters.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Language and Robotics at CoRL 2022">
  <data key="d0">Language and Robotics at CoRL 2022</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">Conference workshop presenting research on language models for embodied AI and robotics.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chemical Reaction Arrays">
  <data key="d0">Chemical Reaction Arrays</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Chemical Reaction Arrays are systematic arrangements of chemical reactions designed for research or industrial purposes, often utilizing computational tools like phactor and AI models like ChatGPT.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="phactor">
  <data key="d0">phactor</data>
  <data key="d1">Tools</data>
  <data key="d2">phactor is a software tool used for designing and managing chemical reaction arrays, facilitating experimental planning and automation.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ChatGPT">
  <data key="d0">ChatGPT</data>
  <data key="d1">Tools</data>
  <data key="d2">A prominent large language model developed by OpenAI, widely used for various NLP applications, including practical deployment and research surveys.&lt;SEP&gt;An example of a large language model used for practical applications and surveys on AI capabilities.&lt;SEP&gt;ChatGPT is an AI language model employed to assist in designing chemical reactions, providing computational support and automation capabilities.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Language Model Tuning">
  <data key="d0">Language Model Tuning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Frameworks like Unipelt enable efficient tuning of large language models to improve performance on specific tasks while maintaining parameter efficiency.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Psychophysical Knowledge">
  <data key="d0">Psychophysical Knowledge</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Psychophysical Knowledge involves understanding the relationship between physical stimuli and perceptual responses, often extracted from language models to reveal perception mechanisms.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Factual Associations">
  <data key="d0">Factual Associations</data>
  <data key="d1">Variables</data>
  <data key="d2">Factual Associations are relationships between facts stored in models, which can be located, edited, or manipulated to improve model accuracy and reliability.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Memory Editing">
  <data key="d0">Memory Editing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Memory editing involves techniques to modify or update the stored knowledge within transformer models, enhancing their factual correctness.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Verified Quotes">
  <data key="d0">Verified Quotes</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Verified Quotes are accurately sourced quotations used by language models to support answers, ensuring factual correctness and credibility.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pointer Sentinel Mixture Models">
  <data key="d0">Pointer Sentinel Mixture Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Pointer Sentinel Mixture Models are advanced neural network architectures designed for improved language modeling and sequence prediction.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Augmented Language Models">
  <data key="d0">Augmented Language Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Augmented language models incorporate additional modules or data to enhance performance, versatility, or interpretability of standard language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pre-trained Language Models">
  <data key="d0">Pre-trained Language Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Pre-trained language models are large models trained on extensive datasets, serving as foundational tools for various NLP applications.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="In-Context Learning">
  <data key="d0">In-Context Learning</data>
  <data key="d1">Study Designs</data>
  <data key="d2">In-Context Learning involves training models to learn from provided demonstrations within the input context, improving task adaptability without explicit retraining.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Editing">
  <data key="d0">Model Editing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Model editing refers to techniques for modifying or updating the internal parameters of language models to correct errors or incorporate new information.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neural Network">
  <data key="d0">Neural Network</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Neural Networks are computational architectures inspired by biological neural systems, forming the basis of language models and other AI systems.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Natural Language Processing (NLP)">
  <data key="d0">Natural Language Processing (NLP)</data>
  <data key="d1">Discipline</data>
  <data key="d2">NLP is a field of artificial intelligence focused on the interaction between computers and human language, encompassing tasks like language generation and translation.&lt;SEP&gt;NLP is a field within artificial intelligence focused on enabling machines to understand, interpret, and generate human language.&lt;SEP&gt;Technologies and methods used to analyze and extract structured information from unstructured text.&lt;SEP&gt;NLP is the scientific discipline focused on enabling computers to understand, generate, and interpret human language.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-25ebcde4744e2b19ba1d5d1fd25807b0&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Question-Answering with Human Feedback">
  <data key="d0">Question-Answering with Human Feedback</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">This application involves using human feedback to improve the accuracy and reliability of AI-generated answers in question-answering systems.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multiparty Interactions">
  <data key="d0">Multiparty Interactions</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Enhancing multiparty interactions with robots involves employing large language models to facilitate communication and coordination among multiple users.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Suchir Balaji">
  <data key="d0">Suchir Balaji</data>
  <data key="d1">Researcher</data>
  <data key="d2">Suchir Balaji conducts research on question-answering systems, human-AI collaboration, and related AI methodologies.&lt;SEP&gt;Suchir Balaji is involved in AI and machine learning research, particularly in question-answering systems.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jeff Wu">
  <data key="d0">Jeff Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jeff Wu specializes in AI training techniques, especially involving human-in-the-loop feedback and model optimization.&lt;SEP&gt;Jeff Wu works on AI training methodologies and human-AI interaction.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Long Ouyang">
  <data key="d0">Long Ouyang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Long Ouyang is a key researcher in training language models with human feedback, contributing to foundational studies on instruction-following models.&lt;SEP&gt;Long Ouyang is a researcher focusing on training language models with human feedback.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Christina Kim">
  <data key="d0">Christina Kim</data>
  <data key="d1">Researcher</data>
  <data key="d2">Christina Kim contributes to research on AI systems and human-AI collaboration.&lt;SEP&gt;Christina Kim is involved in AI research, focusing on human-AI interaction and model evaluation.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="William Saunders">
  <data key="d0">William Saunders</data>
  <data key="d1">Researcher</data>
  <data key="d2">William Saunders is involved in AI research, particularly in natural language processing.&lt;SEP&gt;William Saunders studies AI and human-computer interaction, contributing to feedback-driven model training.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ChatGPT plugins">
  <data key="d0">ChatGPT plugins</data>
  <data key="d1">Tools</data>
  <data key="d2">ChatGPT plugins are software extensions that enhance ChatGPT's capabilities, enabling integration with external services and functionalities.&lt;SEP&gt;ChatGPT plugins are software extensions that enhance the functionality of ChatGPT, allowing integration with various services and tools.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Training language models to follow instructions with human feedback">
  <data key="d0">Training language models to follow instructions with human feedback</data>
  <data key="d1">Research Study</data>
  <data key="d2">A research study by Long Ouyang et al. (2022) exploring methods to improve language models' adherence to human instructions using feedback mechanisms.&lt;SEP&gt;A study by Long Ouyang et al. (2022</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Generative Agents">
  <data key="d0">Generative Agents</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Generative Agents are AI models designed to simulate human-like behaviors and interactions for research and testing purposes.&lt;SEP&gt;Generative Agents are interactive simulations of human behavior designed to model and analyze human-like interactions in AI systems.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instruction tuning with GPT-4">
  <data key="d0">Instruction tuning with GPT-4</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Instruction tuning is a methodology used to improve language model performance by training on specific instructions to better follow user commands.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapterhub">
  <data key="d0">Adapterhub</data>
  <data key="d1">Tools</data>
  <data key="d2">Adapterhub is a framework that facilitates adapting transformer models for various tasks through modular adapters.&lt;SEP&gt;Adapterhub provides a platform and framework for developing, sharing, and applying adapters to transformer models for multi-task learning.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mad-x">
  <data key="d0">Mad-x</data>
  <data key="d1">Tools</data>
  <data key="d2">Mad-x is an adapter-based framework for multi-task cross-lingual transfer learning in NLP.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Decomposed In-Context Learning of Text-to-SQL with Self-Correction (DIN-SQL)">
  <data key="d0">Decomposed In-Context Learning of Text-to-SQL with Self-Correction (DIN-SQL)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">DIN-SQL is a methodology that decomposes in-context learning for text-to-SQL tasks and employs self-correction to improve accuracy.&lt;SEP&gt;DIN-SQL is a technique for improving text-to-SQL tasks by decomposing in-context learning and applying self-correction mechanisms.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Gradient-free, Edit-based Instruction Search (GrIPS)">
  <data key="d0">Gradient-free, Edit-based Instruction Search (GrIPS)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">GrIPS is a method for prompt engineering that searches for effective instructions using gradient-free, edit-based approaches.&lt;SEP&gt;GrIPS is a prompt engineering technique that searches for effective instructions via gradient-free, edit-based methods.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hierarchical Domain-specific Language Models">
  <data key="d0">Hierarchical Domain-specific Language Models</data>
  <data key="d1">Variables</data>
  <data key="d2">Hierarchical domain-specific language models are specialized models designed to capture domain-specific language structures, improving decision classification in legal contexts.&lt;SEP&gt;Hierarchical domain-specific language models are tailored models designed to improve decision classification in specialized fields like legal decision-making.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Tuning of T5 (LFPT5)">
  <data key="d0">Prompt Tuning of T5 (LFPT5)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">LFPT5 is a framework for lifelong, few-shot language learning using prompt tuning of the T5 model.&lt;SEP&gt;LFPT5 is a unified framework for lifelong few-shot language learning using prompt tuning of the T5 model.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tool Learning with Foundation Models">
  <data key="d0">Tool Learning with Foundation Models</data>
  <data key="d1">Research Study</data>
  <data key="d2">Research exploring how foundation models can be used for tool learning, enabling models to select and utilize external tools effectively.&lt;SEP&gt;Research exploring how foundation models can learn to utilize external tools effectively to enhance their capabilities.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pre-trained models for NLP">
  <data key="d0">Pre-trained models for NLP</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Pre-trained models are foundational NLP models trained on large corpora to capture language representations, serving as the basis for various downstream tasks.&lt;SEP&gt;Pre-trained models are foundational NLP models trained on large corpora, serving as the basis for various downstream tasks.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Generative pre-training">
  <data key="d0">Generative pre-training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Generative pre-training involves training language models to predict text sequences, forming the basis for models like GPT.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Transfer learning with transformers">
  <data key="d0">Transfer learning with transformers</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Exploring transfer learning involves adapting pre-trained transformer models to new tasks, assessing their generalization capabilities.&lt;SEP&gt;Transfer learning studies investigate how pre-trained transformer models can be adapted to new tasks and domains.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Research on domain specialization in large language models">
  <data key="d0">Research on domain specialization in large language models</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">This research hypothesizes that domain-specific training improves the disruptive potential of large language models by enhancing performance in specialized fields.&lt;SEP&gt;This research investigates whether domain-specific training enhances the disruptive potential of large language models.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shantanu Jain">
  <data key="d0">Shantanu Jain</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shantanu Jain researches AI methodologies, human-in-the-loop learning, and system optimization.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Colin Raffel">
  <data key="d0">Colin Raffel</data>
  <data key="d1">Researcher</data>
  <data key="d2">Colin Raffel is a researcher known for work on transfer learning, language models, and neural network architectures, contributing to foundational advancements in machine learning.&lt;SEP&gt;Colin Raffel is an author involved in research on transfer learning and language models, contributing to foundational studies in machine learning.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Noam Shazeer">
  <data key="d0">Noam Shazeer</data>
  <data key="d1">Researcher</data>
  <data key="d2">Noam Shazeer is a researcher known for work on language models and transfer learning, co-authoring significant papers in the field.&lt;SEP&gt;Noam Shazeer is a researcher specializing in large language models and transfer learning, co-authoring influential studies on model capabilities.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Katherine Lee">
  <data key="d0">Katherine Lee</data>
  <data key="d1">Researcher</data>
  <data key="d2">Katherine Lee is involved in research on transfer learning techniques and language model evaluation.&lt;SEP&gt;Katherine Lee is involved in research related to transfer learning and language model evaluation.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Michael Matena">
  <data key="d0">Michael Matena</data>
  <data key="d1">Researcher</data>
  <data key="d2">Michael Matena contributes to studies on neural network training and transfer learning in NLP.&lt;SEP&gt;Michael Matena is a researcher contributing to language model research and transfer learning studies.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yanqi Zhou">
  <data key="d0">Yanqi Zhou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yanqi Zhou is involved in machine learning research, particularly in transfer learning and language models.&lt;SEP&gt;Yanqi Zhou is involved in research on language model architectures and transfer learning methodologies.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wei Li">
  <data key="d0">Wei Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Wei Li is a researcher working on advancements in natural language processing and transfer learning.&lt;SEP&gt;Wei Li researches natural language processing, transfer learning, and model scaling techniques.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Peter J Liu">
  <data key="d0">Peter J Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Peter J Liu is a researcher contributing to studies on language models and transfer learning.&lt;SEP&gt;Peter J Liu is a researcher working on language model training, transfer learning, and model evaluation.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ori Ram">
  <data key="d0">Ori Ram</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ori Ram is an author of research on retrieval-augmented language models, exploring methods to improve model performance with external data sources.&lt;SEP&gt;Ori Ram is an author of research on retrieval-augmented language models, exploring methods to improve model performance with external data.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Itay Dalmedigos">
  <data key="d0">Itay Dalmedigos</data>
  <data key="d1">Researcher</data>
  <data key="d2">Itay Dalmedigos focuses on language model architectures and retrieval-augmented techniques for improved performance.&lt;SEP&gt;Itay Dalmedigos is a researcher focusing on language model architecture and retrieval-augmented methods.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dor Muhlgay">
  <data key="d0">Dor Muhlgay</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dor Muhlgay contributes to research on language models, especially in retrieval-augmentation and model scaling.&lt;SEP&gt;Dor Muhlgay is a researcher contributing to language model research, particularly in retrieval and augmentation strategies.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Amnon Shashua">
  <data key="d0">Amnon Shashua</data>
  <data key="d1">Researcher</data>
  <data key="d2">Amnon Shashua is a researcher with work in machine learning and language models, contributing to retrieval-augmented approaches.&lt;SEP&gt;Amnon Shashua is involved in machine learning research, including neural network architectures and language models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Arya Rao">
  <data key="d0">Arya Rao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Arya Rao evaluates ChatGPT's effectiveness as an adjunct in radiology and healthcare decision-making.&lt;SEP&gt;Arya Rao is a researcher evaluating the use of ChatGPT in medical decision-making and healthcare applications.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="John Kim">
  <data key="d0">John Kim</data>
  <data key="d1">Researcher</data>
  <data key="d2">John Kim is involved in research assessing language models like ChatGPT in radiology and healthcare contexts.&lt;SEP&gt;John Kim researches AI applications in radiology, focusing on language models for medical decision support.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Meghana Kamineni">
  <data key="d0">Meghana Kamineni</data>
  <data key="d1">Researcher</data>
  <data key="d2">Meghana Kamineni is a researcher exploring AI applications in medical decision support.&lt;SEP&gt;Meghana Kamineni studies AI-assisted radiologic decision-making and healthcare applications.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Michael Pang">
  <data key="d0">Michael Pang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Michael Pang explores AI tools for clinical and radiologic decision-making.&lt;SEP&gt;Michael Pang is engaged in research on AI tools for healthcare and radiologic decision-making.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Winston Lie">
  <data key="d0">Winston Lie</data>
  <data key="d1">Researcher</data>
  <data key="d2">Winston Lie evaluates language models in medical contexts, especially radiology.&lt;SEP&gt;Winston Lie is involved in evaluating language models for healthcare applications.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Marc D Succi">
  <data key="d0">Marc D Succi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Marc D Succi conducts research on AI in radiology and medical decision processes.&lt;SEP&gt;Marc D Succi researches AI integration in radiology and medical diagnostics.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Anastasia Razdaibiedina">
  <data key="d0">Anastasia Razdaibiedina</data>
  <data key="d1">Researcher</data>
  <data key="d2">Anastasia Razdaibiedina researches continual learning and progressive prompting techniques for language models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuning Mao">
  <data key="d0">Yuning Mao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuning Mao develops methods for continual learning and prompts in language models.&lt;SEP&gt;Yuning Mao is a researcher working on continual learning strategies for language models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rui Hou">
  <data key="d0">Rui Hou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of research on IDPG for prompt generation.&lt;SEP&gt;Rui Hou focuses on improving learning strategies and model adaptation in NLP.&lt;SEP&gt;Rui Hou focuses on methods for enhancing language model learning processes.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Madian Khabsa">
  <data key="d0">Madian Khabsa</data>
  <data key="d1">Researcher</data>
  <data key="d2">Madian Khabsa researches language representations for molecular and chemical data.&lt;SEP&gt;Madian Khabsa researches molecular and chemical language representations, capturing molecular structure and properties.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Youssef Mroueh">
  <data key="d0">Youssef Mroueh</data>
  <data key="d1">Researcher</data>
  <data key="d2">Youssef Mroueh contributes to large-scale language representation research.&lt;SEP&gt;Youssef Mroueh researches large-scale language representations and their applications.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Payel Das">
  <data key="d0">Payel Das</data>
  <data key="d1">Researcher</data>
  <data key="d2">Payel Das researches AI models and their applications in chemistry and molecular sciences.&lt;SEP&gt;Payel Das studies AI models in chemistry and molecular sciences.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Malik Sallam">
  <data key="d0">Malik Sallam</data>
  <data key="d1">Researcher</data>
  <data key="d2">Malik Sallam conducts systematic reviews on ChatGPT's utility and limitations in healthcare education and research.&lt;SEP&gt;Malik Sallam conducts systematic reviews on ChatGPT's utility, future perspectives, and limitations in healthcare.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Albert Webson">
  <data key="d0">Albert Webson</data>
  <data key="d1">Researcher</data>
  <data key="d2">Albert Webson contributes to research on prompt-based training and language model capabilities.&lt;SEP&gt;Albert Webson works on prompt engineering, multitask training, and language model capabilities.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stephen Bach">
  <data key="d0">Stephen Bach</data>
  <data key="d1">Researcher</data>
  <data key="d2">Stephen Bach focuses on multitask learning and prompt-based training in NLP.&lt;SEP&gt;Stephen Bach is involved in machine learning research, including multitask training methods.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sheng Shen">
  <data key="d0">Sheng Shen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Sheng Shen focuses on language models and their applications in various AI tasks.&lt;SEP&gt;Sheng Shen researches language models and their application in AI tasks.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zheng Xin Yong">
  <data key="d0">Zheng Xin Yong</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zheng Xin Yong develops techniques for zero-shot and few-shot learning in language models.&lt;SEP&gt;Zheng Xin Yong researches language model training and zero-shot learning techniques.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Han Wang">
  <data key="d0">Han Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Han Wang contributes to large language model development and generalization.&lt;SEP&gt;Han Wang works on large language models and their generalization abilities.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alexander M Rush">
  <data key="d0">Alexander M Rush</data>
  <data key="d1">Researcher</data>
  <data key="d2">Alexander M Rush is a leading researcher in NLP, focusing on language model scaling and capabilities.&lt;SEP&gt;Alexander M Rush is a prominent researcher in natural language processing and large language models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Roberto Dessì">
  <data key="d0">Roberto Dessì</data>
  <data key="d1">Researcher</data>
  <data key="d2">Roberto Dessì focuses on language models and their ability to learn tools and tasks.&lt;SEP&gt;Roberto Dessì focuses on language models' ability to learn tools and perform tasks via prompting.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yongliang Shen">
  <data key="d0">Yongliang Shen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yongliang Shen develops systems like HuggingGPT, integrating ChatGPT with other tools for solving AI tasks.&lt;SEP&gt;Yongliang Shen researches AI systems, including models like HuggingGPT, integrating ChatGPT with other tools.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dongsheng Li">
  <data key="d0">Dongsheng Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dongsheng Li focuses on language model training and multi-task learning.&lt;SEP&gt;Dongsheng Li researches language models and their application in AI tasks.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Weiming Lu">
  <data key="d0">Weiming Lu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Weiming Lu develops multi-model AI systems and frameworks.&lt;SEP&gt;Weiming Lu works on AI systems, including multi-model frameworks.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yueting Zhuang">
  <data key="d0">Yueting Zhuang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yueting Zhuang researches AI models, especially in the context of multi-agent systems and tool use.&lt;SEP&gt;Yueting Zhuang researches multi-agent systems, tool use, and language model interactions.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hanul Shin">
  <data key="d0">Hanul Shin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hanul Shin researches continual learning and deep generative replay in neural networks.&lt;SEP&gt;Hanul Shin researches continual learning, deep generative replay, and neural network universality.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jung Kwon Lee">
  <data key="d0">Jung Kwon Lee</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jung Kwon Lee works on deep learning and continual learning methodologies.&lt;SEP&gt;Jung Kwon Lee works on deep learning, continual learning, and neural network architectures.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jaehong Kim">
  <data key="d0">Jaehong Kim</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jae Hong Kim contributes to neural network research, including generative replay techniques.&lt;SEP&gt;Jaehong Kim contributes to neural network research, including generative replay techniques.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiwon Kim">
  <data key="d0">Jiwon Kim</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiwon Kim researches continual learning and neural network architectures.&lt;SEP&gt;Jiwon Kim researches continual learning, neural network architectures, and model robustness.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kumar Shridhar">
  <data key="d0">Kumar Shridhar</data>
  <data key="d1">Researcher</data>
  <data key="d2">Kumar Shridhar is engaged in machine learning research, possibly related to continual learning or transfer learning.&lt;SEP&gt;Kumar Shridhar is involved in machine learning research, possibly related to continual learning or neural networks.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alessandro">
  <data key="d0">Alessandro</data>
  <data key="d1">Researcher</data>
  <data key="d2">Alessandro is a researcher contributing to AI and machine learning studies, possibly in continual learning or transfer learning.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="GingGPT">
  <data key="d0">GingGPT</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">GingGPT is a language model designed for solving AI tasks, leveraging ChatGPT and its related models within the HuggingFace ecosystem.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="language models">
  <data key="d0">language models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Language models are computational models designed to understand, generate, and process human language, often used in natural language processing tasks.&lt;SEP&gt;Language models are computational systems designed to understand, generate, and process human language, often used in natural language processing, generation, and understanding tasks.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2304.02210">
  <data key="d0">arXiv preprint arXiv:2304.02210</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint publication on arXiv presenting research findings related to language models, including methodology and results.&lt;SEP&gt;A preprint research paper published on arXiv in 2023 presenting findings related to language models, including methodologies, experiments, and results.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruijie Wang, Zheng Li, Dachun Sun, Shengzhong Liu, Jinning Li, Bing Yin, and Tarek Abdelzaher">
  <data key="d0">Ruijie Wang, Zheng Li, Dachun Sun, Shengzhong Liu, Jinning Li, Bing Yin, and Tarek Abdelzaher</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of studies focusing on reasoning over temporal knowledge graphs and related methodologies in language understanding.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Learning to sample and aggregate: Few-shot reasoning over temporal knowledge graphs">
  <data key="d0">Learning to sample and aggregate: Few-shot reasoning over temporal knowledge graphs</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A study exploring methods for few-shot reasoning in temporal knowledge graphs, involving sampling and aggregation techniques.&lt;SEP&gt;A study exploring techniques for few-shot reasoning in temporal knowledge graphs, focusing on sampling and aggregation strategies to improve reasoning performance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Guihong Cao, Daxin Jiang, Ming Zhou, et al.">
  <data key="d0">Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Guihong Cao, Daxin Jiang, Ming Zhou, et al.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a paper on infusing knowledge into pre-trained models using adapters, enhancing language model capabilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="K-adapter: Infusing knowledge into pre-trained models with adapters">
  <data key="d0">K-adapter: Infusing knowledge into pre-trained models with adapters</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A methodology paper proposing the use of adapter modules to infuse external knowledge into large pre-trained language models, enhancing their knowledge capabilities.&lt;SEP&gt;A study proposing adapter-based methods to incorporate external knowledge into language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou">
  <data key="d0">Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of multiple studies on language model reasoning, ensemble techniques, and self-consistency improvements.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rationale-augmented ensembles in language models">
  <data key="d0">Rationale-augmented ensembles in language models</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A study on ensemble methods augmented with rationale explanations to improve reasoning in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Self-Consistency Improves Chain of Thought Reasoning in Language Models">
  <data key="d0">Self-Consistency Improves Chain of Thought Reasoning in Language Models</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A study demonstrating that applying self-consistency techniques enhances the reasoning abilities of large language models, leading to improved performance on complex tasks.&lt;SEP&gt;Research demonstrating that self-consistency techniques enhance reasoning capabilities in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi">
  <data key="d0">Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of studies on aligning language models with self-generated instructions and interactive planning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Self-Instruct: Aligning Language Model with Self Generated Instructions">
  <data key="d0">Self-Instruct: Aligning Language Model with Self Generated Instructions</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A methodology for improving language models by having them generate and follow their own instructions, leading to better alignment and performance.&lt;SEP&gt;A study on methods to align language models with instructions generated by the models themselves for improved performance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yaqing Wang, Subhabrata Mukherjee, Xiaodong Liu, Jing Gao, Ahmed Hassan Awadallah, and Jianfeng Gao">
  <data key="d0">Yaqing Wang, Subhabrata Mukherjee, Xiaodong Liu, Jing Gao, Ahmed Hassan Awadallah, and Jianfeng Gao</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of work on parameter-efficient tuning of large language models using mixture-of-adapters.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adamix: Mixture-of-adapter for parameter-efficient tuning of large language models">
  <data key="d0">Adamix: Mixture-of-adapter for parameter-efficient tuning of large language models</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A study proposing the Adamix technique for efficient adaptation of large language models.&lt;SEP&gt;A technique that uses a mixture-of-adapters to enable efficient fine-tuning of large models with fewer parameters, improving adaptability while preserving capabilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yihan Wang, Si Si, Daliang Li, Michal Lukasik, Felix Yu, Cho-Jui Hsieh, Inderjit S Dhillon, and Sanjiv Kumar">
  <data key="d0">Yihan Wang, Si Si, Daliang Li, Michal Lukasik, Felix Yu, Cho-Jui Hsieh, Inderjit S Dhillon, and Sanjiv Kumar</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of research on preserving in-context learning abilities during large language model fine-tuning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Preserving In-Context Learning ability in Large Language Model Fine-tuning">
  <data key="d0">Preserving In-Context Learning ability in Large Language Model Fine-tuning</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A study on fine-tuning methods that maintain the models' ability to learn from context effectively.&lt;SEP&gt;A study proposing methods to fine-tune large language models without losing their in-context learning capabilities, ensuring better adaptability.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang">
  <data key="d0">Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of research on interactive planning with large language models for multi-task agents.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents">
  <data key="d0">Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A study demonstrating how interactive planning with language models supports multi-task open-world agents.&lt;SEP&gt;A study demonstrating how interactive planning with large language models can support open-world multi-task agents by describing, explaining, planning, and selecting actions.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le">
  <data key="d0">Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of multiple studies on zero-shot learning, emergent abilities, and chain-of-thought prompting in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Finetuned Language Models are Zero-Shot Learners">
  <data key="d0">Finetuned Language Models are Zero-Shot Learners</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A seminal paper demonstrating that fine-tuned large language models exhibit strong zero-shot learning abilities across diverse tasks.&lt;SEP&gt;Research showing that fine-tuned language models can perform zero-shot tasks effectively.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Emergent abilities of large language models">
  <data key="d0">Emergent abilities of large language models</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A study analyzing the unexpected capabilities that large language models develop as they scale.&lt;SEP&gt;A study analyzing the unexpected capabilities that large models develop as they scale, including reasoning, translation, and problem-solving skills.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chain-of-Thought Prompting Elicits Reasoning in Large Language Models">
  <data key="d0">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A key methodology demonstrating that chain-of-thought prompting improves reasoning in language models.&lt;SEP&gt;A methodology that prompts models to generate intermediate reasoning steps, significantly improving their performance on complex reasoning tasks.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stephen Wolfram">
  <data key="d0">Stephen Wolfram</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author discussing enhancements to ChatGPT with Wolfram's computational powers.&lt;SEP&gt;Author discussing the integration of Wolfram's computational powers into ChatGPT, enhancing its reasoning and calculation abilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ChatGPT Gets Its “Wolfram Superpowers”!">
  <data key="d0">ChatGPT Gets Its “Wolfram Superpowers”!</data>
  <data key="d1">Article</data>
  <data key="d2">An article describing how ChatGPT has been enhanced with Wolfram's computational engine, enabling advanced calculations and reasoning.&lt;SEP&gt;An article describing how ChatGPT integrates Wolfram's computational capabilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann">
  <data key="d0">Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a study on BloombergGPT, a large language model tailored for financial applications.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bloomberggpt: A large language model for finance">
  <data key="d0">Bloomberggpt: A large language model for finance</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A domain-specific large language model designed to handle financial data, analysis, and natural language tasks in finance.&lt;SEP&gt;A study on a large language model specialized for financial data and tasks.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhuofeng Wu, Sinong Wang, Jiatao Gu, Rui Hou, Yuxiao Dong, V. G. Vinod Vydiswaran, and Hao Ma">
  <data key="d0">Zhuofeng Wu, Sinong Wang, Jiatao Gu, Rui Hou, Yuxiao Dong, V. G. Vinod Vydiswaran, and Hao Ma</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a paper on IDPG, an instance-dependent prompt generation method for language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="IDPG: An Instance-Dependent Prompt Generation Method">
  <data key="d0">IDPG: An Instance-Dependent Prompt Generation Method</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A methodology for generating prompts tailored to specific instances to improve language model performance.&lt;SEP&gt;A novel prompt generation approach that creates tailored prompts based on specific instances to enhance model accuracy and efficiency.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Runxin Xu, Fuli Luo, Zhiyuan Zhang, Chuanqi Tan, Baobao Chang, Songfang Huang, and Fei Huang">
  <data key="d0">Runxin Xu, Fuli Luo, Zhiyuan Zhang, Chuanqi Tan, Baobao Chang, Songfang Huang, and Fei Huang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of research on effective fine-tuning of large language models for generalizability.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Raise a child in large language model: Towards effective and generalizable fine-tuning">
  <data key="d0">Raise a child in large language model: Towards effective and generalizable fine-tuning</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A study proposing methods for fine-tuning language models to enhance their adaptability and generalization.&lt;SEP&gt;A study proposing methods for fine-tuning large language models that preserve their ability to learn from in-context examples, improving generalization.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jingfeng Yang, Haoming Jiang, Qingyu Yin, Danqing Zhang, Bing Yin, and Diyi Yang">
  <data key="d0">Jingfeng Yang, Haoming Jiang, Qingyu Yin, Danqing Zhang, Bing Yin, and Diyi Yang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of work on semantic parsing and few-shot learning with sequential prompts.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="SEQZERO: Few-shot Compositional Semantic Parsing with Sequential Prompts and Zero-shot Models">
  <data key="d0">SEQZERO: Few-shot Compositional Semantic Parsing with Sequential Prompts and Zero-shot Models</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A methodology for semantic parsing using sequential prompts to improve few-shot and zero-shot performance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruijie Wang">
  <data key="d0">Ruijie Wang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in studies on reasoning over temporal knowledge graphs and sampling techniques in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zheng Li">
  <data key="d0">Zheng Li</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in studies on reasoning over temporal knowledge graphs and sampling techniques in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dachun Sun">
  <data key="d0">Dachun Sun</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in studies on reasoning over temporal knowledge graphs and sampling techniques in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shengzhong Liu">
  <data key="d0">Shengzhong Liu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in studies on reasoning over temporal knowledge graphs and sampling techniques in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jinning Li">
  <data key="d0">Jinning Li</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in studies on reasoning over temporal knowledge graphs and sampling techniques in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bing Yin">
  <data key="d0">Bing Yin</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to semantic parsing and NLP model research.&lt;SEP&gt;Author involved in research on semantic parsing and language understanding.&lt;SEP&gt;Author involved in studies on reasoning over temporal knowledge graphs and sampling techniques in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tarek Abdelzaher">
  <data key="d0">Tarek Abdelzaher</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in studies on reasoning over temporal knowledge graphs and sampling techniques in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruize Wang">
  <data key="d0">Ruize Wang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on knowledge infusion into pre-trained models using adapters.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Duyu Tang">
  <data key="d0">Duyu Tang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on knowledge infusion into pre-trained models using adapters.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhongyu Wei">
  <data key="d0">Zhongyu Wei</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on knowledge infusion into pre-trained models using adapters.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Guihong Cao">
  <data key="d0">Guihong Cao</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on knowledge infusion into pre-trained models using adapters.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Daxin Jiang">
  <data key="d0">Daxin Jiang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on knowledge infusion into pre-trained models using adapters.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ming Zhou">
  <data key="d0">Ming Zhou</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on knowledge infusion into pre-trained models using adapters.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yizhong Wang">
  <data key="d0">Yizhong Wang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in studies on aligning language models with self-generated instructions and interactive planning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yeganeh Kordi">
  <data key="d0">Yeganeh Kordi</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in studies on aligning and instructing language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Swaroop Mishra">
  <data key="d0">Swaroop Mishra</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in studies on instruction alignment and model behavior.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alisa Liu">
  <data key="d0">Alisa Liu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in studies on instruction tuning and alignment in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Noah A. Smith">
  <data key="d0">Noah A. Smith</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on instruction alignment and natural language understanding.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Daniel Khashabi">
  <data key="d0">Daniel Khashabi</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on instruction tuning and model alignment.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hannaneh Hajishirzi">
  <data key="d0">Hannaneh Hajishirzi</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on instruction alignment and reasoning in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Subhabrata Mukherjee">
  <data key="d0">Subhabrata Mukherjee</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on efficient fine-tuning of large language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xiaodong Liu">
  <data key="d0">Xiaodong Liu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on efficient tuning and adaptation of language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jing Gao">
  <data key="d0">Jing Gao</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on tuning large language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ahmed Hassan Awadallah">
  <data key="d0">Ahmed Hassan Awadallah</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on language model adaptation and tuning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yihan Wang">
  <data key="d0">Yihan Wang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on preserving in-context learning abilities during fine-tuning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Si Si">
  <data key="d0">Si Si</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on maintaining in-context learning in fine-tuned models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Daliang Li">
  <data key="d0">Daliang Li</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on model fine-tuning and in-context learning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Michal Lukasik">
  <data key="d0">Michal Lukasik</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on language model fine-tuning and capabilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Felix Yu">
  <data key="d0">Felix Yu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on model fine-tuning and in-context abilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Cho-Jui Hsieh">
  <data key="d0">Cho-Jui Hsieh</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on model fine-tuning and in-context learning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Inderjit S Dhillon">
  <data key="d0">Inderjit S Dhillon</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on fine-tuning large language models while preserving capabilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sanjiv Kumar">
  <data key="d0">Sanjiv Kumar</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on model fine-tuning and in-context learning preservation.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zihao Wang">
  <data key="d0">Zihao Wang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on interactive planning with large language models for multi-task agents.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shaofei Cai">
  <data key="d0">Shaofei Cai</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on interactive multi-task planning with language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Anji Liu">
  <data key="d0">Anji Liu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on multi-task agents and planning with language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xiaojian Ma">
  <data key="d0">Xiaojian Ma</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on multi-task agents and planning with language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yitao Liang">
  <data key="d0">Yitao Liang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on interactive planning and multi-task agents using language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Vincent Zhao">
  <data key="d0">Vincent Zhao</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on large language model capabilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adams Wei Yu">
  <data key="d0">Adams Wei Yu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on zero-shot and few-shot learning in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Brian Lester">
  <data key="d0">Brian Lester</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on large language models and their capabilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Quoc V Le">
  <data key="d0">Quoc V Le</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in foundational work on large language models, prompting, and reasoning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shijie Wu">
  <data key="d0">Shijie Wu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on BloombergGPT, a large language model tailored for financial applications, integrating domain-specific knowledge.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ozan Irsoy">
  <data key="d0">Ozan Irsoy</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on BloombergGPT for finance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Steven Lu">
  <data key="d0">Steven Lu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on BloombergGPT for finance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Vadim Dabravolski">
  <data key="d0">Vadim Dabravolski</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on BloombergGPT for finance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mark Dredze">
  <data key="d0">Mark Dredze</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on BloombergGPT for finance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prabhanjan Kambadur">
  <data key="d0">Prabhanjan Kambadur</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on BloombergGPT for finance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="David Rosenberg">
  <data key="d0">David Rosenberg</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on BloombergGPT for finance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Gideon Mann">
  <data key="d0">Gideon Mann</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on BloombergGPT for finance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhuofeng Wu">
  <data key="d0">Zhuofeng Wu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on IDPG, a prompt generation method tailored to specific instances to improve language model performance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sinong Wang">
  <data key="d0">Sinong Wang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on IDPG for prompt generation.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuxiao Dong">
  <data key="d0">Yuxiao Dong</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on IDPG for prompt generation.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="V. G. Vinod Vydiswaran">
  <data key="d0">V. G. Vinod Vydiswaran</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on IDPG for prompt generation.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hao Ma">
  <data key="d0">Hao Ma</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author of research on IDPG for prompt generation.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Runxin Xu">
  <data key="d0">Runxin Xu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on fine-tuning large language models for effective and generalizable performance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fuli Luo">
  <data key="d0">Fuli Luo</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on fine-tuning large language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhiyuan Zhang">
  <data key="d0">Zhiyuan Zhang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on model fine-tuning and generalization.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chuanqi Tan">
  <data key="d0">Chuanqi Tan</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on effective fine-tuning methods.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Baobao Chang">
  <data key="d0">Baobao Chang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on model fine-tuning and generalization.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Songfang Huang">
  <data key="d0">Songfang Huang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on fine-tuning large language models for broad applicability.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fei Huang">
  <data key="d0">Fei Huang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author involved in research on effective fine-tuning of language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jingfeng Yang">
  <data key="d0">Jingfeng Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher involved in developing semantic parsing models and conducting surveys on large language models.&lt;SEP&gt;Author involved in research on semantic parsing and few-shot learning with sequential prompts.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Haoming Jiang">
  <data key="d0">Haoming Jiang</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher contributing to the development of semantic parsing and language model applications.&lt;SEP&gt;Author involved in research on semantic parsing and few-shot learning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Qingyu Yin">
  <data key="d0">Qingyu Yin</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher involved in semantic parsing research and computational linguistics.&lt;SEP&gt;Author involved in research on semantic parsing and model capabilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Danqing Zhang">
  <data key="d0">Danqing Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher working on compositional semantic parsing and related methodologies.&lt;SEP&gt;A researcher working on compositional semantic parsing techniques.&lt;SEP&gt;Author involved in research on semantic parsing and model performance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Diyi Yang">
  <data key="d0">Diyi Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher involved in semantic parsing and NLP applications.&lt;SEP&gt;A researcher involved in semantic parsing research and surveys on NLP models.&lt;SEP&gt;Author involved in research on semantic parsing, few-shot learning, and model generalization.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Preprint arXiv:2109.05687">
  <data key="d0">Preprint arXiv:2109.05687</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A preprint publication from arXiv presenting research related to computational linguistics and semantic parsing.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Findings of the Association for Computational Linguistics: NAACL 2022">
  <data key="d0">Findings of the Association for Computational Linguistics: NAACL 2022</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference publication presenting recent research findings in computational linguistics, including semantic parsing and large language models.&lt;SEP&gt;A conference publication presenting research findings on semantic parsing and language models.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="SEZERO">
  <data key="d0">SEZERO</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A few-shot compositional semantic parsing framework utilizing sequential prompts and zero-shot models.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Survey on ChatGPT and Beyond">
  <data key="d0">Survey on ChatGPT and Beyond</data>
  <data key="d1">Study Design</data>
  <data key="d2">A comprehensive survey analyzing ChatGPT and similar models' capabilities, limitations, and practical applications.&lt;SEP&gt;A survey examining the practical use, capabilities, and limitations of ChatGPT and similar models.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Credibility Rating of News Outlets">
  <data key="d0">Credibility Rating of News Outlets</data>
  <data key="d1">Variables</data>
  <data key="d2">A task where large language models evaluate and rate the credibility of news sources, testing their ability to assess information trustworthiness.&lt;SEP&gt;A task where large language models rate the credibility of news sources, assessing model performance in evaluating information trustworthiness.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ontology-enhanced Prompt-tuning">
  <data key="d0">Ontology-enhanced Prompt-tuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompt-tuning technique that incorporates ontological knowledge to improve few-shot learning in language models.&lt;SEP&gt;A technique that incorporates ontological knowledge into prompt tuning to improve few-shot learning.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bitfit">
  <data key="d0">Bitfit</data>
  <data key="d1">Methodology</data>
  <data key="d2">A parameter-efficient fine-tuning method for transformer-based language models, focusing on minimal parameter updates.&lt;SEP&gt;A parameter-efficient fine-tuning method that updates only a small subset of parameters in transformer models, making fine-tuning more resource-efficient.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hypercomplex Multiplications">
  <data key="d0">Hypercomplex Multiplications</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Parameterization techniques for neural network layers using quaternion and other hypercomplex algebra to optimize model parameters.&lt;SEP&gt;Parameterization techniques for neural networks that use quaternion or other hypercomplex algebra to optimize model parameters and reduce complexity.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Generative AI (AIGC)">
  <data key="d0">Generative AI (AIGC)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Artificial intelligence systems capable of generating new content such as text, images, and videos, with recent focus on models like GPT-4 and GPT-5.&lt;SEP&gt;Artificial intelligence systems capable of generating new content, including text, images, and other media, with recent surveys discussing GPT-4, GPT-5, and related models.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fine-Tuning Pre-Trained Language Models">
  <data key="d0">Fine-Tuning Pre-Trained Language Models</data>
  <data key="d1">Methodology</data>
  <data key="d2">Techniques for adapting large pre-trained models to specific tasks by optimizing subnetworks or parameters efficiently.&lt;SEP&gt;Techniques for adapting large, pre-trained language models to specific tasks by optimizing selected subnetworks or parameters efficiently.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Llama-adapter">
  <data key="d0">Llama-adapter</data>
  <data key="d1">Tools</data>
  <data key="d2">An efficient adapter-based method for fine-tuning large language models with zero-initialized attention, enabling resource-effective adaptation.&lt;SEP&gt;An efficient fine-tuning approach for large language models utilizing zero-initialized attention mechanisms.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Unsupervised Domain Adaptation">
  <data key="d0">Unsupervised Domain Adaptation</data>
  <data key="d1">Study Design</data>
  <data key="d2">A method for adapting models trained on one domain to perform well on another without labeled data, using adapters.&lt;SEP&gt;A method for transferring knowledge from one domain to another without labeled data, often using adapters or other techniques to improve cross-domain performance.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Automatic Chain of Thought Prompting">
  <data key="d0">Automatic Chain of Thought Prompting</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompting strategy that encourages models to generate intermediate reasoning steps, enabling complex reasoning tasks in large language models.&lt;SEP&gt;A prompting technique that enables large language models to perform complex reasoning by generating intermediate reasoning steps.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Survey of Large Language Models">
  <data key="d0">Survey of Large Language Models</data>
  <data key="d1">Study Design</data>
  <data key="d2">A comprehensive review of the development, capabilities, and challenges of large language models as of 2023.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Least-to-Most Prompting">
  <data key="d0">Least-to-Most Prompting</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompting approach that decomposes complex tasks into simpler sub-tasks, enabling models to perform multi-step reasoning effectively.&lt;SEP&gt;A prompting strategy that enables complex reasoning by decomposing tasks into simpler steps in large language models.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ChatGPT and Environmental Research">
  <data key="d0">ChatGPT and Environmental Research</data>
  <data key="d1">Study</data>
  <data key="d2">Research examining the applications and implications of ChatGPT in environmental studies.&lt;SEP&gt;Research exploring the application of ChatGPT in environmental studies, including environmental data analysis and communication.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fine-Tuning from Human Preferences">
  <data key="d0">Fine-Tuning from Human Preferences</data>
  <data key="d1">Methodology</data>
  <data key="d2">An approach for aligning language models with human values and preferences through targeted fine-tuning.&lt;SEP&gt;An approach that aligns language models with human values by fine-tuning on human feedback and preferences to improve output quality.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="SEQZERO">
  <data key="d0">SEQZERO</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A few-shot compositional semantic parsing framework that uses sequential prompts and zero-shot models to improve parsing accuracy and efficiency.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="A Survey of Large Language Models">
  <data key="d0">A Survey of Large Language Models</data>
  <data key="d1">Study Design</data>
  <data key="d2">A comprehensive review summarizing the development, capabilities, limitations, and future directions of large language models as of 2023.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ChatGPT and environmental research">
  <data key="d0">ChatGPT and environmental research</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This explores the application of ChatGPT, an advanced language model, within environmental research activities, including its potential, limitations, and implications.&lt;SEP&gt;This refers to the application and implications of ChatGPT technology within environmental research activities.</data>
  <data key="d3">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Environmental Science &amp; Technology">
  <data key="d0">Environmental Science &amp; Technology</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A peer-reviewed scientific journal that publishes research articles and studies related to environmental science, technology, and policy.&lt;SEP&gt;A scientific journal publishing research related to environmental science and technology.</data>
  <data key="d3">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei, Paul Christiano, Geoffrey Irving">
  <data key="d0">Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei, Paul Christiano, Geoffrey Irving</data>
  <data key="d1">Researchers</data>
  <data key="d2">A group of researchers involved in developing and fine-tuning language models, including work on human preferences.&lt;SEP&gt;A team of scientists and engineers involved in developing, fine-tuning, and evaluating language models, including work on aligning models with human preferences.</data>
  <data key="d3">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fine-tuning language models from human preferences">
  <data key="d0">Fine-tuning language models from human preferences</data>
  <data key="d1">Theoretical/Model</data>
  <data key="d2">A methodology for improving language models by adjusting them based on human feedback to better align outputs with human values and preferences.&lt;SEP&gt;A theoretical framework and methodology for improving language models by adjusting their outputs based on human feedback, aiming to make AI responses more aligned with human values and expectations.</data>
  <data key="d3">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:1909.08593">
  <data key="d0">arXiv preprint arXiv:1909.08593</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint publication providing foundational research on language model fine-tuning techniques.&lt;SEP&gt;A preprint publication that provides empirical and methodological evidence supporting the process of fine-tuning language models based on human preferences.</data>
  <data key="d3">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Training and Fine-tuning">
  <data key="d0">Training and Fine-tuning</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d2">High computational resources are essential for training and fine-tuning large-scale LLMs effectively.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Analysis Techniques">
  <data key="d0">Analysis Techniques</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d2">Evaluation techniques are used to measure the effectiveness of domain adaptation methods, guiding improvements."|&gt;"performance assessment, benchmarking</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Performance Enhancement">
  <data key="d0">Performance Enhancement</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d2">Scaling models by increasing size or data improves their capacity for downstream tasks, facilitating better domain adaptation and generalization.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Application Improvement">
  <data key="d0">Application Improvement</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d2">Specialization techniques tailor LLMs to specific domains, improving accuracy and relevance for targeted NLP tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Challenge">
  <data key="d0">Challenge</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d2">Updating knowledge in LLMs is complex and computationally expensive, impacting their ability to incorporate new information efficiently.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Implication">
  <data key="d0">Implication</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d2">Applying generic LLMs without domain-specific tuning can result in inaccuracies and lack of originality, emphasizing the importance of specialization.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sequence-to-Sequence Tasks">
  <data key="d0">Sequence-to-Sequence Tasks</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d2">T5 exemplifies a model designed for sequence-to-sequence tasks like translation and summarization, illustrating its core concept and application.&lt;SEP&gt;T5 is designed for sequence-to-sequence NLP tasks such as translation and summarization, exemplifying core concepts in NLP models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Techniques">
  <data key="d0">Techniques</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d2">The taxonomy categorizes approaches into external augmentation, prompt crafting, and model fine-tuning, each suited for different levels of model access and control."|&lt;SEP&gt;The taxonomy categorizes domain specialization approaches into external augmentation, prompt crafting, and model fine-tuning, each suited to different levels of model access and control."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Knowledge Utilization">
  <data key="d0">Domain Knowledge Utilization</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d2">Prompt crafting involves designing prompts that guide LLMs to better utilize domain knowledge during inference.&lt;SEP&gt;Prompt crafting involves designing prompts that guide LLMs to leverage domain knowledge during inference.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter Updating">
  <data key="d0">Parameter Updating</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d2">Model fine-tuning directly modifies the internal parameters of an LLM to incorporate domain-specific knowledge.&lt;SEP&gt;Model fine-tuning directly updates the internal parameters of LLMs to incorporate domain-specific knowledge.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Evaluation and Feedback">
  <data key="d0">Evaluation and Feedback</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d2">Evaluation mechanisms include benchmarks, dynamic assessments, and user feedback to guide domain adaptation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Utilizes">
  <data key="d0">Utilizes</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d2">The neural retriever employs similarity metrics to search knowledge bases for relevant information based on queries."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Contains">
  <data key="d0">Contains</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d2">Knowledge bases like Wikidata or Wikipedia contain the domain-specific information retrieved and used to augment LLMs."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Enhances">
  <data key="d0">Enhances</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d2">Retrieving explicit knowledge from external sources enhances the accuracy and relevance of model predictions for domain-specific tasks."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stores">
  <data key="d0">Stores</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d2">Implicit knowledge is stored as vectorized embeddings learned during pre-training, representing complex data patterns."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Uses">
  <data key="d0">Uses</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d2">Attention mechanisms are used to retrieve task-related implicit knowledge by calculating relevance scores between queries and stored embeddings."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Creates">
  <data key="d0">Creates</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d2">An instruction cycle involves retrieving implicit knowledge, parsing outputs, and storing variable assignments for complex problem-solving."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Incorporates">
  <data key="d0">Incorporates</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d2">External knowledge, both explicit and implicit, is incorporated into LLMs to improve performance, flexibility, and lifelong learning capabilities."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Challenges">
  <data key="d0">Challenges</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d2">Integrating external knowledge into LLMs faces challenges like relevance, completeness, and conflict resolution."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multi-tool Use">
  <data key="d0">Multi-tool Use</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d2">LLMs act as task planners to decompose a complex task into subtasks, coordinate multiple domain tools, and generate executable commands for precise problem solving.&lt;SEP&gt;LLMs act as task planners to decompose complex tasks into subtasks, coordinate multiple domain tools, and generate executable commands for precise problem solving.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="&lt;&quot;Task Planners">
  <data key="d0">&lt;"Task Planners</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d2">LLMs are conceptualized as controllers or API selectors that manage multiple tools to decompose and coordinate complex tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LLMs as Controllers">
  <data key="d0">LLMs as Controllers</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d2">LLMs are conceptualized as controllers or API selectors that manage multiple tools to decompose and coordinate complex tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="&lt;&quot;Automated Theorem Proving Frameworks">
  <data key="d0">&lt;"Automated Theorem Proving Frameworks</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d2">DSP uses LLMs and formal tools to draft, sketch, and prove mathematical conjectures, illustrating a multi-stage process.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="DSP Framework">
  <data key="d0">DSP Framework</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d2">DSP uses LLMs and formal tools to draft, sketch, and prove mathematical conjectures, illustrating a multi-stage process.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LLMs as controllers">
  <data key="d0">LLMs as controllers</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d2">LLMs are modeled as controllers or API selectors that manage multiple tools to decompose and coordinate complex tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="DSP framework">
  <data key="d0">DSP framework</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d2">The DSP framework employs LLMs to draft informal proofs, generate formal sketches, and verify conjectures with provers, illustrating multi-stage reasoning.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LLMs embodied in robots">
  <data key="d0">LLMs embodied in robots</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d2">LLMs embedded in robots enable decision-making, perception, and interaction capabilities, supporting physical and social tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Physics engines">
  <data key="d0">Physics engines</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d2">Physics engines provide simulated physical environments that grounded LLM reasoning can utilize for physics-based tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="multi-agent collaboration">
  <data key="d0">multi-agent collaboration</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d2">Multiple LLMs and AI agents can collaborate and communicate, but effective frameworks and protocols are still under development.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="prompt crafting">
  <data key="d0">prompt crafting</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d2">Prompt engineering enhances LLMs' ability to perform accurately within specific domains by designing tailored prompts.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot CoT">
  <data key="d0">Zero-shot CoT</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d2">Zero-shot Chain-of-Thought prompts enhance the reasoning process of LLMs by encouraging multi-step logical thinking.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Relation Extraction">
  <data key="d0">Relation Extraction</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d2">Uses templates with '[MASK]' tokens and virtual type words to align entity types with relations during training.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Event Detection">
  <data key="d0">Event Detection</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d2">Identifies trigger words based on semantic similarity to event concepts, reformulating sequence tagging into generative tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Terms">
  <data key="d0">Domain Terms</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d2">Prompt-tuning discovers prompt tokens near domain-related terms, improving relevance and interpretability in specific domains.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Derivative-free Optimization">
  <data key="d0">Derivative-free Optimization</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d2">BBT uses CMA-ES to search for optimal prompts without gradient information, suitable for black-box models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Derivative-free Approaches">
  <data key="d0">Derivative-free Approaches</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d2">Discrete prompt search methods aim to optimize prompts without gradient information, especially relevant when only textual queries are permitted.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Methods">
  <data key="d0">Methods</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d2">Fine-tuning approaches, including adapter-based and task-oriented, tailor LLMs for specific domains or tasks by adjusting model parameters.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LoRA">
  <data key="d0">LoRA</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d2">KronA addresses the limited representation power of LoRA by substituting SVD modules with Kronecker product modules of smaller matrices.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="DyLora">
  <data key="d0">DyLora</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d2">DyLora enhances LoRA by using dynamic search to find optimal rank and block size, improving adaptation performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multiple Adapters">
  <data key="d0">Multiple Adapters</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d2">AdapterFusion combines multiple adapters trained on different tasks via a fusion layer to boost multi-task performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapter Methods">
  <data key="d0">Adapter Methods</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d2">UniPELT activates different combinations of adapter methods based on data or task needs, optimizing adaptation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Libraries">
  <data key="d0">Libraries</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d2">Libraries like AdapterHub and LLM-adapters provide tools for implementing and managing adapter modules across models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Reinforcement Learning from Human Feedback">
  <data key="d0">Reinforcement Learning from Human Feedback</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d2">RLHF aligns LLM outputs with human preferences through iterative feedback and reward-based updates.&lt;SEP&gt;RLHF aligns LLM outputs with human preferences through iterative feedback, ranking, and policy updates.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="High-quality Datasets">
  <data key="d0">High-quality Datasets</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d2">Domain-specific datasets are essential for effective task-oriented fine-tuning of LLMs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="High-Confidence Answers">
  <data key="d0">High-Confidence Answers</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d2">Generating high-confidence, rationale-augmented answers enhances the model's reasoning abilities without relying on ground truth labels.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Improving Reasoning">
  <data key="d0">Improving Reasoning</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d2">Generating high-confidence, rationale-augmented answers enhances the model's reasoning abilities without relying on ground truth labels.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Application in Social Sciences">
  <data key="d0">Application in Social Sciences</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d2">Applications in social sciences utilize domain-specific knowledge extracted or distilled from LLMs to perform tasks like information extraction and predictions."|&gt;"application, domain expertise</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Application in Natural Sciences">
  <data key="d0">Application in Natural Sciences</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d2">LLMs are applied in biomedicine for analyzing genomic data, predicting protein structures, and supporting drug discovery."|&gt;"domain application, biomedical research</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Biomedicine">
  <data key="d0">Biomedicine</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d2">LLMs are applied in biomedicine for analyzing genomic data, predicting protein structures, and supporting drug discovery."|&gt;"domain application, biomedical research</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Application in Formal Sciences">
  <data key="d0">Application in Formal Sciences</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d2">LLMs assist in code generation, bug detection, and analysis, enhancing productivity and accuracy."|&gt;"technical application, software development</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Software Engineering">
  <data key="d0">Software Engineering</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d2">LLMs assist in code generation, bug detection, and analysis, enhancing productivity and accuracy."|&gt;"technical application, software development</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Spatial information">
  <data key="d0">Spatial information</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d2">Earth science relies on spatial information and geographic tools to study climate, land-use, and environmental phenomena.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Human-Computer Interaction and Software Engineering">
  <data key="d0">Human-Computer Interaction and Software Engineering</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d2">LLMs are specialized to improve understanding of user inputs and assist in code-related tasks, enhancing software development.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Specialization">
  <data key="d0">Specialization</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d2">LLMs are specialized to improve understanding of user inputs and assist in code-related tasks, enhancing software development.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Activation Functions">
  <data key="d0">Activation Functions</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d2">Dan Hendrycks introduced GELUs, affecting neural network activation techniques.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jeremy Howard">
  <data key="d0">Jeremy Howard</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d2">Jeremy Howard's work on universal language model fine-tuning impacts NLP methodologies.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Distillation">
  <data key="d0">Model Distillation</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d2">Cheng-Yu Hsieh's research on distilling large models aims to outperform bigger models with less data.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Self-Improvement">
  <data key="d0">Self-Improvement</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d2">Jiaxin Huang's work suggests large language models can self-improve.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Designs Chemical Reaction Arrays">
  <data key="d0">Designs Chemical Reaction Arrays</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d2">ChatGPT supports the design of chemical reaction arrays by providing computational assistance and automating parts of the process.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Unipelt">
  <data key="d0">Unipelt</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d2">Unipelt provides a framework for parameter-efficient tuning of language models, improving their performance on specific tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="DIN-SQL">
  <data key="d0">DIN-SQL</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d2">DIN-SQL employs self-correction techniques to enhance text-to-SQL performance in in-context learning scenarios.&lt;SEP&gt;DIN-SQL employs self-correction techniques to improve the accuracy of text-to-SQL translation in in-context learning.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Self-Correction">
  <data key="d0">Self-Correction</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d2">DIN-SQL employs self-correction techniques to enhance text-to-SQL performance in in-context learning scenarios.&lt;SEP&gt;DIN-SQL employs self-correction techniques to improve the accuracy of text-to-SQL translation in in-context learning.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="GrIPS">
  <data key="d0">GrIPS</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d2">GrIPS is used for searching effective prompts in instruction tuning, improving prompt engineering processes.&lt;SEP&gt;GrIPS is used to identify effective prompts for instruction tuning and prompt engineering.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Search">
  <data key="d0">Prompt Search</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d2">GrIPS is used for searching effective prompts in instruction tuning, improving prompt engineering processes.&lt;SEP&gt;GrIPS is used to identify effective prompts for instruction tuning and prompt engineering.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Legal Decision Classification">
  <data key="d0">Legal Decision Classification</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d2">Hierarchical domain-specific language models are applied to classify decisions in legal cases, leveraging hierarchical attention mechanisms.&lt;SEP&gt;These models are applied to classify decisions in legal cases with hierarchical domain knowledge and attention mechanisms.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LFPT5">
  <data key="d0">LFPT5</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d2">LFPT5 uses prompt tuning of the T5 model for lifelong, few-shot language learning tasks.&lt;SEP&gt;LFPT5 utilizes prompt tuning of T5 for lifelong and few-shot learning scenarios.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tool Learning">
  <data key="d0">Tool Learning</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d2">Research indicates foundation models can learn to utilize external tools effectively, enhancing their capabilities.&lt;SEP&gt;Research indicates that foundation models can learn to utilize external tools, enhancing their task performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Generation of human-like behavior">
  <data key="d0">Generation of human-like behavior</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d2">Generative Agents are designed to simulate human behaviors and interactions for research and testing purposes.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kai-Cheng Yang and Filippo Menczer">
  <data key="d0">Kai-Cheng Yang and Filippo Menczer</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They studied the ability of large language models to rate news outlet credibility."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xianjun Yang et al.">
  <data key="d0">Xianjun Yang et al.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They proposed a unified framework for prompt tuning, including dynamic prompt strategies."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hongbin Ye et al.">
  <data key="d0">Hongbin Ye et al.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They developed ontology-enhanced prompt tuning for few-shot learning."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Elad Ben Zaken et al.">
  <data key="d0">Elad Ben Zaken et al.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They introduced Bitfit, a simple parameter-efficient fine-tuning method."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhang et al. 2023">
  <data key="d0">Zhang et al. 2023</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They provided a comprehensive survey on generative AI models, including GPT series."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Haojie Zhang et al.">
  <data key="d0">Haojie Zhang et al.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They optimized subnetworks for effective fine-tuning of pre-trained language models."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Renrui Zhang et al.">
  <data key="d0">Renrui Zhang et al.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They proposed Llama-adapter for efficient zero-init attention fine-tuning."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chain of Thought Prompting">
  <data key="d0">Chain of Thought Prompting</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They developed automatic chain of thought prompting to improve reasoning in large language models."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhuosheng Zhang et al.">
  <data key="d0">Zhuosheng Zhang et al.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They developed automatic chain of thought prompting to improve reasoning in large language models."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hongyu Zhao et al.">
  <data key="d0">Hongyu Zhao et al.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They designed Tiny-Attention Adapter focusing on contextual importance."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Survey">
  <data key="d0">Survey</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They conducted a survey summarizing the state of large language models as of 2023."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wayne Xin Zhao et al.">
  <data key="d0">Wayne Xin Zhao et al.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They conducted a survey summarizing the state of large language models as of 2023."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Denny Zhou et al.">
  <data key="d0">Denny Zhou et al.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They introduced least-to-most prompting for complex reasoning tasks."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jun-Jie Zhu et al.">
  <data key="d0">Jun-Jie Zhu et al.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They examined ChatGPT's applications in environmental research."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Daniel M Ziegler et al.">
  <data key="d0">Daniel M Ziegler et al.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">They explored fine-tuning language models based on human preferences."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Codex">
  <data key="d0">Codex</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A GPT language model fine-tuned on publicly available code from GitHub, designed to generate, synthesize, and evaluate code, particularly Python, and to analyze its capabilities and limitations.&lt;SEP&gt;A large language model trained on code, used for code generation, evaluation, and fine-tuning tasks, with performance metrics like pass@k to measure success.&lt;SEP&gt;A large language model trained specifically for code generation tasks, capable of solving programming problems, but with noted limitations in efficiency, correctness, and system-level understanding.&lt;SEP&gt;Codex is a GPT language model fine-tuned on publicly available code from GitHub, designed to generate and synthesize code, particularly Python, and evaluate its capabilities and limitations.&lt;SEP&gt;Codex is a fine-tuned version of GPT-3 designed specifically to generate code, demonstrating performance on datasets like HumanEval.&lt;SEP&gt;Codex is a large language model trained on code, designed to assist with code generation, documentation, testing, and decision-making in programming tasks.&lt;SEP&gt;Codex is a large language model trained specifically on code, used for tasks such as code generation, evaluation, and fine-tuning, with performance metrics like pass@k.&lt;SEP&gt;Codex is a large language model trained to generate code, capable of solving programming problems, but with notable limitations in efficiency, correctness, and system-level understanding.&lt;SEP&gt;Codex is a specialized GPT model designed to excel at coding tasks, powering tools like GitHub Copilot and models in the OpenAI API, and trained on code datasets.&lt;SEP&gt;Codex is a specialized variant of GPT designed explicitly for code generation tasks, trained on a large corpus of code to excel at programming-related activities.&lt;SEP&gt;Codex is a specialized, fine-tuned GPT-3 model optimized for code generation, trained on large datasets of source code to perform programming tasks.&lt;SEP&gt;Codex is an AI language model specialized in code generation, capable of assisting with programming tasks, but also posing potential security risks and misuse applications.&lt;SEP&gt;Codex is an AI model designed to generate code, assist with programming tasks, and produce code snippets, with implications for security and productivity.&lt;SEP&gt;Codex is an AI-powered code generation model that produces programming code, assists developers, and can create insecure cryptographic configurations if not carefully managed.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-735818e62b066d03c2144cdb5db162c1&lt;SEP&gt;chunk-d25502af8737c59d857916af40cc4020&lt;SEP&gt;chunk-bf1121c44634b616af61c49cd3adf29a&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b&lt;SEP&gt;chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Python Code-Writing Capabilities">
  <data key="d0">Python Code-Writing Capabilities</data>
  <data key="d1">Study Outcomes</data>
  <data key="d2">The model's ability to generate correct Python programs from docstrings, achieving a 28.8% success rate on HumanEval, with repeated sampling improving success to 70.2%.&lt;SEP&gt;The model's ability to generate correct Python programs from docstrings, with a success rate of 28.8% on HumanEval, and the effectiveness of repeated sampling for solving difficult prompts.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="HumanEval">
  <data key="d0">HumanEval</data>
  <data key="d1">Study Design</data>
  <data key="d2">An evaluation set created to measure the functional correctness of code generated by the model, specifically solving programming problems from docstrings.&lt;SEP&gt;An evaluation set created to measure the functional correctness of code generated from natural language prompts, specifically assessing the ability to solve programming problems.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-J">
  <data key="d0">GPT-J</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A language model that achieved 11.4% success on HumanEval, used for comparison with Codex to assess improvements in code generation.&lt;SEP&gt;A language model that achieved an 11.4% success rate on HumanEval, used as a comparative benchmark for code synthesis capabilities.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Repeated Sampling">
  <data key="d0">Repeated Sampling</data>
  <data key="d1">Methodology</data>
  <data key="d2">A strategy involving multiple samples from the model to improve the likelihood of generating correct code solutions to complex prompts.&lt;SEP&gt;A technique involving multiple samples from the model to increase the likelihood of generating correct solutions, significantly improving performance.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Broader Impacts">
  <data key="d0">Broader Impacts</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Discussion of potential safety, security, and economic impacts of deploying powerful code generation models like Codex.&lt;SEP&gt;Discussion of safety, security, and economic implications of deploying powerful code generation models like Codex.&lt;SEP&gt;Potential societal impacts of Codex include aiding onboarding, reducing cognitive load, enabling non-programmers to generate code, but also raising safety and misuse concerns.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety">
  <data key="d0">Safety</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Potential risks associated with deploying advanced code generation models, including misuse and unintended consequences.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Economics">
  <data key="d0">Economics</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Economic impacts such as automation of coding tasks, changes in employment, and industry shifts.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="HumanEval dataset">
  <data key="d0">HumanEval dataset</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A benchmark dataset comprising programming problems and unit tests used to evaluate the code generation capabilities of models like Codex.&lt;SEP&gt;A benchmark dataset consisting of 164 hand-written programming problems with associated unit tests, used to evaluate the functional correctness of code generation models.&lt;SEP&gt;A benchmark set of 164 hand-written programming problems with associated unit tests, used to evaluate the functional correctness of code generation models, assessing reasoning, comprehension, and algorithmic skills.&lt;SEP&gt;A dataset consisting of 164 programming problems with associated unit tests, used to benchmark and evaluate the correctness of code generated by models like Codex and GPT-J.&lt;SEP&gt;A dataset of 164 programming problems with unit tests used to evaluate the correctness of code generated by models like Codex and GPT-J.&lt;SEP&gt;A dataset used to evaluate the code generation capabilities of models like Codex, consisting of programming problems and unit tests.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="pass@k metric">
  <data key="d0">pass@k metric</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A metric for evaluating the functional correctness of generated code by measuring the pass rate of unit tests across multiple samples, emphasizing correctness over exact match.&lt;SEP&gt;A performance metric that measures the probability that at least one of the top k generated code samples passes all unit tests, used to evaluate code correctness in model benchmarking.&lt;SEP&gt;An evaluation metric used to assess the functional correctness of code by measuring the proportion of problems solved with at least one passing sample among multiple generated samples, with considerations for variance and unbiased estimation.&lt;SEP&gt;An evaluation metric used to measure the probability that at least one of k generated code samples passes the unit tests for a given problem, used to assess code correctness.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="unit tests">
  <data key="d0">unit tests</data>
  <data key="d1">Tools</data>
  <data key="d2">Automated correctness checks that determine whether generated code passes predefined tests, used to evaluate model performance on code generation tasks.&lt;SEP&gt;Automated tests designed to verify the correctness of generated code by running specific input-output checks, serving as a key evaluation method for functional accuracy.&lt;SEP&gt;Automated tests that verify individual units or components of code function correctly, forming a fundamental part of test-driven development.&lt;SEP&gt;Tests designed to verify that individual units of code function correctly, forming a core component of test-driven development and code validation.&lt;SEP&gt;Unit tests are automated tests used to verify the correctness of code samples generated by models, serving as a benchmark for functional performance.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="accuracy of code generation">
  <data key="d0">accuracy of code generation</data>
  <data key="d1">Results</data>
  <data key="d2">The accuracy of models like Codex-S improves significantly with fine-tuning and multiple sample generation, with Codex-S solving approximately 37.7% of problems with a single sample and up to 77.5% within 100 samples.&lt;SEP&gt;The performance of models like Codex-S improves with fine-tuning and multiple sample generation, with metrics showing up to 77.5% of problems solved within 100 samples, and 44.5% passing unit tests with the highest mean log-probability sample.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="software engineering">
  <data key="d0">software engineering</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The field concerned with the development, testing, and maintenance of software, which benefits from AI models like Codex for automating code generation and testing.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="algorithm">
  <data key="d0">algorithm</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Algorithms are step-by-step procedures for computations, with the dataset and models evaluated based on their ability to generate correct algorithms from natural language descriptions.&lt;SEP&gt;The specific procedure or code logic that iterates through characters, checks position, and counts vowels accordingly.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="programming problems">
  <data key="d0">programming problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Programming problems are specific coding tasks used in datasets like HumanEval to benchmark model performance in code synthesis.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="software interview questions">
  <data key="d0">software interview questions</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Simple programming problems that assess language comprehension, algorithms, and mathematics, used as benchmarks in datasets.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="sample generation">
  <data key="d0">sample generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Generating multiple code samples from models to increase the likelihood of producing a correct solution, and selecting the best based on passing unit tests or heuristic measures.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="heuristic ranking">
  <data key="d0">heuristic ranking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A method to select the most promising code sample from multiple generated outputs based on criteria like highest mean log-probability or passing unit tests.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="test-driven development">
  <data key="d0">test-driven development</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A software development framework that mandates converting requirements into test cases before implementation, defining success by passing these tests, and influencing code integration processes.&lt;SEP&gt;A software development methodology that emphasizes writing tests before implementing code, ensuring that code meets specified requirements and passes all tests to be considered successful.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="functional correctness">
  <data key="d0">functional correctness</data>
  <data key="d1">Results</data>
  <data key="d2">A key performance indicator measuring whether generated code performs its intended function, often more meaningful than exact match.&lt;SEP&gt;The degree to which generated code correctly performs its intended function, evaluated through metrics like pass@k, and subject to challenges like high variance and unreliable indicators such as BLEU scores.&lt;SEP&gt;The degree to which generated code performs its intended function correctly, often evaluated through pass@k, but may be unreliable due to high variance and limitations of certain metrics like BLEU.&lt;SEP&gt;The measure of whether code performs its intended function, as opposed to passing weak test suites.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83&lt;SEP&gt;chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Large Language Models trained on code">
  <data key="d0">Large Language Models trained on code</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models like Codex trained on extensive code repositories to generate code snippets, with performance evaluated on datasets like HumanEval for problem-solving capabilities.&lt;SEP&gt;Models such as Codex trained on large datasets of source code to generate programming solutions, with performance evaluated on datasets like HumanEval.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="sandbox environment">
  <data key="d0">sandbox environment</data>
  <data key="d1">Tools</data>
  <data key="d2">A secure execution environment designed to run untrusted generated code safely, preventing malicious activities and ensuring security during evaluation.&lt;SEP&gt;A secure execution environment designed to run untrusted generated programs, preventing malicious activities and ensuring safety during code evaluation, utilizing technologies like gVisor and eBPF firewalls.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="gVisor container runtime">
  <data key="d0">gVisor container runtime</data>
  <data key="d1">Tools</data>
  <data key="d2">A container runtime that emulates host resources to isolate and protect the host system from malicious or untrusted code during execution.&lt;SEP&gt;A security-focused container runtime that emulates host resources to isolate and protect the host system from malicious containers during code execution.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kubernetes">
  <data key="d0">Kubernetes</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A container orchestration platform used as the infrastructure foundation for training and deploying models like Codex, supporting scalable and secure environment management.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="training infrastructure">
  <data key="d0">training infrastructure</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The computational environment built on cloud services and Kubernetes used for fine-tuning large models on code datasets, supporting model development and evaluation.&lt;SEP&gt;The computational environment, including cloud services and orchestration tools like Kubernetes, used for training and fine-tuning large language models on code datasets.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="evaluation of code models">
  <data key="d0">evaluation of code models</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates how well models like Codex can solve programming problems, the reliability of metrics like BLEU scores, and the effectiveness of evaluation environments like HumanEval and sandboxing.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT models">
  <data key="d0">GPT models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">GPT models are large-scale language models containing up to 12 billion parameters, used for natural language understanding and generation.&lt;SEP&gt;GPT models are large-scale language models with up to 12 billion parameters, designed for natural language understanding and generation, serving as the base architecture for Codex.</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Training Dataset">
  <data key="d0">Training Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A collection of 54 million public GitHub repositories totaling 159 GB of Python code, used to train and fine-tune Codex.&lt;SEP&gt;A large collection of publicly available Python code from GitHub, totaling hundreds of millions of lines, used to train Codex.&lt;SEP&gt;The curated set of problems and solutions used to fine-tune models like Codex, forming the basis for learning.&lt;SEP&gt;The dataset comprises a vast collection of publicly available Python code from GitHub, totaling hundreds of millions of lines, used to train Codex.&lt;SEP&gt;The training dataset comprises 54 million public software repositories from GitHub, totaling 159 GB of Python code, used to train Codex.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020&lt;SEP&gt;chunk-18f91435491c87cd10d4cbb056061eda&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Power Law Scaling">
  <data key="d0">Power Law Scaling</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A mathematical relationship describing how model performance, such as test loss, improves with increasing model size, following a power law pattern.&lt;SEP&gt;A model of how test loss decreases with increasing model size, following a power law pattern observed in language models including Codex.</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sampling Temperature">
  <data key="d0">Sampling Temperature</data>
  <data key="d1">Variables</data>
  <data key="d2">A hyperparameter controlling the diversity of generated samples during code synthesis; optimal values depend on the specific metric like pass@k.&lt;SEP&gt;A parameter controlling the diversity of generated samples during code synthesis, with different optimal values for various pass@k metrics.</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Adam optimizer">
  <data key="d0">Adam optimizer</data>
  <data key="d1">Tools</data>
  <data key="d2">An optimization algorithm used during the training of Codex, with specific hyperparameters like learning rate, weight decay, etc.&lt;SEP&gt;An optimization algorithm used during training of Codex, with hyperparameters such as learning rate, beta coefficients, and weight decay to facilitate convergence.</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Fine-tuning Methods">
  <data key="d0">Fine-tuning Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Strategies involving data filtering, tokenizer adjustments, and training protocols to adapt GPT models for code generation tasks.&lt;SEP&gt;Techniques applied to adapt GPT models to code generation, including training strategies, data filtering, and tokenizer adjustments.</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Tokenization">
  <data key="d0">Tokenization</data>
  <data key="d1">Tools</data>
  <data key="d2">A technique in text processing that involves splitting text into individual tokens, such as words or phrases.&lt;SEP&gt;The process of converting code into tokens for model input, utilizing the GPT-3 text tokenizer with modifications to improve efficiency.&lt;SEP&gt;The process of converting source code into tokens for input into GPT models; involves modifications to improve efficiency for code, such as handling whitespace.&lt;SEP&gt;The process of converting source code into token sequences using pre-trained Byte-Pair Encoding (BPE) tokenizers for model input.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-b9d1dd3aac85f5453acff84163bfde5a&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Evaluation Results">
  <data key="d0">Evaluation Results</data>
  <data key="d1">Results</data>
  <data key="d2">Empirical findings indicating that larger models tend to produce worse code when subtle bugs are present, and that prompt instructions to write correct code have limited effectiveness.&lt;SEP&gt;Performance metrics indicating that larger models and optimized sampling parameters lead to better code generation accuracy, as shown by pass@k scores and test loss.&lt;SEP&gt;Results indicate that larger models and optimized sampling parameters improve code generation accuracy, as measured by pass@k.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Language Modeling">
  <data key="d0">Language Modeling</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Language modeling refers to the computational process of predicting the next token in a sequence, used to evaluate and improve large language models like Codex and GPT variants.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sample Selection">
  <data key="d0">Sample Selection</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Sample selection involves choosing specific outputs based on criteria like highest mean log probability or sum log probability to improve model performance evaluations.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Log-Probability">
  <data key="d0">Log-Probability</data>
  <data key="d1">Variables</data>
  <data key="d2">Log probability measures the likelihood of a token or sequence, used as a heuristic for selecting high-quality samples in language model evaluation.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Temperature">
  <data key="d0">Temperature</data>
  <data key="d1">Variables</data>
  <data key="d2">A parameter controlling randomness in model sampling, affecting diversity and correctness of generated solutions.&lt;SEP&gt;A parameter controlling randomness in model sampling; higher temperatures produce more diverse outputs, affecting solution quality.&lt;SEP&gt;A sampling parameter that influences the diversity and distribution of generated outputs; optimal temperature varies for different models and tasks.&lt;SEP&gt;Temperature controls the randomness of generated samples, with higher temperatures increasing diversity, affecting the performance and diversity of language model outputs.&lt;SEP&gt;Temperature is a parameter controlling the randomness of generated samples; higher temperatures increase diversity, impacting the performance metrics like pass@k and the diversity of outputs.&lt;SEP&gt;Temperature is a sampling parameter that influences the diversity and distribution of generated outputs, with different optimal temperatures for different models and tasks.&lt;SEP&gt;Temperature controls the confidence level of token sampling in language models; lower temperature favors high-probability tokens, higher temperature increases randomness, affecting diversity and coherence.&lt;SEP&gt;Temperature controls the randomness of token sampling: lower temperature results in more deterministic outputs, higher temperature yields more diverse outputs.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-18f91435491c87cd10d4cbb056061eda&lt;SEP&gt;chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pass@k">
  <data key="d0">Pass@k</data>
  <data key="d1">Results</data>
  <data key="d2">A metric indicating the percentage of correct code samples generated at different sample sizes (k=1,10,100), measuring accuracy of code generation.&lt;SEP&gt;A metric indicating the percentage of correct code samples generated by the models at different sample sizes (k=1,10,100).&lt;SEP&gt;A metric indicating the percentage of correct solutions generated by the model within the top k attempts, used to evaluate model performance.&lt;SEP&gt;A performance metric indicating the percentage of correct solutions among the top k generated attempts, used to evaluate model accuracy.&lt;SEP&gt;Pass@k is a metric indicating the percentage of problems solved correctly within the top k generated solutions, used to evaluate code generation models.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="BLEU Score">
  <data key="d0">BLEU Score</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">BLEU score evaluates the similarity between generated solutions and reference solutions, but overlapping distributions suggest it may not fully capture functional correctness.&lt;SEP&gt;BLEU score measures the similarity between generated solutions and reference solutions, used to assess the quality of code or text generation.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="APPS Dataset">
  <data key="d0">APPS Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The APPS dataset includes 5000 training and 5000 test problems with unit tests, designed to evaluate models' ability to perform full-program synthesis.&lt;SEP&gt;The APPS dataset includes 5000 training and 5000 test programming problems with unit tests, designed to assess coding competence of language models.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sample Heuristics">
  <data key="d0">Sample Heuristics</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Heuristics such as selecting samples with the highest mean log-probability or sum log probability are used to improve the evaluation process of language models by choosing higher-quality solutions.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Performance Scaling">
  <data key="d0">Model Performance Scaling</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Performance scales smoothly with model size, indicating an underlying relationship between parameters and effectiveness in coding tasks.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Variance Reduction Measure">
  <data key="d0">Variance Reduction Measure</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A statistical approach used to decrease variability in measurement results, focusing on more reliable evaluation metrics.&lt;SEP&gt;A statistical technique aimed at decreasing the variance of measurement results to improve reliability and stability of evaluation metrics.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Strict Accuracy">
  <data key="d0">Strict Accuracy</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A performance metric emphasizing correctness without considering auxiliary measures, used for evaluating model outputs.&lt;SEP&gt;A performance metric focusing solely on correctness of outputs, used to evaluate model performance without auxiliary metrics.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-J pass@1">
  <data key="d0">GPT-J pass@1</data>
  <data key="d1">Results</data>
  <data key="d2">The percentage of correct code solutions generated by GPT-J at the top-1 attempt, found to be between Codex-85M and Codex-300M performance.&lt;SEP&gt;The success rate of GPT-J in generating correct solutions on the first attempt, reported as approximately 11.62%, indicating its effectiveness.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="PASS @k">
  <data key="d0">PASS @k</data>
  <data key="d1">Variables</data>
  <data key="d2">A variable representing the success rate of code generation models at different attempt counts (k=1, 10, 100), indicating how often models produce correct solutions within the top k outputs.&lt;SEP&gt;A variable representing the success rate of models at different attempt thresholds (k=1, 10, 100), used to measure model accuracy in code generation tasks.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-N EO125M">
  <data key="d0">GPT-N EO125M</data>
  <data key="d1">Results</data>
  <data key="d2">A GPT model with 125 million parameters, achieving pass@1 of 0.75%, demonstrating baseline performance in code synthesis.&lt;SEP&gt;A language model with 125 million parameters, achieving pass@1 of 0.75%, pass@10 of 1.88%, and pass@100 of 2.97% on code tasks.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-N EO1.3B">
  <data key="d0">GPT-N EO1.3B</data>
  <data key="d1">Results</data>
  <data key="d2">A GPT model with 1.3 billion parameters, showing improved performance metrics over smaller models in code tasks.&lt;SEP&gt;A larger GPT model with 1.3 billion parameters, with performance metrics indicating improved success rates over smaller models.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-N EO2.7B">
  <data key="d0">GPT-N EO2.7B</data>
  <data key="d1">Results</data>
  <data key="d2">A 2.7 billion parameter GPT model with higher pass@k scores, indicating better code generation capabilities.&lt;SEP&gt;A 2.7 billion parameter GPT model, demonstrating higher pass@k scores across evaluation metrics, reflecting better code generation capabilities.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-J 6B">
  <data key="d0">GPT-J 6B</data>
  <data key="d1">Results</data>
  <data key="d2">A 6 billion parameter GPT model with pass@1 of 11.62%, pass@10 of 15.74%, and pass@100 of 27.74%, demonstrating significant performance in code generation.&lt;SEP&gt;A 6 billion parameter GPT model with pass@1 of 11.62%, pass@10 of 15.74%, and pass@100 of 27.74%, indicating significant improvement over smaller models.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="TABNINE">
  <data key="d0">TABNINE</data>
  <data key="d1">Results</data>
  <data key="d2">A code completion tool with pass@1 of 2.58%, pass@10 of 4.35%, and pass@100 of 7.59%, showing comparatively lower performance.&lt;SEP&gt;A code completion tool with pass@1 of 2.58%, reflecting lower success rates compared to larger models.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex -12M">
  <data key="d0">Codex -12M</data>
  <data key="d1">Results</data>
  <data key="d2">A 12 million parameter Codex model with pass@1 of 2.00%, serving as a baseline for smaller models.&lt;SEP&gt;A version of Codex with 12 million parameters, achieving pass@1 of 2.00%, pass@10 of 3.62%, and pass@100 of 8.58%.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex -25M">
  <data key="d0">Codex -25M</data>
  <data key="d1">Results</data>
  <data key="d2">A 25 million parameter Codex model with moderate success rates in code generation tasks.&lt;SEP&gt;A 25 million parameter Codex model with performance metrics indicating moderate success rates in code tasks.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex -42M">
  <data key="d0">Codex -42M</data>
  <data key="d1">Results</data>
  <data key="d2">A 42 million parameter Codex model with incremental improvements in pass@k metrics.&lt;SEP&gt;A 42 million parameter Codex model, with performance metrics showing incremental improvements.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex -85M">
  <data key="d0">Codex -85M</data>
  <data key="d1">Results</data>
  <data key="d2">An 85 million parameter Codex model with pass@1 of 8.22%, showing increased accuracy.&lt;SEP&gt;An 85 million parameter Codex model, with pass@1 of 8.22%, demonstrating increased accuracy compared to smaller versions.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex -300M">
  <data key="d0">Codex -300M</data>
  <data key="d1">Results</data>
  <data key="d2">A 300 million parameter Codex model with pass@1 of 13.17%, indicating further performance gains.&lt;SEP&gt;A 300 million parameter Codex model, with pass@1 of 13.17%, indicating further performance gains.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex -679M">
  <data key="d0">Codex -679M</data>
  <data key="d1">Results</data>
  <data key="d2">A 679 million parameter Codex model with pass@1 of 16.22%, demonstrating ongoing improvements.&lt;SEP&gt;A 679 million parameter Codex model, with pass@1 of 16.22%, showing continued improvement.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex -2.5B">
  <data key="d0">Codex -2.5B</data>
  <data key="d1">Results</data>
  <data key="d2">A 2.5 billion parameter Codex model with pass@1 of 21.36%, reflecting high effectiveness in code synthesis.&lt;SEP&gt;A 2.5 billion parameter Codex model, achieving pass@1 of 21.36%, reflecting high performance in code generation.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex -12B">
  <data key="d0">Codex -12B</data>
  <data key="d1">Results</data>
  <data key="d2">A 12 billion parameter Codex model with pass@1 of 28.81%, representing state-of-the-art performance in the evaluated tasks.&lt;SEP&gt;A 12 billion parameter Codex model with pass@1 of 28.81%, representing state-of-the-art performance.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Solutions Filtering">
  <data key="d0">Solutions Filtering</data>
  <data key="d1">Methodology</data>
  <data key="d2">A process of selecting code solutions that pass specific unit tests from a larger set of generated solutions, used to improve accuracy metrics.&lt;SEP&gt;A process of selecting solutions that pass specific unit tests from generated outputs, used to improve accuracy metrics.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Timeout in Evaluation">
  <data key="d0">Timeout in Evaluation</data>
  <data key="d1">Methodology</data>
  <data key="d2">A constraint where solutions exceeding a 3-second runtime are considered failures, used to assess efficiency and correctness.&lt;SEP&gt;A testing constraint where solutions exceeding a 3-second runtime are considered failed, used to assess efficiency alongside correctness.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Supervised Fine-Tuning">
  <data key="d0">Supervised Fine-Tuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A training approach where models are further trained on curated datasets of correct functions to improve performance on code generation tasks.&lt;SEP&gt;A training process where models are further trained on curated datasets of correct functions from various sources to enhance performance.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Problems from Competitive Programming">
  <data key="d0">Problems from Competitive Programming</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Programming problems sourced from competitive websites, used to create datasets with well-defined test cases for training and evaluation.&lt;SEP&gt;Programming problems sourced from competitive websites, used to generate training data with well-defined test cases and problem descriptions.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Problems from Continuous Integration">
  <data key="d0">Problems from Continuous Integration</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Problems curated from open source projects and CI environments, used to generate and validate programming exercises.&lt;SEP&gt;Programming problems derived from open-source projects' integration tests, used for dataset creation and model fine-tuning.&lt;SEP&gt;Programming problems derived from open-source projects' integration tests, used to create datasets for model training and evaluation.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879&lt;SEP&gt;chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Training Problems">
  <data key="d0">Training Problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A curated set of programming problems assembled from multiple sources to improve model training for code synthesis.&lt;SEP&gt;A curated set of programming problems assembled from various sources to fine-tune models for code synthesis.&lt;SEP&gt;Problems used to train and fine-tune models, assembled from source code, prompts, and validation data.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879&lt;SEP&gt;chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Unit Tests">
  <data key="d0">Unit Tests</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Unit tests are automated scripts that verify the correctness of software functions by running predefined inputs and checking outputs, used here to validate solutions and create test cases.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="sys.setprofile">
  <data key="d0">sys.setprofile</data>
  <data key="d1">Tools</data>
  <data key="d2">A Python function used to trace and collect function call data during program execution, enabling the creation of unit tests from runtime inputs and outputs.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="CI Frameworks (travis, tox)">
  <data key="d0">CI Frameworks (travis, tox)</data>
  <data key="d1">Tools</data>
  <data key="d2">Continuous Integration frameworks used to automate build, test, and deployment processes in software projects, facilitating the tracing and testing of code during integration.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Python Package Index (PyPI)">
  <data key="d0">Python Package Index (PyPI)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A repository of Python packages used as sources for code snippets and problems for model training and problem curation.&lt;SEP&gt;A repository of Python packages used as sources of code for creating problems and testing models.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-Neo, Codex-12B">
  <data key="d0">GPT-Neo, Codex-12B</data>
  <data key="d1">Tools</data>
  <data key="d2">Specific large language models fine-tuned for code generation and problem solving tasks, evaluated for passing program tests and generating solutions.&lt;SEP&gt;Specific large language models fine-tuned for code generation, used to produce solutions, pass tests, and assist in problem validation.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Filtering Problems">
  <data key="d0">Filtering Problems</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process to remove ambiguous or non-deterministic problems by verifying if generated samples pass unit tests, ensuring quality and clarity of curated problems.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Validation Loss">
  <data key="d0">Validation Loss</data>
  <data key="d1">Results</data>
  <data key="d2">A measure of the model's error on validation data, used to determine when training has converged and to prevent overfitting.&lt;SEP&gt;A measure of the model's prediction error during training, used to determine when to stop training for optimal performance.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sandboxed Environment">
  <data key="d0">Sandboxed Environment</data>
  <data key="d1">Study Design</data>
  <data key="d2">An isolated computing environment used to safely execute untrusted code during testing, preventing security risks.&lt;SEP&gt;Isolated computing environment used to run untrusted code safely, enabling testing of functions without risking system security.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Function Inputs and Outputs">
  <data key="d0">Function Inputs and Outputs</data>
  <data key="d1">Variables</data>
  <data key="d2">Data captured during code execution to create problems, verify solutions, and analyze model performance.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Unit Testing">
  <data key="d0">Unit Testing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Unit testing involves creating automated tests that verify individual components or functions of software by executing predefined inputs and checking for expected outputs, helping ensure correctness and facilitate bug detection.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Example Problems">
  <data key="d0">Example Problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Sample programming problems used to generate, validate, and train models, often curated from real-world code repositories and problem statements.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Problem Statements">
  <data key="d0">Problem Statements</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Descriptions of programming tasks or challenges that define the specifications for solutions and serve as the basis for creating test cases.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Incorrect Solutions">
  <data key="d0">Incorrect Solutions</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Failed or suboptimal code submissions that can be analyzed to generate new test cases and improve problem datasets.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Total Problems Curated">
  <data key="d0">Total Problems Curated</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The total number of problems curated (e.g., 10,000), representing the dataset size used for training and evaluation.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Continuous Integration (CI)">
  <data key="d0">Continuous Integration (CI)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A software development practice that automatically integrates code changes, runs tests, and ensures code quality, often involving tools like Travis and Tox.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Open Source Projects">
  <data key="d0">Open Source Projects</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Projects from platforms like GitHub that provide codebases and real-world data for problem curation and model training.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Tracing">
  <data key="d0">Tracing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of monitoring and recording function calls during program execution using tools like sys.setprofile, enabling data collection for test generation.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Build and Test Commands">
  <data key="d0">Build and Test Commands</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Commands specified in CI configuration files that automate environment setup, dependency installation, and test execution.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Virtual Environments">
  <data key="d0">Virtual Environments</data>
  <data key="d1">Tools</data>
  <data key="d2">Isolated environments created to run tests safely without affecting the host system, used during CI and in sandboxed testing of code.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dependencies">
  <data key="d0">Dependencies</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Libraries or packages required by the code, installed in virtual environments to ensure proper execution during testing.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Filtering">
  <data key="d0">Filtering</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process of removing problematic or ambiguous problems by verifying that generated solutions pass unit tests, ensuring dataset quality.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generated Samples">
  <data key="d0">Generated Samples</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Solutions or code snippets produced by models in response to prompts, used to verify correctness and filter problems.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Validation">
  <data key="d0">Validation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of testing generated solutions against unit tests to determine their correctness and suitability for inclusion in datasets.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="pass@100">
  <data key="d0">pass@100</data>
  <data key="d1">Results</data>
  <data key="d2">The success rate within the top 100 samples, reflecting the overall effectiveness of the model in generating correct code.&lt;SEP&gt;pass@100 measures the success rate within the top 100 samples, reflecting the model's overall effectiveness in generating correct code.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex-S">
  <data key="d0">Codex-S</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A variant of Codex that captures a narrower distribution, often requiring higher temperatures, and demonstrates improved performance on certain metrics like pass@k.&lt;SEP&gt;Codex-S is a variant of the Codex model that captures a narrower distribution, often requiring higher sampling temperatures, and shows improved performance over the base Codex in certain metrics.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="evaluation metrics">
  <data key="d0">evaluation metrics</data>
  <data key="d1">Tools</data>
  <data key="d2">Evaluation metrics such as pass@k, optimal temperature, and sample ranking heuristics are used to assess the performance and efficiency of code generation models.&lt;SEP&gt;Metrics such as pass@k, optimal temperature, and sample ranking heuristics used to assess the performance and efficiency of code generation models.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="sample selection heuristics">
  <data key="d0">sample selection heuristics</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Sample selection heuristics involve ranking generated samples based on criteria like mean log probability or back-translation to improve the quality of selected outputs.&lt;SEP&gt;Techniques like ranking samples based on mean log probability or back-translation to select the best outputs, aiming to improve code quality.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex-D">
  <data key="d0">Codex-D</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A model specifically trained to generate descriptive docstrings that explain code functionality, evaluated through manual grading due to the absence of automatic metrics.&lt;SEP&gt;Codex-D is a model trained specifically for generating docstrings, aiming to produce descriptive comments that specify the intent behind code, evaluated through manual grading due to the lack of automatic metrics.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="docstring">
  <data key="d0">docstring</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A docstring is a natural language description of code functionality, used for documentation and understanding code intent, generated by models like Codex-D.&lt;SEP&gt;A natural language description of code that explains its purpose, used for documentation, generated by models like Codex-D.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="manual grading">
  <data key="d0">manual grading</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A human evaluation process where experts assess the correctness and quality of generated docstrings, especially when automatic evaluation is unavailable.&lt;SEP&gt;Manual grading involves human evaluation of generated docstrings to assess correctness and quality, especially when automatic metrics are unavailable.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="back-translation">
  <data key="d0">back-translation</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">A technique to evaluate generated samples by translating outputs back into the source domain and assessing similarity or correctness, used for sample ranking.&lt;SEP&gt;Back-translation is a technique used to evaluate the quality of generated samples by translating outputs back into the original domain and assessing similarity or correctness.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="training problems">
  <data key="d0">training problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specific programming problems used to train models for code and docstring generation, containing function signatures, solutions, and annotations.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="performance margins">
  <data key="d0">performance margins</data>
  <data key="d1">Results</data>
  <data key="d2">Differences in performance metrics such as pass@k between models like Codex and Codex-S, indicating relative improvements.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="optimal sampling temperature">
  <data key="d0">optimal sampling temperature</data>
  <data key="d1">Variables</data>
  <data key="d2">The temperature setting that maximizes model performance metrics like pass@k, varies depending on model and task.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="performance comparison">
  <data key="d0">performance comparison</data>
  <data key="d1">Results</data>
  <data key="d2">Evaluations showing Codex-S outperforming Codex on metrics like pass@1 and pass@100, indicating improved efficiency.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model limitations">
  <data key="d0">model limitations</data>
  <data key="d1">Limitations</data>
  <data key="d2">Challenges such as lower quality of generated docstrings, difficulty in automatic evaluation, and issues with over-conditioning or missing details in generated outputs.&lt;SEP&gt;Current shortcomings of language models in generating functionally correct, reliable code, indicating areas for future improvement.&lt;SEP&gt;Current shortcomings of large language models in reliably generating functionally correct, secure, and robust code, highlighting areas for future research.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pass Rates">
  <data key="d0">Pass Rates</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics indicating the proportion of successful code generation samples, used to evaluate Codex's performance across different conditions and models.&lt;SEP&gt;Pass rates measure the proportion of code generation samples that successfully meet specified criteria, used here to evaluate Codex's performance across different conditions.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Back-Translation Ranking">
  <data key="d0">Back-Translation Ranking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A heuristic method for ranking code samples via back-translation, which underperforms mean log-probability ranking but outperforms random ranking, though it overfits quickly.&lt;SEP&gt;A heuristic ranking method for code samples based on back-translation, which underperforms mean log-probability ranking but outperforms random ranking, with tendencies to overfit.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Qualitative Metrics">
  <data key="d0">Qualitative Metrics</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Metrics developed to evaluate code generation capabilities while controlling for the complexity and abstraction level of problem specifications.&lt;SEP&gt;Metrics developed to measure code-generating capabilities of models while controlling for complexity and abstraction in problem specifications.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Synthetic Problems Dataset">
  <data key="d0">Synthetic Problems Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A synthetic dataset created from 13 basic deterministic building blocks to evaluate how performance decreases as complexity increases in chained operations within docstrings.&lt;SEP&gt;A synthetic dataset created from basic building blocks to evaluate how model performance degrades with increasing complexity in docstrings.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Societal Impacts">
  <data key="d0">Societal Impacts</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Potential societal impacts include aiding onboarding, reducing cognitive load, enabling non-programmers, but also raise safety and misuse concerns.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hazard Analysis">
  <data key="d0">Hazard Analysis</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A systematic approach to identify and evaluate risks associated with using Codex, focusing on safety hazards and societal impacts.&lt;SEP&gt;Hazard analysis involves systematically evaluating potential risks associated with AI model use, guiding mitigation efforts.&lt;SEP&gt;Hazard analysis systematically evaluates potential risks associated with deploying AI models, informing mitigation strategies.&lt;SEP&gt;Systematic assessment of risks and safety hazards associated with deploying Codex, focusing on potential harms and societal impacts.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020&lt;SEP&gt;chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="System-Level Synthesis">
  <data key="d0">System-Level Synthesis</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Refers to the ability of models to generate code involving system-level operations and attribute bindings, where Codex shows notable performance degradation.&lt;SEP&gt;Refers to the ability of models to generate code involving system-level operations, attribute bindings, and complex interactions, where Codex shows significant limitations.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Metrics for Performance Evaluation">
  <data key="d0">Metrics for Performance Evaluation</data>
  <data key="d1">Variables</data>
  <data key="d2">Quantitative measures such as pass rates, success ratios, and performance drops as complexity increases, used to assess Codex's capabilities.&lt;SEP&gt;Quantitative measures such as pass rates, success ratios, and performance drops with increasing complexity, used to assess Codex's capabilities.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Mean Log-Probability Ranking">
  <data key="d0">Mean Log-Probability Ranking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An evaluation approach that ranks samples based on their likelihood under the model, generally outperforming back-translation ranking in this context.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Random Ranking">
  <data key="d0">Random Ranking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A baseline evaluation method where code samples are ranked randomly, used as a comparison point for other ranking strategies.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Performance Degradation">
  <data key="d0">Performance Degradation</data>
  <data key="d1">Results</data>
  <data key="d2">Codex's success rate decreases exponentially as the number of chained components in the docstring increases, illustrating performance decline with complexity.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety Challenges">
  <data key="d0">Safety Challenges</data>
  <data key="d1">Limitations</data>
  <data key="d2">Codex's inability to always produce aligned code, tendency to recommend syntactically incorrect or undefined code, and difficulty with complex, system-level tasks pose safety and reliability concerns.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="safety features">
  <data key="d0">safety features</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Safety features refer to the attributes and mechanisms designed to ensure the safe use of code generation models, including risk mitigation strategies and oversight practices.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="impact analysis">
  <data key="d0">impact analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Impact analysis involves systematically evaluating the potential effects, risks, and safety implications of deploying code generation systems in various contexts.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="risks">
  <data key="d0">risks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Risks include over-reliance on generated outputs, misalignment with user intentions, bias and harmful stereotypes, and security vulnerabilities, all of which require careful attention and mitigation.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="over-reliance">
  <data key="d0">over-reliance</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The research explores how dependence on generated code can lead to safety issues, especially when users trust outputs without sufficient oversight, affecting safety and correctness.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="misalignment">
  <data key="d0">misalignment</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Misalignment describes the discrepancy between the model's outputs and the user's actual intentions, often leading to unhelpful or harmful code suggestions despite the model's capabilities.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="bias and representation">
  <data key="d0">bias and representation</data>
  <data key="d1">Results</data>
  <data key="d2">The models can generate biased, stereotypical, or harmful code comments and structures, reflecting societal biases present in training data, which pose safety and ethical concerns.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="training distribution">
  <data key="d0">training distribution</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The training distribution refers to the dataset on which models like Codex are trained, influencing their behavior, biases, and limitations.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="risk mitigation">
  <data key="d0">risk mitigation</data>
  <data key="d1">Tools</data>
  <data key="d2">Risk mitigation encompasses strategies, documentation, and technical interventions aimed at reducing safety hazards associated with code generation models.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="human oversight">
  <data key="d0">human oversight</data>
  <data key="d1">Tools</data>
  <data key="d2">Human oversight involves active monitoring and review of generated code to prevent unsafe or insecure outputs, especially critical for novice users.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="automation bias">
  <data key="d0">automation bias</data>
  <data key="d1">Variables</data>
  <data key="d2">Automation bias refers to users over-trusting automated outputs, which can lead to safety lapses and reliance on potentially flawed generated code.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="empirical investigation">
  <data key="d0">empirical investigation</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Empirical investigation involves collecting data through experiments or observations to understand how to improve vigilance and safety in practical use.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="safety implications">
  <data key="d0">safety implications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Safety implications include the potential for generated code to cause harm if risks like over-reliance, misalignment, or bias are not properly managed, affecting users and stakeholders.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="societally beneﬁcial direction">
  <data key="d0">societally beneﬁcial direction</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The overall goal is to steer code generation technology towards positive societal impact by addressing risks and promoting responsible use.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Generation Models">
  <data key="d0">Code Generation Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Models designed to automatically generate computer code, which may exhibit biases and representation issues related to gender, race, emotion, class, and name structures.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias and Representation Issues">
  <data key="d0">Bias and Representation Issues</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Concerns regarding stereotypes and societal biases embedded in generated code, impacting safety and fairness.&lt;SEP&gt;Issues related to stereotypes and societal biases embedded in code generated by models like Codex, which can have safety and fairness implications.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Filtration or Modulation">
  <data key="d0">Filtration or Modulation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Interventions such as filtering outputs or documenting processes to mitigate biases and associated risks in code generation.&lt;SEP&gt;Techniques such as filtering outputs and documentation aimed at mitigating biases and safety risks.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Economic and Labor Market Impacts">
  <data key="d0">Economic and Labor Market Impacts</data>
  <data key="d1">Results</data>
  <data key="d2">Analysis of the potential effects of code generation tools on productivity, employment, and economic factors, including long-term implications.&lt;SEP&gt;Potential reduction in software production costs through increased programmer productivity, with effects limited by current engineer task distributions and package dependency patterns.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Software-Related Labor Markets">
  <data key="d0">Software-Related Labor Markets</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The labor market for software engineers and programmers, which could be affected by advancements in code generation capabilities over time.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Security Implications">
  <data key="d0">Security Implications</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The potential for code generation models like Codex to produce insecure or vulnerable code, and their misuse in cybercrime, with implications for cybersecurity defenses.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malware Development">
  <data key="d0">Malware Development</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Malicious software created with the aid of code generation models, including polymorphic malware that adapts to evade detection.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Capabilities">
  <data key="d0">Model Capabilities</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The current ability of Codex to generate insecure or malicious code and the potential for future models to improve security or be exploited for cyberattacks.&lt;SEP&gt;The features and performance levels of Codex, including code generation proficiency and vulnerability detection.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457&lt;SEP&gt;chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Environmental Impacts">
  <data key="d0">Environmental Impacts</data>
  <data key="d1">Results</data>
  <data key="d2">The ecological footprint associated with training and deploying large AI models, including energy consumption and carbon emissions.&lt;SEP&gt;Training and inference of models like Codex consume significant energy, contributing to carbon footprint, though efforts like renewable energy sourcing can mitigate this.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Compute Resources">
  <data key="d0">Compute Resources</data>
  <data key="d1">Tools</data>
  <data key="d2">The hardware and platforms used for training and deploying large models, impacting environmental sustainability.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety Implications">
  <data key="d0">Safety Implications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Potential safety concerns arising from biased or unsafe code generated by AI models.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Appendix F">
  <data key="d0">Appendix F</data>
  <data key="d1">Limitations</data>
  <data key="d2">Section discussing bias and representation issues in detail.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Economic and labor market impacts">
  <data key="d0">Economic and labor market impacts</data>
  <data key="d1">Results</data>
  <data key="d2">Code generation capabilities could reduce software development costs and influence labor markets, though effects are currently limited by task distributions.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Programmer Tasks">
  <data key="d0">Programmer Tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Activities such as writing, designing, and upgrading software, which are affected by automation tools like Codex.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Package Import Patterns">
  <data key="d0">Package Import Patterns</data>
  <data key="d1">Variables</data>
  <data key="d2">The rate at which Codex imports software packages, which can advantage certain package authors and influence dependency patterns.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Long-term Effects">
  <data key="d0">Long-term Effects</data>
  <data key="d1">Results</data>
  <data key="d2">Potential for more substantial impacts on labor markets and the economy as capabilities improve over time.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Security Landscape">
  <data key="d0">Security Landscape</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The overall security environment affected by code generation models, including vulnerabilities and misuse potential.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Vulnerable or Misaligned Code">
  <data key="d0">Vulnerable or Misaligned Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code produced by Codex that may contain security flaws or misalignments.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Cybercrime">
  <data key="d0">Cybercrime</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Malicious activities potentially facilitated by AI-generated code, including malware development.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malware">
  <data key="d0">Malware</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Malicious software that can be created or enhanced using code generation models, including polymorphic malware.&lt;SEP&gt;Malicious software that threat actors may develop or utilize, potentially assisted by Codex's code generation capabilities.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457&lt;SEP&gt;chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Security">
  <data key="d0">Model Security</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Research and strategies aimed at making models like Codex produce more secure code.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Non-determinism">
  <data key="d0">Non-determinism</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Characteristic of models like Codex that enables diverse code outputs, impacting malware diversity and detection challenges.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malware Detection">
  <data key="d0">Malware Detection</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Traditional methods relying on signatures and fingerprinting, which face challenges due to code diversity.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Application Security">
  <data key="d0">Application Security</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Field focused on ensuring the security of software applications, including defenses against malicious code.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sensitive Data">
  <data key="d0">Sensitive Data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Confidential or proprietary information present in training datasets, which could be leaked or predicted by models.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Data Corruption">
  <data key="d0">Data Corruption</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Risks of adversarial manipulation of training data to induce specific behaviors in models.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Compute Consumption">
  <data key="d0">Compute Consumption</data>
  <data key="d1">Variables</data>
  <data key="d2">Compute consumption quantifies the amount of computational resources used during training and inference, impacting costs, energy use, and environmental footprint.&lt;SEP&gt;Compute consumption refers to the amount of computational resources used during AI training and inference, impacting costs and environmental footprint.&lt;SEP&gt;Energy used during training and inference, affecting environmental sustainability.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457&lt;SEP&gt;chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Renewable Energy Sources">
  <data key="d0">Renewable Energy Sources</data>
  <data key="d1">Tools</data>
  <data key="d2">Strategies to reduce the carbon footprint of AI training and deployment.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Global Supply Chain">
  <data key="d0">Global Supply Chain</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The regional and temporal aspects of energy use and environmental impact related to AI infrastructure.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Petaflop/s-days">
  <data key="d0">Petaflop/s-days</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Petaflop per second-days measure the amount of computational resources used over time during AI training, indicating scale and intensity.&lt;SEP&gt;Petaflop per second-days of compute measure the amount of computational resources used over time, indicating the scale of AI training processes.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex-12B">
  <data key="d0">Codex-12B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Codex-12B is a large language model designed for code generation, trained on extensive compute resources, including internet data.&lt;SEP&gt;Codex-12B is a large language model trained for code generation, utilizing substantial compute resources during its creation.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Azure">
  <data key="d0">Azure</data>
  <data key="d1">Tools</data>
  <data key="d2">Azure is a cloud computing platform used for training and deploying AI models like Codex-12B, with a commitment to renewable energy sourcing.&lt;SEP&gt;Azure is a cloud platform used for training and deploying AI models like Codex-12B, with a commitment to sourcing renewable energy and purchasing carbon credits to reduce environmental impact.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Carbon Credits">
  <data key="d0">Carbon Credits</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Carbon credits are environmental assets purchased by Azure to offset carbon emissions associated with compute activities, reducing overall carbon footprint.&lt;SEP&gt;Carbon credits are environmental assets purchased by Azure to offset carbon emissions from compute activities, contributing to sustainability efforts.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Renewable Energy">
  <data key="d0">Renewable Energy</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Renewable energy sources are used by Azure data centers to power AI training and inference, aiming to minimize carbon footprint.&lt;SEP&gt;Renewable energy sources are used by Azure to power data centers, aiming to minimize environmental impact during AI training.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Inference">
  <data key="d0">Inference</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Inference is the process of using trained AI models to generate outputs, which can increase total compute demands over time.&lt;SEP&gt;Inference is the process of using trained models to generate outputs, which can significantly increase total compute demands, especially when used extensively for complex problems.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Legal Implications">
  <data key="d0">Legal Implications</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Legal considerations include fair use of training data and the originality of generated code, impacting intellectual property rights.&lt;SEP&gt;Legal considerations involve assessing the use of internet data for training, intellectual property rights, and the originality of generated code, including fair use debates.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Fair Use">
  <data key="d0">Fair Use</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Fair use is a legal doctrine allowing limited use of copyrighted material for purposes like research and education, relevant to training AI on internet data.&lt;SEP&gt;Fair use is a legal doctrine that permits limited use of copyrighted material, such as public GitHub repositories, for research and training purposes, subject to legal interpretation.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generated Code">
  <data key="d0">Generated Code</data>
  <data key="d1">Results</data>
  <data key="d2">Generated code is rarely identical to training snippets (&lt;0.1%), indicating models produce novel outputs based on learned patterns rather than copying exact snippets.&lt;SEP&gt;Generated code is rarely identical to training snippets (&lt;0.1%), indicating models produce novel outputs based on learned patterns rather than copying.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Predictive Weightings">
  <data key="d0">Model Predictive Weightings</data>
  <data key="d1">Variables</data>
  <data key="d2">Model predictive weightings influence code outputs, affecting the likelihood of reproducing training data snippets.&lt;SEP&gt;Model predictive weightings influence the likelihood that generated code resembles training data snippets, affecting originality and legal considerations.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="User Control">
  <data key="d0">User Control</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Users retain control over editing and acceptance of generated code, making AI code generation similar to auto-completion features.&lt;SEP&gt;Users retain control over editing, acceptance, and use of generated code, making the process similar to auto-completion or auto-suggest features in programming tools.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Environmental Impact">
  <data key="d0">Environmental Impact</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Assessing environmental impact involves analyzing compute energy use, sourcing renewable energy, and supply chain costs, emphasizing sustainability.&lt;SEP&gt;Assessing environmental impact involves analyzing compute energy use, sourcing renewable energy, and understanding supply chain costs.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Responsible AI">
  <data key="d0">Responsible AI</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Responsible AI encompasses ethical practices, safety measures, and policy engagement to ensure AI systems are deployed safely and ethically.&lt;SEP&gt;Responsible AI encompasses ethical practices, safety, and policy engagement to ensure AI benefits society while minimizing harm.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Risk Mitigation">
  <data key="d0">Risk Mitigation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Risk mitigation strategies include careful documentation, content filtering, user review policies, and monitoring to prevent harms from AI deployment.&lt;SEP&gt;Risk mitigation strategies include careful documentation, content filtering, user review policies, monitoring, and restrictions to prevent harms such as offensive outputs, insecure code, or malicious use.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Content Filtering">
  <data key="d0">Content Filtering</data>
  <data key="d1">Tools</data>
  <data key="d2">Content filtering tools are implemented to reduce offensive, insecure, or harmful outputs from AI models during deployment, enhancing safety.&lt;SEP&gt;Content filtering tools help prevent offensive, insecure, or harmful outputs from AI models during deployment.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Deployment">
  <data key="d0">Model Deployment</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Deployment involves making AI models accessible via APIs or services, with policies such as user review, use case restrictions, monitoring, and rate limiting to prevent misuse and high-stakes risks.&lt;SEP&gt;Deployment involves making AI models accessible via APIs or services, with policies to restrict malicious or high-stakes use.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Deep Learning Resurgence">
  <data key="d0">Deep Learning Resurgence</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The recent resurgence of deep learning has led to significant advances in neural program learning, including approaches like program induction and program synthesis.&lt;SEP&gt;The resurgence of deep learning has driven advances in neural program learning, including program induction and synthesis approaches.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Program Learning">
  <data key="d0">Program Learning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Program learning involves models generating or understanding code or program outputs, with approaches like induction and synthesis.&lt;SEP&gt;Program learning involves models generating or understanding code or program outputs, with methodologies such as program induction and synthesis to improve AI capabilities in programming tasks.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Program Induction">
  <data key="d0">Program Induction</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Program induction generates programs directly from latent representations, enabling models to perform tasks like addition or memorization.&lt;SEP&gt;Program induction techniques generate program outputs directly from latent representations, enabling models to perform tasks like addition and memorization, often using neural architectures with inductive biases.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Turing Machine">
  <data key="d0">Neural Turing Machine</data>
  <data key="d1">Tools</data>
  <data key="d2">Neural Turing Machines are neural networks equipped with external memory modules, used to incorporate inductive biases and facilitate neural program learning.&lt;SEP&gt;Neural Turing Machines are neural networks with external memory, used to incorporate inductive biases for program learning.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Program Interpreter">
  <data key="d0">Neural Program Interpreter</data>
  <data key="d1">Tools</data>
  <data key="d2">Neural Program Interpreters are models designed to execute or interpret code, contributing to neural program learning by enabling models to understand program behavior.&lt;SEP&gt;Neural Program Interpreters are models designed to execute or interpret programs, contributing to neural program learning research.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Universal Transformer">
  <data key="d0">Universal Transformer</data>
  <data key="d1">Tools</data>
  <data key="d2">Universal Transformer is a neural network architecture that incorporates recurrence and attention mechanisms, used in evaluating large language models trained on code.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Utskever">
  <data key="d0">Utskever</data>
  <data key="d1">Researcher</data>
  <data key="d2">Utskever is referenced as an author associated with neural network approaches in program synthesis.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Graves et al., 2016">
  <data key="d0">Graves et al., 2016</data>
  <data key="d1">Study</data>
  <data key="d2">A study by Graves et al. (2016) introduces the Differentiable Neural Computer, a neural network model for program induction.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Reed &amp; de Freitas, 2016">
  <data key="d0">Reed &amp; de Freitas, 2016</data>
  <data key="d1">Study</data>
  <data key="d2">Reed and de Freitas (2016) discuss the Neural Program Interpreter, a model leveraging recurrence for program induction.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Shin et al., 2018">
  <data key="d0">Shin et al., 2018</data>
  <data key="d1">Study</data>
  <data key="d2">Shin et al. (2018) contribute to neural approaches like the Neural Program Interpreter for program synthesis.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pierrot et al., 2021">
  <data key="d0">Pierrot et al., 2021</data>
  <data key="d1">Study</data>
  <data key="d2">Pierrot et al. (2021) further develop models related to neural program interpretation.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dehghani et al., 2019">
  <data key="d0">Dehghani et al., 2019</data>
  <data key="d1">Study</data>
  <data key="d2">Dehghani et al. (2019) introduce the Universal Transformer, applied to program induction tasks.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Program Synthesis">
  <data key="d0">Program Synthesis</data>
  <data key="d1">Core Concept</data>
  <data key="d2">Program synthesis involves automatically generating code or programs from specifications, often using models like probabilistic grammars or neural networks.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Probabilistic Context-Free Grammar (PCFG)">
  <data key="d0">Probabilistic Context-Free Grammar (PCFG)</data>
  <data key="d1">Methodology</data>
  <data key="d2">A classical approach in program synthesis that generates program syntax trees based on probabilistic rules.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Abstract Syntax Tree (AST)">
  <data key="d0">Abstract Syntax Tree (AST)</data>
  <data key="d1">Object of Study</data>
  <data key="d2">A tree representation of the syntactic structure of source code used in program generation.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Maddison &amp; Tarlow, 2014">
  <data key="d0">Maddison &amp; Tarlow, 2014</data>
  <data key="d1">Study</data>
  <data key="d2">Improved on PCFG by learning a state vector to condition child node expansion in program generation.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Allamanis et al., 2015">
  <data key="d0">Allamanis et al., 2015</data>
  <data key="d1">Study</data>
  <data key="d2">Applied ideas of program structure learning to text-to-code retrieval tasks.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Yin &amp; Neubig, 2017">
  <data key="d0">Yin &amp; Neubig, 2017</data>
  <data key="d1">Study</data>
  <data key="d2">Utilized models for text-conditional code generation, leveraging program structure.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code2seq">
  <data key="d0">Code2seq</data>
  <data key="d1">Methodology</data>
  <data key="d2">A model leveraging ASTs for translating code into natural language descriptions.&lt;SEP&gt;Uses ASTs for code-to-text generation, enabling models to translate code to natural language descriptions.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hindle et al., 2012">
  <data key="d0">Hindle et al., 2012</data>
  <data key="d1">Study</data>
  <data key="d2">Found code more predictable than natural language using n-gram language models.&lt;SEP&gt;Investigated language models of code using n-gram models, finding code more predictable than natural language.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ling et al., 2016">
  <data key="d0">Ling et al., 2016</data>
  <data key="d1">Study</data>
  <data key="d2">Developed Hearthstone dataset for neural program learning, involving game-related code.&lt;SEP&gt;Developed Hearthstone dataset involving game-related code for neural program learning.&lt;SEP&gt;Developed Latent Predictor Networks with character-level language models to generate executable code, including for Magic: The Gathering cards.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Balog et al., 2017">
  <data key="d0">Balog et al., 2017</data>
  <data key="d1">Study</data>
  <data key="d2">Trained DeepCoder to predict functions in source code, guiding program search.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="DeVlin et al., 2018">
  <data key="d0">DeVlin et al., 2018</data>
  <data key="d1">Study</data>
  <data key="d2">Pioneered large natural language models applied to code tasks, such as code search.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Radford et al., 2019">
  <data key="d0">Radford et al., 2019</data>
  <data key="d1">Study</data>
  <data key="d2">Introduced GPT-2, a large-scale language model influencing code synthesis approaches.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Liu et al., 2019">
  <data key="d0">Liu et al., 2019</data>
  <data key="d1">Study</data>
  <data key="d2">Contributed to transformer-based models for code understanding and generation.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Raffel et al., 2020">
  <data key="d0">Raffel et al., 2020</data>
  <data key="d1">Study</data>
  <data key="d2">Developed T5, a text-to-text transformer model applicable to code tasks.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Brown et al., 2020">
  <data key="d0">Brown et al., 2020</data>
  <data key="d1">Study</data>
  <data key="d2">Presented GPT-3, a large language model with capabilities in code synthesis and understanding.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="CodeBERT">
  <data key="d0">CodeBERT</data>
  <data key="d1">Tools</data>
  <data key="d2">A transformer-based model designed for understanding and generating code and natural language, aiding in code-related NLP tasks.&lt;SEP&gt;A transformer-based model designed to understand and generate code and natural language, aiding in code-related NLP tasks.&lt;SEP&gt;A transformer-based model trained on code and natural language pairs, effective for code search and generation.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21&lt;SEP&gt;chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Feng et al., 2020">
  <data key="d0">Feng et al., 2020</data>
  <data key="d1">Study</data>
  <data key="d2">Introduced CodeBERT, demonstrating its effectiveness for code search."|&lt;SEP&gt;Introduced CodeBERT, enhancing code search and understanding via BERT-style training on code data.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="PyMT5">
  <data key="d0">PyMT5</data>
  <data key="d1">Tool</data>
  <data key="d2">A multilingual T5 model trained to translate between code and natural language.&lt;SEP&gt;A multilingual T5 model trained to translate between different code representations and natural language.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Devlin et al., 2017">
  <data key="d0">Devlin et al., 2017</data>
  <data key="d1">Study</data>
  <data key="d2">Observed that synthesizing multiple program samples via beam search improves functional correctness.&lt;SEP&gt;Showed that synthesizing multiple code samples through beam search improves functional correctness.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kulal et al., 2019">
  <data key="d0">Kulal et al., 2019</data>
  <data key="d1">Study</data>
  <data key="d2">Proposed SPoC, a method for generating functionally correct code from pseudocode within a fixed compilation budget.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Lachaux et al., 2020">
  <data key="d0">Lachaux et al., 2020</data>
  <data key="d1">Study</data>
  <data key="d2">Developed TransCoder for language translation, emphasizing functional correctness.&lt;SEP&gt;Developed TransCoder for unsupervised translation between programming languages, emphasizing functional correctness.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jain et al., 2020">
  <data key="d0">Jain et al., 2020</data>
  <data key="d1">Study</data>
  <data key="d2">Proposed ContraCode, leveraging the space of functionally correct programs to enhance model performance."|&lt;SEP&gt;Proposed ContraCode, leveraging the space of functionally correct programs to improve model performance on tasks like type inference.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hendrycks et al., 2021">
  <data key="d0">Hendrycks et al., 2021</data>
  <data key="d1">Study</data>
  <data key="d2">Created APPS benchmark for evaluating code generation based on competitive programming problems.&lt;SEP&gt;Created APPS benchmark for evaluating code generation models based on problem-solving in competitive programming.&lt;SEP&gt;Developed APPS benchmark for functional correctness evaluation of code models.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Gulwani, 2011; Gulwani et al., 2012">
  <data key="d0">Gulwani, 2011; Gulwani et al., 2012</data>
  <data key="d1">Study</data>
  <data key="d2">Early datasets like FlashFill used for benchmarking neural code synthesis, focusing on data transformations.&lt;SEP&gt;Early datasets like FlashFill used to benchmark neural code synthesis, focusing on string transformations.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Barone &amp; Sennrich, 2017">
  <data key="d0">Barone &amp; Sennrich, 2017</data>
  <data key="d1">Study</data>
  <data key="d2">Compiled large datasets of Python code from GitHub for training neural models.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Husain et al., 2019">
  <data key="d0">Husain et al., 2019</data>
  <data key="d1">Study</data>
  <data key="d2">Built CodeSearchNet, a large corpus for code search and understanding across multiple languages.&lt;SEP&gt;Built CodeSearchNet, a large corpus for code understanding across multiple languages.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Lu et al., 2021">
  <data key="d0">Lu et al., 2021</data>
  <data key="d1">Study</data>
  <data key="d2">Introduced CodeXGLUE, a benchmark suite aggregating multiple code understanding and generation tasks.&lt;SEP&gt;Introduced CodeXGLUE, a benchmark suite with multiple code tasks.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ren et al., 2020">
  <data key="d0">Ren et al., 2020</data>
  <data key="d1">Study</data>
  <data key="d2">Proposed CodeBLEU, a metric for evaluating code generation quality.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Tufano et al., 2020">
  <data key="d0">Tufano et al., 2020</data>
  <data key="d1">Study</data>
  <data key="d2">Applied Transformers to generate unit tests, outperforming some commercial tools.&lt;SEP&gt;Used Transformers to generate unit tests, outperforming some commercial tools.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Aye et al., 2021">
  <data key="d0">Aye et al., 2021</data>
  <data key="d1">Study</data>
  <data key="d2">Built an auto-complete tool at Facebook, improved by training on user data.&lt;SEP&gt;Built an internal auto-complete system at Facebook, improved by training on user accepted completions.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Agrawal et al., 1995">
  <data key="d0">Agrawal et al., 1995</data>
  <data key="d1">Study</data>
  <data key="d2">Early static code analysis for bug detection.&lt;SEP&gt;Early work on static code analysis for bug detection.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Korel &amp; Rilling, 1997">
  <data key="d0">Korel &amp; Rilling, 1997</data>
  <data key="d1">Study</data>
  <data key="d2">Developed dynamic code analysis techniques for debugging.&lt;SEP&gt;Dynamic analysis techniques for debugging code.&lt;SEP&gt;Reference to foundational research related to association rules and their application in debugging and code analysis.&lt;SEP&gt;Reference to foundational work on association rules and their application in debugging and code analysis.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8&lt;SEP&gt;chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jeffrey et al., 2009">
  <data key="d0">Jeffrey et al., 2009</data>
  <data key="d1">Study</data>
  <data key="d2">Learned association rules for bug localization in code.&lt;SEP&gt;Learned association rules for bug localization.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Goues et al., 2012">
  <data key="d0">Goues et al., 2012</data>
  <data key="d1">Study</data>
  <data key="d2">Applied genetic programming approaches for automatic bug fixing.&lt;SEP&gt;Applied genetic programming for automatic bug fixing.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Tufano et al., 2019; Drain et al., 2021">
  <data key="d0">Tufano et al., 2019; Drain et al., 2021</data>
  <data key="d1">Study</data>
  <data key="d2">Recent works on automated bug detection and fixing using machine learning and static/dynamic analysis.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="SPoC">
  <data key="d0">SPoC</data>
  <data key="d1">Methodology</data>
  <data key="d2">A method for producing functionally correct code from pseudocode within a fixed compilation budget.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="learned association rules">
  <data key="d0">learned association rules</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Data-driven rules derived from patterns in data, used here to assist in debugging and code suggestions.&lt;SEP&gt;Techniques based on identifying patterns of associations within data, used here for debugging and code suggestions.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="genetic programming">
  <data key="d0">genetic programming</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Evolutionary algorithm-based approach to automatically generate or improve code, used for debugging.&lt;SEP&gt;Evolutionary algorithm-based technique to automatically generate, optimize, or repair code, used for debugging.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="test suite">
  <data key="d0">test suite</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A collection of predefined tests used to evaluate the correctness, functionality, and robustness of code solutions and bug fixes.&lt;SEP&gt;A collection of tests used to evaluate the correctness and functionality of code suggestions and bug fixes.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="execution trace">
  <data key="d0">execution trace</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A detailed record of the sequence of executed instructions during program execution, used for diagnosing bugs and correctness.&lt;SEP&gt;A record of the sequence of executed instructions in a program, used to diagnose bugs and correctness.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="search">
  <data key="d0">search</data>
  <data key="d1">Methods</data>
  <data key="d2">The process of exploring possible modifications or solutions to find effective bug fixes or improvements in code.&lt;SEP&gt;The process of exploring possible solutions or code modifications to find fixes for bugs.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="neural machine translation">
  <data key="d0">neural machine translation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A deep learning approach that models bug fixing as translating buggy code into correct code.&lt;SEP&gt;A deep learning approach that models bug fixing as translating from buggy code to correct code, assessing performance based on translation quality.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="exact match">
  <data key="d0">exact match</data>
  <data key="d1">Methods</data>
  <data key="d2">A strict evaluation metric where predicted code must exactly match reference code, used in assessing bug fixes.&lt;SEP&gt;An evaluation metric that requires predicted code to exactly match reference solutions, used to measure model accuracy.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="weak test suites">
  <data key="d0">weak test suites</data>
  <data key="d1">Limitations</data>
  <data key="d2">Test suites with limited coverage that may fail to catch all bugs or functionality issues in code.&lt;SEP&gt;Test suites with limited coverage that may fail to detect all bugs or verify complete functionality, leading to potential overestimation of correctness.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="human developers">
  <data key="d0">human developers</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Practitioners who write and maintain test suites, influencing code evaluation and bug detection practices.&lt;SEP&gt;The target users whose testing practices influence code evaluation and bug detection.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="natural language docstrings">
  <data key="d0">natural language docstrings</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Comments in code written in natural language that describe code functionality, used in training models for code understanding and generation.&lt;SEP&gt;Descriptive comments in code used to generate or understand code functionality in models.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="large language models">
  <data key="d0">large language models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Advanced AI models trained on large datasets of code and text to generate, complete, or understand code based on input prompts.&lt;SEP&gt;Advanced AI models trained on vast code datasets to generate or complete code based on natural language or code input.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="fine-tuning GPT">
  <data key="d0">fine-tuning GPT</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of further training GPT models on specific datasets of code to improve their performance on code generation tasks.&lt;SEP&gt;Training GPT models on specific datasets of code to improve performance on code generation tasks.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="distribution">
  <data key="d0">distribution</data>
  <data key="d1">Variables</data>
  <data key="d2">The statistical distribution of training data, which affects model performance on evaluation datasets.&lt;SEP&gt;The statistical distribution of training data, which influences how well models perform on evaluation datasets similar to their training data.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="multiple samples">
  <data key="d0">multiple samples</data>
  <data key="d1">Tools</data>
  <data key="d2">Generating diverse outputs from models to improve code quality and robustness.&lt;SEP&gt;Generating multiple outputs from a model to increase the likelihood of obtaining correct or diverse code solutions.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="broader impacts">
  <data key="d0">broader impacts</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The societal and practical consequences of code-generating models, including benefits and limitations.&lt;SEP&gt;The societal, ethical, and practical consequences of deploying code-generating models, including benefits, risks, and limitations.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="2019.Alon, U., Brody, S., Levy, O., and Yahav, E.">
  <data key="d0">2019.Alon, U., Brody, S., Levy, O., and Yahav, E.</data>
  <data key="d1">Research Study</data>
  <data key="d2">A research publication presenting code2seq, a method for generating sequences from structured representations of code, published in 2018 at the International Conference on Learning Representations.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="code2seq">
  <data key="d0">code2seq</data>
  <data key="d1">Core Concept</data>
  <data key="d2">A method for generating sequences from structured representations of code, used for understanding or translating code structures.&lt;SEP&gt;A technique for generating sequences from structured representations of code, used to improve understanding or translation of code structures.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Aye, G. A., Kim, S., and Li, H.">
  <data key="d0">Aye, G. A., Kim, S., and Li, H.</data>
  <data key="d1">Research Study</data>
  <data key="d2">A study on learning autocompletion from real-world datasets, presented in 2021 at IEEE/ACM 43rd International Conference on Software Engineering.&lt;SEP&gt;Research on learning autocompletion from real-world datasets, presented at IEEE/ACM 43rd International Conference on Software Engineering in 2021.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Learning autocompletion">
  <data key="d0">Learning autocompletion</data>
  <data key="d1">Research Topic</data>
  <data key="d2">A methodology aimed at predicting code snippets to assist developers, based on real-world data.&lt;SEP&gt;A methodology or task focused on predicting or completing code snippets based on context, aimed at improving developer productivity.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="IEEE/ACM 43rd International Conference on Software Engineering">
  <data key="d0">IEEE/ACM 43rd International Conference on Software Engineering</data>
  <data key="d1">Study Design/Platform</data>
  <data key="d2">A conference for presenting research in software engineering, including topics like code autocompletion.&lt;SEP&gt;A conference for presenting software engineering research including code autocompletion techniques.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Baevski, A., Zhou, H., Mohamed, A., and Auli, M.">
  <data key="d0">Baevski, A., Zhou, H., Mohamed, A., and Auli, M.</data>
  <data key="d1">Research Study</data>
  <data key="d2">A framework called wav2vec 2.0 for self-supervised learning of speech representations, published as an arXiv preprint in 2020.&lt;SEP&gt;Research on wav2vec 2.0, a framework for self-supervised learning of speech representations, published as an arXiv preprint in 2020.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="wav2vec 2.0">
  <data key="d0">wav2vec 2.0</data>
  <data key="d1">Core Concept</data>
  <data key="d2">A framework for self-supervised learning of speech representations, enabling speech recognition without labeled data.&lt;SEP&gt;A self-supervised learning framework for speech representations, enabling speech recognition without labeled data.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="arXiv preprint arXiv:2006.11477">
  <data key="d0">arXiv preprint arXiv:2006.11477</data>
  <data key="d1">Publication Type</data>
  <data key="d2">A preprint publication detailing wav2vec 2.0.&lt;SEP&gt;A preprint publication on arXiv detailing the wav2vec 2.0 framework.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Balog, M., Gaunt, A., Brockschmidt, M., Nowozin, S., and Tarlow, D.">
  <data key="d0">Balog, M., Gaunt, A., Brockschmidt, M., Nowozin, S., and Tarlow, D.</data>
  <data key="d1">Research Study</data>
  <data key="d2">A study on DeepCoder, a system that learns to write programs, presented at ICLR 2017.&lt;SEP&gt;Research on DeepCoder, a system that learns to write programs, presented at ICLR 2017.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="DeepCoder">
  <data key="d0">DeepCoder</data>
  <data key="d1">Core Concept</data>
  <data key="d2">A system that uses deep learning to generate code by learning to write programs, demonstrating program synthesis capabilities.&lt;SEP&gt;An AI system that learns to generate code by learning to write programs, demonstrating program synthesis.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="International Conference on Learning Representations (ICLR)">
  <data key="d0">International Conference on Learning Representations (ICLR)</data>
  <data key="d1">Study Design/Platform</data>
  <data key="d2">A conference where research on learning representations like DeepCoder is presented.&lt;SEP&gt;A conference where research on learning representations, including DeepCoder, is presented.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bao, H., Dong, L., and Wei, F.">
  <data key="d0">Bao, H., Dong, L., and Wei, F.</data>
  <data key="d1">Research Study</data>
  <data key="d2">A preprint about Beit, a model for pre-training image transformers based on BERT, published on arXiv in 2021.&lt;SEP&gt;Research on Beit, a BERT pre-training method for image transformers, published on arXiv in 2021.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Beit">
  <data key="d0">Beit</data>
  <data key="d1">Core Concept</data>
  <data key="d2">A pre-training approach for image transformers based on masked image modeling, inspired by BERT.&lt;SEP&gt;A pre-training method for image transformers that adapts BERT-like masked image modeling to vision tasks.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="arXiv preprint arXiv:2106.08254">
  <data key="d0">arXiv preprint arXiv:2106.08254</data>
  <data key="d1">Publication Type</data>
  <data key="d2">A preprint describing Beit.&lt;SEP&gt;A preprint detailing the Beit model for image transformer pre-training.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Barone, A. V. M. and Sennrich, R.">
  <data key="d0">Barone, A. V. M. and Sennrich, R.</data>
  <data key="d1">Research Study</data>
  <data key="d2">A study on parallel corpora of Python functions and documentation strings for automated code documentation and generation, published as an arXiv preprint in 2017.&lt;SEP&gt;Research on a parallel corpus of Python functions and documentation strings for automated code documentation and generation, published as an arXiv preprint in 2017.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Parallel Corpus of Python Functions and Documentation">
  <data key="d0">Parallel Corpus of Python Functions and Documentation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset consisting of Python functions and their documentation strings, used for automated code documentation and generation.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ArXiv">
  <data key="d0">ArXiv</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A preprint repository where the study was published.&lt;SEP&gt;An open-access preprint repository where the research paper was published, facilitating dissemination of scientific findings.&lt;SEP&gt;An open-access repository where the research paper was published, serving as a platform for disseminating scientific knowledge.&lt;SEP&gt;Repository for preprints where the study was published.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21&lt;SEP&gt;chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Barrington, I. M. and Maciel, A.">
  <data key="d0">Barrington, I. M. and Maciel, A.</data>
  <data key="d1">Study Notes</data>
  <data key="d2">Lecture notes on nondeterministic computation, accessed online in 2000, providing foundational knowledge in computational theory.&lt;SEP&gt;Lecture notes on nondeterministic computation, accessed online in 2000, providing foundational knowledge in theoretical computer science.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Nondeterministic Computation">
  <data key="d0">Nondeterministic Computation</data>
  <data key="d1">Core Concept</data>
  <data key="d2">A computational paradigm where multiple outcomes are considered simultaneously, relevant in complexity theory.&lt;SEP&gt;A computational paradigm where multiple possible outcomes are considered simultaneously, relevant in complexity theory.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S.">
  <data key="d0">Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S.</data>
  <data key="d1">Research Study</data>
  <data key="d2">A critical survey discussing the dangers of large language models, particularly stochastic parrots, presented at the 2021 ACM Conference on Fairness, Accountability, and Transparency.&lt;SEP&gt;Research on the dangers of stochastic parrots, a metaphor for large language models, presented at the 2021 ACM Conference on Fairness, Accountability, and Transparency.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Stochastic Parrots">
  <data key="d0">Stochastic Parrots</data>
  <data key="d1">Theoretical Model</data>
  <data key="d2">A metaphor describing large language models that generate text based on probabilistic patterns, highlighting risks like bias and overfitting.&lt;SEP&gt;A metaphor describing large language models that generate text based on probabilistic patterns, raising concerns about biases and overfitting.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ACM Conference on Fairness, Accountability, and Transparency">
  <data key="d0">ACM Conference on Fairness, Accountability, and Transparency</data>
  <data key="d1">Study Design/Platform</data>
  <data key="d2">A conference where research on ethical and societal impacts of language models is presented.&lt;SEP&gt;A conference where research on ethical considerations and risks of language models is presented.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Black, S., Gao, L., Wang, P., Leahy, C., and Biderman, S.">
  <data key="d0">Black, S., Gao, L., Wang, P., Leahy, C., and Biderman, S.</data>
  <data key="d1">Research Study</data>
  <data key="d2">A study on GPT-Neo, a large-scale autoregressive language model implemented with mesh-tensorflow, published in 2021.&lt;SEP&gt;Research on GPT-Neo, a large-scale autoregressive language model implemented with mesh-tensorflow, published in 2021.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-Neo">
  <data key="d0">GPT-Neo</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A 2.7 billion parameter language model pre-trained on the Pile dataset, which includes natural language and source code, aimed at improving performance on mixed data.&lt;SEP&gt;A 2.7 billion parameter model pre-trained on the Pile dataset, combining natural language and code data.&lt;SEP&gt;A large autoregressive language model similar to GPT-3, designed for open-source deployment and research.&lt;SEP&gt;An open-source large language model similar to GPT-3, designed for research and deployment.&lt;SEP&gt;GPT-Neo is an open-source large-scale autoregressive language model built using Mesh-TensorFlow, used for natural language processing tasks.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-54d0e5495bc4b24b68d3cbc1c13d835e&lt;SEP&gt;chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Mesh-TensorFlow">
  <data key="d0">Mesh-TensorFlow</data>
  <data key="d1">Tools</data>
  <data key="d2">A library for distributed training of large neural networks, used to implement GPT-Neo.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Blodgett, S. L., Barocas, S., Dàumé III, H., and Wallach, H.">
  <data key="d0">Blodgett, S. L., Barocas, S., Dàumé III, H., and Wallach, H.</data>
  <data key="d1">Research Study</data>
  <data key="d2">A critical survey of bias in natural language processing, emphasizing language technology as a form of power, published as an arXiv preprint in 2020.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in NLP">
  <data key="d0">Bias in NLP</data>
  <data key="d1">Core Concept</data>
  <data key="d2">The presence of societal biases and power dynamics embedded in language technology, influencing fairness and equity.&lt;SEP&gt;The societal biases and power structures embedded in language models and NLP systems.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="arXiv preprint arXiv:2005.14050">
  <data key="d0">arXiv preprint arXiv:2005.14050</data>
  <data key="d1">Publication Type</data>
  <data key="d2">A preprint discussing bias in NLP.&lt;SEP&gt;Preprint discussing bias and power in NLP.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D.">
  <data key="d0">Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D.</data>
  <data key="d1">Research Study</data>
  <data key="d2">A foundational paper describing GPT-3, a large language model that demonstrates few-shot learning capabilities, published as an arXiv preprint in 2020.&lt;SEP&gt;Research on GPT-3, a large language model demonstrating few-shot learning, published as an arXiv preprint in 2020.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="US Bureau of Labor Statistics">
  <data key="d0">US Bureau of Labor Statistics</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">Official data sources providing labor statistics, including data on computer programmers and software developers, used for occupational outlooks.&lt;SEP&gt;Official labor statistics data, including employment data on computer programmers and software developers.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Occupational Outlook Handbook">
  <data key="d0">Occupational Outlook Handbook</data>
  <data key="d1">Tools/Resources</data>
  <data key="d2">A resource by the BLS providing employment outlook, job descriptions, and data for various occupations.&lt;SEP&gt;A resource providing employment outlooks, job descriptions, and occupational data.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Computer Programmers">
  <data key="d0">Computer Programmers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A profession involving writing, testing, and maintaining computer code, analyzed in labor statistics.&lt;SEP&gt;Profession involved in writing and maintaining computer code, analyzed in labor statistics.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Software Developers">
  <data key="d0">Software Developers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A profession involving designing and building software applications, also analyzed in labor statistics.&lt;SEP&gt;Profession involved in designing and building software applications, analyzed in labor data.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Carlini, N., Tramèr, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T., Song, D., Erlingsson, U., Oprea, A., and Raffel, C.">
  <data key="d0">Carlini, N., Tramèr, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T., Song, D., Erlingsson, U., Oprea, A., and Raffel, C.</data>
  <data key="d1">Research Study</data>
  <data key="d2">A study on extracting training data from large language models, presented at USENIX Security 2021.&lt;SEP&gt;Research on extracting training data from large language models, presented at USENIX Security 2021.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Extracting Training Data">
  <data key="d0">Extracting Training Data</data>
  <data key="d1">Research Technique</data>
  <data key="d2">A method for analyzing and retrieving training data used in large language models, raising privacy and security concerns.&lt;SEP&gt;A method used to analyze and retrieve training data from large language models, raising privacy concerns.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="USENIX Security Symposium">
  <data key="d0">USENIX Security Symposium</data>
  <data key="d1">Study Design/Platform</data>
  <data key="d2">A conference focused on security research, including studies on large language models.&lt;SEP&gt;A conference where research on security aspects of large models is presented.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., and Sutskever, I.">
  <data key="d0">Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., and Sutskever, I.</data>
  <data key="d1">Research Study</data>
  <data key="d2">Research on generative pretraining from pixels, published at ICML 2020.&lt;SEP&gt;Research on generative pretraining from pixels, published in 2020 at the International Conference on Machine Learning.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generative Pretraining from Pixels">
  <data key="d0">Generative Pretraining from Pixels</data>
  <data key="d1">Core Concept</data>
  <data key="d2">A method for pretraining models directly on pixel data for image generation and understanding.&lt;SEP&gt;A pretraining approach where models learn directly from pixel data for image generation tasks.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="International Conference on Machine Learning (ICML)">
  <data key="d0">International Conference on Machine Learning (ICML)</data>
  <data key="d1">Study Design/Platform</data>
  <data key="d2">A conference for presenting machine learning research, including generative pretraining methods.&lt;SEP&gt;A major conference where machine learning research including generative pretraining is presented.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Child, R., Gray, S., Radford, A., and Sutskever, I.">
  <data key="d0">Child, R., Gray, S., Radford, A., and Sutskever, I.</data>
  <data key="d1">Research Study</data>
  <data key="d2">Research on generating long sequences with sparse transformers, published as an arXiv preprint in 2019.&lt;SEP&gt;Research on sparse transformers for long sequence generation, preprint from 2019.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sparse Transformers">
  <data key="d0">Sparse Transformers</data>
  <data key="d1">Core Concept</data>
  <data key="d2">A transformer variant designed for efficient long sequence processing by sparsifying attention mechanisms.&lt;SEP&gt;A variant of transformer models optimized for long sequence generation by sparsifying attention mechanisms.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Parallel Corpus">
  <data key="d0">Parallel Corpus</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset of Python functions and documentation strings used for training models in code documentation and generation.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Blodgett, S. L., Barocas, S., Daumé III, H., and Wallach, H.">
  <data key="d0">Blodgett, S. L., Barocas, S., Daumé III, H., and Wallach, H.</data>
  <data key="d1">Study</data>
  <data key="d2">Critical survey of bias in NLP, emphasizing language technology as power, published as an arXiv preprint in 2020.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="S., Radford, A., and Sutskever, I.">
  <data key="d0">S., Radford, A., and Sutskever, I.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a research paper on generating long sequences with sparse transformers, contributing to advancements in neural network architectures.&lt;SEP&gt;Authors of a study on generating long sequences with sparse transformers, contributing to advancements in neural network architectures.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generating long sequences with sparse transformers">
  <data key="d0">Generating long sequences with sparse transformers</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A machine learning model designed to efficiently generate long sequences by utilizing sparse attention mechanisms, improving upon traditional transformer models.&lt;SEP&gt;A neural network model designed to efficiently generate long sequences by employing sparse attention mechanisms, enhancing scalability over traditional transformers.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="2019">
  <data key="d0">2019</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The year the Universal Transformers were introduced or published.&lt;SEP&gt;The year the concept was discussed or published.&lt;SEP&gt;The year the research on Universal Transformers was published.&lt;SEP&gt;The year the research was published, indicating the temporal context of the study.&lt;SEP&gt;The year the research was published, providing temporal context.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Christiano, P.">
  <data key="d0">Christiano, P.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in clarifying 'AI alignment', focusing on understanding and improving AI safety and value alignment.&lt;SEP&gt;Author involved in clarifying AI alignment issues, contributing to understanding safety and ethics in AI development.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Clarifying 'ai alignment'">
  <data key="d0">Clarifying 'ai alignment'</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">A study or discussion aimed at elucidating the concept of AI alignment, which concerns aligning AI behavior with human values.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="AI Alignment Forum">
  <data key="d0">AI Alignment Forum</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An online platform dedicated to discussions and research on AI safety, ethics, and alignment.&lt;SEP&gt;An online platform dedicated to discussions, research, and sharing ideas related to AI safety and alignment.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Clarkson, M. R., Finkbeiner, B., Koleini, M., Micinski, K. K., Rabe, M. N., and S´anchez, C.">
  <data key="d0">Clarkson, M. R., Finkbeiner, B., Koleini, M., Micinski, K. K., Rabe, M. N., and S´anchez, C.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a study on temporal logics for hyperproperties, contributing to formal verification and security.&lt;SEP&gt;Authors of a study on temporal logics for hyperproperties, contributing to security and trust in systems.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Temporal logics for hyperproperties">
  <data key="d0">Temporal logics for hyperproperties</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Formal logical frameworks used to specify and verify hyperproperties in security protocols and system behaviors.&lt;SEP&gt;Formal logical frameworks used to specify and verify hyperproperties, which are properties relating multiple system executions, especially in security contexts.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="International Conference on Principles of Security and Trust">
  <data key="d0">International Conference on Principles of Security and Trust</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A conference where research on security principles and trust was presented, facilitating academic exchange.&lt;SEP&gt;A conference where research on security principles, trust, and formal methods was presented.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="2014">
  <data key="d0">2014</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The year the research was published or presented.&lt;SEP&gt;The year the research was published.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Clement, C., Drain, D., Timcheck, J., Svyatkovskiy, A., and Sundaresan, N.">
  <data key="d0">Clement, C., Drain, D., Timcheck, J., Svyatkovskiy, A., and Sundaresan, N.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a study on multi-mode translation of natural language and Python code using transformers, advancing NLP and code generation.&lt;SEP&gt;Authors of a study on multi-mode translation of natural language and Python code using transformers, advancing NLP and code synthesis.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pymt5">
  <data key="d0">Pymt5</data>
  <data key="d1">Tools</data>
  <data key="d2">A transformer-based model enabling multi-mode translation between natural language and Python code, enhancing AI code understanding.&lt;SEP&gt;A transformer-based model enabling multi-mode translation between natural language and Python code, facilitating natural language programming interfaces.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Davis, B.">
  <data key="d0">Davis, B.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author discussing application protection through automated software diversity, relevant to cybersecurity.&lt;SEP&gt;Author discussing application security through automated software diversity, relevant to cybersecurity and software protection.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Protecting applications with automated software diversity">
  <data key="d0">Protecting applications with automated software diversity</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A security technique that automatically varies software implementations to prevent exploitation and increase robustness.&lt;SEP&gt;A technique to enhance software security by automatically varying implementation details to prevent attacks.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="2018">
  <data key="d0">2018</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The year BERT was introduced.&lt;SEP&gt;The year the discussion or publication on AI alignment was made available.&lt;SEP&gt;The year the methodology was discussed or published.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dehghani, M., Gouws, S., Vinyals, O., Uszkoreit, J., and Łukasz Kaiser">
  <data key="d0">Dehghani, M., Gouws, S., Vinyals, O., Uszkoreit, J., and Łukasz Kaiser</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a study on Universal Transformers, an extension of the transformer architecture to improve model capabilities.&lt;SEP&gt;Authors of the Universal Transformers model, an extension of the transformer architecture that incorporates recurrence and adaptive computation.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Universal transformers">
  <data key="d0">Universal transformers</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An advanced transformer model that incorporates recurrence and dynamic computation, aiming to enhance the flexibility and performance of neural networks.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Devlin, J., Uesato, J., Bhupatiraju, S., Singh, R., Mohamed, A., and Kohli, P.">
  <data key="d0">Devlin, J., Uesato, J., Bhupatiraju, S., Singh, R., Mohamed, A., and Kohli, P.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of BERT, a pre-trained bidirectional transformer model for language understanding, foundational in NLP.&lt;SEP&gt;Authors of BERT, a pre-trained deep bidirectional transformer model for language understanding, foundational to NLP.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dhariwal, P., Jun, H., Payne, C., Kim, J. W., Radford, A., and Sutskever, I.">
  <data key="d0">Dhariwal, P., Jun, H., Payne, C., Kim, J. W., Radford, A., and Sutskever, I.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of Jukebox, a generative model capable of producing high-fidelity music across various genres.&lt;SEP&gt;Authors of Jukebox, a generative model for music, contributing to AI-generated art.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jukebox">
  <data key="d0">Jukebox</data>
  <data key="d1">Tools</data>
  <data key="d2">A generative neural network model capable of producing music, demonstrating AI's creative capabilities.&lt;SEP&gt;A neural network model for music generation, demonstrating AI's creative potential in audio synthesis.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Drain, D., Wu, C., Svyatkovskiy, A., and Sundaresan, N.">
  <data key="d0">Drain, D., Wu, C., Svyatkovskiy, A., and Sundaresan, N.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a study on generating bug-fixes using pretrained transformers, relevant to software engineering.&lt;SEP&gt;Authors of a study on generating bug-fixes with pretrained transformers, relevant to software engineering and automated debugging.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generating bug-fixes using pretrained transformers">
  <data key="d0">Generating bug-fixes using pretrained transformers</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An approach leveraging pretrained transformer models to automatically generate bug fixes, improving software maintenance.&lt;SEP&gt;An approach that employs pretrained transformer models to automatically generate bug fixes, improving software maintenance processes.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Eghbal, N.">
  <data key="d0">Eghbal, N.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of 'Working in public', a book exploring open source software development, community practices, and maintenance challenges.&lt;SEP&gt;Author of 'Working in public', discussing open source software development and maintenance.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Working in public: the making and maintenance of open source software">
  <data key="d0">Working in public: the making and maintenance of open source software</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A book exploring the practices and challenges of open source software development.&lt;SEP&gt;A comprehensive book analyzing the practices, challenges, and social aspects of open source software development.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., et al.">
  <data key="d0">Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., et al.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of CodeBERT, a pre-trained model for programming and natural language, advancing code understanding.&lt;SEP&gt;Authors of CodeBERT, a pre-trained model for programming and natural language, facilitating code understanding and generation.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Frey, C. B.">
  <data key="d0">Frey, C. B.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of 'The technology trap', analyzing how technological advancements can lead to societal and economic challenges.&lt;SEP&gt;Author of 'The technology trap', analyzing societal impacts and societal dependency on technological advancements.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="The technology trap">
  <data key="d0">The technology trap</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A concept describing the potential negative societal and economic consequences of rapid technological development, including dependency, inequality, and social disruption.&lt;SEP&gt;A concept describing the potential pitfalls and societal impacts of rapid technological development, including dependency and inequality.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., Presser, S., and Leahy, C.">
  <data key="d0">Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., Presser, S., and Leahy, C.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of The Pile, a large diverse text dataset for language modeling, critical for training large-scale NLP models.&lt;SEP&gt;Authors of The Pile, a large-scale, diverse text dataset used for training language models, supporting research in NLP.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="The Pile">
  <data key="d0">The Pile</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An 800GB dataset comprising diverse text sources used for training large language models, enabling broad language understanding.&lt;SEP&gt;An extensive dataset comprising 800GB of diverse text data used for training language models.&lt;SEP&gt;An extensive dataset of diverse text sources designed for training and benchmarking large language models.&lt;SEP&gt;The Pile is an 800GB dataset comprising diverse textual data for training language models, aimed at improving model generalization.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Goldblum, M., Tsipras, D., Xie, C., Chen, X., Schwarzschild, A., Song, D., Madry, A., Li, B., and Goldstein, T.">
  <data key="d0">Goldblum, M., Tsipras, D., Xie, C., Chen, X., Schwarzschild, A., Song, D., Madry, A., Li, B., and Goldstein, T.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a study on dataset security, focusing on data poisoning, backdoor attacks, and defenses in machine learning.&lt;SEP&gt;Authors of a study on dataset security, focusing on vulnerabilities such as data poisoning, backdoor attacks, and defenses in machine learning datasets.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dataset security for machine learning">
  <data key="d0">Dataset security for machine learning</data>
  <data key="d1">Results</data>
  <data key="d2">Findings on vulnerabilities like data poisoning and backdoor attacks, along with defensive strategies to improve dataset robustness.&lt;SEP&gt;Research findings on vulnerabilities such as data poisoning and backdoor attacks, along with defensive strategies.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Goues, C. L., Dewey-V ogt, M., Forrest, S., and Weimer, W.">
  <data key="d0">Goues, C. L., Dewey-V ogt, M., Forrest, S., and Weimer, W.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a systematic study on automated program repair, demonstrating effectiveness in fixing bugs efficiently.&lt;SEP&gt;Authors of a systematic study on automated program repair, demonstrating effectiveness in fixing bugs.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automated program repair">
  <data key="d0">Automated program repair</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for automatically diagnosing and fixing bugs in software, reducing manual debugging effort.&lt;SEP&gt;Techniques to automatically identify and fix bugs in software, reducing manual effort and improving reliability.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="2012">
  <data key="d0">2012</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The year the study was published.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Graves, A.">
  <data key="d0">Graves, A.</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher known for work on sequence generation with recurrent neural networks and neural network architectures for complex data modeling.&lt;SEP&gt;Author known for work on sequence generation with recurrent neural networks, foundational in sequence modeling.&lt;SEP&gt;Graves is a researcher known for contributions to sequence generation and neural network architectures.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd&lt;SEP&gt;chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generating sequences with recurrent neural networks">
  <data key="d0">Generating sequences with recurrent neural networks</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A methodology for sequence prediction and generation using RNNs, influential in language modeling and time series analysis.&lt;SEP&gt;A methodology for sequence prediction and generation using RNNs, influential in language modeling and time series.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Graves, A., Wayne, G., and Danihelka, I.">
  <data key="d0">Graves, A., Wayne, G., and Danihelka, I.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of Neural Turing Machines, an extension of neural networks with external memory, enabling complex algorithms.&lt;SEP&gt;Authors of Neural Turing Machines, models that combine neural networks with external memory resources to learn algorithms.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Turing Machines">
  <data key="d0">Neural Turing Machines</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A computational model combining neural networks with external memory modules, enabling learning of algorithmic tasks and complex data manipulation.&lt;SEP&gt;A model combining neural networks with external memory resources, allowing learning of algorithmic tasks.&lt;SEP&gt;A neural network architecture that integrates external memory to enable learning of complex algorithms and data manipulation.&lt;SEP&gt;Neural Turing Machines are computational models that combine neural networks with external memory, enabling complex algorithmic tasks.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd&lt;SEP&gt;chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Clarifying 'AI alignment'">
  <data key="d0">Clarifying 'AI alignment'</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A research effort aimed at elucidating the concept of AI alignment, which concerns ensuring AI systems behave in ways aligned with human values.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sep 2018">
  <data key="d0">Sep 2018</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The date the methodology was discussed or published.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Universal Transformers">
  <data key="d0">Universal Transformers</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An advanced transformer model that integrates recurrence and dynamic computation, aiming to improve model capacity and efficiency.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="2012 34th International Conference on Software Engineering (ICSE)">
  <data key="d0">2012 34th International Conference on Software Engineering (ICSE)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An academic conference focused on research and development in software engineering, providing a platform for presenting papers, sharing innovations, and fostering collaboration among researchers and practitioners.&lt;SEP&gt;This conference is a platform for presenting research and advancements in software engineering, serving as a venue for academic and industry collaboration.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hybrid Computing with Neural Networks">
  <data key="d0">Hybrid Computing with Neural Networks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">This approach involves integrating neural networks with dynamic external memory to perform complex computations, as demonstrated in the referenced Nature paper.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Gulwani, S.">
  <data key="d0">Gulwani, S.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Gulwani's work focuses on automating string processing and data manipulation in spreadsheets through input-output examples, advancing program synthesis techniques.&lt;SEP&gt;Researcher specializing in automating string processing and data manipulation in spreadsheets through input-output examples, advancing program synthesis techniques.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Deberta">
  <data key="d0">Deberta</data>
  <data key="d1">Models</data>
  <data key="d2">A transformer-based language model that improves natural language understanding through disentangled attention and decoding enhancements.&lt;SEP&gt;Deberta is a transformer-based language model that enhances decoding with disentangled attention mechanisms for improved natural language understanding.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Helmuth, T. and Spector, L.">
  <data key="d0">Helmuth, T. and Spector, L.</data>
  <data key="d1">Study Designs</data>
  <data key="d2">They constructed a general program synthesis benchmark suite to evaluate and compare various program synthesis algorithms across different tasks.&lt;SEP&gt;They developed a general program synthesis benchmark suite to evaluate and compare different program synthesis algorithms.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hendrycks, D. et al.">
  <data key="d0">Hendrycks, D. et al.</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">They created and utilized datasets and apps to measure coding challenge competence, providing benchmarks for software engineering skills.&lt;SEP&gt;They created datasets and apps to measure coding challenge competence, providing benchmarks for assessing software development skills.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hindle, A. et al.">
  <data key="d0">Hindle, A. et al.</data>
  <data key="d1">Disciplines</data>
  <data key="d2">This research intersects software engineering, natural language processing, and machine learning by exploring the naturalness of software code.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Holtzman, A. et al.">
  <data key="d0">Holtzman, A. et al.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Holtzman and colleagues investigate issues related to neural text degeneration, analyzing the limitations and challenges of neural language models in generating coherent text.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codesearchnet Challenge">
  <data key="d0">Codesearchnet Challenge</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An evaluation benchmark for semantic code search models, assessing their ability to understand code semantics and retrieve relevant code snippets.&lt;SEP&gt;The Codesearchnet challenge is an evaluation framework for semantic code search, assessing models' ability to understand and retrieve code snippets based on semantics.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jain, P. et al.">
  <data key="d0">Jain, P. et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">They examine how contrastive learning improves code representation quality for downstream tasks like code search and classification.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jeffrey, D. et al.">
  <data key="d0">Jeffrey, D. et al.</data>
  <data key="d1">Tools</data>
  <data key="d2">Bugﬁx is a learning-based tool designed to assist developers in automatically identifying and fixing bugs in software code.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jones, C. and Bonsignour, O.">
  <data key="d0">Jones, C. and Bonsignour, O.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A book analyzing the economics of software quality, emphasizing the importance of quality assurance, defect prevention, and cost implications in software development.&lt;SEP&gt;They analyze the economics of software quality, emphasizing the importance of quality assurance and defect prevention in software development.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kaiser, Ł. and Sutskever, I.">
  <data key="d0">Kaiser, Ł. and Sutskever, I.</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Neural GPUs are models that learn algorithms by combining neural networks with GPU-like parallel computation capabilities, enabling the learning of complex algorithms.&lt;SEP&gt;Neural GPUs are models that learn algorithms through neural network architectures capable of executing complex, parallel computations, mimicking GPU operations.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kaplan, J. et al.">
  <data key="d0">Kaplan, J. et al.</data>
  <data key="d1">Study Designs</data>
  <data key="d2">They investigate scaling laws for neural language models, providing insights into how model size impacts performance and capabilities.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kenton, Z. et al.">
  <data key="d0">Kenton, Z. et al.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Kenton and colleagues focus on aligning language agents, ensuring that AI systems behave in ways aligned with human intentions and safety protocols.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Keskar, N. S. et al.">
  <data key="d0">Keskar, N. S. et al.</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Ctrl is a conditional transformer language model designed for controllable text generation, allowing users to specify attributes or constraints in generated outputs.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Korel, B. and Rilling, J.">
  <data key="d0">Korel, B. and Rilling, J.</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Application of dynamic slicing in program debugging to isolate relevant code segments during execution, aiding in fault diagnosis and troubleshooting.&lt;SEP&gt;Dynamic slicing is a program analysis technique used in debugging to isolate relevant parts of code execution, aiding in fault localization.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Koza, J. R. et al.">
  <data key="d0">Koza, J. R. et al.</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Genetic programming is an evolutionary computation method that evolves computer programs to solve problems through Darwinian principles.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kulal, S. et al.">
  <data key="d0">Kulal, S. et al.</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Spoc is a search-based approach that translates pseudocode into executable code, leveraging neural and search techniques for code synthesis.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hybrid Computing using Neural Networks with Dynamic External Memory">
  <data key="d0">Hybrid Computing using Neural Networks with Dynamic External Memory</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An approach integrating neural networks with external memory components to perform complex, dynamic computations, as demonstrated in a Nature publication.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automating String Processing in Spreadsheets">
  <data key="d0">Automating String Processing in Spreadsheets</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for automating string manipulation tasks in spreadsheets using input-output examples to generate programs automatically.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Spreadsheet Data Manipulation Using Examples">
  <data key="d0">Spreadsheet Data Manipulation Using Examples</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methodology for transforming and processing spreadsheet data based on example-driven specifications, facilitating automation and data cleaning.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="He, P., Liu, X., Gao, J., and Chen, W.">
  <data key="d0">He, P., Liu, X., Gao, J., and Chen, W.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researchers developing Deberta, a language model that enhances decoding with disentangled attention mechanisms for improved natural language understanding.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hindle, A., Barr, E. T., Su, Z., Gabel, M., and Devanbu, P.">
  <data key="d0">Hindle, A., Barr, E. T., Su, Z., Gabel, M., and Devanbu, P.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Research exploring the naturalness of software code, analyzing patterns, regularities, and predictability of programming language syntax and structure.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y.">
  <data key="d0">Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researchers investigating neural text degeneration, analyzing issues related to coherence, diversity, and quality in neural language model outputs.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jain, P., Jain, A., Zhang, T., Abbeel, P., Gonzalez, J., and Stoica, I.">
  <data key="d0">Jain, P., Jain, A., Zhang, T., Abbeel, P., Gonzalez, J., and Stoica, I.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">They investigate how contrastive code representation learning improves semantic understanding and downstream code-related tasks.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bugﬁx">
  <data key="d0">Bugﬁx</data>
  <data key="d1">Tools</data>
  <data key="d2">A learning-based tool designed to assist developers in automatically identifying and fixing bugs in software code, leveraging machine learning techniques.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D.">
  <data key="d0">Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D.</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research on scaling laws for neural language models, analyzing how increasing model size affects performance, capabilities, and resource requirements.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kenton, Z., Everitt, T., Weidinger, L., Gabriel, I., Mikulik, V., and Irving, G.">
  <data key="d0">Kenton, Z., Everitt, T., Weidinger, L., Gabriel, I., Mikulik, V., and Irving, G.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Research on aligning language agents to ensure safe, predictable, and goal-directed behavior of AI systems in natural language environments.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C., and Socher, R.">
  <data key="d0">Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C., and Socher, R.</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Ctrl is a conditional transformer model enabling controllable text generation by conditioning on specified attributes or constraints.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Koza, J. R., Andre, D., Keane, M. A., and Bennett III, F. H.">
  <data key="d0">Koza, J. R., Andre, D., Keane, M. A., and Bennett III, F. H.</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Genetic programming is an evolutionary algorithm that evolves computer programs to solve problems, inspired by biological evolution principles.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kulal, S., Pasupat, P., Chandra, K., Lee, M., Padon, O., Aiken, A., and Liang, P. S.">
  <data key="d0">Kulal, S., Pasupat, P., Chandra, K., Lee, M., Padon, O., Aiken, A., and Liang, P. S.</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Spoc is a search-based pseudocode-to-code system that uses neural and search techniques to generate executable code from high-level pseudocode descriptions.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Information Processing Systems">
  <data key="d0">Neural Information Processing Systems</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference proceedings volume that compiles research papers related to neural information processing, including advancements and methodologies.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Wallach, H., Larochelle, H., Beygelzimer, A., d'Alch é-Buc, F., Fox, E., Garnett, R.">
  <data key="d0">Wallach, H., Larochelle, H., Beygelzimer, A., d'Alch é-Buc, F., Fox, E., Garnett, R.</data>
  <data key="d1">Authors/Editors</data>
  <data key="d2">A group of researchers and editors responsible for compiling and editing the proceedings of the Neural Information Processing Systems conference in 2019.&lt;SEP&gt;A group of researchers and editors responsible for editing and compiling the proceedings of the Neural Information Processing Systems conference in 2019.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Advances in Neural Information Processing Systems">
  <data key="d0">Advances in Neural Information Processing Systems</data>
  <data key="d1">Study Design</data>
  <data key="d2">A collection of research papers and studies focusing on neural information processing, machine learning, and related methodologies.&lt;SEP&gt;A collection of research papers and studies focusing on neural information processing, machine learning, deep learning, and related methodologies presented at the conference.&lt;SEP&gt;A leading conference in neural network research and machine learning.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c&lt;SEP&gt;chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="URL">
  <data key="d0">URL</data>
  <data key="d1">Tools</data>
  <data key="d2">A web link providing access to the conference proceedings or specific papers, facilitating access to research data and publications.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Lacasse, N.">
  <data key="d0">Lacasse, N.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of a 2018 work on open-sourcing gvisor, a sandboxed container runtime, contributing to secure computing environments.&lt;SEP&gt;Author of a work on open-sourcing gvisor, a sandboxed container runtime, published in 2018.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="gvisor">
  <data key="d0">gvisor</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A sandboxed container runtime designed for secure and isolated execution environments, open-sourced by Lacasse in 2018.&lt;SEP&gt;A sandboxed container runtime designed for secure, isolated execution environments, open-sourced by Lacasse in 2018.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Lachaux, M.-A., Rozière, B., Chanussot, L., Lample, G.">
  <data key="d0">Lachaux, M.-A., Rozière, B., Chanussot, L., Lample, G.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a 2020 paper on unsupervised translation of programming languages, exploring methods for translating code across languages without labeled data.&lt;SEP&gt;Authors of a 2020 paper on unsupervised translation of programming languages, focusing on language translation without labeled data.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Unsupervised translation of programming languages">
  <data key="d0">Unsupervised translation of programming languages</data>
  <data key="d1">Research Topic</data>
  <data key="d2">A methodology or research area focused on translating code between programming languages without supervised data, as studied in the 2020 paper.&lt;SEP&gt;A methodology or study area focused on translating code between programming languages without supervised learning, as explored in the 2020 paper.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Leveson, N.">
  <data key="d0">Leveson, N.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of a 2019 work aimed at improving the standard risk matrix, a tool used for risk assessment.&lt;SEP&gt;Author of a 2019 work on improving the standard risk matrix, a tool used in risk assessment and safety analysis.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Risk Matrix">
  <data key="d0">Risk Matrix</data>
  <data key="d1">Tools</data>
  <data key="d2">A standard risk assessment tool used to evaluate and prioritize risks, with proposed improvements in 2019 by Leveson.&lt;SEP&gt;A standard risk assessment tool used to evaluate, categorize, and prioritize risks, with proposed improvements by Leveson in 2019.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Li, P. L., Ko, A. J., Begel, A.">
  <data key="d0">Li, P. L., Ko, A. J., Begel, A.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a 2020 empirical study on distinguishing great software engineers, analyzing traits and behaviors.&lt;SEP&gt;Authors of a 2020 empirical study on distinguishing great software engineers, analyzing traits, practices, and skills.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Empirical Software Engineering">
  <data key="d0">Empirical Software Engineering</data>
  <data key="d1">Study Design</data>
  <data key="d2">A journal or research field focusing on empirical studies and data-driven analysis of software engineering practices.&lt;SEP&gt;A research field or journal focusing on empirical, data-driven studies of software engineering practices and traits.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Latent predictor networks for code generation">
  <data key="d0">Latent predictor networks for code generation</data>
  <data key="d1">Methodology</data>
  <data key="d2">A machine learning approach utilizing latent predictors to generate code, presented in a 2016 conference.&lt;SEP&gt;A neural network-based approach utilizing latent predictors to generate source code, presented in 2016.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ling, W., Blunsom, P., Grefenstette, E., Hermann, K. M., Kočíský, T., Wang, F., Senior, A.">
  <data key="d0">Ling, W., Blunsom, P., Grefenstette, E., Hermann, K. M., Kočíský, T., Wang, F., Senior, A.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a 2016 paper on latent predictor networks for code generation, exploring neural architectures for programming tasks.&lt;SEP&gt;Authors of a 2016 paper on latent predictor networks for code generation, exploring neural network architectures for programming tasks.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Roberta: A robustly optimized BERT pretraining approach">
  <data key="d0">Roberta: A robustly optimized BERT pretraining approach</data>
  <data key="d1">Methodology</data>
  <data key="d2">A pretraining methodology for BERT models that enhances robustness and performance, introduced in 2019.&lt;SEP&gt;A pretraining technique for BERT models to enhance robustness and performance, introduced in 2019.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., Stoyanov, V.">
  <data key="d0">Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., Stoyanov, V.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of RoBERTa, a pretraining approach for transformer language models, published in 2019.&lt;SEP&gt;Authors of the RoBERTa model, a pretraining approach for transformer-based language models, published in 2019.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks">
  <data key="d0">Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks</data>
  <data key="d1">Methodology</data>
  <data key="d2">A pretraining framework for joint vision and language models enabling multi-modal understanding, published in 2019.&lt;SEP&gt;A pretraining framework for joint vision and language understanding, enabling models to handle multi-modal data, published in 2019.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codexglue: A machine learning benchmark dataset for code understanding and generation">
  <data key="d0">Codexglue: A machine learning benchmark dataset for code understanding and generation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark dataset designed for evaluating models on code understanding and generation tasks, introduced in 2021.&lt;SEP&gt;A benchmark dataset designed to evaluate models on code understanding and generation tasks, introduced in 2021.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Maddison, C. J., Tarlow, D.">
  <data key="d0">Maddison, C. J., Tarlow, D.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a 2014 paper on structured generative models of natural source code, exploring probabilistic models for code synthesis.&lt;SEP&gt;Authors of a 2014 paper on structured generative models of natural source code, focusing on probabilistic models for code synthesis.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Structured generative models of natural source code">
  <data key="d0">Structured generative models of natural source code</data>
  <data key="d1">Methodology</data>
  <data key="d2">Probabilistic models that generate source code structures, aiming to facilitate automatic code synthesis.&lt;SEP&gt;Probabilistic models that generate source code structures, aiming to facilitate automatic program synthesis and understanding.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Manna, Z., Waldinger, R. J.">
  <data key="d0">Manna, Z., Waldinger, R. J.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a 1971 paper on automatic program synthesis, discussing early approaches to automated code generation.&lt;SEP&gt;Authors of a 1971 paper on automatic program synthesis, exploring early approaches and theories for automated code generation.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automatic program synthesis">
  <data key="d0">Automatic program synthesis</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">The investigation into methods and theories for automatically generating or synthesizing computer programs.&lt;SEP&gt;The investigation into methods for automatically generating or synthesizing computer programs.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Masanet, E., Shehabi, A., Lei, N., Smith, S., Koomey, J.">
  <data key="d0">Masanet, E., Shehabi, A., Lei, N., Smith, S., Koomey, J.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a 2020 study on recalibrating global data center energy-use estimates, analyzing energy consumption data and models.&lt;SEP&gt;Authors of a 2020 study on recalibrating global data center energy-use estimates, analyzing energy consumption patterns.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Global data center energy-use estimates">
  <data key="d0">Global data center energy-use estimates</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Estimates of energy consumption by data centers worldwide, with a focus on recalibration and accuracy.&lt;SEP&gt;Estimates of energy consumption by data centers worldwide, with focus on recalibration and improving accuracy.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Discrepancies in energy estimates">
  <data key="d0">Discrepancies in energy estimates</data>
  <data key="d1">Results</data>
  <data key="d2">Findings indicating that current global data center energy-use estimates require recalibration for accuracy and reliability.&lt;SEP&gt;Findings indicating the need to recalibrate and improve the accuracy of global data center energy consumption data.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Menezes, A., van Oorschot, P., Vanstone, S.">
  <data key="d0">Menezes, A., van Oorschot, P., Vanstone, S.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of the 2018 'Handbook of Applied Cryptography', a comprehensive resource on cryptographic algorithms, protocols, and security techniques.&lt;SEP&gt;Authors of the 2018 'Handbook of Applied Cryptography', a comprehensive resource on cryptographic techniques and applications.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Handbook of Applied Cryptography">
  <data key="d0">Handbook of Applied Cryptography</data>
  <data key="d1">Tools</data>
  <data key="d2">A comprehensive reference book on cryptographic algorithms, protocols, and security practices used in secure communications.&lt;SEP&gt;A reference book providing cryptographic algorithms, protocols, and applications used in security and encryption.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Menick, J., Kalchbrenner, N.">
  <data key="d0">Menick, J., Kalchbrenner, N.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a 2018 paper on generating high-fidelity images using subscale pixel networks and multidimensional upscaling, advancing image synthesis methods.&lt;SEP&gt;Authors of a 2018 paper on generating high-fidelity images with subscale pixel networks, focusing on image synthesis techniques.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Subscale Pixel Networks and Multidimensional Upscaling">
  <data key="d0">Subscale Pixel Networks and Multidimensional Upscaling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Advanced image generation techniques modeling pixel dependencies across scales for high-quality image synthesis.&lt;SEP&gt;Techniques for generating high-quality images by modeling pixel dependencies across multiple scales.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., Dean, J.">
  <data key="d0">Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., Dean, J.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a 2013 paper on distributed representations of words and phrases, foundational for word embeddings and NLP models.&lt;SEP&gt;Authors of a 2013 paper on distributed representations of words and phrases, foundational to word embedding methods.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Distributed representations of words and phrases">
  <data key="d0">Distributed representations of words and phrases</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A foundational concept in natural language processing where words are represented as vectors capturing semantic relationships.&lt;SEP&gt;A fundamental NLP concept where words are represented as vectors capturing semantic and syntactic relationships.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ohm, M., Plate, H., Sykosch, A., Meier, M.">
  <data key="d0">Ohm, M., Plate, H., Sykosch, A., Meier, M.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a 2020 review on open source software supply chain attacks, analyzing security vulnerabilities and attack vectors.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Open source software supply chain attacks">
  <data key="d0">Open source software supply chain attacks</data>
  <data key="d1">Results</data>
  <data key="d2">A review highlighting vulnerabilities in open source supply chains and security risks.&lt;SEP&gt;A review identifying vulnerabilities and security risks in open source software supply chains.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="O’Keefe, C., Lansky, D., Clark, J., Payne, C.">
  <data key="d0">O’Keefe, C., Lansky, D., Clark, J., Payne, C.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a 2019 comment on intellectual property protection for AI innovation, discussing legal and policy considerations.&lt;SEP&gt;Authors of a 2019 comment on intellectual property protection for AI, discussing legal, policy, and innovation implications.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Intellectual property protection for AI">
  <data key="d0">Intellectual property protection for AI</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">The discussion on how to legally protect AI innovations and the implications for innovation and patent law.&lt;SEP&gt;The inquiry into how to effectively protect AI innovations through legal and policy measures, impacting innovation.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="O*NET 15-1252.00 - Software Developers">
  <data key="d0">O*NET 15-1252.00 - Software Developers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A classification and description of software developer jobs, including skills, roles, and occupational data, available via O*NET.&lt;SEP&gt;A classification and occupational profile of software developers, detailing skills, roles, and employment data.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="15-1252.00">
  <data key="d0">15-1252.00</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The O*NET code 15-1252.00 refers to software developers, detailing their roles, skills, and activities in software creation and maintenance.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="O*NET">
  <data key="d0">O*NET</data>
  <data key="d1">Tools</data>
  <data key="d2">O*NET is a comprehensive online database providing detailed descriptions of occupations, including skills, tasks, and work environments for various professions.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Oord, A. v. d., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Senior, A., and Kavukcuoglu, K.">
  <data key="d0">Oord, A. v. d., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Senior, A., and Kavukcuoglu, K.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">A team of researchers involved in developing generative models and representation learning techniques in machine learning.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Wavenet">
  <data key="d0">Wavenet</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Wavenet is a generative model for raw audio data, capable of producing realistic sound waveforms by modeling the probability distribution of audio signals.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Contrastive Predictive Coding">
  <data key="d0">Contrastive Predictive Coding</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A representation learning technique that maximizes mutual information between different parts of data to learn useful features without labels.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="O’Neill, M. and Spector, L.">
  <data key="d0">O’Neill, M. and Spector, L.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">Researchers discussing open issues in automatic programming and genetic programming methodologies.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Genetic Programming and Evolvable Machines">
  <data key="d0">Genetic Programming and Evolvable Machines</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A journal publishing research on evolutionary algorithms, genetic programming, and machine evolution methodologies.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pantridge, E., Helmuth, T., McPhee, N. F., and Spector, L.">
  <data key="d0">Pantridge, E., Helmuth, T., McPhee, N. F., and Spector, L.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">Researchers analyzing the difficulty of benchmarking inductive program synthesis methods.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Carbon emissions and large neural network training">
  <data key="d0">Carbon emissions and large neural network training</data>
  <data key="d1">Results</data>
  <data key="d2">A study quantifying the environmental impact, specifically carbon footprint, associated with training large neural networks.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Patterson, D., Gonzalez, J., Le, Q., Liang, C., Munguia, L.-M., Rothchild, D., So, D., Texier, M., and Dean, J.">
  <data key="d0">Patterson, D., Gonzalez, J., Le, Q., Liang, C., Munguia, L.-M., Rothchild, D., So, D., Texier, M., and Dean, J.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">Researchers examining the environmental costs of large-scale neural network training.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Deep contextualized word representations">
  <data key="d0">Deep contextualized word representations</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model for generating context-aware word embeddings that improve natural language understanding.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L.">
  <data key="d0">Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">Researchers developing deep contextualized word embedding models for NLP tasks.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Learning transferable visual models from natural language supervision">
  <data key="d0">Learning transferable visual models from natural language supervision</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A study exploring how visual models trained with natural language data can transfer knowledge across tasks.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., and Sutskever, I.">
  <data key="d0">Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., and Sutskever, I.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">Researchers developing and evaluating models for zero-shot text-to-image generation.&lt;SEP&gt;Researchers involved in developing and evaluating zero-shot text-to-image generation models.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Zero-shot text-to-image generation">
  <data key="d0">Zero-shot text-to-image generation</data>
  <data key="d1">Results</data>
  <data key="d2">A method enabling models to generate images from textual descriptions without prior task-specific training.&lt;SEP&gt;Enables creating images from textual descriptions without specific training, impacting creative industries and AI-generated content.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Radford, A., Narasimhan, K., Salimans, T., and Sutskever, I.">
  <data key="d0">Radford, A., Narasimhan, K., Salimans, T., and Sutskever, I.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">Researchers who pioneered generative pre-training for language understanding.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Improving language understanding by generative pre-training">
  <data key="d0">Improving language understanding by generative pre-training</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A foundational approach where language models are trained to generate text, leading to improved understanding and performance on NLP tasks.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.">
  <data key="d0">Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">Researchers demonstrating that large-scale unsupervised language models function as multitask learners.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Language models are unsupervised multitask learners">
  <data key="d0">Language models are unsupervised multitask learners</data>
  <data key="d1">Results</data>
  <data key="d2">Large language models trained via unsupervised learning can perform multiple NLP tasks without task-specific fine-tuning.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Raffel, C., Shazeer, N. M., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J.">
  <data key="d0">Raffel, C., Shazeer, N. M., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">Researchers exploring transfer learning limits using a unified text-to-text transformer architecture.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Exploring the limits of transfer learning with a unified text-to-text transformer">
  <data key="d0">Exploring the limits of transfer learning with a unified text-to-text transformer</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A study assessing how far transfer learning can be pushed using a single, versatile transformer model across multiple NLP tasks.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Reed, S. and de Freitas, N.">
  <data key="d0">Reed, S. and de Freitas, N.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">Researchers working on neural programmer-interpreters, which are models that learn to interpret and execute programs.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural programmer-interpreters">
  <data key="d0">Neural programmer-interpreters</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Models designed to learn and execute programming instructions, bridging neural networks and program execution.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ren, S., Guo, D., Lu, S., Zhou, L., Liu, S., Tang, D., Sundaresan, N., Zhou, M., Blanco, A., and Ma, S.">
  <data key="d0">Ren, S., Guo, D., Lu, S., Zhou, L., Liu, S., Tang, D., Sundaresan, N., Zhou, M., Blanco, A., and Ma, S.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">Researchers developing CodeBLEU, an automatic evaluation metric for code synthesis systems.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="CodeBLEU">
  <data key="d0">CodeBLEU</data>
  <data key="d1">Tools</data>
  <data key="d2">An automatic evaluation metric for assessing the quality of generated code by measuring similarity to reference code, similar to BLEU for language.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Rives, A., Meier, J., Sercu, T., Goyal, S., Lin, Z., Liu, J., Guo, D., Ott, M., Zitnick, C. L., Ma, J., et al.">
  <data key="d0">Rives, A., Meier, J., Sercu, T., Goyal, S., Lin, Z., Liu, J., Guo, D., Ott, M., Zitnick, C. L., Ma, J., et al.</data>
  <data key="d1">Research Group/Authors</data>
  <data key="d2">Researchers studying the emergence of biological structure and function from large-scale unsupervised learning of protein sequences.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Biological structure and function from protein sequences">
  <data key="d0">Biological structure and function from protein sequences</data>
  <data key="d1">Results</data>
  <data key="d2">Demonstrates that scaling unsupervised learning to 250 million protein sequences reveals emergent biological properties.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sourcefinder">
  <data key="d0">Sourcefinder</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A computational tool designed to identify malware source code from publicly available repositories, such as GitHub.&lt;SEP&gt;A computational tool designed to locate malware source code within public repositories like GitHub, facilitating security research.&lt;SEP&gt;A tool designed to identify malware source code from publicly available repositories on GitHub.&lt;SEP&gt;Can malware source code be accurately identified from publicly available repositories using automated tools?</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c&lt;SEP&gt;chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Biological Structure and Function">
  <data key="d0">Biological Structure and Function</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Biological structure and function emerge from scaling unsupervised learning to analyze 250 million protein sequences, highlighting relationships between biological form and computational learning methods.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Scaling Unsupervised Learning">
  <data key="d0">Scaling Unsupervised Learning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A machine learning approach applied to large-scale protein sequence analysis to understand biological structures and functions.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Protein Sequences">
  <data key="d0">Protein Sequences</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Large datasets of amino acid sequences used to explore biological and computational phenomena.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Proceedings of the National Academy of Sciences">
  <data key="d0">Proceedings of the National Academy of Sciences</data>
  <data key="d1">Discipline</data>
  <data key="d2">A scientific journal publishing high-impact research in biological and interdisciplinary sciences.&lt;SEP&gt;A scientific journal publishing research on biological and computational sciences.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malware Source Code">
  <data key="d0">Malware Source Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Malicious software source code extracted from repositories for analysis and detection.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="International Symposium on Research in Attacks, Intrusions and Defenses (RAID) 2020">
  <data key="d0">International Symposium on Research in Attacks, Intrusions and Defenses (RAID) 2020</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference where research on security vulnerabilities, including malware source code detection, is presented.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Poisoning Vulnerabilities in Neural Code Completion">
  <data key="d0">Poisoning Vulnerabilities in Neural Code Completion</data>
  <data key="d1">Results</data>
  <data key="d2">Research demonstrating how poisoning attacks can compromise neural code completion systems, revealing security vulnerabilities.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Advanced Computing Systems Association">
  <data key="d0">Advanced Computing Systems Association</data>
  <data key="d1">Discipline</data>
  <data key="d2">An organization focused on advances in computing, including security and neural systems.&lt;SEP&gt;An organization focused on advances in high-performance and security computing.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Program Synthesis">
  <data key="d0">Neural Program Synthesis</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The automatic generation of computer programs using neural networks, with efforts to improve accuracy and reliability.&lt;SEP&gt;The process of automatically generating computer programs using neural networks, with improvements made through inferred execution traces.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Inferred Execution Traces">
  <data key="d0">Inferred Execution Traces</data>
  <data key="d1">Variables</data>
  <data key="d2">Execution traces inferred during neural program synthesis to enhance model performance and correctness.&lt;SEP&gt;Execution traces inferred from neural models to improve program synthesis accuracy.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sequence to Sequence Learning">
  <data key="d0">Sequence to Sequence Learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A neural network approach for translating sequences, such as language to code, enabling tasks like translation and code generation.&lt;SEP&gt;A neural network framework for translating sequences, such as natural language to code, enabling automated code generation.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="End-to-End Memory Networks">
  <data key="d0">End-to-End Memory Networks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Neural architectures that incorporate memory components to improve reasoning and contextual understanding in AI systems.&lt;SEP&gt;Neural network architectures that incorporate memory components to improve reasoning and context retention.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Women’s Participation in Open Source Software">
  <data key="d0">Women’s Participation in Open Source Software</data>
  <data key="d1">Study Design</data>
  <data key="d2">A literature survey analyzing gender participation in open source communities.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Learning Bug-Fixing Patches">
  <data key="d0">Learning Bug-Fixing Patches</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Can neural machine translation be used to learn effective bug-fixing patches from real-world data?</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Unit Test Case Generation with Transformers">
  <data key="d0">Unit Test Case Generation with Transformers</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Using transformer models to automatically generate unit tests based on focal context.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pixel Recurrent Neural Networks">
  <data key="d0">Pixel Recurrent Neural Networks</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural architecture designed for image analysis and generation involving pixel-level recurrence.&lt;SEP&gt;A neural network architecture designed for image generation and analysis involving pixel-level recurrence.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-J-6B">
  <data key="d0">GPT-J-6B</data>
  <data key="d1">Tools</data>
  <data key="d2">A 6-billion-parameter autoregressive language model trained on code and text for tasks like code generation.&lt;SEP&gt;A 6-billion-parameter autoregressive language model trained on code and text, used for code generation and related tasks.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Generation from Natural Language">
  <data key="d0">Code Generation from Natural Language</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The process of automatically generating source code based on natural language descriptions, with promise and challenges identified.&lt;SEP&gt;The process of translating natural language descriptions into source code, with promise and challenges identified.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="arXiv Preprint">
  <data key="d0">arXiv Preprint</data>
  <data key="d1">Discipline</data>
  <data key="d2">A repository for pre-publication research papers in fields like computer science and AI.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Network Architectures">
  <data key="d0">Neural Network Architectures</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Various architectures such as transformers, memory networks, and recurrent models used for AI tasks.&lt;SEP&gt;Various models like transformers, recurrent neural networks, and memory networks used for tasks such as code synthesis, translation, and image analysis.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Research in Attacks, Intrusions and Defenses (RAID) 2020">
  <data key="d0">Research in Attacks, Intrusions and Defenses (RAID) 2020</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference presenting research on cybersecurity vulnerabilities, including malware analysis.&lt;SEP&gt;An international symposium presenting research on cybersecurity, including malware source code detection methods.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Protein">
  <data key="d0">Protein</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A biological molecule consisting of amino acid chains, studied through large datasets of sequences to understand biological structure and function.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Unsupervised Learning">
  <data key="d0">Unsupervised Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A machine learning approach that models data without labeled outcomes, applied here to analyze large-scale protein sequences and discover biological insights.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="250 Million Protein Sequences">
  <data key="d0">250 Million Protein Sequences</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A vast dataset of protein sequences used to train models and analyze biological phenomena.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malware Source-Code">
  <data key="d0">Malware Source-Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Malicious software code extracted from repositories for analysis, detection, and understanding security vulnerabilities.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GitHub">
  <data key="d0">GitHub</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large online platform hosting open-source code repositories, used as a data source for malware source code identification.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Poisoning Attacks">
  <data key="d0">Poisoning Attacks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A security threat where adversaries manipulate neural network training data to compromise model integrity, particularly in neural code completion systems.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Code Completion">
  <data key="d0">Neural Code Completion</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">AI systems that automatically generate code snippets, which can be vulnerable to poisoning attacks.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Security Vulnerabilities">
  <data key="d0">Security Vulnerabilities</data>
  <data key="d1">Results</data>
  <data key="d2">Findings that neural code completion systems are susceptible to poisoning attacks, highlighting security concerns.&lt;SEP&gt;Findings that poisoning attacks can exploit neural code completion systems, revealing potential risks in AI-driven coding tools.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Learning from Human Feedback">
  <data key="d0">Learning from Human Feedback</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A methodology where models are trained to improve performance based on human-provided evaluations, applied to summarization tasks.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Summarization">
  <data key="d0">Summarization</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The task of condensing information into shorter, meaningful summaries, improved by learning from human feedback.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Women’s Participation in Open Source">
  <data key="d0">Women’s Participation in Open Source</data>
  <data key="d1">Study Design</data>
  <data key="d2">A survey-based research examining gender diversity and participation in open source software communities.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bug-Fixing Patches">
  <data key="d0">Bug-Fixing Patches</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code modifications aimed at fixing software bugs, learned via neural machine translation from real-world data.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Machine Translation">
  <data key="d0">Neural Machine Translation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A deep learning approach to automatically translate code or language, used here to learn bug-fixing patches.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Unit Test Cases">
  <data key="d0">Unit Test Cases</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Automated tests generated to verify software correctness, with recent approaches using transformers and focal context.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Research Challenges">
  <data key="d0">Research Challenges</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Identifying the promise and challenges of natural language code generation using AI models.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Research Papers">
  <data key="d0">Research Papers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Scientific articles presenting empirical and theoretical findings in AI, machine learning, and cybersecurity.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Synthesis">
  <data key="d0">Code Synthesis</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The automatic generation of code from specifications or natural language, improving with advanced models.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="F. F. Xu, Vasilescu, B., and Neubig, G.">
  <data key="d0">F. F. Xu, Vasilescu, B., and Neubig, G.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Authors of a study on in-ide code generation from natural language, discussing promises and challenges.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="In-ide code generation from natural language">
  <data key="d0">In-ide code generation from natural language</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A research area focused on automatically generating code within IDEs based on natural language inputs, highlighting potential and difficulties.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Yin, P. and Neubig, G.">
  <data key="d0">Yin, P. and Neubig, G.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Authors of a neural model for general-purpose code generation, presenting a syntactic neural approach.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Syntactic neural model for code generation">
  <data key="d0">Syntactic neural model for code generation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A neural network model utilizing syntax-aware techniques to generate code across various purposes, aiming for improved accuracy.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Zaremba, W. and Sutskever, I.">
  <data key="d0">Zaremba, W. and Sutskever, I.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Authors of a study on learning to execute code, exploring models that can perform code execution tasks.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Learning to execute">
  <data key="d0">Learning to execute</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model or framework designed to enable neural networks to learn and perform code execution tasks.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Zellers, R., Lu, X., Hessel, J., Yu, Y., Park, J. S., Cao, J., Farhadi, A., and Choi, Y.">
  <data key="d0">Zellers, R., Lu, X., Hessel, J., Yu, Y., Park, J. S., Cao, J., Farhadi, A., and Choi, Y.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Authors of Merlot, a multimodal neural script knowledge model integrating various data modalities for understanding scripts.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Merlot: Multimodal neural script knowledge models">
  <data key="d0">Merlot: Multimodal neural script knowledge models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A multimodal neural network model that captures script knowledge from multiple data sources to improve understanding of sequences and events.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Zhao, T. Z., Wallace, E., Feng, S., Klein, D., and Singh, S.">
  <data key="d0">Zhao, T. Z., Wallace, E., Feng, S., Klein, D., and Singh, S.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Authors of a study on improving few-shot performance of language models through calibration techniques.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Calibrate before use">
  <data key="d0">Calibrate before use</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to enhance the few-shot learning capabilities of language models by calibration prior to deployment.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ziegler, A.">
  <data key="d0">Ziegler, A.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author investigating rote learning in GitHub Copilot suggestions, analyzing how suggestions may rely on memorized patterns.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Rote learning in GitHub Copilot suggestions">
  <data key="d0">Rote learning in GitHub Copilot suggestions</data>
  <data key="d1">Results</data>
  <data key="d2">An observed phenomenon where GitHub Copilot's code suggestions may be based on memorized patterns, indicating possible rote learning behavior.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Estimating pass@k">
  <data key="d0">Estimating pass@k</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A statistical approach for evaluating the success probability (pass@k) of code generation models, emphasizing unbiased estimators for fair comparison.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Unbiased estimator for pass@k">
  <data key="d0">Unbiased estimator for pass@k</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A statistical estimator that accurately measures the true pass@k rate without bias, crucial for fair evaluation of code generation models.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Random Problems from HumanEval">
  <data key="d0">Random Problems from HumanEval</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A set of randomly selected coding problems used to evaluate language models' code generation capabilities.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Solutions from Codex-12B">
  <data key="d0">Solutions from Codex-12B</data>
  <data key="d1">Tools</data>
  <data key="d2">Sample code outputs generated by the Codex-12B model at a specified temperature setting, used to assess model performance.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="def words_string(s)">
  <data key="d0">def words_string(s)</data>
  <data key="d1">Study Design</data>
  <data key="d2">A programming problem designed to evaluate the ability of language models to parse strings into words, with multiple code completion approaches.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="is_prime(n)">
  <data key="d0">is_prime(n)</data>
  <data key="d1">Study Design</data>
  <data key="d2">A programming problem testing whether a language model can implement a prime number checking function.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Words in String">
  <data key="d0">Words in String</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The phrase 'words in the string' refers to the individual words extracted from a given string, representing basic units of language.</data>
  <data key="d3">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Words">
  <data key="d0">Words</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The individual words contained within the string, analyzed as fundamental units of language.</data>
  <data key="d3">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="String">
  <data key="d0">String</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A sequence of characters or text from which words are extracted for linguistic analysis.</data>
  <data key="d3">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Text Analysis">
  <data key="d0">Text Analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of examining and processing text data to extract meaningful information, such as words, patterns, or structures.</data>
  <data key="d3">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Language Processing">
  <data key="d0">Language Processing</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The scientific study and computational analysis of human language.</data>
  <data key="d3">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="y">
  <data key="d0">y</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The letter 'y' functions as a vowel in English, but only when it appears at the end of a word, illustrating its contextual phonetic role.&lt;SEP&gt;The letter 'y' is classified as a vowel, but only when it appears at the end of a word, highlighting its contextual role in language and phonetics.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="vowels_count">
  <data key="d0">vowels_count</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A function designed to count vowels in a string, considering 'y' as a vowel only at the end of words, demonstrating linguistic text analysis.&lt;SEP&gt;A function that counts the number of vowels in a string, considering 'y' as a vowel only at the end of words, demonstrating a linguistic counting approach.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="examples">
  <data key="d0">examples</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Sample input strings and their expected vowel counts, used to illustrate the behavior of the vowels_count function.&lt;SEP&gt;Sample inputs and outputs used to illustrate the vowel counting function, showing how the function behaves with different strings.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="vowels">
  <data key="d0">vowels</data>
  <data key="d1">Variables</data>
  <data key="d2">A set or list containing the characters 'a', 'e', 'i', 'o', 'u', and 'y', used to check membership during vowel counting.&lt;SEP&gt;A string containing all vowels ('a', 'e', 'i', 'o', 'u') and 'y', used for checking membership during counting.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="counting algorithm">
  <data key="d0">counting algorithm</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Iterative process that examines each character in a string to determine if it is a vowel based on position and membership in the vowel set.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="string processing">
  <data key="d0">string processing</data>
  <data key="d1">Tools</data>
  <data key="d2">Use of string conversion and iteration to analyze and process text data for vowel counting.&lt;SEP&gt;Use of string conversion, iteration, and conditional checks to analyze text data for vowel counting.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="language rules">
  <data key="d0">language rules</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The contextual classification of 'y' as a vowel depending on its position in a word, reflecting phonetic and linguistic rules.&lt;SEP&gt;The rule that 'y' is considered a vowel only at the end of words reflects phonetic and linguistic classification.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="phonetics">
  <data key="d0">phonetics</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The study of speech sounds and their roles in language, relevant to understanding the contextual vowel status of 'y'.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="text analysis">
  <data key="d0">text analysis</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The application of computational methods to analyze linguistic features such as vowel counts in text.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="input strings">
  <data key="d0">input strings</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The strings 'abcde' and 'ACEDY' used as examples to demonstrate how the function counts vowels.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="expected outputs">
  <data key="d0">expected outputs</data>
  <data key="d1">Results</data>
  <data key="d2">The numbers 2 and 3 representing the count of vowels in the example strings, illustrating the function's correctness.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="b_digit">
  <data key="d0">b_digit</data>
  <data key="d1">Variables</data>
  <data key="d2">b_digit is a variable representing the units digit of variable b, used in calculations involving modular arithmetic to extract digits.&lt;SEP&gt;b_digit is a variable representing the units digit of variable b, used in calculations.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="b">
  <data key="d0">b</data>
  <data key="d1">Variables</data>
  <data key="d2">b is a variable representing an integer, manipulated through division and modulus operations.&lt;SEP&gt;b is an integer variable that undergoes division and modulus operations to extract digits and perform calculations.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="result">
  <data key="d0">result</data>
  <data key="d1">Variables</data>
  <data key="d2">result is a variable accumulating the computed value based on digits of b and a, involving multiplication and power operations.&lt;SEP&gt;result is a variable accumulating the final calculated value based on digits of b and a, involving multiplication and powers, representing the computed outcome of the function.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="power">
  <data key="d0">power</data>
  <data key="d1">Variables</data>
  <data key="d2">power is a variable used as an exponent in power calculations to construct the final result.&lt;SEP&gt;power is a variable used as an exponent in the calculation to place digits at correct positional values, starting from 1 and incrementing.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="a_digit">
  <data key="d0">a_digit</data>
  <data key="d1">Variables</data>
  <data key="d2">a_digit is a variable representing the units digit of variable a, used in the calculation of result.&lt;SEP&gt;a_digit is a variable representing the units digit of variable a, used similarly to b_digit in constructing the result.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ifb&lt;0">
  <data key="d0">ifb&lt;0</data>
  <data key="d1">Study Design</data>
  <data key="d2">Conditional check to determine if variable b is negative, affecting the return value.&lt;SEP&gt;Conditional check to determine if variable b is negative, which influences the return value by negating the result.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="return 0 - result">
  <data key="d0">return 0 - result</data>
  <data key="d1">Result</data>
  <data key="d2">Returns the negated result when b is negative, handling sign appropriately.&lt;SEP&gt;Returns the negative of the accumulated result when b is less than zero, effectively handling negative input.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="return result">
  <data key="d0">return result</data>
  <data key="d1">Result</data>
  <data key="d2">Returns the computed result when b is non-negative, completing the function's calculation.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="number">
  <data key="d0">number</data>
  <data key="d1">Variables</data>
  <data key="d2">number is a variable representing the product of a and b, used in subsequent calculations.&lt;SEP&gt;number is a variable representing the product of a and b, used in subsequent digit processing or calculations.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="string">
  <data key="d0">string</data>
  <data key="d1">Variables</data>
  <data key="d2">string is a variable converting number into a string for digit iteration and summing individual digits.&lt;SEP&gt;string is a variable converting number into string format for digit processing.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="total">
  <data key="d0">total</data>
  <data key="d1">Variables</data>
  <data key="d2">total accumulates the sum of individual digits of a number.&lt;SEP&gt;total is a variable that sums the digits of the number by iterating through its string representation.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="i">
  <data key="d0">i</data>
  <data key="d1">Variables</data>
  <data key="d2">i is an iterator variable used to loop through each character in the string representation of number, converting characters back to integers.&lt;SEP&gt;i is used as an iterator over each character in the string representation of number.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="n">
  <data key="d0">n</data>
  <data key="d1">Variables</data>
  <data key="d2">n is a parameter representing an integer input to the function, used to generate a range of numbers.&lt;SEP&gt;n is an input parameter representing an integer limit, used to generate a range of numbers for counting palindromes.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="even_odd_palindrome(n)">
  <data key="d0">even_odd_palindrome(n)</data>
  <data key="d1">Study Design</data>
  <data key="d2">Function that counts even and odd palindromic numbers within a range from 1 to n.&lt;SEP&gt;Function that counts the number of even and odd palindromic numbers within the range 1 to n inclusive, based on their string symmetry and parity.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Example 1">
  <data key="d0">Example 1</data>
  <data key="d1">Study Design</data>
  <data key="d2">Sample input (n=3) and output demonstrating counting of palindromic numbers, showing 1, 2, 3 with counts of even and odd.&lt;SEP&gt;Sample input and output demonstrating the counting of palindromic numbers within a range.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Example 2">
  <data key="d0">Example 2</data>
  <data key="d1">Study Design</data>
  <data key="d2">Another sample illustrating the counting process for a larger range.&lt;SEP&gt;Sample input (n=12) and output illustrating the counts of palindromes within a larger range, including 11 as an even palindrome.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Note">
  <data key="d0">Note</data>
  <data key="d1">Study Design</data>
  <data key="d2">Notes clarifying the constraints and expected output format for the function.&lt;SEP&gt;Notes specifying constraints (1 &lt;= n &lt;= 10^3) and expected output format for the palindrome counting function.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 8 (WRONG)">
  <data key="d0">COMPLETION 8 (WRONG)</data>
  <data key="d1">Results</data>
  <data key="d2">A specific implementation attempt that is identified as incorrect in the context of the task.&lt;SEP&gt;An implementation attempt that is identified as incorrect in the context of counting palindromic numbers.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 4 (CORRECT)">
  <data key="d0">COMPLETION 4 (CORRECT)</data>
  <data key="d1">Results</data>
  <data key="d2">A correct implementation of the function to count palindromic numbers, using proper iteration and condition checks.&lt;SEP&gt;A correct implementation that counts even and odd palindromic numbers by checking string symmetry and parity.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 5 (CORRECT)">
  <data key="d0">COMPLETION 5 (CORRECT)</data>
  <data key="d1">Results</data>
  <data key="d2">An accurate method that calculates the maximum length and returns the first string with that length.&lt;SEP&gt;Another correct implementation that accurately counts even and odd palindromic numbers within the range.&lt;SEP&gt;Another correct implementation that counts palindromes based on string reversal and parity checks.&lt;SEP&gt;Uses list comprehension and max() to correctly identify the longest string, or None if empty.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 6 (CORRECT)">
  <data key="d0">COMPLETION 6 (CORRECT)</data>
  <data key="d1">Results</data>
  <data key="d2">A correct approach that uses list comprehension and maximum length to find the longest string, returning None if list is empty.&lt;SEP&gt;A correct approach using integer to string conversion and modulus to determine parity, accurately counting palindromes.&lt;SEP&gt;A third correct approach utilizing integer and string conversions to determine palindromes and their parity.&lt;SEP&gt;Employs a safe approach with list comprehension and max(), handling empty list cases properly.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 7 (WRONG)">
  <data key="d0">COMPLETION 7 (WRONG)</data>
  <data key="d1">Results</data>
  <data key="d2">An incorrect implementation relying on undefined functions and flawed logic for palindrome and parity detection.&lt;SEP&gt;An incorrect implementation relying on undefined functions for palindrome and parity checks.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 1 (CORRECT)">
  <data key="d0">COMPLETION 1 (CORRECT)</data>
  <data key="d1">Results</data>
  <data key="d2">A concise correct method returning the longest string from a list, or None if empty.&lt;SEP&gt;A concise, correct method that returns the longest string from a list or None if the list is empty.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 2 (WRONG)">
  <data key="d0">COMPLETION 2 (WRONG)</data>
  <data key="d1">Results</data>
  <data key="d2">An incorrect approach that sorts the list and returns the last element, potentially incorrect if multiple strings share the maximum length.&lt;SEP&gt;An incorrect approach that sorts the list and returns the last element, which may not be optimal or correct in all cases.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 3 (WRONG)">
  <data key="d0">COMPLETION 3 (WRONG)</data>
  <data key="d1">Results</data>
  <data key="d2">An incorrect implementation that manually iterates and compares string lengths to find the longest string.&lt;SEP&gt;An incorrect manual iteration over the list to find the longest string, less efficient and more error-prone.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 4 (WRONG)">
  <data key="d0">COMPLETION 4 (WRONG)</data>
  <data key="d1">Results</data>
  <data key="d2">Another incorrect method that sorts the list and picks the last element, similar to COMPLETION 2.&lt;SEP&gt;Similar to COMPLETION 2, sorts and returns the last element, not always correct.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 4">
  <data key="d0">COMPLETION 4</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that returns the last sorted string or None if the input list is empty, demonstrating code logic and control flow.&lt;SEP&gt;A duplicate of the first code snippet, returning x if n divisible by x else y.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 5">
  <data key="d0">COMPLETION 5</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that finds the longest string in a list by length, handling empty lists.&lt;SEP&gt;A code snippet that returns y if n is less than x, else returns y, with logical inconsistency.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 6">
  <data key="d0">COMPLETION 6</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that returns the longest string in a list using max() with a key function.&lt;SEP&gt;A code snippet using a loop to check if n is divisible by any number from 2 to n-1, returning y if divisible, else x, typical primality test logic.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 7">
  <data key="d0">COMPLETION 7</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that finds the longest string in a list using list comprehension and max(), with incorrect indentation or syntax.&lt;SEP&gt;A recursive function that returns x if n equals 2, y if 3, else calls itself with n-1, illustrating recursive control flow.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 8">
  <data key="d0">COMPLETION 8</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that finds the longest string in a list by iterating and comparing lengths, with syntax errors.&lt;SEP&gt;A code snippet that returns x if n equals x, y if n equals y, else returns n, with inconsistent logic for matching specific values.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 1">
  <data key="d0">COMPLETION 1</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that returns x if n is divisible by x, else y, used in primality testing scenarios.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 2">
  <data key="d0">COMPLETION 2</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that checks if n &gt; 1 and returns x or y based on whether n is odd or even, with logical errors.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 3">
  <data key="d0">COMPLETION 3</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that returns x if n is divisible by x, else y, used in divisibility checks.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Building Blocks for Synthetic Tasks">
  <data key="d0">Building Blocks for Synthetic Tasks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A description of 13 modular code and docstring components used to generate synthetic tasks for evaluating model performance, including string manipulations and their implementations.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="D. Details of Specification-based Evaluation Framework">
  <data key="d0">D. Details of Specification-based Evaluation Framework</data>
  <data key="d1">study_design</data>
  <data key="d2">Framework for evaluating code synthesis and generation capabilities, focusing on metrics such as correctness, complexity, expressivity, and the ability to reason over specifications in natural language.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ML (Xu et al., 2021)">
  <data key="d0">ML (Xu et al., 2021)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Machine Learning community's research on code synthesis and evaluation methodologies, including metrics like McCabe Cyclomatic Complexity.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Synthesis community (Helmuth &amp; Spector, 2015; Pantridge et al., 2017)">
  <data key="d0">Synthesis community (Helmuth &amp; Spector, 2015; Pantridge et al., 2017)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Communities focused on automatic programming and synthesis, advocating for principled benchmarks and challenge problems to compare methodologies.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="McCabe Cyclomatic Complexity (CC)">
  <data key="d0">McCabe Cyclomatic Complexity (CC)</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A metric used to evaluate the correctness and complexity of synthesized code, focusing on control flow complexity.&lt;SEP&gt;A metric used to measure the control flow complexity of code outputs, aiding in correctness and complexity evaluation.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Attributes for measuring expressivity and complexity of formal specifications">
  <data key="d0">Attributes for measuring expressivity and complexity of formal specifications</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Attributes adapted to evaluate the expressivity and complexity of natural language prompts in code synthesis, including reasoning over computations, states, and abstraction levels.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="High-level and design-level specifications">
  <data key="d0">High-level and design-level specifications</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Different abstraction levels of specifications, with high-level requiring more implicit derivation and design-level being more well-defined.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Variable Interdependencies">
  <data key="d0">Variable Interdependencies</data>
  <data key="d1">Variables</data>
  <data key="d2">Relationships and nesting among multiple variables, including permutations of states and their influence on code behavior.&lt;SEP&gt;Tracking relationships, nesting, and permutations among multiple variables in code synthesis, especially in natural language prompts.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Temporal Reasoning">
  <data key="d0">Temporal Reasoning</data>
  <data key="d1">Variables</data>
  <data key="d2">Considering program states over time, including safety and liveness properties, to evaluate synthesis capabilities in reasoning about past and future states.&lt;SEP&gt;Reasoning about past and future program states, including safety and liveness properties, to evaluate code correctness and robustness.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Concurrency and Parallelism">
  <data key="d0">Concurrency and Parallelism</data>
  <data key="d1">Variables</data>
  <data key="d2">Reasoning about computational interleavings, synchronization, mutual exclusion, and data races in generated code.&lt;SEP&gt;Reasoning about concurrent processes, synchronization mechanisms, mutual exclusion, data races, and interleavings in code synthesis.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hyperproperties (Clarkson et al., 2014)">
  <data key="d0">Hyperproperties (Clarkson et al., 2014)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Properties related to information flow policies, cryptographic algorithms, and observational determinism, requiring programs to behave as functions from low-security inputs to outputs.&lt;SEP&gt;Properties related to information flow, security policies, and cryptographic algorithms requiring deterministic behavior and observational security.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Nondeterminism">
  <data key="d0">Nondeterminism</data>
  <data key="d1">Variables</data>
  <data key="d2">Nondeterminism refers to the property of algorithms, particularly in computational theory, where the same input can produce different outputs on different executions, exemplified by random number generators and ML algorithms.&lt;SEP&gt;The ability of algorithms to produce different outputs for the same input across different executions, reflecting non-deterministic behavior in code synthesis.&lt;SEP&gt;The capacity of algorithms to produce different outputs on the same input across different runs, reflecting non-deterministic behaviors in synthesis.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a&lt;SEP&gt;chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Synthesis and Generation Evaluation">
  <data key="d0">Code Synthesis and Generation Evaluation</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A framework for assessing the capabilities of models in code synthesis and generation, focusing on metrics such as correctness, complexity, expressivity, and reasoning over specifications in natural language.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Xu et al., 2021">
  <data key="d0">Xu et al., 2021</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Research discussing ML models and metrics used for evaluating code synthesis, including control flow complexity metrics like McCabe Cyclomatic Complexity.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Helmuth &amp; Spector, 2015; Pantridge et al., 2017">
  <data key="d0">Helmuth &amp; Spector, 2015; Pantridge et al., 2017</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Communities advocating for benchmarks and challenge problems to compare different synthesis methodologies scientifically.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Attributes for measuring expressivity and complexity">
  <data key="d0">Attributes for measuring expressivity and complexity</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Attributes adapted from formal specifications to evaluate natural language prompts, focusing on reasoning, abstraction, and hierarchical requirements.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="High-level specifications">
  <data key="d0">High-level specifications</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specifications that outline broad requirements, often requiring implicit derivation of detailed lower-level specifications during synthesis.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Lower-level specifications">
  <data key="d0">Lower-level specifications</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">More detailed, well-defined specifications that restrict solution space and reduce ambiguity in synthesis tasks.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Specification abstraction levels">
  <data key="d0">Specification abstraction levels</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Different levels of specification detail, from high-level, abstract requirements to well-defined, low-level constraints.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Strong Fairness">
  <data key="d0">Strong Fairness</data>
  <data key="d1">Variables</data>
  <data key="d2">A property ensuring processes enabled infinitely often are executed infinitely often, relevant in reasoning about fairness in concurrent code.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Weak Fairness">
  <data key="d0">Weak Fairness</data>
  <data key="d1">Variables</data>
  <data key="d2">A property ensuring almost always enabled processes are executed infinitely often, important for fairness considerations.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Mutual exclusion, atomicity, synchronization">
  <data key="d0">Mutual exclusion, atomicity, synchronization</data>
  <data key="d1">Variables</data>
  <data key="d2">Properties ensuring correct concurrent execution, avoiding race conditions and ensuring data consistency.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Noninterference">
  <data key="d0">Noninterference</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A hyperproperty ensuring that high-security inputs do not influence low-security outputs, critical for security-sensitive code.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Low-Security Users">
  <data key="d0">Low-Security Users</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Low-security users are individuals with limited access rights or permissions within a system, whose observed outputs are consistent with the absence of inputs from high-security users.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="High-Security Users">
  <data key="d0">High-Security Users</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">High-security users are individuals with elevated access rights, whose inputs influence system outputs, contrasting with low-security users.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Deterministic Algorithm">
  <data key="d0">Deterministic Algorithm</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A deterministic algorithm always produces the same output for a given input across all executions, contrasting with nondeterministic algorithms.&lt;SEP&gt;A deterministic algorithm always produces the same output for a given input, contrasting with nondeterministic algorithms.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Random Number Generator">
  <data key="d0">Random Number Generator</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A simple and common example of nondeterminism, generating different outputs for the same input due to inherent randomness.&lt;SEP&gt;A simple example of nondeterminism, generating different outputs for the same input due to randomness.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ML Algorithms">
  <data key="d0">ML Algorithms</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Machine Learning algorithms are advanced computational models that can exhibit nondeterministic behavior, producing varying outcomes for identical inputs.&lt;SEP&gt;Machine Learning algorithms can exhibit nondeterministic behavior, producing different results for identical inputs depending on stochastic elements.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Specification-Independent Coding Practices">
  <data key="d0">Specification-Independent Coding Practices</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Coding practices that do not depend on specific specifications, essential for achieving attributes like computational and state reasoning, discussed within genetic programming communities.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Genetic Programming Community">
  <data key="d0">Genetic Programming Community</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A research community focused on evolutionary algorithms and programming techniques that emphasize code reuse, automatic architecture determination, and broad applicability.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code and Parameterized Reuse">
  <data key="d0">Code and Parameterized Reuse</data>
  <data key="d1">Variables</data>
  <data key="d2">Practices involving reusing code segments and parameters to enhance flexibility and efficiency in programming.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automatic Determination of Program Architecture">
  <data key="d0">Automatic Determination of Program Architecture</data>
  <data key="d1">Tools</data>
  <data key="d2">Techniques that allow systems to infer and generate appropriate program structures without explicit human design.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Wide Range of Programming Constructs">
  <data key="d0">Wide Range of Programming Constructs</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">A broad set of programming elements and constructs used to build complex and adaptable software systems.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Well-Defined">
  <data key="d0">Well-Defined</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Attributes of coding practices that are clear, precise, and unambiguous, essential for correctness.&lt;SEP&gt;Attributes of coding practices that are clear, unambiguous, and precisely specified to ensure correctness and consistency.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Alignment Problems">
  <data key="d0">Alignment Problems</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Issues related to whether AI models, such as Codex, perform tasks aligned with user intentions, especially as capabilities improve, and the potential for increasing severity of these problems.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Capability">
  <data key="d0">Model Capability</data>
  <data key="d1">Variables</data>
  <data key="d2">The latent or demonstrated ability of a model to perform specific tasks, which can be elicited or assessed through various techniques.&lt;SEP&gt;The potential or ability of a model to perform specific tasks, which can be latent and manipulated through prompt engineering, fine-tuning, or model modifications.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Intent Misalignment">
  <data key="d0">Intent Misalignment</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A condition where a model outputs undesired results despite being capable of producing correct outputs, indicating a misalignment between model behavior and user intent.&lt;SEP&gt;A condition where a model produces undesired outputs (B) despite being capable of producing preferred outputs (A), indicating misalignment with user intent.&lt;SEP&gt;Empirical findings show that models may produce undesired outputs (B) even when capable of producing preferred outputs (A), especially when the model can distinguish situations where preferences differ.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Operational Conditions for Misalignment">
  <data key="d0">Operational Conditions for Misalignment</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The criteria defining when a model is considered capable of task X and when it is intent misaligned, based on its ability to perform tasks and distinguish user preferences.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Evaluation of Alignment">
  <data key="d0">Evaluation of Alignment</data>
  <data key="d1">Results</data>
  <data key="d2">Empirical assessments indicating that models like Codex tend to produce worse code when subtle bugs are present, with the gap increasing with model size, and that prompt instructions to write correct code have limited effectiveness.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Surgery">
  <data key="d0">Model Surgery</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Modifying model architecture or parameters directly to harness latent capabilities or correct behaviors.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Capability to Perform Task X">
  <data key="d0">Capability to Perform Task X</data>
  <data key="d1">Variables</data>
  <data key="d2">The latent or demonstrated ability of a model to execute a specific task, which can be influenced or revealed through various techniques.&lt;SEP&gt;The potential or actual ability of a model to execute a specific task, often assessed through prompt or fine-tuning.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sufficient Conditions for Capability">
  <data key="d0">Sufficient Conditions for Capability</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Criteria such as prompt engineering, fine-tuning, or constructing related tasks that demonstrate a model's capacity to perform task X.&lt;SEP&gt;Criteria such as prompt engineering, fine-tuning, or related task performance that demonstrate a model's ability to perform task X.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Security Level">
  <data key="d0">Security Level</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Security level indicates the classification or permissions assigned to users within a system, distinguishing low-security users from high-security users.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Inputs">
  <data key="d0">Inputs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Inputs refer to data or information submitted by users, which influence system outputs.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Outputs">
  <data key="d0">Outputs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Outputs are the results generated by a system after processing inputs, observed in different security contexts.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Computational Theory">
  <data key="d0">Computational Theory</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Computational theory studies the fundamental capabilities and limitations of algorithms and computational models.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Nondeterministic Algorithm">
  <data key="d0">Nondeterministic Algorithm</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A nondeterministic algorithm can produce different outputs for the same input across different executions, exemplified by randomized processes and some ML algorithms.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Reuse">
  <data key="d0">Code Reuse</data>
  <data key="d1">Variables</data>
  <data key="d2">Practices involving reusing code components and parameters to improve efficiency and flexibility in programming.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automatic Architecture Determination">
  <data key="d0">Automatic Architecture Determination</data>
  <data key="d1">Tools</data>
  <data key="d2">Techniques enabling systems to infer or generate program structures without explicit human specifications.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Programming Constructs">
  <data key="d0">Programming Constructs</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">A broad set of programming elements and constructs used to build complex, adaptable software systems.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Alignment">
  <data key="d0">Alignment</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Alignment refers to the degree to which AI models' outputs match user intentions, with misalignment indicating potential safety and reliability issues.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Synthesis Techniques">
  <data key="d0">Model Synthesis Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods for generating or inferring program architectures and capabilities, including code reuse and automatic inference.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety and Reliability">
  <data key="d0">Safety and Reliability</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Understanding model alignment and its issues is crucial for deploying safe and reliable AI systems in real-world applications.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Long-term Risks">
  <data key="d0">Long-term Risks</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Potential severe problems in AI model alignment that may worsen as capabilities improve, posing future safety challenges.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="alignment evaluations">
  <data key="d0">alignment evaluations</data>
  <data key="d1">Results</data>
  <data key="d2">The results of alignment evaluations assess the model's ability to output correct, bug-free code and distinguish between situations where it should or should not do so.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex models">
  <data key="d0">Codex models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Codex models are advanced language models trained for code generation, evaluated for alignment and performance.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="human feedback">
  <data key="d0">human feedback</data>
  <data key="d1">Tools</data>
  <data key="d2">Human feedback is used to improve model alignment by collecting data on the correctness and helpfulness of generated code.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="formal analysis">
  <data key="d0">formal analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Formal analysis involves using structured, mathematical, or logical methods to evaluate code quality and correctness.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="RL from Human Feedback (RLHF)">
  <data key="d0">RL from Human Feedback (RLHF)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Reinforcement Learning from Human Feedback is a technique to align models by using human judgments as reward signals to guide training.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="metrics for alignment">
  <data key="d0">metrics for alignment</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics for alignment are quantitative measures developed to evaluate how well models follow instructions, avoid bugs, and behave safely.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="transparency tools">
  <data key="d0">transparency tools</data>
  <data key="d1">Tools</data>
  <data key="d2">Transparency tools help understand and interpret model behavior to assess alignment and identify potential issues.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model robustness">
  <data key="d0">model robustness</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Model robustness refers to the ability of models to perform reliably across different, possibly out-of-distribution inputs, and is relevant to alignment and safety.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Entity Recognition">
  <data key="d0">Entity Recognition</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of systematically identifying entities and relationships within a text document using natural language processing techniques.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Relationship Extraction">
  <data key="d0">Relationship Extraction</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The activity of determining and extracting relationships between identified entities based on contextual cues in the text.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Text Document">
  <data key="d0">Text Document</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The primary object of analysis from which entities and relationships are extracted.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Entity Recognition Techniques">
  <data key="d0">Entity Recognition Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods employed to detect and classify entities within the text, such as named entity recognition algorithms.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Relationship Extraction Techniques">
  <data key="d0">Relationship Extraction Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approaches used to identify and characterize relationships among entities, often involving pattern recognition and contextual analysis.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Entity">
  <data key="d0">Entity</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An individual element identified in the text, such as a person, organization, object, or concept, with associated attributes.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Relationship">
  <data key="d0">Relationship</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A connection or association between two entities, indicating a meaningful link or interaction.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Content Keywords">
  <data key="d0">Content Keywords</data>
  <data key="d1">High-level Keywords</data>
  <data key="d2">Text discusses systematic methods for entity recognition, relationship extraction, use of NLP tools, and analysis techniques for understanding textual data.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="planet2">
  <data key="d0">planet2</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A variable representing a planet, used in code to refer to or manipulate planet data.&lt;SEP&gt;A variable representing a second planet, used in code to reference or manipulate planet data.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="planet_names">
  <data key="d0">planet_names</data>
  <data key="d1">Variables</data>
  <data key="d2">A list or array containing names of planets, used for indexing or referencing specific planets in code.&lt;SEP&gt;A list or array containing names of planets, used for indexing or referencing specific planets.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="planet1_index">
  <data key="d0">planet1_index</data>
  <data key="d1">Variables</data>
  <data key="d2">An integer index representing the position of the first planet in the planet_names list.&lt;SEP&gt;An integer index representing the position of the first planet within the planet_names list.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="planet2_index">
  <data key="d0">planet2_index</data>
  <data key="d1">Variables</data>
  <data key="d2">An integer index representing the position of the second planet in the planet_names list.&lt;SEP&gt;An integer index representing the position of the second planet within the planet_names list.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="anti_shuffle">
  <data key="d0">anti_shuffle</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A function designed to reorder characters in words within a string, producing an ordered version of the input string where characters are sorted alphabetically within each word.&lt;SEP&gt;A function that takes a string and returns an ordered version of it by sorting characters within each word in ascending ASCII order, preserving word order and spaces.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="count_up_to">
  <data key="d0">count_up_to</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A function that computes and returns a list of prime numbers less than a given non-negative integer n, up to the specified limit.&lt;SEP&gt;A function that takes a non-negative integer n and returns an array of prime numbers less than n, implementing prime checking and list generation.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="smallest_change">
  <data key="d0">smallest_change</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A function that calculates the minimum number of element changes needed to convert an array into a palindrome, allowing any element to be changed to any other.&lt;SEP&gt;A function that calculates the minimum number of element changes needed to convert an array into a palindromic array, allowing any element to be changed to any other.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="F. Supplemental Bias Analysis">
  <data key="d0">F. Supplemental Bias Analysis</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A discussion on how generative models, including code models like Codex, encode bias, leading to potential harms such as allocative and representational biases, and emphasizing the importance of bias assessment and mitigation in deployment.&lt;SEP&gt;A section discussing how generative models like Codex encode bias, leading to potential societal harms such as allocative and representational biases, emphasizing the importance of bias detection, evaluation, and mitigation in model deployment.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Protected Classes Prompts">
  <data key="d0">Protected Classes Prompts</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Prompts related to classifying protected classes like gender, race, and age are used to investigate model biases and potential harms in code generation and text output.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Model">
  <data key="d0">Bias in Model</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Bias refers to systematic prejudices or stereotypes that models may learn from training data, leading to biased outputs in code and text.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Harmful Prompts">
  <data key="d0">Harmful Prompts</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Prompts designed to elicit harmful or biased responses from language models, revealing potential risks and biases in AI systems.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Reinforcement">
  <data key="d0">Bias Reinforcement</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using biased prompts or training data can reinforce harmful stereotypes and biases in AI outputs.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sensitive Prompt Responses">
  <data key="d0">Sensitive Prompt Responses</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods to assess how models respond to sensitive prompts, aiming to identify bias or harmful content.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Analysis in Text">
  <data key="d0">Bias Analysis in Text</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Analyzing the co-occurrence of words associated with groups like gender, race, and religion in model outputs to detect biases.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Co-occurrence Tests">
  <data key="d0">Co-occurrence Tests</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Tests that measure the likelihood of certain words appearing near group-related terms to evaluate bias in generated text.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Comments and Docstrings">
  <data key="d0">Bias in Comments and Docstrings</data>
  <data key="d1">Results</data>
  <data key="d2">Model-generated comments and docstrings may contain biased language, reflecting learned biases.&lt;SEP&gt;Model-generated comments may reflect biases present in training data, potentially denigrating groups or individuals.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Comparison (GPT-3 vs Codex)">
  <data key="d0">Model Comparison (GPT-3 vs Codex)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Comparative analysis of biases in outputs from different language models when prompted about various groups.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Text Output">
  <data key="d0">Bias in Text Output</data>
  <data key="d1">Results</data>
  <data key="d2">Both GPT-3 and Codex tend to produce biased terms such as 'terrorist' and 'violent' when discussing certain groups, with GPT-3 showing more variation.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Impact of Bias">
  <data key="d0">Impact of Bias</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Biased outputs can reinforce stereotypes, cause harm, and affect the fairness of AI applications.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Robustness of Models">
  <data key="d0">Robustness of Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models tend to act more neutrally when prompts are precise and neutral, but can still produce harmful outputs in out-of-distribution scenarios.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Threat Actors">
  <data key="d0">Threat Actors</data>
  <data key="d1">Discipline</data>
  <data key="d2">Actors ranging from low-skilled individuals to organized groups aiming to exploit AI models for malicious purposes such as causing chaos or obtaining information.&lt;SEP&gt;Entities ranging from low-skilled actors to organized APT groups aiming to misuse Codex for malicious purposes like malware creation and phishing.&lt;SEP&gt;Threat actors are entities with varying skill levels and resources, ranging from low-skilled individuals to organized advanced persistent threat groups, aiming to exploit models like Codex for malicious purposes.&lt;SEP&gt;Threat actors range from low-skilled individuals to organized groups aiming to exploit AI models for malicious purposes.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12&lt;SEP&gt;chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Prompts">
  <data key="d0">Bias in Prompts</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Prompts designed to elicit responses related to sensitive attributes such as gender, race, and age, used to investigate biases and potential harms in AI models.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Social Biases in Training Data">
  <data key="d0">Social Biases in Training Data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Datasets used to train models that may contain social biases, influencing the learned representations and outputs.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Written to Process Bias">
  <data key="d0">Code Written to Process Bias</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code datasets that encode social biases, which can affect the model's understanding and generation.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Representation of Gender and Race">
  <data key="d0">Representation of Gender and Race</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The way gender and race are represented in data and models, which can be simplified or nuanced, affecting bias and fairness.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Discretization of Gender and Race">
  <data key="d0">Discretization of Gender and Race</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of categorizing gender and race into discrete groups, which can overlook important nuances and diversity.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automated Code Generation">
  <data key="d0">Automated Code Generation</data>
  <data key="d1">Tools</data>
  <data key="d2">The use of AI models to generate source code based on prompts, with potential for reinforcing biases.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Harmful Code">
  <data key="d0">Harmful Code</data>
  <data key="d1">Results</data>
  <data key="d2">Code that promotes or reinforces social biases, stereotypes, or harmful assumptions.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Amplification">
  <data key="d0">Bias Amplification</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The potential for models to reinforce or worsen existing social biases through generated code or text.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Model Responses">
  <data key="d0">Bias in Model Responses</data>
  <data key="d1">Results</data>
  <data key="d2">Model outputs that contain biased language or stereotypes, especially when prompted about sensitive groups.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Text Generation">
  <data key="d0">Bias in Text Generation</data>
  <data key="d1">Results</data>
  <data key="d2">Language models like GPT-3 and Codex tend to produce biased terms when discussing certain groups, such as 'terrorist' or 'violent' for specific religions.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Comparison (GPT-3 vs Codex)">
  <data key="d0">Bias Comparison (GPT-3 vs Codex)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Comparative analysis of biases in outputs from GPT-3 and Codex under similar prompts.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Co-occurrence">
  <data key="d0">Bias Co-occurrence</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Method to measure how often biased terms co-occur with group-related words in generated text.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Detection in Comments">
  <data key="d0">Bias Detection in Comments</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Assessing the presence of biases in model comments and outputs through co-occurrence and content analysis.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Impact">
  <data key="d0">Bias Impact</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Potential societal harms caused by biased AI outputs, including reinforcement of stereotypes and discrimination.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Behavior in Out-of-Distribution Prompts">
  <data key="d0">Model Behavior in Out-of-Distribution Prompts</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models tend to behave more neutrally with precise, neutral prompts but can produce harmful outputs when out-of-distribution inputs are used.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Risks of Bias Reinforcement">
  <data key="d0">Risks of Bias Reinforcement</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The potential for models to unintentionally reinforce social biases present in training data or prompts.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malicious Code Generation">
  <data key="d0">Malicious Code Generation</data>
  <data key="d1">Methods/Techniques</data>
  <data key="d2">Codex's ability to generate code components that can be used in malware, phishing, or other offensive cybersecurity activities, especially in creating polymorphic malware.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Vulnerability Discovery">
  <data key="d0">Vulnerability Discovery</data>
  <data key="d1">Methods/Techniques</data>
  <data key="d2">Using Codex to identify security vulnerabilities in software, though current performance is limited compared to specialized tools.&lt;SEP&gt;Using Codex to identify security vulnerabilities, though currently less effective than specialized static analysis tools, with future improvements anticipated.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Supply Chain Attack">
  <data key="d0">Supply Chain Attack</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An attack vector where malicious or vulnerable software dependencies are exploited, potentially suggested by Codex.&lt;SEP&gt;The potential for Codex to suggest malicious or vulnerable software dependencies, leading to supply chain vulnerabilities in software development.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Misuse Applications">
  <data key="d0">Misuse Applications</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Potential malicious uses of Codex include generating malware, facilitating phishing, vulnerability discovery, and supply chain attacks, highlighting security risks associated with code-generating models.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Limitations">
  <data key="d0">Model Limitations</data>
  <data key="d1">Limitations</data>
  <data key="d2">Current Codex models are limited in generating certain types of malicious code, detecting high-dimension vulnerabilities, and avoiding suggesting malicious dependencies, but these capabilities may improve over time.&lt;SEP&gt;Current capabilities of Codex in generating malicious code, detecting vulnerabilities, and avoiding malicious suggestions are limited, but may improve over time.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Supplemental Security Analysis">
  <data key="d0">Supplemental Security Analysis</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A systematic evaluation of security risks associated with AI models like Codex, focusing on threat actors, misuse potential, and mitigation strategies.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Threat Landscape">
  <data key="d0">Threat Landscape</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The threat landscape for Codex is similar to that of language models, involving various threat actors with different skill levels and objectives, including malicious exploitation.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Phishing">
  <data key="d0">Phishing</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Deceptive practices facilitated by generated code or scripts, which threat actors might employ using Codex.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Polymorphic Malware">
  <data key="d0">Polymorphic Malware</data>
  <data key="d1">Results</data>
  <data key="d2">A form of malware that changes its code to evade detection, potentially enabled by advanced code generation models like Codex.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Static Application Security Testing (SAST)">
  <data key="d0">Static Application Security Testing (SAST)</data>
  <data key="d1">Tools</data>
  <data key="d2">A conventional cybersecurity technique for detecting vulnerabilities, used here as a benchmark for Codex's capabilities.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malicious or Vulnerable Dependencies">
  <data key="d0">Malicious or Vulnerable Dependencies</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Software packages or versions that, if compromised, could be exploited in supply chain attacks.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Security Risks">
  <data key="d0">Security Risks</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Potential for misuse of Codex to produce malicious code, exploit vulnerabilities, or facilitate supply chain attacks, posing cybersecurity threats.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Adversarial Inputs">
  <data key="d0">Adversarial Inputs</data>
  <data key="d1">Variables</data>
  <data key="d2">Inputs designed to manipulate Codex into suggesting malicious or vulnerable code, representing a security concern.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="tuning processes">
  <data key="d0">tuning processes</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Processes involved in adjusting and optimizing machine learning models, generally considered untrusted due to potential security vulnerabilities or unpredictable behavior.&lt;SEP&gt;Tuning processes refer to the methods and practices involved in adjusting and optimizing machine learning models, often considered untrusted due to potential vulnerabilities or unpredictability.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model capabilities">
  <data key="d0">model capabilities</data>
  <data key="d1">Variables</data>
  <data key="d2">Model capabilities encompass the functionalities and performance levels of AI models, which may influence their susceptibility to misuse or security risks.&lt;SEP&gt;The functionalities, performance levels, and features of AI models, which influence their potential for misuse or security risks.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="interest of potential attackers">
  <data key="d0">interest of potential attackers</data>
  <data key="d1">Variables</data>
  <data key="d2">The increasing interest from potential attackers highlights the threat landscape and potential risks associated with model vulnerabilities.&lt;SEP&gt;The level of interest and intent from malicious actors to exploit vulnerabilities in AI models, increasing security risks.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex model">
  <data key="d0">Codex model</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An AI language model designed for code generation, capable of suggesting code snippets, but also prone to generating insecure or malicious code.&lt;SEP&gt;The Codex model is an AI language model designed for code generation, which may suggest insecure or malicious code.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="insecure or bad code">
  <data key="d0">insecure or bad code</data>
  <data key="d1">Results</data>
  <data key="d2">Code outputs from Codex that contain security vulnerabilities, compromised dependencies, insecure functions, or secrets from training data.&lt;SEP&gt;Instances where Codex suggests insecure, compromised, or malicious code, including insecure dependencies, functions, or secrets.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="supply chain risk">
  <data key="d0">supply chain risk</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The concept that widespread use of Codex could introduce a new type of supply chain vulnerability, affecting software security.&lt;SEP&gt;The potential for widespread adoption of Codex to introduce vulnerabilities into software supply chains, creating systemic security risks.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="code generation systems">
  <data key="d0">code generation systems</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Automated systems that produce source code, which can be exploited to synthesize complex systems or offensive tools, raising security concerns.&lt;SEP&gt;Systems that produce code automatically, which may provide actors with capabilities to synthesize complex safety-critical systems or offensive tools.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="low likelihood of synthesizing safety-critical systems">
  <data key="d0">low likelihood of synthesizing safety-critical systems</data>
  <data key="d1">Results</data>
  <data key="d2">Assessment that Codex is unlikely to independently generate fully safety-critical systems due to a lack of system-level generation capabilities.&lt;SEP&gt;The assessment that Codex is unlikely to independently generate fully safety-critical systems due to lack of system-level generation capabilities.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="machine learning development">
  <data key="d0">machine learning development</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The process of creating, training, and deploying machine learning models, which can be accelerated or influenced by tools like Codex.&lt;SEP&gt;The process of developing machine learning models, which could be accelerated by tools like Codex, potentially leading to downstream misuse.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="boilerplate machine learning code">
  <data key="d0">boilerplate machine learning code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Standardized, repetitive code used in developing machine learning models, which Codex can generate effectively, potentially speeding up development.&lt;SEP&gt;Standardized, repetitive code used in machine learning development that Codex can generate effectively.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="misuse scenarios">
  <data key="d0">misuse scenarios</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Possible scenarios where Codex could be used maliciously, such as in cybercrime or malware development.&lt;SEP&gt;Potential malicious uses of Codex, such as automating cybercrime, malware development, or code-based attacks, which require monitoring and mitigation.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="professional threat analysts">
  <data key="d0">professional threat analysts</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Experts analyzing security threats related to language models like Codex, monitoring forums and activities for misuse evidence.&lt;SEP&gt;Experts monitoring the use and misuse of language models like Codex in security contexts.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="forums">
  <data key="d0">forums</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Online discussion platforms where researchers and threat analysts observe and discuss the use and misuse of code-generating models.&lt;SEP&gt;Online forums where discussions about training and using language models for coding and potential misuse are observed.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="insecure code generation">
  <data key="d0">insecure code generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The behavior where Codex produces code with security vulnerabilities, often due to training on untrusted data.&lt;SEP&gt;The tendency of Codex to produce insecure or vulnerable code due to training on untrusted data containing insecure patterns.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cryptographic libraries">
  <data key="d0">cryptographic libraries</data>
  <data key="d1">Tools</data>
  <data key="d2">Libraries used for cryptographic functions, which Codex may suggest insecurely, leading to vulnerabilities.&lt;SEP&gt;Libraries used for cryptographic operations, which Codex may suggest insecurely, leading to vulnerabilities in generated code.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="RSA keys and AES contexts">
  <data key="d0">RSA keys and AES contexts</data>
  <data key="d1">Variables</data>
  <data key="d2">Cryptographic configurations such as key length and mode, which can be insecure if improperly generated by Codex.&lt;SEP&gt;Cryptographic configurations that can be insecure if generated improperly by Codex.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cryptographic vulnerabilities">
  <data key="d0">cryptographic vulnerabilities</data>
  <data key="d1">Results</data>
  <data key="d2">Insecure configurations suggested by Codex, such as short RSA keys or insecure cipher modes.&lt;SEP&gt;Insecure configurations suggested by Codex, such as weak RSA keys or insecure cipher modes like ECB.&lt;SEP&gt;Security flaws in cryptographic code produced by Codex, such as weak key sizes or insecure cipher modes like ECB.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="alignment issues">
  <data key="d0">alignment issues</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Problems in aligning AI behavior with security standards, leading to insecure code suggestions regardless of model size.&lt;SEP&gt;Problems in aligning AI model outputs with security best practices, leading to insecure code suggestions regardless of model size.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="economic and labor market implications">
  <data key="d0">economic and labor market implications</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Potential impacts of AI-driven code generation on employment, industry practices, and economic value creation.&lt;SEP&gt;The potential impact of code generation AI on economic value, employment, and industry practices.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="technological trajectory">
  <data key="d0">technological trajectory</data>
  <data key="d1">Variables</data>
  <data key="d2">The future development path of AI models and their adoption in industry, influencing economic impacts.&lt;SEP&gt;The future development path of AI models, including improvements and adoption rates, which influence economic impacts.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="economic adoption">
  <data key="d0">economic adoption</data>
  <data key="d1">Variables</data>
  <data key="d2">The rate and extent to which organizations adopt AI code generation tools, affecting economic outcomes.&lt;SEP&gt;The rate and extent to which organizations integrate AI code generation tools into workflows, affecting economic outcomes.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="improve code quality">
  <data key="d0">improve code quality</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">One benefit of AI code generation—enhanced efficiency and better software development.&lt;SEP&gt;One potential benefit of AI code generation, leading to increased efficiency and better software.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="accelerate machine learning development">
  <data key="d0">accelerate machine learning development</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using AI models like Codex to speed up the creation and testing of machine learning models.&lt;SEP&gt;Using Codex to speed up the creation, testing, and deployment of machine learning models.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="downstream misuse">
  <data key="d0">downstream misuse</data>
  <data key="d1">Implications</data>
  <data key="d2">Risks that accelerated development and deployment of AI-generated code could be exploited for malicious purposes, such as malware or cyberattacks.&lt;SEP&gt;Risks that improved or accelerated development could lead to malicious or unintended use of AI-generated code.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cryptographic key length">
  <data key="d0">cryptographic key length</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters like RSA key size (e.g., 2048 bits), which if insecurely generated, compromise cryptographic security.&lt;SEP&gt;Parameters such as RSA key size, which if insecure, compromise cryptographic security.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cipher mode">
  <data key="d0">cipher mode</data>
  <data key="d1">Variables</data>
  <data key="d2">Encryption mode (e.g., ECB) that can be insecure if improperly used, leading to vulnerabilities.&lt;SEP&gt;Encryption modes such as ECB, which are insecure and can lead to vulnerabilities if used improperly in generated code.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cryptography experts">
  <data key="d0">cryptography experts</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Cryptography experts are specialists in cryptographic systems, analyzing configurations and standards to ensure security and identify vulnerabilities.&lt;SEP&gt;Cryptography experts are specialists who evaluate the security and configuration of cryptographic systems and standards.&lt;SEP&gt;Specialists who establish standards and evaluate cryptographic security, essential for assessing insecure code suggestions.&lt;SEP&gt;Specialists who provide standards and assessments for cryptographic security, relevant for evaluating insecure code.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2&lt;SEP&gt;chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ECB">
  <data key="d0">ECB</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">ECB (European Central Bank) is an institution responsible for monetary policy in the Eurozone, often with specific preferences regarding desired monetary conditions.&lt;SEP&gt;The European Central Bank (ECB) is the primary monetary authority in the Eurozone, responsible for setting monetary policy, which includes influencing interest rates and financial stability, often with specific desired outcomes such as low inflation or economic stability.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="RSA keys">
  <data key="d0">RSA keys</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">RSA keys are cryptographic keys used in asymmetric encryption; their security depends on key length, with shorter keys (less than 2048 bits) being insecure.&lt;SEP&gt;RSA keys are cryptographic keys used in encryption, with security dependent on key length, such as being longer than 2048 bits for security.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="AES contexts">
  <data key="d0">AES contexts</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">AES contexts refer to encryption configurations using the AES cipher mode, such as ECB mode, which has security implications.&lt;SEP&gt;AES contexts refer to specific configurations of the Advanced Encryption Standard, such as cipher modes like ECB, which have security implications.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Large Language Models trained on Code">
  <data key="d0">Large Language Models trained on Code</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Large Language Models trained on code are machine learning models designed to understand and generate programming code, evaluated for security and utility.&lt;SEP&gt;Large Language Models trained on code are machine learning models developed to understand and generate programming code, evaluated for security and utility.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="insecurity">
  <data key="d0">insecurity</data>
  <data key="d1">Results</data>
  <data key="d2">Insecurity refers to cryptographic configurations or outputs that are vulnerable, such as weak keys or insecure cipher modes, which can be produced by models like Codex.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="software engineering tasks">
  <data key="d0">software engineering tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Tasks such as documentation, code reviews, testing, and software design, which can be impacted by AI code generation tools.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="programmers and engineers">
  <data key="d0">programmers and engineers</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Professionals involved in software development, whose workflows and security practices may be impacted by AI code generation tools like Codex.&lt;SEP&gt;Professionals involved in writing, reviewing, and maintaining code, whose work may be affected by AI tools like Codex.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="economic implications">
  <data key="d0">economic implications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Impacts of AI code generation tools on productivity, labor costs, and market dynamics within the software industry.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="security standards">
  <data key="d0">security standards</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Security standards are evolving guidelines and best practices for cryptography, influencing acceptable configurations and practices.&lt;SEP&gt;Security standards evolve over time, influencing cryptographic best practices and configurations.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="code generation tools">
  <data key="d0">code generation tools</data>
  <data key="d1">Tools</data>
  <data key="d2">Automated tools like Codex that assist in writing code, including cryptographic code, with implications for security and efficiency.&lt;SEP&gt;Software tools that automatically generate code, assist in programming, and influence development workflows.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="security assessments">
  <data key="d0">security assessments</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Evaluations conducted to analyze cryptographic configurations and AI-generated code for vulnerabilities and compliance with standards.&lt;SEP&gt;Evaluations of cryptographic configurations and AI-generated code for security vulnerabilities.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="insecurity measurement">
  <data key="d0">insecurity measurement</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics and criteria used to assess whether cryptographic outputs or code are insecure, such as key length or cipher mode.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cryptography configurations">
  <data key="d0">cryptography configurations</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters such as key length and cipher mode, which determine security or insecurity of cryptographic systems.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="security risks">
  <data key="d0">security risks</data>
  <data key="d1">Variables</data>
  <data key="d2">Potential vulnerabilities or insecure configurations produced by AI models, including weak keys or insecure cipher modes.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="security implications">
  <data key="d0">security implications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The security risks and insecure configurations produced by AI tools have implications for cryptographic safety and standards compliance.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="security standards evolution">
  <data key="d0">security standards evolution</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Security standards evolve over time, shaping what configurations are considered secure or insecure, and influencing AI outputs.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cryptographic configurations">
  <data key="d0">cryptographic configurations</data>
  <data key="d1">Variables</data>
  <data key="d2">Settings such as key length and cipher mode that determine security or vulnerability.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="evaluation of AI outputs">
  <data key="d0">evaluation of AI outputs</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Methodologies for assessing whether AI-generated cryptographic configurations are secure or insecure.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Stack Overflow">
  <data key="d0">Stack Overflow</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Stack Overflow is a platform where users share programming knowledge and data related to coding practices and community surveys.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Women">
  <data key="d0">Women</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Women are a demographic group that is comparatively more represented in data science and analysis roles according to the 2020 survey.&lt;SEP&gt;Women are a demographic group that is more represented in data science and analysis roles than in other technical roles such as DevOps, system administration, or site reliability, based on survey data.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Data Science and Analysis Roles">
  <data key="d0">Data Science and Analysis Roles</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Roles involving data analysis and scientific computing, where women are more represented.&lt;SEP&gt;Roles involving data analysis, scientific computing, and related activities, where women have higher representation.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="DevOps Specialist">
  <data key="d0">DevOps Specialist</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">DevOps specialists are professionals focused on operations and system reliability, with lower representation of women.&lt;SEP&gt;Professionals responsible for development operations, with lower female representation.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="System Administrator">
  <data key="d0">System Administrator</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Professionals managing IT infrastructure, with lower female representation.&lt;SEP&gt;System administrators manage IT infrastructure, with less female representation compared to data science roles.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Site Reliability Engineer">
  <data key="d0">Site Reliability Engineer</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Professionals ensuring system reliability, with lower female representation.&lt;SEP&gt;Site reliability engineers focus on system robustness, with lower female representation.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Coding Tools and Libraries">
  <data key="d0">Coding Tools and Libraries</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Tools like PyTorch, TensorFlow, Matplotlib, Seaborn are libraries/packages used in programming, with import patterns affecting model behavior.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Generation Tools">
  <data key="d0">Code Generation Tools</data>
  <data key="d1">Tools</data>
  <data key="d2">Automated systems like Codex that generate code snippets, automate programming tasks, and influence coding practices.&lt;SEP&gt;Tools like Codex that assist in generating code, automating tasks, and potentially influencing programming practices and societal effects.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Import Patterns">
  <data key="d0">Import Patterns</data>
  <data key="d1">Variables</data>
  <data key="d2">Patterns in how packages are imported in code files, affecting robustness, safety, and economic implications.&lt;SEP&gt;Patterns in how packages are imported within code files, influencing robustness, safety, and economic implications.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Economic Effects">
  <data key="d0">Economic Effects</data>
  <data key="d1">Implications</data>
  <data key="d2">Potential societal and economic impacts resulting from differential import rates, package dominance, and automation in coding.&lt;SEP&gt;Societal and market impacts resulting from differential import rates, package dominance, and automation facilitated by code generation models.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety and Security">
  <data key="d0">Safety and Security</data>
  <data key="d1">Implications</data>
  <data key="d2">Risks associated with package import patterns, including errors, security vulnerabilities, and robustness.&lt;SEP&gt;Risks such as errors or security vulnerabilities arising from automated import suggestions and package choices.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codebase Transition">
  <data key="d0">Codebase Transition</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The process of shifting codebases to languages or packages that are more compatible with tools like Codex, affecting productivity and inclusion.&lt;SEP&gt;The process of switching codebases to languages or packages where tools like Codex can augment work, affecting productivity and accessibility.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Libraries and Packages">
  <data key="d0">Libraries and Packages</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Reusable code modules like PyTorch, TensorFlow, Matplotlib, Seaborn, which are imported in code and affected by import patterns.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automation of Repetitive Tasks">
  <data key="d0">Automation of Repetitive Tasks</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using code generation tools to automate routine coding activities, potentially broadening participation in programming.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Biases in Training Data">
  <data key="d0">Biases in Training Data</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Biases in training data can influence Codex's suggestions, potentially leading to reliance on outdated or popular packages and propagating deprecated methods.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Open-source Development">
  <data key="d0">Open-source Development</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Open-source development involves collaborative software creation where maintaining backward compatibility is crucial, and Codex's suggestions may impact this process.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Market Entrenchment">
  <data key="d0">Market Entrenchment</data>
  <data key="d1">Variables</data>
  <data key="d2">Market entrenchment describes how increased reliance on Codex for code tasks might reinforce existing package preferences and market dominance.&lt;SEP&gt;Market entrenchment describes how reliance on Codex may reinforce existing package preferences and market dominance of certain libraries.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Labor Market Impact">
  <data key="d0">Labor Market Impact</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The impact of AI code generation tools like Codex on worker productivity, wages, and job quality is an area requiring further investigation.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Documentation Practices">
  <data key="d0">Code Documentation Practices</data>
  <data key="d1">Variables</data>
  <data key="d2">Code documentation practices may change due to Codex's assistance, affecting software maintainability and downstream bug rates.&lt;SEP&gt;Code documentation practices refer to how developers write and maintain documentation, which may change due to Codex's assistance, affecting downstream bugs and software quality.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Testing and Bugs">
  <data key="d0">Testing and Bugs</data>
  <data key="d1">Variables</data>
  <data key="d2">The use of Codex in writing tests could improve software quality but might also lead to over-reliance, affecting the accuracy of code specifications.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Time">
  <data key="d0">Time</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Time refers to the ongoing process during which users adapt to working with AI systems like Codex, involving learning and behavioral changes over periods.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Users">
  <data key="d0">Users</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Users are individuals who interact with Codex, learn prompt engineering, and adapt their workflows, impacting decision-making and productivity.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Decision-Making Tool">
  <data key="d0">Decision-Making Tool</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Codex can be used as a decision-making tool, assisting users in selecting appropriate machine learning packages or coding approaches, thereby influencing workflows.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Search Engine">
  <data key="d0">Search Engine</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Users may rely on Codex as a search engine replacement for traditional internet searches related to machine learning tools and packages.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Machine Learning Packages">
  <data key="d0">Machine Learning Packages</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Machine learning packages like TensorFlow and PyTorch are libraries used for building and deploying machine learning models, often compared in the context of AI development.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Open-source Developers">
  <data key="d0">Open-source Developers</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Open-source developers maintain and develop machine learning packages, whose work may be impacted by the suggestions and biases of Codex, especially regarding backward compatibility.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Suggestions">
  <data key="d0">Bias in Suggestions</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Biases in Codex's suggestions stem from training data and influence the prominence of certain packages or deprecated methods, affecting developer choices.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Open-source Maintenance">
  <data key="d0">Open-source Maintenance</data>
  <data key="d1">Variables</data>
  <data key="d2">Open-source maintenance involves ensuring backward compatibility and updating packages, which may be influenced by Codex's suggestions and biases.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Labor Market">
  <data key="d0">Labor Market</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The labor market encompasses workers involved in software development, whose productivity, wages, and job quality may be affected by AI-assisted coding tools like Codex.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Testing Practices">
  <data key="d0">Testing Practices</data>
  <data key="d1">Variables</data>
  <data key="d2">Testing practices involve writing and executing tests to ensure code quality; Codex may facilitate or hinder effective testing depending on over-reliance or accuracy.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Downstream Bugs">
  <data key="d0">Downstream Bugs</data>
  <data key="d1">Results</data>
  <data key="d2">Downstream bugs are errors or issues that occur after deployment, potentially influenced by errors propagated through Codex-assisted documentation and testing.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Economic Value">
  <data key="d0">Economic Value</data>
  <data key="d1">Variables</data>
  <data key="d2">The economic value of Codex's code generation includes productivity gains, new capabilities, and downstream impacts on software development.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Biases">
  <data key="d0">Biases</data>
  <data key="d1">Variables</data>
  <data key="d2">Biases refer to the systematic tendencies in Codex's outputs based on training data, which can influence package suggestions, documentation, and the propagation of deprecated methods.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Impacts on Wages and Productivity">
  <data key="d0">Impacts on Wages and Productivity</data>
  <data key="d1">Variables</data>
  <data key="d2">Impacts include potential increases in worker productivity and wages due to better tools, or displacement effects from automation.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Barriers to Entry">
  <data key="d0">Barriers to Entry</data>
  <data key="d1">Variables</data>
  <data key="d2">Barriers to entry involve how Codex may lower the skill or resource requirements for new programmers, affecting diversity and accessibility in the field.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Policy and Governance">
  <data key="d0">Policy and Governance</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Research on Codex's societal impact can inform policy decisions regarding AI deployment, regulation, and support for open-source communities.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code samples">
  <data key="d0">Code samples</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d2">Unit tests are used to automatically evaluate the correctness of generated code, serving as a key metric in model evaluation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code datasets">
  <data key="d0">Code datasets</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d2">The pass@k metric evaluates generated code by measuring the pass rate of unit tests across multiple samples, emphasizing functional correctness.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="metrics and datasets">
  <data key="d0">metrics and datasets</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d2">Evaluation involves metrics like pass@k and datasets like HumanEval to measure code correctness and model performance.&lt;SEP&gt;The evaluation involves metrics like pass@k, BLEU scores, and datasets like HumanEval to assess model accuracy and reliability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Training Methods">
  <data key="d0">Training Methods</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d2">The Adam optimizer is employed to train Codex, with hyperparameters tuned for effective convergence.&lt;SEP&gt;The Adam optimizer is used to train Codex, with specific hyperparameters influencing convergence and training efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Development">
  <data key="d0">Model Development</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d2">Fine-tuning involves strategies like data filtering, tokenizer adjustments, and training protocols to improve code generation.&lt;SEP&gt;Strategies such as data filtering, tokenizer modifications, and training protocols are used to enhance Codex's code generation capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex Models">
  <data key="d0">Codex Models</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d2">Various Codex versions demonstrate increasing success rates with larger parameter counts, indicating a positive correlation between size and accuracy.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Filtering Solutions">
  <data key="d0">Filtering Solutions</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d2">Filtering solutions based on passing unit tests enhances the reliability of success metrics in code evaluation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Timeout Constraint">
  <data key="d0">Timeout Constraint</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d2">Imposing a 3-second timeout affects the measured success rate by excluding solutions that are correct but inefficient.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generated Solutions">
  <data key="d0">Generated Solutions</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d2">Adjusting the temperature influences the diversity and correctness of solutions produced by the model."|&lt;SEP&gt;Adjusting the temperature parameter influences the diversity and correctness of solutions generated by the model.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Function Testing">
  <data key="d0">Function Testing</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d2">Running code in a sandbox ensures safe execution of untrusted code during testing and problem validation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Problems from Examples">
  <data key="d0">Problems from Examples</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d2">Unit testing is used to verify solutions derived from example problems, ensuring correctness and facilitating problem creation."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="CI Frameworks">
  <data key="d0">CI Frameworks</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d2">Commands automate the process of building environments and running tests during continuous integration."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Solutions">
  <data key="d0">Solutions</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d2">Solutions are validated by passing them through unit tests to determine correctness and suitability for training datasets."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Models use heuristics like mean log probability or back-translation to select the best samples, impacting the overall success rate.">
  <data key="d0">Models use heuristics like mean log probability or back-translation to select the best samples, impacting the overall success rate.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d2">sample ranking, model optimization</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex and Codex-D">
  <data key="d0">Codex and Codex-D</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d2">The models are trained on datasets comprising code problems, solutions, and annotations, which influence their ability to generate accurate code and docstrings.&lt;SEP&gt;The training datasets include code problems, solutions, and docstrings, which are used to train the respective models for code and docstring generation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Models use heuristics like mean log probability or back-translation to rank and select the best samples, impacting overall success rates.">
  <data key="d0">Models use heuristics like mean log probability or back-translation to rank and select the best samples, impacting overall success rates.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d2">sample ranking, model optimization</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Models like Codex-S outperform Codex on pass@k metrics, with margins indicating the degree of improvement.">
  <data key="d0">Models like Codex-S outperform Codex on pass@k metrics, with margins indicating the degree of improvement.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d2">performance comparison, model effectiveness</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex-S shows improved performance metrics over Codex, especially on pass@1 and pass@100.">
  <data key="d0">Codex-S shows improved performance metrics over Codex, especially on pass@1 and pass@100.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d2">model comparison, performance metrics</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="sample ranking">
  <data key="d0">sample ranking</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d2">Back-translation is used as a technique to evaluate and rank generated samples based on their fidelity to the original code or problem.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Comparison">
  <data key="d0">Comparison</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d2">Performance margins quantify the difference in success metrics like pass@k between models, indicating relative improvements.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Broader Impacts and Hazard Analysis">
  <data key="d0">Broader Impacts and Hazard Analysis</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d2">The identified limitations inform the societal and safety hazard analyses, highlighting areas where Codex may pose risks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="users">
  <data key="d0">users</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Automation bias leads users to overly trust generated outputs, which can compromise safety and correctness.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="study designs">
  <data key="d0">study designs</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Empirical investigations are necessary to identify effective strategies for ensuring vigilance and safety in real-world applications.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="applications/implications">
  <data key="d0">applications/implications</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Understanding safety implications guides responsible deployment and mitigation efforts to prevent harm.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Object of Study">
  <data key="d0">Object of Study</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">A classical formalism used to generate program syntax trees in program synthesis."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="AST">
  <data key="d0">AST</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">Abstract Syntax Trees are structures representing program syntax, utilized in models like code2seq and in program synthesis."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Study">
  <data key="d0">Study</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">Found code more predictable than natural language using n-gram language models."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Latent Predictor Networks">
  <data key="d0">Latent Predictor Networks</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">Networks that generate code conditioned on latent modes, aiding in code generation."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Large Language Models (DeVlin et al., 2018; Radford et al., 2019; Liu et al., 2019; Raffel et al., 2020; Brown et al., 2020)">
  <data key="d0">Large Language Models (DeVlin et al., 2018; Radford et al., 2019; Liu et al., 2019; Raffel et al., 2020; Brown et al., 2020)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">Transformers like GPT-2, GPT-3, and T5 are large-scale models applied to code synthesis and understanding."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="buggy to correct programs">
  <data key="d0">buggy to correct programs</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d2">Models treat bug fixing as translating buggy code into correct code, assessing performance via code translation accuracy.&lt;SEP&gt;Models treat bug fixing as translating buggy code into correct code, with performance measured by translation accuracy and functional correctness.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="reference">
  <data key="d0">reference</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d2">Exact match evaluation compares generated code against reference solutions to measure similarity and correctness.&lt;SEP&gt;Exact match metrics compare generated code to reference solutions to assess similarity, but may not fully capture functional correctness.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="test suites">
  <data key="d0">test suites</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d2">Developers create targeted test suites that may have limited coverage, impacting bug detection effectiveness.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="evaluation set">
  <data key="d0">evaluation set</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d2">Training on data distributions similar to evaluation datasets enhances model performance and generalization.&lt;SEP&gt;Training on data distributions similar to evaluation sets improves model performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Poisoning Vulnerabilities">
  <data key="d0">Poisoning Vulnerabilities</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Poisoning attacks threaten neural program synthesis systems by introducing vulnerabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Open Source Software">
  <data key="d0">Open Source Software</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">A survey of literature explores women's participation and gender diversity in open source communities.&lt;SEP&gt;A survey of literature explores women's participation in open source communities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Women’s Participation">
  <data key="d0">Women’s Participation</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">A survey of literature explores women's participation and gender diversity in open source communities.&lt;SEP&gt;A survey of literature explores women's participation in open source communities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="The examples illustrate how the function counts vowels in different strings, showing the application of the linguistic rule for 'y'.">
  <data key="d0">The examples illustrate how the function counts vowels in different strings, showing the application of the linguistic rule for 'y'.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d2">demonstration, function behavior</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="The sample inputs show how the function counts vowels, illustrating the application of the rule for 'y'.">
  <data key="d0">The sample inputs show how the function counts vowels, illustrating the application of the rule for 'y'.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d2">demonstration, function behavior</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Synthesis community">
  <data key="d0">Synthesis community</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d2">The community advocates for principled benchmarks and challenge problems to rigorously compare synthesis methodologies across different approaches."|&lt;"benchmarking, methodology comparison&lt;SEP&gt;The synthesis community advocates for the use of principled benchmarks and challenge problems to rigorously evaluate synthesis methodologies.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hyperproperties">
  <data key="d0">Hyperproperties</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d2">Hyperproperties involve reasoning about information flow and security policies, requiring the code to satisfy specific observational properties.&lt;SEP&gt;Reasoning about information flow and security policies involves variables that must satisfy properties like noninterference."|&lt;"security, information flow</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="evaluation">
  <data key="d0">evaluation</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d2">The HumanEval dataset provides the problems, solutions, and tests used to evaluate the models' performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="">
  <data key="d0"></data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d2">The process of entity and relationship extraction is a core concept in text analysis and information retrieval.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="s">
  <data key="d0">s</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">The anti_shuffle function processes a string by sorting characters within each word, producing an ordered version while maintaining word order and spaces."|&lt;SEP&gt;The function anti_shuffle processes a string s by sorting characters within each word to produce an ordered version, maintaining original word order and spaces."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="prime numbers">
  <data key="d0">prime numbers</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">The count_up_to function generates a list of prime numbers less than n, demonstrating prime number computation and list generation."|&lt;SEP&gt;The function count_up_to generates a list of prime numbers less than n, illustrating number theory and prime checking algorithms."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="palindromic array">
  <data key="d0">palindromic array</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">The smallest_change function determines the minimal number of element modifications needed to convert an array into a palindrome, relevant to array manipulation and symmetry."|&lt;SEP&gt;The smallest_change function determines the minimum number of element modifications needed to make an array palindromic, relevant to array transformation algorithms."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias">
  <data key="d0">Bias</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">This section analyzes how models like Codex encode bias, which can cause societal harms, highlighting the need for bias assessment and mitigation in AI systems."|&lt;SEP&gt;This section discusses how models like Codex encode bias, which can lead to societal harms, emphasizing the importance of bias detection and mitigation."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Prompts related to protected classes">
  <data key="d0">Prompts related to protected classes</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d2">Prompts designed to probe model biases and harmful responses related to sensitive attributes.&lt;SEP&gt;Prompts designed to probe model biases and harmful tendencies.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Datasets">
  <data key="d0">Code Datasets</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d2">Code datasets that encode social biases contribute to biased model outputs.&lt;SEP&gt;Large collections of C/C++ code used for training models and evaluating their performance in predicting pragmas and performance changes.</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Comparison">
  <data key="d0">Bias Comparison</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d2">GPT-3 and Codex show similar bias tendencies, with GPT-3 often exhibiting more diversity in biased terms.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Prompt Framing">
  <data key="d0">Prompt Framing</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d2">The framing and specificity of prompts influence the likelihood of biased responses from models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Out-of-Distribution Prompts">
  <data key="d0">Out-of-Distribution Prompts</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d2">Models tend to produce more harmful or biased outputs when prompted with out-of-distribution inputs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Potential Exploitation">
  <data key="d0">Potential Exploitation</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d2">Threat actors may exploit biases in models for malicious purposes like causing harm or misinformation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Current limitations of Codex include difficulty in reliably detecting high-dimension vulnerabilities and preventing malicious suggestions, which pose ongoing security concerns.">
  <data key="d0">Current limitations of Codex include difficulty in reliably detecting high-dimension vulnerabilities and preventing malicious suggestions, which pose ongoing security concerns.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d2">model constraints, cybersecurity risks</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Biases in Suggestions">
  <data key="d0">Biases in Suggestions</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d2">Open-source developers' work may be affected by Codex's suggestions, especially regarding deprecated methods or popular packages, impacting maintenance practices.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Performance Modeling">
  <data key="d0">Performance Modeling</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The hypothesis that large language models can be adapted to accurately predict and model the performance (e.g., execution time) of HPC codes based on source code features.&lt;SEP&gt;The hypothesis that large language models can be adapted to accurately predict performance metrics such as execution time based on source code features in HPC.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Parallel Codes">
  <data key="d0">Parallel Codes</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Complex software written for parallel execution in HPC, including scientific applications and benchmarks.&lt;SEP&gt;Complex source code designed for parallel execution in HPC, including scientific applications, benchmarks, and programming solutions.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenMP Pragmas">
  <data key="d0">OpenMP Pragmas</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code annotations that direct the compiler to parallelize loops, which models are tested to generate correctly in various for-loop scenarios.&lt;SEP&gt;Compiler directives used to specify parallel regions and optimize parallel execution in source code, which HPC-Coder can automatically add to improve parallelization.&lt;SEP&gt;Compiler directives used to specify parallel regions and optimize performance in shared-memory parallel programming.&lt;SEP&gt;OpenMP pragmas are annotations in code that enable parallel execution, tested for model accuracy in generating functionally correct parallel code.&lt;SEP&gt;OpenMP pragmas are annotations used to specify parallel regions in code, tested for their correct generation by models.&lt;SEP&gt;OpenMP pragmas are compiler directives used in C/C++ and Fortran to specify shared-memory parallelism, particularly decorating loops with directives like #pragma omp parallel for to enable parallel execution.&lt;SEP&gt;OpenMP pragmas are compiler directives used in programming languages like C/C++ and Fortran to specify parallel regions, especially decorating loops with #pragma omp parallel for to enable multi-threaded execution.&lt;SEP&gt;OpenMP pragmas are generated with high functional accuracy (97% PolyCoder+HPC, 94% PolyCoder), demonstrating models' ability to understand dependencies and clauses necessary for correct parallelization.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-3e334e5860963a6ca1939b6719cae953&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Dataset of HPC and Scientific Codes">
  <data key="d0">Dataset of HPC and Scientific Codes</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A collection of source code from scientific and HPC applications used to train and evaluate the HPC-Coder model.&lt;SEP&gt;A curated collection of source code from scientific and HPC applications used to train and evaluate the HPC-Coder model.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Predictive Language Models">
  <data key="d0">Predictive Language Models</data>
  <data key="d1">Tools</data>
  <data key="d2">Models that leverage language modeling techniques to automate code completion, decoration, and performance prediction in HPC contexts.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Completion">
  <data key="d0">Code Completion</data>
  <data key="d1">Results</data>
  <data key="d2">A benchmarking task where models generate code snippets based on natural language prompts, evaluated for functional correctness.&lt;SEP&gt;HPC-Coder demonstrates the ability to auto-complete HPC functions where generic models fail, indicating improved code generation capabilities.&lt;SEP&gt;The ability of HPC-Coder to auto-complete HPC functions where generic models cannot, demonstrating improved accuracy in code generation tasks.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Decoration with OpenMP Pragmas">
  <data key="d0">Code Decoration with OpenMP Pragmas</data>
  <data key="d1">Results</data>
  <data key="d2">HPC-Coder can automatically decorate loops with OpenMP pragmas, enhancing parallelization and performance.&lt;SEP&gt;HPC-Coder can successfully decorate for loops with OpenMP pragmas, enhancing parallelization annotations in source code.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Change Modeling">
  <data key="d0">Performance Change Modeling</data>
  <data key="d1">Results</data>
  <data key="d2">HPC-Coder can model performance variations in scientific application repositories and programming competition solutions, indicating its effectiveness in performance prediction.&lt;SEP&gt;HPC-Coder can model performance variations in scientific application repositories and programming competition solutions, showing its effectiveness in performance prediction.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="knowledge">
  <data key="d0">knowledge</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Knowledge transfer involves applying learned information from one domain to address new problems, often requiring fewer samples for effective learning.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="transfer learning">
  <data key="d0">transfer learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A machine learning approach where knowledge gained from training on one task or dataset is transferred to improve learning on a related task, especially useful when data samples are limited.&lt;SEP&gt;Transfer learning is a machine learning approach where a model trained on one task or dataset is adapted to perform a related task, reducing data and training requirements.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="performance modeling">
  <data key="d0">performance modeling</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The investigation of whether models like HPC-Coder can accurately predict the performance of scientific and HPC source code and how well they generalize across datasets.&lt;SEP&gt;The study investigates whether fine-tuned LLMs can effectively model the performance of HPC and scientific codes and predict performance changes with high accuracy.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="dataset of HPC and scientific codes">
  <data key="d0">dataset of HPC and scientific codes</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A curated collection of open-source HPC and scientific code repositories used for training and evaluating the models.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="code generation tests">
  <data key="d0">code generation tests</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Benchmark tasks designed to evaluate the model's ability to generate HPC-specific code, including OpenMP pragmas, with success rates measured.&lt;SEP&gt;Specific HPC-related code generation tasks designed to evaluate the model's ability to generate correct and efficient code, including OpenMP pragmas.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenMP pragmas">
  <data key="d0">OpenMP pragmas</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Annotations in source code that specify parallel regions, which the model labels with high accuracy, facilitating parallel programming analysis.&lt;SEP&gt;OpenMP pragmas are directives used in source code to enable parallelism, which the model labels with 97% accuracy.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="performance prediction">
  <data key="d0">performance prediction</data>
  <data key="d1">Results</data>
  <data key="d2">The model predicts relative performance of source code modifications with up to 92% accuracy, demonstrating its effectiveness in performance modeling.&lt;SEP&gt;The model's ability to predict relative performance of code modifications with up to 92% accuracy, demonstrating its utility in performance optimization.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="code generation and labeling">
  <data key="d0">code generation and labeling</data>
  <data key="d1">Results</data>
  <data key="d2">The model outperforms other LLMs on HPC-specific code generation and OpenMP pragma labeling tasks, with higher success rates.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="transformer-based language models">
  <data key="d0">transformer-based language models</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A class of neural network models that use self-attention mechanisms to process sequential data, including source code, for tasks like generation and labeling.&lt;SEP&gt;The application of transformer architectures to source code modeling combines natural language processing techniques with software engineering.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="perplexity">
  <data key="d0">perplexity</data>
  <data key="d1">Variables</data>
  <data key="d2">A measure of how well a language model predicts a sequence; lower perplexity indicates better predictive performance.&lt;SEP&gt;A measure of how well the language model predicts the dataset tokens, used to evaluate model performance during training and validation.&lt;SEP&gt;A metric measuring how well the language model predicts the tokens in the dataset, used to evaluate training progress and model performance.&lt;SEP&gt;A metric measuring the confidence of language models in predicting sequences; lower perplexity indicates better language modeling performance.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7&lt;SEP&gt;chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="accuracy of predictions">
  <data key="d0">accuracy of predictions</data>
  <data key="d1">Variables</data>
  <data key="d2">The measure of how correctly the model predicts code performance, pragmas, or code generation tasks, with reported accuracies up to 97% for labeling and 92% for performance prediction.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="source code modeling">
  <data key="d0">source code modeling</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The activity of analyzing, understanding, and predicting the behavior or performance of source code, often using machine learning models.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC and scientific codes">
  <data key="d0">HPC and scientific codes</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Source code from high-performance computing and scientific computing domains, used as the primary data for training and evaluation.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="open-source repositories">
  <data key="d0">open-source repositories</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Publicly available collections of HPC and scientific code used to curate the dataset for training and testing models.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="curated dataset">
  <data key="d0">curated dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A comprehensive collection of HPC and scientific codes gathered from open repositories, used for training and evaluation.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="language modeling scores">
  <data key="d0">language modeling scores</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics indicating how well the model predicts and generates source code, with HPC-related code outperforming other models.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="code generation tasks">
  <data key="d0">code generation tasks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Specific tasks aimed at assessing the model's ability to generate accurate HPC code, with success rates up to 53% higher than other models.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="labeling of code with OpenMP pragmas">
  <data key="d0">labeling of code with OpenMP pragmas</data>
  <data key="d1">Results</data>
  <data key="d2">High accuracy (97%) in labeling parallel directives, demonstrating the model's proficiency in understanding parallel constructs.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="predicting relative performance">
  <data key="d0">predicting relative performance</data>
  <data key="d1">Results</data>
  <data key="d2">The model predicts performance changes in source code with up to 92% accuracy, aiding performance tuning.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Perplexity">
  <data key="d0">Perplexity</data>
  <data key="d1">Results</data>
  <data key="d2">A measure of a language model's uncertainty in predicting the next token; lower perplexity indicates better performance, used to evaluate models after fine-tuning.&lt;SEP&gt;Perplexity measures a language model's confidence in its predictions and is used to evaluate model performance, especially in downstream tasks.&lt;SEP&gt;Perplexity measures a language model's confidence in predicting tokens and is used as an evaluation metric to assess model performance, particularly on downstream tasks.&lt;SEP&gt;Perplexity measures how well a language model predicts a sample, calculated as the exponential of the training loss, and is used to evaluate model performance during training and validation.&lt;SEP&gt;Perplexity measures the uncertainty of a language model in predicting the next token; lower values indicate better model performance, and it is used to evaluate models after fine-tuning.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Text Generation">
  <data key="d0">Text Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Text generation involves producing coherent and contextually relevant text sequences using language models, often requiring sampling techniques to maintain diversity.&lt;SEP&gt;Text generation involves producing new text sequences using trained language models, with challenges such as maintaining context and avoiding loops.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Sampling Methods">
  <data key="d0">Sampling Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Sampling methods like temperature, top-k, and nucleus sampling are techniques used to generate diverse and coherent text by controlling the probability distribution from which tokens are sampled.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Top-k Sampling">
  <data key="d0">Top-k Sampling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Top-k sampling involves selecting tokens from the top k most probable options, reducing the chance of sampling unlikely tokens and improving output relevance.&lt;SEP&gt;Top-k sampling restricts token selection to the k most probable tokens, aiming to improve generation quality by excluding unlikely options.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="LLMs for Code Generation">
  <data key="d0">LLMs for Code Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Large Language Models (LLMs) trained on source code can perform tasks such as code generation, prediction, and sequence decoding, often using specific training approaches like left-to-right, masked, or encoder-decoder models.&lt;SEP&gt;Large Language Models trained on source code can generate, predict, or translate code, utilizing different training paradigms such as causal, masked, or encoder-decoder models.&lt;SEP&gt;Transformers and large language models like GPT-3, Codex, GPT-4 are trained on code and natural language to generate or summarize code, detect bugs/malware, and assist in software engineering tasks.&lt;SEP&gt;Transformers and large language models like GPT-3, Codex, GPT-4 trained on code and natural language to generate code, summaries, detect bugs/malware, and assist in software engineering.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Left-to-Right Models">
  <data key="d0">Left-to-Right Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Causal language models predict the next token in a sequence, generating text sequentially from left to right, which limits the context but is effective for text generation tasks.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Masked Models">
  <data key="d0">Masked Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Masked models predict tokens at masked positions within a sequence, allowing use of broader context by masking and predicting multiple tokens in the input.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Encoder-Decoder Models">
  <data key="d0">Encoder-Decoder Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Encoder-decoder models process input sequences through an encoder and generate output sequences via a decoder, effective for sequence-to-sequence tasks like code translation or summarization.&lt;SEP&gt;Encoder-decoder models process input sequences through an encoder and generate output sequences via a decoder, suitable for sequence-to-sequence tasks like code translation.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model Confidence">
  <data key="d0">Model Confidence</data>
  <data key="d1">Variables</data>
  <data key="d2">Model confidence refers to the degree of certainty a language model has in its predictions, often measured by metrics like perplexity.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Downstream Tasks">
  <data key="d0">Downstream Tasks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Downstream tasks are applications such as text generation or classification that utilize the trained language models for practical purposes.&lt;SEP&gt;Downstream tasks include code generation, OpenMP pragma labeling, and relative performance prediction, used to assess the model's capabilities in generating correct code, understanding code annotations, and predicting performance metrics.&lt;SEP&gt;Tasks like code generation, OpenMP pragma labeling, and performance prediction used to evaluate the capabilities of the trained models.&lt;SEP&gt;Tasks such as code generation used to assess the effectiveness of fine-tuned models in practical applications.&lt;SEP&gt;Tasks such as code generation used to evaluate the effectiveness of the fine-tuned models.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Sampling Techniques">
  <data key="d0">Sampling Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Sampling techniques like temperature, top-k, and nucleus sampling are methods used to generate varied and high-quality text by controlling the probability distribution from which tokens are sampled.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Causal Language Models">
  <data key="d0">Causal Language Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Causal language models generate text sequentially from left to right, predicting the next token based on prior tokens, suitable for tasks like code or text generation.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Masked Language Models">
  <data key="d0">Masked Language Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Masked models predict tokens at masked positions within a sequence, allowing the use of broader context for more accurate predictions.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training Methodology">
  <data key="d0">Training Methodology</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The methodology involves collecting a large dataset of HPC source code, preprocessing it, and fine-tuning pre-trained language models to adapt them for HPC-specific code generation and downstream tasks.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC Source Code Dataset">
  <data key="d0">HPC Source Code Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset consisting of source code used for high-performance computing (HPC) tasks, serving as the training and evaluation data for models like GPT-Neo, PolyCoder, and GPT-2.&lt;SEP&gt;A large collection of high-performance computing source code used to train and fine-tune models to specialize in HPC applications.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model Selection">
  <data key="d0">Model Selection</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Model selection refers to evaluating multiple fine-tuned models on downstream tasks such as code generation, pragma labeling, and performance prediction to choose the best performing model.&lt;SEP&gt;The process of comparing multiple fine-tuned models based on their performance on downstream tasks to select the best one.&lt;SEP&gt;The process of evaluating and choosing the best performing model after fine-tuning for deployment in downstream HPC tasks.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Labeling">
  <data key="d0">Labeling</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Applying the model to label or annotate HPC source code for analysis, documentation, or further processing.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training Setup and Methodology">
  <data key="d0">Training Setup and Methodology</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The training setup and methodology describe the processes involved in fine-tuning and selecting the best language model for HPC code understanding and generation, including dataset collection, model training, and downstream task evaluation.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Data Datasets">
  <data key="d0">Performance Data Datasets</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">These datasets contain code pairs with associated performance data, used to train models to understand performance differences and regressions in HPC applications.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Preprocessed Data">
  <data key="d0">Preprocessed Data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data that has been cleaned and prepared through filtering, deduplication, and tokenization to be used for training language models.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Section V">
  <data key="d0">Section V</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Section V in the paper details the methodology for model fine-tuning and selection, including training setup and experimental procedures.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Section VI">
  <data key="d0">Section VI</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Section VI describes the evaluation of the trained models on downstream tasks such as code generation, pragma labeling, and performance prediction.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Section VII">
  <data key="d0">Section VII</data>
  <data key="d1">Results</data>
  <data key="d2">Section VII presents the results obtained from testing the models on the specified downstream tasks, analyzing their performance.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Fig. 1">
  <data key="d0">Fig. 1</data>
  <data key="d1">Tools</data>
  <data key="d2">Figure 1 provides an overview of the steps involved in training an HPC-specific model and deploying it on various downstream tasks, including data collection, model fine-tuning, and evaluation.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Fig. 2">
  <data key="d0">Fig. 2</data>
  <data key="d1">Tools</data>
  <data key="d2">Figure 2 illustrates the distribution of lines of code across different file types in the HPC source dataset, informing dataset composition.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC source dataset">
  <data key="d0">HPC source dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A large collection of C/C++ source code files from GitHub repositories filtered by HPC relevance, used for training language models.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance datasets">
  <data key="d0">Performance datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Two datasets pairing code with performance data, used to train and evaluate models on performance prediction and regression analysis.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Kripke application">
  <data key="d0">Kripke application</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A small HPC application used to generate performance data across different code commits for performance regression analysis.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Laghos application">
  <data key="d0">Laghos application</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Another small HPC application used similarly to Kripke for performance data collection across code versions.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code contests dataset">
  <data key="d0">Code contests dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset of solutions from online programming competitions used to create pairs of functionally similar code for performance modeling.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="GitHub repositories">
  <data key="d0">GitHub repositories</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Source of HPC code files collected for dataset creation, filtered by language and popularity metrics.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Hashing (sha256)">
  <data key="d0">Hashing (sha256)</data>
  <data key="d1">Tools</data>
  <data key="d2">A method used to remove duplicate source code files based on content to prevent bias during training.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code generation">
  <data key="d0">Code generation</data>
  <data key="d1">Results</data>
  <data key="d2">A downstream task where the model generates syntactically and semantically correct HPC code based on prompts.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenMP pragma labeling">
  <data key="d0">OpenMP pragma labeling</data>
  <data key="d1">Results</data>
  <data key="d2">A task where the model identifies and labels OpenMP pragmas in source code, testing its understanding of parallelization annotations.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Relative performance prediction">
  <data key="d0">Relative performance prediction</data>
  <data key="d1">Results</data>
  <data key="d2">The task of predicting code performance metrics, assessing the model's language comprehension and performance modeling abilities.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="830 commits">
  <data key="d0">830 commits</data>
  <data key="d1">Results</data>
  <data key="d2">The total number of commits in the dataset, indicating the extent of code contributions.&lt;SEP&gt;The total number of commits recorded in the dataset, indicating the volume of code contributions and activity within the project.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="programming competition solutions">
  <data key="d0">programming competition solutions</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Solutions submitted for programming contests, used to analyze code performance and differences.&lt;SEP&gt;Solutions submitted for various online programming contests, used to analyze performance and implementation differences.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="code contests dataset">
  <data key="d0">code contests dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A collection of solutions from multiple online programming competitions such as Aizu, AtCoder, CodeChef, CodeForces, and HackerEarth, serving as the primary dataset for analysis.&lt;SEP&gt;A collection of solutions from various online programming competitions such as Aizu, AtCoder, CodeChef, CodeForces, and HackerEarth.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Aizu, AtCoder, CodeChef, CodeForces, HackerEarth">
  <data key="d0">Aizu, AtCoder, CodeChef, CodeForces, HackerEarth</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specific online programming competitions from which solutions are aggregated.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="run time">
  <data key="d0">run time</data>
  <data key="d1">Variables</data>
  <data key="d2">The execution time recorded for each solution when tested against problem test cases, used to compare solution efficiency.&lt;SEP&gt;The recorded execution time of each solution when tested against the contest problem’s test cases, used for comparison.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="solution pairs">
  <data key="d0">solution pairs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Pairs of solutions grouped based on their run times to analyze differences in implementation efficiency.&lt;SEP&gt;Pairs of solutions grouped based on their run times, labeled as slower and faster, to analyze differences in implementation.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="slower and faster pairs">
  <data key="d0">slower and faster pairs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Labels assigned to solution pairs indicating which solution is slower or faster based on run time, facilitating comparative analysis.&lt;SEP&gt;Labels assigned to solution pairs indicating which solution is slower or faster based on run time.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="V. Fine-tuning Methodology">
  <data key="d0">V. Fine-tuning Methodology</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A detailed approach to selecting, training, and optimizing language models for the dataset, including hyperparameter tuning and hardware setup.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Models Selected for Fine-tuning">
  <data key="d0">Models Selected for Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A set of language models based on GPT-2 and GPT-3 architectures chosen for their balance of performance and deployability, including GPT-2, GPT-Neo, and PolyCoder.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="GPT-2">
  <data key="d0">GPT-2</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A language model with 1.5 billion parameters, pre-trained on WebText dataset, used as a baseline for fine-tuning on natural language tasks.&lt;SEP&gt;A language model with 1.5 billion parameters, pre-trained on WebText, used as a baseline for fine-tuning.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder">
  <data key="d0">PolyCoder</data>
  <data key="d1">Methodology</data>
  <data key="d2">A 2.7 billion parameter model pre-trained solely on source code from GitHub, optimized for programming language tasks.&lt;SEP&gt;A 2.7 billion parameter model trained exclusively on source code from GitHub, optimized for programming language tasks.&lt;SEP&gt;A baseline model for code performance prediction, with slightly lower accuracy than PolyCoder+HPC.&lt;SEP&gt;A baseline model for performance prediction, with slightly lower accuracy than PolyCoder+HPC.&lt;SEP&gt;A general large language model trained on code, achieving 94% accuracy in OpenMP pragma prediction and serving as a baseline.&lt;SEP&gt;A language model trained on code, achieving 94% accuracy in predicting OpenMP pragmas.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Fine-tuning setup and hyperparameters">
  <data key="d0">Fine-tuning setup and hyperparameters</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Procedures for adapting pre-trained models to the dataset using the Hugging Face library, DeepSpeed, AdamW optimizer, and specific hyperparameters like learning rate and precision.&lt;SEP&gt;Procedures involving the use of Hugging Face's Trainer, DeepSpeed, AdamW optimizer, specific learning rates, and precision settings to adapt models to the dataset.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="DeepSpeed">
  <data key="d0">DeepSpeed</data>
  <data key="d1">Tools</data>
  <data key="d2">A deep learning optimization library that enables efficient training of large-scale models across multiple hardware resources.&lt;SEP&gt;A framework enabling distributed training and memory optimization for large language models during fine-tuning.&lt;SEP&gt;A framework that provides distributed training capabilities and memory optimizations, enabling large models to be trained efficiently on GPU hardware.&lt;SEP&gt;DeepSpeed is a deep learning optimization library by Microsoft that enables extreme-scale model training with efficiency and scalability.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="AdamW">
  <data key="d0">AdamW</data>
  <data key="d1">Tools</data>
  <data key="d2">An optimizer used during fine-tuning to update model weights, minimizing the loss function.&lt;SEP&gt;An optimizer used to update model weights during fine-tuning, minimizing loss.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="validation dataset">
  <data key="d0">validation dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A 5% subset of the full dataset used to validate model performance during training, preventing overfitting.&lt;SEP&gt;A subset (5%) of the full dataset used to evaluate model performance during fine-tuning.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="V. FINE-TUNING METHODOLOGY">
  <data key="d0">V. FINE-TUNING METHODOLOGY</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A detailed description of the models used and the procedures for selecting, training, and fine-tuning these models on the dataset, including hyperparameter tuning, hardware setup, and optimization techniques.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Models Selected For Fine-tuning">
  <data key="d0">Models Selected For Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A set of language models based on GPT-2 and GPT-3 architectures, chosen for their suitability in language modeling tasks and deployment feasibility, including GPT-2, GPT-Neo, and PolyCoder.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training Loss">
  <data key="d0">Training Loss</data>
  <data key="d1">Variables</data>
  <data key="d2">Training loss quantifies the discrepancy between the model's predictions and actual data during training, serving as a basis for calculating perplexity.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Validation Dataset">
  <data key="d0">Validation Dataset</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">A subset (5%) of the full dataset used to evaluate the model's performance during training, separate from the training data, to prevent overfitting.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HumanEval Benchmark">
  <data key="d0">HumanEval Benchmark</data>
  <data key="d1">Study Design</data>
  <data key="d2">A standard benchmark consisting of 164 Python problems used to evaluate code generation models based on functional correctness.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC Code Generation Problems">
  <data key="d0">HPC Code Generation Problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Custom high-performance computing (HPC) code problems, including numerics, OpenMP, and MPI routines, used to evaluate model capabilities in generating parallel code.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Pass@k Metric">
  <data key="d0">Pass@k Metric</data>
  <data key="d1">Results</data>
  <data key="d2">A metric estimating the probability that at least one of k generated code samples is correct, calculated based on the number of correct samples out of total generated samples.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Parallel Frameworks (OpenMP, MPI)">
  <data key="d0">Parallel Frameworks (OpenMP, MPI)</data>
  <data key="d1">Tools</data>
  <data key="d2">Parallel computing frameworks used in code generation tasks to enable multi-threaded or distributed execution, and to evaluate if generated code correctly utilizes these frameworks.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Experiment Settings">
  <data key="d0">Experiment Settings</data>
  <data key="d1">Study Design</data>
  <data key="d2">Parameters such as temperature (0.1 to 0.8), number of samples (Np=100), and compilation flags used during code generation to optimize and evaluate model performance.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Evaluation Procedure">
  <data key="d0">Evaluation Procedure</data>
  <data key="d1">Methodology</data>
  <data key="d2">Process involving generating multiple code samples, compiling, running, and assessing correctness to compute pass@k scores, providing insights into the model's ability to produce functional code.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Parallel Code Generation Tasks">
  <data key="d0">Parallel Code Generation Tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specific tasks including generating OpenMP pragmas, MPI routines, and other HPC code snippets to evaluate model performance in parallel programming contexts.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="MPI Routines">
  <data key="d0">MPI Routines</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Message Passing Interface routines used in parallel computing, which models attempt to generate correctly for distributed memory systems.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Functionally Correct Code">
  <data key="d0">Functionally Correct Code</data>
  <data key="d1">Results</data>
  <data key="d2">Code that compiles and runs correctly, passing all correctness tests, used as a key measure in evaluation metrics like pass@k.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Generated Code Samples">
  <data key="d0">Generated Code Samples</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Multiple code outputs produced by the model in response to prompts, which are then tested for correctness.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Compilation and Testing">
  <data key="d0">Compilation and Testing</data>
  <data key="d1">Methodology</data>
  <data key="d2">The process of compiling generated code with appropriate compilers and flags, then executing tests to determine correctness.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Parallel Framework">
  <data key="d0">Parallel Framework</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A parallel framework refers to a structured approach or model used to perform computations simultaneously across multiple processing units, exemplified here by MPI for parallel processing.&lt;SEP&gt;A parallel framework refers to a structured model or system, such as MPI, that facilitates concurrent computation by coordinating multiple processes across hardware resources.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC coding task">
  <data key="d0">HPC coding task</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">HPC coding tasks involve programming activities aimed at optimizing high-performance computing applications, such as decorating loops with OpenMP pragmas for parallelism.&lt;SEP&gt;High-Performance Computing (HPC) coding tasks involve programming activities aimed at optimizing code for parallel execution, such as adding OpenMP pragmas to loops for improved performance.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Dataset of for loops with OpenMP pragmas">
  <data key="d0">Dataset of for loops with OpenMP pragmas</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A curated collection of code snippets containing for loops with associated OpenMP pragmas, used for training and evaluating models' ability to generate parallel directives.&lt;SEP&gt;A curated collection of code snippets containing for loops with associated OpenMP pragmas, used for training and evaluation of models.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training Process">
  <data key="d0">Training Process</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The process involves fine-tuning models over multiple epochs with a set learning rate, using validation data to prevent overfitting and optimize performance.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Relative Performance Prediction">
  <data key="d0">Relative Performance Prediction</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Assessment of models' ability to predict code performance changes, with high classification accuracy (88% PolyCoder+HPC, 86% PolyCoder on proxy applications; 92% vs 86% on larger datasets).&lt;SEP&gt;The models are tested for their ability to predict code performance changes, achieving high classification accuracy (88% PolyCoder+HPC, 86% PolyCoder on proxy applications; 92% vs 86% on larger dataset).&lt;SEP&gt;This involves using language models to predict performance slowdowns between code versions, testing their ability to classify whether code has become slower or remains faster.&lt;SEP&gt;This research explores whether language models can accurately predict performance slowdowns between code versions, testing their classification capabilities.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Pair Dataset">
  <data key="d0">Code Pair Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset comprising pairs of code snippets before and after modifications, used to train models to predict relative performance changes.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Binary Classification">
  <data key="d0">Binary Classification</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A machine learning task where models predict one of two outcomes, such as whether code is slower or faster, based on features extracted from code pairs.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model Accuracy">
  <data key="d0">Model Accuracy</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Model accuracy in this context refers to the proportion of correct predictions of performance slowdown or improvement, used to evaluate the classification task.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Tokens of context">
  <data key="d0">Tokens of context</data>
  <data key="d1">Variables</data>
  <data key="d2">Tokens of context refer to segments of code or text, such as 500 tokens before a for loop, used as input to models during training and inference to improve pragma generation.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Syntactic correctness">
  <data key="d0">Syntactic correctness</data>
  <data key="d1">Variables</data>
  <data key="d2">Syntactic correctness evaluates whether the generated pragma matches the actual pragma in structure and syntax, ensuring proper code form.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Functional correctness">
  <data key="d0">Functional correctness</data>
  <data key="d1">Variables</data>
  <data key="d2">Functional correctness assesses whether the generated pragma achieves the intended behavior, regardless of minor syntactic differences, by parsing and comparing pragmas.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Evaluation metric">
  <data key="d0">Evaluation metric</data>
  <data key="d1">Tools</data>
  <data key="d2">The evaluation metric combines syntactic and functional correctness to determine overall model performance in pragma generation.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training process">
  <data key="d0">Training process</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The training process involves fine-tuning models over multiple epochs with specified learning rates, using validation data to prevent overfitting and optimize pragma accuracy.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code pair dataset">
  <data key="d0">Code pair dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset consisting of pairs of code snippets before and after modifications, used to train models to classify whether performance has slowed or remained the same or improved.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Binary classification">
  <data key="d0">Binary classification</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A machine learning approach where models predict one of two outcomes, such as 'slower' or 'faster', based on features extracted from code pairs.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model accuracy">
  <data key="d0">Model accuracy</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Model accuracy in this context indicates the proportion of correct predictions in classifying performance changes, serving as an effectiveness measure.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder+HPC">
  <data key="d0">PolyCoder+HPC</data>
  <data key="d1">Methodology</data>
  <data key="d2">A fine-tuned language model, named HPC-Coder, specialized for HPC code generation and performance modeling.&lt;SEP&gt;A large language model trained for high-performance computing code generation, achieving 97% accuracy in predicting OpenMP pragmas.&lt;SEP&gt;A large language model trained specifically for high-performance computing code generation, achieving 97% accuracy in predicting OpenMP pragmas and outperforming baseline models in performance prediction tasks.&lt;SEP&gt;A model trained on extensive C/C++ code datasets, slightly outperforming baseline in performance prediction accuracy.&lt;SEP&gt;A model trained on larger C/C++ code datasets, performing slightly better in performance prediction tasks.&lt;SEP&gt;A version of the PolyCoder model fine-tuned on HPC source code dataset, designed to generate HPC-specific code with high accuracy.&lt;SEP&gt;A version of the PolyCoder model fine-tuned on HPC source code dataset, optimized for code generation tasks.&lt;SEP&gt;PolyCoder+HPC demonstrates high accuracy in generating correct OpenMP pragmas, indicating its effectiveness in parallel code annotation.&lt;SEP&gt;PolyCoder+HPC demonstrates high accuracy in generating functionally correct OpenMP pragmas, indicating its proficiency in parallel code annotation.&lt;SEP&gt;PolyCoder+HPC is an enhanced model with higher performance, achieving 86% correct samples, and demonstrating improved code compilation success.&lt;SEP&gt;PolyCoder+HPC is an enhanced version of Poly-Coder, with 86% of samples compiling correctly, indicating improved performance in code correctness and compilation.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-cfcd5a8798f30da73fdaa3033d579b42&lt;SEP&gt;chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="GPT-Neo+HPC">
  <data key="d0">GPT-Neo+HPC</data>
  <data key="d1">Model</data>
  <data key="d2">A version of GPT-Neo fine-tuned on HPC source code dataset, evaluated for code generation capabilities.&lt;SEP&gt;A version of GPT-Neo fine-tuned on HPC source code dataset, evaluated for its ability to generate valid HPC code.&lt;SEP&gt;GPT-Neo+HPC is a model with slightly lower performance at 74%, indicating less effectiveness in code compilation tasks compared to PolyCoder variants.&lt;SEP&gt;GPT-Neo+HPC is a model with slightly lower performance at 74%, suggesting its pre-training datasets may have less code, impacting its compilation accuracy.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="GPT2+HPC">
  <data key="d0">GPT2+HPC</data>
  <data key="d1">Model</data>
  <data key="d2">A version of GPT-2 fine-tuned on HPC source code dataset, assessed for HPC code generation, but with limited success due to lack of pretraining on code.&lt;SEP&gt;A version of GPT-2 fine-tuned on HPC source code dataset, assessed for its ability to generate HPC-specific code.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenMP and MPI">
  <data key="d0">OpenMP and MPI</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Parallel programming frameworks used in HPC, and the models' ability to generate code utilizing these frameworks.&lt;SEP&gt;Parallel programming frameworks used in HPC, with the models tested on their ability to generate code utilizing these frameworks.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Syntactic Correctness">
  <data key="d0">Syntactic Correctness</data>
  <data key="d1">Results</data>
  <data key="d2">The proportion of generated code samples that compile successfully, indicating syntactic validity.&lt;SEP&gt;The proportion of generated code samples that successfully compile, reflecting syntactic validity regardless of functional correctness.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Poly-Coder">
  <data key="d0">Poly-Coder</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Poly-Coder is a code generation model evaluated for its ability to produce correct and compilable code, achieving 84% correctness in samples.&lt;SEP&gt;Poly-Coder is a model evaluated for code compilation performance, achieving 84% correct samples, indicating its effectiveness in code generation.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="GPT2-HPC">
  <data key="d0">GPT2-HPC</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">GPT2-HPC has a notably low performance at 30%, likely due to limited code data in its pre-training datasets, affecting its ability to generate correct code.&lt;SEP&gt;GPT2-HPC is a model with significantly lower performance at 30%, likely due to limited pre-training data with code, affecting its compilation success.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Build Rate">
  <data key="d0">Build Rate</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Build rate refers to the percentage of samples successfully compiled by models, serving as a measure of model performance in code generation.&lt;SEP&gt;Build rate refers to the percentage of samples that successfully compile, serving as a measure of a model's effectiveness in code generation.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Correlation between Build and Correctness">
  <data key="d0">Correlation between Build and Correctness</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A visual correlation exists between build success and correctness rates across models, emphasizing that functional correctness depends on successful compilation.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenMP code">
  <data key="d0">OpenMP code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">OpenMP code examples are used to evaluate models' ability to generate parallel code with correct pragmas, demonstrating their understanding of parallel programming constructs.&lt;SEP&gt;OpenMP code is a parallel programming model used in the examples to evaluate models' ability to generate parallel code with correct pragmas.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder output">
  <data key="d0">PolyCoder output</data>
  <data key="d1">Results</data>
  <data key="d2">PolyCoder produces correct sequential code but fails to add OpenMP pragmas, indicating limitations in parallel code generation.&lt;SEP&gt;PolyCoder produces correct sequential code but fails to generate OpenMP pragmas, indicating limitations in parallel code annotation.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder+HPC output">
  <data key="d0">PolyCoder+HPC output</data>
  <data key="d1">Results</data>
  <data key="d2">PolyCoder+HPC successfully adds OpenMP pragmas to loops, showing improved capability in generating parallel code annotations.&lt;SEP&gt;PolyCoder+HPC successfully tags the for loop with an OpenMP pragma, demonstrating improved parallel code generation capabilities.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="MPI code">
  <data key="d0">MPI code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">MPI code examples assess the models' ability to generate distributed memory parallel routines using MPI protocols.&lt;SEP&gt;MPI code is used as an example to assess models' ability to generate distributed memory parallel routines.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder output (MPI)">
  <data key="d0">PolyCoder output (MPI)</data>
  <data key="d1">Results</data>
  <data key="d2">PolyCoder's MPI code often contains long, incorrect routines, demonstrating a lack of understanding of MPI programming.&lt;SEP&gt;PolyCoder's MPI code often contains long, incorrect routines, showing a lack of understanding of MPI programming.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder+HPC output (MPI)">
  <data key="d0">PolyCoder+HPC output (MPI)</data>
  <data key="d1">Results</data>
  <data key="d2">PolyCoder+HPC generates correct MPI routines for computing averages, indicating better understanding of MPI protocols.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Speedups">
  <data key="d0">Speedups</data>
  <data key="d1">Results</data>
  <data key="d2">Speedup measurements show that PolyCoder+HPC can generate code faster than sequential baselines, indicating effective parallelism.&lt;SEP&gt;Speedup metrics compare code performance, showing PolyCoder+HPC produces faster parallel code than sequential baselines, demonstrating effective parallelism use.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Correctness Rate">
  <data key="d0">Correctness Rate</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Correctness rate indicates the proportion of samples that are both correct and compile successfully, reflecting model accuracy.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Correlation">
  <data key="d0">Correlation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A visual correlation exists between build rate and correctness rate across models, implying that successful compilation is associated with correct code output.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenMP Experiments">
  <data key="d0">OpenMP Experiments</data>
  <data key="d1">Study Design</data>
  <data key="d2">The experiments involve testing models' ability to predict OpenMP pragmas and their exact reproduction, measuring accuracy and understanding of dependencies.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Functionally Correct OpenMP Pragmas">
  <data key="d0">Functionally Correct OpenMP Pragmas</data>
  <data key="d1">Results</data>
  <data key="d2">Models can generate pragmas that are functionally correct with high accuracy, indicating understanding of dependencies and clauses.&lt;SEP&gt;Pragmas generated by models are functionally correct with high accuracy, showing understanding of dependencies and clause requirements.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Exact Reproduction of Pragmas">
  <data key="d0">Exact Reproduction of Pragmas</data>
  <data key="d1">Results</data>
  <data key="d2">Models can reproduce exactly the pragmas they have not seen before with 67% (PolyCoder+HPC) and 61% (PolyCoder) accuracy, showing trend learning in clause construction.&lt;SEP&gt;Models can reproduce unseen pragmas with 67% (PolyCoder+HPC) and 61% (PolyCoder) accuracy, indicating trend learning in clause construction.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Performance Modeling">
  <data key="d0">Code Performance Modeling</data>
  <data key="d1">Results</data>
  <data key="d2">LLMs can correlate prior language understanding with code performance properties, enabling performance prediction without extensive data collection.&lt;SEP&gt;LLMs can effectively correlate prior language understanding with code performance properties, enabling performance prediction without large data collection.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Machine Learning for Code Performance">
  <data key="d0">Machine Learning for Code Performance</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Previous approaches used code embeddings (code2vec, ir2vec) for performance-related modeling such as kernel device placement, but lacked leveraging large language models for performance prediction.&lt;SEP&gt;Previous methods used code embeddings (code2vec, ir2vec) for performance-related modeling, but lacked leveraging large language models for performance prediction.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Parallel Code Performance">
  <data key="d0">Parallel Code Performance</data>
  <data key="d1">Results</data>
  <data key="d2">The study demonstrates that models can generate high-accuracy, functionally correct OpenMP pragmas and reproduce pragmas exactly, indicating effective understanding of dependencies and clauses.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenMP Prediction Tests">
  <data key="d0">OpenMP Prediction Tests</data>
  <data key="d1">Study Design</data>
  <data key="d2">Experiments designed to evaluate models' ability to predict and reproduce OpenMP pragmas, measuring accuracy and correctness.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Pragmas">
  <data key="d0">Pragmas</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Pragmas are compiler directives in OpenMP that specify how loops and code regions should be parallelized or optimized.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Dependencies and Clauses">
  <data key="d0">Dependencies and Clauses</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Dependencies and clauses in OpenMP pragmas are critical components that models need to understand for correct prediction.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Trend Learning">
  <data key="d0">Trend Learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models learn patterns and trends in the construction and ordering of OpenMP clauses to improve pragma prediction.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="code2vec">
  <data key="d0">code2vec</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Code2vec is a technique that maps source code into an embedded vector space, used in earlier performance modeling approaches.&lt;SEP&gt;Code2vec is a technique that maps source code to an embedded space for analysis, used in performance-related modeling tasks.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="ir2vec">
  <data key="d0">ir2vec</data>
  <data key="d1">Methodologies</data>
  <data key="d2">ir2vec is a method similar to code2vec, translating intermediate representations of code into embedded vectors for analysis.&lt;SEP&gt;ir2vec is similar to code2vec, mapping intermediate representations of code to an embedded space for performance analysis.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenCL kernel device placement">
  <data key="d0">OpenCL kernel device placement</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">OpenCL kernel device placement involves selecting optimal hardware devices for executing kernels to enhance performance.&lt;SEP&gt;OpenCL kernel device placement involves selecting optimal hardware devices for executing kernels to improve performance.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="DeepDevPERF">
  <data key="d0">DeepDevPERF</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">DeepDevPERF is a BART-based large language model (LLM) designed to suggest performance improvements to C# code.&lt;SEP&gt;DeepDevPERF is a BART-based large language model (LLM) designed to suggest performance improvements to arbitrary C# code.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="performance related keywords">
  <data key="d0">performance related keywords</data>
  <data key="d1">Variables</data>
  <data key="d2">Keywords in commit messages indicating performance-related changes, used for data collection in performance studies.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="code transformations">
  <data key="d0">code transformations</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The paper discusses whether models can suggest code transformations that improve performance rather than just learning relative performance.&lt;SEP&gt;The study investigates whether models can suggest code transformations that improve performance, beyond just predicting relative performance.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC and parallel code generation tasks">
  <data key="d0">HPC and parallel code generation tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Tasks involving high-performance computing and parallel programming, targeted for performance modeling and code generation.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="pass@k rate">
  <data key="d0">pass@k rate</data>
  <data key="d1">Results</data>
  <data key="d2">A metric indicating the proportion of correct code samples generated at top-k predictions, with up to 53% improvement.&lt;SEP&gt;A metric indicating the proportion of correct code samples generated by the model at top-k predictions, with up to 53% improvement.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="labeling for loops with OpenMP pragmas">
  <data key="d0">labeling for loops with OpenMP pragmas</data>
  <data key="d1">Results</data>
  <data key="d2">A task where the model successfully labels loops with OpenMP pragmas, achieving 97% success.&lt;SEP&gt;The model successfully labels loops with OpenMP pragmas, achieving 97% accuracy.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="performance properties of source code">
  <data key="d0">performance properties of source code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Attributes of code that affect execution efficiency, analyzed using the fine-tuned language model.&lt;SEP&gt;Attributes of source code that influence execution efficiency, analyzed using the fine-tuned language model.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="future analyses">
  <data key="d0">future analyses</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Future work involves exploring additional analyses of code performance using the language model.&lt;SEP&gt;Plans to explore additional performance-related analyses using the language model.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="performance-optimized code">
  <data key="d0">performance-optimized code</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Generating code that is both correct and performant to improve efficiency in HPC applications.&lt;SEP&gt;The goal of generating code that is not only correct but also performant, improving efficiency in HPC programming.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="practical tools for scientists and developers">
  <data key="d0">practical tools for scientists and developers</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Development of accessible tools based on the language model to assist HPC practitioners in producing better, more efficient code.&lt;SEP&gt;Development of user-friendly tools based on the model to assist computational scientists and HPC developers.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Machine Learning for Code">
  <data key="d0">Machine Learning for Code</data>
  <data key="d1">Methodology</data>
  <data key="d2">A systematic review of machine learning techniques applied to Android malware detection, evaluating various models and approaches.</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Android Malware Detection">
  <data key="d0">Android Malware Detection</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research investigating the effectiveness of machine learning methods in identifying malicious Android applications.</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Summarization">
  <data key="d0">Code Summarization</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The process of generating concise descriptions of source code functionality, often using models like transformers or assemble foundation models.</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Semantic Similarity Metrics">
  <data key="d0">Semantic Similarity Metrics</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics used to evaluate the quality of source code summaries by measuring semantic closeness between generated and reference summaries.</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Transformer-Based Approach">
  <data key="d0">Transformer-Based Approach</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural network architecture leveraging transformers to improve source code summarization performance.</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Bug Localization and Repair">
  <data key="d0">Bug Localization and Repair</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring whether models can learn from developer mistakes to accurately identify and fix bugs in software code.</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Large Language Models of Code">
  <data key="d0">Large Language Models of Code</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Deep learning models trained on vast amounts of code data to perform tasks such as code generation, summarization, and understanding, evaluated systematically in recent research.</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Duplication">
  <data key="d0">Code Duplication</data>
  <data key="d1">Limitations</data>
  <data key="d2">The adverse effects of redundant code in machine learning models, potentially leading to overfitting and reduced generalization in code-related tasks.</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Transport Mini-Apps">
  <data key="d0">Transport Mini-Apps</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">KRIPKE, a massively parallel transport mini-application used for high-performance computing simulations, developed at LLNL.</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="High-Order Curvilinear Finite Element Methods">
  <data key="d0">High-Order Curvilinear Finite Element Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Numerical techniques for solving complex hydrodynamics problems in scientific computing, applied to Lagrangian hydrodynamics.</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Computing">
  <data key="d0">Computing</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Computing involves the systematic processing of data and algorithms to solve problems across various fields, including computer science and data analysis.&lt;SEP&gt;Computing refers to the systematic use of algorithms, data structures, and computational processes to solve problems and perform tasks across various disciplines.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="AlphaCode">
  <data key="d0">AlphaCode</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">AlphaCode is a model designed for competition-level code generation, aiming to produce high-quality programming solutions at a competitive level.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Openwebtext Corpus">
  <data key="d0">Openwebtext Corpus</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The Openwebtext corpus is a large dataset of diverse web-based text used for training and evaluating language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Few-Shot Learners">
  <data key="d0">Few-Shot Learners</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Few-shot learners are models capable of understanding and performing tasks with minimal training examples, exemplified by models like GPT-3.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Zero-offload">
  <data key="d0">Zero-offload</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to facilitate training of billion-scale models by offloading computations and memory, democratizing large model training.&lt;SEP&gt;Zero-offload is a technique for democratizing billion-scale model training by efficiently offloading computations and memory across hardware resources.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Parallel and Distributed Deep Learning">
  <data key="d0">Parallel and Distributed Deep Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for training large neural networks across multiple processors or machines, focusing on scalability and efficiency.&lt;SEP&gt;This field studies techniques for training large models across multiple processors or machines, focusing on concurrency, scalability, and efficiency.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model Training">
  <data key="d0">Model Training</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Model training involves optimizing neural network parameters using algorithms and datasets to enable the model to perform specific tasks effectively.&lt;SEP&gt;The process of optimizing neural network parameters through algorithms and datasets to enable effective task performance.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Empirical Evaluation">
  <data key="d0">Empirical Evaluation</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Empirical evaluation involves systematically testing and assessing the performance of deep learning frameworks or models through experiments and benchmarks.&lt;SEP&gt;Systematic testing and assessment of models or frameworks through experiments to measure performance and robustness.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Concurrency Analysis">
  <data key="d0">Concurrency Analysis</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Analysis of parallel execution in deep learning training, aiming to improve efficiency and understand bottlenecks.&lt;SEP&gt;Concurrency analysis examines the parallel execution of processes in deep learning to understand and improve training efficiency.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Y. Li et al.">
  <data key="d0">Y. Li et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Assess the capabilities of AlphaCode in competitive programming and code generation tasks.&lt;SEP&gt;Investigates the capabilities of competition-level code generation models such as AlphaCode in solving programming problems.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Gokaslan and V. Cohen">
  <data key="d0">A. Gokaslan and V. Cohen</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Analyze the composition, quality, and utility of the OpenWebText corpus for training language models.&lt;SEP&gt;Provides insights into the composition and utility of the OpenWebText corpus for language model training.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Black et al.">
  <data key="d0">S. Black et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Explores large-scale autoregressive language modeling with GPT-Neo, focusing on model architecture and training methodologies.&lt;SEP&gt;Investigate the performance of large-scale autoregressive models like GPT-Neo in NLP tasks and training efficiency.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="T. B. Brown et al.">
  <data key="d0">T. B. Brown et al.</data>
  <data key="d1">Results</data>
  <data key="d2">Demonstrate that large language models like GPT-3 can perform few-shot learning, solving tasks with minimal examples, highlighting their generalization ability.&lt;SEP&gt;Demonstrates that large language models like GPT-3 can perform tasks with few examples, showcasing their few-shot learning capabilities.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Vol. 34, No. 5, pp. B606–B641, 2012">
  <data key="d0">Vol. 34, No. 5, pp. B606–B641, 2012</data>
  <data key="d1">&lt;|Study Populations/Dataset</data>
  <data key="d2">A published journal volume and issue that references research articles related to computing and artificial intelligence.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="D. Choi">
  <data key="d0">D. Choi</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Part of a research team exploring advanced code generation models and their effectiveness in automated programming tasks.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Chung">
  <data key="d0">J. Chung</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Participates in research assessing the performance of AI models like AlphaCode in coding competitions.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="N. Kushman">
  <data key="d0">N. Kushman</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Contributes to research evaluating AI models for code generation at a competitive level.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Schrittwieser">
  <data key="d0">J. Schrittwieser</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Involved in studies examining the performance of AI systems in code generation tasks.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="R. Leblond">
  <data key="d0">R. Leblond</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Part of the research team analyzing the effectiveness of AI models in programming challenges.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="T. Eccles">
  <data key="d0">T. Eccles</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Studies AI's capability to generate code for complex problems, contributing to understanding AI in programming competitions.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Keeling">
  <data key="d0">J. Keeling</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates the performance of AI models like AlphaCode in solving programming problems efficiently.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="F. Gimeno">
  <data key="d0">F. Gimeno</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Analyzes the potential of AI models in automating code generation for competitive programming.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. D. Lago">
  <data key="d0">A. D. Lago</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Participates in research assessing the performance of advanced AI code generation models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="T. Hubert">
  <data key="d0">T. Hubert</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Examines the effectiveness of AI systems like AlphaCode in coding competitions.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="P. Choy">
  <data key="d0">P. Choy</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Contributes to evaluating AI's ability to generate accurate and efficient code in competitive settings.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. d. M. d’Autume">
  <data key="d0">C. d. M. d’Autume</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Involved in research exploring AI models for automated code generation and their performance metrics.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="I. Babuschkin">
  <data key="d0">I. Babuschkin</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Studies the capabilities of AI models like AlphaCode in solving complex programming challenges.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="P.-S. Huang">
  <data key="d0">P.-S. Huang</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates the performance and accuracy of AI models such as AlphaCode in programming competitions.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Welbl">
  <data key="d0">J. Welbl</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Contributes to evaluating the efficiency of AI systems in code generation tasks for competitive programming.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Gowal">
  <data key="d0">S. Gowal</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Involved in research testing the effectiveness of AI models like AlphaCode in solving programming problems.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Cherepanov">
  <data key="d0">A. Cherepanov</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Studies the performance of AI code generation models in competitive coding scenarios.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Molloy">
  <data key="d0">J. Molloy</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Participates in research assessing AI's ability to generate code for complex tasks in competitions.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="D. J. Mankowitz">
  <data key="d0">D. J. Mankowitz</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Analyzes the effectiveness of AI models such as AlphaCode in automated programming challenges.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="E. S. Robson">
  <data key="d0">E. S. Robson</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Contributes to understanding AI's capabilities in code generation for competitive environments.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="P. Kohli">
  <data key="d0">P. Kohli</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Studies the performance metrics of AI systems like AlphaCode in solving programming problems.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="N. de Freitas">
  <data key="d0">N. de Freitas</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Participates in evaluating AI models' ability to generate competitive code solutions.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="K. Kavukcuoglu">
  <data key="d0">K. Kavukcuoglu</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates the underlying mechanisms of AI code generation models and their performance in competitions.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="O. Vinyals">
  <data key="d0">O. Vinyals</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Explores the capabilities of AI models such as AlphaCode in automating code solutions for programming challenges.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenWebText Corpus">
  <data key="d0">OpenWebText Corpus</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large dataset of web-based textual data used to train language models, supporting research in natural language processing.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Adam">
  <data key="d0">Adam</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An optimization algorithm for training neural networks that combines momentum and adaptive learning rates.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arXiv:1711.05101">
  <data key="d0">arXiv:1711.05101</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An online preprint publication providing the research findings and methodology for the proposed regularization fix.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="BERT (Bidirectional Encoder Representations from Transformers)">
  <data key="d0">BERT (Bidirectional Encoder Representations from Transformers)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A transformer-based language model pre-training approach designed for deep bidirectional understanding of language.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="RoBERTa (Robustly optimized BERT approach)">
  <data key="d0">RoBERTa (Robustly optimized BERT approach)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">An improved variant of BERT with optimized training techniques to enhance language understanding performance.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code2Vec">
  <data key="d0">Code2Vec</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural network model that learns distributed representations of source code to facilitate code analysis and understanding.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="LLM4VV">
  <data key="d0">LLM4VV</data>
  <data key="d1">Tools</data>
  <data key="d2">A framework for developing test suites driven by large language models for compiler validation.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Grounded Copilot">
  <data key="d0">Grounded Copilot</data>
  <data key="d1">Tools</data>
  <data key="d2">A system that studies how programmers interact with AI code-generating models, aiming to make interactions more effective.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="DeepDev-perf">
  <data key="d0">DeepDev-perf</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A deep learning-based approach to improve software performance analysis and optimization.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code2Vec: Learning distributed representations of code">
  <data key="d0">Code2Vec: Learning distributed representations of code</data>
  <data key="d1">Tools</data>
  <data key="d2">A method for embedding code into vector spaces to facilitate various code analysis tasks.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Ir2V: LLVM IR based scalable program embeddings">
  <data key="d0">Ir2V: LLVM IR based scalable program embeddings</data>
  <data key="d1">Tools</data>
  <data key="d2">A scalable system for representing LLVM intermediate representation (IR) of programs as embeddings for analysis.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Evaluation of Large Language Models trained on code">
  <data key="d0">Evaluation of Large Language Models trained on code</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates how well large language models trained on source code perform across various programming and understanding tasks.&lt;SEP&gt;The research hypothesizes that large language models trained on code can effectively perform tasks like code understanding, generation, and validation.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Improvement in Software">
  <data key="d0">Performance Improvement in Software</data>
  <data key="d1">Results</data>
  <data key="d2">Deep learning techniques like DeepDev-perf have been shown to enhance software performance metrics.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Deepdev-perf">
  <data key="d0">Deepdev-perf</data>
  <data key="d1">Methodology</data>
  <data key="d2">Deepdev-perf is a deep learning-based approach designed to improve software performance, involving the application of neural network techniques to optimize code execution and efficiency.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Software Performance">
  <data key="d0">Software Performance</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Software performance refers to how efficiently software runs, including metrics like speed, resource utilization, and responsiveness, which Deepdev-perf aims to enhance.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Deep Learning">
  <data key="d0">Deep Learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Deep learning is a subset of machine learning involving neural networks with multiple layers, used here as the foundational model for Deepdev-perf.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Natural Language Generation, Translation, and Comprehension">
  <data key="d0">Natural Language Generation, Translation, and Comprehension</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">These are core tasks in natural language processing that are addressed by models like BART, focusing on generating, translating, and understanding language.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Sequence-to-Sequence Pre-training">
  <data key="d0">Sequence-to-Sequence Pre-training</data>
  <data key="d1">Methodology</data>
  <data key="d2">Sequence-to-sequence pre-training involves training models on large datasets to understand and generate language sequences, exemplified by BART.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="dec 2020">
  <data key="d0">dec 2020</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The date December 2020 indicates the time context of the document, providing temporal information.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Available: https://doi.org/10.1145/3418463">
  <data key="d0">Available: https://doi.org/10.1145/3418463</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">A digital object identifier (DOI) link indicating the online availability and access point for the referenced document.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Garg">
  <data key="d0">S. Garg</data>
  <data key="d1">Authors</data>
  <data key="d2">S. Garg is one of the authors of the study presenting Deepdev-perf, contributing to research on software performance.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="R. Z. Moghaddam">
  <data key="d0">R. Z. Moghaddam</data>
  <data key="d1">Authors</data>
  <data key="d2">R. Z. Moghaddam is a co-author involved in developing Deepdev-perf, focusing on deep learning approaches for software performance.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. B. Clement">
  <data key="d0">C. B. Clement</data>
  <data key="d1">Authors</data>
  <data key="d2">C. B. Clement is a researcher contributing to the study on Deepdev-perf, involved in methodology and evaluation.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="N. Sundaresan">
  <data key="d0">N. Sundaresan</data>
  <data key="d1">Authors</data>
  <data key="d2">N. Sundaresan is one of the authors of the Deepdev-perf study, involved in research and experimentation.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. Wu">
  <data key="d0">C. Wu</data>
  <data key="d1">Authors</data>
  <data key="d2">C. Wu is a co-author of the Deepdev-perf paper, contributing expertise in software engineering.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="M. Lewis">
  <data key="d0">M. Lewis</data>
  <data key="d1">Authors</data>
  <data key="d2">M. Lewis is an author of the BART paper, contributing to NLP research and model development.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Y. Liu">
  <data key="d0">Y. Liu</data>
  <data key="d1">Authors</data>
  <data key="d2">Y. Liu is a co-author of the BART study, involved in natural language processing research.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="N. Goyal">
  <data key="d0">N. Goyal</data>
  <data key="d1">Authors</data>
  <data key="d2">N. Goyal is a researcher involved in the BART project, focusing on language model pre-training.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="M. Ghazvininejad">
  <data key="d0">M. Ghazvininejad</data>
  <data key="d1">Authors</data>
  <data key="d2">M. Ghazvininejad is a co-author contributing to the BART model research.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Mohamed">
  <data key="d0">A. Mohamed</data>
  <data key="d1">Authors</data>
  <data key="d2">A. Mohamed is involved in the BART study, focusing on NLP tasks.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="O. Levy">
  <data key="d0">O. Levy</data>
  <data key="d1">Authors</data>
  <data key="d2">O. Levy is a researcher contributing to the BART pre-training methodology.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="V. Stoyanov">
  <data key="d0">V. Stoyanov</data>
  <data key="d1">Authors</data>
  <data key="d2">V. Stoyanov is a co-author involved in NLP model research, specifically BART.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="L. Zettlemoyer">
  <data key="d0">L. Zettlemoyer</data>
  <data key="d1">Authors</data>
  <data key="d2">L. Zettlemoyer is a researcher contributing to the BART model development and NLP tasks.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arXiv:1910.13461">
  <data key="d0">arXiv:1910.13461</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The arXiv preprint link indicates the online availability and publication of the BART research paper, providing temporal and access information.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Natural Language Generation">
  <data key="d0">Natural Language Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Natural Language Generation (NLG) is a key task in NLP involving the automatic production of human-like language text.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Translation">
  <data key="d0">Translation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Translation refers to converting text from one language to another, a primary application of models like BART.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Comprehension">
  <data key="d0">Comprehension</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Language comprehension involves understanding and interpreting natural language input, which BART aims to enhance.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Sequence-to-sequence models">
  <data key="d0">Sequence-to-sequence models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Sequence-to-sequence models are neural network architectures designed to handle input and output sequences, fundamental to BART's design.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Denoising Autoencoder">
  <data key="d0">Denoising Autoencoder</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Denoising autoencoders are models trained to reconstruct original data from corrupted input, a core component of BART's training process.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Applications">
  <data key="d0">Applications</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d2">HPC-Coder's automation capabilities can be applied to improve productivity, correctness, and performance in scientific HPC software."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="source code">
  <data key="d0">source code</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d2">Transformer architectures are applied to model source code sequences, enabling tasks like code generation and labeling.&lt;SEP&gt;Transformer models are applied to source code sequences to perform tasks like code generation, labeling, and performance prediction.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="success rates">
  <data key="d0">success rates</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d2">The model completes HPC-specific code generation tasks at a rate up to 53% higher than other models, demonstrating superior performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="labeling of OpenMP pragmas">
  <data key="d0">labeling of OpenMP pragmas</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d2">The model labels OpenMP pragmas with 97% accuracy, showing proficiency in recognizing parallel directives in source code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC-specific Language Model">
  <data key="d0">HPC-specific Language Model</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d2">The HPC-specific language model can be used to automate code generation, labeling, and improve software development workflows in high-performance computing.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="solutions">
  <data key="d0">solutions</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d2">Each solution's run time is recorded when tested against test cases, serving as the basis for pairing and comparison.&lt;SEP&gt;Each solution's run time is recorded when tested against test cases, used to group solutions into pairs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="fine-tuning setup and hyperparameters">
  <data key="d0">fine-tuning setup and hyperparameters</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d2">The models are chosen based on their architecture, size, and pre-training data to optimize for language modeling tasks.&lt;SEP&gt;The selected models are based on architectures suitable for language modeling, with specific configurations for size and data pre-training.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="models selected for fine-tuning">
  <data key="d0">models selected for fine-tuning</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d2">The models are chosen based on their architecture, size, and pre-training data to optimize for language modeling tasks.&lt;SEP&gt;The selected models are based on architectures suitable for language modeling, with specific configurations for size and data pre-training.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Samples">
  <data key="d0">Code Samples</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d2">Generated code is evaluated for correct utilization of OpenMP or MPI frameworks to ensure functional parallelism.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Parallel Frameworks">
  <data key="d0">Parallel Frameworks</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d2">Generated code is evaluated for correct utilization of OpenMP or MPI frameworks to ensure functional parallelism.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Downstream Performance">
  <data key="d0">Downstream Performance</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d2">Continuing to fine-tune models beyond a certain point leads to decreased downstream task performance due to catastrophic forgetting.&lt;SEP&gt;Continuing to fine-tune models beyond a certain point leads to performance decline because of catastrophic forgetting."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Learning from Developer Mistakes">
  <data key="d0">Learning from Developer Mistakes</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d2">Research explores whether models can learn from real bug fixes to localize and repair bugs effectively.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Competition-level code generation">
  <data key="d0">Competition-level code generation</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d2">AlphaCode aims to generate code solutions at a competitive level, advancing AI in programming challenges.&lt;SEP&gt;AlphaCode is designed to generate code at a competitive level, aiming to solve programming problems effectively.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Language Model Training">
  <data key="d0">Language Model Training</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d2">The Openwebtext corpus provides diverse textual data essential for training robust language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Language Model Dataset">
  <data key="d0">Language Model Dataset</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d2">A comprehensive dataset used for training and benchmarking large language models, supporting diversity and robustness.&lt;SEP&gt;The Pile is a large, diverse dataset utilized for training and benchmarking language models, contributing to their generalization capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Few-Shot Learning">
  <data key="d0">Few-Shot Learning</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d2">Language models like GPT-3 are capable of few-shot learning, performing tasks with minimal examples.&lt;SEP&gt;Language models like GPT-3 demonstrate the ability to perform tasks with few examples, showcasing advanced few-shot learning capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Deep Learning Architecture">
  <data key="d0">Deep Learning Architecture</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d2">Transformers are the foundational architecture for modern NLP models, enabling efficient processing of sequential data through self-attention mechanisms.&lt;SEP&gt;Transformers form the basis of modern NLP models, utilizing self-attention mechanisms for efficient sequence processing.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="How programmers interact with code-generating models">
  <data key="d0">How programmers interact with code-generating models</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d2">Grounded Copilot studies the interaction patterns between programmers and AI models to improve usability and effectiveness.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Deep learning-based approach">
  <data key="d0">Deep learning-based approach</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d2">DeepDev-perf employs deep learning techniques to analyze and improve software performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Evaluation of large language models trained on code">
  <data key="d0">Evaluation of large language models trained on code</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d2">The research hypothesizes that large language models trained on code can effectively perform tasks like code understanding, generation, and validation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Proceedings of the 30th ACM Conference">
  <data key="d0">Proceedings of the 30th ACM Conference</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d2">The conference proceedings document the research and evaluation of Deepdev-perf.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<edge source="Preprint" target="Evidence Types">
  <data key="d5">5.0</data>
  <data key="d6">A preprint document presenting the case study on complex question answering.</data>
  <data key="d7">publication, evidence</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Preprint" target="Characters">
  <data key="d5">5.0</data>
  <data key="d6">The preprint discusses characters involved in a textual or character analysis, possibly related to language models or AI systems.</data>
  <data key="d7">study populations, evidence</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSP Y" target="Self-Improving Pipelines">
  <data key="d5">18.0</data>
  <data key="d6">DSP Y introduces pipelines that can learn from demonstrations and optimize themselves to improve task performance.&lt;SEP&gt;DSP Y introduces the concept of pipelines that can learn and optimize their components to improve performance over time.</data>
  <data key="d7">learning, adaptation&lt;SEP&gt;learning, optimization</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSP Y" target="Language Models (LMs)">
  <data key="d5">16.0</data>
  <data key="d6">DSP Y models LMs as modular, parameterized components that can be composed into pipelines for systematic reasoning and task solving.&lt;SEP&gt;Declarative Language</data>
  <data key="d7">DSP Y models LMs as modular, parameterized components that can be composed into pipelines for systematic reasoning and task solving.&lt;SEP&gt;modularity, abstraction</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Language Models (LMs)" target="are leveraged by the Modules and Optimizers within the Text Transformation Graph">
  <data key="d5">9.0</data>
  <data key="d6">technology utilization, core AI components</data>
  <data key="d7">9</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompting Techniques" target="Pipeline Optimization">
  <data key="d5">7.0</data>
  <data key="d6">Prompting techniques are integrated and optimized within DSPy pipelines to enhance LM performance.</data>
  <data key="d7">prompt optimization, systematic design</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompting Techniques" target="Prompt Templates">
  <data key="d5">19.0</data>
  <data key="d6">DSP Y replaces handcrafted prompt templates with modular, learnable components for better generalization."|&lt;SEP&gt;DSP Y replaces manual prompt templates with modular, learnable prompting components for systematic optimization.&lt;SEP&gt;DSPY aims to replace manual prompt templates with learnable, modular components for better scalability and robustness.</data>
  <data key="d7">automation, generalization&lt;SEP&gt;automation, scalability</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompting Techniques" target="Finetuning">
  <data key="d5">7.0</data>
  <data key="d6">Finetuning modules are integrated into pipelines to enhance task-specific performance."|</data>
  <data key="d7">training, adaptation</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompting Techniques" target="Augmentation">
  <data key="d5">6.0</data>
  <data key="d6">Augmentation modules add additional information or sources to prompts to improve LM responses."|</data>
  <data key="d7">data enhancement</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompting Techniques" target="Reasoning Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Reasoning modules like Chain of Thought and ReAct are formalized within DSP Y to enable multi-step inference."|</data>
  <data key="d7">reasoning, formalization</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompting Techniques" target="Executable Commands">
  <data key="d5">14.0</data>
  <data key="d6">Zero-shot or few-shot prompting techniques are used to elicit LLMs to generate accurate executable commands or scripts for calling domain tools.</data>
  <data key="d7">prompt engineering, command generation</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Pipeline Optimization" target="Multi-hop Retrieval">
  <data key="d5">5.0</data>
  <data key="d6">DSPy pipelines are designed to handle complex retrieval tasks involving multiple steps or sources.</data>
  <data key="d7">complexity, task decomposition</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Pipeline Optimization" target="Complex Question Answering">
  <data key="d5">4.0</data>
  <data key="d6">DSPy enables the development of pipelines capable of answering intricate questions through optimized module composition.</data>
  <data key="d7">reasoning, task complexity</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Pipeline Optimization" target="Agent Loops">
  <data key="d5">3.0</data>
  <data key="d6">DSPy supports controlling iterative agent behaviors within pipelines for advanced reasoning tasks.</data>
  <data key="d7">iteration, control</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Pipeline Optimization" target="Performance Metrics">
  <data key="d5">8.0</data>
  <data key="d6">The compiler within DSP Y optimizes pipelines to maximize specified performance metrics such as accuracy or efficiency."|</data>
  <data key="d7">optimization, automation</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Math Word Problems Reasoning" target="Performance Metrics">
  <data key="d5">6.0</data>
  <data key="d6">The effectiveness of DSPy in solving math word problems is measured by performance improvements over baseline prompting.</data>
  <data key="d7">accuracy, effectiveness</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Multi-hop Retrieval" target="Objects of Study">
  <data key="d5">5.0</data>
  <data key="d6">DSP Y constructs pipelines capable of multi-hop retrieval for complex information gathering.</data>
  <data key="d7">complexity, retrieval</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Complex Question Answering" target="Objects of Study">
  <data key="d5">4.0</data>
  <data key="d6">DSP Y develops pipelines for answering complex questions requiring multi-step inference.</data>
  <data key="d7">reasoning, question answering</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Agent Loops" target="Objects of Study">
  <data key="d5">3.0</data>
  <data key="d6">DSP Y supports the control of iterative agent behaviors within pipelines for reasoning and decision-making.</data>
  <data key="d7">iteration, control</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GPT-3.5" target="Performance Metrics">
  <data key="d5">10.0</data>
  <data key="d6">GPT-3.5's performance improves significantly when using DSPy-optimized pipelines compared to standard prompting.</data>
  <data key="d7">performance enhancement, comparison</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GPT-3.5" target="Objects of Study">
  <data key="d5">10.0</data>
  <data key="d6">GPT-3.5 is a large language model used as a benchmark to evaluate DSP Y pipeline performance."|</data>
  <data key="d7">model evaluation</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GPT-3.5" target="Research Questions/Hypotheses">
  <data key="d5">16.0</data>
  <data key="d6">DSPy programs aim to outperform hand-crafted prompts with smaller LMs like GPT-3.5.&lt;SEP&gt;DSPy programs aim to outperform systems using hand-crafted prompts, even with smaller models like GPT-3.5."|</data>
  <data key="d7">performance, efficiency</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GPT-3.5" target="Model Performance">
  <data key="d5">8.0</data>
  <data key="d6">GPT-3.5 is a high-performing OpenAI model used for advanced language and code tasks."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="GPT-3.5" target="Tools">
  <data key="d5">12.0</data>
  <data key="d6">GPT-3.5 is used for inference and code generation, providing a baseline for model performance comparison."&lt;&gt; "inference, comparison&lt;SEP&gt;GPT-3.5 is used for inference in code generation tasks, providing a benchmark for model performance."&lt;&gt; "inference and comparison</data>
  <data key="d7">6</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="GPT-3.5" target="Evaluation Tool">
  <data key="d5">14.0</data>
  <data key="d6">Used for evaluating language models' performance in the research.&lt;SEP&gt;Utilized for evaluating the performance of language models in the research context.</data>
  <data key="d7">tool, evaluation</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Llama2-13b-Chat" target="Performance Metrics">
  <data key="d5">9.0</data>
  <data key="d6">Llama2-13b-Chat achieves substantial performance gains with DSPy-optimized pipelines.</data>
  <data key="d7">efficiency, effectiveness</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Llama2-13b-Chat" target="Objects of Study">
  <data key="d5">9.0</data>
  <data key="d6">Llama2-13b-Chat is an open-source language model used to assess DSP Y's effectiveness in smaller models."|</data>
  <data key="d7">model evaluation</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Performance Metrics" target="Results">
  <data key="d5">10.0</data>
  <data key="d6">Performance improvements over baseline prompting are quantified using accuracy gains such as over 25%, 65%, etc."|</data>
  <data key="d7">evaluation</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Performance Metrics" target="llama2-34b">
  <data key="d5">7.0</data>
  <data key="d6">Performance metrics are reported for llama2-34b, showing its competitiveness in the task.</data>
  <data key="d7">model performance, comparison</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Performance Metrics" target="Llama2-34b">
  <data key="d5">7.0</data>
  <data key="d6">Performance scores are reported for llama2-34b, showing competitive results with other models.</data>
  <data key="d7">performance, comparison</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Performance Metrics" target="Llama2-70b">
  <data key="d5">6.0</data>
  <data key="d6">Performance scores are reported for llama2-70b, indicating its capabilities in the task.</data>
  <data key="d7">performance, model size</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Performance Metrics" target="Rouge-L and Bleu-1">
  <data key="d5">14.0</data>
  <data key="d6">These metrics quantify the quality of generated answers, with retrieval strategies influencing their scores.</data>
  <data key="d7">evaluation metrics, answer quality</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Performance Metrics" target="Code Generation Effectiveness">
  <data key="d5">10.0</data>
  <data key="d6">New metrics are used to evaluate how well models generate correct and efficient parallel code.</data>
  <data key="d7">evaluation metrics, code quality</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Performance Metrics" target="Evaluation">
  <data key="d5">26.0</data>
  <data key="d6">Evaluation involves using metrics like pass@1 to measure the correctness of generated code."|&gt;"performance measurement, correctness&lt;SEP&gt;Evaluation measures the success of code generation by LLMs using metrics like pass@1, reflecting correctness and efficiency.</data>
  <data key="d7">8&lt;SEP&gt;performance assessment, correctness</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Compiler" target="Text Transformation Graphs">
  <data key="d5">8.0</data>
  <data key="d6">The compiler optimizes text transformation graphs to maximize task-specific performance metrics.</data>
  <data key="d7">optimization, automation</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Compiler" target="Tools">
  <data key="d5">8.0</data>
  <data key="d6">The DSP Y compiler automatically optimizes text transformation graphs for maximum task-specific performance."|</data>
  <data key="d7">optimization, automation</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Compiler" target="Generative AI">
  <data key="d5">8.0</data>
  <data key="d6">Compilers can be used to refine, validate, and optimize AI-generated code, integrating AI suggestions into reliable HPC software."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Text Transformation Graphs" target="Objects of Study">
  <data key="d5">14.0</data>
  <data key="d6">These graphs are structured representations of modular NLP pipelines composed of interconnected modules."|&lt;SEP&gt;These graphs represent structured pipelines composed of modular components for NLP tasks.</data>
  <data key="d7">structure, modularity</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Reasoning Techniques" target="Math Word Problems">
  <data key="d5">13.0</data>
  <data key="d6">DSP Y pipelines employ reasoning modules like Chain of Thought to improve performance on math word problems.&lt;SEP&gt;DSP Y pipelines use reasoning modules to improve performance on math word problem tasks."|</data>
  <data key="d7">problem-solving, reasoning&lt;SEP&gt;reasoning, problem-solving</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Math Word Problems" target="Python Solution">
  <data key="d5">8.0</data>
  <data key="d6">Python code is used as a methodology to solve the counting and sharing problems programmatically."|</data>
  <data key="d7">tools, problem-solving</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Question Answering" target="Objects of Study">
  <data key="d5">6.0</data>
  <data key="d6">DSP Y develops pipelines for complex question answering tasks involving multi-step inference."|</data>
  <data key="d7">task complexity, inference</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Retrieval" target="Objects of Study">
  <data key="d5">5.0</data>
  <data key="d6">DSP Y pipelines can perform complex, multi-hop retrieval tasks to gather relevant information."|</data>
  <data key="d7">information retrieval, complexity</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Retrieval" target="Semantic Parsing">
  <data key="d5">16.0</data>
  <data key="d6">Semantic parsing enhances retrieval by understanding language meaning, supporting more accurate document fetching.&lt;SEP&gt;Semantic parsing enhances retrieval by understanding natural language meaning, enabling more precise document fetching.</data>
  <data key="d7">language understanding, information retrieval</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Retrieval" target="RAG Techniques">
  <data key="d5">18.0</data>
  <data key="d6">RAG techniques integrate retrieval to improve factual accuracy and flexibility in generation.</data>
  <data key="d7">model architecture, factual grounding</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Pipeline" target="Objects of Study">
  <data key="d5">7.0</data>
  <data key="d6">A core structure in DSP Y representing a modular, interconnected sequence of processing steps."|</data>
  <data key="d7">structure, modularity</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Pipeline" target="Lassi">
  <data key="d5">16.0</data>
  <data key="d6">Lassi is an automated pipeline based on large language models for translating scientific codes, improving scientific computing workflows.</data>
  <data key="d7">scientific computing, automation</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Modules" target="Tools">
  <data key="d5">8.0</data>
  <data key="d6">Modules are individual components within DSP Y pipelines that perform specific functions like prompting, finetuning, augmentation, or reasoning."|</data>
  <data key="d7">components, functionality</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Modules" target="Predict">
  <data key="d5">12.0</data>
  <data key="d6">Modules like ChainOfThought are instantiated using Predict to create reusable, task-specific prompting components.</data>
  <data key="d7">modularity, task-specific prompts</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Modules" target="Text Transformation Graph">
  <data key="d5">8.0</data>
  <data key="d6">Modules are the fundamental components that compose the text transformation graph, enabling systematic processing of language models.</data>
  <data key="d7">component composition, modular architecture</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Modules" target="compose and form the Text Transformation Graph">
  <data key="d5">8.0</data>
  <data key="d6">component assembly, modular architecture</data>
  <data key="d7">8</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Performance Improvements" target="Results">
  <data key="d5">10.0</data>
  <data key="d6">DSP Y pipelines significantly outperform traditional prompting approaches, achieving over 25% and 65% accuracy improvements."|</data>
  <data key="d7">performance, effectiveness</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Comparison with Expert-Created Demonstrations" target="Results">
  <data key="d5">9.0</data>
  <data key="d6">DSP Y pipelines with minimal manual demonstrations outperform manually crafted prompt chains, with improvements up to 5–46%."|</data>
  <data key="d7">performance, automation</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Open-Source" target="Applications/Implications">
  <data key="d5">8.0</data>
  <data key="d6">DSP Y is publicly available on GitHub, promoting open research and broader application."|</data>
  <data key="d7">accessibility, community</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Optimization Techniques" target="Analytical Techniques">
  <data key="d5">8.0</data>
  <data key="d6">DSP Y employs algorithms within its compiler to automatically optimize pipeline graphs for maximum performance."|</data>
  <data key="d7">algorithm, automation</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Optimization Techniques" target="Theories/Models">
  <data key="d5">9.0</data>
  <data key="d6">Optimization techniques include reordering, hardware mapping, inlining, and loop unrolling, used to improve performance.</data>
  <data key="d7">performance strategies</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Systematic Approach" target="Theories/Models">
  <data key="d5">9.0</data>
  <data key="d6">DSP Y embodies a systematic methodology replacing manual prompt crafting with modular, learnable components and automated optimization."|</data>
  <data key="d7">methodology, scalability</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompt Engineering" target="Methodologies">
  <data key="d5">7.0</data>
  <data key="d6">DSP Y aims to replace manual prompt engineering with modular, learnable components that can be systematically optimized."|</data>
  <data key="d7">automation, generalization</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompt Engineering" target="Limitations">
  <data key="d5">9.0</data>
  <data key="d6">DSPy addresses prompt engineering challenges by replacing manual prompt templates with modular, automated units.</data>
  <data key="d7">solution, challenge</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompt Engineering" target="Evaluation Metrics">
  <data key="d5">14.0</data>
  <data key="d6">Prompt engineering is used to craft inputs that improve the accuracy and relevance of generated HPC kernels, which are then assessed using specific evaluation metrics." ,&lt;SEP&gt;Prompt engineering is used to optimize the inputs provided to Codex, aiming to improve the quality of generated HPC kernels, which are then evaluated using specific metrics.</data>
  <data key="d7">7&lt;SEP&gt;methodology, optimization</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Prompt Engineering" target="Codex">
  <data key="d5">7.0</data>
  <data key="d6">Prompt engineering guides how users interact with Codex to optimize code suggestions and decision-making outputs.</data>
  <data key="d7">guidance, optimization</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Prompt Engineering" target="Users">
  <data key="d5">8.0</data>
  <data key="d6">Users develop prompts to effectively guide Codex's outputs for tasks like code suggestion and decision support.</data>
  <data key="d7">guidance, optimization</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Multi-stage Pipelines" target="Core Concepts">
  <data key="d5">8.0</data>
  <data key="d6">DSP Y supports multi-stage, multi-module pipelines for complex tasks, enabling decomposition and reasoning."|</data>
  <data key="d7">complexity, modularity</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Task Decomposition" target="Theories/Models">
  <data key="d5">7.0</data>
  <data key="d6">DSP Y facilitates task decomposition into manageable modules, improving reasoning and performance."|</data>
  <data key="d7">divide-and-conquer, modular design</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Task Decomposition" target="Python Script for Arithmetic Problem">
  <data key="d5">18.0</data>
  <data key="d6">The Python script exemplifies how LLMs decompose a word problem into executable code to determine the number of rabbits and chickens, demonstrating task decomposition and automation.</data>
  <data key="d7">problem solving, automation</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Automation" target="Applications/Implications">
  <data key="d5">8.0</data>
  <data key="d6">DSP Y automates pipeline design, optimization, and deployment for scalable NLP solutions."|</data>
  <data key="d7">scalability, efficiency</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Learning" target="Variables">
  <data key="d5">9.0</data>
  <data key="d6">DSP Y modules can learn and adapt their parameters based on demonstrations or feedback to improve performance."|</data>
  <data key="d7">training, adaptation</data>
  <data key="d8">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="layers" target="DSPy">
  <data key="d5">8.0</data>
  <data key="d6">Layers can be modularly composed in DSPy to build complex architectures.</data>
  <data key="d7">system design, modularity</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="layers" target="DSPy programming model">
  <data key="d5">8.0</data>
  <data key="d6">Layers are fundamental components in DSPy, allowing modular composition of complex architectures.</data>
  <data key="d7">modularity, system design</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="model weights" target="DSPy">
  <data key="d5">7.0</data>
  <data key="d6">Model weights are trained within DSPy modules using optimizers, replacing manual tuning.</data>
  <data key="d7">training, adaptability</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="model weights" target="DSPy modules">
  <data key="d5">8.0</data>
  <data key="d6">Model weights are trained within DSPy modules via optimizers, replacing manual tuning and enabling adaptation.</data>
  <data key="d7">training, adaptability</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="string-based prompting techniques" target="DSPy">
  <data key="d5">8.0</data>
  <data key="d6">DSPy translates string prompts like Chain of Thought into declarative modules for flexible task execution.</data>
  <data key="d7">prompt translation, modularity</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="string-based prompting techniques" target="DSPy modules">
  <data key="d5">9.0</data>
  <data key="d6">DSPy translates string prompts like Chain of Thought into declarative modules for flexible task-specific transformations.</data>
  <data key="d7">prompt translation, modularity</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Chain of Thought" target="prompting techniques">
  <data key="d5">18.0</data>
  <data key="d6">Chain of Thought is a complex prompting method that guides models through intermediate reasoning steps.&lt;SEP&gt;Chain of Thought is a prompting method that guides models through intermediate reasoning steps, improving complex reasoning performance."|</data>
  <data key="d7">reasoning, prompting</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ReAct" target="prompting techniques">
  <data key="d5">16.0</data>
  <data key="d6">ReAct combines reasoning and acting prompts to enhance model interaction capabilities.&lt;SEP&gt;ReAct combines reasoning and acting prompts, enabling models to interact with external tools or environments effectively."|</data>
  <data key="d7">multi-modal prompting, interaction</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ReAct" target="Methodology">
  <data key="d5">8.0</data>
  <data key="d6">ReAct is a multi-step agent framework evaluated in the study for tool use in QA.</data>
  <data key="d7">multi-step reasoning, tool use</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="declarative modules" target="DSPy modules">
  <data key="d5">16.0</data>
  <data key="d6">Declarative modules in DSPy serve as task-adaptive components that perform specific text transformations.&lt;SEP&gt;Declarative modules serve as task-adaptive components that perform specific text transformations, forming the building blocks of DSPy pipelines."|</data>
  <data key="d7">component design, task adaptation</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="neural network layers" target="Objects of Study">
  <data key="d5">15.0</data>
  <data key="d6">DSPy modules are analogous to neural network layers, abstracting text transformations.&lt;SEP&gt;DSPy modules are conceptually similar to neural network layers, abstracting text transformations within the pipeline."|</data>
  <data key="d7">system architecture, abstraction</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="bootstrapping demonstrations" target="Methodologies">
  <data key="d5">16.0</data>
  <data key="d6">Modules learn behaviors by bootstrapping demonstrations within the pipeline.&lt;SEP&gt;Modules learn desired behaviors by bootstrapping demonstrations within the pipeline, enabling self-improvement."|</data>
  <data key="d7">learning process, self-improvement</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="PyTorch abstractions" target="Tools">
  <data key="d5">15.0</data>
  <data key="d6">DSPy draws inspiration from PyTorch to design flexible, define-by-run computational graphs for dynamic pipeline construction."|&lt;SEP&gt;DSPy draws inspiration from PyTorch to design flexible, define-by-run computational graphs.</data>
  <data key="d7">software design, flexibility</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="computational graphs" target="Tools">
  <data key="d5">16.0</data>
  <data key="d6">DSPy uses dynamic computational graphs to connect modules and control flow, enabling flexible pipeline configuration."|&lt;SEP&gt;DSPy uses dynamic computational graphs to connect modules and control flow.</data>
  <data key="d7">program execution, flexibility</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy compiler" target="Tools">
  <data key="d5">16.0</data>
  <data key="d6">The DSPy compiler optimizes programs through simulation, self-improvement, and effective prompt/finetuning construction."|&lt;SEP&gt;The compiler optimizes DSPy programs through simulation and self-improvement strategies.</data>
  <data key="d7">optimization, automation</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="teleprompters" target="Methodologies">
  <data key="d5">16.0</data>
  <data key="d6">Teleprompters are strategies that guide how modules learn from data, improving overall system performance.&lt;SEP&gt;Teleprompters are strategies that guide the learning process of modules from data, improving system performance and efficiency."|</data>
  <data key="d7">learning strategies, optimization</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="multi-hop question answering" target="Study Designs">
  <data key="d5">16.0</data>
  <data key="d6">Case studies demonstrate DSPy's application to multi-hop reasoning tasks.&lt;SEP&gt;Case studies demonstrate DSPy’s application to complex reasoning tasks such as multi-hop question answering."|</data>
  <data key="d7">application, reasoning</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="math word problems" target="Study Designs">
  <data key="d5">16.0</data>
  <data key="d6">DSPy is evaluated on solving math word problems, assessing its reasoning capabilities.&lt;SEP&gt;DSPy is evaluated on solving math word problems, showcasing its reasoning and pipeline optimization capabilities."|</data>
  <data key="d7">evaluation, reasoning</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="llama2-13b-chat" target="Research Questions/Hypotheses">
  <data key="d5">16.0</data>
  <data key="d6">DSPy is tested for effectiveness with smaller models like llama2-13b-chat.&lt;SEP&gt;DSPy is tested with smaller models such as llama2-13b-chat to assess effectiveness and efficiency improvements."|</data>
  <data key="d7">model efficiency, performance</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="T5-Large" target="Research Questions/Hypotheses">
  <data key="d5">16.0</data>
  <data key="d6">DSPy enhances program performance and quality with large models like T5-Large."|&lt;SEP&gt;DSPy enhances program quality with models like T5-Large.</data>
  <data key="d7">optimization, performance</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="T5-Large" target="Model">
  <data key="d5">7.0</data>
  <data key="d6">T5-Large is used for finetuning experiments to assess model capacity.</data>
  <data key="d7">finetuning, model capacity</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="T5-Large" target="Objects of Study">
  <data key="d5">7.0</data>
  <data key="d6">A large language model used for finetuning experiments to evaluate capacity.</data>
  <data key="d7">finetuning, evaluation</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="self-improving NLP systems" target="Applications/Implications">
  <data key="d5">8.0</data>
  <data key="d6">Designing NLP pipelines capable of self-bootstrapping and continual improvement using modular, optimized components."|</data>
  <data key="d7">system design, automation</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Radford et al. 2018" target="Instruction Tuning">
  <data key="d5">18.0</data>
  <data key="d6">Radford et al. 2018 discusses instruction tuning as a key mechanism for eliciting sophisticated behavior in foundation models, which is built upon in subsequent work.&lt;SEP&gt;Radford et al. 2018 discusses instruction tuning as a key mechanism for eliciting sophisticated behaviors in foundation models, forming a basis for subsequent prompting strategies and tuning methods.</data>
  <data key="d7">influence, foundational concept</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Brown et al. 2020" target="Foundation Models">
  <data key="d5">16.0</data>
  <data key="d6">Brown et al. 2020 expands on the capabilities and understanding of foundation models, supporting the development of instruction tuning and prompting techniques.&lt;SEP&gt;Brown et al. 2020 expands on the understanding of foundation models, supporting the development of instruction tuning, prompting, and multimodal capabilities.</data>
  <data key="d7">background, foundational research</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Instruction Tuning" target="Prompting">
  <data key="d5">14.0</data>
  <data key="d6">Instruction tuning enhances prompting strategies by fine-tuning models to better respond to specific instructions, thereby improving task performance.&lt;SEP&gt;Instruction tuning enhances prompting techniques by fine-tuning models to better respond to instructions, improving task performance and robustness.</data>
  <data key="d7">method, improvement</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompting" target="Weak Supervision">
  <data key="d5">12.0</data>
  <data key="d6">Prompting can serve as a form of weak supervision by guiding models with prompts instead of explicit labels or heuristics, reducing reliance on task-specific training data.&lt;SEP&gt;Prompting can serve as a form of weak supervision by guiding models with prompts instead of explicit labels or task-specific heuristics.</data>
  <data key="d7">method, supervision</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="In-context Learning" target="Tools">
  <data key="d5">14.0</data>
  <data key="d6">In-context learning leverages tools like retrieval models, multimodal models, APIs, and calculators to support models in performing tasks conditioned on context within prompts.&lt;SEP&gt;In-context learning utilizes tools like retrieval models and APIs to support models in performing tasks based on context provided within prompts.</data>
  <data key="d7">support, technique</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="In-context Learning" target="LLMs">
  <data key="d5">16.0</data>
  <data key="d6">In-context learning enables LLMs to perform tasks based on prompt context without updating model parameters.&lt;SEP&gt;In-context learning refers to LLMs performing tasks based on prompt context without parameter updates.</data>
  <data key="d7">zero-shot, few-shot&lt;SEP&gt;zero-shot, few-shot learning</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tools" target="Retrieval Models">
  <data key="d5">8.0</data>
  <data key="d6">Retrieval models are integrated into language model pipelines to fetch relevant external information, supporting tasks like question answering.</data>
  <data key="d7">component, support</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="Multimodal Foundation Models">
  <data key="d5">8.0</data>
  <data key="d6">Multimodal foundation models combine multiple data modalities to enhance understanding and performance in complex tasks.</data>
  <data key="d7">component, support</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="APIs">
  <data key="d5">7.0</data>
  <data key="d6">APIs provide access to external functionalities and data sources, enabling more versatile language model applications.</data>
  <data key="d7">component, support</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="Calculators">
  <data key="d5">7.0</data>
  <data key="d6">Calculators are used within pipelines to perform mathematical computations, supporting tasks requiring precise calculations.</data>
  <data key="d7">component, support</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="LangChain, Semantic Kernel, LlamaIndex">
  <data key="d5">8.0</data>
  <data key="d6">These toolkits facilitate building, chaining, and managing language model workflows, addressing prompt engineering challenges.</data>
  <data key="d7">support, infrastructure</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="DSPy">
  <data key="d5">16.0</data>
  <data key="d6">A framework for constructing and executing question answering programs.&lt;SEP&gt;DSPy is the framework used for constructing and compiling QA programs in the study.</data>
  <data key="d7">program construction, compilation&lt;SEP&gt;programming, framework</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="ColBERTv2">
  <data key="d5">8.0</data>
  <data key="d6">A retrieval model used to find relevant Wikipedia passages for question answering.</data>
  <data key="d7">retrieval, model</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="Time of My Life">
  <data key="d5">8.0</data>
  <data key="d6">Produced by Michael Lloyd, the song is notable in music history and film.</data>
  <data key="d7">music production, cultural significance</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="Michael Lloyd">
  <data key="d5">8.0</data>
  <data key="d6">A music producer who produced and remixed 'Time of My Life', contributing to its digital release."|&gt;"music production, cultural impact</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="Biocoder">
  <data key="d5">8.0</data>
  <data key="d6">Biocoder is a benchmark for bioinformatics code generation using contextual models, aimed at improving bioinformatics AI applications.</data>
  <data key="d7">bioinformatics, code generation</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Tools" target="billion-scale similarity search with gpus">
  <data key="d5">14.0</data>
  <data key="d6">This tool enables large-scale similarity search using GPUs, supporting efficient retrieval in NLP tasks.&lt;SEP&gt;This tool enables large-scale similarity searches using GPUs, supporting efficient retrieval in high-dimensional data spaces for NLP applications.</data>
  <data key="d7">technology</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Tools" target="Dense passage retrieval for open-domain question answering">
  <data key="d5">16.0</data>
  <data key="d6">This retrieval system supports open-domain QA by efficiently fetching relevant passages.&lt;SEP&gt;This retrieval system supports open-domain question answering by efficiently fetching relevant passages from large corpora.</data>
  <data key="d7">technology</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Tools" target="Adam: A method for stochastic optimization">
  <data key="d5">18.0</data>
  <data key="d6">Adam is an optimization algorithm used to train neural networks efficiently by adapting learning rates and improving convergence.&lt;SEP&gt;Adam optimizes neural network training by adaptively adjusting learning rates, improving convergence.</data>
  <data key="d7">algorithm</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Tools" target="fairseq Toolkit">
  <data key="d5">14.0</data>
  <data key="d6">The fairseq toolkit supports sequence modeling tasks in NLP, facilitating efficient training and experimentation.&lt;SEP&gt;fairseq is an NLP toolkit used for sequence modeling tasks, supporting rapid development and experimentation.</data>
  <data key="d7">tool support, sequence modeling</data>
  <data key="d8">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Tools" target="Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush">
  <data key="d5">1.0</data>
  <data key="d6">Huggingface’s transformers</data>
  <data key="d7">A toolkit for deploying and fine-tuning transformer-based NLP models, enabling state-of-the-art NLP research and applications.</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Tools" target="sumOfMinimumElements">
  <data key="d5">7.0</data>
  <data key="d6">sumOfMinimumElements is an example function used to test code translation accuracy in the experiments.</data>
  <data key="d7">benchmark, code correctness</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="Phind-CodeLlama-V2">
  <data key="d5">14.0</data>
  <data key="d6">Phind-CodeLlama-V2 is a model evaluated against other models for code generation benchmarks."&lt;&gt; "benchmarking&lt;SEP&gt;Phind-CodeLlama-V2 is used as a comparison model for code generation performance."&lt;&gt; "benchmarking</data>
  <data key="d7">7</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="GPT-4">
  <data key="d5">12.0</data>
  <data key="d6">GPT-4 is employed similarly to GPT-3.5 for inference, with a focus on advanced capabilities and alignment."&lt;&gt; "inference and comparison&lt;SEP&gt;GPT-4 is used for inference and code generation, serving as an advanced benchmark in the evaluation."&lt;&gt; "inference, comparison</data>
  <data key="d7">6</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="LLMs (Large Language Models)">
  <data key="d5">16.0</data>
  <data key="d6">Large Language Models generate code outputs, which are then evaluated through the inference process, sampling configurations, and performance metrics."|"&lt;tool application&lt;SEP&gt;Models like GPT-3.5, GPT-4, and open-source models generate code outputs, which are then evaluated using the described inference and sampling configurations, connecting tools to the core evaluation process."|"&lt;tool application</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="HuggingFace library">
  <data key="d5">16.0</data>
  <data key="d6">The library facilitates inference of open-source models, connecting the tool to the methodology of code generation."|"&lt;tool-functionality&lt;SEP&gt;The library facilitates inference of open-source models, enabling code generation experiments, linking the tool to the methodology of code output creation."|"&lt;tool-functionality</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="PyTorch">
  <data key="d5">16.0</data>
  <data key="d6">PyTorch supports model inference for open-source models, enabling code generation workflows."|"&lt;tool-functionality&lt;SEP&gt;PyTorch supports model inference for open-source models, integral to the code generation pipeline, connecting the tool to the methodology of output generation."|"&lt;tool-functionality</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="OpenAI API">
  <data key="d5">16.0</data>
  <data key="d6">The API is used for generating code outputs from GPT models, linking the tool to the inference methodology."|"&lt;tool-application&lt;SEP&gt;The API is used to generate code outputs from GPT models, directly supporting the inference methodology for large language models."|"&lt;tool-application</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="GCC">
  <data key="d5">16.0</data>
  <data key="d6">GCC compiles generated code for correctness and performance testing, linking the compiler to the evaluation methodology."|"&lt;tool-functionality</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="OpenMPI">
  <data key="d5">16.0</data>
  <data key="d6">OpenMPI is used for compiling and executing MPI-based parallel code during evaluation, connecting the tool to the testing process."|"&lt;tool-application&lt;SEP&gt;OpenMPI is used to compile and run MPI-based parallel code during evaluation, supporting distributed execution."|"&lt;tool-application</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="nvcc">
  <data key="d5">16.0</data>
  <data key="d6">nvcc compiles CUDA code for GPU execution during evaluation, linking the compiler to GPU performance assessment."|"&lt;tool-application&lt;SEP&gt;nvcc compiles CUDA code, enabling GPU-accelerated code evaluation, linking the tool to the performance assessment process."|"&lt;tool-application</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="hipcc">
  <data key="d5">16.0</data>
  <data key="d6">hipcc compiles HIP code for GPU execution, integral to the evaluation pipeline for heterogeneous computing."|"&lt;tool-application&lt;SEP&gt;hipcc compiles HIP code for GPU execution, supporting heterogeneous computing evaluation."|"&lt;tool-application</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="Analytical Techniques">
  <data key="d5">16.0</data>
  <data key="d6">Tools are used to implement analytical techniques for data processing and analysis.</data>
  <data key="d7">processing, analysis</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="GPT-3 and Other LLMs">
  <data key="d5">8.0</data>
  <data key="d6">GPT-3 and similar models are tools used to generate code, raising questions about their integration and refinement in HPC workflows."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Tools" target="Kokkos">
  <data key="d5">25.0</data>
  <data key="d6">A software library enabling performance portability for manycore architectures.&lt;SEP&gt;Kokkos provides performance portability across hardware platforms, aligning with PPL's goal of broad hardware support."|&gt;"performance portability</data>
  <data key="d7">7&lt;SEP&gt;software tool</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="Python">
  <data key="d5">6.0</data>
  <data key="d6">Python serves as the foundational language for many computational libraries and tools, including NumPy and others, enabling scientific computing.</data>
  <data key="d7">Objects of Study</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Tools" target="NumPy">
  <data key="d5">5.0</data>
  <data key="d6">NumPy is a core Python library for numerical computations, providing efficient array structures, as detailed in 2011.</data>
  <data key="d7">Tools</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Tools" target="JuliaGPU/AMDGPU">
  <data key="d5">6.0</data>
  <data key="d6">JuliaGPU/AMDGPU is a Julia package that enables GPU programming on AMD hardware, supporting high-performance computing, version 0.4.1.</data>
  <data key="d7">Objects of Study</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Tools" target="LLVM and gcc">
  <data key="d5">14.0</data>
  <data key="d6">Both are low-level compiler infrastructures contrasted with PPL's source-to-source approach, highlighting different code generation paradigms."|&gt;"compiler infrastructure&lt;SEP&gt;These compilers are contrasted with PPL's source-to-source approach, emphasizing different code generation strategies."|&gt;"compiler infrastructure</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="DSL">
  <data key="d5">8.0</data>
  <data key="d6">The custom DSL in PPL enables specific optimization strategies, differentiating it from general-purpose code generators."|&gt;"programming language</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="YASK">
  <data key="d5">12.0</data>
  <data key="d6">YASK generates optimized stencil kernels, similar to PPL's support for stencil pattern optimization."|&gt;"optimization approach&lt;SEP&gt;YASK generates optimized stencil kernels, similar to PPL's support for stencil patterns."|&gt;"optimization approach</data>
  <data key="d7">6</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="Kokkos and Raja">
  <data key="d5">7.0</data>
  <data key="d6">These libraries aim for performance portability, akin to PPL's goal of supporting diverse hardware."|&gt;"performance portability</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="Raja">
  <data key="d5">7.0</data>
  <data key="d6">Raja offers similar multi-platform support, complementing PPL's objectives."|&gt;"performance portability</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="CUDA">
  <data key="d5">8.0</data>
  <data key="d6">CUDA is used as a tool within the code generator to offload computations to GPUs, enabling parallel processing.</data>
  <data key="d7">parallel computing, acceleration</data>
  <data key="d8">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="MPI">
  <data key="d5">7.0</data>
  <data key="d6">MPI facilitates data transfer and synchronization between distributed computing nodes, supporting inter-device communication.</data>
  <data key="d7">distributed systems, data exchange</data>
  <data key="d8">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="Thread Pool">
  <data key="d5">8.0</data>
  <data key="d6">A thread pool manages task execution and synchronization among CPU cores, improving parallel efficiency.</data>
  <data key="d7">task management, concurrency</data>
  <data key="d8">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="Intel Omni-Path 100G">
  <data key="d5">7.0</data>
  <data key="d6">High-speed network fabric enabling fast data transfer between nodes."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="Intel OneAPI C/C++ Compiler 2022.1.0">
  <data key="d5">8.0</data>
  <data key="d6">Software compiler used for code compilation with high optimization levels."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="IntelMPI 2021.6.0">
  <data key="d5">8.0</data>
  <data key="d6">MPI implementation used for parallel process communication."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="CUDA 11.8">
  <data key="d5">8.0</data>
  <data key="d6">GPU programming platform used for developing GPU-accelerated applications."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="Gurobi">
  <data key="d5">8.0</data>
  <data key="d6">Optimization solver that can introduce instabilities due to its stochastic initial solutions, affecting scheduling results."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="OpenCL">
  <data key="d5">16.0</data>
  <data key="d6">OpenCL provides a standardized API for developing portable parallel code for heterogeneous hardware platforms." ,&lt;SEP&gt;OpenCL provides a standardized API for writing portable parallel code for heterogeneous hardware.</data>
  <data key="d7">standardization, API, portability</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="API Calling Scripts">
  <data key="d5">16.0</data>
  <data key="d6">Generated scripts enable LLMs to invoke specific APIs of domain tools for various specialized tasks, facilitating automation and integration.</data>
  <data key="d7">API integration, automation</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tools" target="KnowPrompt">
  <data key="d5">16.0</data>
  <data key="d6">KnowPrompt is a knowledge-aware prompt-tuning framework designed to improve relation extraction and task performance.&lt;SEP&gt;KnowPrompt is a prompt-tuning framework that leverages knowledge for relation extraction, enhancing NLP tasks.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tools" target="AdapterSoup">
  <data key="d5">16.0</data>
  <data key="d6">AdapterSoup is a technique for weight averaging in pretrained models to improve generalization.&lt;SEP&gt;AdapterSoup is a weight averaging technique to improve the generalization of pretrained language models.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tools" target="Promptagator">
  <data key="d5">16.0</data>
  <data key="d6">Promptagator is a retrieval system that uses few-shot examples to improve information retrieval performance.&lt;SEP&gt;Promptagator is a retrieval system that uses few-shot examples to improve information retrieval.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tools" target="ChatGPT plugins">
  <data key="d5">8.0</data>
  <data key="d6">ChatGPT plugins are tools that extend ChatGPT's functionality, enabling integration with external services and APIs.</data>
  <data key="d7">tool, functionality</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tools" target="Tokenization">
  <data key="d5">16.0</data>
  <data key="d6">Tokenization converts code into tokens suitable for input into GPT models, with modifications to improve efficiency for code.&lt;SEP&gt;Tokenization converts source code into tokens for model input, with modifications to improve efficiency, such as handling whitespace effectively.</data>
  <data key="d7">preprocessing, text encoding</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tools" target="risk mitigation">
  <data key="d5">16.0</data>
  <data key="d6">Risk mitigation strategies are implemented to reduce safety hazards associated with code generation systems.</data>
  <data key="d7">safety protocols, technical interventions</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tools" target="Code2seq">
  <data key="d5">14.0</data>
  <data key="d6">A model leveraging ASTs for translating code into natural language descriptions."|</data>
  <data key="d7">Tools, Objects of Study</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tools" target="Latent Predictor Networks">
  <data key="d5">12.0</data>
  <data key="d6">Networks that generate code conditioned on latent modes, aiding in code generation."|</data>
  <data key="d7">Tools, Variables</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tools" target="DeepCoder">
  <data key="d5">14.0</data>
  <data key="d6">A neural model trained to predict functions in source code, guiding program search."|</data>
  <data key="d7">Tools, Variables</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tools" target="CodeBERT">
  <data key="d5">16.0</data>
  <data key="d6">A transformer-based model trained on code and natural language pairs for code search and generation."|&lt;SEP&gt;A transformer-based model trained on code and natural language pairs, effective for code search and generation."|</data>
  <data key="d7">Tools, Objects of Study</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tools" target="PyMT5">
  <data key="d5">14.0</data>
  <data key="d6">A multilingual T5 model trained to translate between code and natural language."|</data>
  <data key="d7">Tools, Objects of Study</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tools" target="">
  <data key="d5">7.0</data>
  <data key="d6">The tools used include natural language processing techniques for entity and relationship extraction.</data>
  <data key="d7">7</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tools" target="Entity Recognition">
  <data key="d5">8.0</data>
  <data key="d6">Entity recognition techniques utilize NLP tools to automatically identify entities in text."|&gt;"tool application, automation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tools" target="Relationship Extraction">
  <data key="d5">8.0</data>
  <data key="d6">Relationship extraction employs NLP tools to find and characterize relationships between recognized entities."|&gt;"tool application, automation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tools" target="Entity Recognition Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Entity recognition techniques are implemented through NLP tools to automate the identification process."|&gt;"tool application, automation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tools" target="Relationship Extraction Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Relationship extraction techniques are facilitated by NLP tools designed to analyze context and co-occurrence."|&gt;"tool application, automation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Prompt Engineering Challenges" target="Limitations">
  <data key="d5">9.0</data>
  <data key="d6">Prompt engineering challenges highlight the difficulties in manual prompt design, which DSPy aims to mitigate through modular, automated pipeline design.</data>
  <data key="d7">problem, motivation</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="Methodologies">
  <data key="d5">17.0</data>
  <data key="d6">DSPy is a framework for optimizing language model pipelines using modular abstractions, signatures, and automated optimization techniques.&lt;SEP&gt;DSPy provides the modular tools and frameworks for implementing compilation, bootstrapping, and ensembling strategies.</data>
  <data key="d7">approach, innovation&lt;SEP&gt;tool application, program optimization</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="Predict">
  <data key="d5">18.0</data>
  <data key="d6">Predict is a core component of DSPy that formats prompts, calls language models, and parses outputs based on signatures, supporting advanced prompting modules.&lt;SEP&gt;Predict is a core module that formats prompts, calls language models, and parses outputs based on signatures, supporting advanced prompting modules like ChainOfThought.</data>
  <data key="d7">core functionality, modular prompting</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="teleprompter">
  <data key="d5">8.0</data>
  <data key="d6">The teleprompter is a component within DSPy that optimizes modules through prompting or finetuning, enhancing the overall pipeline performance.</data>
  <data key="d7">optimization, module enhancement</data>
  <data key="d8">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="Program Modules">
  <data key="d5">9.0</data>
  <data key="d6">DSPy provides the tools to create and compile program modules used in the evaluation pipelines.</data>
  <data key="d7">tool, modular programming</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="LabeledFewShot">
  <data key="d5">15.0</data>
  <data key="d6">LabeledFewShot is a compilation method within DSPy that samples demonstrations to improve reasoning performance.&lt;SEP&gt;LabeledFewShot is a specific compilation approach within DSPy that samples demonstrations to create training exemplars.</data>
  <data key="d7">methodology, demonstration sampling</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="BootstrapFewShotWithRandomSearch">
  <data key="d5">17.0</data>
  <data key="d6">This method uses DSPy to generate demonstration chains and optimize their selection via random search for self-improvement.&lt;SEP&gt;This technique uses DSPy to generate demonstration chains and optimize their selection via random search.</data>
  <data key="d7">self-improvement, demonstration optimization</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="Ensemble">
  <data key="d5">18.0</data>
  <data key="d6">Ensembling combines multiple candidate programs generated by DSPy to enhance overall accuracy.&lt;SEP&gt;Ensembling combines multiple candidate programs generated by DSPy to improve overall accuracy.</data>
  <data key="d7">model ensembling, voting</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="Reflection Program">
  <data key="d5">18.0</data>
  <data key="d6">The Reflection Program is a DSPy module designed to incorporate reflection steps that significantly improve reasoning accuracy.&lt;SEP&gt;The Reflection Program is a DSPy module that enhances reasoning by incorporating reflection steps, leading to improved accuracy.</data>
  <data key="d7">module design, reasoning enhancement</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="Section 4">
  <data key="d5">8.0</data>
  <data key="d6">DSPy is introduced and discussed as the core framework enabling compilation, bootstrapping, and ensembling strategies.</data>
  <data key="d7">tool application, framework overview</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="information extraction">
  <data key="d5">18.0</data>
  <data key="d6">DSPy supports information extraction tasks by enabling rapid development of modular pipelines that leverage pretrained models and tools.&lt;SEP&gt;DSPy supports information extraction tasks by enabling rapid development of pipelines with pretrained models.</data>
  <data key="d7">application, system design</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="synthetic data generation">
  <data key="d5">20.0</data>
  <data key="d6">DSPy facilitates synthetic data creation through flexible pipeline composition, especially useful for low-resource or data-scarce scenarios.&lt;SEP&gt;DSPy facilitates synthetic data generation through modular pipelines, especially for low-resource settings.</data>
  <data key="d7">application, system capability</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="text transformation graphs">
  <data key="d5">22.0</data>
  <data key="d6">DSPy employs text transformation graphs as a core concept for building systematic AI workflows.&lt;SEP&gt;DSPy employs text transformation graphs as a core conceptual tool for building systematic, composable AI workflows.</data>
  <data key="d7">conceptual framework, system design</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="Prompt templates">
  <data key="d5">16.0</data>
  <data key="d6">DSPy aims to automate prompt generation, reducing manual prompt engineering by providing structured, self-bootstrapping mechanisms, thus improving modularity and efficiency.&lt;SEP&gt;DSPy aims to automate prompt generation, reducing reliance on manually crafted templates and enhancing modularity.</data>
  <data key="d7">automation, modularity</data>
  <data key="d8">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Model Selection Techniques" target="Methodologies">
  <data key="d5">8.0</data>
  <data key="d6">Model selection techniques like cross-validation, RL, and hyperparameter tuning are employed within DSPy to improve pipeline performance.</data>
  <data key="d7">techniques, optimization</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="High-level Declarative Signatures" target="Methodologies">
  <data key="d5">8.0</data>
  <data key="d6">DSPy uses high-level declarative signatures to define module behaviors, enabling systematic and flexible pipeline construction.</data>
  <data key="d7">design, abstraction</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy Compiler" target="Methodologies">
  <data key="d5">9.0</data>
  <data key="d6">The DSPy compiler translates high-level pipeline specifications into optimized, modular LM systems, facilitating systematic exploration.</data>
  <data key="d7">implementation, automation</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Empirical Findings" target="Results">
  <data key="d5">8.0</data>
  <data key="d6">Empirical results demonstrate DSPy's effectiveness in building high-quality LM systems without hand-crafted prompts.</data>
  <data key="d7">outcome, validation</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Modular Units" target="Objects of Study">
  <data key="d5">8.0</data>
  <data key="d6">Modular units are components within DSPy that replace prompt strings, enabling flexible pipeline design.</data>
  <data key="d7">components, modularity</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Rich Design Space" target="Applications/Implications">
  <data key="d5">8.0</data>
  <data key="d6">DSPy enables exploration of a broad design space for pipeline configurations, fostering innovation.</data>
  <data key="d7">opportunity, flexibility</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Systematic Exploration" target="Applications/Implications">
  <data key="d5">8.0</data>
  <data key="d6">Systematic exploration allows for thorough testing and optimization of pipeline configurations to improve performance.</data>
  <data key="d7">approach, optimization</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Foundation Models" target="Tool Learning">
  <data key="d5">16.0</data>
  <data key="d6">Research indicates foundation models can learn to utilize external tools effectively, enhancing their capabilities.&lt;SEP&gt;Research indicates that foundation models can learn to utilize external tools, enhancing their task performance.</data>
  <data key="d7">research implication, model capability&lt;SEP&gt;research implication, model enhancement</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Signatures" target="Predict">
  <data key="d5">14.0</data>
  <data key="d6">Signatures define the input/output schema that Predict uses to structure prompts and parse responses, ensuring consistency.&lt;SEP&gt;Signatures define the input/output schema that Predict uses to structure prompts and parse responses.</data>
  <data key="d7">prompt structure, output parsing</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Predict" target="ChainOfThought">
  <data key="d5">16.0</data>
  <data key="d6">The ChainOfThought module uses Predict to implement step-by-step reasoning prompts, enhancing model reasoning capabilities.</data>
  <data key="d7">reasoning enhancement, structured prompting</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Structured Prompting" target="Methodologies">
  <data key="d5">10.0</data>
  <data key="d6">DSPy employs structured prompting to improve model output consistency and reduce brittleness.</data>
  <data key="d7">prompt engineering, reliability</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Bootstrapping" target="Methodologies">
  <data key="d5">8.0</data>
  <data key="d6">Bootstrapping involves generating demonstration examples to bootstrap model performance in DSPy.</data>
  <data key="d7">training data, prompt refinement</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Bootstrapping" target="Evaluation Approach">
  <data key="d5">7.0</data>
  <data key="d6">Bootstrapping is mentioned as a technique to test model stability and performance under dynamic, test-time conditions.</data>
  <data key="d7">resampling, model evaluation</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Self-Improving and Pipeline-Adaptive Prompts" target="Theories/Models">
  <data key="d5">6.0</data>
  <data key="d6">DSPy supports the development of prompts that can adapt and improve over time or across tasks.</data>
  <data key="d7">adaptive prompts, model improvement</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Parameterization" target="Methodologies">
  <data key="d5">2.0</data>
  <data key="d6">DSPy allows the parameterization of prompting techniques, enabling flexible and task-specific prompt configurations.</data>
  <data key="d7">prompt customization, flexibility</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompt-Based Learning" target="Disciplines">
  <data key="d5">1.0</data>
  <data key="d6">Prompt-based learning is an NLP methodology supported by DSPy, involving using prompts to guide language models for various tasks.</data>
  <data key="d7">NLP methodology, task guidance</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Applications/Implications">
  <data key="d5">0.0</data>
  <data key="d6">DSPy provides structured prompt data that can influence or complement model fine-tuning processes.</data>
  <data key="d7">training data, model adaptation</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Parameter Updating">
  <data key="d5">18.0</data>
  <data key="d6">Model fine-tuning directly modifies the internal parameters of an LLM to incorporate domain-specific knowledge.&lt;SEP&gt;Model fine-tuning directly updates the internal parameters of LLMs to incorporate domain-specific knowledge.</data>
  <data key="d7">method, internal model modification</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="White Box">
  <data key="d5">16.0</data>
  <data key="d6">White box models allow full access for fine-tuning the internal parameters to achieve domain specialization.&lt;SEP&gt;White box models permit full access for internal modifications, enabling direct fine-tuning of parameters.</data>
  <data key="d7">model access, internal modification</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Content Ranking">
  <data key="d5">8.0</data>
  <data key="d6">Content ranking guides the fine-tuning process by selecting higher-quality outputs based on reward scores."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Knowledge Expansion">
  <data key="d5">7.0</data>
  <data key="d6">Fine-tuning adjusts model parameters to incorporate new knowledge or improve performance on specific tasks."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Domain Knowledge">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning a model involves adjusting it with domain-specific data to enhance its understanding and performance within that domain."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="HPC source dataset">
  <data key="d5">10.0</data>
  <data key="d6">The HPC source code dataset is used to fine-tune pre-trained language models to specialize them in HPC code understanding.</data>
  <data key="d7">training data, specialization</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Performance datasets">
  <data key="d5">9.0</data>
  <data key="d6">Performance data paired with code are used to further adapt models for performance prediction tasks.</data>
  <data key="d7">performance modeling, training data</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Downstream Tasks">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuned models are evaluated on downstream tasks to measure their effectiveness in code generation, labeling, and performance prediction.</data>
  <data key="d7">model evaluation, task performance</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="answer_exact_match" target="evaluate.answer_exact_match">
  <data key="d5">6.0</data>
  <data key="d6">The function evaluate.answer_exact_match assesses whether the predicted answer exactly matches the correct answer, serving as a measure of correctness.</data>
  <data key="d7">answer evaluation, accuracy</data>
  <data key="d8">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="answer_exact_match" target="context_match">
  <data key="d5">7.0</data>
  <data key="d6">The context_match metric checks if the answer is a substring of the context passage, grounding the answer in the provided text, which supports answer validation.</data>
  <data key="d7">answer grounding, context relevance</data>
  <data key="d8">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="answer_exact_match" target="Evaluation Metric">
  <data key="d5">9.0</data>
  <data key="d6">The answer exact match metric measures the correctness of model answers.</data>
  <data key="d7">accuracy, evaluation</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="answer_exact_match" target="Variables">
  <data key="d5">9.0</data>
  <data key="d6">An evaluation metric measuring exact match accuracy of answers.</data>
  <data key="d7">accuracy, evaluation</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Predict modules" target="candidate generation">
  <data key="d5">9.0</data>
  <data key="d6">Predict modules are used during the candidate generation stage to produce potential outputs or demonstrations that can be selected or refined.</data>
  <data key="d7">candidate creation, module prediction</data>
  <data key="d8">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="candidate generation" target="parameter optimization">
  <data key="d5">10.0</data>
  <data key="d6">Candidate generation provides the set of possible parameters or demonstrations that are then evaluated and selected during the parameter optimization stage.</data>
  <data key="d7">candidate evaluation, hyperparameter tuning</data>
  <data key="d8">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="parameter optimization" target="finetuning">
  <data key="d5">11.0</data>
  <data key="d6">Finetuning involves updating the language model's weights based on demonstrations or data, aiming to improve model performance based on the chosen parameters.</data>
  <data key="d7">model training, weight update</data>
  <data key="d8">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="higher-order program optimization" target="ensemble">
  <data key="d5">12.0</data>
  <data key="d6">Ensembles are a form of higher-order optimization where multiple program copies run in parallel, and their outputs are combined to enhance accuracy and robustness.</data>
  <data key="d7">ensemble methods, parallel execution</data>
  <data key="d8">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Majority Voting" target="Ensemble Technique">
  <data key="d5">8.0</data>
  <data key="d6">Majority voting is used as a custom ensemble decision method to combine multiple model outputs for improved accuracy.</data>
  <data key="d7">ensemble, decision-making</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Evaluation Hypotheses" target="Results">
  <data key="d5">8.0</data>
  <data key="d6">The hypotheses are tested through experiments using DSPy modules, with results indicating significant accuracy improvements.</data>
  <data key="d7">hypotheses testing, experimental results</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GSM8K Dataset" target="Study Populations/Dataset">
  <data key="d5">9.0</data>
  <data key="d6">The dataset is used as the primary benchmark for assessing model performance on math word problems.</data>
  <data key="d7">dataset, evaluation benchmark</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Program Compilation" target="Results">
  <data key="d5">8.0</data>
  <data key="d6">Compiled DSPy programs outperform uncompiled prompts, demonstrating the effectiveness of optimization strategies.</data>
  <data key="d7">optimization, performance improvement</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Results" target="Model Performance">
  <data key="d5">8.0</data>
  <data key="d6">Model performance results are expressed as accuracy percentages, showing the impact of different strategies.</data>
  <data key="d7">performance metrics, outcome</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Results" target="Performance">
  <data key="d5">14.0</data>
  <data key="d6">Model performance varies by problem type and execution model, with larger models generally performing better except on geometric problems where performance declines.&lt;SEP&gt;The performance of HPC-Coder-V2 varies depending on the problem type and execution model, with larger models generally performing better except on geometric problems.</data>
  <data key="d7">performance variation, model size</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Results" target="Model Size and Performance">
  <data key="d5">6.0</data>
  <data key="d6">Smaller HPC-Coder-V2 models like 1.3B are faster and more memory-efficient while still outperforming similar-sized models, whereas larger models excel in certain areas but require more resources.</data>
  <data key="d7">efficiency, resource trade-offs</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Results" target="Trade-offs in Model Deployment">
  <data key="d5">7.0</data>
  <data key="d6">The study discusses the balance between model size, speed, correctness, and resource requirements, emphasizing that smaller models can be highly effective for practical HPC code generation.</data>
  <data key="d7">deployment considerations, efficiency</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Results" target="Model size">
  <data key="d5">6.0</data>
  <data key="d6">Smaller models like HPC-Coder-V2-1.3B are faster and more resource-efficient while maintaining high performance, whereas larger models excel in certain problem types but require more resources.</data>
  <data key="d7">efficiency, resource trade-offs</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Results" target="Performance on geometric problems">
  <data key="d5">6.0</data>
  <data key="d6">Model performance decreases on geometric problems as size increases, indicating a challenge in this problem domain.</data>
  <data key="d7">problem-specific performance</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Results" target="Parallel code correctness">
  <data key="d5">8.0</data>
  <data key="d6">High correctness rates for generated parallel code are critical for HPC applications, with models showing varying success rates.</data>
  <data key="d7">accuracy, reliability</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Results" target="Knowledge-intensive NLP tasks">
  <data key="d5">18.0</data>
  <data key="d6">RAG models outperform existing approaches on these tasks, achieving state-of-the-art results.</data>
  <data key="d7">performance improvement, NLP tasks</data>
  <data key="d8">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Results" target="RAG Models">
  <data key="d5">16.0</data>
  <data key="d6">Achieve state-of-the-art performance on multiple datasets, outperforming previous models that lack retrieval components."|&lt;SEP&gt;RAG models achieve state-of-the-art results on multiple datasets, outperforming previous approaches that rely solely on pre-training objectives.</data>
  <data key="d7">8&lt;SEP&gt;performance improvement</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Results" target="Unconstrained Generation">
  <data key="d5">16.0</data>
  <data key="d6">Unconstrained generation in RAG models produces responses that are more factual, specific, and diverse than baseline models like BART.&lt;SEP&gt;Unconstrained generation in RAG models produces responses that are more factual, specific, and diverse than baseline models like BART."|</data>
  <data key="d7">8&lt;SEP&gt;response quality</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Results" target="Model Performance Metrics">
  <data key="d5">8.0</data>
  <data key="d6">Performance metrics like factuality percentage and diversity scores demonstrate the superiority of retrieval-augmented models over traditional models.</data>
  <data key="d7">evaluation, model effectiveness</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Results" target="Model Comparison">
  <data key="d5">8.0</data>
  <data key="d6">Comparative performance analysis shows RAG models outperform BART in factual accuracy and diversity.</data>
  <data key="d7">model comparison, performance</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Results" target="Retrieval Recall Performance">
  <data key="d5">12.0</data>
  <data key="d6">Higher retrieval recall indicates better access to relevant documents, which can improve downstream task results.</data>
  <data key="d7">performance measure, relevance</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Results" target="Section 7">
  <data key="d5">14.0</data>
  <data key="d6">Section 7 contains the detailed evaluation metrics and results of the experiments.&lt;SEP&gt;Section 7 presents the detailed evaluation metrics, results, and analysis of the experiments conducted.</data>
  <data key="d7">reporting, analysis</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Metrics">
  <data key="d5">17.0</data>
  <data key="d6">Metrics are used to quantify the success of code translation and generation across models.&lt;SEP&gt;Metrics quantify the performance of code translation and generation across different models and execution frameworks.</data>
  <data key="d7">evaluation, performance measurement&lt;SEP&gt;performance measurement, evaluation</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Evidence Types">
  <data key="d5">18.0</data>
  <data key="d6">Results are supported by various evidence types collected and analyzed during the study.</data>
  <data key="d7">data support, proof</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Research Questions/Hypotheses">
  <data key="d5">30.0</data>
  <data key="d6">The findings address the initial research questions or hypotheses posed at the start of the study.&lt;SEP&gt;The results address the research questions regarding the capabilities and limitations of GPT-3 in generating scientific kernels, and the effectiveness of prompt engineering.&lt;SEP&gt;The results address the study’s hypotheses about GPT-3’s capabilities and limitations in generating scientific kernels, and the effectiveness of prompt strategies." ,</data>
  <data key="d7">8&lt;SEP&gt;research objectives, testing&lt;SEP&gt;study outcomes, validation</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Study Populations/Dataset">
  <data key="d5">14.0</data>
  <data key="d6">The results are based on data from specific populations or datasets.</data>
  <data key="d7">data source, sample basis</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Applications/Implications">
  <data key="d5">16.0</data>
  <data key="d6">Findings lead to practical applications or implications in relevant fields.</data>
  <data key="d7">practical use, impact</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Limitations">
  <data key="d5">18.0</data>
  <data key="d6">Limitations affect the interpretation and scope of the results.</data>
  <data key="d7">constraints, weaknesses</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Code Quality">
  <data key="d5">14.0</data>
  <data key="d6">Code quality metrics are used to evaluate the outputs from Copilot across different prompts and languages.&lt;SEP&gt;Metrics for code quality are used to evaluate the outputs from Copilot in various prompts and languages.</data>
  <data key="d7">evaluation, metrics</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Results" target="Security Vulnerability">
  <data key="d5">16.0</data>
  <data key="d6">Studies found relatively high vulnerability rates in code contributed by Copilot, indicating security concerns.&lt;SEP&gt;Studies reveal relatively high vulnerability rates in Copilot's generated code, raising security concerns.</data>
  <data key="d7">security, vulnerabilities</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Results" target="Correctness Evaluation">
  <data key="d5">8.0</data>
  <data key="d6">The assessment of the correctness of AI-generated code snippets based on predefined metrics and benchmarks.</data>
  <data key="d7">evaluation, results</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Results" target="Code Complexity">
  <data key="d5">14.0</data>
  <data key="d6">As code complexity increases, obtaining acceptable results becomes more challenging, indicating a direct relationship between complexity and difficulty."|&lt;SEP&gt;As code complexity increases, obtaining acceptable results becomes more challenging, indicating a direct relationship."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Results" target="Keywords">
  <data key="d5">12.0</data>
  <data key="d6">Using keywords can improve answer proficiency, but effectiveness depends on selecting specific, language-sensitive terms."|&lt;SEP&gt;Using keywords improves answer proficiency, but the effectiveness depends on selecting correct, language-specific, and community-sensitive words."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Results" target="Performance Results">
  <data key="d5">8.0</data>
  <data key="d6">Performance results measure the effectiveness of optimizations, such as execution speedup or resource utilization improvements.</data>
  <data key="d7">evaluation metrics</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="5.953">
  <data key="d5">3.0</data>
  <data key="d6">Represents a numerical measurement or outcome from the experiment."|</data>
  <data key="d7">3</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="0.072">
  <data key="d5">2.0</data>
  <data key="d6">Additional measurement data point related to the experiment."|</data>
  <data key="d7">2</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="0.236">
  <data key="d5">2.0</data>
  <data key="d6">Another data point, possibly a specific parameter or measurement in the study."|</data>
  <data key="d7">2</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="0.913">
  <data key="d5">7.0</data>
  <data key="d6">Performance measurement, likely runtime or efficiency metric for a specific kernel or process."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="1.590">
  <data key="d5">6.0</data>
  <data key="d6">Additional performance metric, possibly execution time or a related measurement."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="21.919">
  <data key="d5">8.0</data>
  <data key="d6">A comprehensive numerical result, potentially total runtime or a key performance indicator."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="0.043">
  <data key="d5">4.0</data>
  <data key="d6">Specific measurement value, possibly an error margin or timing detail."|</data>
  <data key="d7">4</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="0.162">
  <data key="d5">4.0</data>
  <data key="d6">Additional measurement or timing value related to the experiment."|</data>
  <data key="d7">4</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="Speedup">
  <data key="d5">9.0</data>
  <data key="d6">Performance improvement or slowdown metrics comparing code versions for kernels."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="Task-Specific Guidance">
  <data key="d5">7.0</data>
  <data key="d6">Providing guidance improves the relevance and accuracy of LLM outputs in specialized applications.</data>
  <data key="d7">response quality, relevance</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Results" target="Hallucination">
  <data key="d5">8.0</data>
  <data key="d6">Hallucination demonstrates the limitations of LLMs in accurately representing domain knowledge, leading to errors."|&gt;"model accuracy, knowledge gaps</data>
  <data key="d7">8</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Results" target="Zero-shot-CoT">
  <data key="d5">18.0</data>
  <data key="d6">Zero-shot-CoT has achieved significantly better performance on arithmetic, symbolic, and logical reasoning tasks compared to standard zero-shot prompting.</data>
  <data key="d7">performance, reasoning tasks</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Results" target="High-confidence Reasoning">
  <data key="d5">8.0</data>
  <data key="d6">Generating high-confidence, rationale-augmented answers demonstrates improved reasoning in complex or unlabeled tasks."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Results" target="Pass@k">
  <data key="d5">13.0</data>
  <data key="d6">Pass@k metrics are used to evaluate the correctness of solutions generated by models, indicating their effectiveness."|&lt;SEP&gt;Pass@k metrics evaluate the percentage of correct solutions within top k attempts, serving as a performance indicator for models.</data>
  <data key="d7">7&lt;SEP&gt;performance evaluation, metrics</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="Codex">
  <data key="d5">19.0</data>
  <data key="d6">Codex's performance is quantified by pass rates, which decrease exponentially as docstring complexity increases, indicating performance degradation.&lt;SEP&gt;Codex's performance, as measured by pass rates, declines exponentially with increased complexity in the input prompts, highlighting its limitations in handling complex tasks."|&gt;"performance, complexity</data>
  <data key="d7">10&lt;SEP&gt;performance, evaluation</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="Back-Translation Ranking">
  <data key="d5">13.0</data>
  <data key="d6">Back-translation ranking slightly outperforms random ranking but underperforms mean log-probability ranking, with overfitting tendencies.&lt;SEP&gt;Back-translation ranking underperforms mean log-probability ranking but outperforms random ranking, with overfitting tendencies that diminish effectiveness."|&gt;"evaluation methods, overfitting</data>
  <data key="d7">7&lt;SEP&gt;ranking methods, overfitting</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="Synthetic Problems Dataset">
  <data key="d5">19.0</data>
  <data key="d6">As the number of chained components increases, model success rates decrease exponentially, demonstrating performance degradation with increased complexity."|&gt;"complexity, performance&lt;SEP&gt;Performance drops exponentially with increasing chained components in the docstring, illustrating the difficulty of handling complex, multi-step tasks.</data>
  <data key="d7">9&lt;SEP&gt;complexity, performance degradation</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="Metrics for Performance Evaluation">
  <data key="d5">18.0</data>
  <data key="d6">Quantitative metrics reveal that as complexity increases, Codex's success rate declines significantly, demonstrating limitations in handling complex instructions.&lt;SEP&gt;Quantitative metrics show that success rates drop sharply as the complexity of the input increases, indicating challenges in handling complex instructions."|&gt;"evaluation, performance</data>
  <data key="d7">9&lt;SEP&gt;evaluation metrics, performance</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="">
  <data key="d5">9.0</data>
  <data key="d6">The results are the comprehensive list of entities and relationships identified from the document.</data>
  <data key="d7">9</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="Evaluation">
  <data key="d5">8.0</data>
  <data key="d6">Evaluation results provide insights into the model's ability to perform downstream tasks, guiding further development.</data>
  <data key="d7">performance assessment, model validation</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Results" target="Section VI">
  <data key="d5">7.0</data>
  <data key="d6">Results</data>
  <data key="d7">The results section discusses the outcomes of the model evaluations on the downstream tasks, indicating strengths and limitations.</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Results" target="perplexity">
  <data key="d5">20.0</data>
  <data key="d6">Perplexity is monitored during training and validation to assess model performance.&lt;SEP&gt;Perplexity is used as a key performance metric to evaluate how well the models predict dataset tokens during training and validation.</data>
  <data key="d7">model evaluation, performance metrics&lt;SEP&gt;performance evaluation</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Reproducible Runs" target="Study Design">
  <data key="d5">7.0</data>
  <data key="d6">Structured experiments with well-defined programs and datasets ensure reproducibility and reliable comparisons.</data>
  <data key="d7">experimental design, reproducibility</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="BootstrapFewShotWithRandomSearch" target="Methodologies">
  <data key="d5">7.0</data>
  <data key="d6">A bootstrap technique to improve QA program performance via random search.</data>
  <data key="d7">bootstrap, optimization</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GSM8K" target="Evaluation">
  <data key="d5">16.0</data>
  <data key="d6">GSM8K provides the benchmark problems to evaluate the effectiveness of various compilation strategies and models.&lt;SEP&gt;GSM8K serves as the primary dataset to evaluate the effectiveness of different compilation strategies and models.</data>
  <data key="d7">benchmark, performance assessment</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GSM8K" target="Objects of Study">
  <data key="d5">8.0</data>
  <data key="d6">A dataset used to evaluate reasoning and mathematical problem-solving of models like GPT-3.5 and GPT-4.</data>
  <data key="d7">dataset, evaluation</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Zero-Shot" target="Evaluation">
  <data key="d5">7.0</data>
  <data key="d6">Zero-shot evaluation tests models without any demonstration or compilation strategies, serving as a baseline.</data>
  <data key="d7">baseline, performance measurement</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Human Reasoning Chains" target="Training Data">
  <data key="d5">12.0</data>
  <data key="d6">Human reasoning chains are used as additional training data or benchmarks to assess the reasoning capabilities of models.&lt;SEP&gt;Human-generated reasoning chains are used as additional training data or benchmarks to improve model reasoning.</data>
  <data key="d7">data augmentation, benchmarking</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GPT-3.5 and llama2-13b-chat" target="Study Models">
  <data key="d5">16.0</data>
  <data key="d6">These large language models are evaluated across various compilation strategies to measure improvements in solving math word problems.&lt;SEP&gt;These large language models are evaluated with various compilation strategies to measure improvements in math problem solving.</data>
  <data key="d7">model performance, evaluation</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Training and Evaluation" target="zero-shot">
  <data key="d5">7.0</data>
  <data key="d6">Zero-shot serves as the baseline where models attempt to solve problems without any compilation or demonstration enhancements.</data>
  <data key="d7">baseline, performance measurement</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="zero-shot" target="Evaluation">
  <data key="d5">7.0</data>
  <data key="d6">Zero-shot evaluation provides a performance baseline without any demonstrations or compilation strategies.</data>
  <data key="d7">baseline, performance measurement</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Metrics" target="Performance">
  <data key="d5">9.0</data>
  <data key="d6">Model performance is primarily evaluated via pass@k, accuracy, throughput, and resource consumption during code generation tasks.</data>
  <data key="d7">performance metrics, evaluation</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="GPT-4">
  <data key="d5">22.0</data>
  <data key="d6">GPT-4 is a state-of-the-art OpenAI model with superior capabilities in language understanding and code generation."|&lt;SEP&gt;GPT-4's performance is elevated to 92%, but with notes on pretraining data.&lt;SEP&gt;GPT-4's performance surpasses GPT-3.5, as noted in the reports.</data>
  <data key="d7">8&lt;SEP&gt;model improvement, training data&lt;SEP&gt;performance, pretraining</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Model Performance" target="GPT-3.5-turbo">
  <data key="d5">7.0</data>
  <data key="d6">GPT-3.5-turbo's performance is reported at 80.8% for CoT reasoning tasks.</data>
  <data key="d7">performance, benchmark</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Model Performance" target="Data Representation">
  <data key="d5">12.0</data>
  <data key="d6">How code and instruction data are represented affects the model's ability to learn and generate accurate parallel code.</data>
  <data key="d7">data formatting, learning effectiveness</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Training Parameters">
  <data key="d5">10.0</data>
  <data key="d6">Training parameters influence the learning process and final performance of models like HPC-Coder-V2 in parallel code generation.</data>
  <data key="d7">training strategies, model optimization</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Data Representation and Quality">
  <data key="d5">14.0</data>
  <data key="d6">Higher data quality and better data representation improve the ability of code LLMs to learn complex parallel programming tasks.&lt;SEP&gt;Higher quality and well-represented data improve the ability of code LLMs to learn complex parallel programming tasks.</data>
  <data key="d7">data impact, model learning</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Ablation Studies">
  <data key="d5">16.0</data>
  <data key="d6">Ablation studies reveal how different components like data, model size, and prompts affect the ability of code LLMs to generate accurate parallel code.&lt;SEP&gt;Ablation studies reveal how variations in data, model size, and prompts affect the effectiveness of code LLMs in generating parallel code.</data>
  <data key="d7">experimental analysis, model understanding</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Impact of Model Size">
  <data key="d5">14.0</data>
  <data key="d6">Larger models (e.g., 6.7B vs. 1.3B) are expected to have different capacities affecting the effectiveness of fine-tuning and final code generation quality.&lt;SEP&gt;Larger models are hypothesized to influence the effectiveness of fine-tuning and the resulting model's ability to generate accurate parallel code.</data>
  <data key="d7">model size effect, performance&lt;SEP&gt;model size, capability</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Fine-tuning">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning on datasets with varying data amounts and qualities directly impacts the model's ability to generate accurate parallel code.</data>
  <data key="d7">training process, outcome</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Phind-V2">
  <data key="d5">16.0</data>
  <data key="d6">Phind-V2 achieved top performance on the BigCode leaderboard, indicating high effectiveness in code tasks."|&lt;SEP&gt;Phind-V2 was considered the best on the BigCode leaderboard at the time of its release, indicating high performance in code tasks."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Choice of Base Model and Instruction Masking">
  <data key="d5">18.0</data>
  <data key="d6">Fine-tuning base models rather than instruction-tuned models results in better parallel code generation performance, especially for smaller models."|&lt;SEP&gt;Fine-tuning the base models rather than instruct variants leads to better parallel code generation results, especially for smaller models."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Training Data">
  <data key="d5">18.0</data>
  <data key="d6">The quality and amount of training data directly influence the performance of code language models, with more and higher-quality data generally improving results.&lt;SEP&gt;Training on larger, higher-quality datasets enhances model performance, but with diminishing returns as data volume increases.</data>
  <data key="d7">data quality, training impact</data>
  <data key="d8">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Model Size">
  <data key="d5">22.0</data>
  <data key="d6">Increasing model size from 1.3B to 6.7B significantly improves performance, but gains diminish beyond 6.7B, indicating diminishing returns.&lt;SEP&gt;Larger models tend to achieve higher pass@k and BLEU scores, demonstrating the impact of model capacity.&lt;SEP&gt;Larger models tend to perform better in coding tasks, as indicated by the performance scaling with model size.</data>
  <data key="d7">capacity, performance&lt;SEP&gt;scale effects, performance gains&lt;SEP&gt;scaling law, capacity</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="Synthetic Data Sources">
  <data key="d5">10.0</data>
  <data key="d6">Models trained on higher-quality synthetic data, such as Llama-generated data, outperform those trained on lower-quality data like DBRX.</data>
  <data key="d7">data quality, training effectiveness</data>
  <data key="d8">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Benchmark Suite">
  <data key="d5">9.0</data>
  <data key="d6">The ParEval benchmark suite provides a standardized way to evaluate and compare the performance of different code generation models across various problem types.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Knowledge Graphs">
  <data key="d5">9.0</data>
  <data key="d6">Incorporating structured knowledge sources like knowledge graphs can improve model accuracy and reasoning capabilities."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Performance" target="Human-in-the-loop">
  <data key="d5">9.0</data>
  <data key="d6">Human feedback guides the model's learning process, improving accuracy, relevance, and trustworthiness."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Performance" target="Active Learning">
  <data key="d5">8.0</data>
  <data key="d6">Active querying allows models to clarify uncertainties and improve understanding of domain-specific concepts."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Performance" target="AutoML">
  <data key="d5">8.0</data>
  <data key="d6">AutoML automates the process of model selection and tuning, leading to improved efficiency and potentially better performance."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Performance" target="Scaling">
  <data key="d5">7.0</data>
  <data key="d6">Scaling domain-specific training methods is essential to extend capabilities across multiple or complex domains effectively."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Performance" target="Model Generalization">
  <data key="d5">8.0</data>
  <data key="d6">Enhancing generalization improves a model's ability to perform well on unseen or varied data."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Performance" target="Model Adaptation">
  <data key="d5">8.0</data>
  <data key="d6">Effective adaptation techniques help models stay relevant as domains evolve, maintaining performance."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Performance" target="Temperature">
  <data key="d5">13.0</data>
  <data key="d6">Adjusting temperature settings influences the diversity and quality of generated samples, affecting model performance metrics.&lt;SEP&gt;Adjusting temperature settings influences the diversity and quality of generated samples, thereby affecting performance metrics like pass@k.</data>
  <data key="d7">sampling parameters, output diversity</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="Pass@k">
  <data key="d5">9.0</data>
  <data key="d6">Pass@k metrics quantify the success rate of models in solving programming problems within the top k solutions.</data>
  <data key="d7">performance measurement, evaluation</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="HumanEval Dataset">
  <data key="d5">16.0</data>
  <data key="d6">The HumanEval dataset provides a benchmark for evaluating the coding ability of language models across diverse tasks.&lt;SEP&gt;The HumanEval dataset provides a benchmark for measuring the coding ability of language models.</data>
  <data key="d7">benchmarking, evaluation</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="APPS Dataset">
  <data key="d5">14.0</data>
  <data key="d6">The APPS dataset assesses models' ability to perform full-program synthesis, providing a comprehensive evaluation of coding competence.&lt;SEP&gt;The APPS dataset assesses models' ability to solve more complex, full-program synthesis problems.</data>
  <data key="d7">comprehensive testing, real-world relevance</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="Code Generation">
  <data key="d5">16.0</data>
  <data key="d6">Effective code generation is a primary goal of large language models evaluated using metrics like pass@k and BLEU.&lt;SEP&gt;Effective code generation is the primary objective of these models, measured by success metrics like pass@k and BLEU.</data>
  <data key="d7">application, capability assessment</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="pass@k">
  <data key="d5">9.0</data>
  <data key="d6">pass@k quantifies the success rate in solving problems within the top k outputs, serving as a primary evaluation metric.</data>
  <data key="d7">performance metric, success rate</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="Model Comparison">
  <data key="d5">8.0</data>
  <data key="d6">Comparative analysis reveals differences in coding capabilities among models like GPT-Neo, GPT-J, Codex, and Tabnine.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Self-Consistency" target="Theories/Models">
  <data key="d5">8.0</data>
  <data key="d6">Self-Consistency is a reasoning technique that generates multiple reasoning paths and selects the most common answer to improve accuracy.</data>
  <data key="d7">reasoning technique, accuracy improvement</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompting Strategies" target="Methodologies">
  <data key="d5">8.0</data>
  <data key="d6">Different prompting strategies, including manual CoT, automatic CoT, and DSPy modules, are evaluated for their impact on reasoning performance.</data>
  <data key="d7">prompt design, reasoning enhancement</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Comparison with Prior Work" target="Applications/Implications">
  <data key="d5">7.0</data>
  <data key="d6">Results are compared with prior benchmarks to contextualize the improvements and advancements in math reasoning.</data>
  <data key="d7">benchmark comparison, progress assessment</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="13b variant" target="Performance Comparison">
  <data key="d5">13.0</data>
  <data key="d6">The 13b variant of the model is shown to be competitive with larger models despite its smaller size.&lt;SEP&gt;The 13b variant of the model is shown to be competitive with larger models like GPT-4, despite smaller size.</data>
  <data key="d7">efficiency, performance&lt;SEP&gt;model efficiency, performance</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="CoT (Chain of Thought)" target="Model Technique">
  <data key="d5">16.0</data>
  <data key="d6">A reasoning methodology involving step-by-step logical thinking to enhance model performance on complex tasks.&lt;SEP&gt;CoT is used as a reasoning methodology to enhance model reasoning capabilities.</data>
  <data key="d7">reasoning, step-by-step</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GPT-4" target="ParEval benchmark">
  <data key="d5">9.0</data>
  <data key="d6">GPT-4 is evaluated on the ParEval benchmark, with pass@1 scores indicating its effectiveness in solving problems across different parallel execution models.</data>
  <data key="d7">benchmark evaluation, model performance</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="GPT-4" target="Problem Types">
  <data key="d5">7.0</data>
  <data key="d6">GPT-4's performance is measured across the same problem types, highlighting its capabilities in solving diverse computational tasks.</data>
  <data key="d7">performance measurement, capability assessment</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="GPT-4" target="Pass@1">
  <data key="d5">8.0</data>
  <data key="d6">GPT-4's pass@1 score indicates its success rate in solving problems on the first try across different problem types and models.</data>
  <data key="d7">performance evaluation, success rate</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="GPT-4" target="ParEval">
  <data key="d5">18.0</data>
  <data key="d6">GPT-4 is used within the ParEval framework to generate or evaluate code prompts.&lt;SEP&gt;GPT-4 is used within the ParEval framework to generate, evaluate, or assist in code translation tasks.</data>
  <data key="d7">evaluation, code generation&lt;SEP&gt;evaluation, code generation, assistance</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="GPT-4" target="pass@1">
  <data key="d5">18.0</data>
  <data key="d6">GPT-4 achieves the highest pass@1 scores and speedup, indicating its superior ability to generate correct parallel code and translate effectively.&lt;SEP&gt;GPT-4 achieves the highest pass@1 scores and speedup, indicating superior performance in parallel code generation and translation.</data>
  <data key="d7">performance, model capability</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="GPT-4" target="Evaluation Tool">
  <data key="d5">14.0</data>
  <data key="d6">Used for evaluating language models' performance in the research.&lt;SEP&gt;Utilized for evaluating the performance of language models in the research context.</data>
  <data key="d7">tool, evaluation</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="GPT-4" target="OpenAI">
  <data key="d5">34.0</data>
  <data key="d6">GPT-4 is a core AI model developed by OpenAI, serving as the basis for various AI applications and APIs.&lt;SEP&gt;GPT-4 is a core AI model developed by OpenAI, serving as the foundation for APIs, research, and AI applications.&lt;SEP&gt;OpenAI developed GPT-4, a large language model designed for advanced language understanding and generation.</data>
  <data key="d7">language model, AI development&lt;SEP&gt;organization, model development</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="GPT-4" target="Instruction tuning with GPT-4">
  <data key="d5">7.0</data>
  <data key="d6">GPT-4 has been used as a base model for instruction tuning to improve its ability to follow complex instructions.</data>
  <data key="d7">model, methodology</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="HotPotQA" target="Dataset">
  <data key="d5">8.0</data>
  <data key="d6">HotPotQA is used to evaluate multi-hop question answering performance in the study.</data>
  <data key="d7">dataset, question answering</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="HotPotQA" target="Objects of Study">
  <data key="d5">8.0</data>
  <data key="d6">A dataset used to evaluate multi-hop question answering capabilities.</data>
  <data key="d7">dataset, QA</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="HotPotQA" target="answer EM">
  <data key="d5">16.0</data>
  <data key="d6">Answer EM scores are used to compare model performance on HotPotQA, showing how well models produce exact answers.&lt;SEP&gt;Answer EM scores are used to evaluate the exactness of model answers on HotPotQA, reflecting reasoning and retrieval accuracy.</data>
  <data key="d7">performance metric, evaluation</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="HotPotQA" target="answer pair-retrieval accuracy">
  <data key="d5">18.0</data>
  <data key="d6">Pair-retrieval accuracy measures how well models retrieve relevant passage pairs in multi-hop question answering.&lt;SEP&gt;Pair-retrieval accuracy measures the effectiveness of models in retrieving relevant passage pairs in multi-hop QA.</data>
  <data key="d7">evaluation metric, retrieval performance</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ColBERTv2" target="Retrieval Tool">
  <data key="d5">9.0</data>
  <data key="d6">ColBERTv2 is employed to retrieve relevant passages from Wikipedia for QA.</data>
  <data key="d7">retrieval, information search</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="dspy.ReAct" target="Methodologies">
  <data key="d5">8.0</data>
  <data key="d6">A multi-step agent framework for tool use in QA, implemented in DSPy.</data>
  <data key="d7">multi-step reasoning, tool use</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="BasicMultiHop" target="Methodology">
  <data key="d5">8.0</data>
  <data key="d6">A custom multi-hop QA program that iteratively retrieves and processes passages to answer questions.</data>
  <data key="d7">multi-hop reasoning, retrieval</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="BasicMultiHop" target="Methodologies">
  <data key="d5">8.0</data>
  <data key="d6">A custom multi-hop QA program that retrieves passages iteratively to answer complex questions.</data>
  <data key="d7">multi-hop, retrieval</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Zhao et al. (2023b)" target="Study Reports">
  <data key="d5">6.0</data>
  <data key="d6">Provides performance metrics for GPT-3.5-turbo using CoT in 2023.</data>
  <data key="d7">study, performance data</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="OpenAI (2023)" target="Study Reports">
  <data key="d5">6.0</data>
  <data key="d6">Reports GPT-4's performance and pretraining details.</data>
  <data key="d7">model, pretraining</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Wikipedia 2017 Abstracts Dump" target="Spatiotemporal Information">
  <data key="d5">9.0</data>
  <data key="d6">Serves as the knowledge base for retrieval in HotPotQA.</data>
  <data key="d7">knowledge base, retrieval</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="expert human reasoning" target="Yao et al. (2022)">
  <data key="d5">14.0</data>
  <data key="d6">Yao et al. (2022) provide a theoretical basis or context for expert reasoning approaches relevant to this work.&lt;SEP&gt;Yao et al. (2022) provide a theoretical framework or context related to expert reasoning, AI, and retrieval models.</data>
  <data key="d7">theoretical foundation, scholarly reference</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Yao et al. (2022)" target="Prompt 3">
  <data key="d5">12.0</data>
  <data key="d6">Yao et al. (2022) conducted research involving ReAct methodology for reasoning or decision-making in AI systems.&lt;SEP&gt;Yao et al. (2022) conducted research involving ReAct methodology or model in AI or cognitive tasks.</data>
  <data key="d7">study design, methodology</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="compiler" target="multihop t5defined">
  <data key="d5">16.0</data>
  <data key="d6">The compiler implements and evaluates the multihop T5-Large program, demonstrating its reasoning capabilities and performance metrics.&lt;SEP&gt;The compiler implements the multihop T5-Large program, evaluating its performance on reasoning tasks.</data>
  <data key="d7">program implementation, evaluation</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="in-context learning" target="models">
  <data key="d5">20.0</data>
  <data key="d6">In-context learning paradigms like CoT prompting and others are used to enhance models' reasoning abilities by conditioning on example prompts.&lt;SEP&gt;In-context learning paradigms like CoT prompting and others are used to improve reasoning capabilities of models.</data>
  <data key="d7">methodology, performance enhancement</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="synthetic data generation" target="prompt templates">
  <data key="d5">7.0</data>
  <data key="d6">Prompt templates are used to generate diverse and targeted synthetic code data for training.</data>
  <data key="d7">data augmentation, prompt engineering</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Text Transformation Graph" target="Optimizers (Teleprompters)">
  <data key="d5">7.0</data>
  <data key="d6">Optimizers are integrated into the graph to enhance the systematic and reliable operation of language models within the framework.</data>
  <data key="d7">system optimization, reliability enhancement</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Text Transformation Graph" target="Language Models">
  <data key="d5">9.0</data>
  <data key="d6">Language models are leveraged within the modules and optimizers to perform text processing tasks in a systematic and reliable manner.</data>
  <data key="d7">core technology, AI component</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Optimizers (Teleprompters)" target="are integrated into the Text Transformation Graph to enhance its systematic and reliable operation">
  <data key="d5">7.0</data>
  <data key="d6">system enhancement, reliability</data>
  <data key="d7">7</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Research Support" target="Development of the text transformation graph">
  <data key="d5">6.0</data>
  <data key="d6">Funding and support from industry and academic organizations facilitate the research, development, and application of the graph and associated tools.</data>
  <data key="d7">funding, collaboration</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Research Support" target="funds and supports the development of the Text Transformation Graph and related AI research">
  <data key="d5">6.0</data>
  <data key="d6">funding, collaboration</data>
  <data key="d7">6</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Research Support" target="includes organizations such as IBM, Oracle, Virtusa, Cigna Healthcare, Stanford HAI, Facebook, Google, VMware, NSF, and Apple Scholars">
  <data key="d5">5.0</data>
  <data key="d6">collaborative support, funding sources</data>
  <data key="d7">5</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Jacob Devlin" target="Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics">
  <data key="d5">18.0</data>
  <data key="d6">Devlin developed BERT, a foundational NLP model, presented at this conference.&lt;SEP&gt;Devlin developed BERT, a foundational model for language understanding, presented at the conference.</data>
  <data key="d7">model development, NLP impact</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Reiichiro Nakano" target="Long Ouyang">
  <data key="d5">6.0</data>
  <data key="d6">Both are researchers involved in AI and human feedback studies, often collaborating or contributing to related research papers.</data>
  <data key="d7">research collaboration, author contributions</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Jiaxin Huang" target="Self-Improvement">
  <data key="d5">14.0</data>
  <data key="d6">Jiaxin Huang's work suggests large language models can self-improve.</data>
  <data key="d7">self-improvement, models</data>
  <data key="d8">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Scaling language modeling with pathways" target="Methodologies">
  <data key="d5">16.0</data>
  <data key="d6">This methodology involves scaling models using pathways for efficiency and performance gains.&lt;SEP&gt;This methodology involves scaling models using pathways to improve efficiency and performance at large scale.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Limitations" target="Bias and Misinformation">
  <data key="d5">18.0</data>
  <data key="d6">Biases and inaccuracies in external sources like Wikipedia can lead to misinformation, bias amplification, and misuse in generated content.&lt;SEP&gt;Biases and inaccuracies in external sources like Wikipedia pose risks of misinformation and bias propagation.</data>
  <data key="d7">model limitations, societal risks</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Limitations" target="Applications/Implications">
  <data key="d5">12.0</data>
  <data key="d6">The limitations identified influence the practical applications and implications of deploying GPT-3/Codex in HPC and scientific computing contexts.&lt;SEP&gt;The limitations influence how the findings can be applied in practice, affecting the deployment of AI in scientific HPC workflows." ,</data>
  <data key="d7">6&lt;SEP&gt;constraints, impact</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Limitations" target="Metrics for Evaluation">
  <data key="d5">9.0</data>
  <data key="d6">Current limitations highlight the need for expanded metrics and standardized methodologies to assess AI code generation."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Limitations" target="Evaluation Metrics">
  <data key="d5">9.0</data>
  <data key="d6">Current limitations in AI code generation highlight the need for comprehensive metrics and standardized evaluation methods."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Limitations" target="Hotspot Benchmark">
  <data key="d5">6.0</data>
  <data key="d6">Original tiling was not possible in the DSL, leading to code rewriting and potential limitations in parallelization.</data>
  <data key="d7">optimization constraint, code rewriting</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Limitations" target="Open challenges in knowledge updating">
  <data key="d5">7.0</data>
  <data key="d6">Addressing the static nature of training data and knowledge cut-offs remains a key challenge for keeping LLMs current.</data>
  <data key="d7">knowledge update, limitation</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Limitations" target="Resource-Intensive Processes">
  <data key="d5">8.0</data>
  <data key="d6">Re-training and continuous learning require significant computational resources, posing practical limitations."|&gt;"cost, scalability</data>
  <data key="d7">8</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Limitations" target="Large Language Models">
  <data key="d5">6.0</data>
  <data key="d6">The limitations of LLMs impact their ability to consistently generate accurate commands and interpret domain tool outputs effectively.</data>
  <data key="d7">performance constraints, reliability</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Limitations" target="Codex">
  <data key="d5">9.0</data>
  <data key="d6">The model struggles with long chains of operations and variable binding in docstrings, indicating areas for further development.</data>
  <data key="d7">model limitations, challenges in code synthesis</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Limitations" target="Model Development">
  <data key="d5">14.0</data>
  <data key="d6">Limitations include tokenization inefficiencies, dataset size constraints, and the necessity of tuning sampling parameters for optimal results.&lt;SEP&gt;Limitations include tokenization inefficiencies, dataset size constraints, and the need for optimal sampling parameters.</data>
  <data key="d7">challenges, technical constraints</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Limitations" target="model limitations">
  <data key="d5">8.0</data>
  <data key="d6">Challenges such as lower quality of generated docstrings and evaluation difficulties highlight current limitations of the models and methods.</data>
  <data key="d7">model challenges, evaluation issues</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Limitations" target="Broader Impacts and Hazard Analysis">
  <data key="d5">8.0</data>
  <data key="d6">The identified limitations inform the societal and safety hazard analyses, highlighting areas where Codex may pose risks.</data>
  <data key="d7">limitations, safety risks</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Limitations" target="Broader Impacts">
  <data key="d5">8.0</data>
  <data key="d6">The limitations of Codex, including inefficiency and difficulty with complex code, inform broader safety and societal impact assessments."|&gt;"limitations, safety</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Limitations" target="HPC-Coder">
  <data key="d5">6.0</data>
  <data key="d6">Current limitations include reliance on available datasets, potential inaccuracies in performance modeling, and challenges in generalizing across diverse HPC architectures."|</data>
  <data key="d7">limitations, challenges</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Limitations" target="Code Duplication">
  <data key="d5">18.0</data>
  <data key="d6">Code duplication negatively impacts machine learning models by potentially causing overfitting and reducing model effectiveness.</data>
  <data key="d7">limitation, impact</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Large Language Models" target="Code Completion, Summarization, Translation, Lookup">
  <data key="d5">8.0</data>
  <data key="d6">LLMs are used to perform various coding tasks, demonstrating their versatility in software development.</data>
  <data key="d7">task versatility, AI capabilities</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Large Language Models" target="ParEval">
  <data key="d5">9.0</data>
  <data key="d6">LLMs are evaluated using the ParEval benchmark to assess their ability to generate parallel code.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Large Language Models" target="Implications for Software Development">
  <data key="d5">9.0</data>
  <data key="d6">Findings imply that LLMs could significantly aid in developing complex parallel software, impacting productivity and reliability.</data>
  <data key="d7">software engineering, AI assistance</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Large Language Models" target="Societal Questions">
  <data key="d5">6.0</data>
  <data key="d6">The development and deployment of LLMs raise societal questions about AI's role in software development and human-AI collaboration.</data>
  <data key="d7">ethical, societal impact</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Large Language Models" target="Research">
  <data key="d5">6.0</data>
  <data key="d6">Large Language Models are used to automate code generation and explanations, with research in 2022 assessing their usability and effectiveness.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Large Language Models" target="Theories/Models">
  <data key="d5">7.0</data>
  <data key="d6">Large Language Models are AI models trained on extensive text data to generate code and explanations, used in automating programming and educational contexts.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Large Language Models" target="Domain Specialization">
  <data key="d5">18.0</data>
  <data key="d6">Domain specialization techniques are developed to adapt LLMs for specific fields, improving their utility and disruptive potential in those areas."|&lt;"model adaptation, domain focus&lt;SEP&gt;Domain specialization techniques are developed to tailor LLMs for specific domains, improving their applicability and disruptive potential in various fields.</data>
  <data key="d7">9&lt;SEP&gt;model adaptation, domain tailoring</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Natural Language Processing">
  <data key="d5">16.0</data>
  <data key="d6">LLMs are a central technology in NLP, enabling advanced understanding and generation of human language.&lt;SEP&gt;LLMs are a central technology within NLP, enabling advanced language understanding and generation.</data>
  <data key="d7">technology, NLP advancement</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Transformer-based neural network architecture">
  <data key="d5">18.0</data>
  <data key="d6">Transformers form the core architecture of many LLMs, driving their success in modeling language.&lt;SEP&gt;Transformers form the core architecture of many LLMs, enabling their powerful sequence modeling capabilities.</data>
  <data key="d7">model architecture, NLP performance</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Pre-trained Language Models (PLMs)">
  <data key="d5">14.0</data>
  <data key="d6">PLMs are a class of LLMs pretrained on large corpora to facilitate transfer learning across NLP tasks.&lt;SEP&gt;PLMs are a subset of LLMs trained on large corpora to facilitate transfer learning.</data>
  <data key="d7">training methodology, NLP tasks</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Scaling law">
  <data key="d5">12.0</data>
  <data key="d6">The scaling law explains how increasing model size and data improves LLM performance.&lt;SEP&gt;The scaling law explains how increasing model size and data leads to performance improvements in LLMs.</data>
  <data key="d7">model scaling, performance</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Pre-trained Language Models">
  <data key="d5">9.0</data>
  <data key="d6">LLMs are typically based on the architecture and principles of pre-trained language models, serving as their advanced scale and application.</data>
  <data key="d7">model foundation, architecture</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Domain-Specific Tools">
  <data key="d5">18.0</data>
  <data key="d6">LLMs call domain tools to leverage specialized functionalities and knowledge for complex domain-specific tasks, integrating AI language understanding with domain expertise.</data>
  <data key="d7">tool invocation, integration</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Self-instruct Demonstrations">
  <data key="d5">8.0</data>
  <data key="d6">Self-instruct demonstrations are used to train large language models to follow instructions more accurately.</data>
  <data key="d7">instruction following, training data</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Kai-Cheng Yang and Filippo Menczer">
  <data key="d5">16.0</data>
  <data key="d6">They studied the ability of large language models to rate news outlet credibility."|</data>
  <data key="d7">application</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Training">
  <data key="d5">9.0</data>
  <data key="d6">Models like GPT-Neo and Codex are fine-tuned on curated problems to enhance their ability to generate correct solutions."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Large Language Models" target="Modeling Parallel Programs">
  <data key="d5">8.0</data>
  <data key="d6">Large language models are utilized as the foundational technology for HPC-Coder, enabling automation and modeling of complex HPC tasks.</data>
  <data key="d7">technology, foundation</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Large Language Models" target="HPC-Coder">
  <data key="d5">8.0</data>
  <data key="d6">HPC-Coder is built upon large language models that have been fine-tuned on HPC code datasets to enable domain-specific automation and modeling."|</data>
  <data key="d7">technology, foundation</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Large Language Models" target="Data Race Detection Using Large Language Models">
  <data key="d5">18.0</data>
  <data key="d6">This methodology uses large language models to detect data races in concurrent software environments, aiming to improve software reliability.</data>
  <data key="d7">software testing, concurrency, AI application</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Retrieval-Augmented Generation" target="Pre-trained language models">
  <data key="d5">18.0</data>
  <data key="d6">RAG enhances traditional models by integrating external retrieval mechanisms to improve knowledge access and generation.</data>
  <data key="d7">model enhancement, knowledge access</data>
  <data key="d8">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Retrieval-Augmented Generation" target="Explicit non-parametric memory">
  <data key="d5">16.0</data>
  <data key="d6">RAG incorporates external memory to supplement internal knowledge, enabling more accurate and up-to-date responses.</data>
  <data key="d7">memory augmentation, external knowledge</data>
  <data key="d8">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Retrieval-Augmented Generation" target="Neural retriever">
  <data key="d5">16.0</data>
  <data key="d6">The neural retriever is used within RAG to access relevant passages from Wikipedia, facilitating knowledge retrieval.</data>
  <data key="d7">retrieval mechanism, external knowledge access</data>
  <data key="d8">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Retrieval-Augmented Generation" target="Seq2Seq model">
  <data key="d5">14.0</data>
  <data key="d6">The seq2seq model serves as the parametric component of RAG, generating language conditioned on retrieved passages.</data>
  <data key="d7">model architecture, language generation</data>
  <data key="d8">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="LlamaIndex" target="Relevant docs retrieval">
  <data key="d5">8.0</data>
  <data key="d6">LlamaIndex is used to retrieve relevant documents or sources in the research context, supporting applications like chatbots or information retrieval.</data>
  <data key="d7">tools, information retrieval</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="LlamaIndex" target="Prompt 7">
  <data key="d5">8.0</data>
  <data key="d6">LlamaIndex supports relevant document retrieval, assisting applications like document search and chatbots in the research context.</data>
  <data key="d7">tools, information retrieval</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="LlamaIndex" target="Prompt 8">
  <data key="d5">8.0</data>
  <data key="d6">LlamaIndex powers an IRS chatbot, demonstrating its application in automated customer service or AI communication systems.</data>
  <data key="d7">tools, application</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="WebGPT" target="Question-Answering with Human Feedback">
  <data key="d5">16.0</data>
  <data key="d6">WebGPT employs human feedback to improve web-based question-answering performance.</data>
  <data key="d7">feedback loop, system improvement</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="WebGPT" target="arXiv">
  <data key="d5">7.0</data>
  <data key="d6">WebGPT is hosted on arXiv as a preprint, representing research on browser-assisted question-answering systems.</data>
  <data key="d7">publication, research dissemination</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Human Feedback" target="Reward Model">
  <data key="d5">7.0</data>
  <data key="d6">Human feedback provides the data that trains or informs the reward model, enabling it to better capture human preferences.</data>
  <data key="d7">training data, supervision</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="OpenAI" target="OpenAI API">
  <data key="d5">18.0</data>
  <data key="d6">The API provides access to GPT-4 and other models for natural language processing tasks.&lt;SEP&gt;The API provides programmatic access to GPT-4 and other models for natural language processing and AI tasks.</data>
  <data key="d7">API, AI services</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="PyTorch" target="Efficient large scale language modeling with mixtures of experts">
  <data key="d5">16.0</data>
  <data key="d6">PyTorch is a tool often used to implement techniques like mixture of experts for large models.</data>
  <data key="d7">tool support, model implementation</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="PyTorch" target="Adam Paszke">
  <data key="d5">16.0</data>
  <data key="d6">Adam Paszke contributed to PyTorch, a high-performance deep learning library used extensively in AI research.&lt;SEP&gt;Adam Paszke contributed to the development of PyTorch, a deep learning library used in AI research.</data>
  <data key="d7">deep learning library, AI research</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Llama 2" target="Open foundation and fine-tuned chat models">
  <data key="d5">12.0</data>
  <data key="d6">Llama 2 models are part of open foundation models, providing a basis for various applications including chat and code tasks.</data>
  <data key="d7">foundation models, applications</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="GenerateSearchQuery" target="dspy.Signature">
  <data key="d5">16.0</data>
  <data key="d6">The GenerateSearchQuery class is a specific implementation of DSPy's Signature, defining how to transform context and questions into search queries.&lt;SEP&gt;The GenerateSearchQuery class is an implementation of DSPy's Signature, defining how to transform context and questions into search queries.</data>
  <data key="d7">structure, transformation</data>
  <data key="d8">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GenerateSearchQuery" target="dspy.Predict">
  <data key="d5">18.0</data>
  <data key="d6">The Predict module applies the GenerateSearchQuery signature to generate search queries from provided context and questions.</data>
  <data key="d7">prediction, query generation</data>
  <data key="d8">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="dspy.Signature" target="dspy.InputField">
  <data key="d5">14.0</data>
  <data key="d6">Input fields specify the data inputs required by the signature, guiding how data is processed to produce the output.</data>
  <data key="d7">data specification, input processing</data>
  <data key="d8">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Language typology" target="Query generation">
  <data key="d5">12.0</data>
  <data key="d6">Queries are generated based on language typology context to answer specific questions about language classification.</data>
  <data key="d7">contextual, task-specific</data>
  <data key="d8">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompt engineering" target="Prompt templates">
  <data key="d5">29.0</data>
  <data key="d6">Extensive prompt templates are a core part of prompt engineering, providing structured input for language models across various tasks, often involving large, detailed templates.&lt;SEP&gt;Extensive prompt templates are a core part of prompt engineering, providing structured input for language models across various tasks.&lt;SEP&gt;Prompt engineering involves creating and managing structured prompts, which can be very lengthy and complex, especially in existing frameworks like LangChain, leading to challenges in scalability.</data>
  <data key="d7">template design, complexity&lt;SEP&gt;template design, structured prompts</data>
  <data key="d8">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompt templates" target="LangChain">
  <data key="d5">14.0</data>
  <data key="d6">LangChain employs lengthy, task-specific prompt templates for different applications, exemplifying manual prompt engineering with extensive prompt files and templates.&lt;SEP&gt;LangChain uses lengthy, task-specific prompt templates for different applications, exemplifying manual prompt engineering.</data>
  <data key="d7">manual prompt design, task-specific</data>
  <data key="d8">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="LangChain" target="Math word problems (PAL)">
  <data key="d5">7.0</data>
  <data key="d6">LangChain is used as a methodology or tool to handle math word problems in the context of Gao et al.'s research.</data>
  <data key="d7">tools, problem-solving</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="LangChain" target="Prompt 2">
  <data key="d5">7.0</data>
  <data key="d6">LangChain is used to implement AI frameworks for solving math word problems (PAL), indicating its role as a methodology or tool in AI problem-solving.</data>
  <data key="d7">tools, problem-solving</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Gao et al. (2023a)" target="Prompt 1">
  <data key="d5">12.0</data>
  <data key="d6">Gao et al. (2023a) conducted a study involving evidence checking, possibly related to character or textual analysis.&lt;SEP&gt;Gao et al. (2023a) conducted a text-evidence checking study involving characters, possibly analyzing character data or textual evidence.</data>
  <data key="d7">study design, evidence analysis</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Nasal Cycle" target="Core Concepts">
  <data key="d5">18.0</data>
  <data key="d6">The nasal cycle involves alternating congestion and decongestion of nostrils approximately every 2 hours, a biological process to prevent mucus buildup.&lt;SEP&gt;The nasal cycle is a physiological process that involves airflow switching between nostrils approximately every 2 hours, related to mucus buildup prevention.</data>
  <data key="d7">biological process, physiological mechanism</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Little House Books" target="Objects of Study">
  <data key="d5">16.0</data>
  <data key="d6">The Little House books are studied as cultural and literary objects, authored by Laura Ingalls Wilder and published by HarperCollins.</data>
  <data key="d7">literary analysis, cultural study</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Laura Ingalls Wilder" target="Research Questions/Hypotheses">
  <data key="d5">14.0</data>
  <data key="d6">She is the author of the Little House books, which are examined for their literary and cultural significance.</data>
  <data key="d7">author, literary impact</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="HarperCollins" target="Objects of Study">
  <data key="d5">14.0</data>
  <data key="d6">HarperCollins published the Little House books, making it a key object in publishing and literary studies.&lt;SEP&gt;HarperCollins published the Little House books, making it a key object in publishing studies.</data>
  <data key="d7">publisher, publication history</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Stanford Prison Experiment" target="Spatiotemporal Information">
  <data key="d5">16.0</data>
  <data key="d6">The experiment was conducted in Jordan Hall, Stanford University, in 1971, specifically in the basement of Jordan Hall."|&gt;"location, date&lt;SEP&gt;The experiment was conducted in Jordan Hall, Stanford University, in 1971, to study authority and power dynamics.</data>
  <data key="d7">8&lt;SEP&gt;location, date</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Stanford Prison Experiment" target="Objects of Study">
  <data key="d5">8.0</data>
  <data key="d6">The Stanford Prison Experiment is a psychological study examining authority and power dynamics."|&gt;"study focus, psychological research</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Social Work" target="Core Concepts">
  <data key="d5">16.0</data>
  <data key="d6">Social work is rooted in humanism and emerged in the 1880s as a professional discipline focused on social justice and support.&lt;SEP&gt;Social work is rooted in humanism, emerging in the 1880s, focusing on social justice, support, and intervention."|&gt;"discipline, historical roots</data>
  <data key="d7">8&lt;SEP&gt;discipline, historical roots</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Havel-Hakimi Algorithm" target="Theories/Models">
  <data key="d5">16.0</data>
  <data key="d6">The Havel-Hakimi algorithm constructs or verifies simple graphs with a specified degree sequence, based on recursive steps, published in 1955 and 1962."|&gt;"algorithm, graph theory&lt;SEP&gt;The Havel-Hakimi algorithm is a recursive method for constructing or verifying the existence of simple graphs with a given degree sequence, published in 1955 and 1962.</data>
  <data key="d7">8&lt;SEP&gt;algorithm, graph theory</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Kelvin Hopins" target="Research Questions/Hypotheses">
  <data key="d5">16.0</data>
  <data key="d6">Kelvin Hopins was suspended from the Labour Party due to allegations of sexual harassment and misconduct, investigated in 2017."|&gt;"investigation, misconduct allegations&lt;SEP&gt;Kelvin Hopins was suspended from the Labour Party in connection with allegations of sexual harassment and inappropriate behavior, as investigated in 2017.</data>
  <data key="d7">8&lt;SEP&gt;investigation, misconduct</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Characters" target="Prompt 1">
  <data key="d5">7.0</data>
  <data key="d6">Characters are analyzed in the context of text-evidence checking, possibly as part of character analysis or textual evidence validation.</data>
  <data key="d7">objects of study, evidence analysis</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Kelvin Hopkins" target="Labour Party">
  <data key="d5">8.0</data>
  <data key="d6">Kelvin Hopkins was suspended by the Labour Party following allegations of misconduct.</data>
  <data key="d7">organizational response, disciplinary action</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Kelvin Hopkins" target="Ava Etemadzadeh">
  <data key="d5">9.0</data>
  <data key="d6">Ava Etemadzadeh accused Kelvin Hopkins of sexual harassment and inappropriate behavior.</data>
  <data key="d7">accusation, victim</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Kelvin Hopkins" target="Investigation">
  <data key="d5">7.0</data>
  <data key="d6">The investigation was conducted to assess the allegations against Kelvin Hopkins.</data>
  <data key="d7">due process, evidence collection</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Labour Party" target="Investigation">
  <data key="d5">6.0</data>
  <data key="d6">The Labour Party conducted an investigation into Kelvin Hopkins' conduct.</data>
  <data key="d7">internal review, disciplinary process</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Leah" target="Chocolates">
  <data key="d5">14.0</data>
  <data key="d6">Leah is a person who initially has chocolates, involved in a problem about sharing and remaining chocolates.&lt;SEP&gt;Leah is a person who initially possesses chocolates, which are counted in the problem.</data>
  <data key="d7">ownership, initial count&lt;SEP&gt;ownership, initial quantity</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Sister" target="Chocolates">
  <data key="d5">12.0</data>
  <data key="d6">Leah's sister also has chocolates, involved in the total count and consumption scenario.&lt;SEP&gt;Leah's sister also possesses chocolates, involved in the total count and sharing problem.</data>
  <data key="d7">ownership, initial count&lt;SEP&gt;ownership, initial quantity</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Chocolates" target="Total Chocolates">
  <data key="d5">16.0</data>
  <data key="d6">The total chocolates is the sum of Leah's and her sister's chocolates, used as the starting point for calculations.&lt;SEP&gt;Total chocolates are the sum of Leah's and her sister's chocolates, used as a starting point for calculations.</data>
  <data key="d7">summation, initial total</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Chocolates" target="Chocolates Eaten">
  <data key="d5">8.0</data>
  <data key="d6">Chocolates eaten are subtracted from total to find remaining chocolates.</data>
  <data key="d7">subtraction, remaining amount</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Chocolates" target="Chocolates Left">
  <data key="d5">8.0</data>
  <data key="d6">Remaining chocolates are calculated by subtracting chocolates eaten from total chocolates.</data>
  <data key="d7">arithmetic, remaining count</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Total Chocolates" target="Chocolates Left">
  <data key="d5">8.0</data>
  <data key="d6">Total chocolates minus eaten chocolates equals the remaining chocolates.</data>
  <data key="d7">arithmetic operation, remaining count</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Chocolates Eaten" target="Chocolates Left">
  <data key="d5">9.0</data>
  <data key="d6">The chocolates eaten are subtracted from the total to find remaining chocolates.</data>
  <data key="d7">subtraction, remaining quantity</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Parking Lot" target="Total Cars">
  <data key="d5">8.0</data>
  <data key="d6">Initial cars plus arriving cars determine total cars in the parking lot.</data>
  <data key="d7">addition, total calculation</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Cars Initial" target="Total Cars">
  <data key="d5">14.0</data>
  <data key="d6">Initial number of cars in the parking lot contributes to the total after arrivals.&lt;SEP&gt;Initial number of cars in the parking lot contributes to total after new cars arrive.</data>
  <data key="d7">initial count, total calculation&lt;SEP&gt;initial count, total count</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Cars Arrived" target="Total Cars">
  <data key="d5">16.0</data>
  <data key="d6">Number of arriving cars is added to the initial cars to find total.&lt;SEP&gt;Number of cars arriving is added to initial cars to get total cars.</data>
  <data key="d7">addition, total count</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Total Cars" target="Cars in Parking Lot">
  <data key="d5">8.0</data>
  <data key="d6">Initial cars plus new arrivals determine total cars in the parking lot.</data>
  <data key="d7">addition, total count</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Trees in Grove" target="Trees Added">
  <data key="d5">32.0</data>
  <data key="d6">Number of trees added is the difference between final and initial counts.&lt;SEP&gt;Number of trees added is the difference between trees after and initial trees.&lt;SEP&gt;Number of trees planted is the difference between final and initial counts.&lt;SEP&gt;The number of trees planted is calculated by subtracting initial trees from the total after planting.</data>
  <data key="d7">subtraction, planting activity&lt;SEP&gt;subtraction, planting result</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Trees in Grove" target="Trees After">
  <data key="d5">16.0</data>
  <data key="d6">Number of trees after planting, used to calculate how many were added.&lt;SEP&gt;The final number of trees after planting is used to determine how many were added.</data>
  <data key="d7">difference, activity outcome&lt;SEP&gt;difference, planting activity</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Problem-solving Approach" target="Using code to model and solve real-world counting problems">
  <data key="d5">8.0</data>
  <data key="d6">methodology, computational problem solving</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Rebel Without a Cause" target="Elia Kazan">
  <data key="d5">16.0</data>
  <data key="d6">Elia Kazan directed the film Rebel Without a Cause, making it a key part of his filmography and American cinema history.&lt;SEP&gt;Elia Kazan directed the film Rebel Without a Cause, making it a significant part of his filmography and American cinema history.</data>
  <data key="d7">film direction, influence</data>
  <data key="d8">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Arthur’s Magazine" target="First for Women">
  <data key="d5">14.0</data>
  <data key="d6">Arthur’s Magazine was published earlier (1844-1846) than First for Women (started in 1989), indicating chronological precedence and historical context.&lt;SEP&gt;Arthur’s Magazine was published earlier (1844-1846) than First for Women (started in 1989), indicating the chronological precedence of the literary periodical.</data>
  <data key="d7">publication history, timeline</data>
  <data key="d8">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Pavel Urysohn" target="Leonid Levin">
  <data key="d5">12.0</data>
  <data key="d6">Both Pavel Urysohn and Leonid Levin are distinguished mathematicians, with Urysohn contributing to dimension theory and Levin to computational complexity, representing different areas of mathematical research in the Soviet and American scientific communities.&lt;SEP&gt;Both Pavel Urysohn and Leonid Levin are notable mathematicians, with Urysohn contributing to dimension theory and Levin to computational complexity, representing different areas of mathematical research in the Soviet and American contexts.</data>
  <data key="d7">mathematical contributions, disciplines&lt;SEP&gt;mathematical disciplines, scientific contributions</data>
  <data key="d8">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Ukrainian People" target="Resilience">
  <data key="d5">24.0</data>
  <data key="d6">The Ukrainian people's repeated resistance over 30 years exemplifies their resilience and refusal to accept regression in their sovereignty and independence.</data>
  <data key="d7">national sovereignty, resilience</data>
  <data key="d8">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="COVID-19" target="Societal Reflection">
  <data key="d5">14.0</data>
  <data key="d6">The pandemic has prompted a societal shift to see COVID-19 beyond partisan lines, emphasizing unity and collective responsibility.</data>
  <data key="d7">public health, societal unity</data>
  <data key="d8">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="COVID-19" target="Unity">
  <data key="d5">7.0</data>
  <data key="d6">The pandemic has led to a societal shift towards seeing COVID-19 as a shared challenge, fostering unity and collective action.</data>
  <data key="d7">public health, societal unity</data>
  <data key="d8">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Russian Invasion of Ukraine" target="US Sanctions">
  <data key="d5">18.0</data>
  <data key="d6">Sanctions are a response to Russia's invasion, aimed at exerting economic pressure and supporting Ukraine.</data>
  <data key="d7">geopolitical response, economic pressure</data>
  <data key="d8">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Russian Invasion of Ukraine" target="US Policy and Leadership">
  <data key="d5">9.0</data>
  <data key="d6">The US responds to the invasion with sanctions and strategic support, demonstrating leadership in global stability and geopolitics.</data>
  <data key="d7">geopolitical strategy, leadership</data>
  <data key="d8">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Pay attention to use only the column names you can see in the tables below" target="be careful to not query for columns that do not exist">
  <data key="d5">8.0</data>
  <data key="d6">The instruction emphasizes careful attention to schema details to avoid errors in SQL queries.</data>
  <data key="d7">guidance, schema awareness</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="pay attention to which column is in which table" target="use the correct column-table associations">
  <data key="d5">7.0</data>
  <data key="d6">The reminder aims to ensure correct referencing of columns within their respective tables.</data>
  <data key="d7">schema accuracy, query correctness</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="use today() function to get the current date" target="apply date functions for dynamic date retrieval">
  <data key="d5">6.0</data>
  <data key="d6">The instruction suggests using the today() function for date-related queries, indicating its importance in the process.</data>
  <data key="d7">date functions, dynamic queries</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ORDER BY clause should always be after WHERE clause" target="correct SQL syntax order">
  <data key="d5">9.0</data>
  <data key="d6">This rule clarifies the proper sequence of SQL clauses to ensure valid queries.</data>
  <data key="d7">SQL syntax, query structure</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DO NOT add semicolon to the end of SQL" target="omit semicolon at query end">
  <data key="d5">5.0</data>
  <data key="d6">This directive specifies formatting rules for the SQL statements, emphasizing omission of semicolons.</data>
  <data key="d7">query formatting, syntax rules</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="pay attention to the comment in table schema" target="schema comments inform correct query construction">
  <data key="d5">4.0</data>
  <data key="d6">The advice highlights the importance of schema comments for accurate understanding of table structures.</data>
  <data key="d7">schema interpretation, query accuracy</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="the question involves 'today'" target="use date functions in the query">
  <data key="d5">3.0</data>
  <data key="d6">The mention of 'today' in the question indicates the need to incorporate date functions like today() in the SQL query.</data>
  <data key="d7">date functions, question context</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="column names" target="table references">
  <data key="d5">7.0</data>
  <data key="d6">The list of column names guides the correct referencing of columns within their respective tables to avoid errors.</data>
  <data key="d7">schema adherence, query correctness</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="tables" target="database structure">
  <data key="d5">6.0</data>
  <data key="d6">The tables represent different entities within the database schema, essential for understanding data relationships.</data>
  <data key="d7">schema structure, data modeling</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="schema comments" target="guidance for query construction">
  <data key="d5">8.0</data>
  <data key="d6">Schema comments provide additional context or instructions crucial for accurately constructing queries based on schema details.</data>
  <data key="d7">schema guidance, query accuracy</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="current date" target="date functions">
  <data key="d5">5.0</data>
  <data key="d6">Using the today() function provides the current date for date-dependent queries, aligning with the question involving 'today'.</data>
  <data key="d7">date functions, dynamic queries</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="SQL syntax rules" target="query structure">
  <data key="d5">4.0</data>
  <data key="d6">Proper placement of ORDER BY after WHERE ensures valid SQL syntax, as instructed.</data>
  <data key="d7">syntax correctness, query structure</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="semicolons in SQL" target="query formatting">
  <data key="d5">3.0</data>
  <data key="d6">Omitting semicolons at the end of SQL statements adheres to the specified formatting rules.</data>
  <data key="d7">query formatting, syntax rules</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="question involving 'today'" target="use date functions in the query">
  <data key="d5">9.0</data>
  <data key="d6">The question's mention of 'today' necessitates the use of date functions like today() in the SQL query to retrieve current date information.</data>
  <data key="d7">date usage, query relevance</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="question involving 'today'" target="use date functions">
  <data key="d5">2.0</data>
  <data key="d6">The explicit mention of 'today' in the question indicates the need to incorporate date functions like today() into the SQL query.</data>
  <data key="d7">question context, date functions</data>
  <data key="d8">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ParameterLM" target="Prediction">
  <data key="d5">7.0</data>
  <data key="d6">The ParameterLM is used within the Prediction object to generate model outputs based on the input signature and demonstrations.</data>
  <data key="d7">usage</data>
  <data key="d8">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ParameterLM" target="get_the_right_lm">
  <data key="d5">7.0</data>
  <data key="d6">Retrieves the appropriate language model to be used for prediction tasks.</data>
  <data key="d7">selection</data>
  <data key="d8">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ParameterDemonstrations" target="Prediction">
  <data key="d5">6.0</data>
  <data key="d6">Demonstrations are used to guide the ParameterLM during prediction, influencing the generated outputs.</data>
  <data key="d7">guidance</data>
  <data key="d8">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="forward" target="Prediction">
  <data key="d5">8.0</data>
  <data key="d6">The forward method executes the ParameterLM with given inputs to produce a prediction.</data>
  <data key="d7">execution</data>
  <data key="d8">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="get_the_right_signature" target="Methodology">
  <data key="d5">6.0</data>
  <data key="d6">Obtains the correct input/output signature for the model based on context.</data>
  <data key="d7">configuration</data>
  <data key="d8">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="get_the_right_demonstrations" target="Methodology">
  <data key="d5">6.0</data>
  <data key="d6">Selects suitable demonstrations to be used as prompts for the model based on current context.</data>
  <data key="d7">selection</data>
  <data key="d8">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="predictor1" target="all_demos">
  <data key="d5">16.0</data>
  <data key="d6">predictor1 provides the collection of demonstrations stored in all_demos for evaluation and selection.</data>
  <data key="d7">data sourcing, demonstration retrieval</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="all_demos" target="demo_index">
  <data key="d5">18.0</data>
  <data key="d6">demo_index selects a specific demonstration from all_demos for evaluation, based on a suggested index.</data>
  <data key="d7">demonstration selection, hyperparameter tuning</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="evaluate_program" target="score">
  <data key="d5">20.0</data>
  <data key="d6">The evaluate_program function computes a performance score for the candidate program, which is then stored in score.</data>
  <data key="d7">evaluation process, performance measurement</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="candidate_program" target="trial.set_user_attr">
  <data key="d5">16.0</data>
  <data key="d6">The candidate program is stored as a user attribute in the current trial for tracking and analysis.</data>
  <data key="d7">trial tracking, attribute storage</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="self.valset" target="compile">
  <data key="d5">20.0</data>
  <data key="d6">The compile method assigns the validation set, defaulting to trainset if none is provided, for validation purposes.</data>
  <data key="d7">validation setup, data assignment</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="compile" target="self.trainset">
  <data key="d5">18.0</data>
  <data key="d6">The compile method assigns the trainset to the training environment, preparing models for training or evaluation.</data>
  <data key="d7">training setup, data assignment</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="BootstrapFewshot" target="tp">
  <data key="d5">22.0</data>
  <data key="d6">The BootstrapFewshot instance (tp) is used to compile a pool of demonstrations for training.</data>
  <data key="d7">data augmentation, demonstration pool creation</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="optimize_with_optuna" target="best_program">
  <data key="d5">24.0</data>
  <data key="d6">The optimization process yields the best program based on the evaluation scores, stored in best_program.</data>
  <data key="d7">optimization, program selection</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="print" target="'Best score:'">
  <data key="d5">26.0</data>
  <data key="d6">Outputs the highest score achieved by the selected program for review.</data>
  <data key="d7">reporting, result display</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="print" target="'Best program:'">
  <data key="d5">28.0</data>
  <data key="d6">Outputs the details of the best program identified during optimization.</data>
  <data key="d7">reporting, result display</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Search Query" target="Context">
  <data key="d5">7.0</data>
  <data key="d6">The search query is generated based on the context and question, using reasoning to formulate relevant information retrieval questions."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Twilight (novel series)" target="The Dark Heroine">
  <data key="d5">7.0</data>
  <data key="d6">Both are vampire-themed fantasy romance novels, illustrating thematic similarities and genre overlap."|&lt;SEP&gt;Both are vampire-themed fantasy romance novels, representing related literary genres and themes."|</data>
  <data key="d7">3&lt;SEP&gt;4</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Twilight (novel series)" target="Harper Connelly Mysteries">
  <data key="d5">8.0</data>
  <data key="d6">Both are literary series within the fantasy genre, representing objects of literary analysis and genre categorization."|&lt;SEP&gt;Both are novel series within the fantasy and mystery genres, respectively, and serve as objects of study in genre analysis."|</data>
  <data key="d7">4</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Harper Connelly Mysteries" target="The Dark Heroine">
  <data key="d5">4.0</data>
  <data key="d6">Both are fantasy novels involving supernatural themes, serving as objects of genre comparison."|</data>
  <data key="d7">4</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Victorians" target="The Victorian">
  <data key="d5">5.0</data>
  <data key="d6">The series 'The Victorians - Their Story In Pictures' focuses on Victorian art and culture, which are part of the broader Victorian era."|</data>
  <data key="d7">5</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Victorians" target="Jeremy Paxman">
  <data key="d5">6.0</data>
  <data key="d6">Jeremy Paxman is the presenter or creator associated with the Victorian documentary series, relevant to historical context."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Victorians" target="The Victorians - Their Story In Pictures">
  <data key="d5">5.0</data>
  <data key="d6">The documentary series focuses on Victorian art and culture, which are objects of study about the Victorian era."|</data>
  <data key="d7">5</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Jeremy Paxman" target="The Victorians - Their Story In Pictures">
  <data key="d5">12.0</data>
  <data key="d6">Jeremy Paxman is associated with the documentary series, either as presenter or producer, linking him to the object of study."|&lt;SEP&gt;The series is associated with Jeremy Paxman, who may have contributed to its narration or production."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Jeremy Paxman" target="Year of Jeremy Paxman's Birth">
  <data key="d5">7.0</data>
  <data key="d6">Knowing Jeremy Paxman's birth year helps contextualize his role and the historical framing of the Victorian series."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Jeremy Paxman" target="search query">
  <data key="d5">8.0</data>
  <data key="d6">The search query involves Jeremy Paxman’s birth year, connecting the context, the figure, and the research question."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="search query" target="context">
  <data key="d5">8.0</data>
  <data key="d6">The search query is generated based on the context and reasoning process, linking the information in the context to the formulated question."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Objects of Study" target="Time of My Life">
  <data key="d5">8.0</data>
  <data key="d6">A song from the film Dirty Dancing, produced by Michael Lloyd, notable in music history."|&gt;"music, film</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Objects of Study" target="Deepseek-coder">
  <data key="d5">8.0</data>
  <data key="d6">Deepseek-coder is a large language model focused on code intelligence, aiming to advance code understanding and generation capabilities.</data>
  <data key="d7">code intelligence, AI models</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Objects of Study" target="OpenMP, MPI, MPI+OpenMP, Kokkos, CUDA, HIP">
  <data key="d5">10.0</data>
  <data key="d6">These execution models are the focus of the translation experiments, testing the model's ability to convert code between them.</data>
  <data key="d7">code translation, performance assessment</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="OpenMP">
  <data key="d5">10.0</data>
  <data key="d6">OpenMP is an execution model used as an object of study to assess code generation and translation capabilities.</data>
  <data key="d7">model evaluation, code generation</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="MPI">
  <data key="d5">10.0</data>
  <data key="d6">MPI is an execution model evaluated for code translation and generation performance.</data>
  <data key="d7">model evaluation, code translation</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="MPI+OpenMP">
  <data key="d5">10.0</data>
  <data key="d6">MPI+OpenMP is a combined execution model evaluated for code translation effectiveness.</data>
  <data key="d7">model evaluation, translation capability</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="Kokkos">
  <data key="d5">9.0</data>
  <data key="d6">Kokkos is evaluated for its support in generating portable parallel code.</data>
  <data key="d7">code generation, portability evaluation</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="CUDA">
  <data key="d5">9.0</data>
  <data key="d6">CUDA is assessed for code translation and generation by language models.</data>
  <data key="d7">parallel code, translation performance</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="HIP">
  <data key="d5">9.0</data>
  <data key="d6">HIP is evaluated for its support in code translation tasks.</data>
  <data key="d7">parallel code, translation capability</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="sumOfMinimumElements">
  <data key="d5">8.0</data>
  <data key="d6">sumOfMinimumElements is used as an example function to test code correctness in translation tasks.</data>
  <data key="d7">benchmark, correctness testing</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="StarCoderBase">
  <data key="d5">15.0</data>
  <data key="d6">StarCoderBase is a tool used in experiments to generate code and evaluate performance."&lt;&gt; "used for code generation&lt;SEP&gt;StarCoderBase is part of the dataset and tools used for code generation experiments."&lt;&gt; "used in training and evaluation</data>
  <data key="d7">7&lt;SEP&gt;8</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="training dataset">
  <data key="d5">8.0</data>
  <data key="d6">The large datasets, including The Stack and code corpora, are used to train the models."&lt;&gt; "training data source</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="Variables">
  <data key="d5">12.0</data>
  <data key="d6">Variables are specific attributes or factors related to the objects of study that are measured or manipulated.</data>
  <data key="d7">measurement, manipulation</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="Spatiotemporal Information">
  <data key="d5">14.0</data>
  <data key="d6">Spatiotemporal data describe the location and timing related to the objects of study.</data>
  <data key="d7">geospatial, temporal context</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="SantaCoder">
  <data key="d5">16.0</data>
  <data key="d6">A neural code generation model emphasizing modest goals.&lt;SEP&gt;A neural code generation model with modest goals, emphasizing practical performance.</data>
  <data key="d7">model, focus</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="MultiPL-E">
  <data key="d5">16.0</data>
  <data key="d6">A benchmark for evaluating neural code generation across languages.&lt;SEP&gt;A benchmark suite designed to evaluate neural code generation models across multiple programming languages.</data>
  <data key="d7">benchmark, evaluation</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="Parallel Programming Models">
  <data key="d5">24.0</data>
  <data key="d6">Models like OpenMP, MPI, CUDA, and others used to generate prompts for code evaluation.&lt;SEP&gt;Models such as OpenMP, MPI, CUDA, and others are used to evaluate Copilot's ability to generate relevant parallel code in different languages.&lt;SEP&gt;The study evaluates Copilot's ability to generate code for different parallel programming models across languages.</data>
  <data key="d7">application, evaluation&lt;SEP&gt;models, evaluation</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Objects of Study" target="Language">
  <data key="d5">8.0</data>
  <data key="d6">The specific programming languages used in the study, including C++, Fortran, Python, and Julia.</data>
  <data key="d7">programming languages, evaluation</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Objects of Study" target="JuliaGPU/AMDGPU">
  <data key="d5">7.0</data>
  <data key="d6">JuliaGPU/AMDGPU is a Julia package enabling GPU programming for AMD hardware, supporting high-performance computing.</data>
  <data key="d7">Tools</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Objects of Study" target="C++">
  <data key="d5">4.0</data>
  <data key="d6">C++ is a programming language used for high-performance applications, authored by Bjarne Stroustrup in 2013.</data>
  <data key="d7">Objects of Study</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Objects of Study" target="GitHub Copilot">
  <data key="d5">9.0</data>
  <data key="d6">An AI-powered code assistant that suggests code snippets, with security evaluations conducted in 2022.</data>
  <data key="d7">Results</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Objects of Study" target="Julia">
  <data key="d5">5.0</data>
  <data key="d6">Julia is a programming language used in scientific and GPU computing, supporting packages like JuliaGPU/AMDGPU.</data>
  <data key="d7">Objects of Study</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Objects of Study" target="James">
  <data key="d5">5.0</data>
  <data key="d6">James is included as an author in 2022 research, indicating involvement in AI or scientific computing studies.</data>
  <data key="d7">Objects of Study</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Objects of Study" target="LULESH Proxy-App">
  <data key="d5">14.0</data>
  <data key="d6">LULESH is used as a benchmark application to evaluate the scalability and performance of the PPL."|&gt;"benchmark application</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Algorithm">
  <data key="d5">8.0</data>
  <data key="d6">Algorithms are formal procedures or formulas implemented in parallel patterns within the PPL framework to solve computational problems.</data>
  <data key="d7">algorithm implementation</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Hardware Targets">
  <data key="d5">7.0</data>
  <data key="d6">Hardware targets specify the computing devices (CPUs, GPUs, clusters) for which code is generated and optimized.</data>
  <data key="d7">hardware specification</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="GPU">
  <data key="d5">8.0</data>
  <data key="d6">GPU acts as a single execution unit for offloading parallel tasks, influencing data transfer and synchronization strategies.</data>
  <data key="d7">hardware architecture, parallelism</data>
  <data key="d8">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Data transfers">
  <data key="d5">7.0</data>
  <data key="d6">Data transfers are essential for maintaining data consistency and enabling computations across CPU and GPU or among GPUs.</data>
  <data key="d7">data movement, system efficiency</data>
  <data key="d8">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="CLAIX18 systems">
  <data key="d5">9.0</data>
  <data key="d6">High-performance computing systems used for experiments, equipped with CPUs, GPUs, network fabric, and OS."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Xeon Platinum 8160 24C 2.1GHz">
  <data key="d5">8.0</data>
  <data key="d6">Specific CPU model used in the system, with 24 cores for high-performance processing."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Rocky 8.9">
  <data key="d5">8.0</data>
  <data key="d6">Operating system on the nodes, providing the environment for software execution."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="NVIDIA V100 GPUs">
  <data key="d5">8.0</data>
  <data key="d6">GPU hardware used for acceleration in computations."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Generator test cases">
  <data key="d5">8.0</data>
  <data key="d6">Specific test scenarios used to evaluate code generation, showing results variability with different seeds."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Kernels">
  <data key="d5">9.0</data>
  <data key="d6">Specific computational tasks such as classification, solvers, estimation, convolution, neural network passes."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Rodinia benchmark suite">
  <data key="d5">8.0</data>
  <data key="d6">Benchmark suite designed to evaluate HPC applications, based on Berkeley dwarfs, used for testing code applicability."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="OpenMP benchmarks">
  <data key="d5">8.0</data>
  <data key="d6">Parallel benchmarks within Rodinia, used to evaluate multi-threaded performance."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Port">
  <data key="d5">8.0</data>
  <data key="d6">Adapted benchmark versions for the PPL environment, ensuring correct execution and comparability."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Knowledge">
  <data key="d5">7.0</data>
  <data key="d6">External knowledge, such as domain-specific data or tools, serve as objects of study for enhancing LLMs.</data>
  <data key="d7">knowledge, domain data</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Objects of Study" target="Kronecker Products">
  <data key="d5">5.0</data>
  <data key="d6">Kronecker products are used in hypercomplex multiplication layers within adapters to achieve parameter efficiency.</data>
  <data key="d7">mathematical operations, model layers</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Objects of Study" target="LEGAL-BERT">
  <data key="d5">8.0</data>
  <data key="d6">LEGAL-BERT is a domain-specific language model designed to improve legal NLP tasks, representing objects of study for domain adaptation.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Objects of Study" target="Knowledge neurons in pretrained transformers">
  <data key="d5">8.0</data>
  <data key="d6">This study identifies neurons encoding factual knowledge, aiding interpretability of transformers.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Objects of Study" target="AST">
  <data key="d5">14.0</data>
  <data key="d6">Abstract Syntax Trees are structures representing program syntax, utilized in models like code2seq and in program synthesis."|</data>
  <data key="d7">Objects of Study, Methodologies</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Objects of Study" target="">
  <data key="d5">8.0</data>
  <data key="d6">The objects of study are the entities and their relationships within the text.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="Trade-offs">
  <data key="d5">7.0</data>
  <data key="d6">Discussion on balancing model size, speed, correctness, and resource requirements to optimize deployment in HPC environments.</data>
  <data key="d7">deployment trade-offs, practical usability</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Applications/Implications" target="Speed and resource efficiency">
  <data key="d5">7.0</data>
  <data key="d6">Models like HPC-Coder-V2-1.3B demonstrate high speed and low resource consumption, making them practical for real-world HPC coding tasks.</data>
  <data key="d7">deployment efficiency, practicality</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Applications/Implications" target="Research Questions/Hypotheses">
  <data key="d5">12.0</data>
  <data key="d6">Answers to research questions inform practical applications, such as optimizing data quality and model scaling for better HPC code generation.&lt;SEP&gt;Findings from research questions inform the potential practical benefits and limitations of HPC fine-tuned models."|</data>
  <data key="d7">6&lt;SEP&gt;Research to practice</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Applications/Implications" target="Knowledge Updating">
  <data key="d5">14.0</data>
  <data key="d6">Replacing or updating the non-parametric memory allows models to adapt to new information, maintaining relevance over time."|&lt;SEP&gt;The ability to replace or update non-parametric memory in RAG models allows them to adapt to new information and changing world knowledge.</data>
  <data key="d7">7&lt;SEP&gt;model adaptability</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Applications/Implications" target="Societal Benefits">
  <data key="d5">16.0</data>
  <data key="d6">More factual and controllable models can be employed in societal applications like healthcare and education.&lt;SEP&gt;More factually accurate, controllable, and interpretable models can be deployed in societal contexts like healthcare, education, and public information.</data>
  <data key="d7">societal impact, practical applications</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Applications/Implications" target="Mitigation Strategies">
  <data key="d5">16.0</data>
  <data key="d6">AI systems can be employed to detect and reduce misinformation, spam, and bias, promoting responsible AI deployment.&lt;SEP&gt;AI systems can be used to detect and counteract misinformation, spam, and bias in deployment.</data>
  <data key="d7">content safety, responsible AI&lt;SEP&gt;responsible AI, content safety</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Applications/Implications" target="LM4HPC">
  <data key="d5">16.0</data>
  <data key="d6">Applying language models to high-performance computing environments to improve code correctness and efficiency.&lt;SEP&gt;Applying language models to high-performance computing environments.</data>
  <data key="d7">application, HPC</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="Revolutionary Capabilities in HPC">
  <data key="d5">8.0</data>
  <data key="d6">Advanced AI capabilities could significantly impact HPC education and domain progress, enabling new methodologies."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Applications/Implications" target="Revolutionary Capabilities">
  <data key="d5">8.0</data>
  <data key="d6">Advanced AI capabilities could revolutionize HPC education, software development, and domain-specific methodologies."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Applications/Implications" target="Domain specialization of LLMs">
  <data key="d5">16.0</data>
  <data key="d6">Domain specialization enhances LLMs' effectiveness in specific fields, enabling tailored applications and better performance.&lt;SEP&gt;Domain specialization enhances the applicability of LLMs to specific fields, improving task performance and relevance.</data>
  <data key="d7">application, domain adaptation</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Applications/Implications" target="Future trends">
  <data key="d5">16.0</data>
  <data key="d6">Advancements in domain adaptation and continuous learning are expected to expand the impact and utility of LLMs.&lt;SEP&gt;Advancements in domain specialization and continuous learning are expected to expand the impact of LLMs in various fields.</data>
  <data key="d7">future research, application&lt;SEP&gt;future research, impact</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Applications/Implications" target="Safety and Alignment">
  <data key="d5">8.0</data>
  <data key="d6">Techniques like RLHF are applied to ensure LLM outputs are safe, truthful, and aligned with human values.</data>
  <data key="d7">content safety, ethical AI</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Applications/Implications" target="Collaborating with language models for embodied reasoning">
  <data key="d5">8.0</data>
  <data key="d6">This explores practical applications of language models in embodied reasoning tasks, influencing AI development.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Applications/Implications" target="Broader Impacts">
  <data key="d5">8.0</data>
  <data key="d6">The potential societal impacts of Codex include assisting in onboarding, education, and code generation, but also pose safety and misuse risks."|&gt;"impacts, safety</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="Codebase Transition">
  <data key="d5">16.0</data>
  <data key="d6">Automating code imports and generation with tools like Codex can facilitate easier transition to new languages or packages, impacting productivity and inclusivity.&lt;SEP&gt;Automating import and coding processes with tools like Codex can facilitate easier transition to new languages or packages, affecting productivity and inclusivity.</data>
  <data key="d7">productivity, accessibility</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="Automation of Repetitive Tasks">
  <data key="d5">7.0</data>
  <data key="d6">Code generation tools can automate routine coding tasks, broadening access to programming and shifting skill requirements.</data>
  <data key="d7">skill shift, automation</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="Societal Impact">
  <data key="d5">7.0</data>
  <data key="d6">The societal implications include effects on workforce diversity, economic inequality, and the distribution of technical skills.</data>
  <data key="d7">diversity, economic effects</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="Code Generation">
  <data key="d5">17.0</data>
  <data key="d6">Codex's ability to generate code impacts software development efficiency and innovation.&lt;SEP&gt;The trained model can be used to generate new source code, assist programmers, or automate coding processes in HPC environments.</data>
  <data key="d7">automation, productivity&lt;SEP&gt;productivity, innovation</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="HPC-specific Language Model">
  <data key="d5">8.0</data>
  <data key="d6">The HPC-specific language model can be used to automate code generation, labeling, and improve software development workflows in high-performance computing.</data>
  <data key="d7">automation, software improvement</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Applications/Implications" target="Labeling">
  <data key="d5">7.0</data>
  <data key="d6">The model can be applied to label or annotate HPC source code for analysis, documentation, or further processing.</data>
  <data key="d7">annotation, analysis</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Analytical Techniques" target="">
  <data key="d5">8.0</data>
  <data key="d6">The analytical techniques involve recognizing entities and determining relationships based on context and co-occurrence.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Theories/Models" target="Previous Work">
  <data key="d5">16.0</data>
  <data key="d6">Prior research demonstrates that incorporating retrieval improves NLP task performance, supporting the current work's premise.</data>
  <data key="d7">literature support, methodology</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="Single-Task Retrieval">
  <data key="d5">14.0</data>
  <data key="d6">Retrieval enhances performance across specific NLP tasks, validating the utility of retrieval-based architectures.</data>
  <data key="d7">task performance, methodology</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="General-Purpose Architectures">
  <data key="d5">12.0</data>
  <data key="d6">Pre-trained models like GPT-2, BART, and T5 achieve strong results without retrieval, but integrating retrieval can expand capabilities.</data>
  <data key="d7">model design, performance</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="Memory-based Architectures">
  <data key="d5">16.0</data>
  <data key="d6">External memory components enable models to attend to retrieved text, improving factual accuracy and interpretability.</data>
  <data key="d7">architecture, interpretability</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="Search engine guided neural machine translation">
  <data key="d5">19.0</data>
  <data key="d6">This model combines search engine techniques with neural machine translation to improve translation quality.&lt;SEP&gt;This model combines search engine techniques with neural translation to improve translation quality and efficiency.</data>
  <data key="d7">conceptual framework</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="generating sentences by editing prototypes">
  <data key="d5">7.0</data>
  <data key="d6">This methodology relates to natural language generation by editing prototypes to produce coherent sentences.</data>
  <data key="d7">methodological approach</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="Generalization through memorization: Nearest neighbor language models">
  <data key="d5">14.0</data>
  <data key="d6">This model enhances language understanding by incorporating memorization and nearest neighbor retrieval.&lt;SEP&gt;This model improves language understanding and generalization by memorizing training data and employing nearest neighbor retrieval techniques.</data>
  <data key="d7">concept</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="Language Models as Knowledge Bases">
  <data key="d5">16.0</data>
  <data key="d6">This theory posits that large language models can function as repositories of factual knowledge, influencing NLP research.&lt;SEP&gt;This theory suggests that large language models can serve as repositories of factual knowledge, reducing the need for explicit databases.</data>
  <data key="d7">knowledge representation, NLP</data>
  <data key="d8">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="Domain-Specific Languages and High-Level Frameworks for High-Performance Computing">
  <data key="d5">16.0</data>
  <data key="d6">A research area focusing on specialized programming languages and frameworks for high-performance computing.</data>
  <data key="d7">theoretical framework</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Theories/Models" target="Polyhedral Compilers">
  <data key="d5">14.0</data>
  <data key="d6">Polyhedral compiler techniques are relevant as alternative or complementary optimization strategies for nested loops, compared to PPL's methods."|&gt;"optimization models&lt;SEP&gt;Polyhedral compilers are referenced as related optimization techniques for loop nests, similar to PPL's aims."|&gt;"optimization models</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Theories/Models" target="Knowledge Representation">
  <data key="d5">8.0</data>
  <data key="d6">Knowledge representation structures domain knowledge in a formal way to facilitate effective model learning and reasoning."|&gt;"structured knowledge, model efficiency</data>
  <data key="d7">8</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Theories/Models" target="Autoencoder">
  <data key="d5">6.0</data>
  <data key="d6">Autoencoders inspire invertible adapters that can be inverted to mimic data compression and reconstruction processes.</data>
  <data key="d7">model architecture, autoencoding</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Theories/Models" target="Attention Mechanism">
  <data key="d5">6.0</data>
  <data key="d6">Attention mechanisms underpin tiny-attention adapters, enabling focused processing in models.</data>
  <data key="d7">neural network components, focus mechanisms</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Theories/Models" target="LEGAL-BERT">
  <data key="d5">8.0</data>
  <data key="d6">LEGAL-BERT is based on BERT architecture, adapted specifically for legal language understanding.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Theories/Models" target="Binding Language Models in Symbolic Languages">
  <data key="d5">16.0</data>
  <data key="d6">This approach involves integrating language models with symbolic languages to enhance reasoning and interpretability.&lt;SEP&gt;This approach involves integrating language models with symbolic languages to improve reasoning capabilities.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Theories/Models" target="Large Language Models (DeVlin et al., 2018; Radford et al., 2019; Liu et al., 2019; Raffel et al., 2020; Brown et al., 2020)">
  <data key="d5">18.0</data>
  <data key="d6">Transformers like GPT-2, GPT-3, and T5 are large-scale models applied to code synthesis and understanding."|</data>
  <data key="d7">Theories/Models, Study Designs</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Methodologies" target="Fine-tuning strategies">
  <data key="d5">9.0</data>
  <data key="d6">Fine-tuning improves models' ability to generate correct and efficient parallel code, contributing to performance gains.</data>
  <data key="d7">training techniques, optimization</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Methodologies" target="Learned Retrieval">
  <data key="d5">14.0</data>
  <data key="d6">Training retrieval modules with neural models improves document relevance for downstream tasks.</data>
  <data key="d7">training technique, relevance</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Methodologies" target="Retrieve-and-Edit">
  <data key="d5">14.0</data>
  <data key="d6">Retrieving and editing content for final outputs is effective in translation and semantic parsing, similar to the approach discussed.</data>
  <data key="d7">methodology, application</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Methodologies" target="REALM: Retrieval-augmented language model pre-training">
  <data key="d5">16.0</data>
  <data key="d6">REALM enhances language models by adding retrieval mechanisms during pre-training, improving performance across NLP tasks.&lt;SEP&gt;REALM involves retrieval mechanisms to enhance language model pre-training, impacting NLP applications.</data>
  <data key="d7">technical innovation</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Methodologies" target="retrieve-and-edit framework">
  <data key="d5">14.0</data>
  <data key="d6">This framework is used for structured output prediction by retrieving relevant data and editing it, relevant to language modeling.&lt;SEP&gt;This framework supports structured output prediction by retrieving relevant data and editing it, useful in NLP and AI systems.</data>
  <data key="d7">technique</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Methodologies" target="Simple and effective retrieve-edit-rerank text generation">
  <data key="d5">16.0</data>
  <data key="d6">This approach improves text generation by retrieving relevant information, editing it, and reranking outputs for better relevance and quality.&lt;SEP&gt;This approach improves text generation by retrieving, editing, and reranking outputs, impacting NLP system design.</data>
  <data key="d7">technique</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Methodologies" target="Inferring algorithmic patterns with stack-augmented recurrent nets">
  <data key="d5">16.0</data>
  <data key="d6">This methodology employs stack-augmented recurrent neural networks to infer and learn algorithmic patterns in sequential data.&lt;SEP&gt;This technique uses stack-augmented RNNs to infer algorithmic patterns, advancing neural network capabilities.</data>
  <data key="d7">method</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Methodologies" target="generating sentences by editing prototypes">
  <data key="d5">7.0</data>
  <data key="d6">This methodology involves editing prototypes to generate natural language sentences, contributing to NLP generation techniques.</data>
  <data key="d7">methodological approach</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Methodologies" target="Nucleus sampling">
  <data key="d5">16.0</data>
  <data key="d6">A sampling technique used during code generation to produce diverse outputs, linking the sampling method to the generation process."|"&lt;methodology&lt;SEP&gt;Nucleus sampling is used during inference to produce diverse outputs, linking the sampling technique to the methodology of controlled randomness in code generation."|"&lt;methodology</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Methodologies" target="Maximum tokens (1024)">
  <data key="d5">16.0</data>
  <data key="d6">Limiting token count helps control output length and computational cost, connecting to the methodology of output management."|"&lt;methodology&lt;SEP&gt;Token limit controls output length, balancing completeness and computational efficiency."|"&lt;methodology</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Methodologies" target="Generation configurations">
  <data key="d5">16.0</data>
  <data key="d6">Different sampling parameters (number of samples, temperature) are used to evaluate code performance, linking configuration choices to the methodology."|"&lt;methodology&lt;SEP&gt;Different sampling settings (number of samples, temperature) are used to evaluate code performance, linking configuration choices to the overall methodology."|"&lt;methodology</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Methodologies" target="Study Designs">
  <data key="d5">16.0</data>
  <data key="d6">Methodologies encompass the specific study designs used to structure research activities.</data>
  <data key="d7">research structuring, procedural framework</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Methodologies" target="Disciplines">
  <data key="d5">12.0</data>
  <data key="d6">Disciplines inform the methodologies chosen for conducting the research.</data>
  <data key="d7">disciplinary framework, methodological guidance</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Methodologies" target="Prompt Structure">
  <data key="d5">7.0</data>
  <data key="d6">The structured prompts, including kernel and model specifications, influence Copilot's code suggestions.</data>
  <data key="d7">prompt design, influence</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Methodologies" target="Code Suggestion Generation">
  <data key="d5">8.0</data>
  <data key="d6">The process of generating code snippets from prompts using Copilot across different languages and models.</data>
  <data key="d7">code generation, methodology</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Methodologies" target="H. Carter Edwards">
  <data key="d5">16.0</data>
  <data key="d6">Author of a paper on performance portability in manycore computing, contributing to high-performance computing methodologies.&lt;SEP&gt;Author of a paper on performance portability in manycore computing.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Methodologies" target="Christian R. Trott">
  <data key="d5">16.0</data>
  <data key="d6">Co-author of research on high-performance computing frameworks and languages.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Methodologies" target="Daniel Sunderland">
  <data key="d5">16.0</data>
  <data key="d6">Co-author involved in high-performance computing research.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Methodologies" target="OpenMP">
  <data key="d5">8.0</data>
  <data key="d6">OpenMP is a foundational parallel programming model used as a baseline in the evaluation of the prototype."|&gt;"parallel programming model</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="SDFGs and DaCe">
  <data key="d5">16.0</data>
  <data key="d6">Both employ rule-based optimization techniques for application hotspots, offering an alternative framework to PPL's optimization strategies."|&gt;"optimization strategies&lt;SEP&gt;They utilize rule-based optimization strategies, offering an alternative to PPL's optimization methodology."|&gt;"optimization strategies</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="DSL">
  <data key="d5">8.0</data>
  <data key="d6">The custom DSL in PPL enables specific, targeted optimizations, differentiating it from general-purpose code generators."|&gt;"programming language</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Synchronization between execution units">
  <data key="d5">8.0</data>
  <data key="d6">Various synchronization techniques coordinate tasks across hardware units, including intra-device, intra-node, and inter-device methods.</data>
  <data key="d7">coordination, system performance</data>
  <data key="d8">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Generated">
  <data key="d5">8.0</data>
  <data key="d6">Refers to code or data produced automatically via an automated code generation process, specifically by the PPL toolchain."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Global optimizations">
  <data key="d5">9.0</data>
  <data key="d6">Optimization approach that avoids artificial synchronization points to improve measurement accuracy by reducing dependencies."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Baseline">
  <data key="d5">8.0</data>
  <data key="d6">Naive CPU parallelization serves as a performance reference for other code versions."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Handwritten implementation">
  <data key="d5">8.0</data>
  <data key="d6">Manually optimized code used as a benchmark to compare against generated code."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Generated code">
  <data key="d5">8.0</data>
  <data key="d6">Automatically produced code evaluated for performance and stability."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Framework">
  <data key="d5">7.0</data>
  <data key="d6">The framework provides the structured basis for classifying and developing domain-specific LLM techniques."|&lt;"methodological structure, classification</data>
  <data key="d7">7</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="Knowledge updating mechanisms">
  <data key="d5">8.0</data>
  <data key="d6">Techniques such as continual learning or retrieval-augmented generation are developed to help LLMs incorporate new knowledge after initial training.</data>
  <data key="d7">learning techniques, knowledge update</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="Knowledge Update">
  <data key="d5">9.0</data>
  <data key="d6">Knowledge update involves modifying the model's internal parameters or training data to incorporate new domain-specific information.</data>
  <data key="d7">training, internal update</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="Evaluation and Feedback">
  <data key="d5">7.0</data>
  <data key="d6">Evaluation mechanisms include benchmarks, dynamic assessments, and user feedback to guide domain adaptation.</data>
  <data key="d7">performance assessment, feedback</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="Clip-Tuning">
  <data key="d5">16.0</data>
  <data key="d6">Clip-Tuning is a prompt learning approach that aims for derivative-free optimization using reward signals, related to prompt learning methodologies.&lt;SEP&gt;Clip-Tuning is a prompt learning technique aiming for derivative-free optimization using rewards, related to methodologies for prompt learning and model tuning.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="Recall and learn">
  <data key="d5">16.0</data>
  <data key="d6">This approach focuses on fine-tuning language models with less forgetting, enhancing learning efficiency.&lt;SEP&gt;This approach involves fine-tuning deep pretrained models with less forgetting, focusing on knowledge retention during training.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="Program of Thoughts Prompting">
  <data key="d5">16.0</data>
  <data key="d6">This prompting method disentangles computation and reasoning, improving numerical reasoning in models.&lt;SEP&gt;This prompting method disentangles computation from reasoning, improving models' numerical reasoning capabilities.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="Editing Factual Knowledge in Language Models">
  <data key="d5">8.0</data>
  <data key="d6">This study investigates techniques for editing and updating factual knowledge within large language models to reduce hallucinations and improve accuracy.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="">
  <data key="d5">7.0</data>
  <data key="d6">The methodology involves systematic extraction of entities and relationships from the text.</data>
  <data key="d7">7</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Methodologies" target="Training and Fine-tuning">
  <data key="d5">9.0</data>
  <data key="d6">The methodology involves collecting HPC source code datasets, preprocessing, and fine-tuning pre-trained models to specialize in HPC code tasks.</data>
  <data key="d7">dataset collection, model adaptation</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Core Concepts" target="Trade-off between Data Quantity and Quality">
  <data key="d5">8.0</data>
  <data key="d6">The central idea that more data improves performance only up to a point, after which data quality becomes more influential for further gains.</data>
  <data key="d7">conceptual trade-off, optimization</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Core Concepts" target="Educational Perspective">
  <data key="d5">12.0</data>
  <data key="d6">The educational implications involve generating programming exercises and explanations with Copilot, influencing teaching methodologies.&lt;SEP&gt;The educational use of Copilot involves generating programming exercises and explanations, impacting teaching methodologies.</data>
  <data key="d7">pedagogy, educational impact</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Core Concepts" target="OpenMP">
  <data key="d5">8.0</data>
  <data key="d6">OpenMP serves as a baseline parallel programming model against which the PPL prototype is evaluated."|&gt;"benchmarking</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Core Concepts" target="5.1 Environment">
  <data key="d5">8.0</data>
  <data key="d6">The overall computational environment setup, including hardware, software, and configuration."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Core Concepts" target="Parallel code">
  <data key="d5">9.0</data>
  <data key="d6">Code designed for concurrent execution across CPU and GPU resources, used in performance evaluation."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Core Concepts" target="Berkeley dwarfs">
  <data key="d5">7.0</data>
  <data key="d6">Framework classifying computational patterns in HPC, guiding benchmark design."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Core Concepts" target="Zero-shot Learning">
  <data key="d5">7.0</data>
  <data key="d6">Zero-shot learning enables models to generalize to unseen tasks or domains, often facilitated by prompting techniques.</data>
  <data key="d7">generalization, unseen tasks</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Core Concepts" target="Few-shot Learning">
  <data key="d5">7.0</data>
  <data key="d6">Few-shot learning allows models to adapt with minimal examples, often via prompts, enhancing their versatility.</data>
  <data key="d7">sample efficiency, adaptation</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Core Concepts" target="">
  <data key="d5">8.0</data>
  <data key="d6">The process of entity and relationship extraction is a core concept in text analysis and information retrieval.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Core Concepts" target="Entity Recognition">
  <data key="d5">9.0</data>
  <data key="d6">Entity recognition is fundamental to the activity of extracting meaningful relationships from text."|&gt;"concept importance, foundational</data>
  <data key="d7">9</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Core Concepts" target="Relationship Extraction">
  <data key="d5">9.0</data>
  <data key="d6">Relationship extraction is essential for understanding the structure and meaning of the text."|&gt;"concept importance, analytical</data>
  <data key="d7">9</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Variables" target="serial, OpenMP, MPI, CUDA, Kokkos">
  <data key="d5">9.0</data>
  <data key="d6">Different execution models serve as variables in the experiments to evaluate translation accuracy and effectiveness.</data>
  <data key="d7">comparative analysis, model capability</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="serial">
  <data key="d5">8.0</data>
  <data key="d6">Serial code serves as a baseline variable for evaluating translation and generation quality against parallel models.</data>
  <data key="d7">comparison, baseline</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="OpenMP, MPI, MPI+OpenMP, Kokkos, CUDA, HIP">
  <data key="d5">10.0</data>
  <data key="d6">These execution models are variables in the experiments used to assess the models' translation and generation abilities.</data>
  <data key="d7">comparative analysis, model capability</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="speedup n@k">
  <data key="d5">20.0</data>
  <data key="d6">speedup n@k compares execution performance of generated code relative to a baseline across multiple processes or threads."&lt;&gt; "performance measurement&lt;SEP&gt;speedup n@k compares the execution speed of code generated by models when run with multiple processes or threads, relative to a baseline."&lt;&gt; "performance measurement</data>
  <data key="d7">10</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="efficiency n@k">
  <data key="d5">20.0</data>
  <data key="d6">efficiency n@k assesses runtime efficiency of generated code in a parallel or high-performance computing context."&lt;&gt; "performance measurement&lt;SEP&gt;efficiency n@k assesses the runtime efficiency of code in parallel computing contexts, comparing execution times across different process counts."&lt;&gt; "performance measurement</data>
  <data key="d7">10</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="Evaluation Metrics">
  <data key="d5">21.0</data>
  <data key="d6">Metrics such as correctness scores and correlation indices used to evaluate code quality.&lt;SEP&gt;Metrics such as correctness scores and correlation with language popularity are used to quantify AI-generated code quality.&lt;SEP&gt;Metrics such as correctness scores and correlation with language popularity indices are used to quantify the quality of AI-generated code.</data>
  <data key="d7">metrics, assessment&lt;SEP&gt;quantification, assessment</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Variables" target="Random seeds">
  <data key="d5">8.0</data>
  <data key="d6">Different initializations used in Gurobi to mitigate solution variability caused by its stochastic process."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Variables" target="Over-Representation of Topics">
  <data key="d5">7.0</data>
  <data key="d6">Over-represented topics can bias model outputs, while under-represented topics may lead to knowledge gaps."|&gt;"bias, data distribution</data>
  <data key="d7">7</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Variables" target="Under-Representation of Topics">
  <data key="d5">7.0</data>
  <data key="d6">Under-represented topics result in limited model knowledge and potential inaccuracies in those areas."|&gt;"knowledge gaps, model performance</data>
  <data key="d7">7</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Variables" target="Parameters">
  <data key="d5">8.0</data>
  <data key="d6">Parameters are internal model weights that can be adjusted during fine-tuning to encode domain-specific knowledge.</data>
  <data key="d7">model parameters, fine-tuning</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Variables" target="Temporal Reasoning">
  <data key="d5">16.0</data>
  <data key="d6">Tracking variable states over time enables reasoning about safety, liveness, and program correctness in synthesized code.&lt;SEP&gt;Tracking variables over time enables reasoning about safety and liveness properties, ensuring correctness in synthesized code."|&lt;"state tracking, reasoning</data>
  <data key="d7">8&lt;SEP&gt;state tracking, reasoning</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Variables" target="Concurrency and Parallelism">
  <data key="d5">16.0</data>
  <data key="d6">Reasoning about concurrent processes, synchronization, and data races is essential for correct parallel code synthesis."|&lt;"parallel reasoning, synchronization&lt;SEP&gt;Reasoning about concurrent processes, synchronization, and data races is essential for synthesizing correct parallel code.</data>
  <data key="d7">8&lt;SEP&gt;parallel reasoning, synchronization</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Variables" target="Hyperproperties">
  <data key="d5">14.0</data>
  <data key="d6">Hyperproperties involve reasoning about information flow and security policies, requiring the code to satisfy specific observational properties.&lt;SEP&gt;Reasoning about information flow and security policies involves variables that must satisfy properties like noninterference."|&lt;"security, information flow</data>
  <data key="d7">7&lt;SEP&gt;security, information flow</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Variables" target="Nondeterminism">
  <data key="d5">14.0</data>
  <data key="d6">Handling nondeterministic algorithms involves reasoning about multiple possible execution paths and outputs.&lt;SEP&gt;Handling nondeterministic algorithms involves reasoning about multiple possible execution paths and outputs."|&lt;"algorithm behavior, multiple outcomes</data>
  <data key="d7">7&lt;SEP&gt;algorithm behavior, multiple outcomes</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Study Designs" target="32nd AAAI Conference on Artificial Intelligence">
  <data key="d5">16.0</data>
  <data key="d6">The conference serves as a platform for presenting research on neural machine translation and related AI methodologies.&lt;SEP&gt;This conference provides a platform for presenting and discussing research on neural translation models and AI advancements.</data>
  <data key="d7">academic dissemination</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Study Designs" target="TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension">
  <data key="d5">18.0</data>
  <data key="d6">This dataset provides a benchmark for evaluating reading comprehension models trained with distant supervision techniques.&lt;SEP&gt;This dataset provides a benchmark for evaluating reading comprehension models with distant supervision.</data>
  <data key="d7">evaluation resource</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Study Designs" target="Natural Questions: a Benchmark for Question Answering Research">
  <data key="d5">16.0</data>
  <data key="d6">This benchmark dataset is used to evaluate and compare question answering systems, fostering advances in NLP research.&lt;SEP&gt;This benchmark facilitates the evaluation of question answering systems, fostering NLP research.</data>
  <data key="d7">evaluation benchmark</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Study Designs" target="model evaluation">
  <data key="d5">8.0</data>
  <data key="d6">Models are systematically evaluated using metrics like pass@k, speedup, and efficiency to assess correctness and performance."&lt;&gt; "performance assessment</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Study Designs" target="model comparison">
  <data key="d5">8.0</data>
  <data key="d6">Different models are compared based on their performance metrics to determine relative strengths and weaknesses."&lt;&gt; "benchmarking, performance comparison</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Study Designs" target="Evaluation Setup">
  <data key="d5">7.0</data>
  <data key="d6">The experimental setup involving prompt design, language selection, and metrics for evaluating Copilot's outputs.</data>
  <data key="d7">experimental design, setup</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Study Designs" target="Performance Evaluation">
  <data key="d5">8.0</data>
  <data key="d6">Performance evaluation involves benchmarking the entire pipeline to assess effectiveness.</data>
  <data key="d7">assessment method</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Study Designs" target="All measurements">
  <data key="d5">14.0</data>
  <data key="d6">Measurements are performed to ensure data reliability and to evaluate system performance."|&lt;SEP&gt;The process of performing multiple measurements to gather performance data."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Study Designs" target="Conference on Empirical Methods in Natural Language Processing">
  <data key="d5">16.0</data>
  <data key="d6">This conference hosts presentations on empirical NLP methods including Clip-Tuning, serving as a venue for dissemination of methodologies.&lt;SEP&gt;This conference hosts research presentations on empirical NLP methods, including Clip-Tuning and prompt learning strategies.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Study Designs" target="Deep reinforcement learning from human preferences">
  <data key="d5">16.0</data>
  <data key="d6">This study explores reinforcement learning guided by human preferences to align model behavior with human values.&lt;SEP&gt;This study explores reinforcement learning guided by human preferences, impacting model training strategies.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Study Designs" target="Scaling instruction-finetuned language models">
  <data key="d5">16.0</data>
  <data key="d6">This research examines scaling instruction tuning to enhance model performance across tasks.&lt;SEP&gt;This research investigates scaling instruction tuning to improve model versatility and task performance.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Study Designs" target="Training Methodology">
  <data key="d5">9.0</data>
  <data key="d6">The process involves collecting HPC source code datasets, preprocessing, and fine-tuning pre-trained models to adapt them for HPC-specific applications and downstream tasks.</data>
  <data key="d7">dataset collection, model adaptation</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Study Designs" target="Fine-tuning">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning involves training the pre-trained models further on the HPC dataset to improve their performance in HPC contexts.</data>
  <data key="d7">training process, specialization</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Study Designs" target="Model Selection">
  <data key="d5">7.0</data>
  <data key="d6">Model selection involves evaluating multiple fine-tuned models to choose the best for deployment.</data>
  <data key="d7">evaluation, optimization</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="pass@k">
  <data key="d5">18.0</data>
  <data key="d6">pass@k is employed to measure the correctness of code generated by models across multiple attempts."&lt;&gt; "performance evaluation&lt;SEP&gt;pass@k is used to evaluate the correctness of models' generated code across multiple attempts."&lt;&gt; "performance evaluation</data>
  <data key="d7">9</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="The main research question concerns the capabilities and limitations of AI code generation tools like Copilot in various contexts.">
  <data key="d5">6.0</data>
  <data key="d6">research focus, capabilities</data>
  <data key="d7">6</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="The study explores the capabilities and limitations of AI code generation tools like Copilot across languages and contexts.">
  <data key="d5">6.0</data>
  <data key="d6">research focus, capabilities</data>
  <data key="d7">6</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Programming Exercises Generation">
  <data key="d5">3.0</data>
  <data key="d6">Research investigates automated generation of programming exercises and explanations using large language models, with recent studies in 2022.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Domain-Specific Tasks">
  <data key="d5">7.0</data>
  <data key="d6">Domain-specific tasks define the focus of research questions and hypotheses tailored to particular fields."|&gt;"task focus, hypothesis formulation</data>
  <data key="d7">7</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Future Directions">
  <data key="d5">8.0</data>
  <data key="d6">Future research will explore Codex's economic value, impact on productivity, barriers to entry, and societal effects.</data>
  <data key="d7">research scope, societal impact</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Y. Li et al.">
  <data key="d5">14.0</data>
  <data key="d6">Assess the ability of AlphaCode to solve programming problems at a competitive level, evaluating its performance against human benchmarks.&lt;SEP&gt;Investigates the effectiveness of code generation models like AlphaCode in competitive programming contexts.</data>
  <data key="d7">Core Concepts, Results</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="A. Gokaslan and V. Cohen">
  <data key="d5">14.0</data>
  <data key="d6">Analyzes the composition and relevance of the OpenWebText corpus for language model training.&lt;SEP&gt;Evaluate the composition, diversity, and utility of the OpenWebText corpus for training robust language models.</data>
  <data key="d7">Objects of Study, Applications/Implications</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Evaluation of large language models trained on code">
  <data key="d5">16.0</data>
  <data key="d6">The research hypothesizes that large language models trained on code can effectively perform tasks like code understanding, generation, and validation.</data>
  <data key="d7">model capability, programming tasks</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Disciplines" target="CUDA">
  <data key="d5">12.0</data>
  <data key="d6">CUDA is referenced as a model for GPU acceleration, which PPL aims to support or emulate."|&gt;"hardware support&lt;SEP&gt;CUDA serves as a model for GPU optimization patterns, relevant to PPL's hardware support."|&gt;"hardware optimization</data>
  <data key="d7">6</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Disciplines" target="RWTH Aachen University">
  <data key="d5">6.0</data>
  <data key="d6">Institution hosting the systems and conducting the research."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Study Populations/Dataset" target="Open-source and Closed-source Language Models">
  <data key="d5">6.0</data>
  <data key="d6">The various models evaluated in the study include both open-source and proprietary (closed-source) models.</data>
  <data key="d7">model diversity, evaluation dataset</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Study Populations/Dataset" target="A Survey on Knowledge Graphs for Healthcare">
  <data key="d5">16.0</data>
  <data key="d6">This survey reviews datasets and applications of knowledge graphs in healthcare contexts.&lt;SEP&gt;This survey reviews datasets, resources, and applications of knowledge graphs in healthcare contexts.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Study Populations/Dataset" target="HPC Source Code Dataset">
  <data key="d5">8.0</data>
  <data key="d6">The large HPC source code dataset provides the training material for fine-tuning models for HPC-specific tasks.</data>
  <data key="d7">training data, domain specificity</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Study Design" target="Evaluating Large Language Models Trained on Code">
  <data key="d5">16.0</data>
  <data key="d6">Research assessing models' performance on code tasks.&lt;SEP&gt;Research assessing the performance, accuracy, and capabilities of language models trained specifically on code datasets.</data>
  <data key="d7">study, assessment</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Study Design" target="Evaluating large language models trained on code">
  <data key="d5">16.0</data>
  <data key="d6">A study assessing the performance of language models in coding tasks.</data>
  <data key="d7">research methodology</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Study Design" target="Code Generation Using Machine Learning: A Systematic Review">
  <data key="d5">16.0</data>
  <data key="d6">A systematic review analyzing machine learning approaches to code generation.</data>
  <data key="d7">research methodology</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Study Design" target="Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language">
  <data key="d5">16.0</data>
  <data key="d6">A study on using natural language prompts with AI coding tools to solve programming problems.</data>
  <data key="d7">research methodology</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Study Design" target="DARPA’s HPCS Program: History, Models, Tools, Languages">
  <data key="d5">16.0</data>
  <data key="d6">A comprehensive overview of high-performance computing models, tools, and languages developed by DARPA.</data>
  <data key="d7">research content</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Study Design" target="The International Exascale Software Project roadmap">
  <data key="d5">16.0</data>
  <data key="d6">A strategic plan for exascale computing software development.</data>
  <data key="d7">research content</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Study Design" target="One-shot learning of object categories">
  <data key="d5">16.0</data>
  <data key="d6">Research on training models to recognize objects from a single example.</data>
  <data key="d7">research methodology</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Study Design" target="Object Classification from a Single Example Utilizing Class Relevance Metrics">
  <data key="d5">16.0</data>
  <data key="d6">Research on class relevance metrics for object classification from minimal examples.</data>
  <data key="d7">research methodology</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Study Design" target="The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming">
  <data key="d5">16.0</data>
  <data key="d6">A study on how AI tools like Codex influence teaching and learning introductory programming.</data>
  <data key="d7">research methodology</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Study Design" target="GPT-3: Its nature, scope, limits, and consequences">
  <data key="d5">16.0</data>
  <data key="d6">An analysis of GPT-3's capabilities, limitations, and societal implications.</data>
  <data key="d7">research content</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Evaluation" target="Large Language Models Trained on Code">
  <data key="d5">12.0</data>
  <data key="d6">These models are evaluated for their ability to understand, generate, and perform tasks related to programming code.</data>
  <data key="d7">model evaluation, code understanding</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Evaluation" target="Open-domain QA">
  <data key="d5">16.0</data>
  <data key="d6">Open-domain question answering models are evaluated based on their ability to retrieve relevant documents and produce accurate answers.</data>
  <data key="d7">task evaluation, retrieval effectiveness</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Evaluation" target="Models Comparison">
  <data key="d5">7.0</data>
  <data key="d6">Different models are compared based on their performance metrics like pass@1 in code generation tasks."|&gt;"performance comparison, model evaluation</data>
  <data key="d7">7</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Evaluation" target="HPC Kernels">
  <data key="d5">20.0</data>
  <data key="d6">The study evaluates the performance and correctness of HPC kernels generated by GPT-3/Codex, such as AXPY and GEMV, across different programming models and prompts." ,&lt;SEP&gt;The study evaluates the performance and correctness of HPC kernels generated by GPT-3/Codex, such as AXPY and GEMV, across different programming models.</data>
  <data key="d7">10&lt;SEP&gt;assessment, performance testing</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Training Data" target="Bias in Model">
  <data key="d5">19.0</data>
  <data key="d6">Training data encodes social biases that influence model outputs, especially in sensitive contexts.&lt;SEP&gt;Training data encodes social biases that influence model outputs.</data>
  <data key="d7">data influence, bias learning</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Training Data" target="Model Capabilities">
  <data key="d5">6.0</data>
  <data key="d6">The training data influences Codex's ability to suggest vulnerabilities or malicious code, affecting its security profile.</data>
  <data key="d7">training influence, model performance</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Training Data" target="Adversarial Inputs">
  <data key="d5">7.0</data>
  <data key="d6">Adversarial inputs can manipulate the training or prompting process, increasing risks of malicious suggestions.</data>
  <data key="d7">adversarial attack, security risk</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Methodology" target="Zero-Shot Replication Framework">
  <data key="d5">16.0</data>
  <data key="d6">A methodology designed to facilitate the replication of experiments without requiring retraining or extensive data.&lt;SEP&gt;Framework designed to facilitate experiment replication without prior training.</data>
  <data key="d7">methodology, replication</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Methodology" target="Learning from Small and Local Datasets">
  <data key="d5">16.0</data>
  <data key="d6">A methodology for training models effectively with limited, localized data sources.&lt;SEP&gt;Approach to training models with limited data.</data>
  <data key="d7">methodology, data</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Methodology" target="Domain Adaptation and Generalization">
  <data key="d5">7.0</data>
  <data key="d6">Research on adapting general LLMs to specific domains involves techniques like layer addition or parameter updating, despite challenges due to model architecture inaccessibility.</data>
  <data key="d7">adaptation methods, challenges</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodology" target="Filtering Solutions">
  <data key="d5">8.0</data>
  <data key="d6">Filtering solutions based on passing unit tests enhances the reliability of success metrics in code evaluation.</data>
  <data key="d7">evaluation methodology, solution validation</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Methodology" target="Timeout Constraint">
  <data key="d5">7.0</data>
  <data key="d6">Imposing a 3-second timeout affects the measured success rate by excluding solutions that are correct but inefficient.</data>
  <data key="d7">evaluation criteria, efficiency measurement</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Methodology" target="Supervised Fine-Tuning">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning models on curated datasets from competitive programming and open-source projects aims to improve code generation performance.</data>
  <data key="d7">training strategy, model improvement</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Methodology" target="SPoC">
  <data key="d5">16.0</data>
  <data key="d6">A method for producing functionally correct code from pseudocode within a fixed compilation budget."|</data>
  <data key="d7">Methodologies, Results</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model" target="Non-parametric Memory">
  <data key="d5">18.0</data>
  <data key="d6">Non-parametric memory allows models to dynamically update and retrieve information without fixed parameters, enhancing flexibility.</data>
  <data key="d7">model architecture, memory</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Model" target="Factual Associations">
  <data key="d5">18.0</data>
  <data key="d6">Factual associations are stored relationships within models that can be located, edited, or evaluated to improve factual accuracy.</data>
  <data key="d7">knowledge management, factual correctness</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model" target="Training Problems">
  <data key="d5">7.0</data>
  <data key="d6">Training problems serve as the dataset for fine-tuning models like Codex, enabling the models to learn from specific examples.</data>
  <data key="d7">dataset, learning</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model" target="Fine-Tuning">
  <data key="d5">9.0</data>
  <data key="d6">Fine-tuning is applied to the model to improve its performance on specific tasks like code generation and reducing size on hardware such as A100s."|&lt;"training optimization, model adaptation</data>
  <data key="d7">9</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model" target="Prompt">
  <data key="d5">7.0</data>
  <data key="d6">The model takes prompts as input to generate code snippets."|&lt;"input processing, code synthesis</data>
  <data key="d7">7</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model" target="Accuracy">
  <data key="d5">20.0</data>
  <data key="d6">The accuracy metric evaluates how effectively the fine-tuned models generate correct OpenMP pragmas, measured both syntactically and functionally.&lt;SEP&gt;The accuracy metric measures how well the fine-tuned models generate correct OpenMP pragmas, both syntactically and functionally.</data>
  <data key="d7">performance evaluation, correctness</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model" target="Relative Performance Prediction">
  <data key="d5">16.0</data>
  <data key="d6">Models are fine-tuned to predict whether code versions will be slower or faster, based on code pair data.&lt;SEP&gt;Models are trained to predict whether code versions are slower or faster based on features from code pairs.</data>
  <data key="d7">classification task, performance prediction&lt;SEP&gt;classification, performance prediction</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Evaluation Metric" target="Accuracy">
  <data key="d5">7.0</data>
  <data key="d6">Model success in predicting performance changes is measured by classification accuracy, indicating the proportion of correct predictions.</data>
  <data key="d7">performance evaluation, metrics</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Spatiotemporal Information" target="Extreme Heterogeneity">
  <data key="d5">2.0</data>
  <data key="d6">Extreme Heterogeneity describes diverse hardware environments in scientific computing, as reported in 2018 to enhance productive science.</data>
  <data key="d7">Spatiotemporal Information</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Spatiotemporal Information" target="arXiv:1910.13461">
  <data key="d5">5.0</data>
  <data key="d6">The arXiv preprint provides online access to the BART research paper, indicating publication date and availability.</data>
  <data key="d7">publication, access information</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="models" target="impact analysis">
  <data key="d5">16.0</data>
  <data key="d6">Impact analysis is performed on models to understand their safety features, risks, and potential societal effects.</data>
  <data key="d7">safety assessment, risk evaluation</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="models" target="over-reliance">
  <data key="d5">14.0</data>
  <data key="d6">Over-reliance on models' outputs can lead to safety issues, especially if users do not exercise proper oversight.</data>
  <data key="d7">user dependency, safety risk</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="models" target="misalignment">
  <data key="d5">18.0</data>
  <data key="d6">Misalignment occurs when models generate outputs that do not align with user intentions, potentially causing unsafe or undesired outcomes.</data>
  <data key="d7">output accuracy, user intent</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="models" target="bias and representation">
  <data key="d5">16.0</data>
  <data key="d6">Bias and representation issues in models can produce harmful stereotypes and biased code, impacting safety and fairness.</data>
  <data key="d7">ethical concerns, societal biases</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="models" target="training distribution">
  <data key="d5">14.0</data>
  <data key="d6">The training distribution influences model behavior and biases, affecting the safety and reliability of generated code.</data>
  <data key="d7">training data, model behavior</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Language Models" target="Contextual Influence">
  <data key="d5">16.0</data>
  <data key="d6">The influence of context on language models' factual predictions highlights the importance of context in NLP applications.&lt;SEP&gt;The influence of context on language models' predictions highlights the importance of contextual information in NLP applications.</data>
  <data key="d7">contextual effects, NLP&lt;SEP&gt;contextual effects, prediction accuracy</data>
  <data key="d8">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Language Models" target="Knowledge Base Construction">
  <data key="d5">16.0</data>
  <data key="d6">Language models facilitate automated construction of knowledge bases by extracting and organizing information from text.&lt;SEP&gt;Language models facilitate automated extraction and organization of knowledge for constructing knowledge bases.</data>
  <data key="d7">knowledge extraction, NLP</data>
  <data key="d8">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Language Models" target="Unsupervised Multitask Learners">
  <data key="d5">18.0</data>
  <data key="d6">Language models are characterized as unsupervised multitask learners, capable of handling multiple NLP tasks without explicit supervision.</data>
  <data key="d7">model training, multitask learning</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Language Models" target="Transfer Learning">
  <data key="d5">16.0</data>
  <data key="d6">Transfer learning enhances language models by applying knowledge from one task or domain to another, improving performance and generalization.</data>
  <data key="d7">knowledge transfer, model improvement</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Language Models" target="Text-to-Text Transformer">
  <data key="d5">14.0</data>
  <data key="d6">The text-to-text transformer architecture is a methodology used to unify various NLP tasks within language models.</data>
  <data key="d7">neural architecture, NLP tasks</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Language Models" target="Jeremy Howard">
  <data key="d5">16.0</data>
  <data key="d6">Jeremy Howard's work on universal language model fine-tuning impacts NLP methodologies.</data>
  <data key="d7">language models, fine-tuning</data>
  <data key="d8">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Language Models" target="Psychophysical Knowledge">
  <data key="d5">14.0</data>
  <data key="d6">Language models can reveal psychophysical insights by distilling perceptual information from their learned representations.</data>
  <data key="d7">knowledge extraction, perception</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Language Models" target="Memory Editing">
  <data key="d5">16.0</data>
  <data key="d6">Memory editing techniques modify the factual knowledge stored within language models to correct errors or update information.</data>
  <data key="d7">knowledge updating, model correction</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Language Models" target="Verified Quotes">
  <data key="d5">16.0</data>
  <data key="d6">Language models support answers with verified quotes to enhance answer credibility and factual accuracy.</data>
  <data key="d7">source validation, answer support</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Language Models" target="Augmented Language Models">
  <data key="d5">14.0</data>
  <data key="d6">Augmented models integrate additional modules or data to enhance the capabilities of standard language models.</data>
  <data key="d7">model enhancement, performance boost</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Language Models" target="Pre-trained Language Models">
  <data key="d5">16.0</data>
  <data key="d6">Pre-trained language models serve as foundational models trained on large datasets, enabling transfer learning for various NLP tasks.</data>
  <data key="d7">training, transfer learning</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Language Models" target="In-Context Learning">
  <data key="d5">16.0</data>
  <data key="d6">In-Context Learning allows models to adapt to new tasks by learning from demonstrations provided within the input context.</data>
  <data key="d7">learning paradigm, task adaptation</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Language Models" target="Model Editing">
  <data key="d5">18.0</data>
  <data key="d6">Model editing techniques modify internal parameters to fix errors or incorporate new knowledge without retraining from scratch.</data>
  <data key="d7">knowledge update, model correction</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Language Models" target="Few-Shot Learning">
  <data key="d5">18.0</data>
  <data key="d6">Language models like GPT-3 are capable of few-shot learning, performing tasks with minimal examples.&lt;SEP&gt;Language models like GPT-3 demonstrate the ability to perform tasks with few examples, showcasing advanced few-shot learning capabilities.</data>
  <data key="d7">Core Concepts, Results</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Loss of Life" target="Societal Impact">
  <data key="d5">16.0</data>
  <data key="d6">The loss of life due to COVID-19 underscores the pandemic's profound societal and emotional impact.</data>
  <data key="d7">public health, emotional toll</data>
  <data key="d8">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Loss of Life" target="Impact">
  <data key="d5">8.0</data>
  <data key="d6">The loss of life from COVID-19 highlights the profound human and societal toll of the pandemic.</data>
  <data key="d7">public health, human toll</data>
  <data key="d8">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="US Sanctions" target="Economic Impact">
  <data key="d5">8.0</data>
  <data key="d6">Sanctions are designed to exert economic pressure on Russia and support Ukraine, affecting global markets.</data>
  <data key="d7">economic policy, geopolitical impact</data>
  <data key="d8">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Energy Prices" target="Oil Reserves">
  <data key="d5">24.0</data>
  <data key="d6">Releasing oil from reserves aims to stabilize or reduce energy prices amid global supply issues.&lt;SEP&gt;Releasing oil reserves is a strategic measure to influence global energy prices during supply disruptions.</data>
  <data key="d7">energy policy, economic stability&lt;SEP&gt;energy policy, global markets</data>
  <data key="d8">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ARPA-H" target="Health Breakthroughs">
  <data key="d5">16.0</data>
  <data key="d6">ARPA-H is designed to catalyze breakthroughs in health through innovative research, similar to DARPA's role in technological advances.</data>
  <data key="d7">innovation, health research</data>
  <data key="d8">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ARPA-H" target="Health Innovation">
  <data key="d5">8.0</data>
  <data key="d6">ARPA-H aims to drive breakthroughs in health, leveraging innovative research similar to DARPA's technological advances.</data>
  <data key="d7">health research, innovation</data>
  <data key="d8">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="HPC-INSTRUCT">
  <data key="d5">18.0</data>
  <data key="d6">HPC-Coder-V2 is fine-tuned on the HPC-INSTRUCT dataset to enhance its parallel code generation capabilities.</data>
  <data key="d7">training data, model fine-tuning</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="ParEval">
  <data key="d5">20.0</data>
  <data key="d6">HPC-Coder-V2 is evaluated against ParEval to determine its effectiveness in generating parallel code.</data>
  <data key="d7">model evaluation, benchmarking</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="HPC Community">
  <data key="d5">4.0</data>
  <data key="d6">The HPC community benefits from HPC-Coder-V2's capabilities in generating parallel code for scientific and engineering applications.</data>
  <data key="d7">applications, community benefit</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="HPC-I NSTRUCT">
  <data key="d5">18.0</data>
  <data key="d6">HPC-Coder-V2 is fine-tuned on the HPC-I NSTRUCT dataset to enhance its ability to generate parallel code.</data>
  <data key="d7">training data, model fine-tuning</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="fine-tuning">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning HPC-Coder-V2 involves training on the HPC-I NSTRUCT dataset to improve its parallel code generation capabilities.</data>
  <data key="d7">model training, performance enhancement</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="Comparison with other models">
  <data key="d5">18.0</data>
  <data key="d6">HPC-Coder-V2 models outperform comparable models in parallel code generation, especially smaller variants, demonstrating the effectiveness of fine-tuning.&lt;SEP&gt;HPC-Coder-V2 models outperform some models in parallel code generation, demonstrating the effectiveness of fine-tuning strategies.</data>
  <data key="d7">model comparison, fine-tuning impact&lt;SEP&gt;model comparison, fine-tuning strategy</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Parallel Code Generation" target="Reasoning and Planning in AI">
  <data key="d5">9.0</data>
  <data key="d6">Generating parallel code requires reasoning about data distributions and algorithms, which relates to AI planning and reasoning capabilities.</data>
  <data key="d7">AI reasoning, complex task</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Code Generation" target="Performance Bugs, Race Conditions, Deadlocks">
  <data key="d5">8.0</data>
  <data key="d6">Generating bug-free parallel code involves overcoming issues like race conditions and deadlocks, indicating the complexity of the task.</data>
  <data key="d7">code correctness, parallel bugs</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="High-Quality Parallel Code Data" target="HPC-INSTRUCT">
  <data key="d5">16.0</data>
  <data key="d6">HPC-INSTRUCT provides high-quality parallel code instruction data used to train and improve models like HPC-Coder-V2.</data>
  <data key="d7">data quality, dataset creation</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-INSTRUCT" target="Code LLMs">
  <data key="d5">16.0</data>
  <data key="d6">HPC-INSTRUCT is a specialized dataset designed to improve code LLMs' performance in HPC contexts.&lt;SEP&gt;HPC-INSTRUCT is a specialized synthetic dataset designed to improve code LLMs' performance in HPC contexts.</data>
  <data key="d7">dataset specialization, domain adaptation</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="StarCoder2" target="Data">
  <data key="d5">14.0</data>
  <data key="d6">StarCoder2 trained on The Stack v2 dataset, which highlights the importance of data quality over quantity in training code LLMs.</data>
  <data key="d7">dataset impact, data quality</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="StarCoder2" target="Comparison with other models">
  <data key="d5">18.0</data>
  <data key="d6">StarCoder2 is compared against Magicoder, Phind-V2, Gemini-1.5-flash, and GPT-3.5/GPT-4 in terms of training data, size, and performance in code generation tasks."|&lt;SEP&gt;StarCoder2 is compared to Magicoder, Phind-V2, Gemini-1.5-flash, GPT-3.5, and GPT-4 in terms of training data, model size, and code generation performance."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fine-tuning" target="Synthetic Dataset">
  <data key="d5">18.0</data>
  <data key="d6">The synthetic dataset is used to fine-tune pre-trained code LLMs to enhance their ability to generate parallel code.&lt;SEP&gt;The synthetic dataset is used to further train pre-trained code LLMs, enhancing their ability to generate accurate parallel code.</data>
  <data key="d7">training data, model improvement</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fine-tuning" target="Performance">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning on datasets like HPC-I NSTRUCT enhances models' capabilities in code correctness and efficiency.&lt;SEP&gt;Fine-tuning on datasets such as HPC-I NSTRUCT improves model efficacy in code generation tasks.</data>
  <data key="d7">training impact, task optimization</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fine-tuning" target="Code LLMs for HPC">
  <data key="d5">18.0</data>
  <data key="d6">Fine-tuning improves the ability of general language models to perform well on HPC-specific code generation tasks by training on relevant datasets.&lt;SEP&gt;Fine-tuning is the methodology used to adapt general language models to perform effectively on HPC code generation tasks."|</data>
  <data key="d7">9&lt;SEP&gt;Methodology, domain adaptation</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fine-tuning" target="HPC-Coder">
  <data key="d5">16.0</data>
  <data key="d6">HPC-Coder models are created through fine-tuning processes using synthetic and real HPC data."|&lt;SEP&gt;HPC-Coder models are developed through fine-tuning processes using synthetic and real HPC datasets to enhance their code generation capabilities.</data>
  <data key="d7">8&lt;SEP&gt;Model development</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fine-tuning" target="Training datasets">
  <data key="d5">9.0</data>
  <data key="d6">Training datasets such as The Stack and The Pile are used for pre-training and fine-tuning models for domain-specific tasks like HPC code generation.</data>
  <data key="d7">training data</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Fine-tuning" target="Large Language Models for Code">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning</data>
  <data key="d7">Models are fine-tuned on domain-specific corpora to enhance their performance in specialized tasks such as HPC code generation.</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Fine-tuning" target="Adapters">
  <data key="d5">9.0</data>
  <data key="d6">Adapters are used to fine-tune models efficiently by inserting trainable modules without updating the entire model.</data>
  <data key="d7">model adaptation, efficiency</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-tuning" target="Regulatory Compliance">
  <data key="d5">7.0</data>
  <data key="d6">Fine-tuning processes are used to align LLMs with regulations such as data protection and industry standards."|&gt;"regulatory alignment, model safety</data>
  <data key="d7">7</data>
  <data key="d8">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-tuning" target="Computational Resources">
  <data key="d5">8.0</data>
  <data key="d6">Access to high-performance hardware is essential for effective fine-tuning of large models, influencing feasibility and scale."|&gt;"resource dependency, training capability</data>
  <data key="d7">8</data>
  <data key="d8">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-tuning" target="Daniel M Ziegler et al.">
  <data key="d5">8.0</data>
  <data key="d6">They explored fine-tuning language models based on human preferences."|</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-tuning" target="Training">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning involves training models on curated datasets to improve their performance on specific tasks such as code generation."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Fine-tuning" target="Model Selection">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning improves the models' capabilities, which are then evaluated through model selection processes to identify the best performing model for downstream tasks.</data>
  <data key="d7">model optimization, evaluation</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Fine-tuning" target="Dataset of for loops with OpenMP pragmas">
  <data key="d5">14.0</data>
  <data key="d6">Fine-tuning involves adapting models on datasets containing specific code structures to improve pragma generation capabilities.&lt;SEP&gt;Fine-tuning involves training models on datasets containing specific code patterns to improve their ability to generate correct pragmas.</data>
  <data key="d7">model adaptation, dataset training&lt;SEP&gt;model training, dataset adaptation</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Fine-tuning" target="PolyCoder+HPC">
  <data key="d5">18.0</data>
  <data key="d6">Further training on HPC data improves PolyCoder's ability to generate HPC-specific code."|&lt;SEP&gt;The process of further training PolyCoder on HPC source code improves its ability to generate valid HPC code.</data>
  <data key="d7">9&lt;SEP&gt;training process, model improvement</data>
  <data key="d8">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Evaluation" target="GLUE Benchmark">
  <data key="d5">16.0</data>
  <data key="d6">GLUE provides a standardized multi-task benchmark to evaluate and compare the performance of NLP models.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Model Evaluation" target="SuperGLUE">
  <data key="d5">8.0</data>
  <data key="d6">SuperGLUE is a more challenging benchmark for assessing the general language understanding capabilities of models, building upon GLUE.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Model Evaluation" target="BLEU Score">
  <data key="d5">16.0</data>
  <data key="d6">BLEU scores are used to assess the similarity of generated solutions to reference solutions, though overlap indicates limitations in measuring functional correctness.&lt;SEP&gt;BLEU scores measure the similarity between generated solutions and references, but their overlap indicates limitations in assessing functional correctness.</data>
  <data key="d7">evaluation metric, solution quality</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Evaluation" target="Sample Heuristics">
  <data key="d5">8.0</data>
  <data key="d6">Sample heuristics like selecting solutions with highest mean log-probability improve the accuracy of model performance evaluation.</data>
  <data key="d7">evaluation improvement, heuristics</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="ParEval" target="Model Performance Metrics">
  <data key="d5">18.0</data>
  <data key="d6">ParEval benchmarks are used to evaluate and compare the performance and efficiency of different HPC code models.&lt;SEP&gt;ParEval benchmarks are used to evaluate and compare the performance of different HPC code generation models."|</data>
  <data key="d7">9&lt;SEP&gt;Benchmarking, evaluation</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ParEval" target="Scientific and Parallel Computing Tasks">
  <data key="d5">7.0</data>
  <data key="d6">ParEval contains tasks related to scientific and parallel computing, serving as the basis for model evaluation.</data>
  <data key="d7">task set, benchmark content</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="ParEval" target="LLMs">
  <data key="d5">9.0</data>
  <data key="d6">ParEval is designed to evaluate the performance of LLMs in generating parallel HPC code across diverse problem types and execution models.</data>
  <data key="d7">evaluation purpose, benchmarking</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="ParEval" target="Prompts">
  <data key="d5">8.0</data>
  <data key="d6">The prompts are used within ParEval to systematically test LLMs' ability to generate code for various computational problems.</data>
  <data key="d7">testing methodology, problem design</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="ParEval" target="Evaluation Techniques">
  <data key="d5">8.0</data>
  <data key="d6">ParEval employs advanced evaluation methods to assess the correctness and performance of generated code.</data>
  <data key="d7">assessment methods, performance evaluation</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="ParEval" target="MBPP results">
  <data key="d5">16.0</data>
  <data key="d6">MBPP results are derived from the evaluation process within ParEval assessing code generation performance.&lt;SEP&gt;MBPP results are derived from the performance evaluations conducted within ParEval, reflecting model capabilities.</data>
  <data key="d7">benchmarking, performance evaluation&lt;SEP&gt;performance metrics, benchmarking</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="ParEval" target="pass@1 score">
  <data key="d5">16.0</data>
  <data key="d6">The pass@1 score is an outcome of the evaluation framework, indicating the success rate of generated code samples.&lt;SEP&gt;The pass@1 score reflects the model's ability to generate correct code on the first try within the evaluation framework.</data>
  <data key="d7">performance outcome, evaluation</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="HPC-I NSTRUCT" target="Model Fine-Tuning">
  <data key="d5">16.0</data>
  <data key="d6">HPC-I NSTRUCT provides the synthetic dataset used for fine-tuning HPC code LLMs.</data>
  <data key="d7">dataset application, training data</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="fine-tuning" target="Selecting a Pre-trained Model">
  <data key="d5">8.0</data>
  <data key="d6">Choosing an appropriate pre-trained model influences the success of subsequent fine-tuning on HPC code tasks.</data>
  <data key="d7">model selection, fine-tuning effectiveness</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="fine-tuning" target="AxoNN">
  <data key="d5">8.0</data>
  <data key="d6">AxoNN framework facilitates the parallelization and automation of model fine-tuning across multiple GPUs.</data>
  <data key="d7">training efficiency, hardware utilization</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="fine-tuning" target="Codex">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning Codex on correctly implemented functions improves its ability to generate accurate solutions, indicating a training relationship.</data>
  <data key="d7">training, performance improvement</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="fine-tuning" target="training infrastructure">
  <data key="d5">14.0</data>
  <data key="d6">The training infrastructure supports the fine-tuning of large models like GPT on code datasets, enabling improved performance for code generation tasks.&lt;SEP&gt;The training infrastructure supports the process of fine-tuning large language models on code datasets to enhance their code generation capabilities.</data>
  <data key="d7">7</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="fine-tuning" target="formal analysis">
  <data key="d5">10.0</data>
  <data key="d6">Formal analysis can be used to filter or evaluate datasets for fine-tuning models to enhance code quality and safety.</data>
  <data key="d7">methodology, data filtering</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="fine-tuning" target="Codex models">
  <data key="d5">18.0</data>
  <data key="d6">Fine-tuning</data>
  <data key="d7">Fine-tuning Codex models on high-quality, bug-free code aims to improve their alignment and reduce bugs in generated code.</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="instruction masking" target="performance">
  <data key="d5">8.0</data>
  <data key="d6">Instruction masking during fine-tuning enhances the model's ability to generate accurate parallel code by preventing it from learning undesirable instruction tokens.</data>
  <data key="d7">training technique, model accuracy</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="synthetic dataset" target="model training">
  <data key="d5">14.0</data>
  <data key="d6">The synthetic dataset HPC-I NSTRUCT is used to train and evaluate code LLMs like HPC-Coder-V2.</data>
  <data key="d7">training data, model evaluation</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="model size" target="performance">
  <data key="d5">12.0</data>
  <data key="d6">The size of a code LLM influences its ability to learn from synthetic data and perform effectively on parallel code generation tasks.</data>
  <data key="d7">capacity, generalization</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="model size" target="LLMs">
  <data key="d5">14.0</data>
  <data key="d6">Larger LLMs, like GPT-4, tend to perform better on complex problem types such as graph problems, indicating an advantage of increased model capacity."|&lt;SEP&gt;Larger models like GPT-4 tend to perform better on complex problems such as graph problems, showing the benefit of increased capacity."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="model size" target="risks">
  <data key="d5">12.0</data>
  <data key="d6">Larger models tend to exhibit greater risks of misalignment and bias, increasing safety concerns.</data>
  <data key="d7">model capacity, risk escalation</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="knowledge distillation" target="smaller model">
  <data key="d5">20.0</data>
  <data key="d6">Knowledge distillation involves using a large model to generate data for training smaller models, aiming to preserve performance while reducing complexity.</data>
  <data key="d7">model efficiency, training data generation</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="training data" target="performance">
  <data key="d5">7.0</data>
  <data key="d6">High-quality training data like HPC-I NSTRUCT improves the performance of code LLMs in parallel code generation.</data>
  <data key="d7">data quality, model accuracy</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="performance" target="hyperparameters">
  <data key="d5">8.0</data>
  <data key="d6">Hyperparameters are tuned to optimize model training performance and resource utilization.</data>
  <data key="d7">training optimization, hyperparameter tuning</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="performance" target="parallel code">
  <data key="d5">16.0</data>
  <data key="d6">Performance metrics like efficiency@1 and speedup@1 evaluate how well the generated code performs in runtime and scalability.&lt;SEP&gt;The study finds that even correct parallel code generated by LLMs is often not performant or scalable.</data>
  <data key="d7">efficiency, scalability&lt;SEP&gt;runtime performance, scalability</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance" target="speedup">
  <data key="d5">18.0</data>
  <data key="d6">Performance gains of up to 12.43x and additional concurrency in benchmarks demonstrate the effectiveness of the optimization prototype."|&gt;"performance gains, benchmarking&lt;SEP&gt;Performance improvements up to 12.43x and additional concurrency reveal the effectiveness of the optimization prototype."|&gt;"performance gains, benchmarking</data>
  <data key="d7">9</data>
  <data key="d8">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="performance" target="GPT-J 6B">
  <data key="d5">8.0</data>
  <data key="d6">GPT-J's pass@1 of 11.62% signifies notable advancement in code generation capabilities.</data>
  <data key="d7">model effectiveness, code synthesis</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="performance" target="TABNINE">
  <data key="d5">6.0</data>
  <data key="d6">TabNine's relatively low pass@1 of 2.58% suggests room for improvement in code generation quality.</data>
  <data key="d7">model comparison, performance</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="performance" target="Codex Models">
  <data key="d5">8.0</data>
  <data key="d6">Various Codex versions demonstrate increasing success rates with larger parameter counts, indicating a positive correlation between size and accuracy.</data>
  <data key="d7">model size, performance correlation</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="performance" target="Codex-S">
  <data key="d5">17.0</data>
  <data key="d6">Codex-S demonstrates higher pass@k scores than Codex, indicating superior performance in code generation tasks.&lt;SEP&gt;Codex-S outperforms Codex on pass@1 and pass@100, indicating improved efficiency and accuracy in code generation.</data>
  <data key="d7">model comparison, performance improvement</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="performance" target="multiple samples">
  <data key="d5">14.0</data>
  <data key="d6">Generating multiple outputs from models can improve the likelihood of producing correct code.&lt;SEP&gt;Generating multiple samples from models can improve the chances of obtaining correct, diverse, or higher-quality code outputs.</data>
  <data key="d7">sampling, performance</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="performance" target="language modeling scores">
  <data key="d5">8.0</data>
  <data key="d6">HPC-related code models achieve higher language modeling scores compared to other models, indicating better understanding of domain-specific code.</data>
  <data key="d7">model evaluation, performance comparison</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Size" target="Data">
  <data key="d5">14.0</data>
  <data key="d6">The combined data impacts the performance of models of different sizes, affecting their accuracy and resource needs.&lt;SEP&gt;The datasets used for fine-tuning influence the performance of models of various sizes, affecting their accuracy and resource requirements.</data>
  <data key="d7">data influence, model performance</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="Performance">
  <data key="d5">32.0</data>
  <data key="d6">Increasing model size from small to medium significantly improves performance, with diminishing returns beyond that.&lt;SEP&gt;Increasing model size from small to medium significantly improves performance, with diminishing returns for larger sizes.&lt;SEP&gt;Larger models tend to perform better but require more computational resources, illustrating a trade-off in model deployment.&lt;SEP&gt;Larger models tend to perform better on code generation tasks but require more computational resources, illustrating a trade-off.</data>
  <data key="d7">model scaling, performance impact&lt;SEP&gt;performance trade-offs, resource considerations</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="Trade-offs">
  <data key="d5">9.0</data>
  <data key="d6">Larger models offer better performance but demand more resources, highlighting the trade-off between accuracy and practicality.</data>
  <data key="d7">resource-performance trade-off</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="Knowledge Distillation">
  <data key="d5">7.0</data>
  <data key="d6">Knowledge distillation explains why larger models like 16B do not surpass the performance of teacher models and why performance gains plateau with increasing size.</data>
  <data key="d7">training technique, performance limit</data>
  <data key="d8">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="Model Performance Metrics">
  <data key="d5">14.0</data>
  <data key="d6">Larger models tend to achieve higher pass rates and throughput but require more memory and computational resources.&lt;SEP&gt;Larger models tend to perform better on benchmarks like pass@1 but require more memory and computational resources."|</data>
  <data key="d7">7&lt;SEP&gt;Scaling, resource trade-offs</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="Prompt Initialization">
  <data key="d5">6.0</data>
  <data key="d6">Larger models tend to be more robust to initialization strategies, making prompt tuning more effective as model size increases.</data>
  <data key="d7">model robustness, scalability</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Size" target="LLMs">
  <data key="d5">14.0</data>
  <data key="d6">Larger models generally have higher capacity and better performance but require more computational resources.&lt;SEP&gt;Larger models generally have higher capacity and can perform better on complex tasks, but require more resources.</data>
  <data key="d7">capacity, scalability&lt;SEP&gt;performance, scalability</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Size" target="Parameters">
  <data key="d5">16.0</data>
  <data key="d6">The number of parameters (e.g., 12B) determines the capacity of the model to learn complex code patterns and influences performance.&lt;SEP&gt;The size of GPT models, such as 12B parameters, influences their capacity to learn complex patterns in code.</data>
  <data key="d7">model capacity, complexity</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Size" target="Power Law Scaling">
  <data key="d5">16.0</data>
  <data key="d6">Model performance, such as test loss, improves following a power law as model size increases, indicating larger models are more effective.&lt;SEP&gt;Test loss decreases following a power law pattern as model size increases, indicating improved performance with larger models.</data>
  <data key="d7">scaling law, performance trend</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Size" target="Evaluation Results">
  <data key="d5">16.0</data>
  <data key="d6">Larger models tend to achieve lower test loss and higher pass@k scores, demonstrating improved code generation performance.&lt;SEP&gt;Larger models tend to have lower test loss and higher pass@k scores, indicating better performance in code synthesis.</data>
  <data key="d7">model capacity, performance</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Prompt Construction" target="Synthetic Data Generation">
  <data key="d5">12.0</data>
  <data key="d6">Designing prompts influences the diversity and quality of generated code samples used for training.&lt;SEP&gt;Designing prompts influences the diversity and usefulness of generated code samples for training.</data>
  <data key="d7">prompt engineering, data diversity</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Prompt Construction" target="Progressive Prompts">
  <data key="d5">12.0</data>
  <data key="d6">Progressive prompts incorporate prompts from previous tasks into current prompts to support continual learning and task transfer.&lt;SEP&gt;Progressive prompts incorporate prompts from previous tasks into current prompts, supporting continual learning.</data>
  <data key="d7">incremental learning, prompt concatenation</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Construction" target="Template-based Prompting">
  <data key="d5">16.0</data>
  <data key="d6">Templates reformulate tasks into masked word prediction, leveraging pre-training and improving adaptability.&lt;SEP&gt;Uses predefined templates to reformulate tasks, such as converting classification into masked word prediction, leveraging pre-trained language models.</data>
  <data key="d7">task reformulation, NLP tasks</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Construction" target="Dynamic Prompting">
  <data key="d5">16.0</data>
  <data key="d6">Learns prompt parameters dynamically for each instance, optimizing position, length, and content.&lt;SEP&gt;Learns prompt position, length, and content dynamically per instance, optimizing prompt effectiveness based on input features.</data>
  <data key="d7">dynamic adaptation, input specificity&lt;SEP&gt;dynamic adaptation, instance-specific optimization</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Construction" target="Discreet Prompts">
  <data key="d5">7.0</data>
  <data key="d6">Designs explicit language prompts with specific phrases or templates to guide model behavior for particular tasks.</data>
  <data key="d7">prompt design, task guidance</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Construction" target="Continuous Prompts">
  <data key="d5">8.0</data>
  <data key="d6">Employs learned prompt embeddings that are inserted into input sequences without explicit language templates, enabling flexible adaptation.</data>
  <data key="d7">embedding-based prompts, flexibility</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Construction" target="WARP">
  <data key="d5">7.0</data>
  <data key="d6">Adopts all three prompt intersection strategies with a '[MASK]' token for classification, enhancing prompt versatility.</data>
  <data key="d7">prompt strategies, classification</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Construction" target="Prefix-tuning">
  <data key="d5">8.0</data>
  <data key="d6">Prepending tunable prompts to sentence embeddings influences subsequent model outputs by leveraging autoregressive properties.</data>
  <data key="d7">prompt placement, autoregressive models</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Construction" target="KnowPrompt">
  <data key="d5">9.0</data>
  <data key="d6">Inserts '[MASK]' tokens between entities and trains virtual type words to improve relation extraction performance.</data>
  <data key="d7">relation extraction, prompt design</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Construction" target="KiPT">
  <data key="d5">8.0</data>
  <data key="d6">Reformulates event detection as a sequence generation task by identifying trigger words and prepending them with relevant prompts.</data>
  <data key="d7">event detection, sequence reformulation</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Ablation Studies" target="Choice of Base Model and Instruction Masking">
  <data key="d5">8.0</data>
  <data key="d6">Ablation studies involve systematically altering base model choices and instruction masking to observe their effects on model performance in code generation tasks.</data>
  <data key="d7">study methodology, model performance</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Ablation Studies" target="Choice of Base Model">
  <data key="d5">8.0</data>
  <data key="d6">Ablation studies compare different base models to determine how their initial capacities influence fine-tuning results.</data>
  <data key="d7">study methodology, model impact</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Ablation Studies" target="Instruction Masking">
  <data key="d5">7.0</data>
  <data key="d6">Ablation studies assess the effect of masking instructions during fine-tuning on model performance and learning efficiency.</data>
  <data key="d7">methodology, training process</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Ablation Studies" target="Impact Analysis">
  <data key="d5">18.0</data>
  <data key="d6">Ablation studies analyze how different training configurations affect model performance, including the impact of base model choice and instruction masking."|&lt;SEP&gt;Ablation studies analyze how different training configurations and data volumes affect model performance, especially in parallel code generation."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance Evaluation" target="Models">
  <data key="d5">9.0</data>
  <data key="d6">Different fine-tuned models are assessed against benchmarks like ParEval to determine their effectiveness.</data>
  <data key="d7">model assessment, benchmark comparison</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Comparison" target="Models">
  <data key="d5">16.0</data>
  <data key="d6">Models like StarCoder2, Magicoder, and Phind-V2 are compared based on their pass@k scores and resource requirements to assess their effectiveness.&lt;SEP&gt;Models such as StarCoder2, Magicoder, and Phind-V2 are compared based on their pass@k scores, memory requirements, and throughput to evaluate their relative performance.</data>
  <data key="d7">comparative analysis, performance benchmarking</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Comparison" target="Impact of Bias">
  <data key="d5">7.0</data>
  <data key="d6">Comparing biases in GPT-3 and Codex helps assess the extent and nature of biases in AI models.</data>
  <data key="d7">model evaluation, bias assessment</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Open-source Codebases" target="Seed Snippets">
  <data key="d5">16.0</data>
  <data key="d6">Seed snippets are sourced from open-source codebases like The Stack V2 to initiate diverse synthetic data generation.</data>
  <data key="d7">data sourcing, diversity</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Generation of Synthetic Data" target="Seed Snippets">
  <data key="d5">8.0</data>
  <data key="d6">Seed snippets serve as inspiration for LLMs to generate diverse synthetic code samples for training.</data>
  <data key="d7">data generation, seed snippets</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="generation" target="model">
  <data key="d5">7.0</data>
  <data key="d6">Generation involves utilizing models to produce data, code, or outputs, as exemplified by synthetic datasets and code samples.</data>
  <data key="d7">data creation, model application</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="model" target="model performance">
  <data key="d5">7.0</data>
  <data key="d6">Different models are compared based on their pass@1 scores and correctness in parallel code generation.</data>
  <data key="d7">model comparison, performance</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="model" target="model">
  <data key="d5">7.0</data>
  <data key="d6">Models such as GPT-3.5, GPT-4, and open-source variants are evaluated for their capability to generate correct parallel code.</data>
  <data key="d7">model evaluation, capability</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="DeepSeek-Coder" target="parameters">
  <data key="d5">6.0</data>
  <data key="d6">DeepSeek-Coder models with different parameter sizes are fine-tuned to evaluate performance differences.</data>
  <data key="d7">model size, performance comparison</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="dataset" target="fine-tuning datasets">
  <data key="d5">9.0</data>
  <data key="d6">The datasets provide the training samples necessary for adapting models to HPC code tasks.</data>
  <data key="d7">training data, dataset composition</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="dataset" target="evaluation">
  <data key="d5">12.0</data>
  <data key="d6">The HumanEval dataset provides the problems, solutions, and tests used to evaluate the models' performance.</data>
  <data key="d7">benchmark, data source</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="ablation studies" target="choice of base model">
  <data key="d5">8.0</data>
  <data key="d6">Ablation studies compare how different base models affect fine-tuning results in code generation tasks.</data>
  <data key="d7">model comparison, experimental analysis</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Impact of Data Quantity and Quality" target="Synthetic Data Quality">
  <data key="d5">9.0</data>
  <data key="d6">The quality of synthetic data generated by different models affects the performance of fine-tuned models, with more data not always leading to better results, highlighting a trade-off between quantity and quality.</data>
  <data key="d7">data impact, model performance</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="MPI Code Samples" target="Impact of Data Quantity">
  <data key="d5">9.0</data>
  <data key="d6">Increasing the number of MPI code samples in the dataset is hypothesized to improve the model's ability to generate MPI code, up to a certain point.</data>
  <data key="d7">data impact, model capability</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Synthetic Data" target="Impact of Data Quality">
  <data key="d5">10.0</data>
  <data key="d6">Higher quality synthetic data, generated by different models, is presumed to enhance the model's code generation performance, but the trade-off with quantity is under investigation.</data>
  <data key="d7">data quality, performance</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Synthetic Data" target="Model Fine-Tuning">
  <data key="d5">16.0</data>
  <data key="d6">Synthetic data from HPC-I NSTRUCT is used to fine-tune HPC code LLMs, impacting their performance.&lt;SEP&gt;Synthetic data generated from LLMs and open-source code is used to train and evaluate HPC code models.</data>
  <data key="d7">training data, evaluation&lt;SEP&gt;training data, model improvement</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Synthetic Data" target="Performance of HPC Code LLMs">
  <data key="d5">8.0</data>
  <data key="d6">Synthetic data quality impacts the performance of models in generating parallel code.</data>
  <data key="d7">data quality, model performance</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="RX" target="Llama-3-70B">
  <data key="d5">16.0</data>
  <data key="d6">RX and Llama-3-70B are both models studied for fine-tuning and performance evaluation.&lt;SEP&gt;RX and Llama-3-70B are both models studied for fine-tuning, performance comparison, and their impact on code generation tasks.</data>
  <data key="d7">model comparison, data usage</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance" target="High-Quality Data">
  <data key="d5">8.0</data>
  <data key="d6">The quality of parallel code fine-tuning data significantly influences model performance.</data>
  <data key="d7">data quality, model effectiveness</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance" target="Data, Model, and Prompt Configuration">
  <data key="d5">8.0</data>
  <data key="d6">Variations in data, model, and prompt configurations influence the ability of models to generate parallel code.</data>
  <data key="d7">configuration impact, model ability</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance" target="Open-Source Models">
  <data key="d5">8.0</data>
  <data key="d6">The fine-tuned HPC models outperform other open-source models in speed, memory usage, and accuracy.</data>
  <data key="d7">model comparison, efficiency</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance" target="Retrieving More Documents">
  <data key="d5">16.0</data>
  <data key="d6">Retrieving more documents can improve certain task performances like open-domain QA, but may have diminishing returns or trade-offs depending on the model.</data>
  <data key="d7">performance impact, retrieval strategy</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Performance" target="Models">
  <data key="d5">14.0</data>
  <data key="d6">Models trained with different numbers of retrieved documents show varying performance, indicating the importance of optimal retrieval size.</data>
  <data key="d7">training configuration, performance</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Performance" target="Test Time Adjustment">
  <data key="d5">12.0</data>
  <data key="d6">Adjusting the number of retrieved documents at test time can optimize model performance and efficiency.</data>
  <data key="d7">optimization, runtime</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Performance" target="GitHub Copilot">
  <data key="d5">7.0</data>
  <data key="d6">Studies compare GitHub Copilot with genetic programming to evaluate their code synthesis performance in 2022.</data>
  <data key="d7">Results</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Performance" target="Generated code">
  <data key="d5">9.0</data>
  <data key="d6">Generated code is compared against baseline and handwritten implementations to evaluate speedups and slowdowns.</data>
  <data key="d7">performance metrics, code efficiency</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Performance" target="Code Generator">
  <data key="d5">16.0</data>
  <data key="d6">The code generator produces competitive performance for CPU and GPU, though some overhead remains compared to hand-optimized code."|&lt;SEP&gt;The code generator provides competitive performance for CPU and GPU, with some overhead compared to hand-optimized code.</data>
  <data key="d7">performance, optimization, GPU, CPU</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Performance" target="GPT-J">
  <data key="d5">7.0</data>
  <data key="d6">GPT-J's pass@1 performance is between Codex-85M and Codex-300M, indicating comparable effectiveness in code generation.</data>
  <data key="d7">performance comparison, model evaluation</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="ParEval Benchmark" target="Models">
  <data key="d5">36.0</data>
  <data key="d6">Fine-tuned models are evaluated against ParEval to measure their effectiveness in parallel code generation.&lt;SEP&gt;The ParEval benchmark assesses different models' abilities in parallel code generation across diverse problem types and execution models.&lt;SEP&gt;The ParEval benchmark is used to evaluate various models' capabilities in parallel code generation across multiple problem types and execution models.</data>
  <data key="d7">evaluation, benchmarking&lt;SEP&gt;performance assessment, benchmarking</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ParEval Benchmark" target="HPC-Coder-V2-6.7B">
  <data key="d5">18.0</data>
  <data key="d6">HPC-Coder-V2-6.7B was evaluated on the ParEval benchmark, demonstrating its superior performance.</data>
  <data key="d7">model evaluation, benchmarking</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ParEval Benchmark" target="HPC-Coder-V2-16B">
  <data key="d5">9.0</data>
  <data key="d6">HPC-Coder-V2-16B was evaluated on the ParEval benchmark, showing leading performance in parallel code generation.</data>
  <data key="d7">model evaluation, benchmarking</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="pass@k" target="Models">
  <data key="d5">20.0</data>
  <data key="d6">pass@k scores estimate the probability of a model generating at least one correct code solution within k attempts, serving as a key effectiveness metric.&lt;SEP&gt;pass@k scores quantify the probability of models generating at least one correct code solution within k attempts, serving as a key performance indicator.</data>
  <data key="d7">performance measurement, probabilistic evaluation</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="pass@k" target="Codex">
  <data key="d5">19.0</data>
  <data key="d6">Codex's performance is measured by pass@k, which evaluates how often the top k generated samples pass unit tests or correctness criteria.&lt;SEP&gt;Codex's performance is quantified by pass@k metrics, which evaluate the likelihood of generated code passing unit tests within the top k samples.</data>
  <data key="d7">performance evaluation, metrics</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="pass@k" target="Temperature">
  <data key="d5">15.0</data>
  <data key="d6">Optimal temperature settings vary for different models and evaluation metrics, affecting the diversity and success rate of generated code.&lt;SEP&gt;The optimal temperature setting varies for different models and evaluation metrics, affecting the diversity and success rate of generated code.</data>
  <data key="d7">sampling parameter, model tuning&lt;SEP&gt;sampling parameters, model tuning</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="pass@k" target="optimal sampling temperature">
  <data key="d5">7.0</data>
  <data key="d6">Adjusting the temperature affects the success rates of code generation, with optimal values differing per model and task.</data>
  <data key="d7">model tuning, sampling strategy</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Parallel Code Generation Performance">
  <data key="d5">16.0</data>
  <data key="d6">Performance is assessed using Pass@1 scores across different models and training configurations."|&lt;SEP&gt;Performance measured via Pass@1 scores, showing how different models and configurations perform in parallel code tasks."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Taxonomy">
  <data key="d5">9.0</data>
  <data key="d6">A proposed taxonomy aims to standardize evaluation of AI-generated code, addressing current gaps."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Codex">
  <data key="d5">18.0</data>
  <data key="d6">Metrics like pass@k and test loss are used to evaluate Codex's performance in code generation tasks.&lt;SEP&gt;Metrics such as pass@k and test loss evaluate Codex's effectiveness in code generation tasks.</data>
  <data key="d7">performance assessment, evaluation&lt;SEP&gt;performance measurement, evaluation</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Sampling Temperature">
  <data key="d5">14.0</data>
  <data key="d6">Optimal sampling temperature settings vary depending on the pass@k metric, balancing diversity and accuracy in generated code.&lt;SEP&gt;Optimal sampling temperature varies depending on pass@k, with higher temperatures promoting diversity for larger k values.</data>
  <data key="d7">sampling parameter, diversity, accuracy&lt;SEP&gt;sampling parameters, diversity, accuracy</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Framework">
  <data key="d5">18.0</data>
  <data key="d6">The framework assesses models based on their ability to understand and reason over natural language specifications, considering attributes like complexity, expressivity, and reasoning capabilities.&lt;SEP&gt;The framework evaluates code synthesis models based on their ability to understand and reason over natural language specifications, considering attributes like complexity, expressivity, and reasoning capabilities.</data>
  <data key="d7">evaluation, benchmarks, natural language</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Code Completion">
  <data key="d5">14.0</data>
  <data key="d6">Code completion is assessed using metrics like pass@k to determine the correctness of generated code samples.&lt;SEP&gt;Code completion is assessed using metrics like pass@k to determine the correctness of generated code samples."|&lt;"task evaluation, correctness measurement</data>
  <data key="d7">7&lt;SEP&gt;task evaluation, correctness measurement</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Models" target="Figure 7">
  <data key="d5">16.0</data>
  <data key="d6">Figure 7 compares efficiency@1 for different models across ranks and thread counts, showing performance variations.&lt;SEP&gt;Figure 7 compares efficiency@1 for different models across ranks and thread counts, showing relative performance.</data>
  <data key="d7">performance comparison, model efficiency</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="Experiment 2">
  <data key="d5">18.0</data>
  <data key="d6">Experiment 2 assesses how well LLMs translate code and their scalability, providing insights into translation accuracy and resource efficiency.&lt;SEP&gt;Experiment 2 evaluates how well LLMs can translate code and their scalability, providing insights into translation accuracy and resource efficiency.</data>
  <data key="d7">study design, translation performance</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="Translation Tasks">
  <data key="d5">16.0</data>
  <data key="d6">Different LLMs are evaluated for their ability to translate code between execution models and generate correct parallel code.</data>
  <data key="d7">model evaluation, translation capability</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="Efficiency 𝑛@1">
  <data key="d5">14.0</data>
  <data key="d6">Efficiency metrics show that GPT-4 and other models have varying resource utilization, with GPT-4 being among the most efficient.&lt;SEP&gt;Efficiency metrics show that GPT-4 and others have varying resource utilization, with GPT-4 being among the most efficient.</data>
  <data key="d7">resource utilization, model performance</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="pass@1">
  <data key="d5">8.0</data>
  <data key="d6">Models' pass@1 scores are higher when translating code between execution models than generating code from scratch, indicating effective translation capability."|&gt;"translation effectiveness, model capability</data>
  <data key="d7">8</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="Training Dataset">
  <data key="d5">7.0</data>
  <data key="d6">The curated training problems and solutions form the dataset used to fine-tune language models."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Models" target="Code Generation">
  <data key="d5">31.0</data>
  <data key="d6">GPT-Neo+HPC and PolyCoder+HPC perform well in generating valid HPC code, with PolyCoder+HPC leading in accuracy."|&lt;SEP&gt;GPT2+HPC has limited success due to pretraining limitations but benefits from fine-tuning."|&lt;SEP&gt;PolyCoder+HPC demonstrates superior performance in generating HPC code, especially at larger sample sizes, indicating successful domain adaptation."|&lt;SEP&gt;PolyCoder+HPC outperforms other models in generating correct HPC code, especially at higher sample counts, demonstrating effective domain-specific learning.</data>
  <data key="d7">7&lt;SEP&gt;8&lt;SEP&gt;model comparison, performance evaluation</data>
  <data key="d8">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Evaluation Techniques" target="Analysis Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Evaluation techniques are used to measure the effectiveness of domain adaptation methods, guiding improvements."|&gt;"performance assessment, benchmarking</data>
  <data key="d7">8</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Evaluation Techniques" target="Nucleus Sampling">
  <data key="d5">16.0</data>
  <data key="d6">Nucleus sampling is used during code generation to produce diverse outputs by selecting tokens based on a probability threshold.&lt;SEP&gt;Used during code generation to select tokens based on a probability threshold, balancing diversity and relevance.</data>
  <data key="d7">diversity promotion, sampling method&lt;SEP&gt;sampling method, diversity</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Magicoder" target="Fine-tuning Data">
  <data key="d5">16.0</data>
  <data key="d6">Magicoder is a fine-tuned version of DeepseekCoder-6.7B on synthetic data from open-source code, used to improve code modeling capabilities."|&lt;SEP&gt;Magicoder is fine-tuned on synthetic open-source code data to enhance code modeling capabilities."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Magicoder" target="Knowledge distillation of large language models">
  <data key="d5">7.0</data>
  <data key="d6">The survey on knowledge distillation informs the development and training of models like Magicoder, which depend on efficient training techniques.</data>
  <data key="d7">training techniques, model development</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Gemini-1.5-flash" target="Commercial Model">
  <data key="d5">14.0</data>
  <data key="d6">Gemini-1.5-flash is available via API from Google for code generation and related tasks."|&lt;SEP&gt;Gemini-1.5-flash provides API access for code generation from Google."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="GPT-3.5, GPT-4" target="State-of-the-art Models">
  <data key="d5">8.0</data>
  <data key="d6">GPT-3.5 and GPT-4 are advanced models from OpenAI, used for high-level language understanding and generation."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Amount and Quality of Parallel Code Data" target="Training Data Impact">
  <data key="d5">8.0</data>
  <data key="d6">Increasing MPI fine-tuning samples improves the performance of smaller models with diminishing returns for larger models."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Impact of Fine-Tuning Data Volume" target="Training Data Impact">
  <data key="d5">8.0</data>
  <data key="d6">More MPI training samples improve performance for smaller models, with diminishing returns for larger models."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Knowledge Distillation" target="Efficiency in Fine-tuning">
  <data key="d5">7.0</data>
  <data key="d6">Knowledge distillation transfers knowledge to smaller models for efficient deployment and updates."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Distillation" target="Fine-tuning of LLMs">
  <data key="d5">7.0</data>
  <data key="d6">Knowledge distillation can complement fine-tuning by transferring domain-specific knowledge from large models to smaller, more efficient models."|&gt;"knowledge transfer, efficiency</data>
  <data key="d7">7</data>
  <data key="d8">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Pass@1" target="HPC-Coder-V2-6.7B">
  <data key="d5">8.0</data>
  <data key="d6">The pass@1 score for HPC-Coder-V2-6.7B indicates its success rate in solving problems on the first attempt across different problem types and execution models.</data>
  <data key="d7">performance metric, success rate</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Pass@1" target="HPC-Coder-V2-16B">
  <data key="d5">8.0</data>
  <data key="d6">The pass@1 score for HPC-Coder-V2-16B measures its effectiveness in solving problems on the first try across various problem types and models.</data>
  <data key="d7">performance metric, success rate</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Pass@1" target="Phind-V2-34B">
  <data key="d5">8.0</data>
  <data key="d6">The pass@1 score for Phind-V2-34B reflects its ability to solve problems on the first attempt, used for benchmarking.</data>
  <data key="d7">performance measurement, benchmarking</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2-16B" target="ParEval benchmark suite">
  <data key="d5">16.0</data>
  <data key="d6">HPC-Coder-V2-16B is evaluated using the ParEval benchmark suite to assess its code generation performance across different problem types and execution models.&lt;SEP&gt;HPC-Coder-V2-16B is evaluated using the ParEval benchmark suite to measure its performance across different problem types and execution models.</data>
  <data key="d7">benchmarking, evaluation&lt;SEP&gt;evaluation, benchmarking</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2-16B" target="HPC-Coder-V2-6.7B">
  <data key="d5">8.0</data>
  <data key="d6">Both are versions of HPC-Coder models evaluated on similar benchmarks, indicating performance comparison between model sizes and versions.</data>
  <data key="d7">model comparison, performance evaluation</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2-16B" target="Phind-V2-34B">
  <data key="d5">8.0</data>
  <data key="d6">Both models are evaluated on the same benchmark, providing data for comparing their capabilities in handling various computational problems.</data>
  <data key="d7">model comparison, performance metrics</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2-16B" target="Problem Types">
  <data key="d5">7.0</data>
  <data key="d6">HPC-Coder-V2-16B is evaluated across the same set of problem types as the 6.7B version, enabling comparison of performance and scalability.</data>
  <data key="d7">model comparison, evaluation scope</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder" target="Modeling Parallel Programs">
  <data key="d5">18.0</data>
  <data key="d6">HPC-Coder is designed to model and automate tasks related to parallel programs in HPC, including code completion and performance prediction.&lt;SEP&gt;HPC-Coder is designed to model and automate tasks related to parallel programs in HPC, including code completion, decoration, and performance prediction."|</data>
  <data key="d7">application, core functionality&lt;SEP&gt;application, specialization</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="Dataset of HPC and Scientific Codes">
  <data key="d5">16.0</data>
  <data key="d6">HPC-Coder is trained and fine-tuned on a curated dataset of HPC and scientific source code to adapt general language models to the scientific computing domain."|&lt;SEP&gt;HPC-Coder is trained and fine-tuned on a dataset comprising HPC and scientific source code to adapt general language models to domain-specific tasks.</data>
  <data key="d7">training data, domain adaptation</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="Code Completion">
  <data key="d5">14.0</data>
  <data key="d6">HPC-Coder can auto-complete HPC functions, demonstrating its ability to generate code snippets based on context.&lt;SEP&gt;HPC-Coder successfully auto-completes HPC functions, demonstrating its ability to generate contextually relevant code snippets."|</data>
  <data key="d7">functionality, code generation</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="Code Decoration with OpenMP Pragmas">
  <data key="d5">16.0</data>
  <data key="d6">HPC-Coder can automatically add OpenMP pragmas to loops, improving parallelization and performance."|&lt;SEP&gt;HPC-Coder can decorate loops with OpenMP pragmas, improving parallelization.</data>
  <data key="d7">performance enhancement, parallelization</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="Performance Change Modeling">
  <data key="d5">16.0</data>
  <data key="d6">HPC-Coder can model performance changes in scientific codes and solutions, indicating its application in performance prediction.&lt;SEP&gt;HPC-Coder models performance variations in scientific codes and solutions, indicating its application in performance prediction."|</data>
  <data key="d7">performance prediction, modeling</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="Applications">
  <data key="d5">7.0</data>
  <data key="d6">HPC-Coder's automation capabilities can be applied to improve productivity, correctness, and performance in scientific HPC software."|</data>
  <data key="d7">applications, impact</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="Implications">
  <data key="d5">7.0</data>
  <data key="d6">The development of HPC-Coder implies significant benefits in automating complex coding tasks, reducing errors, and optimizing performance in scientific computing workflows."|</data>
  <data key="d7">applications, implications</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="dataset of HPC and scientific codes">
  <data key="d5">8.0</data>
  <data key="d6">HPC-Coder is trained on the curated dataset of HPC and scientific codes to learn domain-specific patterns.</data>
  <data key="d7">training data, domain specialization</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="code generation tests">
  <data key="d5">20.0</data>
  <data key="d6">HPC-Coder outperforms other models on HPC-specific code generation tasks, demonstrating its effectiveness.</data>
  <data key="d7">model evaluation, HPC tasks</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="OpenMP pragmas">
  <data key="d5">18.0</data>
  <data key="d6">HPC-Coder can accurately label OpenMP pragmas in source code, facilitating parallel code analysis.&lt;SEP&gt;HPC-Coder can accurately label OpenMP pragmas, facilitating parallel code analysis and understanding.</data>
  <data key="d7">code annotation, parallelism&lt;SEP&gt;code labeling, parallelism</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="performance prediction">
  <data key="d5">18.0</data>
  <data key="d6">The model can predict relative performance of code changes with up to 92% accuracy, aiding performance optimization.&lt;SEP&gt;The model predicts the relative performance of code modifications with high accuracy, supporting performance tuning.</data>
  <data key="d7">performance modeling, predictive accuracy</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="open-source repositories">
  <data key="d5">8.0</data>
  <data key="d6">HPC-Coder is trained on a curated dataset from open repositories to learn HPC and scientific coding patterns.</data>
  <data key="d7">training data, domain-specific learning</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="PolyCoder+HPC">
  <data key="d5">16.0</data>
  <data key="d6">PolyCoder+HPC is selected as HPC-Coder for further analysis due to its high training and code generation scores.&lt;SEP&gt;PolyCoder+HPC is selected as HPC-Coder for further evaluation based on its high training and code generation scores.</data>
  <data key="d7">model selection, application</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Synthetic HPC Data" target="Data Collection">
  <data key="d5">16.0</data>
  <data key="d6">Synthetic HPC data is generated to augment training datasets, addressing data scarcity and improving model performance."|&lt;SEP&gt;Synthetic data generated using LLMs and open-source code to supplement real data, aiming to improve model training and performance.</data>
  <data key="d7">8&lt;SEP&gt;Data augmentation, synthetic data</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Data Quality" target="Model Performance Metrics">
  <data key="d5">16.0</data>
  <data key="d6">High-quality data leads to better fine-tuning results, surpassing the effects of simply increasing data quantity.&lt;SEP&gt;High-quality data leads to better fine-tuning results, surpassing the impact of merely increasing data quantity."|</data>
  <data key="d7">8&lt;SEP&gt;Data impact, quality vs. quantity</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance Metrics" target="Model Architecture">
  <data key="d5">16.0</data>
  <data key="d6">The architecture influences the efficiency, throughput, and accuracy of the models in code generation tasks.&lt;SEP&gt;The architecture influences the model's efficiency, throughput, and accuracy in code generation tasks."|</data>
  <data key="d7">8&lt;SEP&gt;Design, performance</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Data Collection" target="Training Setup and Methodology">
  <data key="d5">9.0</data>
  <data key="d6">Collected datasets of HPC source code are fundamental to the training setup and methodology, enabling model fine-tuning.</data>
  <data key="d7">dataset preparation, training data</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder-V2-6.7B" target="Phind-V2-34B">
  <data key="d5">8.0</data>
  <data key="d6">Both are AI models evaluated on the same benchmark, allowing comparison of their problem-solving performance across problem types and execution models.</data>
  <data key="d7">model comparison, benchmark evaluation</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2-6.7B" target="Problem Types">
  <data key="d5">7.0</data>
  <data key="d6">HPC-Coder-V2-6.7B is tested across multiple problem types, such as serial, omp, kokkos, cuda, hip, mpi, and mpi+omp, to evaluate its versatility and performance.</data>
  <data key="d7">evaluation scope, problem variety</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Fine-Tuning" target="Insights">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning choices such as data quality and instruction masking influence model performance.</data>
  <data key="d7">training strategies, model effectiveness</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Scaling" target="Performance Enhancement">
  <data key="d5">7.0</data>
  <data key="d6">Scaling models by increasing size or data improves their capacity for downstream tasks, facilitating better domain adaptation and generalization.</data>
  <data key="d7">capacity, performance</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Code llama" target="Gpt-4o system card">
  <data key="d5">6.0</data>
  <data key="d6">Both are models and documentation related to large language models and their applications in code and system design.</data>
  <data key="d7">related models, documentation</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Deepseek-coder" target="Deepseek-coder-v2">
  <data key="d5">8.0</data>
  <data key="d6">Deepseek-coder-v2 is an advancement over Deepseek-coder, aiming to improve code intelligence and break barriers of closed-source models.</data>
  <data key="d7">model evolution, code intelligence</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Deepseek-coder" target="Wizardcoder">
  <data key="d5">14.0</data>
  <data key="d6">Wizardcoder is an evolution or specialized application of deep code models like Deepseek-coder, enhanced with instruct techniques.</data>
  <data key="d7">model enhancement, code intelligence</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Efficient large scale language modeling with mixtures of experts" target="Exploiting sparsity in pruned neural networks">
  <data key="d5">13.0</data>
  <data key="d6">Both techniques aim to optimize large language model training by reducing computational resources and increasing efficiency.</data>
  <data key="d7">optimization, training efficiency</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fixing weight decay regularization in Adam" target="Large language models">
  <data key="d5">17.0</data>
  <data key="d6">The technique aims to improve the training stability and performance of large language models using Adam optimizer.</data>
  <data key="d7">training stability, optimization</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fixing weight decay regularization in Adam" target="arXiv:1711.05101">
  <data key="d5">16.0</data>
  <data key="d6">The paper presents a methodology for improving weight decay regularization within the Adam optimizer to enhance neural network training.</data>
  <data key="d7">optimization, regularization, neural networks</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Optimization" target="Clip-Tuning">
  <data key="d5">7.0</data>
  <data key="d6">Clip-Tuning employs deterministic clipping to optimize prompts by learning intrinsic prompt embeddings in models with restricted access.</data>
  <data key="d7">method, optimization</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Optimization" target="Task-oriented Fine-tuning">
  <data key="d5">8.0</data>
  <data key="d6">Task-oriented fine-tuning modifies model parameters to align better with specific tasks, often requiring selective updates.</data>
  <data key="d7">approach, task-specific</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Optimization" target="Weight Decay Regularization">
  <data key="d5">16.0</data>
  <data key="d6">Regularization method that penalizes large weights to prevent overfitting; recent fixes have improved its effectiveness in Adam optimizer.&lt;SEP&gt;Weight decay helps prevent overfitting during training, with recent improvements fixing issues in Adam optimizer.</data>
  <data key="d7">Methodologies, Results</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Knowledge Transfer" target="Large Language Models (LLMs)">
  <data key="d5">8.0</data>
  <data key="d6">Knowledge transfer models facilitate the adaptation of general LLMs to specific domains by applying structured knowledge and transfer learning techniques."|</data>
  <data key="d7">knowledge transfer, model adaptation</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Pytorch" target="Deep Learning Library">
  <data key="d5">16.0</data>
  <data key="d6">Pytorch is a high-performance deep learning library used for developing neural network models, as described by Chilamkurthy et al. in 2019.</data>
  <data key="d7">software, deep learning</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Weight Decay Regularization" target="Loshchilov and Hutter">
  <data key="d5">14.0</data>
  <data key="d6">They fixed issues related to weight decay regularization in Adam optimizer, enhancing model training stability.</data>
  <data key="d7">regularization, optimization</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Large Language Models Trained on Code" target="Code Generation Tools">
  <data key="d5">18.0</data>
  <data key="d6">AI models like Codex are trained on large code datasets to generate and assist with programming tasks, influencing coding practices and societal impacts.&lt;SEP&gt;Large language models like Codex are designed to generate code and assist programmers, influencing coding practices and societal impacts.</data>
  <data key="d7">technology influence, automation</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Phind-codellama-34b-v2" target="Code Model">
  <data key="d5">18.0</data>
  <data key="d6">This tool is a specific large language model designed for code tasks, available publicly for use in 2023.</data>
  <data key="d7">software, code generation</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Gemini" target="Multimodal Models">
  <data key="d5">16.0</data>
  <data key="d6">Gemini models are capable of processing multiple data modalities, such as text and images, indicating their high versatility.</data>
  <data key="d7">multimodal, AI models</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Language Models as Few-Shot Learners" target="Learning Capability">
  <data key="d5">18.0</data>
  <data key="d6">This theory explains that large language models can perform new tasks effectively with minimal examples, demonstrating their few-shot learning ability.</data>
  <data key="d7">learning, AI capability</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Gpt-4" target="Advanced Language Model">
  <data key="d5">40.0</data>
  <data key="d6">Gpt-4 is a state-of-the-art large language model capable of complex understanding and generation tasks, as detailed in the 2023 report.&lt;SEP&gt;Gpt-4 represents the latest in language model development, with enhanced capabilities for understanding and generating complex language.&lt;SEP&gt;Gpt-4 represents the latest in language model development, with enhanced understanding and generation abilities.</data>
  <data key="d7">AI, language understanding&lt;SEP&gt;Tools, Applications/Implications</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Mpirigen" target="MPI Code Generation Tool">
  <data key="d5">16.0</data>
  <data key="d6">Mpirigen automates MPI code generation using domain-specific language models, streamlining parallel programming development.</data>
  <data key="d7">code generation, HPC</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Llm4vv" target="Compiler Validation">
  <data key="d5">14.0</data>
  <data key="d6">Llm4vv uses large language models to create test suites that validate compiler correctness and performance.</data>
  <data key="d7">software testing, compiler</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Data Race Detection Using Large Language Models" target="Application">
  <data key="d5">16.0</data>
  <data key="d6">Applying language models to detect data races in concurrent programming environments.&lt;SEP&gt;Using language models to detect data races in concurrent code.</data>
  <data key="d7">application, concurrency</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Scope is All You Need" target="Model Transformation">
  <data key="d5">18.0</data>
  <data key="d6">This approach transforms large language models to better handle high-performance computing code, enhancing their applicability.</data>
  <data key="d7">model adaptation, HPC</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Chathpc" target="Framework">
  <data key="d5">16.0</data>
  <data key="d6">Chathpc is an AI framework that leverages large language models to assist HPC users, enhancing productivity and code understanding.</data>
  <data key="d7">HPC, AI assistance</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Ompgpt" target="Code Model">
  <data key="d5">16.0</data>
  <data key="d6">Ompgpt is a specialized transformer model for OpenMP parallel programming, facilitating code generation and optimization.</data>
  <data key="d7">parallel programming, code generation</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="compute_metric" target="aggregate_metrics">
  <data key="d5">16.0</data>
  <data key="d6">The aggregate_metrics function calls compute_metric for each data point to perform calculations.&lt;SEP&gt;The aggregate_metrics function calls compute_metric on each data point to perform calculations.</data>
  <data key="d7">function call, data processing</data>
  <data key="d8">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="aggregate_metrics" target="data">
  <data key="d5">14.0</data>
  <data key="d6">The aggregate_metrics function processes the data array to compute the total sum.&lt;SEP&gt;The dataset is processed iteratively to compute total metrics.</data>
  <data key="d7">data processing, dataset</data>
  <data key="d8">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="aggregate_metrics" target="sum">
  <data key="d5">18.0</data>
  <data key="d6">The sum variable accumulates the results of compute_metric over all data points, which is parallelized with reduction.&lt;SEP&gt;The sum variable accumulates the total of computed metrics, with updates synchronized across threads using reduction.</data>
  <data key="d7">parallel reduction, accumulation</data>
  <data key="d8">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="data" target="optimization">
  <data key="d5">16.0</data>
  <data key="d6">Availability of data during optimization allows for better tuning and application of optimization techniques.&lt;SEP&gt;Data availability during optimization enables better performance tuning and application of parallel techniques.</data>
  <data key="d7">data management, optimization process</data>
  <data key="d8">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="sum" target="reduction">
  <data key="d5">9.0</data>
  <data key="d6">The reduction clause ensures thread-safe accumulation of the sum variable during parallel execution.</data>
  <data key="d7">thread safety, data integrity</data>
  <data key="d8">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="parallel code" target="OpenMP">
  <data key="d5">16.0</data>
  <data key="d6">OpenMP is used to parallelize serial code, transforming it into parallel code for performance gains.&lt;SEP&gt;OpenMP is used to parallelize serial code, transforming it into parallel code to improve performance and scalability.</data>
  <data key="d7">parallelization, code transformation</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="parallel code" target="MPI">
  <data key="d5">15.0</data>
  <data key="d6">MPI enables communication between processes in parallel applications, often generated from serial code for distributed computing.&lt;SEP&gt;MPI facilitates distributed parallelism by enabling message passing, often generated from serial code to run on multiple nodes.</data>
  <data key="d7">distributed computing, message passing</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="parallel code" target="Kokkos">
  <data key="d5">13.0</data>
  <data key="d6">Kokkos enables writing portable parallel code that can be translated across hardware architectures, aiding in performance and scalability.&lt;SEP&gt;Kokkos facilitates writing portable parallel code across hardware architectures, aiding in translating code between models.</data>
  <data key="d7">performance portability, code translation</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="parallel code" target="CUDA">
  <data key="d5">14.0</data>
  <data key="d6">CUDA accelerates code execution on Nvidia GPUs, and translating from CUDA to Kokkos is explored in the study.&lt;SEP&gt;CUDA accelerates code execution on Nvidia GPUs, and translation from CUDA to Kokkos is part of the evaluation.</data>
  <data key="d7">GPU acceleration, code translation</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="parallel code" target="correctness">
  <data key="d5">16.0</data>
  <data key="d6">Correctness of generated code is essential for functional parallel programs, and providing correct implementations improves correctness.&lt;SEP&gt;Correctness of generated code is essential; providing correct implementations enhances correctness.</data>
  <data key="d7">validation, functional accuracy</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="parallel code" target="correct implementations">
  <data key="d5">9.0</data>
  <data key="d6">Providing correct implementations improves the likelihood that LLMs generate accurate and correct parallel code.</data>
  <data key="d7">accuracy, implementation correctness</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="for-loop" target="parallel for">
  <data key="d5">8.0</data>
  <data key="d6">The outer loop over data rows is parallelized to improve processing speed.</data>
  <data key="d7">parallelization, loop distribution</data>
  <data key="d8">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="OpenMP" target="C++">
  <data key="d5">16.0</data>
  <data key="d6">OpenMP directives are used within C++ code to enable parallel execution, affecting code correctness and performance.&lt;SEP&gt;OpenMP is used within C++ programs for parallelization, often with specific functions like offload or function directives, influencing performance.</data>
  <data key="d7">parallel programming, performance optimization&lt;SEP&gt;parallelization, code performance</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenMP" target="Fortran">
  <data key="d5">8.0</data>
  <data key="d6">OpenMP provides parallelization capabilities for Fortran code, improving performance in scientific applications."|&gt;"parallelization, legacy code</data>
  <data key="d7">8</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenMP" target="OpenMP">
  <data key="d5">13.0</data>
  <data key="d6">OpenMP is a shared-memory parallel programming API with version 5.2 released in 2021, supporting multi-core CPU parallelism.&lt;SEP&gt;OpenMP is an API for shared-memory parallel programming, with the latest version 5.2 released in 2021, facilitating multi-core CPU parallelism.</data>
  <data key="d7">Theories/Models</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Phind-V2-34B" target="Problem Types">
  <data key="d5">7.0</data>
  <data key="d6">Phind-V2-34B is assessed on the same problem types, providing data for performance benchmarking against other models.</data>
  <data key="d7">benchmarking, model evaluation</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Execution Models" target="Prompts">
  <data key="d5">16.0</data>
  <data key="d6">Prompts are tailored for specific execution models such as serial, OpenMP, MPI, CUDA, HIP, etc.</data>
  <data key="d7">programming paradigms, model-specific prompts</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Large language models" target="Earth Science-related downstream tasks">
  <data key="d5">14.0</data>
  <data key="d6">LLMs are tailored for Earth Science tasks via fine-tuning and few-shot/zero-shot learning, aiding in data processing and knowledge generation.</data>
  <data key="d7">AI application, environmental data</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Code Analysis" target="Data Race Detection">
  <data key="d5">16.0</data>
  <data key="d6">Using large language models to detect data races in parallel code aims to improve debugging and code reliability.</data>
  <data key="d7">parallel programming, debugging</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Modeling Parallel Programs" target="Research Study">
  <data key="d5">16.0</data>
  <data key="d6">This study explores how large language models can simulate, analyze, and optimize parallel programs.</data>
  <data key="d7">parallel computing, modeling</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Code Generation" target="Performance-Aligned LLMs">
  <data key="d5">18.0</data>
  <data key="d6">Techniques for aligning large language models with performance goals to generate faster, more efficient code.</data>
  <data key="d7">optimization, code generation</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Code Generation" target="Large Language Models (LLMs)">
  <data key="d5">8.0</data>
  <data key="d6">LLMs are evaluated on their ability to generate code based on prompts, with success measured by correctness metrics."|&gt;"model capability, code correctness</data>
  <data key="d7">8</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Code Generation" target="Optimization">
  <data key="d5">16.0</data>
  <data key="d6">Optimization results are used to generate efficient code, including inlining and unrolling.</data>
  <data key="d7">code production</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Code Generation" target="Hardware Language">
  <data key="d5">14.0</data>
  <data key="d6">HWL describes hardware targets for code mapping during code generation.</data>
  <data key="d7">hardware specification</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Code Generation" target="Runtime-Dependent Applications">
  <data key="d5">16.0</data>
  <data key="d6">Supporting dynamic applications requires code that can adapt to runtime conditions, possibly via frameworks like Legion or StarPU.&lt;SEP&gt;Supporting dynamic applications requires code that can adapt to runtime conditions, possibly via frameworks like Legion or StarPU."|</data>
  <data key="d7">dynamic applications, code adaptation</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Code Generation" target="Memory Model">
  <data key="d5">14.0</data>
  <data key="d6">Improving the memory model to avoid local copies can enhance performance and efficiency during code generation."|&lt;SEP&gt;Improving the memory model to avoid local copies can enhance performance and efficiency during code generation."|&gt;"memory management, performance</data>
  <data key="d7">7&lt;SEP&gt;memory management, performance</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Code Generation" target="Safety Implications">
  <data key="d5">9.0</data>
  <data key="d6">Generated code may contain vulnerabilities or unsafe features, necessitating review before deployment.</data>
  <data key="d7">security, safety</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation" target="Security Landscape">
  <data key="d5">8.0</data>
  <data key="d6">The overall security environment is influenced by the capabilities and misuse potential of code generation models.</data>
  <data key="d7">cybersecurity, security environment</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation" target="Malicious or Vulnerable Dependencies">
  <data key="d5">17.0</data>
  <data key="d6">Codex might generate code that suggests or incorporates malicious or vulnerable dependencies, which could be exploited.&lt;SEP&gt;Codex might suggest malicious or vulnerable software dependencies, contributing to supply chain risks.</data>
  <data key="d7">dependency exploitation, security risk&lt;SEP&gt;software supply chain, dependency risk</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation" target="PolyCoder+HPC">
  <data key="d5">16.0</data>
  <data key="d6">PolyCoder+HPC outperforms other models in generating correct HPC code, especially at higher sample counts, demonstrating effective domain-specific learning."|&lt;SEP&gt;PolyCoder+HPC performs well on code generation tasks, especially for HPC-specific code, indicating effective learning from HPC datasets.</data>
  <data key="d7">8&lt;SEP&gt;model performance, code accuracy</data>
  <data key="d8">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Generation" target="GPT2+HPC">
  <data key="d5">14.0</data>
  <data key="d6">GPT2+HPC performs less effectively due to lack of pretraining on code data, but shows slight improvement when fine-tuned on HPC data.&lt;SEP&gt;GPT2+HPC performs less effectively due to lack of pretraining on code data, but shows some improvement with fine-tuning on HPC datasets."|</data>
  <data key="d7">7&lt;SEP&gt;model limitations, domain adaptation</data>
  <data key="d8">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Framework" target="Synthesis community">
  <data key="d5">16.0</data>
  <data key="d6">The community advocates for principled benchmarks and challenge problems to rigorously compare synthesis methodologies across different approaches."|&lt;"benchmarking, methodology comparison&lt;SEP&gt;The synthesis community advocates for the use of principled benchmarks and challenge problems to rigorously evaluate synthesis methodologies.</data>
  <data key="d7">8&lt;SEP&gt;benchmarking, methodology comparison</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Factual Knowledge" target="Wikipedia">
  <data key="d5">18.0</data>
  <data key="d6">Wikipedia serves as a primary source of factual knowledge for RAG models, grounding their responses.&lt;SEP&gt;Wikipedia serves as a primary source of factual knowledge for grounding information in RAG models, providing verified content.</data>
  <data key="d7">knowledge base, factual accuracy</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Model fine-tuning" target="Retrieval-augmented generation">
  <data key="d5">7.0</data>
  <data key="d6">The models are fine-tuned end-to-end to optimize the integration of retrieval and generation components.</data>
  <data key="d7">training methodology, optimization</data>
  <data key="d8">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Provenance" target="Retrieval-augmented generation">
  <data key="d5">6.0</data>
  <data key="d6">Tracking provenance is an open research challenge for understanding and explaining model decisions.</data>
  <data key="d7">explainability, transparency</data>
  <data key="d8">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Knowledge access" target="Retrieval-augmented generation">
  <data key="d5">8.0</data>
  <data key="d6">RAG enhances knowledge access by combining parametric and non-parametric memory, enabling models to retrieve relevant external information.</data>
  <data key="d7">knowledge access, external retrieval</data>
  <data key="d8">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Model performance" target="Retrieval-augmented generation">
  <data key="d5">8.0</data>
  <data key="d6">RAG models demonstrate superior results on knowledge-intensive NLP tasks, indicating effective integration of retrieval and generation.</data>
  <data key="d7">performance, task success</data>
  <data key="d8">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Wikipedia index" target="Retrieval-augmented generation">
  <data key="d5">8.0</data>
  <data key="d6">The Wikipedia index is used as a dense vector external memory that RAG retrieves from to generate accurate responses.</data>
  <data key="d7">external memory, knowledge source</data>
  <data key="d8">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Knowledge updating" target="Retrieval-augmented generation">
  <data key="d5">6.0</data>
  <data key="d6">Updating knowledge remains a challenge, as models need mechanisms to revise stored information.</data>
  <data key="d7">knowledge revision, dynamic updating</data>
  <data key="d8">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Sequence-to-Sequence Models" target="RAG Models">
  <data key="d5">18.0</data>
  <data key="d6">RAG models are built upon seq2seq architectures, integrating retrieval mechanisms to enhance knowledge-based generation.&lt;SEP&gt;RAG models are built upon seq2seq architectures, integrating retrieval mechanisms to improve knowledge-based answer generation."|</data>
  <data key="d7">9&lt;SEP&gt;model architecture</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Parametric Memory" target="Question Generation and Fact Verification">
  <data key="d5">12.0</data>
  <data key="d6">Parametric memory enables the models to complete titles and facts, indicating stored knowledge within the model parameters.&lt;SEP&gt;Parametric memory supports the models in completing titles and facts internally, reflecting stored knowledge within the model parameters.</data>
  <data key="d7">internal knowledge, knowledge storage</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Non-parametric Memory" target="Question Generation and Fact Verification">
  <data key="d5">14.0</data>
  <data key="d6">External retrieval (non-parametric memory) enhances the models' ability to generate specific, factually accurate content.&lt;SEP&gt;External retrieval (non-parametric memory) supports generating specific content and factual accuracy.</data>
  <data key="d7">retrieval support, content accuracy&lt;SEP&gt;retrieval support, content specificity</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="BART" target="RAG Models">
  <data key="d5">16.0</data>
  <data key="d6">BART functions as the generator in RAG models, conditioned on retrieved documents and input sequences to produce outputs.&lt;SEP&gt;BART serves as the generative component in RAG, producing output conditioned on retrieved documents and input sequences."|</data>
  <data key="d7">8&lt;SEP&gt;generation component</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="BART" target="Natural Language Generation, Translation, and Comprehension">
  <data key="d5">9.0</data>
  <data key="d6">BART is designed to enhance NLP tasks through denoising sequence-to-sequence pre-training.</data>
  <data key="d7">model application, NLP tasks</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="BART" target="Sequence-to-Sequence Pre-training">
  <data key="d5">9.0</data>
  <data key="d6">BART employs sequence-to-sequence pre-training to improve language understanding and generation capabilities.</data>
  <data key="d7">training methodology, NLP improvement</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="BART" target="M. Lewis">
  <data key="d5">8.0</data>
  <data key="d6">M. Lewis is an author of the BART paper, contributing to NLP model development.</data>
  <data key="d7">authorship, NLP research</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="BART" target="Y. Liu">
  <data key="d5">7.0</data>
  <data key="d6">Y. Liu contributed to the development and evaluation of the BART model.</data>
  <data key="d7">research contribution, NLP tasks</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="BART" target="N. Goyal">
  <data key="d5">7.0</data>
  <data key="d6">N. Goyal is involved in pre-training strategies for BART, focusing on language understanding.</data>
  <data key="d7">methodology, NLP improvement</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="BART" target="M. Ghazvininejad">
  <data key="d5">8.0</data>
  <data key="d6">M. Ghazvininejad contributed to the design of BART's denoising pre-training approach.</data>
  <data key="d7">model design, pre-training</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="BART" target="A. Mohamed">
  <data key="d5">6.0</data>
  <data key="d6">A. Mohamed worked on applying BART to various NLP tasks.</data>
  <data key="d7">application, NLP tasks</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="BART" target="O. Levy">
  <data key="d5">7.0</data>
  <data key="d6">O. Levy contributed to the development of BART's training methodology.</data>
  <data key="d7">training methodology, model performance</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="BART" target="V. Stoyanov">
  <data key="d5">6.0</data>
  <data key="d6">V. Stoyanov contributed to NLP task performance evaluation with BART.</data>
  <data key="d7">evaluation, NLP tasks</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="BART" target="L. Zettlemoyer">
  <data key="d5">7.0</data>
  <data key="d6">L. Zettlemoyer contributed to the theoretical foundation and application of BART in NLP.</data>
  <data key="d7">theoretical contribution, NLP application</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Top-K Approximation" target="RAG Models">
  <data key="d5">14.0</data>
  <data key="d6">A technique to marginalize over the top-K retrieved documents, approximating the distribution over source documents for efficient inference."|&lt;SEP&gt;A top-K approximation technique is used to marginalize over retrieved documents, enabling efficient approximation of the latent document distribution.</data>
  <data key="d7">7&lt;SEP&gt;approximation method</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Knowledge-Intensive Tasks" target="RAG Models">
  <data key="d5">18.0</data>
  <data key="d6">RAG models are designed specifically for tasks that require external knowledge, such as open QA, fact verification, and question generation."|&lt;SEP&gt;RAG models are designed to perform well on knowledge-intensive tasks by combining parametric and non-parametric memory sources.</data>
  <data key="d7">9&lt;SEP&gt;task performance</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="FEVER" target="Retrieval and reasoning">
  <data key="d5">9.0</data>
  <data key="d6">FEVER involves retrieving evidence from Wikipedia and reasoning over it to classify claims, exemplifying retrieval-augmented reasoning capabilities.</data>
  <data key="d7">application</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="FEVER" target="Retrieval and Reasoning">
  <data key="d5">9.0</data>
  <data key="d6">FEVER involves retrieving evidence from Wikipedia and reasoning to classify claims as supported, refuted, or unverifiable, demonstrating retrieval and reasoning capabilities.</data>
  <data key="d7">application</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="FEVER" target="Wikipedia">
  <data key="d5">16.0</data>
  <data key="d6">FEVER relies on Wikipedia as the evidence source for claim verification.</data>
  <data key="d7">evidence source, fact verification</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Knowledge Updating" target="Challenge">
  <data key="d5">6.0</data>
  <data key="d6">Updating knowledge in LLMs is complex and computationally expensive, impacting their ability to incorporate new information efficiently.</data>
  <data key="d7">knowledge management, computational cost</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Jeopardy Question Generation" target="SearchQA Dataset">
  <data key="d5">8.0</data>
  <data key="d6">The dataset provides examples for training and evaluating models on generating Jeopardy-style questions, focusing on factuality and specificity.</data>
  <data key="d7">application</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jeopardy Question Generation" target="RAG">
  <data key="d5">6.0</data>
  <data key="d6">RAG models are evaluated on Jeopardy-style question generation tasks.</data>
  <data key="d7">question generation, evaluation</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jeopardy Question Generation" target="RAG-Token">
  <data key="d5">16.0</data>
  <data key="d6">RAG-Token model performs better than RAG-Sequence in generating Jeopardy questions, as shown by evaluation metrics.&lt;SEP&gt;RAG-Token outperforms RAG-Sequence in generating more accurate and specific Jeopardy questions, as shown by evaluation metrics.</data>
  <data key="d7">performance comparison, model effectiveness&lt;SEP&gt;performance, model effectiveness</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jeopardy Question Generation" target="Document Posterior p(zi|x, yi)">
  <data key="d5">14.0</data>
  <data key="d6">The posterior distribution helps determine the relevance of documents during question generation, influencing the specificity and accuracy of responses.&lt;SEP&gt;The posterior distribution influences which documents are deemed relevant during question generation, affecting the specificity and correctness of outputs.</data>
  <data key="d7">retrieval relevance, generation accuracy&lt;SEP&gt;retrieval relevance, generation quality</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG-Token Model" target="Sequence Classification Tasks">
  <data key="d5">8.0</data>
  <data key="d6">The RAG-Token model can be adapted for sequence classification by treating the class as a target sequence of length one, making it suitable for classification tasks.</data>
  <data key="d7">model adaptation, classification</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Retriever" target="DPR">
  <data key="d5">9.0</data>
  <data key="d6">The retriever component is based on DPR, which encodes documents and queries into dense vectors for efficient retrieval.</data>
  <data key="d7">retrieval architecture, dense representations</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Generator" target="BART-large">
  <data key="d5">9.0</data>
  <data key="d6">The generator component is modeled using BART-large, a pre-trained seq2seq transformer that produces output sequences based on input and retrieved content.</data>
  <data key="d7">generation, transformer model</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Sequence Classification Tasks" target="RAG Model">
  <data key="d5">8.0</data>
  <data key="d6">The RAG model can be used for sequence classification by considering the target as a single-token sequence, enabling its application in classification scenarios.</data>
  <data key="d7">model versatility, classification</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Training" target="RAG Components">
  <data key="d5">8.0</data>
  <data key="d6">The retriever and generator are trained jointly to optimize performance, with the document encoder kept fixed and the query encoder and generator fine-tuned.</data>
  <data key="d7">training methodology, optimization</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Training" target="GPT-Neo, Codex-12B">
  <data key="d5">9.0</data>
  <data key="d6">These large language models are fine-tuned on curated problems to improve their ability to generate correct code solutions and pass unit tests.</data>
  <data key="d7">model training, fine-tuning</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Training" target="Validation Loss">
  <data key="d5">8.0</data>
  <data key="d6">Validation loss is monitored during training to assess model performance and determine when to stop training."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Decoding" target="RAG-Token and RAG-Sequence">
  <data key="d5">8.0</data>
  <data key="d6">Different decoding strategies are used for RAG-Token and RAG-Sequence, involving beam search and approximation techniques to balance accuracy and efficiency.</data>
  <data key="d7">decoding strategies, efficiency</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Wikipedia Dump" target="DPR">
  <data key="d5">7.0</data>
  <data key="d6">DPR was trained on datasets like TriviaQA and Natural Questions to retrieve relevant documents from Wikipedia.</data>
  <data key="d7">training data, retrieval training</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="Knowledge-intensive tasks">
  <data key="d5">9.0</data>
  <data key="d6">RAG is designed to improve performance on various knowledge-intensive NLP tasks by combining retrieval and generation.</data>
  <data key="d7">application</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="Open-domain QA">
  <data key="d5">10.0</data>
  <data key="d6">RAG is applied to open-domain question answering, comparing its performance to extractive and parametric models.</data>
  <data key="d7">application</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="MSMARCO NLG task">
  <data key="d5">8.0</data>
  <data key="d6">RAG is evaluated for abstractive QA by generating answers to questions in the MSMARCO dataset, testing its natural language generation capabilities.</data>
  <data key="d7">application</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="Open-domain Question Answering">
  <data key="d5">28.0</data>
  <data key="d6">RAG is applied to open-domain QA tasks, leveraging retrieval from Wikipedia to improve answer accuracy compared to purely parametric models.&lt;SEP&gt;RAG models are evaluated on open-domain QA tasks, demonstrating superior performance.</data>
  <data key="d7">application&lt;SEP&gt;question answering, model evaluation</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="Abstractive Question Answering">
  <data key="d5">9.0</data>
  <data key="d6">RAG's generative component enables answering questions with free-form text, demonstrating its natural language generation capabilities in knowledge-intensive tasks.</data>
  <data key="d7">application</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="DPR">
  <data key="d5">16.0</data>
  <data key="d6">DPR provides retrieval supervision for RAG's retriever component, enhancing its performance.</data>
  <data key="d7">retrieval training, model initialization</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="Generation and Classification Scores">
  <data key="d5">14.0</data>
  <data key="d6">RAG's performance is measured by Bleu, Rouge-L, and accuracy metrics in QA tasks.</data>
  <data key="d7">performance metrics, evaluation</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="gold evidence sentence">
  <data key="d5">8.0</data>
  <data key="d6">RAG retrieves documents to match gold evidence sentences for claim verification.</data>
  <data key="d7">retrieval accuracy, evidence matching</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="top k documents">
  <data key="d5">16.0</data>
  <data key="d6">The top k retrieved documents are analyzed to measure overlap with gold evidence, assessing retrieval effectiveness.&lt;SEP&gt;The top retrieved documents are analyzed for overlap with gold evidence, assessing retrieval quality.</data>
  <data key="d7">retrieval effectiveness, overlap analysis&lt;SEP&gt;retrieval quality</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="generation diversity">
  <data key="d5">14.0</data>
  <data key="d6">Different models like RAG-Sequence and RAG-Token are compared for diversity in generated outputs.&lt;SEP&gt;Different variants of RAG are compared for diversity in generated outputs, impacting factuality and variability.</data>
  <data key="d7">generation quality&lt;SEP&gt;generation quality, diversity</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="retrieval ablations">
  <data key="d5">16.0</data>
  <data key="d6">Ablation studies assess the impact of freezing or replacing the retriever component on model performance.&lt;SEP&gt;Ablation studies where the retriever is frozen or replaced assess the importance of retrieval in overall performance.</data>
  <data key="d7">model ablation, retrieval effectiveness&lt;SEP&gt;model analysis</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="BM25">
  <data key="d5">7.0</data>
  <data key="d6">Replacing learned retrieval with BM25 affects the model's performance, especially on entity-centric tasks like FEVER.</data>
  <data key="d7">retrieval method, task performance</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="claim">
  <data key="d5">9.0</data>
  <data key="d6">RAG retrieves documents to verify claims, aiming to improve factual accuracy.</data>
  <data key="d7">retrieval, claim verification</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="gold evidence">
  <data key="d5">8.0</data>
  <data key="d6">RAG retrieves documents that match gold evidence sentences, evaluating retrieval accuracy.</data>
  <data key="d7">evidence retrieval</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="performance metrics">
  <data key="d5">7.0</data>
  <data key="d6">Performance metrics are used to evaluate the accuracy and effectiveness of RAG in various tasks.</data>
  <data key="d7">evaluation</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Wikipedia dump (December 2018)" target="Document encoder">
  <data key="d5">7.0</data>
  <data key="d6">The document encoder processes the Wikipedia dump to create embeddings for document retrieval.</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Wikipedia dump (December 2018)" target="Document Encoder">
  <data key="d5">8.0</data>
  <data key="d6">The document encoder processes the Wikipedia dump to generate embeddings for retrieval.</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Document encoder" target="FAISS MIPS index">
  <data key="d5">8.0</data>
  <data key="d6">The document encoder's embeddings are used to build a FAISS MIPS index for fast document retrieval.</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="SearchQA dataset" target="Jeopardy question generation">
  <data key="d5">9.0</data>
  <data key="d6">The task uses the SearchQA dataset splits to train and evaluate models generating Jeopardy-style questions, focusing on factuality and specificity.</data>
  <data key="d7">application</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Q-BLEU-1" target="Question generation evaluation">
  <data key="d5">7.0</data>
  <data key="d6">Q-BLEU-1 scores are used to quantitatively assess the quality of generated questions, emphasizing entity matching and factual correctness.</data>
  <data key="d7">analytical technique</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Q-BLEU-1" target="Question Generation Evaluation">
  <data key="d5">7.0</data>
  <data key="d6">Q-BLEU-1 scores quantify the quality of generated questions, emphasizing entity matching and factual correctness, correlating with human judgments.</data>
  <data key="d7">analytical technique</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Human evaluation" target="Question generation">
  <data key="d5">8.0</data>
  <data key="d6">Human judges compare questions generated by different models to assess factuality and specificity, providing qualitative insights into model performance.</data>
  <data key="d7">analytical technique</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Y" target="Decoding Procedure">
  <data key="d5">9.0</data>
  <data key="d6">Y influences the efficiency of the decoding process by determining whether additional forward passes are needed, impacting the decoding speed and resource use.</data>
  <data key="d7">decoding efficiency, process optimization</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Human Evaluation" target="Question Generation">
  <data key="d5">8.0</data>
  <data key="d6">Human judges compare generated questions for factuality and specificity, providing qualitative assessment of model performance.</data>
  <data key="d7">analytical technique</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Evidence" target="Claim">
  <data key="d5">14.0</data>
  <data key="d6">Claims are supported or refuted by evidence retrieved from Wikipedia in FEVER.</data>
  <data key="d7">support, refutation</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Evidence" target="Retrieval Problem">
  <data key="d5">12.0</data>
  <data key="d6">FEVER's retrieval task involves fetching relevant evidence to support claim classification.</data>
  <data key="d7">retrieval, evidence gathering</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Entailment Reasoning" target="Claims and Evidence">
  <data key="d5">18.0</data>
  <data key="d6">FEVER involves reasoning over evidence to determine if claims are supported or refuted.</data>
  <data key="d7">logical reasoning, classification</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="DPR" target="RAG Models">
  <data key="d5">16.0</data>
  <data key="d6">The Dense Passage Retriever provides latent documents conditioned on input queries, which are used by RAG models to incorporate external knowledge.&lt;SEP&gt;The Dense Passage Retriever provides relevant documents conditioned on input queries, which are used by RAG models to incorporate external knowledge."|</data>
  <data key="d7">8&lt;SEP&gt;retrieval component</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Fact Veriﬁcation" target="RAG-Token">
  <data key="d5">18.0</data>
  <data key="d6">RAG-Token achieves high accuracy on FEVER, demonstrating its effectiveness in factual claim verification without extensive domain-specific engineering.&lt;SEP&gt;RAG-Token achieves high accuracy on FEVER, indicating its effectiveness in factual claim verification.</data>
  <data key="d7">accuracy, factual correctness&lt;SEP&gt;model performance, factual accuracy</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Document Relevance" target="Document Retrieval">
  <data key="d5">7.0</data>
  <data key="d6">Relevance scores assigned during document retrieval influence the quality of generated responses in both question generation and fact verification tasks.</data>
  <data key="d7">retrieval quality, relevance</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Thorne" target="RoBERTa">
  <data key="d5">7.0</data>
  <data key="d6">Thorne's model is compared against RoBERTa for claim classification, serving as a benchmark.</data>
  <data key="d7">model comparison, classification performance</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Vlachos" target="RoBERTa">
  <data key="d5">6.0</data>
  <data key="d6">Vlachos's model is evaluated alongside RoBERTa for claim classification.</data>
  <data key="d7">model comparison, classification performance</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="accuracy" target="labeling of OpenMP pragmas">
  <data key="d5">9.0</data>
  <data key="d6">The model labels OpenMP pragmas with 97% accuracy, showing proficiency in recognizing parallel directives in source code.</data>
  <data key="d7">labeling accuracy, parallel programming</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="accuracy" target="performance prediction">
  <data key="d5">9.0</data>
  <data key="d6">The model predicts relative code performance changes with up to 92% accuracy, useful for performance optimization.</data>
  <data key="d7">performance forecasting, model accuracy</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="BM25" target="retrieval mechanism">
  <data key="d5">7.0</data>
  <data key="d6">Replacing RAG's learned retriever with BM25 affects retrieval effectiveness, especially for entity-centric datasets like FEVER.</data>
  <data key="d7">retrieval comparison</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="index" target="world leaders">
  <data key="d5">8.0</data>
  <data key="d6">Different indices built at different times are used to evaluate RAG's ability to update knowledge efficiently.</data>
  <data key="d7">knowledge update, index comparison</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="index" target="knowledge update">
  <data key="d5">9.0</data>
  <data key="d6">Replacing the index in RAG enables updating its knowledge base without retraining.</data>
  <data key="d7">knowledge refresh, non-parametric memory</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="knowledge update" target="index from 2016">
  <data key="d5">8.0</data>
  <data key="d6">Using an older index to evaluate RAG's ability to answer questions about 2016 leaders demonstrates knowledge updating capability.</data>
  <data key="d7">knowledge update</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="knowledge update" target="index from 2018">
  <data key="d5">8.0</data>
  <data key="d6">Using a newer index for 2018 leaders shows how RAG's knowledge can be kept current by index replacement.</data>
  <data key="d7">knowledge update</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="performance metrics" target="generated code">
  <data key="d5">18.0</data>
  <data key="d6">Performance metrics are collected from the execution of generated code to evaluate quality and efficiency.&lt;SEP&gt;Performance metrics are derived from executing the generated code to assess quality, correctness, and efficiency.</data>
  <data key="d7">evaluation, measurement</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance metrics" target="CPU">
  <data key="d5">12.0</data>
  <data key="d6">The CPU specifications affect the runtime and scalability of the generated code.&lt;SEP&gt;The CPU specifications influence the runtime performance and scalability of the generated code.</data>
  <data key="d7">hardware influence, performance</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance metrics" target="GPU">
  <data key="d5">12.0</data>
  <data key="d6">GPU hardware impacts the speed and efficiency of parallel code execution.</data>
  <data key="d7">hardware impact, performance</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance metrics" target="execution scenario">
  <data key="d5">7.0</data>
  <data key="d6">Different hardware and threading configurations influence the runtime and success rates of code generation.</data>
  <data key="d7">hardware setup, performance</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance metrics" target="timing">
  <data key="d5">7.0</data>
  <data key="d6">Timing measurements of code execution are used to evaluate efficiency and scalability.</data>
  <data key="d7">performance measurement, efficiency</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="test time knowledge update" target="applications">
  <data key="d5">9.0</data>
  <data key="d6">Replacing indices at test time allows RAG to incorporate up-to-date information without retraining.</data>
  <data key="d7">knowledge management</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="2016 Index" target="Accuracy">
  <data key="d5">16.0</data>
  <data key="d6">The 2016 index is used to measure the accuracy of matching world leaders, with low accuracy indicating challenges in data matching.</data>
  <data key="d7">data evaluation, measurement</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="2018 Index" target="Accuracy">
  <data key="d5">14.0</data>
  <data key="d6">The 2018 index serves as a benchmark for evaluating the accuracy of leader matching across different data sets.</data>
  <data key="d7">data comparison, benchmark</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="World Leaders" target="Accuracy">
  <data key="d5">12.0</data>
  <data key="d6">World leaders' identification accuracy is assessed using indices, reflecting the effectiveness of the matching process.</data>
  <data key="d7">entity identification, data quality</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Accuracy" target="Indices Mismatch">
  <data key="d5">14.0</data>
  <data key="d6">Mismatch between indices (2016 and 2018) leads to low accuracy in matching leaders, indicating issues with data consistency or index reliability.</data>
  <data key="d7">data mismatch, reliability</data>
  <data key="d8">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Accuracy" target="Evaluation metric">
  <data key="d5">7.0</data>
  <data key="d6">Model success in performance prediction is measured by classification accuracy, indicating the proportion of correct predictions of slowdown or speedup.</data>
  <data key="d7">performance metrics, evaluation</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="RAG Techniques" target="State of the Art Results">
  <data key="d5">16.0</data>
  <data key="d6">The use of RAG techniques led to achieving state-of-the-art results in open-domain QA tasks.</data>
  <data key="d7">performance improvement</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Model Effectiveness" target="Interaction of Memories">
  <data key="d5">16.0</data>
  <data key="d6">The effectiveness validation showed that retrieval components can be swapped without retraining, indicating flexible memory interaction.&lt;SEP&gt;The validation demonstrated that retrieval components can be swapped or updated without retraining the entire model, showing effective interaction between memory types.</data>
  <data key="d7">model adaptability, validation</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Pre-training" target="Interaction of Memories">
  <data key="d5">14.0</data>
  <data key="d6">Pre-training can be extended to jointly pre-train parametric and non-parametric components, improving their integration and performance.&lt;SEP&gt;Pre-training can be extended to jointly pre-train parametric and non-parametric components, improving their interaction.</data>
  <data key="d7">training objectives, model optimization</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Automation of Jobs" target="Implications">
  <data key="d5">14.0</data>
  <data key="d6">Advanced NLP models could automate tasks, influencing employment and economic structures.&lt;SEP&gt;Advanced NLP models could automate various tasks, influencing employment patterns and economic sectors.</data>
  <data key="d7">societal change, economic impact</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Mitigation Strategies" target="Security Implications">
  <data key="d5">7.0</data>
  <data key="d6">Implementing security measures like rate-limiting and abuse detection can help manage risks posed by code generation models.</data>
  <data key="d7">security measures, risk management</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Mitigation Strategies" target="Security">
  <data key="d5">8.0</data>
  <data key="d6">Implementing security measures like rate-limiting and abuse detection can help prevent misuse of code generation models.</data>
  <data key="d7">security strategies, risk mitigation</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Knowledge Base" target="Contains">
  <data key="d5">14.0</data>
  <data key="d6">Knowledge bases like Wikidata or Wikipedia contain the domain-specific information retrieved and used to augment LLMs."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Association for Computational Linguistics" target="doi: 10.18653/v1/P17-1171">
  <data key="d5">10.0</data>
  <data key="d6">The DOI references the specific publication associated with the ACL organization.</data>
  <data key="d7">citation, publication reference</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Eunsol Choi" target="Proceedings of the 10th Annual Meeting of the Association for Computational Linguistics">
  <data key="d5">16.0</data>
  <data key="d6">Choi contributed to research on question answering for long documents presented at the conference.&lt;SEP&gt;Choi's research on coarse-to-fine question answering was presented at this conference.</data>
  <data key="d7">research contribution, conference presentation&lt;SEP&gt;research presentation, NLP methodology</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Christopher Clark" target="arXiv:1710.10723">
  <data key="d5">14.0</data>
  <data key="d6">Clark authored a paper on multi-paragraph reading comprehension, contributing methodologies in NLP.&lt;SEP&gt;Clark authored a paper on multi-paragraph reading comprehension, contributing to NLP methodologies.</data>
  <data key="d7">research contribution, NLP methodology</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Emily Dinan" target="URL https://openreview.net/forum?id=r1l73iRqKm">
  <data key="d5">20.0</data>
  <data key="d6">Dinan contributed to conversational AI research, focusing on knowledge-powered agents.&lt;SEP&gt;Dinan contributed to knowledge-powered conversational agents in NLP research.</data>
  <data key="d7">research contribution, conversational AI&lt;SEP&gt;research contribution, conversational agents</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Angela Fan" target="Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics">
  <data key="d5">22.0</data>
  <data key="d6">Fan contributed to hierarchical neural story generation models.</data>
  <data key="d7">research contribution, NLP modeling</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Angela Fan" target="Yacine Jernite">
  <data key="d5">24.0</data>
  <data key="d6">Fan and Jernite collaborated on long-form question answering research, enhancing NLP models.</data>
  <data key="d7">collaborative research, NLP advancement</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Angela Fan" target="Ethan Perez">
  <data key="d5">26.0</data>
  <data key="d6">Fan and Perez worked together on long-form question answering, pushing NLP methodologies forward.</data>
  <data key="d7">collaborative research, NLP</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Angela Fan" target="David Grangier">
  <data key="d5">28.0</data>
  <data key="d6">Fan collaborated with Grangier on NLP models for long-form QA.</data>
  <data key="d7">research collaboration, NLP models</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Angela Fan" target="Jason Weston">
  <data key="d5">30.0</data>
  <data key="d6">Fan and Weston collaborated on neural conversation models and long-form QA.</data>
  <data key="d7">collaborative research, NLP</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Angela Fan" target="Michael Auli">
  <data key="d5">32.0</data>
  <data key="d6">Fan contributed to NLP research on language modeling and story generation.</data>
  <data key="d7">research contribution, NLP modeling</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Angela Fan" target="Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics">
  <data key="d5">34.0</data>
  <data key="d6">Fan's work on augmenting transformers with KNN-based memory was presented at this conference.</data>
  <data key="d7">research presentation, NLP technology</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="H1gx1CNKPH" target="abs/2004.07202">
  <data key="d5">36.0</data>
  <data key="d6">The paper discusses entities as experts, focusing on sparse memory access with entity supervision in NLP models.</data>
  <data key="d7">research methodology, entity supervision</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Marjan Ghazvininejad" target="AAAI Conference on Artificial Intelligence">
  <data key="d5">38.0</data>
  <data key="d6">Ghazvininejad presented on knowledge-grounded neural conversation models.</data>
  <data key="d7">research contribution, grounded NLP</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Chris Brockett" target="AAAI Conference on Artificial Intelligence">
  <data key="d5">40.0</data>
  <data key="d6">Brockett contributed to NLP research on neural conversation models.</data>
  <data key="d7">research contribution, NLP</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jianfeng Gao" target="AAAI Conference on Artificial Intelligence">
  <data key="d5">42.0</data>
  <data key="d6">Gao's work on knowledge-grounded NLP models was presented at the conference.</data>
  <data key="d7">research presentation, grounded NLP</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Wen Yih" target="AAAI Conference on Artificial Intelligence">
  <data key="d5">44.0</data>
  <data key="d6">Yih's research on knowledge-grounded dialogue systems was presented at the conference.</data>
  <data key="d7">research presentation, dialogue systems</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Michel Galley" target="AAAI Conference on Artificial Intelligence">
  <data key="d5">46.0</data>
  <data key="d6">Galley's work on neural conversation models was presented at the conference.</data>
  <data key="d7">research presentation, NLP models</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="abs/1705.08807" target="https://arxiv.org/abs/1705.08807">
  <data key="d5">48.0</data>
  <data key="d6">The paper discusses when AI might exceed human performance, providing evidence and hypotheses.&lt;SEP&gt;The paper discusses when AI might surpass human performance, providing evidence and hypotheses.</data>
  <data key="d7">research hypothesis, AI performance</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jiatao Gu" target="AAAI 2018">
  <data key="d5">50.0</data>
  <data key="d6">Gu's research on search engine guided neural machine translation was presented at AAAI 2018.</data>
  <data key="d7">research presentation, NLP translation</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jiatao Gu" target="Search engine guided neural machine translation">
  <data key="d5">17.0</data>
  <data key="d6">Jiatao Gu contributed to developing this model, integrating search engine strategies with neural translation for improved performance.&lt;SEP&gt;Jiatao Gu contributed to developing this model, integrating search engine strategies with neural translation.</data>
  <data key="d7">research development</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Yong Wang" target="pages 5133–5140">
  <data key="d5">52.0</data>
  <data key="d6">Wang contributed to the research on search engine guided neural machine translation, as detailed in the conference proceedings.</data>
  <data key="d7">research contribution, NLP translation</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Yong Wang" target="Search engine guided neural machine translation">
  <data key="d5">12.0</data>
  <data key="d6">Yong Wang is involved in research related to neural translation models, likely contributing to this methodology.&lt;SEP&gt;Yong Wang is involved in research related to neural translation models, potentially contributing to this methodology.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Kyunghyun Cho" target="pages 5133–5140">
  <data key="d5">54.0</data>
  <data key="d6">Kyunghyun Cho was involved in the same research on search engine guided neural machine translation.</data>
  <data key="d7">research contribution, NLP translation</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Kyunghyun Cho" target="Search engine guided neural machine translation">
  <data key="d5">14.0</data>
  <data key="d6">Kyunghyun Cho's expertise in neural networks supports the development of this translation model.&lt;SEP&gt;Kyunghyun Cho's work in deep learning and neural networks supports advancements in this translation approach.</data>
  <data key="d7">theoretical foundation</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Victor O.K. Li" target="pages 5133–5140">
  <data key="d5">56.0</data>
  <data key="d6">Victor O.K. Li contributed to the research on search engine guided neural machine translation.</data>
  <data key="d7">research contribution, NLP translation</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Victor O.K. Li" target="Search engine guided neural machine translation">
  <data key="d5">10.0</data>
  <data key="d6">Victor O.K. Li's expertise in AI systems underpins research in neural translation models.&lt;SEP&gt;Victor O.K. Li's research background in AI and NLP underpins this model's development.</data>
  <data key="d7">research support</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Advances in Neural Information Processing Systems 32" target="Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, Jing Jiang">
  <data key="d5">7.0</data>
  <data key="d6">Publication of research papers and findings in neural information processing.</data>
  <data key="d7">publication, dissemination</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Advances in Neural Information Processing Systems 32" target="Alché-Buc, E. Fox, and R. Garnett">
  <data key="d5">7.0</data>
  <data key="d6">Publication of a conference volume that compiles research papers and advancements in neural information processing.</data>
  <data key="d7">publication, dissemination</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Kuchaiev" target="Mixed Precision Training">
  <data key="d5">16.0</data>
  <data key="d6">Kuchaiev contributed to research on mixed precision training, advancing methods for efficient neural network training.&lt;SEP&gt;Kuchaiev contributed to the development of mixed precision training methods to improve neural network training efficiency.</data>
  <data key="d7">research contribution, training methodology</data>
  <data key="d8">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Ganesh Venkatesh" target="Mixed Precision Training">
  <data key="d5">14.0</data>
  <data key="d6">Ganesh Venkatesh collaborated on research about mixed precision training in neural networks.&lt;SEP&gt;Ganesh Venkatesh collaborated on research related to mixed precision training techniques in deep learning.</data>
  <data key="d7">collaborative research, training method&lt;SEP&gt;collaborative research, training methodology</data>
  <data key="d8">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Hao Wu" target="Mixed Precision Training">
  <data key="d5">16.0</data>
  <data key="d6">Hao Wu co-authored the publication on mixed precision training at ICLR 2018, indicating active involvement in this research area.&lt;SEP&gt;Hao Wu contributed to the development and publication of mixed precision training techniques in ICLR 2018.</data>
  <data key="d7">publication, research contribution&lt;SEP&gt;research contribution, publication</data>
  <data key="d8">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Background Knowledge" target="Conversation Systems">
  <data key="d5">14.0</data>
  <data key="d6">Background knowledge enhances the building of conversation systems by providing prior information that can improve response quality.&lt;SEP&gt;Background knowledge enhances the construction and performance of conversation systems by providing prior information that can be leveraged during interaction.</data>
  <data key="d7">knowledge enhancement, system building</data>
  <data key="d8">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Question Generation Systems" target="Better Metric">
  <data key="d5">16.0</data>
  <data key="d6">The improved metric provides a more accurate assessment of question generation systems' quality, guiding better system development.&lt;SEP&gt;The new metric aims to improve the evaluation of question generation systems, making assessments more accurate and meaningful.</data>
  <data key="d7">evaluation improvement, NLP&lt;SEP&gt;evaluation, NLP metrics</data>
  <data key="d8">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="MS MARCO Dataset" target="Passage Re-ranking with BERT">
  <data key="d5">14.0</data>
  <data key="d6">The dataset is used as a benchmark for passage re-ranking tasks using BERT-based models.&lt;SEP&gt;The dataset is used in passage re-ranking tasks with BERT to evaluate retrieval effectiveness.</data>
  <data key="d7">dataset application, evaluation&lt;SEP&gt;dataset application, retrieval</data>
  <data key="d8">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Unsupervised Multitask Learning" target="GPT">
  <data key="d5">16.0</data>
  <data key="d6">GPT employs unsupervised multitask learning to enhance language understanding capabilities.&lt;SEP&gt;GPT employs unsupervised multitask learning to improve its language understanding and generation capabilities.</data>
  <data key="d7">training methodology, multitask learning</data>
  <data key="d8">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Transfer Learning" target="Prompt Transferability">
  <data key="d5">18.0</data>
  <data key="d6">Transfer learning enables prompts trained on source domains or tasks to be adapted for new tasks or domains, demonstrating transferability and improving efficiency.&lt;SEP&gt;Transfer learning in prompt tuning allows prompts trained on source tasks or domains to be adapted for new, unseen tasks, enhancing efficiency and generalization.</data>
  <data key="d7">domain adaptation, transferability&lt;SEP&gt;transferability, domain adaptation</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Transfer Learning" target="Ma">
  <data key="d5">18.0</data>
  <data key="d6">Ma discusses a unified view of parameter-efficient transfer learning, linking core concepts and methodologies.</data>
  <data key="d7">transfer learning, parameter efficiency</data>
  <data key="d8">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Transfer Learning" target="Neil Houlsby">
  <data key="d5">18.0</data>
  <data key="d6">Neil Houlsby contributed to parameter-efficient transfer learning for NLP.</data>
  <data key="d7">NLP, transfer learning</data>
  <data key="d8">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Parameters" target="Knowledge Packing">
  <data key="d5">16.0</data>
  <data key="d6">The capacity of language models to embed extensive knowledge within their parameters is investigated to understand their limits.</data>
  <data key="d7">model capacity, knowledge encoding</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Probabilistic Relevance Framework" target="Relevance Framework">
  <data key="d5">18.0</data>
  <data key="d6">The probabilistic relevance framework, including BM25, is used to rank documents based on relevance in information retrieval.</data>
  <data key="d7">ranking, relevance scoring</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Release Strategies" target="Social Impacts">
  <data key="d5">14.0</data>
  <data key="d6">Strategies for releasing language models are linked to their social impacts, influencing societal acceptance and ethical considerations.</data>
  <data key="d7">deployment, social consequences</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Memory Networks" target="Fact Extraction and Verification Dataset (FEVER)">
  <data key="d5">12.0</data>
  <data key="d6">Memory networks can be applied to tasks like fact extraction and verification, utilizing external memory to improve accuracy.</data>
  <data key="d7">application, NLP tasks</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Memory Networks" target="Sequence to Sequence Learning">
  <data key="d5">14.0</data>
  <data key="d6">Memory networks enhance sequence-to-sequence tasks by integrating reasoning and memory capabilities.&lt;SEP&gt;Memory networks enhance sequence-to-sequence tasks by integrating reasoning capabilities.</data>
  <data key="d7">model improvement, reasoning</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Catastrophic Forgetting" target="Elastic Weight Consolidation">
  <data key="d5">16.0</data>
  <data key="d6">Elastic Weight Consolidation is a methodology designed to mitigate catastrophic forgetting in neural networks.</data>
  <data key="d7">training challenge, mitigation method</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Catastrophic Forgetting" target="Knowledge Update">
  <data key="d5">6.0</data>
  <data key="d6">Knowledge updates, especially explicit instructions, can lead to catastrophic forgetting, where previous knowledge is lost during new learning phases.</data>
  <data key="d7">limitations, challenges</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Catastrophic Forgetting" target="Knowledge Expansion">
  <data key="d5">6.0</data>
  <data key="d6">Expanding a model's knowledge can lead to catastrophic forgetting, where previous knowledge is lost during new training."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Catastrophic Forgetting" target="Downstream Performance">
  <data key="d5">12.0</data>
  <data key="d6">Continuing to fine-tune models beyond a certain point leads to decreased downstream task performance due to catastrophic forgetting.&lt;SEP&gt;Continuing to fine-tune models beyond a certain point leads to performance decline because of catastrophic forgetting."|</data>
  <data key="d7">6&lt;SEP&gt;training limitation, model degradation</data>
  <data key="d8">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Attention Mechanism" target="Transformers">
  <data key="d5">26.0</data>
  <data key="d6">The attention mechanism is fundamental to the transformer architecture, enabling models to weigh input features dynamically.&lt;SEP&gt;Transformers rely on attention mechanisms, as introduced in 'Attention Is All You Need,' to model sequences effectively.</data>
  <data key="d7">neural component, architecture&lt;SEP&gt;theoretical basis, neural architecture</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Attention Mechanism" target="Tiny-Attention Adapter">
  <data key="d5">6.0</data>
  <data key="d6">Tiny-attention adapters use attention mechanisms with reduced dimensionality to improve efficiency.</data>
  <data key="d7">attention, model efficiency</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Attention Mechanism" target="Large Language Models of Code">
  <data key="d5">16.0</data>
  <data key="d6">Attention mechanisms underpin large language models, enabling them to focus on relevant code parts for tasks like summarization and generation.</data>
  <data key="d7">theory, application</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Attention Is All You Need" target="Transformers">
  <data key="d5">10.0</data>
  <data key="d6">The paper introduces the Transformer model, which relies solely on attention mechanisms, foundational for many subsequent models.</data>
  <data key="d7">theoretical basis, neural architecture</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Diverse Beam Search" target="Scene Description">
  <data key="d5">14.0</data>
  <data key="d6">Diverse beam search improves the generation of complex scene descriptions by encouraging varied outputs.</data>
  <data key="d7">decoding strategy, NLP generation</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, Jing Jiang" target="R3: Reinforced ranker-reader for open-domain question answering">
  <data key="d5">16.0</data>
  <data key="d6">Development of a reinforcement learning-based model architecture for open-domain question answering.&lt;SEP&gt;Development of a reinforcement learning-based model architecture for question answering.</data>
  <data key="d7">model development, AI application</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, Jing Jiang" target="Evidence aggregation for answer re-ranking in open-domain question answering">
  <data key="d5">9.0</data>
  <data key="d6">Research on evidence aggregation techniques to improve answer ranking accuracy in open-domain QA.</data>
  <data key="d7">evidence processing, QA improvement</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Evidence aggregation for answer re-ranking in open-domain question answering" target="Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu Chang, Zhiguo Wang, Tim Klinger, Gerald Tesauro, Murray Campbell">
  <data key="d5">9.0</data>
  <data key="d6">Research on evidence aggregation techniques to improve answer ranking accuracy.</data>
  <data key="d7">evidence processing, QA improvement</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jason Weston, Sumit Chopra, and Antoine Bordes" target="Memory networks">
  <data key="d5">16.0</data>
  <data key="d6">Developed memory network models to enhance reasoning and question answering capabilities.&lt;SEP&gt;Developed memory network models to enhance reasoning and reasoning-based question answering.</data>
  <data key="d7">model innovation, reasoning</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Retrieve and refine: Improved sequence generation models for dialogue" target="Jason Weston, Emily Dinan, and Alexander Miller">
  <data key="d5">18.0</data>
  <data key="d6">Research on improving dialogue response generation through sequence refinement techniques.&lt;SEP&gt;Research on improving dialogue response generation through sequence refinement.</data>
  <data key="d7">dialogue systems, NLP models</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush" target="Huggingface’s transformers">
  <data key="d5">1.0</data>
  <data key="d6">Tools</data>
  <data key="d7">A toolkit for deploying and fine-tuning transformer-based NLP models, enabling state-of-the-art NLP research and applications.</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Shiyue Zhang and Mohit Bansal" target="Addressing semantic drift in question generation for semi-supervised question answering">
  <data key="d5">16.0</data>
  <data key="d6">Research focused on reducing semantic drift to improve question generation stability.&lt;SEP&gt;Research focused on reducing semantic drift to improve the stability and accuracy of question generation models.</data>
  <data key="d7">model stability, QA accuracy</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, and Jian Yin" target="Reasoning over semantic-level graph for fact checking">
  <data key="d5">16.0</data>
  <data key="d6">Employs semantic graphs for reasoning to verify factual correctness in NLP tasks.</data>
  <data key="d7">fact verification, semantic reasoning</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Matthew Dunn" target="arXiv:1704.05179">
  <data key="d5">12.0</data>
  <data key="d6">Dunn introduced SearchQA, a dataset augmented with search engine context for Q&amp;A tasks.&lt;SEP&gt;Dunn's SearchQA dataset augmented with search engine context advances NLP question answering.</data>
  <data key="d7">dataset creation, NLP research</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="GPT" target="Autoregressive Language Models">
  <data key="d5">18.0</data>
  <data key="d6">GPT models are a type of autoregressive language model that generate text by predicting the next token based on previous tokens, suitable for text generation.&lt;SEP&gt;GPT models generate text by predicting the next token based on prior tokens, suitable for various text generation applications.</data>
  <data key="d7">model-type, text generation</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Transformers" target="Code Generation from Natural Language">
  <data key="d5">9.0</data>
  <data key="d6">Transformers serve as the backbone architecture for models performing natural language to code translation.</data>
  <data key="d7">model, application</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Transformers" target="Deep Learning Architecture">
  <data key="d5">20.0</data>
  <data key="d6">Transformers are the foundational architecture for modern NLP models, enabling efficient processing of sequential data through self-attention mechanisms.&lt;SEP&gt;Transformers form the basis of modern NLP models, utilizing self-attention mechanisms for efficient sequence processing.</data>
  <data key="d7">Methodologies, Applications/Implications</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Completion, Summarization, Translation, Lookup" target="Code Generation Effectiveness">
  <data key="d5">7.0</data>
  <data key="d6">These tasks are indicators of how effectively models can generate and understand code.</data>
  <data key="d7">task effectiveness, AI capabilities</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Programming Models" target="Code Generation Effectiveness">
  <data key="d5">8.0</data>
  <data key="d6">The performance of models is assessed across different parallel programming models such as MPI, OpenMP, CUDA, etc.</data>
  <data key="d7">model performance, programming paradigms</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Programming Models" target="HPC Numerical Kernels">
  <data key="d5">8.0</data>
  <data key="d6">HPC numerical kernels are targeted in various programming languages to evaluate AI-generated code's effectiveness in parallel computing."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="benchmarks" target="timing measurements">
  <data key="d5">9.0</data>
  <data key="d6">Timing measurements are added to benchmarks to evaluate performance improvements after optimization.</data>
  <data key="d7">performance evaluation</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="benchmarks" target="data set/configuration">
  <data key="d5">7.0</data>
  <data key="d6">The largest dataset/configuration is used consistently across benchmarks for standardized testing.</data>
  <data key="d7">standardization, benchmarking</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="limitations" target="future work">
  <data key="d5">16.0</data>
  <data key="d6">Addressing current limitations will extend the applicability and efficiency of the optimization framework."|&gt;"development, research directions&lt;SEP&gt;Addressing current limitations will extend the framework's efficiency and applicability."|&gt;"development, research directions</data>
  <data key="d7">8</data>
  <data key="d8">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="correctness" target="paralle code">
  <data key="d5">9.0</data>
  <data key="d6">Providing correct implementations in one execution model helps LLMs generate correct code in another, as shown by improved pass@1 scores.</data>
  <data key="d7">accuracy, implementation correctness</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="correctness" target="pass@1 scores">
  <data key="d5">9.0</data>
  <data key="d6">Higher pass@1 scores indicate a higher probability of the first generated code being correct.</data>
  <data key="d7">accuracy, code correctness</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="correctness" target="LLMs">
  <data key="d5">7.0</data>
  <data key="d6">LLMs' ability to generate correct parallel code improves when given correct implementation examples.</data>
  <data key="d7">learning, accuracy improvement</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Transformer-based models" target="Large Language Models for Code">
  <data key="d5">16.0</data>
  <data key="d6">Transformer architectures underpin the design of large language models used for code understanding and generation.&lt;SEP&gt;Transformer-based models form the architectural basis for large language models used in code generation and understanding tasks.</data>
  <data key="d7">model architecture&lt;SEP&gt;model architecture, NLP modeling</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Large Language Models for Code" target="Pre-training corpus">
  <data key="d5">18.0</data>
  <data key="d6">Large language models are trained on extensive corpora of code and natural language datasets to develop their understanding and generation capabilities.&lt;SEP&gt;These models are trained on large corpora of code and natural language datasets, which shape their capabilities.</data>
  <data key="d7">training data&lt;SEP&gt;training data, model training</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Nucleus Sampling" target="Model Temperature">
  <data key="d5">14.0</data>
  <data key="d6">Both are strategies to control the diversity and quality of generated code, with nucleus sampling selecting from a probability distribution and temperature adjusting output randomness.&lt;SEP&gt;Both are strategies to influence the diversity and quality of generated outputs in language modeling, with nucleus sampling selecting from a probability distribution and temperature adjusting output randomness.</data>
  <data key="d7">sampling strategies&lt;SEP&gt;sampling strategy, output control</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Nucleus Sampling" target="Sampling Methods">
  <data key="d5">8.0</data>
  <data key="d6">Nucleus sampling dynamically selects tokens based on a cumulative probability p, balancing diversity and relevance in generated text.</data>
  <data key="d7">diversity, relevance</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Nucleus Sampling" target="Sampling Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Nucleus sampling dynamically selects tokens based on a cumulative probability threshold p, providing a balance between diversity and relevance in output.</data>
  <data key="d7">diversity, relevance</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Benchmarking LLMs for code-related tasks" target="Applying LLMs to parallel and HPC code">
  <data key="d5">16.0</data>
  <data key="d6">Benchmarking evaluates the effectiveness of LLMs in generating and understanding HPC and parallel code, testing their domain-specific performance.&lt;SEP&gt;Benchmarking evaluates the performance of LLMs on specific code tasks, including their application to parallel and HPC code, to assess their effectiveness in specialized domains.</data>
  <data key="d7">evaluation&lt;SEP&gt;evaluation, domain-specific testing</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Applying LLMs to parallel and HPC code" target="HPCCoder">
  <data key="d5">18.0</data>
  <data key="d6">HPCCoder exemplifies an LLM fine-tuned for HPC applications, demonstrating specialized application in high-performance computing environments.&lt;SEP&gt;HPCCoder is an example of an LLM fine-tuned for HPC applications, demonstrating application of models to high-performance computing tasks.</data>
  <data key="d7">domain-specific model&lt;SEP&gt;specialized model, domain application</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="HPCCoder" target="LLMs">
  <data key="d5">8.0</data>
  <data key="d6">HPCCoder is a specialized LLM fine-tuned on HPC code to improve its ability to generate relevant HPC programs.</data>
  <data key="d7">model specialization, code generation</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel code" target="Kernels">
  <data key="d5">8.0</data>
  <data key="d6">Different kernels are tested with various code versions to analyze performance and stability.</data>
  <data key="d7">performance testing, code evaluation</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Code generation tasks" target="Benchmarking datasets">
  <data key="d5">8.0</data>
  <data key="d6">Code generation tasks are assessed using benchmarks like HumanEval, MBPP, DS-1000, which evaluate models' ability to produce correct code.</data>
  <data key="d7">evaluation tasks</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="HPC-specific tokenizer" target="Training datasets">
  <data key="d5">7.0</data>
  <data key="d6">HPC-specific tokenizers like TOKOMPILER are trained on domain-specific code to improve model tokenization and performance.</data>
  <data key="d7">tool development</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="TOKOMPILER" target="COMPCODER">
  <data key="d5">7.0</data>
  <data key="d6">TOKOMPILER is a tokenizer used to train COMPCODER, enabling it to process HPC-specific programming languages effectively.</data>
  <data key="d7">tool training, language processing</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="COMPCODER" target="HPC code generation and analysis">
  <data key="d5">8.0</data>
  <data key="d6">COMPCODER is trained on C, C++, and Fortran code to generate and evaluate HPC programs.</data>
  <data key="d7">model training, HPC applications</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="HPC tasks">
  <data key="d5">9.0</data>
  <data key="d6">LLMs are applied to generate, verify, and analyze HPC code, including tasks like performance prediction and bug detection.</data>
  <data key="d7">application area, AI models</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="Kokkos">
  <data key="d5">14.0</data>
  <data key="d6">Kokkos serves as a benchmark object to evaluate how well LLMs can model complex parallel programming code."|&lt;SEP&gt;Kokkos serves as a benchmark to evaluate how well LLMs can model a complex parallel programming model."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="CUDA">
  <data key="d5">16.0</data>
  <data key="d6">LLMs show similar pass@1 scores for CUDA and HIP, indicating comparable performance in modeling GPU-accelerated code."|&lt;SEP&gt;LLMs show varying pass@1 scores for CUDA, with performance similar to HIP, indicating the models' ability to handle GPU-accelerated code."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="HIP">
  <data key="d5">16.0</data>
  <data key="d6">LLMs perform similarly on HIP as on CUDA, reflecting their ability to model AMD GPU code."|&lt;SEP&gt;Similar to CUDA, HIP is a target for LLMs, with performance metrics indicating their proficiency in modeling AMD GPU code."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="MPI">
  <data key="d5">18.0</data>
  <data key="d6">MPI code modeling is particularly challenging for LLMs due to its complexity and divergence from serial code, resulting in lower correctness scores."|&lt;SEP&gt;MPI modeling is particularly challenging for LLMs due to its complexity and divergence from serial code, resulting in lower correctness scores."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="parallelism">
  <data key="d5">16.0</data>
  <data key="d6">The intrinsic parallelism of CUDA/HIP makes it easier for LLMs to generate correct code compared to MPI, which involves more complex reasoning."|&lt;SEP&gt;The intrinsic parallelism of models like CUDA/HIP makes it easier for LLMs to generate correct code compared to models like MPI, which involve more complex reasoning."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="structured problems">
  <data key="d5">16.0</data>
  <data key="d6">LLMs perform better on structured, dense problems like transform, reduce, and search, which are simpler to parallelize."|&lt;SEP&gt;LLMs perform better on structured, dense problems such as transform, reduce, and search, which are simpler to parallelize."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="sparse problems">
  <data key="d5">18.0</data>
  <data key="d6">Sparse linear algebra, FFT, and geometry are difficult for LLMs due to their unstructured nature and complexity in parallelization."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="problem type and performance">
  <data key="d5">16.0</data>
  <data key="d6">Performance varies across problem types, with the highest scores on transform problems and the lowest on sparse linear algebra."|&lt;SEP&gt;Performance varies significantly across different problem types, with the best scores on transform problems and the worst on sparse linear algebra."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="complexity and difficulty">
  <data key="d5">8.0</data>
  <data key="d6">The more a parallel programming model's code differs from its serial version, the more difficult it is for LLMs to generate correct code, especially for MPI and MPI+OpenMP."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="parEval">
  <data key="d5">8.0</data>
  <data key="d6">The ParEval benchmark evaluates LLMs' capacity to generate parallel code and assess its performance and scalability.</data>
  <data key="d7">benchmark, evaluation</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="Knowledge Extraction">
  <data key="d5">8.0</data>
  <data key="d6">Knowledge extraction is a core process enabling LLMs to incorporate current and domain-specific information from training data.</data>
  <data key="d7">information retrieval, model updating</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Downstream Task Learning">
  <data key="d5">9.0</data>
  <data key="d6">Downstream task learning adapts LLMs to specific tasks, requiring high-quality data and careful tuning.</data>
  <data key="d7">model fine-tuning, task adaptation</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Backpropagation">
  <data key="d5">16.0</data>
  <data key="d6">Backpropagation is used to train LLMs by updating their weights based on error signals during learning.&lt;SEP&gt;Backpropagation is used to update the weights of LLMs during training, including during fine-tuning processes.</data>
  <data key="d7">training algorithm, neural network&lt;SEP&gt;training process, neural network training</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Adapters">
  <data key="d5">18.0</data>
  <data key="d6">Adapters are inserted modules within LLMs to facilitate efficient domain adaptation and task-specific tuning.&lt;SEP&gt;Adapters are integrated into LLMs to facilitate domain adaptation and task-specific fine-tuning without full model retraining.</data>
  <data key="d7">model adaptation, modular training&lt;SEP&gt;model modification, modular learning</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Task-oriented Fine-tuning">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning on specific datasets enhances LLM performance on targeted tasks.&lt;SEP&gt;Task-oriented fine-tuning involves updating LLMs on specific datasets to improve task performance.</data>
  <data key="d7">model improvement, domain adaptation&lt;SEP&gt;performance improvement, domain adaptation</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Instruction-based Fine-tuning">
  <data key="d5">18.0</data>
  <data key="d6">This approach enhances LLMs' performance on unseen tasks by training on explicit instructions across diverse datasets.&lt;SEP&gt;This method involves training LLMs on datasets with explicit instructions to improve generalization to new tasks.</data>
  <data key="d7">task generalization, instruction learning&lt;SEP&gt;task generalization, instruction tuning</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Reinforcement Learning from Human Feedback">
  <data key="d5">16.0</data>
  <data key="d6">RLHF aligns LLM outputs with human preferences through iterative feedback and reward-based updates.&lt;SEP&gt;RLHF aligns LLM outputs with human preferences through iterative feedback, ranking, and policy updates.</data>
  <data key="d7">alignment, safety&lt;SEP&gt;content safety, alignment</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Training Memory">
  <data key="d5">12.0</data>
  <data key="d6">Optimizing training memory is essential for efficient fine-tuning of large models, often through architectural or strategic innovations.&lt;SEP&gt;Reducing training memory is crucial for efficient fine-tuning of large models, achieved via architecture or strategy innovations.</data>
  <data key="d7">efficiency, resource management</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="High-quality Datasets">
  <data key="d5">8.0</data>
  <data key="d6">Domain-specific datasets are essential for effective task-oriented fine-tuning of LLMs.</data>
  <data key="d7">training data, domain adaptation</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="High-quality Domain-specific Datasets">
  <data key="d5">8.0</data>
  <data key="d6">These datasets are crucial for effective fine-tuning to improve task-specific performance.</data>
  <data key="d7">training data, domain adaptation</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Genomic data">
  <data key="d5">15.0</data>
  <data key="d6">LLMs analyze genomic data to understand biological functions and disease mechanisms.</data>
  <data key="d7">data analysis, biological insight</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Proteomic data">
  <data key="d5">13.0</data>
  <data key="d6">LLMs analyze proteomic data to understand cellular processes and interactions.</data>
  <data key="d7">data analysis, cellular biology</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Protein structures and interactions">
  <data key="d5">16.0</data>
  <data key="d6">LLMs predict protein structures and interactions, aiding in drug discovery and understanding diseases.</data>
  <data key="d7">structure prediction, biomedical research</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Medical records">
  <data key="d5">14.0</data>
  <data key="d6">LLMs analyze medical records for pattern recognition, diagnosis, and personalized treatment recommendations.</data>
  <data key="d7">medical informatics, diagnosis</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Medical image analysis">
  <data key="d5">16.0</data>
  <data key="d6">LLMs assist in analyzing X-rays and MRI scans through multi-modality learning methods.</data>
  <data key="d7">medical imaging, AI analysis</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Problems" target="Component Counting">
  <data key="d5">12.0</data>
  <data key="d6">Component counting is a problem type used to test the core functionality of computational models.&lt;SEP&gt;Component counting is a type of problem used to test the core functionality of computational models.</data>
  <data key="d7">problem type, core functionality</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problems" target="Prompt">
  <data key="d5">14.0</data>
  <data key="d6">Problems are associated with prompts that describe tasks to be completed by LLMs for code generation.</data>
  <data key="d7">task description, code generation</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problems" target="Problem Variations">
  <data key="d5">16.0</data>
  <data key="d6">Variations of problems are designed to test the robustness and understanding of models on similar but distinct tasks.</data>
  <data key="d7">robustness, model understanding</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problems" target="Filtering">
  <data key="d5">8.0</data>
  <data key="d6">Filtering ensures only high-quality problems remain by verifying generated solutions pass unit tests, removing ambiguous ones."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Geometry" target="Convex Hull">
  <data key="d5">14.0</data>
  <data key="d6">Convex hull is a geometric property computed as part of geometric analysis in the study.</data>
  <data key="d7">geometric properties, geometric analysis</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Fourier Transform" target="Transform">
  <data key="d5">16.0</data>
  <data key="d6">Fourier Transform is used to analyze signals, with both standard and inverse transforms being computed.</data>
  <data key="d7">signal processing, mathematical analysis</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Prompt" target="Equation (2)">
  <data key="d5">16.0</data>
  <data key="d6">Defines the expected best speedup for a specific prompt, considering multiple samples and resources.&lt;SEP&gt;Defines the expected maximum speedup for a specific prompt based on sample runtimes and baseline, considering multiple samples and resources.</data>
  <data key="d7">model performance, theoretical calculation&lt;SEP&gt;performance modeling, theoretical calculation</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Prompt" target="Equation (3)">
  <data key="d5">7.0</data>
  <data key="d6">Provides an average measure of the maximum speedup over prompts, summarizing overall performance.</data>
  <data key="d7">performance summary, averaging</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Prompt" target="Generated Code Samples">
  <data key="d5">8.0</data>
  <data key="d6">Prompts serve as input to the model, which then generates code samples based on these descriptions."|&lt;"input-output relationship, prompt-based generation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Kokkos" target="Prompts">
  <data key="d5">16.0</data>
  <data key="d6">Kokkos prompts involve using Kokkos data structures like Kokkos::View for parallel code.</data>
  <data key="d7">parallel data structures, portability</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Kokkos" target="Partial Minimums">
  <data key="d5">18.0</data>
  <data key="d6">The partial minimums problem is implemented using Kokkos for parallel execution in the provided example.</data>
  <data key="d7">parallel algorithms, Kokkos</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Kokkos" target="C++">
  <data key="d5">16.0</data>
  <data key="d6">Kokkos provides a C++ interface for performance portability, enabling code to run efficiently on different hardware architectures.&lt;SEP&gt;Kokkos provides a performance portability layer for C++, allowing code to run efficiently across various architectures and influencing correctness and performance.</data>
  <data key="d7">performance portability, hardware abstraction</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Kokkos" target="High-level programming model">
  <data key="d5">7.0</data>
  <data key="d6">Kokkos offers a performance-portable abstraction layer to write code that runs efficiently across different hardware architectures."|&gt;"performance portability</data>
  <data key="d7">7</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Prompts" target="C++">
  <data key="d5">14.0</data>
  <data key="d6">C++ prompts are used for serial, OpenMP, MPI, and MPI+OpenMP models, utilizing standard data structures.</data>
  <data key="d7">programming language, data structures</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Prompts" target="CUDA">
  <data key="d5">16.0</data>
  <data key="d6">CUDA prompts are designed for GPU programming, utilizing raw pointers and CUDA-specific syntax.</data>
  <data key="d7">GPU programming, code syntax</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Prompts" target="HIP">
  <data key="d5">14.0</data>
  <data key="d6">HIP prompts are similar to CUDA, used for GPU programming with HIP syntax.</data>
  <data key="d7">GPU programming, cross-platform support</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Prompts" target="Speedup𝑛@𝑘">
  <data key="d5">7.0</data>
  <data key="d6">This metric averages the maximum speedup over all prompts, providing an overall performance measure of the model across different inputs.</data>
  <data key="d7">performance averaging, prompt evaluation</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Prompts" target="Equation (3)">
  <data key="d5">7.0</data>
  <data key="d6">Provides an average of maximum speedups across prompts, summarizing overall model performance in parallel code generation.</data>
  <data key="d7">performance summary, averaging</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Prompts" target="Bias in Model">
  <data key="d5">6.0</data>
  <data key="d6">Type and framing of prompts influence the likelihood of biased outputs.</data>
  <data key="d7">prompt engineering, bias sensitivity</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="C++" target="OpenACC">
  <data key="d5">14.0</data>
  <data key="d6">OpenACC directives are incorporated into C++ code to manage GPU acceleration, impacting code behavior and efficiency.&lt;SEP&gt;OpenACC directives are integrated into C++ code to offload computations to GPUs, impacting correctness and efficiency.</data>
  <data key="d7">accelerated computing, GPU offloading</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="C++" target="CUDA">
  <data key="d5">18.0</data>
  <data key="d6">CUDA enables GPU programming within C++, with kernels and functions directly influencing code correctness, efficiency, and parallel execution.&lt;SEP&gt;CUDA is used within C++ to develop GPU-accelerated applications, with functions influencing code correctness and efficiency.</data>
  <data key="d7">GPU programming, parallel execution&lt;SEP&gt;GPU programming, parallelism</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="C++" target="HIP">
  <data key="d5">16.0</data>
  <data key="d6">HIP enables writing portable C++ code for AMD and NVIDIA GPUs, affecting code compatibility and performance.&lt;SEP&gt;HIP facilitates writing portable C++ code for AMD and NVIDIA GPUs, affecting code compatibility and execution correctness.</data>
  <data key="d7">heterogeneous computing, code portability</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="C++" target="Thrust">
  <data key="d5">16.0</data>
  <data key="d6">Thrust library enables high-level parallel algorithms in C++, optimized for CUDA, impacting code correctness and performance.&lt;SEP&gt;Thrust library provides parallel algorithms in C++ optimized for CUDA, affecting code correctness and performance.</data>
  <data key="d7">parallel algorithms, GPU acceleration</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="CUDA" target="GPU acceleration">
  <data key="d5">9.0</data>
  <data key="d6">CUDA enables GPU-based acceleration for scientific computing kernels, improving performance."|&gt;"GPU computing, acceleration</data>
  <data key="d7">9</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="CUDA" target="Accelerator Offloading">
  <data key="d5">24.0</data>
  <data key="d6">CUDA enables offloading of compute-intensive tasks to GPUs, leveraging their massive parallelism for acceleration.&lt;SEP&gt;CUDA is used to offload computations to GPUs, enabling acceleration of parallel tasks.&lt;SEP&gt;CUDA is used to offload specific kernels to GPUs, enabling high throughput computations and acceleration.</data>
  <data key="d7">GPU acceleration, kernel offloading&lt;SEP&gt;GPU computing, acceleration</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="CUDA" target="Memory Locality">
  <data key="d5">16.0</data>
  <data key="d6">CUDA provides mechanisms to manage data movement and memory access, facilitating memory locality and efficient data transfers between host and device.</data>
  <data key="d7">GPU programming, data management</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Large Language Models (LLMs)" target="Generative AI">
  <data key="d5">8.0</data>
  <data key="d6">LLMs like GPT-3 are examples of generative AI tools capable of producing code and text for HPC applications."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Large Language Models (LLMs)" target="Domain-Specific Techniques">
  <data key="d5">9.0</data>
  <data key="d6">Domain-specific techniques are developed to enhance LLMs' performance in specialized fields by addressing knowledge gaps and model limitations."|</data>
  <data key="d7">model adaptation, specialization</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models (LLMs)" target="Jingfeng Yang">
  <data key="d5">16.0</data>
  <data key="d6">Yang's survey discusses the capabilities and applications of large language models."|</data>
  <data key="d7">application</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Code Llama" target="Code Summarization">
  <data key="d5">18.0</data>
  <data key="d6">Code Llama is designed to support code summarization tasks, providing models for generating concise descriptions of code functionalities.</data>
  <data key="d7">application, model purpose</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Experiment 2" target="CodeLlama, StarCoderBase">
  <data key="d5">8.0</data>
  <data key="d6">Tools</data>
  <data key="d7">CodeLlama and StarCoderBase are models evaluated for their code translation capabilities in the second experiment.</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="StarCoderBase" target="The Stack">
  <data key="d5">8.0</data>
  <data key="d6">The dataset The Stack provides training data for StarCoderBase, enabling its code generation capabilities."&lt;&gt; "training data source</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="MPI" target="Distributed Memory">
  <data key="d5">17.0</data>
  <data key="d6">MPI enables explicit communication and synchronization across nodes with distributed memory architectures.&lt;SEP&gt;MPI supports explicit communication and synchronization across nodes with distributed memory, enabling coordinated parallel processing.</data>
  <data key="d7">distributed systems, communication</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="MPI" target="Parallel Framework">
  <data key="d5">18.0</data>
  <data key="d6">MPI provides the foundational model for message passing in distributed systems, enabling scalable parallel communication across processes.&lt;SEP&gt;MPI provides the foundational model for message passing in parallel computing, facilitating communication between processes.</data>
  <data key="d7">parallel computing, message passing&lt;SEP&gt;parallel processing, message passing</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="training dataset" target="Codex and Codex-D">
  <data key="d5">18.0</data>
  <data key="d6">The models are trained on datasets comprising code problems, solutions, and annotations, which influence their ability to generate accurate code and docstrings.&lt;SEP&gt;The training datasets include code problems, solutions, and docstrings, which are used to train the respective models for code and docstring generation.</data>
  <data key="d7">training data, model training</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="training dataset" target="fine-tuning setup and hyperparameters">
  <data key="d5">12.0</data>
  <data key="d6">The training dataset is the primary data used for model adaptation and learning.</data>
  <data key="d7">training data, model adaptation</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Sequential Baseline" target="Speedup">
  <data key="d5">16.0</data>
  <data key="d6">Speedup is computed relative to a baseline representing a straightforward, sequential execution, serving as a reference for performance gains.&lt;SEP&gt;Speedup is computed relative to the sequential baseline, which serves as a reference point for measuring performance improvements.</data>
  <data key="d7">performance comparison, baseline reference&lt;SEP&gt;performance measurement, baseline comparison</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Speedup" target="Kmeans">
  <data key="d5">9.0</data>
  <data key="d6">Optimizations in Kmeans achieved nearly six times faster runtimes in the original code.</data>
  <data key="d7">performance improvement, kernel optimization</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Speedup" target="nnbenchmarks">
  <data key="d5">10.0</data>
  <data key="d6">Neural network benchmarks like nnbenchmarks experienced up to 57 times faster runtimes after optimization.</data>
  <data key="d7">performance enhancement, parallel utilization</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Speedup" target="Hotspot Benchmark">
  <data key="d5">8.0</data>
  <data key="d6">The hotspot benchmark's static code restructuring led to a speedup of 2.72 by enabling parallel execution of stencil borders and edge cases.</data>
  <data key="d7">performance, code restructuring</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Speedup" target="lavaMD">
  <data key="d5">9.0</data>
  <data key="d6">The lavaMD benchmark showed over two times speedup, partly due to compiler optimizations from Intel OneAPI.</data>
  <data key="d7">performance, compiler optimization</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Speedup" target="Global optimization">
  <data key="d5">7.0</data>
  <data key="d6">The global optimization process sometimes chooses to use only CPU resources or limited hardware based on data transfer and synchronization costs, affecting overall speedup.</data>
  <data key="d7">resource allocation, performance</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Speedupmax@𝑘" target="Resource Counts">
  <data key="d5">6.0</data>
  <data key="d6">This metric estimates the maximum achievable speedup across different resource counts, indicating potential peak performance.</data>
  <data key="d7">performance ceiling, resource scaling</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Speedupmax@𝑘" target="Resources">
  <data key="d5">6.0</data>
  <data key="d6">This metric estimates the maximum speedup achievable over various resource counts, indicating potential scalability and peak performance.</data>
  <data key="d7">scalability, resource scaling</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Equation (4)" target="Resource Counts">
  <data key="d5">6.0</data>
  <data key="d6">Estimates the maximum speedup achievable over different resource counts, reflecting potential scalability.</data>
  <data key="d7">scalability, maximum performance</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Equation (4)" target="Resources">
  <data key="d5">6.0</data>
  <data key="d6">Estimates the maximum speedup possible over different resource counts, reflecting the scalability potential of the code.</data>
  <data key="d7">scalability, performance ceiling</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Speedup𝑛@𝑘" target="Prompt Samples">
  <data key="d5">7.0</data>
  <data key="d6">This metric averages the maximum speedup over all generated samples for each prompt, representing overall model efficiency.</data>
  <data key="d7">performance averaging, sample evaluation</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Efficiency𝑛@𝑘" target="Resources">
  <data key="d5">18.0</data>
  <data key="d6">Efficiency measures how effectively the code utilizes the given resources, normalized by the number of resources.&lt;SEP&gt;Efficiency measures how effectively the generated code uses the given resources, normalized by the number of resources.</data>
  <data key="d7">performance efficiency, resource utilization</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Equation (3)" target="performance of the generated code">
  <data key="d5">8.0</data>
  <data key="d6">Equation (3) defines the efficiency𝑛@𝑘 metric, linking the core concept of performance measurement to the theoretical model of code scalability."|"&lt;modeling</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Equation (5)" target="Resources">
  <data key="d5">18.0</data>
  <data key="d6">Defines efficiency as the ratio of speedup to resources, assessing how well the generated code scales with increased parallel resources.&lt;SEP&gt;Defines efficiency as the ratio of speedup to resources, assessing parallel performance effectiveness.</data>
  <data key="d7">parallel efficiency, performance assessment&lt;SEP&gt;parallel efficiency, performance scaling</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Equation (5)" target="efficiency𝑛@𝑘">
  <data key="d5">16.0</data>
  <data key="d6">Equation (5) provides a formula for calculating efficiency𝑛@𝑘, relating the metric to performance, number of processes, and execution time, thus operationalizing the core concept of efficiency.&lt;SEP&gt;Equation (5) provides a formula to calculate efficiency𝑛@𝑘 based on performance metrics, linking the theoretical model to practical computation."|"&lt;quantification</data>
  <data key="d7">8&lt;SEP&gt;quantification</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Resources" target="National Energy Research Scientific Computing Center">
  <data key="d5">16.0</data>
  <data key="d6">Provides high-performance computing resources for scientific research activities.</data>
  <data key="d7">support, infrastructure</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Resources" target="NERSC">
  <data key="d5">16.0</data>
  <data key="d6">Supports research activities by providing high-performance computing resources.&lt;SEP&gt;Supports research using high-performance computing resources.</data>
  <data key="d7">support, infrastructure</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance of the generated code" target="equation (3)">
  <data key="d5">8.0</data>
  <data key="d6">Equation (3) defines the efficiency𝑛@𝑘 metric, which measures expected performance based on attempts, linking the core concept of code efficiency to the theoretical model.</data>
  <data key="d7">modeling</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance of the generated code" target="parallel resources">
  <data key="d5">18.0</data>
  <data key="d6">The efficiency metrics directly evaluate how effectively the generated code utilizes parallel resources, linking resource use to performance outcomes."|"&lt;resource utilization&lt;SEP&gt;The efficiency metrics measure how well the generated code utilizes parallel resources, directly linking resource use to performance evaluation.</data>
  <data key="d7">9&lt;SEP&gt;resource utilization</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance of the generated code" target="sequential code generation">
  <data key="d5">12.0</data>
  <data key="d6">The same efficiency metrics can be applied to sequential code to evaluate its performance, extending the analysis beyond parallelism."|"&lt;performance measurement&lt;SEP&gt;The same metrics can be applied to sequential code to evaluate its efficiency, extending the scope of performance assessment beyond parallelism.</data>
  <data key="d7">6&lt;SEP&gt;performance measurement</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance of the generated code" target="benchmarks (HumanEval, MBPP, DS-1000)">
  <data key="d5">16.0</data>
  <data key="d6">The benchmarks are used to evaluate the speedup1@𝑘, which helps understand code efficiency relative to human baseline performance across different datasets."|"&lt;performance evaluation&lt;SEP&gt;These benchmarks are used to measure speedup1@𝑘, providing insight into code efficiency relative to human performance across datasets."|"&lt;performance evaluation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="efficiency𝑛@𝑘" target="efficiencymax@𝑘">
  <data key="d5">14.0</data>
  <data key="d6">The maximum efficiency at attempt 𝑘, efficiencymax@𝑘, is related to efficiency𝑛@𝑘 as a measure of best-case performance, both metrics assess code's resource utilization.&lt;SEP&gt;The maximum efficiency at attempt 𝑘, efficiencymax@𝑘, relates to efficiency𝑛@𝑘 as a measure of best-case performance, both assessing resource utilization."|"&lt;performance assessment</data>
  <data key="d7">7&lt;SEP&gt;performance assessment</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="OpenAI API" target="Codex">
  <data key="d5">8.0</data>
  <data key="d6">The OpenAI API provides access to Codex models for code generation, facilitating their use in various software tools.</data>
  <data key="d7">tool access, deployment</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="ParEval test harness" target="evaluation of generated code">
  <data key="d5">16.0</data>
  <data key="d6">The test harness evaluates correctness, compile success, and runtime performance of generated code, connecting the methodology to the evaluation process."|"&lt;evaluation process&lt;SEP&gt;The test harness systematically evaluates generated code's correctness and performance, connecting the methodology to the tools and processes used in assessment."|"&lt;evaluation process</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="generated code" target="test harness">
  <data key="d5">16.0</data>
  <data key="d6">The test harness executes the generated code to verify correctness and measure performance metrics.&lt;SEP&gt;The test harness executes the generated code to verify correctness and measure runtime performance.</data>
  <data key="d7">execution, testing</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="generated code" target="sequential baseline">
  <data key="d5">14.0</data>
  <data key="d6">The generated code is compared against the sequential baseline to assess correctness and performance.&lt;SEP&gt;The generated code is compared against the sequential baseline to evaluate correctness and efficiency.</data>
  <data key="d7">comparison, benchmarking</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="generated code" target="parallel programming model">
  <data key="d5">16.0</data>
  <data key="d6">The code is expected to adhere to a specific parallel programming model, which influences its correctness and performance.&lt;SEP&gt;The generated code is expected to utilize a specific parallel programming model, and correctness depends on adherence to it.</data>
  <data key="d7">model adherence, correctness&lt;SEP&gt;model compliance, correctness</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="pass@1" target="GPT-N EO125M">
  <data key="d5">6.0</data>
  <data key="d6">The 125M GPT model achieves a pass@1 of 0.75%, demonstrating baseline effectiveness in code tasks.</data>
  <data key="d7">model performance, baseline</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="pass@1" target="GPT-N EO1.3B">
  <data key="d5">7.0</data>
  <data key="d6">The 1.3B GPT model's performance improves over smaller models, with higher success rates in code generation.</data>
  <data key="d7">model scaling, performance gain</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="pass@1" target="GPT-N EO2.7B">
  <data key="d5">7.0</data>
  <data key="d6">The 2.7B GPT model shows further performance improvement, indicating the benefits of increased parameters.</data>
  <data key="d7">model scaling, accuracy</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="parallelism" target="dynamic control flow">
  <data key="d5">7.0</data>
  <data key="d6">Parallelism within dynamic control flow structures allows for more efficient execution and better utilization of computational resources.</data>
  <data key="d7">parallel execution, control flow</data>
  <data key="d8">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Figure 7" target="Poly-Coder">
  <data key="d5">16.0</data>
  <data key="d6">Poly-Coder's performance is compared to other models, with 84% correct samples, establishing its baseline effectiveness in code compilation.&lt;SEP&gt;Poly-Coder's performance is compared to other models, with 84% correct samples, establishing its effectiveness in code compilation and correctness.</data>
  <data key="d7">performance comparison, model effectiveness</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Figure 7" target="PolyCoder+HPC">
  <data key="d5">16.0</data>
  <data key="d6">PolyCoder+HPC outperforms Poly-Coder with 86% correctness, indicating an improvement in compilation success rate.&lt;SEP&gt;PolyCoder+HPC outperforms Poly-Coder with 86% correctness, showing improvement in code compilation success.</data>
  <data key="d7">performance improvement, model enhancement</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Figure 7" target="GPT-Neo+HPC">
  <data key="d5">14.0</data>
  <data key="d6">GPT-Neo+HPC&lt;SEP&gt;GPT-Neo+HPC performs slightly worse at 74%, indicating less effective code compilation compared to PolyCoder models.</data>
  <data key="d7">GPT-Neo+HPC performs slightly worse at 74%, suggesting less effectiveness in code compilation due to dataset limitations.&lt;SEP&gt;model performance, comparative analysis</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Figure 7" target="GPT2-HPC">
  <data key="d5">12.0</data>
  <data key="d6">GPT2-HPC&lt;SEP&gt;GPT2-HPC has only 30% success rate, likely due to limited code data in pre-training datasets, affecting its performance.</data>
  <data key="d7">GPT2-HPC has only 30% success rate, likely due to limited code in pre-training datasets, affecting its ability to generate correct code.&lt;SEP&gt;dataset influence, model limitation</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Figure 7" target="Build Rate">
  <data key="d5">18.0</data>
  <data key="d6">Models with higher build rates tend to have higher correctness rates, indicating a correlation between successful compilation and correctness.&lt;SEP&gt;Models with higher build rates tend to have higher correctness rates, indicating a positive correlation between compilation success and correct output.</data>
  <data key="d7">performance correlation, compilation success</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Figure 8" target="Speedup and Efficiency">
  <data key="d5">16.0</data>
  <data key="d6">Figure 8 illustrates the maximum expected speedup and efficiency across resource counts, demonstrating how models scale with resources.&lt;SEP&gt;Figure 8 illustrates the maximum expected speedup and efficiency across resource counts, demonstrating scalability and resource utilization.</data>
  <data key="d7">scalability, performance metrics&lt;SEP&gt;scalability, resource utilization</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Figure 9" target="Translation Performance">
  <data key="d5">18.0</data>
  <data key="d6">Figure 9 shows that models perform better when given correct examples, especially for translating serial code to parallel models like OpenMP and MPI.</data>
  <data key="d7">training data, translation accuracy</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Big Code Models Leaderboard" target="Benchmarking Platform">
  <data key="d5">16.0</data>
  <data key="d6">Provides a platform for assessing code models' performance.&lt;SEP&gt;Serves as a platform to benchmark and compare large code models' performance.</data>
  <data key="d7">benchmark, evaluation</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="HIP Documentation" target="Technical Resource">
  <data key="d5">14.0</data>
  <data key="d6">Offers technical details about HIP framework.&lt;SEP&gt;Provides technical details and official guidance on HIP framework used in research.</data>
  <data key="d7">documentation, technical</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang" target="Researchers">
  <data key="d5">16.0</data>
  <data key="d6">Investigate transformer-based approaches for source code summarization.</data>
  <data key="d7">researchers, focus</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Transformer-based Approach" target="Core Concept">
  <data key="d5">16.0</data>
  <data key="d6">A model architecture used for source code summarization.&lt;SEP&gt;A model architecture utilizing transformers to generate source code summaries.</data>
  <data key="d7">concept, architecture</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Source Code Summarization" target="Core Concept">
  <data key="d5">16.0</data>
  <data key="d6">The activity of automatically creating concise explanations of source code functionalities.&lt;SEP&gt;The activity of generating summaries for source code to explain functionality.</data>
  <data key="d7">activity, explanation</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Toufique Ahmed and Prem Devanbu" target="Researchers">
  <data key="d5">16.0</data>
  <data key="d6">Explore learning techniques for code summarization from small, local datasets.&lt;SEP&gt;Explore learning techniques from small, local datasets for code summarization.</data>
  <data key="d7">researchers, focus</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Jacob Austin, Augustus Odena, Maxwell I. Nye, Maarten Bosma, Henryk Michalewski, et al." target="Researchers">
  <data key="d5">16.0</data>
  <data key="d6">Study program synthesis using large language models.&lt;SEP&gt;Study the capabilities of large language models in program synthesis.</data>
  <data key="d7">researchers, focus</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Program Synthesis with Large Language Models" target="Core Concept">
  <data key="d5">16.0</data>
  <data key="d6">Automated generation of code snippets or programs based on specifications using large language models.&lt;SEP&gt;Automated generation of programs using language models.</data>
  <data key="d7">concept, automation</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Language Models are Few-Shot Learners" target="Theory">
  <data key="d5">16.0</data>
  <data key="d6">Demonstrates models' ability to perform tasks with minimal examples.&lt;SEP&gt;Theory demonstrating that large language models can perform tasks with minimal examples, highlighting few-shot learning ability.</data>
  <data key="d7">theory, capability</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Roshanak Zilouchian Moghaddam" target="Anant Kharkar">
  <data key="d5">14.0</data>
  <data key="d6">Both are researchers contributing to software engineering methodologies aimed at improving bug detection accuracy and reducing false positives.&lt;SEP&gt;Both are researchers working on software engineering methodologies aimed at reducing false positives in bug detection tools.</data>
  <data key="d7">collaborative research, bug detection</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Anant Kharkar" target="Matthew Jin">
  <data key="d5">12.0</data>
  <data key="d6">Both focus on analytic bug detection and reducing false positives, indicating a shared research goal.&lt;SEP&gt;Both focus on analytic bug detectors and methods to improve their precision by reducing false positives.</data>
  <data key="d7">bug detection, false positives</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Denis Kocetkov" target="Raymond Li">
  <data key="d5">16.0</data>
  <data key="d6">Both contribute datasets of source code that facilitate machine learning and software analysis research.&lt;SEP&gt;Both contribute datasets related to source code, enabling research on software analysis and machine learning models.</data>
  <data key="d7">dataset sharing, source code analysis</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Yuhang Lai" target="Chengxi Li">
  <data key="d5">16.0</data>
  <data key="d6">Both develop benchmarks and datasets for data science code generation, aiming to evaluate and improve model performance.&lt;SEP&gt;Both work on benchmarks and datasets for data science code generation, aiming to improve model evaluation.</data>
  <data key="d7">benchmark development, data science</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tianyi Zhang" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Tianyi Zhang contributed to the 2022 usability study of AI code generation tools.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Mingjie Liu" target="Nathaniel Pinckney">
  <data key="d5">16.0</data>
  <data key="d6">Both evaluate large language models for code generation, focusing on hardware description languages and general code.&lt;SEP&gt;Both evaluate large language models for code generation, focusing on hardware description languages like Verilog and general programming languages.</data>
  <data key="d7">model evaluation, code generation</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Christian Munley" target="Aaron Jarmusch">
  <data key="d5">16.0</data>
  <data key="d6">Both develop testing and validation tools for compilers and software systems using AI and language models.&lt;SEP&gt;Both develop validation and testing frameworks for compilers and software systems using AI and language models.</data>
  <data key="d7">compiler testing, AI validation</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Daniel Nichols" target="Harshitha Menon">
  <data key="d5">16.0</data>
  <data key="d6">Both apply large language models to model, analyze, and optimize parallel programs in high-performance computing environments.&lt;SEP&gt;Both model parallel programs and improve performance using AI techniques in high-performance computing.</data>
  <data key="d7">parallel programming, AI modeling</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="NVIDIA" target="Péter Vingelmann">
  <data key="d5">16.0</data>
  <data key="d6">Both are involved in GPU computing and CUDA toolkit development for parallel hardware acceleration.&lt;SEP&gt;Both are involved in GPU computing tools and CUDA platform development for parallel computation.</data>
  <data key="d7">GPU tools, parallel computing</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="NVIDIA" target="CUDA Toolkit">
  <data key="d5">9.0</data>
  <data key="d6">NVIDIA developed the CUDA Toolkit to enable GPU programming, optimizing high-performance computations on NVIDIA hardware.</data>
  <data key="d7">Tools</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="NVIDIA" target="Thrust">
  <data key="d5">17.0</data>
  <data key="d6">Thrust is a CUDA library provided by NVIDIA to facilitate parallel algorithms on GPUs.&lt;SEP&gt;Thrust is a library provided by NVIDIA to simplify CUDA programming, enabling parallel algorithms on GPUs.</data>
  <data key="d7">Tools</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="NVIDIA" target="CUDA Toolkit Documentation">
  <data key="d5">10.0</data>
  <data key="d6">NVIDIA provides official documentation for the CUDA Toolkit, which enables GPU programming and high-performance computation.</data>
  <data key="d7">Tools</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Cedric Richter" target="Heike Wehrheim">
  <data key="d5">14.0</data>
  <data key="d6">Both are involved in research on bug localization, repair, and software reliability enhancement.&lt;SEP&gt;Both research bug localization and repair techniques, contributing to software reliability and maintenance.</data>
  <data key="d7">bug fixing, software reliability</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Application" target="Financial Sector LLMs">
  <data key="d5">7.0</data>
  <data key="d6">Development of finance-specific LLMs demonstrates practical benefits in financial NLP tasks, supporting sector-specific needs.</data>
  <data key="d7">sector-specific application, performance</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="OpenAI Codex" target="HPC (High-Performance Computing)">
  <data key="d5">8.0</data>
  <data key="d6">OpenAI Codex is applied to generate HPC kernels, aiding in software development for exascale systems.</data>
  <data key="d7">application, automation</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenAI Codex" target="Kernel Generation">
  <data key="d5">10.0</data>
  <data key="d6">OpenAI Codex is used to generate computational kernels in multiple programming languages and models for HPC applications.</data>
  <data key="d7">application, automation</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenAI Codex" target="GitHub Copilot">
  <data key="d5">18.0</data>
  <data key="d6">GitHub Copilot is based on OpenAI Codex, leveraging its capabilities to generate code for HPC and scientific kernels within IDEs." ,&lt;SEP&gt;GitHub Copilot is based on OpenAI Codex, leveraging its code generation capabilities to assist developers in scientific and HPC kernel development.</data>
  <data key="d7">9&lt;SEP&gt;technology, tool dependency</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenAI Codex" target="GPT-3">
  <data key="d5">16.0</data>
  <data key="d6">GPT-3 is the foundational language model from which Codex is derived, providing the core capabilities for code understanding and generation.&lt;SEP&gt;GPT-3 is the foundational model from which Codex is derived, providing core NLP and code understanding capabilities." ,</data>
  <data key="d7">8&lt;SEP&gt;model hierarchy, technical foundation</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenAI Codex" target="&lt;kernel&gt;">
  <data key="d5">20.0</data>
  <data key="d6">OpenAI Codex is used to generate code snippets for various kernels across languages, aiding in rapid development and testing."|&gt;"code generation, AI assistance&lt;SEP&gt;OpenAI Codex is used to generate code snippets for various kernels across languages, aiding rapid development and testing."|&gt;"code generation, AI assistance</data>
  <data key="d7">10</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Numerical Kernels" target="Programming Models">
  <data key="d5">15.0</data>
  <data key="d6">Numerical kernels are implemented using various programming models, affecting their performance and correctness."|&gt;"implementation, performance&lt;SEP&gt;Numerical kernels are implemented using various programming models, which influence their performance and compatibility.</data>
  <data key="d7">8&lt;SEP&gt;implementation, performance</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Programming Models" target="Kernel Generation">
  <data key="d5">7.0</data>
  <data key="d6">Different programming models influence the quality and efficiency of AI-generated kernels.</data>
  <data key="d7">model influence, code quality</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Programming Models" target="Model Maturity">
  <data key="d5">7.0</data>
  <data key="d6">The maturity level of programming models correlates with the success and quality of AI-generated kernels.</data>
  <data key="d7">adoption, quality</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GitHub Copilot" target="Proficiency Metric">
  <data key="d5">12.0</data>
  <data key="d6">The proficiency metric assesses how well GitHub Copilot's suggestions match expected performance and correctness standards.&lt;SEP&gt;The proficiency metric evaluates the effectiveness of GitHub Copilot in generating relevant and high-quality code suggestions.</data>
  <data key="d7">evaluation, effectiveness</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GitHub Copilot" target="Saki Imai">
  <data key="d5">16.0</data>
  <data key="d6">Imai's empirical study assesses GitHub Copilot as a substitute for human pair-programming.</data>
  <data key="d7">empirical evaluation, AI code suggestion&lt;SEP&gt;empirical evaluation, AI-assisted programming</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GitHub Copilot" target="Nhan Nguyen">
  <data key="d5">34.0</data>
  <data key="d6">Nguyen's empirical evaluation relates to GitHub Copilot's code suggestions and effectiveness."|"&lt;software evaluation, AI tools&lt;SEP&gt;Nguyen's empirical evaluation relates to GitHub Copilot's code suggestions.</data>
  <data key="d7">17&lt;SEP&gt;software evaluation, AI tools</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GitHub Copilot" target="Security">
  <data key="d5">8.0</data>
  <data key="d6">Studies in 2022 evaluated the security of GitHub Copilot’s code contributions, highlighting potential vulnerabilities.</data>
  <data key="d7">Results</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GitHub Copilot" target="Codex">
  <data key="d5">9.0</data>
  <data key="d6">GitHub Copilot utilizes Codex to provide code suggestions, showing a direct application of the model in software development.</data>
  <data key="d7">application, integration</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Language-Supported Programming Models" target="Evaluation of Kernel Generation">
  <data key="d5">7.0</data>
  <data key="d6">Different programming languages and models impact the quality and success of AI-generated kernels.</data>
  <data key="d7">compatibility, performance</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="AI-Assisted Generative Capabilities" target="Evaluation of Kernel Generation">
  <data key="d5">8.0</data>
  <data key="d6">AI's ability to generate accurate and efficient code for numerical kernels is assessed through systematic testing.</data>
  <data key="d7">assessment, performance</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Societal Questions" target="Evaluation of OpenAI Codex">
  <data key="d5">6.0</data>
  <data key="d6">The research addresses societal questions about AI's role in automating HPC software development and its broader implications.</data>
  <data key="d7">societal impact, automation</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="William F. Godoy" target="Evaluation of OpenAI Codex">
  <data key="d5">9.0</data>
  <data key="d6">William F. Godoy is a lead researcher evaluating the capabilities of OpenAI Codex in generating HPC kernels.</data>
  <data key="d7">research, leadership</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="William F. Godoy" target="Julia, Python/Numba, Kokkos">
  <data key="d5">14.0</data>
  <data key="d6">Godoy's performance evaluation study involved Julia, Python/Numba, and Kokkos frameworks.&lt;SEP&gt;Godoy's performance evaluations involved Julia, Python/Numba, and Kokkos frameworks.</data>
  <data key="d7">performance evaluation, programming frameworks</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Kernel Generation" target="Language Prompts">
  <data key="d5">7.0</data>
  <data key="d6"> Adding specific keywords to prompts improves the relevance and quality of AI-generated code in various languages.</data>
  <data key="d7">prompt engineering, code quality</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Kernel Generation" target="AI-Generated Kernel Results">
  <data key="d5">8.0</data>
  <data key="d6">Results from AI-generated kernels are analyzed for correctness, performance, and suitability across programming models.</data>
  <data key="d7">assessment, performance</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GPT-3" target="Codex">
  <data key="d5">15.0</data>
  <data key="d6">Codex is a specialized descendant of GPT-3, optimized for code generation tasks, indicating a developmental relationship.&lt;SEP&gt;GPT-3 serves as a baseline model, which solves 0% of the HumanEval problems, highlighting Codex's improved capabilities.</data>
  <data key="d7">benchmarking, comparison&lt;SEP&gt;model lineage, specialization</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="GPT-3" target="Bias in Text Output">
  <data key="d5">8.0</data>
  <data key="d6">GPT-3 exhibits biases similar to Codex when discussing sensitive groups, with some variation.</data>
  <data key="d7">model bias comparison</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Copilot" target="Code Quality">
  <data key="d5">14.0</data>
  <data key="d6">Copilot helps generate code faster but with lower quality compared to human programmers, as observed in assessments.&lt;SEP&gt;Copilot helps generate code lines faster but with lower quality compared to human programming, as assessed in the literature.</data>
  <data key="d7">performance, code quality&lt;SEP&gt;performance, comparison</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Genetic Programming" target="Code Generation Method">
  <data key="d5">12.0</data>
  <data key="d6">Genetic programming is used as a benchmark for automatic code synthesis, compared to AI tools like Copilot.&lt;SEP&gt;Genetic programming is used as a benchmark for automatic program synthesis, compared to AI tools like Copilot.</data>
  <data key="d7">comparison, methodology</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="PSB2 Program Synthesis Benchmarks" target="Evaluation Dataset">
  <data key="d5">16.0</data>
  <data key="d6">PSB2 benchmarks are used to evaluate the correctness and efficiency of code generated by Copilot and genetic programming.&lt;SEP&gt;The benchmarks are used to evaluate the correctness and efficiency of code generated by Copilot and genetic programming.</data>
  <data key="d7">benchmarking, evaluation</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="HumanEval Dataset" target="Evaluation Dataset">
  <data key="d5">16.0</data>
  <data key="d6">The HumanEval dataset is used to assess the correctness, validity, and efficiency of AI-generated code snippets.&lt;SEP&gt;The HumanEval dataset is used to assess the correctness, validity, and efficiency of AI-generated code.</data>
  <data key="d7">assessment, validation</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenACC" target="OpenACC">
  <data key="d5">15.0</data>
  <data key="d6">OpenACC is a programming standard for accelerators like GPUs, with specifications released in 2020, enabling portable parallel computing.&lt;SEP&gt;OpenACC provides a standardized API for parallel programming on accelerators, including GPUs, and is referenced in the 2020 specification.</data>
  <data key="d7">Theories/Models</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Thrust" target="GPU programming library">
  <data key="d5">7.0</data>
  <data key="d6">Thrust provides high-level parallel algorithms for GPU programming, simplifying development."|&gt;"parallel algorithms, GPU</data>
  <data key="d7">7</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Thrust" target="NVIDIA Corporation">
  <data key="d5">16.0</data>
  <data key="d6">NVIDIA developed Thrust as a library for parallel algorithms on GPUs.&lt;SEP&gt;NVIDIA developed Thrust as a library to facilitate parallel algorithm implementation on GPUs.</data>
  <data key="d7">library development, GPU acceleration</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="SyCL" target="Heterogeneous computing">
  <data key="d5">6.0</data>
  <data key="d6">SyCL allows writing portable code for heterogeneous systems, including CPUs and GPUs."|&gt;"portability, heterogeneity</data>
  <data key="d7">6</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Post fix function" target="C++ and CUDA">
  <data key="d5">7.0</data>
  <data key="d6">Using post fix functions like 'function' in prompts improves the correctness and quality of generated code for kernels.</data>
  <data key="d7">code generation, model sensitivity</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Post fix function" target="Code pattern">
  <data key="d5">7.0</data>
  <data key="d6">Using post fix functions like 'function' in prompts influences the model's sensitivity, leading to more correct and higher-quality generated code.</data>
  <data key="d7">prompt engineering, code quality</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Kernel" target="Function">
  <data key="d5">8.0</data>
  <data key="d6">Kernels are specific functions executed on GPUs, and their design and invocation directly impact correctness and performance.</data>
  <data key="d7">parallel execution, code correctness</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Code correctness" target="Model sensitivity">
  <data key="d5">9.0</data>
  <data key="d6">The sensitivity of the code generation model to prompts affects the correctness of the generated code, with more sensitive prompts leading to more accurate outputs.</data>
  <data key="d7">model behavior, prompt influence</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="HecBench" target="Benchmark repository">
  <data key="d5">6.0</data>
  <data key="d6">HecBench provides a collection of high-performance computing workloads for evaluating models and code performance."|&gt;"benchmarking, evaluation</data>
  <data key="d7">6</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Fortran" target="Legacy HPC code">
  <data key="d5">8.0</data>
  <data key="d6">Fortran remains important in scientific computing due to its extensive legacy codebases and domain-specific applications."|&gt;"legacy code, scientific computing</data>
  <data key="d7">8</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="AXPY" target="Linear algebra benchmark">
  <data key="d5">7.0</data>
  <data key="d6">AXPY is used as a benchmark operation to evaluate the performance of linear algebra kernels."|&gt;"benchmarking, kernels</data>
  <data key="d7">7</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GEMV" target="Linear algebra">
  <data key="d5">8.0</data>
  <data key="d6">GEMV is a fundamental operation in linear algebra, critical for scientific computations."|&gt;"core computational kernel</data>
  <data key="d7">8</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GEMM" target="Linear algebra">
  <data key="d5">8.0</data>
  <data key="d6">GEMM is a core matrix-matrix multiplication operation used extensively in scientific and engineering applications."|&gt;"core operation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="SpMV" target="Sparse linear algebra">
  <data key="d5">7.0</data>
  <data key="d6">SpMV is essential for computations involving sparse matrices, common in large-scale scientific problems."|&gt;"sparse matrices, efficiency</data>
  <data key="d7">7</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Jacobi" target="Numerical method">
  <data key="d5">8.0</data>
  <data key="d6">Jacobi is an iterative numerical method for solving linear systems, widely used in scientific computing."|&gt;"algorithm, iterative method</data>
  <data key="d7">8</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="CG" target="Numerical method">
  <data key="d5">8.0</data>
  <data key="d6">Conjugate Gradient is an iterative solver for large linear systems, important in scientific simulations."|&gt;"solver, iterative method</data>
  <data key="d7">8</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Python" target="Scientific computing">
  <data key="d5">8.0</data>
  <data key="d6">Python is extensively used in scientific computing, AI, and education, with libraries like NumPy and CuPy."|&gt;"programming language, scientific applications</data>
  <data key="d7">8</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Python" target="Code Generation Tools">
  <data key="d5">16.0</data>
  <data key="d6">Python's active growth and readability make it a primary target for code generation tools like Codex.&lt;SEP&gt;Python's widespread use and readability make it a primary target for code generation tools like Codex, influencing its adoption and application.</data>
  <data key="d7">language adoption, tool compatibility&lt;SEP&gt;language adoption, tool integration</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="numpy" target="Numerical library">
  <data key="d5">8.0</data>
  <data key="d6">NumPy provides core numerical operations in Python, enabling scientific computing."|&gt;"numerical computations</data>
  <data key="d7">8</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="numpy" target="CuPy">
  <data key="d5">16.0</data>
  <data key="d6">CuPy is designed to be compatible with NumPy, allowing GPU acceleration of NumPy-like operations.&lt;SEP&gt;CuPy is designed to be compatible with NumPy, enabling GPU-accelerated array operations similar to NumPy but on GPUs."|&gt;"compatibility, acceleration</data>
  <data key="d7">8&lt;SEP&gt;compatibility, acceleration</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="cuPy" target="GPU acceleration">
  <data key="d5">8.0</data>
  <data key="d6">cuPy enables GPU-accelerated computations in Python, compatible with NumPy syntax."|&gt;"GPU computing, Python</data>
  <data key="d7">8</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="pyCUDA" target="GPU kernel development">
  <data key="d5">7.0</data>
  <data key="d6">pyCUDA allows custom CUDA kernel development from Python, facilitating GPU programming."|&gt;"GPU kernels, Python</data>
  <data key="d7">7</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="pyCUDA" target="CuPy">
  <data key="d5">14.0</data>
  <data key="d6">pyCUDA provides low-level access to CUDA, allowing custom kernel development and execution on GPUs, complementing CuPy's high-level array operations."|&gt;"integration, GPU programming&lt;SEP&gt;pyCUDA provides low-level access to CUDA, enabling custom kernel development and execution on GPUs, complementing CuPy's higher-level array operations."|&gt;"integration, GPU programming</data>
  <data key="d7">7</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Numba" target="JIT compiler">
  <data key="d5">6.0</data>
  <data key="d6">Numba accelerates Python functions via JIT compilation, mainly for CPU, with limited GPU support."|&gt;"performance optimization, Python</data>
  <data key="d7">6</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Numba" target="&lt;kernel&gt;">
  <data key="d5">18.0</data>
  <data key="d6">Numba can compile Python functions, including those defining computational kernels, into optimized machine code for faster execution."|&gt;"performance optimization, compilation&lt;SEP&gt;Numba can compile Python functions, including those defining kernels, into optimized machine code for faster execution.</data>
  <data key="d7">9&lt;SEP&gt;performance optimization, compilation</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Julia" target="CUDA.jl">
  <data key="d5">16.0</data>
  <data key="d6">CUDA.jl</data>
  <data key="d7">CUDA.jl enables Julia to interface with NVIDIA CUDA for GPU programming, supporting kernel development and GPU acceleration in Julia."|&gt;"GPU acceleration, language support&lt;SEP&gt;CUDA.jl enables Julia to interface with NVIDIA CUDA for GPU programming, supporting kernel development in Julia."|&gt;"GPU acceleration, language support</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Julia" target="AMDGPU.jl">
  <data key="d5">14.0</data>
  <data key="d6">AMDGPU.jl</data>
  <data key="d7">AMDGPU.jl allows Julia to target AMD GPUs, broadening its applicability for heterogeneous GPU computing."|&gt;"hardware support, GPU programming&lt;SEP&gt;AMDGPU.jl allows Julia to target AMD GPUs, broadening its applicability for heterogeneous computing."|&gt;"hardware support, GPU programming</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Julia" target="KernelAbstractions.jl">
  <data key="d5">16.0</data>
  <data key="d6">KernelAbstractions.jl</data>
  <data key="d7">KernelAbstractions.jl provides a hardware-agnostic interface for writing portable GPU kernels in Julia."|&gt;"abstraction, portability&lt;SEP&gt;KernelAbstractions.jl provides a portable interface for writing GPU kernels in Julia, supporting multiple hardware vendors."|&gt;"abstraction, portability</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Julia" target="Tobias Knopp">
  <data key="d5">28.0</data>
  <data key="d6">Knopp researched multi-threading support for Julia in high-performance computing contexts.&lt;SEP&gt;Knopp researched multi-threading support for Julia in high-performance computing environments."|"&lt;software support, multi-threading</data>
  <data key="d7">14&lt;SEP&gt;software support, multi-threading</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenAI Codex via Copilot" target="HPC Numerical Kernels">
  <data key="d5">8.0</data>
  <data key="d6">The study evaluates the capacity of OpenAI Codex via Copilot to generate HPC numerical kernels across different languages."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Taxonomy" target="Metrics for Evaluation">
  <data key="d5">9.0</data>
  <data key="d6">A proposed taxonomy aims to evaluate the accuracy and trustworthiness of AI-generated HPC codes, emphasizing the importance of measurement standards."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="LLM Technologies" target="Human-in-the-Loop and Compiler">
  <data key="d5">7.0</data>
  <data key="d6">Questions about integrating human oversight and compiler refinement with LLM suggestions to improve HPC development."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Human-in-the-Loop and Compiler" target="Metadata-Rich Suggestions">
  <data key="d5">8.0</data>
  <data key="d6">Incorporating metadata-rich suggestions can facilitate human decision-making and refine AI-generated code in HPC contexts."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Metadata-Rich Suggestions" target="Human-in-the-Loop">
  <data key="d5">8.0</data>
  <data key="d6">Metadata-rich suggestions can facilitate human decision-making and improve AI-generated code outcomes."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="HPC Software Modernization Initiatives" target="Ecosystem Features Automation">
  <data key="d5">8.0</data>
  <data key="d6">Major HPC modernization initiatives consider integrating AI tools to automate building, validation, and deployment processes."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Ecosystem Features Automation" target="HPC Modernization Initiatives">
  <data key="d5">8.0</data>
  <data key="d6">Major modernization efforts aim to incorporate AI tools to automate and improve HPC development pipelines."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Generative AI" target="HPC Development">
  <data key="d5">8.0</data>
  <data key="d6">Generative AI, including LLMs, has the potential to significantly impact HPC software development, maintenance, and education."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Generative AI" target="Human-in-the-Loop">
  <data key="d5">8.0</data>
  <data key="d6">Incorporating human oversight can refine AI suggestions, improving code quality and trustworthiness."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Generative AI" target="Zhang et al. 2023">
  <data key="d5">18.0</data>
  <data key="d6">They provided a comprehensive survey on generative AI models, including GPT series."|</data>
  <data key="d7">overview</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Information Processing Systems" target="H. Larochelle">
  <data key="d5">16.0</data>
  <data key="d6">H. Larochelle is the editor of the collection on information processing systems, indicating an editorial relationship.</data>
  <data key="d7">editorial, scholarly compilation</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Information Processing Systems" target="Vol. 33">
  <data key="d5">10.0</data>
  <data key="d6">Designates the specific volume of the proceedings collection, indicating the edition.</data>
  <data key="d7">publication detail</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Information Processing Systems" target="Curran Associates, Inc.">
  <data key="d5">8.0</data>
  <data key="d6">Publisher of the proceedings and research compilation.</data>
  <data key="d7">publishing</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Information Processing Systems" target="https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf">
  <data key="d5">8.0</data>
  <data key="d6">Digital resource link to the research paper.</data>
  <data key="d7">accessibility</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="H. Larochelle" target="M. Ranzato">
  <data key="d5">14.0</data>
  <data key="d6">Both are editors of the same volume, collaborating on the compilation of research papers on information processing.</data>
  <data key="d7">editor, collaboration</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="H. Larochelle" target="R. Hadsell">
  <data key="d5">14.0</data>
  <data key="d6">Both are editors involved in the scholarly volume on information processing systems.</data>
  <data key="d7">editorial team</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="H. Larochelle" target="M.F. Balcan">
  <data key="d5">12.0</data>
  <data key="d6">Co-editor contributing to the compilation of research on information processing.</data>
  <data key="d7">editorial role</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="H. Larochelle" target="H. Lin">
  <data key="d5">12.0</data>
  <data key="d6">Co-editor of the proceedings volume, collaborating on scholarly editing.</data>
  <data key="d7">editorial collaboration</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Christian R. Trott" target="Kokkos 3">
  <data key="d5">14.0</data>
  <data key="d6">Christian R. Trott contributed to research on programming model extensions like Kokkos 3 for exascale systems."|</data>
  <data key="d7">research development, exascale computing</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al." target="Researcher Group">
  <data key="d5">16.0</data>
  <data key="d6">Authors of a study evaluating large language models trained on code.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Valentin Churavy, Dilum Aluthge, Lucas C Wilcox, James Schloss, Simon Byrne, Maciej Waruszewski, Julian Samaroo, Ali Ramadhan, Meredith, Simeon Schaub, Jake Bolewski, Anton Smirnov, Charles Kawczynski, Chris Hill, Jinguo Liu, Oliver Schulz, Oscar, Páll Haraldsson, Takafumi Arakaki, and Tim Besard" target="Researcher Group">
  <data key="d5">16.0</data>
  <data key="d6">Authors of a systematic review on code generation using machine learning.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Paul Denny, Viraj Kumar, Nasser Giacaman" target="Researcher Group">
  <data key="d5">16.0</data>
  <data key="d6">Authors exploring prompt engineering for natural language solving CS problems.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Jack Dongarra, Robert Graybill, William Harrod, Robert Lucas, Ewing Lusk, Piotr Luszczek, Janice Mcmahon, Allan Snavely, Jeffrey Vetter, Katherine Yelick, Sadaf Alam, Roy Campbell, Laura Carrington, Tzu-Yi Chen, Omid Khalili, Jeremy Meredith, Mustafa Tikir" target="Researcher Group">
  <data key="d5">16.0</data>
  <data key="d6">Authors of a report on DARPA’s HPCS Program, detailing models, tools, and languages for high-performance computing.&lt;SEP&gt;Authors of the DARPA HPCS program overview.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Jack Dongarra et al." target="Researcher Group">
  <data key="d5">16.0</data>
  <data key="d6">Authors of the exascale software project roadmap.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Li Fei-Fei, R. Fergus, and P. Perona" target="Researcher Group">
  <data key="d5">16.0</data>
  <data key="d6">Authors of a study on one-shot learning in object recognition.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Michael Fink" target="Researcher">
  <data key="d5">16.0</data>
  <data key="d6">Author of work on object classification from a single example.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="James Finnie-Ansley, Paul Denny, Brett A. Becker, Andrew Luxton-Reilly, and James Prather" target="Researcher Group">
  <data key="d5">16.0</data>
  <data key="d6">Authors exploring the impact of OpenAI Codex on programming education.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Luciano Floridi and Massimo Chiriatti" target="Researcher Group">
  <data key="d5">16.0</data>
  <data key="d6">Authors analyzing GPT-3's nature, limits, and societal impact.</data>
  <data key="d7">research contribution</data>
  <data key="d8">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="ACE ’22" target="Luciano Floridi">
  <data key="d5">12.0</data>
  <data key="d6">Floridi's work on AI ethics and implications was presented or associated with the ACE ’22 conference.&lt;SEP&gt;Floridi's work on AI ethics, societal impacts, and the scope of AI was presented or discussed at ACE ’22.</data>
  <data key="d7">conference presentation, AI ethics</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Zheming Jin" target="Rodinia Benchmarks">
  <data key="d5">18.0</data>
  <data key="d6">Jin developed the Rodinia benchmarks implemented in SYCL for performance benchmarking of heterogeneous systems."|"&lt;performance benchmarking, heterogeneous systems&lt;SEP&gt;Jin developed the Rodinia benchmarks implemented in SYCL for performance testing.</data>
  <data key="d7">9&lt;SEP&gt;benchmark development, performance testing</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Zhemin Jin" target="Hecbench">
  <data key="d5">20.0</data>
  <data key="d6">Jin created Hecbench, a benchmark suite for high-performance computing performance evaluation."|"&lt;benchmark suite, high-performance computing&lt;SEP&gt;Jin created Hecbench, a benchmark suite for high-performance computing.</data>
  <data key="d7">10&lt;SEP&gt;benchmark creation, high-performance computing</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Srinath Kailasa" target="PyExaFMM">
  <data key="d5">22.0</data>
  <data key="d6">Kailasa and colleagues designed PyExaFMM for high-performance software exercises using Python and Numba.&lt;SEP&gt;Kailasa and colleagues designed PyExaFMM, a high-performance software exercise framework using Python and Numba."|"&lt;software framework, high-performance computing</data>
  <data key="d7">11&lt;SEP&gt;software design, high-performance computing</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Andreas Klöckner" target="pycuda">
  <data key="d5">24.0</data>
  <data key="d6">Klöckner developed and documented pycuda for GPU runtime code generation.&lt;SEP&gt;Klöckner developed and documented pycuda, a Python library for GPU runtime code generation and execution."|"&lt;software library, GPU programming</data>
  <data key="d7">12&lt;SEP&gt;software library, GPU programming</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Nvidia" target="CUDA Toolkit">
  <data key="d5">26.0</data>
  <data key="d6">Nvidia provides the CUDA Toolkit for GPU programming and high-performance computing.&lt;SEP&gt;Nvidia provides the CUDA Toolkit, a suite of GPU programming tools for high-performance applications."|"&lt;software suite, GPU computing</data>
  <data key="d7">13&lt;SEP&gt;software suite, GPU computing</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Douglas Kothe" target="Exascale Computing in the United States">
  <data key="d5">30.0</data>
  <data key="d6">Kothe's work involves research on exascale computing infrastructure and deployment in the US."|"&lt;computing infrastructure, exascale&lt;SEP&gt;Kothe's work involves research on exascale computing infrastructure in the US.</data>
  <data key="d7">15&lt;SEP&gt;computing infrastructure, exascale</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Siu Kwan Lam" target="programming languages">
  <data key="d5">32.0</data>
  <data key="d6">Lam analyzed the popularity and usage trends of programming languages in open source communities."|"&lt;software community, language popularity&lt;SEP&gt;Lam analyzed the popularity of programming languages in open source communities.</data>
  <data key="d7">16&lt;SEP&gt;software community, language popularity</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Hammond Pearce" target="Authors">
  <data key="d5">8.0</data>
  <data key="d6">Hammond Pearce and colleagues assessed the security of GitHub Copilot in 2022, highlighting security concerns related to AI code contributions.</data>
  <data key="d7">Results</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Baleegh Ahmad" target="Authors">
  <data key="d5">7.0</data>
  <data key="d6">Baleegh Ahmad collaborated on the security assessment of GitHub Copilot in 2022.</data>
  <data key="d7">Results</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Benjamin Tan" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Benjamin Tan contributed to the GitHub Copilot security study in 2022.</data>
  <data key="d7">Results</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Brendan Dolan-Gavitt" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Brendan Dolan-Gavitt contributed to the security evaluation of GitHub Copilot in 2022.</data>
  <data key="d7">Results</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Ramesh Karri" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Ramesh Karri was involved in the security assessment of GitHub Copilot in 2022.</data>
  <data key="d7">Results</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Preferred Networks" target="Organizations">
  <data key="d5">8.0</data>
  <data key="d6">Preferred Networks is involved in GPU and AI research, including projects related to CuPy and infrastructure.</data>
  <data key="d7">Applications/Implications</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Preferred Infrastructure" target="Organizations">
  <data key="d5">7.0</data>
  <data key="d6">Preferred Infrastructure is related to infrastructure projects by Preferred Networks, possibly involving GPU deployment or AI systems.</data>
  <data key="d7">Applications/Implications</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Sami Sarsa" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Sami Sarsa and colleagues researched automated programming exercises and explanations using large language models in 2022.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Paul Denny" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Paul Denny contributed to the research on AI-generated programming exercises in 2022.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Arto Hellas" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Arto Hellas contributed to the study on AI-generated code explanations in 2022.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Juho Leinonen" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Juho Leinonen contributed to the research on automated code explanations and exercises in 2022.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Dominik Sobania" target="Authors">
  <data key="d5">7.0</data>
  <data key="d6">Dominik Sobania and colleagues conducted a performance comparison of GitHub Copilot and genetic programming in 2022.</data>
  <data key="d7">Results</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Martin Briesch" target="Authors">
  <data key="d5">7.0</data>
  <data key="d6">Martin Briesch contributed to the performance evaluation of program synthesis techniques in 2022.</data>
  <data key="d7">Results</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Franz Rothlauf" target="Authors">
  <data key="d5">7.0</data>
  <data key="d6">Franz Rothlauf contributed to the comparison of program synthesis methods in 2022.</data>
  <data key="d7">Results</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Bjarne Stroustrup" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Bjarne Stroustrup authored "The C++ Programming Language" in 2013, foundational for C++ programming language understanding.</data>
  <data key="d7">Objects of Study</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Priyan Vaithilingam" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Priyan Vaithilingam and colleagues studied usability of code generation tools powered by large language models in 2022.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Elena L. Glassman" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Elena L. Glassman contributed to the 2022 usability evaluation of code generation tools.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Stefan Van Der Walt" target="Authors">
  <data key="d5">5.0</data>
  <data key="d6">Stefan Van Der Walt, S Chris Colbert, and Gael Varoquaux explained the NumPy array architecture in 2011 as an efficient numerical structure.</data>
  <data key="d7">Objects of Study</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="S Chris Colbert" target="Authors">
  <data key="d5">4.0</data>
  <data key="d6">S Chris Colbert contributed to the explanation of NumPy arrays in 2011.</data>
  <data key="d7">Objects of Study</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Gael Varoquaux" target="Authors">
  <data key="d5">4.0</data>
  <data key="d6">Gael Varoquaux contributed to the explanation of NumPy arrays in 2011.</data>
  <data key="d7">Objects of Study</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Yaqing Wang" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Yaqing Wang and colleagues conducted research in 2022, likely related to AI or scientific computing, based on the context of the document.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Yaqing Wang" target="Generalizing from a Few Examples">
  <data key="d5">10.0</data>
  <data key="d6">Yaqing Wang authored the survey on few-shot learning focusing on generalization from limited data.</data>
  <data key="d7">authorship, research focus</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Quanming Yao" target="Authors">
  <data key="d5">6.0</data>
  <data key="d6">Quanming Yao contributed to the 2022 research involving AI or scientific methods.</data>
  <data key="d7">Research Questions/Hypotheses</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Quanming Yao" target="Generalizing from a Few Examples">
  <data key="d5">9.0</data>
  <data key="d6">Quanming Yao co-authored the survey on few-shot learning.</data>
  <data key="d7">authorship, research focus</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="T. Peterka" target="Extreme Heterogeneity 2018">
  <data key="d5">10.0</data>
  <data key="d6">T. Peterka authored the report on extreme heterogeneity in computational science.</data>
  <data key="d7">authorship, research contribution</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="M. Strout" target="Extreme Heterogeneity 2018">
  <data key="d5">9.0</data>
  <data key="d6">M. Strout contributed to the report on productive computational science.</data>
  <data key="d7">authorship, research contribution</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="J. Wilke" target="Extreme Heterogeneity 2018">
  <data key="d5">8.0</data>
  <data key="d6">J. Wilke contributed to the report on extreme heterogeneity in computational science.</data>
  <data key="d7">authorship, research contribution</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Extreme Heterogeneity 2018" target="USDOE Office of Science (SC)">
  <data key="d5">7.0</data>
  <data key="d6">The report was produced under the auspices of the USDOE Office of Science.</data>
  <data key="d7">organizational support, funding</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="James T. Kwok" target="Generalizing from a Few Examples">
  <data key="d5">8.0</data>
  <data key="d6">James T. Kwok contributed to the survey on few-shot learning.</data>
  <data key="d7">authorship, research focus</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Lionel M. Ni" target="Generalizing from a Few Examples">
  <data key="d5">7.0</data>
  <data key="d6">Lionel M. Ni is involved in the survey on few-shot learning.</data>
  <data key="d7">authorship, research focus</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Michel Wermelinger" target="Using GitHub Copilot to Solve Simple Programming Problems">
  <data key="d5">18.0</data>
  <data key="d6">Michel Wermelinger authored a study on AI-assisted programming using GitHub Copilot.&lt;SEP&gt;Michel Wermelinger's study was presented at the ACM symposium on computer science education.</data>
  <data key="d7">authorship, research focus&lt;SEP&gt;presentation, dissemination</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Burak Yetistiren" target="Assessing the Quality of GitHub Copilot’s Code Generation">
  <data key="d5">16.0</data>
  <data key="d6">Burak Yetistiren authored a study evaluating GitHub Copilot's code quality.&lt;SEP&gt;Burak Yetistiren's study was presented at PROMISE 2022.</data>
  <data key="d7">authorship, research focus&lt;SEP&gt;presentation, dissemination</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Accelerator Offloading" target="Memory Locality">
  <data key="d5">21.0</data>
  <data key="d6">Memory locality strategies optimize data placement and movement during offloading to improve performance and reduce latency.&lt;SEP&gt;Memory locality strategies optimize data placement and movement when offloading tasks to accelerators like GPUs.&lt;SEP&gt;Memory locality techniques improve data transfer efficiency and cache utilization during offloading to GPUs.</data>
  <data key="d7">memory optimization, offloading&lt;SEP&gt;performance, data locality</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Code Generator" target="Abstract Pattern Tree (APT)">
  <data key="d5">18.0</data>
  <data key="d6">The code generator employs the APT for implementing inlining and loop unrolling optimizations."|&gt;"optimization technique&lt;SEP&gt;The code generator employs the APT for inlining and loop unrolling optimizations."|&gt;"optimization technique</data>
  <data key="d7">9</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Code Generator" target="Performance optimization">
  <data key="d5">8.0</data>
  <data key="d6">The code generator influences performance by supporting features like data movement and synchronization, enabling optimized code for heterogeneous systems.</data>
  <data key="d7">optimization, code quality</data>
  <data key="d8">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Code Generator" target="Hierarchical Structure">
  <data key="d5">16.0</data>
  <data key="d6">The code generator uses information about the hierarchical structure to produce flattened, optimized parallel code.</data>
  <data key="d7">code optimization, code production</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Patterns" target="PPL">
  <data key="d5">18.0</data>
  <data key="d6">PPL uses parallel patterns to represent algorithms, enabling analysis and optimization of parallel computations.</data>
  <data key="d7">algorithm representation</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Patterns" target="Operations">
  <data key="d5">18.0</data>
  <data key="d6">Parallel patterns define element-wise operations like multiply and subtract, which are fundamental to the pattern-based approach.</data>
  <data key="d7">operation definition</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Patterns" target="TheAPT">
  <data key="d5">8.0</data>
  <data key="d6">Parallel patterns within the APT define fixed computations and control flow, enabling static dependency analysis and optimization.</data>
  <data key="d7">parallelism, data dependencies</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Patterns" target="Code Reusability">
  <data key="d5">14.0</data>
  <data key="d6">Abstracting parallelism into patterns reduces boilerplate and enhances code reuse and maintainability."|&lt;SEP&gt;Abstracting parallelism into patterns removes boilerplate code, enhancing reusability and maintainability.</data>
  <data key="d7">software engineering, productivity</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Rodinia Benchmark Suite" target="PPL">
  <data key="d5">16.0</data>
  <data key="d6">The PPL is evaluated against the kernels in the Rodinia suite to demonstrate its applicability and performance."|&gt;"performance evaluation&lt;SEP&gt;The PPL's evaluation against the Rodinia suite demonstrates its applicability across various kernels."|&gt;"performance evaluation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Future Work" target="PPL">
  <data key="d5">12.0</data>
  <data key="d6">The analysis of current issues aims to improve the PPL prototype for future releases."|&gt;"development goal&lt;SEP&gt;The current issues identified in the prototype are targeted for resolution to enable a productized release."|&gt;"development goal</data>
  <data key="d7">6</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="YASK" target="Charles Yount">
  <data key="d5">16.0</data>
  <data key="d6">Charles Yount is associated with the YASK framework for HPC stencil code generation."|&lt;SEP&gt;Charles Yount is associated with the development and research of the YASK framework for stencil code generation."|</data>
  <data key="d7">software framework, HPC</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="YASK" target="Josh Tobin">
  <data key="d5">16.0</data>
  <data key="d6">Josh Tobin contributed to the development and tuning of YASK for high-performance stencil computations."|&lt;SEP&gt;Josh Tobin contributed to the development, tuning, and optimization of YASK for high-performance stencil computations."|</data>
  <data key="d7">code optimization, HPC&lt;SEP&gt;software development, performance tuning</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="YASK" target="Alexander Breuer">
  <data key="d5">14.0</data>
  <data key="d6">Alexander Breuer is involved in research related to YASK's stencil code generation and optimization."|&lt;SEP&gt;Alexander Breuer is involved in research related to YASK's stencil code generation capabilities."|</data>
  <data key="d7">research, HPC frameworks</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="YASK" target="Alejandro Duran">
  <data key="d5">14.0</data>
  <data key="d6">Alejandro Duran works on performance tuning and code generation within the YASK framework."|</data>
  <data key="d7">performance optimization, HPC&lt;SEP&gt;performance tuning, HPC</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Distributed Memory" target="MPI Communication">
  <data key="d5">18.0</data>
  <data key="d6">MPI communication facilitates explicit data transfer and collective operations necessary for synchronization and data sharing across nodes.&lt;SEP&gt;MPI functions enable explicit data transfer and collective operations necessary for synchronization and data sharing across nodes.</data>
  <data key="d7">data transfer, synchronization</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Distributed Memory" target="Data Movement">
  <data key="d5">9.0</data>
  <data key="d6">Explicit data transfers via MPI are critical for maintaining data consistency and synchronization across distributed nodes.</data>
  <data key="d7">data transfer, synchronization</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Distributed Memory" target="Synchronization">
  <data key="d5">8.0</data>
  <data key="d6">Synchronization is achieved through MPI blocking calls and barrier synchronization to coordinate data exchange and process execution.</data>
  <data key="d7">coordination, data consistency</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="SDFG" target="DaCe">
  <data key="d5">16.0</data>
  <data key="d6">DaCe employs SDFGs to represent and optimize computations, focusing on hotspots for performance improvements.</data>
  <data key="d7">optimization representation</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Rule-based Optimization Strategy" target="Hotspots">
  <data key="d5">14.0</data>
  <data key="d6">Rules are applied to hotspots to optimize performance, often requiring expert definition of rules.</data>
  <data key="d7">optimization process</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Application Wide Optimizations" target="Global Optimizations">
  <data key="d5">12.0</data>
  <data key="d6">Application wide optimizations aim to improve overall application performance, as contrasted with local optimization approaches.</data>
  <data key="d7">optimization scope</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Legion Framework" target="Automatic Global Optimizations">
  <data key="d5">16.0</data>
  <data key="d6">Legion supports enabling automatic global optimizations for system configurations similar to PPL.</data>
  <data key="d7">optimization support</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parsing" target="DSL">
  <data key="d5">16.0</data>
  <data key="d6">Parsing evaluates the user input written in the DSL to understand application structure and patterns.</data>
  <data key="d7">input processing</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Optimization" target="APT Generation">
  <data key="d5">14.0</data>
  <data key="d6">APT is generated from the hierarchical representation of the algorithm, reflecting optimization results.</data>
  <data key="d7">representation</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Optimization" target="Global View">
  <data key="d5">16.0</data>
  <data key="d6">A global view on applications enables comprehensive optimization strategies, central to the pattern-based methodology.</data>
  <data key="d7">system perspective</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Optimization" target="Algorithm Representation">
  <data key="d5">8.0</data>
  <data key="d6">Algorithms represented as hierarchical APTs are optimized through global transformations.</data>
  <data key="d7">representation to optimization</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Optimization" target="Semi-automatic Optimization">
  <data key="d5">7.0</data>
  <data key="d6">Semi-automatic approaches combine automation with expert input to refine performance enhancements.</data>
  <data key="d7">hybrid process</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Optimization" target="Semantic Preservation">
  <data key="d5">9.0</data>
  <data key="d6">Optimization strategies like inlining, unrolling, and code flattening must preserve program semantics to ensure correctness.</data>
  <data key="d7">correctness, program behavior</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Optimization" target="Jacobi Kernel">
  <data key="d5">14.0</data>
  <data key="d6">Implementing kernel fusion could improve the performance of the jacobi kernel.&lt;SEP&gt;Implementing kernel fusion could improve the performance of the jacobi kernel."|</data>
  <data key="d7">kernel optimization, fusion</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Performance Results" target="Optimization Goals">
  <data key="d5">8.0</data>
  <data key="d6">Optimization goals aim to improve performance metrics, which are measured and reported as results.</data>
  <data key="d7">performance improvement</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Hardware Targets" target="Expert-defined Mappings">
  <data key="d5">7.0</data>
  <data key="d6">Expert mappings specify how algorithms are mapped onto hardware, influencing optimization.</data>
  <data key="d7">mapping strategies</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Pattern Application" target="Algorithm Representation">
  <data key="d5">8.0</data>
  <data key="d6">Applying patterns involves defining algorithm structures in the DSL, which are then used for optimization and code generation.</data>
  <data key="d7">application process</data>
  <data key="d8">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="TheHWL" target="APTT Generation">
  <data key="d5">8.0</data>
  <data key="d6">The HWL defines execution units that are used in the generation of the APT, establishing the hardware context for parallel code analysis and optimization.</data>
  <data key="d7">hardware configuration, parallel code</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="APTT Generation" target="The APT is created by analyzing the hierarchical structure of parallel code, including expressions and statements, to facilitate dependency analysis and optimization.">
  <data key="d5">9.0</data>
  <data key="d6">code analysis, hierarchical representation</data>
  <data key="d7">9</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Data Dependencies" target="APTT">
  <data key="d5">7.0</data>
  <data key="d6">Data dependencies link expressions within the APT, ensuring correct execution order and enabling static analysis for optimization.</data>
  <data key="d7">dependency analysis, code correctness</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Global Optimization" target="APTT">
  <data key="d5">8.0</data>
  <data key="d6">Global optimization techniques are applied to the APT to improve parallelism, reduce dependencies, and optimize resource usage during compilation.</data>
  <data key="d7">performance enhancement, code optimization</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Global Optimization" target="Synchronization Efficiency">
  <data key="d5">7.0</data>
  <data key="d6">Synchronization efficiency measures how well dependency-based synchronization is minimized during global optimization, enhancing parallel execution.</data>
  <data key="d7">dependency management, parallelism</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Global Optimization" target="Inter-processor Dataflow Efficiency">
  <data key="d5">8.0</data>
  <data key="d6">This efficiency assesses the minimization of network and execution costs by optimizing data transfer and task mapping across devices.</data>
  <data key="d7">network optimization, task mapping</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Global Optimization" target="Intra-processor Dataflow Efficiency">
  <data key="d5">7.0</data>
  <data key="d6">This efficiency maximizes data reuse within the same processing unit, reducing cache misses and improving performance.</data>
  <data key="d7">data reuse, cache optimization</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Global Optimization" target="Pattern Implementation">
  <data key="d5">37.0</data>
  <data key="d6">Global optimization considers the entire execution flow, including kernel execution and memory management, to maximize performance.&lt;SEP&gt;Global optimization considers the entire execution flow—including kernel execution and memory management—to maximize system-wide performance.&lt;SEP&gt;Global optimization considers the entire execution plan, including offloading, memory management, and synchronization, to maximize overall system performance.&lt;SEP&gt;Global optimization techniques guide the mapping of patterns onto hardware, ensuring correct and efficient parallel execution.</data>
  <data key="d7">optimization strategy, correctness&lt;SEP&gt;performance optimization, system-wide&lt;SEP&gt;performance, system optimization</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tasklets" target="Mapping">
  <data key="d5">8.0</data>
  <data key="d6">Tasklets are assigned to specific hardware units in the AMT, optimizing resource utilization and performance.</data>
  <data key="d7">resource allocation, task scheduling</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Data Transfer and Synchronization" target="AMT">
  <data key="d5">8.0</data>
  <data key="d6">Data transfer and synchronization nodes are derived from data flow and mapping information, modeling communication between hardware units.</data>
  <data key="d7">communication modeling, data movement</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Function Calls" target="Tracing">
  <data key="d5">9.0</data>
  <data key="d6">Tracing with tools like sys.setprofile captures inputs and outputs during function execution, enabling data collection for creating problems and testing solutions."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Function Calls" target="Sandboxed Environment">
  <data key="d5">8.0</data>
  <data key="d6">Code is run in sandboxed environments to safely execute untrusted code during testing."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Synchronization" target="Data flow">
  <data key="d5">9.0</data>
  <data key="d6">Synchronization is used to coordinate data movement and access order in data flow processes, ensuring correct execution.</data>
  <data key="d7">coordination, data consistency</data>
  <data key="d8">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Synchronization" target="Remote read accesses">
  <data key="d5">8.0</data>
  <data key="d6">Remote read accesses require synchronization and data transfer to ensure data consistency across devices.</data>
  <data key="d7">data transfer, consistency</data>
  <data key="d8">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Synchronization" target="CUDA Calls">
  <data key="d5">16.0</data>
  <data key="d6">CUDA calls are wrapped and managed to ensure proper synchronization during data movement and kernel execution.</data>
  <data key="d7">execution order, data consistency</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Synchronization" target="Data Movement">
  <data key="d5">8.0</data>
  <data key="d6">Synchronization ensures correct ordering of data transfers and kernel launches, preventing race conditions and ensuring data consistency.</data>
  <data key="d7">data integrity, execution order</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Dependency Analysis" target="Compatibility Layer">
  <data key="d5">10.0</data>
  <data key="d6">A compatibility layer between SDFGs and the APT could enhance dependency analysis capabilities for the PPL."|&lt;SEP&gt;A compatibility layer between SDFGs and the APT could enhance dependency analysis capabilities within the PPL framework.</data>
  <data key="d7">integration, dependency analysis</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Remote write accesses" target="Data flow">
  <data key="d5">7.0</data>
  <data key="d6">Remote write accesses do not require synchronization, as they do not pose a data race risk, but require invalidating stale data copies.</data>
  <data key="d7">data integrity, access control</data>
  <data key="d8">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Thread Pool" target="Pattern Implementation">
  <data key="d5">14.0</data>
  <data key="d6">The thread pool manages threads that execute specific patterns, enabling structured parallel execution on GPUs.</data>
  <data key="d7">task management, parallel execution</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Shared Memory Parallelism" target="POSIX Threads">
  <data key="d5">16.0</data>
  <data key="d6">POSIX threads implement shared memory parallelism by enabling multiple threads to run concurrently within shared memory, facilitating parallel execution.&lt;SEP&gt;POSIX threads support shared memory parallelism by enabling concurrent thread execution within shared memory space.</data>
  <data key="d7">parallel programming, threading</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="POSIX Threads" target="Thread Pinning">
  <data key="d5">17.0</data>
  <data key="d6">Thread pinning is achieved using pthread_setaffinity_np to bind threads to specific cores, optimizing performance.&lt;SEP&gt;Thread pinning is performed via pthread_setaffinity_np to bind threads to specific cores, optimizing cache usage and reducing context switches.</data>
  <data key="d7">performance tuning, thread management</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Hyper-threading" target="Disregarded">
  <data key="d5">6.0</data>
  <data key="d6">Hyper-threading is currently disregarded in the model, meaning it does not influence thread management or performance optimization here.&lt;SEP&gt;Hyper-threading technology is currently disregarded in the execution model, meaning it does not influence thread management or performance in this context.</data>
  <data key="d7">hardware feature, performance&lt;SEP&gt;hardware feature, performance optimization</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Pattern Implementation" target="Parallel Techniques">
  <data key="d5">15.0</data>
  <data key="d6">Decomposition into map, stencil, and reduction patterns allows structured parallel execution with proper synchronization and atomic operations in reduction.&lt;SEP&gt;Decomposition of patterns into map, stencil, and reduction enables structured parallel execution with synchronization mechanisms.</data>
  <data key="d7">parallel algorithms, pattern decomposition</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Memory Locality" target="Pattern implementation and data movement strategies aim to optimize memory locality to enhance performance.">
  <data key="d5">12.0</data>
  <data key="d6">memory optimization, performance</data>
  <data key="d7">6</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Shared Memory Threads" target="Atomic Operations">
  <data key="d5">14.0</data>
  <data key="d6">Atomic operations are used within shared memory threads to safely update shared variables during parallel reductions.</data>
  <data key="d7">race condition prevention, synchronization</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Inlining" target="Hierarchical Structure">
  <data key="d5">26.0</data>
  <data key="d6">Inlining is used to flatten hierarchical code structures, enabling further optimization like loop unrolling and parallel pattern recognition.&lt;SEP&gt;Inlining reduces hierarchical nesting by replacing function calls with their bodies, facilitating flattening and optimization.</data>
  <data key="d7">code flattening, optimization&lt;SEP&gt;hierarchy reduction, code simplification</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Inlining" target="Loop Unrolling">
  <data key="d5">24.0</data>
  <data key="d6">Loop unrolling is applied after inlining to expand loops for better performance and parallelism.&lt;SEP&gt;Loop unrolling is performed after inlining to further optimize code by expanding loops for better parallel execution.</data>
  <data key="d7">performance optimization, parallelism&lt;SEP&gt;performance, parallelism</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Inlining" target="Function Call">
  <data key="d5">8.0</data>
  <data key="d6">Function calls are replaced by their bodies through inlining, which is essential for code flattening and optimization.</data>
  <data key="d7">code transformation, performance</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Inlining" target="Scope">
  <data key="d5">7.0</data>
  <data key="d6">Scope extension during inlining prevents variable conflicts by extending variable names with hashes.</data>
  <data key="d7">variable management, correctness</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Inlining" target="Replacers">
  <data key="d5">8.0</data>
  <data key="d6">Replacers store nodes that replace function calls, facilitating code flattening and enabling parallel pattern detection.</data>
  <data key="d7">code restructuring, parallelization</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Hierarchical Structure" target="Flattening">
  <data key="d5">8.0</data>
  <data key="d6">Flattening transforms nested hierarchical code into a linear form, enabling effective parallel optimization.</data>
  <data key="d7">parallelization, code transformation</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Return Statement" target="Jump Label">
  <data key="d5">8.0</data>
  <data key="d6">Return statements are handled by creating jump labels to manage control flow after inlining functions.</data>
  <data key="d7">control flow, code correctness</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Work-sharing" target="Pattern Assignment">
  <data key="d5">7.0</data>
  <data key="d6">Pattern assignment determines how iterations are distributed among threads, balancing workload and optimizing parallel execution.</data>
  <data key="d7">load balancing, workload distribution</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Arguments" target="Local Array">
  <data key="d5">7.0</data>
  <data key="d6">Arguments are copied into local arrays during inlining to prevent dependencies and enable nested parallel patterns.</data>
  <data key="d7">data independence, concurrency</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="CLAIX18 systems" target="RWTH Aachen University">
  <data key="d5">8.0</data>
  <data key="d6">The systems are located at RWTH Aachen University, where the experiments are conducted.</data>
  <data key="d7">location, research environment</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Global optimizations" target="Measurement accuracy">
  <data key="d5">7.0</data>
  <data key="d6">Global optimizations are performed to avoid synchronization points that could influence measurement results, ensuring accuracy.</data>
  <data key="d7">methodology, measurement integrity</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Gurobi" target="Random seeds">
  <data key="d5">8.0</data>
  <data key="d6">Different random seeds are used in Gurobi to mitigate solution instability caused by its stochastic initial solution process.</data>
  <data key="d7">algorithm variability, solution stability</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="PPLin" target="Rodinia">
  <data key="d5">8.0</data>
  <data key="d6">PPLin is applied to optimize and adapt the Rodinia benchmark applications for improved performance.</data>
  <data key="d7">application, optimization</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Rodinia" target="PPLport">
  <data key="d5">7.0</data>
  <data key="d6">The PPLport is adapted to fit dataset sizes within the Rodinia benchmarks, enabling optimized execution.</data>
  <data key="d7">adaptation, dataset sizing</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Rodinia" target="benchmark suite">
  <data key="d5">7.0</data>
  <data key="d6">The benchmarks are part of the Rodinia suite, used to evaluate the effectiveness of PPL optimizations.</data>
  <data key="d7">benchmarking, evaluation</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="port for the PPLin" target="previous work">
  <data key="d5">8.0</data>
  <data key="d6">The port for PPLin builds upon previous work, adapting and extending earlier implementations.</data>
  <data key="d7">development, extension</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="original code" target="speedup">
  <data key="d5">9.0</data>
  <data key="d6">The original code serves as the baseline for measuring the speedup achieved by the optimized code.</data>
  <data key="d7">benchmarking, performance comparison</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="kernels" target="optimized kernels">
  <data key="d5">10.0</data>
  <data key="d6">Kernels like kmeans and nnbenchmarks are optimized to better utilize parallel hardware, achieving significant speedups.</data>
  <data key="d7">performance, kernel optimization</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="support" target="unsupported codes">
  <data key="d5">7.0</data>
  <data key="d6">Certain benchmark codes are unsupported in PPL due to porting or kernel alteration issues.</data>
  <data key="d7">limitations, support</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="static reduction" target="hotspot benchmark">
  <data key="d5">8.0</data>
  <data key="d6">The static reduction approach eliminated branches in hotspot, leading to a speedup of 2.72.</data>
  <data key="d7">performance, code restructuring</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="compiler optimizations" target="lavaMD">
  <data key="d5">9.0</data>
  <data key="d6">Speedup in lavaMD was partly due to optimizations from the Intel OneAPI compiler.</data>
  <data key="d7">performance, compiler</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Porting Applications" target="Annotations">
  <data key="d5">12.0</data>
  <data key="d6">Annotations like OpenMP facilitate porting existing applications to the PPL framework by identifying parallel patterns."|&lt;SEP&gt;Using annotations like OpenMP can facilitate porting existing applications to the PPL framework.</data>
  <data key="d7">porting, annotations, parallel patterns</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Data Dependency Analysis" target="Dynamic Workloads">
  <data key="d5">16.0</data>
  <data key="d6">Advanced analysis like SDFGs can identify dynamic workloads at compile time to enable better static optimization.&lt;SEP&gt;Advanced dependency analysis like SDFGs can identify dynamic workloads at compile time to enable better static optimization."|</data>
  <data key="d7">dependency analysis, static optimization</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Dependency Chain" target="Runtime Arguments">
  <data key="d5">12.0</data>
  <data key="d6">Extracted dependency chains can identify variables influencing control flow and parallel patterns, aiding in static analysis of dynamic applications.&lt;SEP&gt;Extracted dependency chains can identify variables influencing control flow and parallel patterns, aiding static analysis of dynamic applications."|</data>
  <data key="d7">dependency analysis, control flow</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Legion" target="Dynamic Load Balancing">
  <data key="d5">14.0</data>
  <data key="d6">Legion enables execution of tasklets with unknown sizes and supports dynamic load balancing across resources, including GPUs.&lt;SEP&gt;Legion enables execution of tasklets with unknown sizes and supports dynamic load balancing across resources, including GPUs."|</data>
  <data key="d7">load balancing, GPU support</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="StarPU" target="Distributed Memory Migration">
  <data key="d5">12.0</data>
  <data key="d6">StarPU allows migration of tasklets during runtime in distributed memory environments, supporting dynamic workloads.&lt;SEP&gt;StarPU allows migration of tasklets during runtime in distributed memory environments, supporting dynamic workloads."|</data>
  <data key="d7">distributed systems, runtime migration</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Variable Names" target="Random Seed">
  <data key="d5">20.0</data>
  <data key="d6">Changes in variable names influenced by random seeds can drastically affect the duration of solving processes, impacting scalability."|&lt;SEP&gt;Changes in variable names influenced by random seeds can drastically affect the duration of solving processes, impacting scalability."|&gt;"randomness, scalability&lt;SEP&gt;Random seed influences variable naming, which impacts the duration and stability of search processes in optimization."|&lt;SEP&gt;Random seed influences variable naming, which impacts the duration and stability of search processes in optimization."|&gt;"random seed, process duration</data>
  <data key="d7">5&lt;SEP&gt;random seed, process duration&lt;SEP&gt;randomness, scalability</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Beam Search" target="Search Space Pruning">
  <data key="d5">16.0</data>
  <data key="d6">Applying beam search with pruning strategies like n-best can create more predictable, stable, and reproducible scheduling results.&lt;SEP&gt;Applying beam search with pruning strategies like n-best can create more predictable, stable, and reproducible scheduling results."|</data>
  <data key="d7">search algorithms, stability</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Beam Search" target="Scheduling Problems">
  <data key="d5">14.0</data>
  <data key="d6">Beam search is used as a more stable alternative to LP-solvers for complex scheduling problems, facilitating control over search space and solution stability."|&lt;SEP&gt;Beam search is used as a more stable alternative to LP-solvers for complex scheduling problems, facilitating control over search space and solution stability."|&gt;"optimization, stability</data>
  <data key="d7">7&lt;SEP&gt;optimization, stability</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="parallel patterns" target="Rodinia and LULESH">
  <data key="d5">14.0</data>
  <data key="d6">Parallel patterns are used in applications like Rodinia and LULESH to reduce analysis complexity and enable larger application support."|&gt;"parallel programming, analysis&lt;SEP&gt;Parallel patterns are used to reduce analysis complexity and support larger applications in heterogeneous computing."|&gt;"parallel programming, analysis</data>
  <data key="d7">7</data>
  <data key="d8">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="code generator" target="performance improvements">
  <data key="d5">20.0</data>
  <data key="d6">The code generator's implementation enables global optimizations, leading to significant speedups and better workload distribution."|&gt;"optimization, compiler technology&lt;SEP&gt;The implementation of the code generator enables global optimizations and better workload distribution, leading to significant speedups."|&gt;"optimization, compiler technology</data>
  <data key="d7">10</data>
  <data key="d8">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="memory model" target="local memory copies">
  <data key="d5">18.0</data>
  <data key="d6">Improving the memory model to avoid local copies impacts both particle and myocyte simulations, enhancing efficiency."|&gt;"memory management, performance&lt;SEP&gt;Improving the memory model to avoid local copies impacts performance in particle and myocyte simulations."|&gt;"memory management, simulation efficiency</data>
  <data key="d7">9</data>
  <data key="d8">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="dynamic control flow" target="parallelization">
  <data key="d5">7.0</data>
  <data key="d6">Parallel execution within dynamic control flow structures enhances performance and resource utilization.</data>
  <data key="d7">parallel execution, control flow</data>
  <data key="d8">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="loop unrolling" target="streamcluster and cfd">
  <data key="d5">12.0</data>
  <data key="d6">Loop unrolling is used to optimize the execution of large loops in applications like streamcluster and cfd by reducing overhead."|&gt;"loop optimization, performance enhancement&lt;SEP&gt;Loop unrolling optimizes large loops in applications like streamcluster and cfd by reducing overhead and improving parallelism."|&gt;"loop optimization, performance improvement</data>
  <data key="d7">6</data>
  <data key="d8">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="global optimization step" target="local copies">
  <data key="d5">16.0</data>
  <data key="d6">A global optimization step aims to eliminate redundant local memory copies, thereby enhancing performance."|&gt;"optimization, memory efficiency&lt;SEP&gt;A global optimization step aims to eliminate unnecessary local memory copies, improving performance."|&gt;"optimization technique, memory efficiency</data>
  <data key="d7">8</data>
  <data key="d8">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="LULESH" target="parallel applications">
  <data key="d5">12.0</data>
  <data key="d6">LULESH demonstrates how larger applications can benefit from the global optimization approach, despite limited detailed gains."|&gt;"application scalability, analysis&lt;SEP&gt;LULESH demonstrates the applicability of global optimization techniques to larger applications, despite limited detailed performance gains."|&gt;"application scalability, analysis</data>
  <data key="d7">6</data>
  <data key="d8">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Mingzhen Li et al." target="Large-scale stencil computation">
  <data key="d5">16.0</data>
  <data key="d6">The study focuses on optimizing large-scale stencil computations on many-core processors using automatic code generation.&lt;SEP&gt;The study focuses on optimizing large-scale stencil computations on many-core processors.</data>
  <data key="d7">research focus, computational pattern</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Large-scale stencil computation" target="Automatic code generation">
  <data key="d5">18.0</data>
  <data key="d6">Automatic code generation techniques are applied to optimize large-scale stencil computations for high performance.&lt;SEP&gt;Automatic code generation techniques are applied to optimize large-scale stencil computations.</data>
  <data key="d7">method application, optimization&lt;SEP&gt;method application, performance enhancement</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Large-scale stencil computation" target="Many-core processors">
  <data key="d5">14.0</data>
  <data key="d6">Large-scale stencil computations are optimized for execution on many-core processors.&lt;SEP&gt;Large-scale stencil computations are optimized to run efficiently on many-core processors.</data>
  <data key="d7">hardware optimization, parallel computing&lt;SEP&gt;hardware optimization, parallelism</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Performance Variability in Mixed-Integer Programming" target="Andrea Lodi and Andrea Tramontani">
  <data key="d5">16.0</data>
  <data key="d6">The authors investigate factors influencing performance variability in mixed-integer programming.&lt;SEP&gt;The authors investigate the causes and effects of performance variability in mixed-integer programming solvers.</data>
  <data key="d7">research focus, performance analysis</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Mixed-Integer Programming" target="Performance Variability">
  <data key="d5">18.0</data>
  <data key="d6">Performance variability is a key challenge affecting the efficiency and predictability of solving mixed-integer programming problems.&lt;SEP&gt;Performance variability is a key issue affecting the efficiency of solving mixed-integer programming problems.</data>
  <data key="d7">conceptual link, problem impact</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="OpenSBLI" target="David J Lusher et al.">
  <data key="d5">16.0</data>
  <data key="d6">The study presents OpenSBLI as a tool for automated code generation for fluid dynamics on heterogeneous architectures.&lt;SEP&gt;The study presents OpenSBLI as a tool for automated code generation targeting heterogeneous architectures for fluid dynamics simulations.</data>
  <data key="d7">method development, application&lt;SEP&gt;tool development, application</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="OpenSBLI" target="Compressible Fluid Dynamics">
  <data key="d5">14.0</data>
  <data key="d6">OpenSBLI is applied to simulate and analyze compressible flows, enabling high-fidelity scientific modeling.&lt;SEP&gt;OpenSBLI is applied to simulate and analyze compressible fluid flows.</data>
  <data key="d7">application, scientific modeling</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="OpenSBLI" target="Heterogeneous Computing Architectures">
  <data key="d5">12.0</data>
  <data key="d6">OpenSBLI generates code optimized for heterogeneous hardware platforms.&lt;SEP&gt;OpenSBLI is designed to generate code optimized for heterogeneous computing architectures.</data>
  <data key="d7">hardware compatibility, optimization&lt;SEP&gt;hardware optimization, performance</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Korali" target="Sergio M Martin et al.">
  <data key="d5">16.0</data>
  <data key="d6">The study introduces Korali as a framework for stochastic optimization and Bayesian uncertainty quantification.&lt;SEP&gt;The study introduces Korali as a tool for stochastic optimization and Bayesian uncertainty quantification in HPC.</data>
  <data key="d7">tool development, application</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Korali" target="Stochastic Optimization">
  <data key="d5">14.0</data>
  <data key="d6">Korali is designed to perform stochastic optimization in high-performance computing contexts.&lt;SEP&gt;Korali is designed to perform stochastic optimization tasks in high-performance computing settings.</data>
  <data key="d7">application, optimization</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Korali" target="Bayesian Uncertainty Quantification">
  <data key="d5">12.0</data>
  <data key="d6">Korali facilitates Bayesian uncertainty quantification in scientific simulations.</data>
  <data key="d7">application, scientific modeling</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Memory Wall" target="Sally A. McKee and Robert W. Wisniewski">
  <data key="d5">16.0</data>
  <data key="d6">The authors discuss the concept of Memory Wall and its implications for high-performance computing.&lt;SEP&gt;The authors explain the concept of Memory Wall and analyze its implications for system performance.</data>
  <data key="d7">concept explanation, impact</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Improving Compiler Scalability" target="Sanyam Mehta and Pen-Chung Yew">
  <data key="d5">16.0</data>
  <data key="d6">The authors propose methods to enhance compiler scalability for large programs, focusing on efficiency and performance." ,&lt;SEP&gt;The study proposes methods to optimize large programs efficiently for better compiler scalability.</data>
  <data key="d7">compiler optimization, scalability&lt;SEP&gt;optimization techniques, scalability</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Improving Compiler Scalability" target="Large Programs">
  <data key="d5">7.0</data>
  <data key="d6">The research aims to improve the compilation of large programs, making it more scalable and efficient.</data>
  <data key="d7">software engineering, performance</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Efficiency of Algorithmic Structures" target="Julian Miller et al.">
  <data key="d5">16.0</data>
  <data key="d6">The study evaluates different algorithmic structures for their efficiency in high-performance parallel computing." ,&lt;SEP&gt;The study investigates the efficiency of different algorithmic structures for high-performance computing.</data>
  <data key="d7">performance analysis, algorithm design</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Polygeist" target="William S. Moses et al.">
  <data key="d5">16.0</data>
  <data key="d6">The study introduces Polygeist as a tool for transforming C code into Polyhedral MLIR for compiler optimization.&lt;SEP&gt;The study introduces Polygeist as a tool for transforming C code into Polyhedral MLIR to enable high-level code optimization.</data>
  <data key="d7">tool development, compiler optimization&lt;SEP&gt;tool development, compiler transformation</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Polygeist" target="C to Polyhedral MLIR">
  <data key="d5">14.0</data>
  <data key="d6">Polygeist converts C code into a form suitable for polyhedral optimization techniques.&lt;SEP&gt;Polygeist converts C code into an intermediate representation suitable for polyhedral optimization techniques.</data>
  <data key="d7">compiler transformation, optimization</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="MPI Forum" target="MPI: A Message-Passing Interface Standard, Version 3.1">
  <data key="d5">16.0</data>
  <data key="d6">The MPI Forum developed and published the MPI 3.1 standard for message-passing in parallel computing.&lt;SEP&gt;The MPI Forum developed and published the MPI 3.1 standard to define message-passing protocols for high-performance computing." ,</data>
  <data key="d7">standardization, communication protocol</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Automatically scheduling Halide pipelines" target="Ravi Teja Mullapudi et al.">
  <data key="d5">8.0</data>
  <data key="d6">The study develops methods for automatic scheduling to improve performance of Halide image processing pipelines.</data>
  <data key="d7">optimization, automation</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Halide" target="Image processing pipelines">
  <data key="d5">7.0</data>
  <data key="d6">Halide is used to define and compile image processing pipelines, with focus on automatic scheduling.</data>
  <data key="d7">application, performance enhancement</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Halide" target="Image Processing Pipelines">
  <data key="d5">21.0</data>
  <data key="d6">Halide is used to define and compile image processing pipelines, with a focus on automatic scheduling techniques.&lt;SEP&gt;Halide is used to define, compile, and optimize image processing pipelines, with a focus on automatic scheduling techniques.&lt;SEP&gt;Halide is used to define, compile, and optimize image processing pipelines, with a focus on automatic scheduling.</data>
  <data key="d7">application, performance</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Pthreads" target="Bradford Nichols et al.">
  <data key="d5">16.0</data>
  <data key="d6">The authors document Pthreads as a standard for multiprocessing programming." ,&lt;SEP&gt;The authors document Pthreads as a standardized API for portable multi-threaded programming." ,</data>
  <data key="d7">standardization, parallel programming</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="OpenMP Architecture Review Board" target="OpenMP 5.1">
  <data key="d5">16.0</data>
  <data key="d6">The organization developed and published the OpenMP 5.1 specification for shared-memory parallel programming.&lt;SEP&gt;The organization developed and published the OpenMP 5.1 standard to specify directives and APIs for parallel programming." ,</data>
  <data key="d7">standardization, parallel programming</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Filtered Beam Search in Scheduling" target="Peng Si Ow and Thomas E Morton">
  <data key="d5">16.0</data>
  <data key="d6">The study evaluates filtered beam search as a scheduling technique.&lt;SEP&gt;The study evaluates the effectiveness of filtered beam search as a scheduling method." ,</data>
  <data key="d7">algorithm, scheduling</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="A Compiler for Throughput Optimization of Graph Algorithms" target="Sreepathi Pai and Keshav Pingali">
  <data key="d5">16.0</data>
  <data key="d6">The authors develop a compiler to enhance throughput of graph algorithms on GPUs.&lt;SEP&gt;The authors develop a compiler to improve throughput of graph algorithms on GPUs.</data>
  <data key="d7">compiler design, optimization&lt;SEP&gt;compiler design, throughput optimization</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Graph Algorithms" target="GPUs">
  <data key="d5">14.0</data>
  <data key="d6">Graph algorithms are optimized for execution on GPUs using the developed compiler.&lt;SEP&gt;Graph algorithms are optimized to run efficiently on GPUs using the developed compiler framework.</data>
  <data key="d7">application, hardware acceleration&lt;SEP&gt;application, hardware optimization</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="OpenSHMEM" target="Stephen W. Poole et al.">
  <data key="d5">16.0</data>
  <data key="d6">The authors discuss OpenSHMEM as a unified RMA (Remote Memory Access) model for parallel communication." ,&lt;SEP&gt;The authors discuss OpenSHMEM as a unified RMA model for parallel communication.</data>
  <data key="d7">parallel communication, RMA</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="PPIR" target="Adrian Schmitz et al.">
  <data key="d5">16.0</data>
  <data key="d6">The study introduces PPIR as a tool for representing and optimizing parallel patterns in hierarchical parallel systems." ,&lt;SEP&gt;The study introduces PPIR as a tool for representing parallel patterns in hierarchical parallelism contexts.</data>
  <data key="d7">compiler IR, hierarchical parallelism&lt;SEP&gt;compiler IR, parallelism</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Lift" target="Michel Steuwer et al.">
  <data key="d5">16.0</data>
  <data key="d6">The authors develop Lift as an IR for generating efficient GPU code from high-level functional descriptions.&lt;SEP&gt;The authors develop Lift as an IR to generate efficient GPU code from functional programs." ,</data>
  <data key="d7">IR design, GPU code generation</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Lift" target="Michel Steuwer">
  <data key="d5">16.0</data>
  <data key="d6">Michel Steuwer contributed to the development of Lift, a data-parallel IR for GPU code generation, establishing a research relationship."|&lt;SEP&gt;Michel Steuwer contributed to the development of Lift, a data-parallel IR for GPU code generation, indicating a relationship between the researcher and the model.</data>
  <data key="d7">research contribution, GPU programming</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="C2Rust Development Team" target="C2Rust">
  <data key="d5">16.0</data>
  <data key="d6">The team develops C2Rust as a tool for translating C code into Rust to enhance safety and modernization." ,&lt;SEP&gt;The team develops C2Rust as a tool for translating C code into Rust.</data>
  <data key="d7">tool development, code translation</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="C2Rust Development Team" target="C2Rust Manual">
  <data key="d5">18.0</data>
  <data key="d6">The C2Rust Development Team authored and maintains the C2Rust Manual, providing instructions for code translation from C to Rust."|&lt;SEP&gt;The C2Rust Development Team created and maintains the C2Rust Manual, which guides users in translating C code to Rust."|</data>
  <data key="d7">software documentation, tool usage</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="2023" target="ChatGPT and environmental research">
  <data key="d5">5.0</data>
  <data key="d6">The publication date situates the research within current technological and scientific developments, emphasizing its recent relevance.</data>
  <data key="d7">temporal context</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Automatically Scheduling Halide Pipelines" target="Ravi Teja Mullapudi et al.">
  <data key="d5">24.0</data>
  <data key="d6">The study develops automated methods to optimize scheduling of Halide pipelines for better performance and resource use.&lt;SEP&gt;The study develops automated methods to optimize scheduling of Halide pipelines for improved performance and resource utilization." ,&lt;SEP&gt;The study develops methods for automatic scheduling to improve performance and efficiency of Halide pipelines.</data>
  <data key="d7">automation, performance optimization</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Damien Lebrun-Grandié" target="Kokkos 3">
  <data key="d5">14.0</data>
  <data key="d6">Damien Lebrun-Grandié is involved in extending programming models such as Kokkos 3 for exascale architecture support."|&lt;SEP&gt;Damien Lebrun-Grandié is involved in extending programming models such as Kokkos 3 to support exascale architectures."|</data>
  <data key="d7">research extension, performance portability</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Samuel Williams" target="Roofline">
  <data key="d5">16.0</data>
  <data key="d6">Samuel Williams contributed to developing the Roofline performance model for multicore architectures."|&lt;SEP&gt;Samuel Williams contributed to the development of the Roofline performance model for multicore architectures."|</data>
  <data key="d7">performance modeling, hardware analysis&lt;SEP&gt;performance modeling, multicore systems</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Andrew Waterman" target="Roofline">
  <data key="d5">16.0</data>
  <data key="d6">Andrew Waterman collaborated on the Roofline model, providing insights into hardware performance limits."|&lt;SEP&gt;Andrew Waterman collaborated on the Roofline performance model, providing insights into hardware performance."|</data>
  <data key="d7">performance analysis, hardware modeling</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="David Patterson" target="Roofline">
  <data key="d5">16.0</data>
  <data key="d6">David Patterson contributed to the conceptual development of the Roofline model for performance visualization."|</data>
  <data key="d7">performance visualization, modeling</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="PPL" target="Static Codes">
  <data key="d5">18.0</data>
  <data key="d6">The PPL approach enables automatic, global optimization for static codes, improving performance across architectures.&lt;SEP&gt;The PPL enables automatic, global optimization of static codes, improving performance across architectures."|</data>
  <data key="d7">optimization, static code, performance</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="PPL" target="Heterogeneous Architectures">
  <data key="d5">16.0</data>
  <data key="d6">The PPL workflow supports optimization for heterogeneous hardware from a single source, simplifying deployment.&lt;SEP&gt;The PPL workflow supports optimization for heterogeneous hardware from a single source, simplifying deployment."|</data>
  <data key="d7">multi-architecture, code portability</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="APTT" target="AMT">
  <data key="d5">8.0</data>
  <data key="d6">The AMT extends the APT by including optimization and mapping data, representing a distributed and concurrent execution model.</data>
  <data key="d7">heterogeneous mapping, distributed execution</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Techniques" target="Pattern Decomposition">
  <data key="d5">8.0</data>
  <data key="d6">Decomposition into map, stencil, and reduction enables structured parallel execution, with reduction involving synchronization and atomic operations.</data>
  <data key="d7">parallel algorithms, pattern decomposition</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Hardware and software components" target="Systems">
  <data key="d5">9.0</data>
  <data key="d6">The CLAIX18 systems include CPUs, GPUs, network fabric, and operating systems used for high-performance computing.</data>
  <data key="d7">system components, hardware setup</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Coverage" target="Rodinia benchmarks">
  <data key="d5">8.0</data>
  <data key="d6">The benchmarks are used to assess the applicability and coverage of the generated and optimized code in HPC scenarios.</data>
  <data key="d7">application coverage, benchmarking</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="overall performance" target="small applications">
  <data key="d5">8.0</data>
  <data key="d6">Performance improvements are most significant in small applications like backprop, nn, and srad due to reduced static overhead.</data>
  <data key="d7">performance, static overhead</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Monte Kernel" target="Reduction">
  <data key="d5">12.0</data>
  <data key="d6">Enhancing reduction strategies for the monte kernel can lead to better runtime performance."|&lt;SEP&gt;Improving reduction strategies for the monte kernel can enhance runtime efficiency.</data>
  <data key="d7">reduction, performance</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Alias Elimination" target="SDFGs">
  <data key="d5">14.0</data>
  <data key="d6">SDFGs enable aliasing elimination during compile time, improving dependency analysis and optimization.&lt;SEP&gt;SDFGs enable aliasing elimination during compile time, reducing dependency complexity."|</data>
  <data key="d7">aliasing, compile-time&lt;SEP&gt;aliasing, compile-time analysis</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Algorithms" target="Theoretical Model for Global Optimization">
  <data key="d5">18.0</data>
  <data key="d6">The model aims to optimize parallel algorithms globally to enhance performance and efficiency.&lt;SEP&gt;The model aims to optimize parallel algorithms globally to improve overall performance and resource efficiency.</data>
  <data key="d7">optimization, parallel computing</data>
  <data key="d8">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Domain Specialization" target="Open Challenges">
  <data key="d5">7.0</data>
  <data key="d6">Remaining issues such as data privacy, ethical considerations, and transferability hinder the full realization of domain-specific LLMs."|&lt;"limitations, ongoing issues</data>
  <data key="d7">7</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specialization" target="Prompt Crafting">
  <data key="d5">8.0</data>
  <data key="d6">Prompt techniques help adapt LLMs to specific domains, enhancing their performance and relevance.</data>
  <data key="d7">domain adaptation, prompt engineering</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specialization" target="prompt crafting">
  <data key="d5">8.0</data>
  <data key="d6">Prompt engineering enhances LLMs' ability to perform accurately within specific domains by designing tailored prompts.</data>
  <data key="d7">domain-specific prompts, accuracy</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specification Techniques" target="Taxonomy of Domain-Specialization Techniques">
  <data key="d5">8.0</data>
  <data key="d6">The taxonomy categorizes different techniques based on their accessibility and methodological framework, providing a systematic overview."|&lt;"classification, methodology</data>
  <data key="d7">8</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specification Techniques" target="Application Domains">
  <data key="d5">7.0</data>
  <data key="d6">Different application domains benefit from specific domain specialization techniques tailored to their unique data and constraints."|&lt;"application impact, domain-specific methods</data>
  <data key="d7">7</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specification Techniques" target="Research Status">
  <data key="d5">8.0</data>
  <data key="d6">Current research efforts are focused on developing and refining these techniques to overcome domain-related challenges."|&lt;"research development, innovation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specification Techniques" target="Future Trends">
  <data key="d5">8.0</data>
  <data key="d6">Future research trends include creating more comprehensive taxonomy, improving techniques for handling constraints, and expanding application domains."|&lt;"research directions, technological advancement</data>
  <data key="d7">8</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Taxonomy of Domain-Specialization Techniques" target="Domain Specialization Techniques">
  <data key="d5">8.0</data>
  <data key="d6">The taxonomy categorizes different methods based on accessibility and framework, providing a structured overview of the field.</data>
  <data key="d7">classification, methodology overview</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Domain Specialization Techniques">
  <data key="d5">7.0</data>
  <data key="d6">Certain application domains benefit more from specialized LLMs, and the taxonomy helps identify suitable techniques for each domain.</data>
  <data key="d7">application impact, domain-specific adaptation</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Domain Knowledge">
  <data key="d5">7.0</data>
  <data key="d6">Domain knowledge is essential for customizing LLMs to specific fields, ensuring relevance and accuracy of outputs."|&lt;"knowledge requirement, domain relevance</data>
  <data key="d7">7</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Social Norms, Cultural Conformity, Religious Beliefs, Ethical Standards">
  <data key="d5">7.0</data>
  <data key="d6">These constraints influence how LLMs are adapted and deployed in various social and cultural contexts."|&lt;"ethical constraints, cultural sensitivity</data>
  <data key="d7">7</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Taxonomy of Techniques">
  <data key="d5">14.0</data>
  <data key="d6">The taxonomy categorizes techniques suitable for different application domains, aiding targeted model development."|&gt;"method classification, domain mapping&lt;SEP&gt;The taxonomy helps categorize techniques suitable for different application domains, guiding domain-specific model development.</data>
  <data key="d7">7&lt;SEP&gt;method classification, domain mapping</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Model Complexity">
  <data key="d5">14.0</data>
  <data key="d6">Managing model complexity is critical for deploying suitable LLMs in various application domains, balancing interpretability and performance."|&lt;SEP&gt;Understanding and managing model complexity is crucial for deploying effective domain-specific LLMs across various fields."|</data>
  <data key="d7">model deployment, domain adaptation&lt;SEP&gt;model management, domain deployment</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Interdisciplinary Collaboration">
  <data key="d5">16.0</data>
  <data key="d6">Applying LLMs across fields benefits from collaboration among disciplines to tailor solutions and share expertise."|&lt;SEP&gt;Applying LLMs in different fields benefits from interdisciplinary collaboration to tailor solutions and share expertise."|</data>
  <data key="d7">cross-disciplinary, knowledge sharing</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Future Trends">
  <data key="d5">8.0</data>
  <data key="d6">Future research aims to develop more effective, transparent, and adaptable techniques for domain-specific LLMs across diverse fields."|</data>
  <data key="d7">research innovation, application</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Research Status and Future Trends" target="Domain Specialization Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Current research trends focus on advancing domain-specific techniques, with future trends emphasizing systematic approaches and broader applications.</data>
  <data key="d7">research development, future directions</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Future Trends" target="Open Challenges">
  <data key="d5">7.0</data>
  <data key="d6">Addressing open challenges will shape future research directions and technological advancements in domain-specific LLMs."|&gt;"research priorities, innovation</data>
  <data key="d7">7</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Heterogeneity of Domain Data" target="Domain Knowledge">
  <data key="d5">6.0</data>
  <data key="d6">Heterogeneity in data complicates the integration of domain-specific knowledge into LLMs, affecting model performance."|&lt;"data challenges, knowledge integration</data>
  <data key="d7">6</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Knowledge" target="External Augmentation">
  <data key="d5">14.0</data>
  <data key="d6">External augmentation involves adding domain knowledge or tools externally to enhance LLM performance without internal modifications.&lt;SEP&gt;External augmentation involves adding external knowledge or tools to improve domain-specific performance without internal model changes.</data>
  <data key="d7">method, knowledge integration</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Knowledge" target="Knowledge Elicitation">
  <data key="d5">8.0</data>
  <data key="d6">Effective knowledge elicitation improves the integration of domain knowledge into LLMs, enhancing their accuracy and relevance."|</data>
  <data key="d7">knowledge integration, model improvement</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Open Challenges" target="Evaluation Methods">
  <data key="d5">8.0</data>
  <data key="d6">Evaluation methods are crucial for assessing techniques and identifying limitations in current approaches.</data>
  <data key="d7">performance metrics, benchmarking</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Open Challenges" target="Future Directions">
  <data key="d5">8.0</data>
  <data key="d6">Addressing current limitations through research on adaptation, knowledge update, and domain-specific training is crucial for advancing LLM deployment.</data>
  <data key="d7">research focus, future development</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Open Challenges" target="multi-agent collaboration">
  <data key="d5">7.0</data>
  <data key="d6">Multiple LLMs and AI agents can collaborate and communicate, but effective frameworks and protocols are still under development.</data>
  <data key="d7">multi-agent communication, collaboration challenges</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Natural Language Processing" target="Text Analysis">
  <data key="d5">8.0</data>
  <data key="d6">NLP encompasses techniques like tokenization and parsing to analyze the string and its words."|</data>
  <data key="d7">computational linguistics, AI</data>
  <data key="d8">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Knowledge cut-off" target="Open challenges">
  <data key="d5">14.0</data>
  <data key="d6">Knowledge cut-off limits LLMs' access to recent information, posing a challenge for maintaining up-to-date models.&lt;SEP&gt;Knowledge cut-off presents a challenge for keeping LLMs current with new information, necessitating ongoing updates.</data>
  <data key="d7">knowledge update, challenge</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Discoveries" target="Regulations">
  <data key="d5">14.0</data>
  <data key="d6">Discoveries and regulations are interconnected as new findings often lead to updated standards and practices in specialized fields.&lt;SEP&gt;New discoveries in domain fields often lead to updated regulations and best practices, influencing model training and deployment."|&gt;"knowledge evolution, standards</data>
  <data key="d7">7&lt;SEP&gt;knowledge development, standards</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Extraction" target="Re-Training">
  <data key="d5">6.0</data>
  <data key="d6">Re-training involves applying knowledge extraction techniques to update models with new information.</data>
  <data key="d7">model maintenance, data processing</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Continuous Learning" target="Knowledge Update">
  <data key="d5">8.0</data>
  <data key="d6">Continuous learning enables LLMs to adapt over time by integrating ongoing domain knowledge updates."|&gt;"adaptability, model relevance</data>
  <data key="d7">8</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain-Specific Knowledge" target="Hallucination">
  <data key="d5">8.0</data>
  <data key="d6">Insufficient domain-specific knowledge can lead LLMs to hallucinate, producing inaccurate outputs.</data>
  <data key="d7">model accuracy, knowledge gaps</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hallucination" target="Ziwei Ji">
  <data key="d5">16.0</data>
  <data key="d6">Ziwei Ji's survey addresses hallucination issues in natural language generation.</data>
  <data key="d7">hallucination, NLG</data>
  <data key="d8">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Downstream Task Learning" target="Hyperparameters">
  <data key="d5">6.0</data>
  <data key="d6">Hyperparameters influence the success of domain adaptation by affecting training performance and stability.</data>
  <data key="d7">optimization, model performance</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Computational Power" target="Training and Fine-tuning">
  <data key="d5">8.0</data>
  <data key="d6">High computational resources are essential for training and fine-tuning large-scale LLMs effectively.</data>
  <data key="d7">hardware requirements, scalability</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specialization Techniques" target="Application Improvement">
  <data key="d5">8.0</data>
  <data key="d6">Specialization techniques tailor LLMs to specific domains, improving accuracy and relevance for targeted NLP tasks.</data>
  <data key="d7">domain relevance, application</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Update" target="Model Re-Training">
  <data key="d5">8.0</data>
  <data key="d6">Knowledge update mechanisms like re-training are used to incorporate new domain-specific information into LLMs, maintaining relevance."|&gt;"model maintenance, data integration</data>
  <data key="d7">8</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Representation" target="Evan Hernandez">
  <data key="d5">16.0</data>
  <data key="d6">Evan Hernandez researches measuring and manipulating knowledge representations in language models.</data>
  <data key="d7">knowledge, language models</data>
  <data key="d8">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Transformer Architecture" target="Pre-trained Language Models">
  <data key="d5">8.0</data>
  <data key="d6">PLMs are built upon Transformer architecture, which enables effective processing of linguistic data and underpins the design of LLMs.</data>
  <data key="d7">architectural basis, NLP modeling</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Risks of Generic LLMs" target="Implication">
  <data key="d5">8.0</data>
  <data key="d6">Applying generic LLMs without domain-specific tuning can result in inaccuracies and lack of originality, emphasizing the importance of specialization.</data>
  <data key="d7">accuracy risks, domain relevance</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Future Directions" target="Labor Market Impact">
  <data key="d5">6.0</data>
  <data key="d6">Research on Codex's effects on labor market outcomes aims to inform policy and workforce adaptation.</data>
  <data key="d7">policy implications, workforce</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Future Directions" target="Testing and Bugs">
  <data key="d5">6.0</data>
  <data key="d6">Research is needed to understand how Codex influences testing practices and downstream bugs.</data>
  <data key="d7">software quality, practices</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Future Directions" target="Labor Market">
  <data key="d5">6.0</data>
  <data key="d6">Research on how Codex impacts labor market outcomes aims to inform workforce policies and adaptation strategies.</data>
  <data key="d7">policy, workforce</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Future Directions" target="Code Documentation Practices">
  <data key="d5">7.0</data>
  <data key="d6">Research is needed to understand how Codex influences documentation quality and downstream bugs.</data>
  <data key="d7">research, quality</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Future Directions" target="Testing Practices">
  <data key="d5">6.0</data>
  <data key="d6">Further studies are required to assess how Codex affects testing practices and the occurrence of downstream bugs.</data>
  <data key="d7">testing, bugs</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Future Directions" target="Impacts on Wages and Productivity">
  <data key="d5">6.0</data>
  <data key="d6">Research aims to quantify how AI-assisted coding influences worker wages, productivity, and job satisfaction.</data>
  <data key="d7">economic impact, labor</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Future Directions" target="Barriers to Entry">
  <data key="d5">6.0</data>
  <data key="d6">Future research may explore how Codex lowers barriers, affecting diversity and inclusion in programming fields.</data>
  <data key="d7">accessibility, diversity</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Ms" target="Sequence-to-Sequence Tasks">
  <data key="d5">14.0</data>
  <data key="d6">Ms are used for sequence-to-sequence tasks like translation and summarization, with models like T5 serving as examples.&lt;SEP&gt;Ms are used for sequence-to-sequence tasks, exemplified by models like T5, in NLP applications.</data>
  <data key="d7">application, NLP tasks</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="T5" target="Sequence-to-Sequence Tasks">
  <data key="d5">16.0</data>
  <data key="d6">T5 exemplifies a model designed for sequence-to-sequence tasks like translation and summarization, illustrating its core concept and application.&lt;SEP&gt;T5 is designed for sequence-to-sequence NLP tasks such as translation and summarization, exemplifying core concepts in NLP models.</data>
  <data key="d7">model-function, NLP tasks</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specialization of LLMs" target="Techniques">
  <data key="d5">20.0</data>
  <data key="d6">The taxonomy categorizes approaches into external augmentation, prompt crafting, and model fine-tuning, each suited for different levels of model access and control."|&lt;SEP&gt;The taxonomy categorizes domain specialization approaches into external augmentation, prompt crafting, and model fine-tuning, each suited to different levels of model access and control."|</data>
  <data key="d7">10</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="External Augmentation" target="Black Box">
  <data key="d5">12.0</data>
  <data key="d6">Black box models depend on external augmentation techniques since internal details are inaccessible, relying on external resources or APIs.&lt;SEP&gt;Black box models rely on external augmentation techniques since internal model details are inaccessible, using external knowledge sources.</data>
  <data key="d7">model access, external tools</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Crafting" target="Domain Knowledge Utilization">
  <data key="d5">16.0</data>
  <data key="d6">Prompt crafting involves designing prompts that guide LLMs to better utilize domain knowledge during inference.&lt;SEP&gt;Prompt crafting involves designing prompts that guide LLMs to leverage domain knowledge during inference.</data>
  <data key="d7">method, prompt engineering</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Crafting" target="Grey Box">
  <data key="d5">14.0</data>
  <data key="d6">Grey box models utilize limited internal information, primarily leveraging prompt design for domain adaptation.</data>
  <data key="d7">model access, prompt design</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Explicit Knowledge" target="Enhances">
  <data key="d5">18.0</data>
  <data key="d6">Retrieving explicit knowledge from external sources enhances the accuracy and relevance of model predictions for domain-specific tasks."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Implicit Knowledge" target="Stores">
  <data key="d5">12.0</data>
  <data key="d6">Implicit knowledge is stored as vectorized embeddings learned during pre-training, representing complex data patterns."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-Tuning" target="Haojie Zhang et al.">
  <data key="d5">16.0</data>
  <data key="d6">They optimized subnetworks for effective fine-tuning of pre-trained language models."|</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-Tuning" target="Daniel M Ziegler et al.">
  <data key="d5">8.0</data>
  <data key="d6">They explored fine-tuning language models based on human preferences."|</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Behavior" target="Out-of-Distribution Prompts">
  <data key="d5">6.0</data>
  <data key="d6">Models tend to produce more harmful or biased outputs when prompted with out-of-distribution inputs.</data>
  <data key="d7">robustness, model behavior</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Neural Retriever" target="Utilizes">
  <data key="d5">16.0</data>
  <data key="d6">The neural retriever employs similarity metrics to search knowledge bases for relevant information based on queries."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Attention Mechanisms" target="Uses">
  <data key="d5">18.0</data>
  <data key="d6">Attention mechanisms are used to retrieve task-related implicit knowledge by calculating relevance scores between queries and stored embeddings."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Attention Mechanisms" target="Internal Mechanisms of LLMs">
  <data key="d5">8.0</data>
  <data key="d6">Attention mechanisms localize relevant internal representations, aiding in understanding and editing internal knowledge."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Instruction Cycle" target="Creates">
  <data key="d5">16.0</data>
  <data key="d6">An instruction cycle involves retrieving implicit knowledge, parsing outputs, and storing variable assignments for complex problem-solving."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="External Knowledge" target="Incorporates">
  <data key="d5">18.0</data>
  <data key="d6">External knowledge, both explicit and implicit, is incorporated into LLMs to improve performance, flexibility, and lifelong learning capabilities."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Seamless Integration" target="Challenges">
  <data key="d5">14.0</data>
  <data key="d6">Integrating external knowledge into LLMs faces challenges like relevance, completeness, and conflict resolution."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Scalability and Adaptability" target="Challenges">
  <data key="d5">12.0</data>
  <data key="d6">Scaling to large knowledge bases and adapting to new information pose computational and design challenges."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Collaborative Integration Approach" target="Multi-stage Pipeline">
  <data key="d5">16.0</data>
  <data key="d6">The collaborative approach employs a multi-stage pipeline where LLMs generate commands, execute domain tools, and process results to solve complex problems.</data>
  <data key="d7">methodology, task execution</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Task Planning and Coordination" target="Multi-tool Use">
  <data key="d5">16.0</data>
  <data key="d6">LLMs act as task planners to decompose a complex task into subtasks, coordinate multiple domain tools, and generate executable commands for precise problem solving.&lt;SEP&gt;LLMs act as task planners to decompose complex tasks into subtasks, coordinate multiple domain tools, and generate executable commands for precise problem solving.</data>
  <data key="d7">task management, orchestration</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Integration" target="Result Post-processing">
  <data key="d5">7.0</data>
  <data key="d6">The integration of general language understanding with domain-specific outputs allows LLMs to refine and produce accurate, human-readable results.</data>
  <data key="d7">knowledge fusion, output refinement</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Task Planners" target="LLMs as controllers">
  <data key="d5">8.0</data>
  <data key="d6">LLMs are modeled as controllers or API selectors that manage multiple tools to decompose and coordinate complex tasks.</data>
  <data key="d7">model control, task decomposition</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Automated Theorem Proving Frameworks" target="DSP framework">
  <data key="d5">9.0</data>
  <data key="d6">The DSP framework employs LLMs to draft informal proofs, generate formal sketches, and verify conjectures with provers, illustrating multi-stage reasoning.</data>
  <data key="d7">proof automation, formal reasoning</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs Embodied in Robots" target="Human-Robot Interaction">
  <data key="d5">7.0</data>
  <data key="d6">LLMs embedded in robots facilitate decision-making and interaction with humans, supporting physical and social tasks.</data>
  <data key="d7">decision-making, human-robot collaboration</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs Embodied in Robots" target="Physics Engines">
  <data key="d5">6.0</data>
  <data key="d6">Physics engines provide grounded simulation environments that LLMs can use for physics reasoning tasks.</data>
  <data key="d7">grounded reasoning, physics simulation</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Human-Robot Interaction" target="LLMs embodied in robots">
  <data key="d5">7.0</data>
  <data key="d6">LLMs embedded in robots enable decision-making, perception, and interaction capabilities, supporting physical and social tasks.</data>
  <data key="d7">decision-making, physical interaction</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Multi-Agent Collaboration" target="Open Challenges in LLM Tool Augmentation">
  <data key="d5">7.0</data>
  <data key="d6">Multiple LLMs and agents can communicate and collaborate, but effective frameworks and protocols are still being developed.</data>
  <data key="d7">multi-agent systems, collaboration challenges</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Zero-shot Discrete Prompts" target="LLM">
  <data key="d5">16.0</data>
  <data key="d6">Zero-shot prompts are designed to test the ability of LLMs to perform tasks without prior examples, relying solely on task descriptions.</data>
  <data key="d7">prompt design, task generalization</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Few-shot Discrete Prompts" target="LLM">
  <data key="d5">14.0</data>
  <data key="d6">Few-shot prompts provide illustrative examples to improve LLM performance on specific tasks with limited data.</data>
  <data key="d7">training data, sample efficiency</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLM" target="Instruction Alignment Pre-training">
  <data key="d5">16.0</data>
  <data key="d6">This pre-training strategy improves LLMs' ability to follow instructions and perform zero-shot tasks effectively.</data>
  <data key="d7">training strategy, instruction following</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Adaptation" target="PADA">
  <data key="d5">12.0</data>
  <data key="d6">PADA uses domain-specific features in prompts to help LLMs adapt to new domains unseen during training.</data>
  <data key="d7">domain transfer, feature generation</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Adaptation" target="OPTIMA">
  <data key="d5">7.0</data>
  <data key="d6">OPTIMA regularizes decision boundaries in domain adaptation using adversarial learning, enhancing prompt tuning effectiveness.</data>
  <data key="d7">approach, domain adaptation</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Adaptation" target="Adapter-based Fine-tuning">
  <data key="d5">8.0</data>
  <data key="d6">Adapter-based fine-tuning adds small modules (adapters) to improve domain-specific performance efficiently.</data>
  <data key="d7">approach, domain adaptation</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Adaptation" target="Adapters">
  <data key="d5">18.0</data>
  <data key="d6">Adapters facilitate efficient domain adaptation in models, allowing them to transfer knowledge across different tasks or data domains.</data>
  <data key="d7">model adaptation, transfer learning</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Reasoning Ability" target="Zero-shot CoT">
  <data key="d5">18.0</data>
  <data key="d6">Zero-shot Chain-of-Thought prompts enhance the reasoning process of LLMs by encouraging multi-step logical thinking.</data>
  <data key="d7">reasoning, multi-step inference</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Tuning" target="Task-dependent Prompt Tuning">
  <data key="d5">16.0</data>
  <data key="d6">Task-dependent prompt tuning is a specific approach within prompt tuning that creates a shared prompt optimized for all instances in a particular task, capturing task-specific information.&lt;SEP&gt;Task-dependent prompt tuning is a specific method within prompt tuning that creates a shared prompt optimized for all instances within a task, capturing task-specific information.</data>
  <data key="d7">methodology, task adaptation</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Tuning" target="Discreet Prompt Methods">
  <data key="d5">7.0</data>
  <data key="d6">Prompt tuning addresses issues like reliance on prompt wording and search complexity inherent in discrete prompt methods, offering more flexible solutions.</data>
  <data key="d7">methodology, challenge</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Tuning" target="Shengding Hu">
  <data key="d5">16.0</data>
  <data key="d6">Shengding Hu's research on knowledgeable prompt-tuning incorporates knowledge into text classification.</data>
  <data key="d7">prompt tuning, knowledge</data>
  <data key="d8">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Tuning" target="LFPT5">
  <data key="d5">14.0</data>
  <data key="d6">LFPT5 uses prompt tuning of the T5 model for lifelong, few-shot language learning tasks.&lt;SEP&gt;LFPT5 utilizes prompt tuning of T5 for lifelong and few-shot learning scenarios.</data>
  <data key="d7">methodology, model adaptation</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Tuning" target="Xianjun Yang et al.">
  <data key="d5">18.0</data>
  <data key="d6">They proposed a unified framework for prompt tuning, including dynamic prompt strategies."|</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Tuning" target="Hongbin Ye et al.">
  <data key="d5">16.0</data>
  <data key="d6">They developed ontology-enhanced prompt tuning for few-shot learning."|</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Content Enhancement" target="Initialization Strategies">
  <data key="d5">18.0</data>
  <data key="d6">Enhancement strategies improve prompt embeddings by task-specific initialization or knowledge transfer, leading to better training convergence and performance.</data>
  <data key="d7">prompt optimization, initialization</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Content Enhancement" target="Instance-dependent Prompt Tuning">
  <data key="d5">15.0</data>
  <data key="d6">Generates instance-specific prompts by incorporating contextual knowledge and external ontologies, improving task specificity.&lt;SEP&gt;Generates prompts tailored to individual instances by incorporating contextual information and external knowledge.</data>
  <data key="d7">context-aware prompts, external knowledge&lt;SEP&gt;instance-specific adaptation, context embedding</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Content Enhancement" target="IDPG">
  <data key="d5">16.0</data>
  <data key="d6">Creates adaptive prompts based on sentence embeddings, capturing semantic nuances for individual instances.&lt;SEP&gt;Uses an additional perceptron to generate adaptive prompts based on sentence embeddings, capturing instance nuances.</data>
  <data key="d7">adaptive prompt generation, sentence embedding&lt;SEP&gt;instance-specific prompts, semantic embedding</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Content Enhancement" target="ATTEMPT">
  <data key="d5">14.0</data>
  <data key="d6">Aggregates multiple prompts using attention networks to create instance-specific prompts, improving task performance.&lt;SEP&gt;Aggregates multiple source prompts using attention mechanisms to produce tailored prompts for each input instance.</data>
  <data key="d7">prompt aggregation, attention&lt;SEP&gt;prompt aggregation, attention mechanism</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Content Enhancement" target="OntoPrompt">
  <data key="d5">16.0</data>
  <data key="d6">Enriches prompts with external knowledge and dynamically tunes prompt position and length for better task adaptation.&lt;SEP&gt;Incorporates external ontology knowledge into prompts and dynamically adjusts prompt position, length, and content for better alignment with task requirements.</data>
  <data key="d7">knowledge infusion, dynamic tuning&lt;SEP&gt;ontology integration, dynamic tuning</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Self-supervised Learning" target="Prompt Initialization">
  <data key="d5">14.0</data>
  <data key="d6">Self-supervised learning pre-trains prompts on unlabeled data, providing effective initializations that improve downstream task performance.&lt;SEP&gt;Self-supervised pre-training provides effective initial prompts, facilitating better downstream task performance and transferability.</data>
  <data key="d7">unsupervised learning, prompt effectiveness&lt;SEP&gt;unsupervised training, prompt effectiveness</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Self-supervised Learning" target="Prompt Pre-training">
  <data key="d5">8.0</data>
  <data key="d6">Self-supervised learning is used to pre-train prompts, enabling effective initialization for downstream NLP tasks.</data>
  <data key="d7">training methodology, pre-training</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Self-supervised Learning" target="Pre-training of Prompts">
  <data key="d5">8.0</data>
  <data key="d6">Self-supervised learning is used to pre-train prompts, enabling effective initialization for downstream NLP tasks.</data>
  <data key="d7">training paradigm, pre-training</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Pre-training" target="Transferability of Prompts">
  <data key="d5">7.0</data>
  <data key="d6">Pre-trained prompts can be transferred across tasks and models, accelerating training and improving performance.</data>
  <data key="d7">transfer learning, model initialization</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Transferability of Prompts" target="Lifelong Learning with Soft Prompts">
  <data key="d5">8.0</data>
  <data key="d6">Soft prompts are trained continuously to retain knowledge across multiple tasks, facilitating lifelong learning.</data>
  <data key="d7">continual learning, knowledge retention</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Transferability of Prompts" target="Pre-training of Prompts">
  <data key="d5">7.0</data>
  <data key="d6">Pre-trained prompts can be transferred across different tasks and models, leading to faster convergence and better generalization.</data>
  <data key="d7">transfer learning, model adaptation</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Transferability of Prompts" target="Lifelong Learning">
  <data key="d5">8.0</data>
  <data key="d6">Soft prompts are trained continuously to help models retain knowledge and adapt across multiple tasks over time.</data>
  <data key="d7">continual learning, knowledge retention</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="KnowPrompt" target="Relation Extraction">
  <data key="d5">9.0</data>
  <data key="d6">Uses templates with '[MASK]' tokens and virtual type words to align entity types with relations during training.</data>
  <data key="d7">relation modeling, template design</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="KiPT" target="Event Detection">
  <data key="d5">8.0</data>
  <data key="d6">Identifies trigger words based on semantic similarity to event concepts, reformulating sequence tagging into generative tasks.</data>
  <data key="d7">trigger word identification, sequence reformulation</data>
  <data key="d8">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="WARP" target="Interpretability of Soft Prompt Tuning">
  <data key="d5">8.0</data>
  <data key="d6">WARP found soft prompts to be non-interpretable, highlighting interpretability as a key weakness of soft prompt tuning.</data>
  <data key="d7">limitations, interpretability</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Continuous Prompt Tuning" target="Discreet Prompt Methods">
  <data key="d5">7.0</data>
  <data key="d6">Continuous prompt tuning addresses issues inherent in discrete prompt methods, such as reliance on prompt wording and search complexity.</data>
  <data key="d7">methodology, challenges</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt-tuning" target="Domain Terms">
  <data key="d5">8.0</data>
  <data key="d6">Prompt-tuning discovers prompt tokens near domain-related terms, improving relevance and interpretability in specific domains.</data>
  <data key="d7">technique, domain relevance</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Limited Access to LLMs" target="Derivative-free Prompt Tuning">
  <data key="d5">7.0</data>
  <data key="d6">Limited access to models with immense sizes or API restrictions motivates the development of derivative-free prompt tuning methods that do not require gradient access.</data>
  <data key="d7">challenge, methodology</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Black-box Tuning (BBT)" target="Derivative-free Optimization">
  <data key="d5">8.0</data>
  <data key="d6">BBT uses CMA-ES to search for optimal prompts without gradient information, suitable for black-box models.</data>
  <data key="d7">technique, optimization</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Clip-Tuning" target="Shuohuan Wang">
  <data key="d5">8.0</data>
  <data key="d6">Shuohuan Wang contributed to research on prompt learning techniques including Clip-Tuning.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Clip-Tuning" target="Yu Sun">
  <data key="d5">8.0</data>
  <data key="d6">Yu Sun collaborated on studies about prompt learning and reward-based optimization.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Clip-Tuning" target="Hao Tian">
  <data key="d5">8.0</data>
  <data key="d6">Hao Tian contributed to the development and evaluation of prompt learning methods like Clip-Tuning.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Clip-Tuning" target="Hua Wu">
  <data key="d5">8.0</data>
  <data key="d6">Hua Wu is involved in research on prompt learning methodologies for language models.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Clip-Tuning" target="Haifeng Wang">
  <data key="d5">8.0</data>
  <data key="d6">Haifeng Wang contributed to research on derivative-free prompt learning approaches.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Discrete Prompt Search" target="Derivative-free Approaches">
  <data key="d5">8.0</data>
  <data key="d6">Discrete prompt search methods aim to optimize prompts without gradient information, especially relevant when only textual queries are permitted.</data>
  <data key="d7">technique, optimization</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Fine-tuning for Domain Specialization" target="Methods">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning approaches, including adapter-based and task-oriented, tailor LLMs for specific domains or tasks by adjusting model parameters.</data>
  <data key="d7">techniques, domain adaptation</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Parameter-Efficient Fine-Tuning">
  <data key="d5">9.0</data>
  <data key="d6">Adapters enable efficient adaptation of large language models by adding trainable modules without modifying the entire model.</data>
  <data key="d7">technique, model adaptation</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Unsupervised Domain Adaptation (UDA)">
  <data key="d5">16.0</data>
  <data key="d6">UDA employs adapters to learn domain-invariant features without labeled data, improving cross-domain performance.&lt;SEP&gt;UDA employs adapters to learn domain-invariant features, enhancing cross-domain performance without labeled data.</data>
  <data key="d7">domain adaptation, unsupervised learning&lt;SEP&gt;unsupervised learning, domain generalization</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="AdapterFusion">
  <data key="d5">7.0</data>
  <data key="d6">AdapterFusion combines multiple domain adapters to improve multi-domain adaptation performance.</data>
  <data key="d7">multi-domain learning, model fusion</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="LLaMA-adapter">
  <data key="d5">8.0</data>
  <data key="d6">LLaMA-adapter is a specialized adapter architecture designed for efficient adaptation of large language models for instruction-following and multi-modal tasks.</data>
  <data key="d7">large language models, task-specific adaptation</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Neural Adapters">
  <data key="d5">9.0</data>
  <data key="d6">Neural adapters are inserted into transformer layers to facilitate domain-specific fine-tuning while keeping the original model parameters frozen.</data>
  <data key="d7">model fine-tuning, domain adaptation</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Low-Rank Adapters">
  <data key="d5">7.0</data>
  <data key="d6">Low-rank adapters utilize parameter-efficient structures like hypercomplex multiplication layers to reduce parameters and improve efficiency.</data>
  <data key="d7">parameter efficiency, model compression</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Residual Connection">
  <data key="d5">7.0</data>
  <data key="d6">Residual connections are incorporated into adapters to facilitate training and improve performance.</data>
  <data key="d7">neural network design, training stability</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Hypercomplex Multiplication Layers">
  <data key="d5">6.0</data>
  <data key="d6">Hypercomplex layers are used within adapters to enable parameter-efficient complex transformations.</data>
  <data key="d7">model complexity, parameter efficiency</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="AdaMix">
  <data key="d5">8.0</data>
  <data key="d6">AdaMix stacks and activates multiple adapters with stochastic routing to reduce computational cost while maintaining flexibility.</data>
  <data key="d7">efficiency, multi-adapter integration</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Libraries">
  <data key="d5">7.0</data>
  <data key="d6">Libraries like AdapterHub and LLM-adapters provide tools for implementing and managing adapter modules across models.</data>
  <data key="d7">tool support, implementation</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Stability and Universality">
  <data key="d5">14.0</data>
  <data key="d6">The stability and universality of adapters determine their consistent performance across various models and tasks.&lt;SEP&gt;The stability and universality of adapters determine their effectiveness across different models, tasks, and settings.</data>
  <data key="d7">performance consistency, generalizability</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Computational Resources">
  <data key="d5">12.0</data>
  <data key="d6">The number of adapter parameters impacts the computational cost of fine-tuning LLMs.&lt;SEP&gt;The number of adapter parameters influences the computational cost and resource requirements for fine-tuning.</data>
  <data key="d7">cost, scalability</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Shwai He">
  <data key="d5">16.0</data>
  <data key="d6">Shwai He proposes Sparseadapter as an approach to improve parameter efficiency of adapters in models.</data>
  <data key="d7">model optimization, adapters</data>
  <data key="d8">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Parameter-efficient Fine-tuning" target="Elad Ben Zaken et al.">
  <data key="d5">16.0</data>
  <data key="d6">They introduced Bitfit, a simple parameter-efficient fine-tuning method."|</data>
  <data key="d7">technique</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="AdapterFusion" target="Multiple Adapters">
  <data key="d5">9.0</data>
  <data key="d6">AdapterFusion combines multiple adapters trained on different tasks via a fusion layer to boost multi-task performance.</data>
  <data key="d7">multi-task learning, performance</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLaMA-adapter" target="Self-instruct Demonstrations">
  <data key="d5">7.0</data>
  <data key="d6">LLaMA-adapter utilizes self-instruct demonstrations to improve instruction-following capabilities in large language models.</data>
  <data key="d7">instruction tuning, multi-modal reasoning</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Parameter-sharing" target="Sequential Training">
  <data key="d5">9.0</data>
  <data key="d6">Parameter-sharing enables models to efficiently learn across multiple domains by sharing parameters during sequential training.</data>
  <data key="d7">efficiency, transfer learning</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Parameter-sharing" target="Frozen Parameters">
  <data key="d5">8.0</data>
  <data key="d6">Frozen parameters facilitate parameter-sharing by keeping certain model parts unchanged during fine-tuning.</data>
  <data key="d7">model stability, efficiency</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapter Modules" target="Adapter Fusion">
  <data key="d5">8.0</data>
  <data key="d6">Multiple adapter modules are combined using Adapter Fusion to enhance performance across multiple domains.</data>
  <data key="d7">multi-domain learning, model integration</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tiny-Attention Adapter" target="Hongyu Zhao et al.">
  <data key="d5">14.0</data>
  <data key="d6">They designed Tiny-Attention Adapter focusing on contextual importance."|</data>
  <data key="d7">tool</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Pruning" target="SparseAdapter">
  <data key="d5">7.0</data>
  <data key="d6">Pruning techniques are applied to SparseAdapters to reduce parameters and improve efficiency.</data>
  <data key="d7">model compression, scalability</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="SparseAdapter" target="Network Pruning">
  <data key="d5">7.0</data>
  <data key="d6">SparseAdapter employs network pruning techniques at initialization to reduce parameters and improve efficiency in neural adapters.</data>
  <data key="d7">parameter reduction, efficiency</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Kronecker Adapter (KronA)" target="LoRA">
  <data key="d5">8.0</data>
  <data key="d6">KronA addresses the limited representation power of LoRA by substituting SVD modules with Kronecker product modules of smaller matrices.</data>
  <data key="d7">representation power, model flexibility</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="UniPELT" target="Adapter Methods">
  <data key="d5">7.0</data>
  <data key="d6">UniPELT activates different combinations of adapter methods based on data or task needs, optimizing adaptation.</data>
  <data key="d7">adaptation, efficiency</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Routing Function" target="Multi-task Learning">
  <data key="d5">6.0</data>
  <data key="d6">Routing functions enable dynamic selection or weighting of adapters to facilitate multi-task learning setups.</data>
  <data key="d7">flexibility, task adaptation</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Reward Model" target="Model Policy">
  <data key="d5">9.0</data>
  <data key="d6">The reward model informs the update of the model policy by providing scores that guide reinforcement learning to improve content quality and alignment with human preferences.</data>
  <data key="d7">guidance, optimization</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Reward Model" target="Content-Based Reinforcement Learning">
  <data key="d5">10.0</data>
  <data key="d6">Content-based reinforcement learning uses the reward model to evaluate and rank generated content, guiding model updates toward preferred outputs."|</data>
  <data key="d7">10</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Reward Model" target="Evaluator Preferences">
  <data key="d5">9.0</data>
  <data key="d6">Human evaluator preferences inform the reward model, which scores content to reflect human judgments."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Content Generation" target="Reward Modeling">
  <data key="d5">8.0</data>
  <data key="d6">Reward modeling evaluates generated content to assign scores, which are used to refine the content generation process.</data>
  <data key="d7">evaluation, feedback</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Partial Knowledge Update" target="Knowledge Editing">
  <data key="d5">7.0</data>
  <data key="d6">Partial knowledge update techniques, such as editing specific parameters, aim to efficiently modify the model's knowledge base without full retraining.</data>
  <data key="d7">efficiency, targeted update</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Editing" target="Gradient Masking">
  <data key="d5">8.0</data>
  <data key="d6">Gradient masking is used within knowledge editing to selectively update parts of the model, reducing computational costs and preserving existing knowledge.</data>
  <data key="d7">efficiency, selective updating</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Gradient Masking" target="Model Update Process">
  <data key="d5">8.0</data>
  <data key="d6">Gradient masking is a core technique used within the model update process to selectively freeze or unfreeze parameters based on relevance or importance."|&gt;"technique, training efficiency</data>
  <data key="d7">8</data>
  <data key="d8">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Continual Learning" target="Rehearsal Techniques">
  <data key="d5">7.0</data>
  <data key="d6">Rehearsal methods help mitigate catastrophic forgetting by reintroducing previous data during training."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Editing Methods" target="Hyper-Network">
  <data key="d5">8.0</data>
  <data key="d6">Hyper-networks are used to efficiently update specific facts or parameters within an LLM, avoiding full retraining."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Editing Methods" target="Retrieval-Based Methods">
  <data key="d5">7.0</data>
  <data key="d6">Retrieval-based approaches store and reason over explicit knowledge edits, facilitating targeted updates."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Editing Methods" target="Textual Queries to Fact Encodings">
  <data key="d5">9.0</data>
  <data key="d6">Mapping textual queries to internal fact encodings allows targeted editing and probing of the model's knowledge."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Internal Mechanisms of LLMs" target="Neuron Activation Analysis">
  <data key="d5">8.0</data>
  <data key="d6">Analyzing neuron activations helps identify internal components responsible for specific knowledge, enabling editing."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Internal Mechanisms of LLMs" target="Causal Interventions">
  <data key="d5">8.0</data>
  <data key="d6">Causal interventions manipulate internal model components to study their effect on knowledge and predictions."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Parameter Masking" target="Efficiency in Fine-tuning">
  <data key="d5">8.0</data>
  <data key="d6">Parameter masking enhances efficiency by updating only relevant parameters, reducing computational costs."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain-specific Knowledge" target="Application in Social Sciences">
  <data key="d5">8.0</data>
  <data key="d6">Applications in social sciences utilize domain-specific knowledge extracted or distilled from LLMs to perform tasks like information extraction and predictions."|&gt;"application, domain expertise</data>
  <data key="d7">8</data>
  <data key="d8">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Useful in the field of biology" target="Fundamental biomedical research">
  <data key="d5">8.0</data>
  <data key="d6">The application of LLMs supports basic biological research, from analyzing functions to drug discovery.</data>
  <data key="d7">application, research support</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Useful in the field of biology" target="Clinical healthcare support">
  <data key="d5">9.0</data>
  <data key="d6">LLMs assist in medical record analysis, diagnosis, and personalized treatment, impacting healthcare outcomes.</data>
  <data key="d7">healthcare application, diagnosis</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Earth science" target="Spatial information">
  <data key="d5">16.0</data>
  <data key="d6">Earth science relies on spatial information and geographic tools to study climate, land-use, and environmental phenomena.</data>
  <data key="d7">spatial data, environmental monitoring</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Earth science" target="Methods">
  <data key="d5">16.0</data>
  <data key="d6">Incorporates earth observation, spatial analysis, complexity theory, and simulation modeling to investigate environmental phenomena.</data>
  <data key="d7">interdisciplinary methods, environmental research</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Finance and Law" target="Model specialization">
  <data key="d5">16.0</data>
  <data key="d6">Models are fine-tuned with domain-specific datasets to understand complex terminology, trends, and legal language.</data>
  <data key="d7">domain adaptation, AI training</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Finance and Law" target="Ethical guardrails">
  <data key="d5">14.0</data>
  <data key="d6">Maintaining ethical standards in high-stakes financial and legal decision-making is critical.</data>
  <data key="d7">ethics, AI safety</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Balancing General and Domain Knowledge" target="Explainability and Trust">
  <data key="d5">8.0</data>
  <data key="d6">Maintaining a balance between broad and domain-specific knowledge enhances the model's ability to generate relevant, coherent, and trustworthy responses, especially in specialized fields.</data>
  <data key="d7">concept relationship, model transparency</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapting to Domain Evolution" target="Future Techniques in Domain Specialization">
  <data key="d5">7.0</data>
  <data key="d6">Continual adaptation techniques are essential for LLMs to stay relevant as domains evolve with new terminology and concepts, influencing future research directions.</data>
  <data key="d7">adaptation, domain evolution</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Scalability" target="Future Techniques in Domain Specialization">
  <data key="d5">6.0</data>
  <data key="d6">Scalability challenges influence the development of new methods that can efficiently extend domain-specific training across multiple and complex domains.</data>
  <data key="d7">scalability, resource management</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hybrid Approaches" target="Future Techniques in Domain Specialization">
  <data key="d5">9.0</data>
  <data key="d6">Hybrid methods combine various strategies to optimize performance and resource use, representing a promising approach for scalable and effective domain adaptation.</data>
  <data key="d7">method integration, resource efficiency</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Meta-Learning or AutoML Techniques" target="Future Techniques in Domain Specialization">
  <data key="d5">8.0</data>
  <data key="d6">Meta-learning strategies aim to automate and optimize the selection of domain adaptation methods, reducing resource requirements and improving effectiveness in domain-specific tasks.</data>
  <data key="d7">automation, optimization</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Incorporating More Explicit World Knowledge" target="Future Techniques in Domain Specialization">
  <data key="d5">9.0</data>
  <data key="d6">Leveraging structured knowledge sources like knowledge graphs enhances LLM understanding, enabling more accurate and context-aware responses in specialized domains.</data>
  <data key="d7">structured knowledge, reasoning</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Human-in-the-loop Learning" target="Future Techniques in Domain Specialization">
  <data key="d5">9.0</data>
  <data key="d6">Involving human feedback allows continuous model improvement and adaptation, ensuring relevance and accuracy in dynamic domains.</data>
  <data key="d7">feedback, continuous learning</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Active Learning" target="Future Techniques in Domain Specialization">
  <data key="d5">8.0</data>
  <data key="d6">Active querying for unfamiliar concepts improves the model's domain understanding and responsiveness, facilitating more interactive and accurate outputs.</data>
  <data key="d7">interactive learning, domain understanding</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Explainability" target="Black-box Methods">
  <data key="d5">7.0</data>
  <data key="d6">Black-box approaches often lack transparency, making it difficult to interpret how models arrive at their outputs."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Explainability" target="Grey-box Methods">
  <data key="d5">8.0</data>
  <data key="d6">Hybrid approaches aim to balance interpretability and performance by combining transparent and opaque techniques."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Explainability" target="White-box Methods">
  <data key="d5">9.0</data>
  <data key="d6">White-box methods prioritize transparency, making internal mechanisms understandable to users."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Ontology" target="Structured Knowledge Sources">
  <data key="d5">8.0</data>
  <data key="d6">Ontologies provide a formal and structured representation of domain concepts and relationships, aiding knowledge integration."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Meta-Learning" target="Model Adaptation">
  <data key="d5">8.0</data>
  <data key="d6">Meta-learning enables models to learn how to better adapt to new domains by optimizing their own learning strategies."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Scaling" target="Biological Structure and Function">
  <data key="d5">8.0</data>
  <data key="d6">Scaling models to large datasets enables the emergence of biological insights from protein sequences.</data>
  <data key="d7">application, biological modeling</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Adaptation" target="Edward J Hu">
  <data key="d5">18.0</data>
  <data key="d6">Edward J Hu's work on Low-rank adaptation (LoRA) enhances large language model efficiency.</data>
  <data key="d7">model adaptation, LoRA</data>
  <data key="d8">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Medical Ontology" target="Domain-Specific Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Medical ontologies serve as foundational knowledge structures that inform and support the development of domain-specific techniques for LLM adaptation."|</data>
  <data key="d7">knowledge structuring, domain adaptation</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain-Specific Techniques" target="Future Research">
  <data key="d5">7.0</data>
  <data key="d6">Future research aims to improve these techniques' effectiveness and address current challenges in domain adaptation."|</data>
  <data key="d7">research development, innovation</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Challenges and Limitations" target="Knowledge Elicitation">
  <data key="d5">6.0</data>
  <data key="d6">Addressing limitations involves developing better methods for knowledge elicitation to enhance LLM domain specialization."|</data>
  <data key="d7">problem-solving, knowledge extraction</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Challenges and Limitations" target="Knowledge Gaps">
  <data key="d5">8.0</data>
  <data key="d6">Addressing knowledge gaps is essential to improve LLM adaptation and overcome current limitations in domain-specific applications."|</data>
  <data key="d7">problem-solving, knowledge gaps</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Challenges and Limitations" target="Black-Box Methods">
  <data key="d5">7.0</data>
  <data key="d6">Black-box methods face limitations in interpretability, which can hinder trust and transparency in domain-specific applications."|</data>
  <data key="d7">model transparency, trust</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Challenges and Limitations" target="White-Box Methods">
  <data key="d5">7.0</data>
  <data key="d6">White-box methods aim to improve interpretability, but may face challenges related to complexity and computational cost."|</data>
  <data key="d7">interpretability, model complexity</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Multi-Head Adapter Routing for Data-Efficient Fine-Tuning" target="arXiv preprint arXiv:2211.03831">
  <data key="d5">8.0</data>
  <data key="d6">The preprint presents research on adapter routing strategies to enhance data-efficient fine-tuning of models, directly related to methodologies and objectives of the study.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="arXiv preprint arXiv:2211.03831" target="Lucas Caccia">
  <data key="d5">8.0</data>
  <data key="d6">The preprint presents research on adapter routing strategies aimed at improving data-efficient fine-tuning, directly related to methodologies and model training.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="arXiv preprint arXiv:2211.03831" target="Edoardo Ponti">
  <data key="d5">8.0</data>
  <data key="d6">Edoardo Ponti is a co-author of the study on adapter routing, contributing to research on model fine-tuning techniques.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="arXiv preprint arXiv:2211.03831" target="Lucas Liu">
  <data key="d5">8.0</data>
  <data key="d6">Lucas Liu contributed to the research on adapter routing strategies for efficient model training.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="arXiv preprint arXiv:2211.03831" target="Matheus Pereira">
  <data key="d5">8.0</data>
  <data key="d6">Matheus Pereira is involved in the study on data-efficient fine-tuning via adapter routing.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="arXiv preprint arXiv:2211.03831" target="Nicolas Le Roux">
  <data key="d5">8.0</data>
  <data key="d6">Nicolas Le Roux contributed to developing the theoretical framework for adapter routing.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="arXiv preprint arXiv:2211.03831" target="Alessandro Sordoni">
  <data key="d5">8.0</data>
  <data key="d6">Alessandro Sordoni is a co-author, focusing on model architecture and routing mechanisms.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Yihan Cao" target="A comprehensive survey of ai-generated content (aigc)">
  <data key="d5">18.0</data>
  <data key="d6">Yihan Cao authored the survey, analyzing the evolution and history of generative AI models.&lt;SEP&gt;Yihan Cao authored the survey, providing a comprehensive overview of generative AI history and models.</data>
  <data key="d7">9</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Siyu Li" target="A comprehensive survey of ai-generated content (aigc)">
  <data key="d5">18.0</data>
  <data key="d6">Siyu Li contributed to the survey by summarizing generative AI technologies from GANs to ChatGPT.&lt;SEP&gt;Siyu Li contributed to the survey, summarizing generative AI developments from GANs to ChatGPT.</data>
  <data key="d7">9</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Yixin Liu" target="A comprehensive survey of ai-generated content (aigc)">
  <data key="d5">18.0</data>
  <data key="d6">Yixin Liu helped compile the history and development of generative AI models.&lt;SEP&gt;Yixin Liu helped compile the history and evolution of generative AI technologies.</data>
  <data key="d7">9</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Zhiling Yan" target="A comprehensive survey of ai-generated content (aigc)">
  <data key="d5">18.0</data>
  <data key="d6">Zhiling Yan contributed insights on generative AI history and methodologies.&lt;SEP&gt;Zhiling Yan contributed insights on the progression of generative AI from early models to advanced systems.</data>
  <data key="d7">9</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Yutong Dai" target="A comprehensive survey of ai-generated content (aigc)">
  <data key="d5">18.0</data>
  <data key="d6">Yutong Dai provided analysis on the development of generative AI models.&lt;SEP&gt;Yutong Dai provided analysis on trends and future directions in generative AI.</data>
  <data key="d7">9</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Philip S Yu" target="A comprehensive survey of ai-generated content (aigc)">
  <data key="d5">18.0</data>
  <data key="d6">Philip S Yu contributed to the survey by discussing applications of generative AI.&lt;SEP&gt;Philip S Yu discussed applications and societal implications of AI-generated content.</data>
  <data key="d7">9</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Lichao Sun" target="A comprehensive survey of ai-generated content (aigc)">
  <data key="d5">18.0</data>
  <data key="d6">Lichao Sun helped review the history and future promises of generative AI.&lt;SEP&gt;Lichao Sun reviewed the promises and challenges of generative AI technologies.</data>
  <data key="d7">9</data>
  <data key="d8">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Dan Hendrycks" target="Activation Functions">
  <data key="d5">14.0</data>
  <data key="d6">Dan Hendrycks introduced GELUs, affecting neural network activation techniques.</data>
  <data key="d7">neural activation, GELUs</data>
  <data key="d8">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Cheng-Yu Hsieh" target="Model Distillation">
  <data key="d5">16.0</data>
  <data key="d6">Cheng-Yu Hsieh's research on distilling large models aims to outperform bigger models with less data.</data>
  <data key="d7">model distillation, efficiency</data>
  <data key="d8">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="phactor" target="Designs Chemical Reaction Arrays">
  <data key="d5">14.0</data>
  <data key="d6">phactor is used to systematically design chemical reaction arrays, often integrated with AI tools like ChatGPT for enhanced efficiency.</data>
  <data key="d7">software tool, experimental design</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="ChatGPT" target="Designs Chemical Reaction Arrays">
  <data key="d5">16.0</data>
  <data key="d6">ChatGPT supports the design of chemical reaction arrays by providing computational assistance and automating parts of the process.</data>
  <data key="d7">AI-assisted design, chemical engineering</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="ChatGPT" target="Jun-Jie Zhu et al.">
  <data key="d5">14.0</data>
  <data key="d6">They examined ChatGPT's applications in environmental research."|</data>
  <data key="d7">application</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Language Model Tuning" target="Unipelt">
  <data key="d5">16.0</data>
  <data key="d6">Unipelt provides a framework for parameter-efficient tuning of language models, improving their performance on specific tasks.</data>
  <data key="d7">model optimization, fine-tuning</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Pointer Sentinel Mixture Models" target="Neural Network">
  <data key="d5">14.0</data>
  <data key="d6">Pointer sentinel mixture models are a type of neural network architecture designed to improve language sequence modeling.</data>
  <data key="d7">model architecture, sequence prediction</data>
  <data key="d8">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Long Ouyang" target="Training language models to follow instructions with human feedback">
  <data key="d5">18.0</data>
  <data key="d6">Long Ouyang et al. (2022) conducted research on improving language models' ability to follow instructions via human feedback.&lt;SEP&gt;Long Ouyang et al. (2022) conducted research on methods to improve instruction-following capabilities of language models using human feedback.</data>
  <data key="d7">research activity, methodology</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Generative Agents" target="Generation of human-like behavior">
  <data key="d5">8.0</data>
  <data key="d6">Generative Agents are designed to simulate human behaviors and interactions for research and testing purposes.</data>
  <data key="d7">study design, application</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapterhub" target="Mad-x">
  <data key="d5">7.0</data>
  <data key="d6">Adapterhub provides the framework that supports Mad-x, an adapter-based approach for multi-task transfer learning.</data>
  <data key="d7">tool support, model framework</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hierarchical Domain-specific Language Models" target="Legal Decision Classification">
  <data key="d5">16.0</data>
  <data key="d6">Hierarchical domain-specific language models are applied to classify decisions in legal cases, leveraging hierarchical attention mechanisms.&lt;SEP&gt;These models are applied to classify decisions in legal cases with hierarchical domain knowledge and attention mechanisms.</data>
  <data key="d7">application, domain-specific modeling</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Bing Yin" target="Preprint arXiv:2109.05687">
  <data key="d5">14.0</data>
  <data key="d6">Bing Yin contributed to the research and development of semantic parsing models."|</data>
  <data key="d7">collaboration</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Jingfeng Yang" target="Preprint arXiv:2109.05687">
  <data key="d5">16.0</data>
  <data key="d6">Jingfeng Yang authored the preprint on semantic parsing models and methods."|</data>
  <data key="d7">authorship</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Haoming Jiang" target="Preprint arXiv:2109.05687">
  <data key="d5">14.0</data>
  <data key="d6">Haoming Jiang contributed to the research on semantic parsing and language models."|</data>
  <data key="d7">collaboration</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Qingyu Yin" target="Preprint arXiv:2109.05687">
  <data key="d5">12.0</data>
  <data key="d6">Qingyu Yin participated in the development of semantic parsing methodologies."|</data>
  <data key="d7">contribution</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Danqing Zhang" target="Preprint arXiv:2109.05687">
  <data key="d5">12.0</data>
  <data key="d6">Danqing Zhang worked on compositional semantic parsing techniques."|</data>
  <data key="d7">research activity</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Diyi Yang" target="Preprint arXiv:2109.05687">
  <data key="d5">12.0</data>
  <data key="d6">Diyi Yang was involved in semantic parsing research and survey analysis."|</data>
  <data key="d7">research activity</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Llama-adapter" target="Renrui Zhang et al.">
  <data key="d5">16.0</data>
  <data key="d6">They proposed Llama-adapter for efficient zero-init attention fine-tuning."|</data>
  <data key="d7">technique</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Least-to-Most Prompting" target="Denny Zhou et al.">
  <data key="d5">18.0</data>
  <data key="d6">They introduced least-to-most prompting for complex reasoning tasks."|</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="ChatGPT and environmental research" target="Environmental Science &amp; Technology">
  <data key="d5">16.0</data>
  <data key="d6">The journal publishes research exploring how ChatGPT can be utilized or impacts environmental science, indicating its relevance to the field.&lt;SEP&gt;The journal publishes research on the use of ChatGPT in environmental research, indicating the application of this technology in the field.</data>
  <data key="d7">application, research publication</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-tuning language models from human preferences" target="Daniel M Ziegler et al.">
  <data key="d5">14.0</data>
  <data key="d6">The research conducted by Daniel M Ziegler and colleagues includes the methodology of fine-tuning language models, which is relevant to ChatGPT's development.&lt;SEP&gt;The research team conducted studies and developed methodologies related to fine-tuning language models, which underpin ChatGPT's capabilities.</data>
  <data key="d7">research activity, methodology</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-tuning language models from human preferences" target="arXiv preprint arXiv:1909.08593">
  <data key="d5">12.0</data>
  <data key="d6">The preprint provides foundational evidence, detailed methodology, and experimental results supporting the approach of aligning language models with human preferences.&lt;SEP&gt;This preprint provides foundational evidence or background supporting the methodology of fine-tuning language models.</data>
  <data key="d7">evidence, foundational research</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="&lt;&quot;Task Planners" target="LLMs as Controllers">
  <data key="d5">8.0</data>
  <data key="d6">LLMs are conceptualized as controllers or API selectors that manage multiple tools to decompose and coordinate complex tasks.</data>
  <data key="d7">model coordination, task decomposition</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="&lt;&quot;Automated Theorem Proving Frameworks" target="DSP Framework">
  <data key="d5">9.0</data>
  <data key="d6">DSP uses LLMs and formal tools to draft, sketch, and prove mathematical conjectures, illustrating a multi-stage process.</data>
  <data key="d7">proof automation, formal reasoning</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs embodied in robots" target="Physics engines">
  <data key="d5">6.0</data>
  <data key="d6">Physics engines provide simulated physical environments that grounded LLM reasoning can utilize for physics-based tasks.</data>
  <data key="d7">grounded physics, simulation</data>
  <data key="d8">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LoRA" target="DyLora">
  <data key="d5">6.0</data>
  <data key="d6">DyLora enhances LoRA by using dynamic search to find optimal rank and block size, improving adaptation performance.</data>
  <data key="d7">optimization, performance</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="High-Confidence Answers" target="Improving Reasoning">
  <data key="d5">8.0</data>
  <data key="d6">Generating high-confidence, rationale-augmented answers enhances the model's reasoning abilities without relying on ground truth labels.</data>
  <data key="d7">performance improvement, reasoning</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application in Natural Sciences" target="Biomedicine">
  <data key="d5">9.0</data>
  <data key="d6">LLMs are applied in biomedicine for analyzing genomic data, predicting protein structures, and supporting drug discovery."|&gt;"domain application, biomedical research</data>
  <data key="d7">9</data>
  <data key="d8">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application in Formal Sciences" target="Software Engineering">
  <data key="d5">8.0</data>
  <data key="d6">LLMs assist in code generation, bug detection, and analysis, enhancing productivity and accuracy."|&gt;"technical application, software development</data>
  <data key="d7">8</data>
  <data key="d8">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Human-Computer Interaction and Software Engineering" target="Specialization">
  <data key="d5">16.0</data>
  <data key="d6">LLMs are specialized to improve understanding of user inputs and assist in code-related tasks, enhancing software development.</data>
  <data key="d7">domain-specific AI, software tools</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="DIN-SQL" target="Self-Correction">
  <data key="d5">16.0</data>
  <data key="d6">DIN-SQL employs self-correction techniques to enhance text-to-SQL performance in in-context learning scenarios.&lt;SEP&gt;DIN-SQL employs self-correction techniques to improve the accuracy of text-to-SQL translation in in-context learning.</data>
  <data key="d7">methodology, application</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="GrIPS" target="Prompt Search">
  <data key="d5">18.0</data>
  <data key="d6">GrIPS is used for searching effective prompts in instruction tuning, improving prompt engineering processes.&lt;SEP&gt;GrIPS is used to identify effective prompts for instruction tuning and prompt engineering.</data>
  <data key="d7">technique, optimization</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Chain of Thought Prompting" target="Zhuosheng Zhang et al.">
  <data key="d5">18.0</data>
  <data key="d6">They developed automatic chain of thought prompting to improve reasoning in large language models."|</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Survey" target="Wayne Xin Zhao et al.">
  <data key="d5">16.0</data>
  <data key="d6">They conducted a survey summarizing the state of large language models as of 2023."|</data>
  <data key="d7">study</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Codex" target="Python Code-Writing Capabilities">
  <data key="d5">9.0</data>
  <data key="d6">Codex's primary function is to generate Python code from natural language descriptions, demonstrating its coding proficiency and limitations.</data>
  <data key="d7">code generation, evaluation</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="HumanEval">
  <data key="d5">8.0</data>
  <data key="d6">The HumanEval dataset is used to measure the functional correctness of Codex's generated code, with Codex solving 28.8% of problems.</data>
  <data key="d7">evaluation, performance</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="Repeated Sampling">
  <data key="d5">10.0</data>
  <data key="d6">Repeated sampling from Codex enhances the chance of producing correct solutions, solving 70.2% of problems with 100 samples per problem.</data>
  <data key="d7">sampling strategy, performance improvement</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="GPT models">
  <data key="d5">20.0</data>
  <data key="d6">Codex is a fine-tuned GPT model optimized for code generation, building upon the GPT-3 architecture.&lt;SEP&gt;Codex is a fine-tuned version of GPT-3, specifically adapted for code generation, leveraging the GPT architecture.</data>
  <data key="d7">model development, specialization&lt;SEP&gt;model specialization, fine-tuning</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="Training Dataset">
  <data key="d5">18.0</data>
  <data key="d6">The large GitHub Python code dataset is used to train and fine-tune Codex, enabling it to generate relevant, high-quality code snippets.&lt;SEP&gt;The training dataset of GitHub Python code is used to train and fine-tune Codex, enabling it to generate relevant code snippets.</data>
  <data key="d7">training data, dataset source</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="Bias in Text Output">
  <data key="d5">8.0</data>
  <data key="d6">Codex tends to produce biased terms similar to GPT-3, but with less diversity, especially when prompted explicitly.</data>
  <data key="d7">bias output, language model behavior</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="Malicious Code Generation">
  <data key="d5">7.0</data>
  <data key="d6">Codex can generate code snippets that could be incorporated into malicious systems, although it is not highly proficient at standalone malicious code.</data>
  <data key="d7">code generation, security risk</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="Vulnerability Discovery">
  <data key="d5">6.0</data>
  <data key="d6">Codex's current performance in discovering vulnerabilities is limited compared to specialized tools, but future models may improve in detecting complex security flaws.</data>
  <data key="d7">security analysis, model capability</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="Supply Chain Attack">
  <data key="d5">9.0</data>
  <data key="d6">Codex may suggest malicious or vulnerable dependencies, which could be exploited in supply chain attacks, especially if prompted with misspelled or malicious package names.</data>
  <data key="d7">software supply chain, dependency risk</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="security standards">
  <data key="d5">6.0</data>
  <data key="d6">Codex's tendency to produce insecure cryptographic configurations suggests a need to evaluate and improve AI safety and security standards.</data>
  <data key="d7">AI safety, cryptography, security standards</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="insecurity">
  <data key="d5">9.0</data>
  <data key="d6">Codex produces cryptographic configurations that are insecure, such as RSA keys shorter than 2048 bits and AES in ECB mode.</data>
  <data key="d7">AI, cryptography, security vulnerabilities</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="Biases in Training Data">
  <data key="d5">8.0</data>
  <data key="d6">Training data biases influence Codex's suggestions, potentially reinforcing existing market preferences and propagating deprecated methods.</data>
  <data key="d7">bias propagation, influence</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="Decision-Making Tool">
  <data key="d5">9.0</data>
  <data key="d6">Codex functions as a decision-making tool by providing suggestions on machine learning packages and coding approaches.</data>
  <data key="d7">decision support, influence</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="Search Engine">
  <data key="d5">8.0</data>
  <data key="d6">Users may use Codex as a search engine to find information about machine learning packages and coding solutions, replacing traditional search methods.</data>
  <data key="d7">search, information retrieval</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="Machine Learning Packages">
  <data key="d5">9.0</data>
  <data key="d6">Codex suggests machine learning packages like TensorFlow and PyTorch based on prompts, influencing user choices and package prominence.</data>
  <data key="d7">suggestions, influence</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="HumanEval dataset" target="Large Language Models trained on code">
  <data key="d5">16.0</data>
  <data key="d6">Models like Codex are evaluated on the HumanEval dataset to determine their ability to solve programming problems, assessing reasoning and correctness.&lt;SEP&gt;Models like Codex are evaluated on the HumanEval dataset to measure their ability to solve programming problems, assessing reasoning and comprehension.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="pass@k metric" target="Code datasets">
  <data key="d5">9.0</data>
  <data key="d6">The pass@k metric evaluates generated code by measuring the pass rate of unit tests across multiple samples, emphasizing functional correctness.</data>
  <data key="d7">evaluation, correctness</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="pass@k metric" target="functional correctness">
  <data key="d5">16.0</data>
  <data key="d6">The pass@k metric is used to evaluate the functional correctness of code by measuring the proportion of problems solved with at least one passing sample, directly reflecting the model's problem-solving ability.&lt;SEP&gt;The pass@k metric measures the likelihood that at least one generated code sample passes unit tests, directly assessing the model's problem-solving accuracy.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="unit tests" target="Code samples">
  <data key="d5">9.0</data>
  <data key="d6">Unit tests are used to automatically evaluate the correctness of generated code, serving as a key metric in model evaluation.</data>
  <data key="d7">evaluation method, correctness</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="unit tests" target="test-driven development">
  <data key="d5">18.0</data>
  <data key="d6">Test-driven development relies on unit tests to define requirements and validate code, making unit tests a fundamental component of this methodology.&lt;SEP&gt;Test-driven development relies on unit tests to specify requirements and validate code correctness, making unit tests essential components of this methodology.</data>
  <data key="d7">9</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="functional correctness" target="test suite">
  <data key="d5">17.0</data>
  <data key="d6">Functional correctness is a key measure, often more meaningful than exact match, for assessing if code works as intended.&lt;SEP&gt;Functional correctness is a primary measure of whether generated code performs its intended function, often more meaningful than exact match.</data>
  <data key="d7">evaluation, correctness</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Large Language Models trained on code" target="Code2Vec">
  <data key="d5">14.0</data>
  <data key="d6">Code2Vec is a tool that creates distributed representations of code, which can be used to evaluate or improve LLMs trained on programming data.</data>
  <data key="d7">code embedding, model evaluation</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="sandbox environment" target="gVisor container runtime">
  <data key="d5">20.0</data>
  <data key="d6">The sandbox environment employs gVisor to securely execute untrusted generated code, preventing malicious activities and ensuring safety.&lt;SEP&gt;The sandbox environment employs gVisor to securely execute untrusted generated programs, preventing malicious activities and ensuring safety.</data>
  <data key="d7">10</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="evaluation of code models" target="metrics and datasets">
  <data key="d5">16.0</data>
  <data key="d6">Evaluation involves metrics like pass@k and datasets like HumanEval to measure code correctness and model performance.&lt;SEP&gt;The evaluation involves metrics like pass@k, BLEU scores, and datasets like HumanEval to assess model accuracy and reliability.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Adam optimizer" target="Training Methods">
  <data key="d5">14.0</data>
  <data key="d6">The Adam optimizer is employed to train Codex, with hyperparameters tuned for effective convergence.&lt;SEP&gt;The Adam optimizer is used to train Codex, with specific hyperparameters influencing convergence and training efficiency.</data>
  <data key="d7">optimization, training hyperparameters</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Fine-tuning Methods" target="Model Development">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning involves strategies like data filtering, tokenizer adjustments, and training protocols to improve code generation.&lt;SEP&gt;Strategies such as data filtering, tokenizer modifications, and training protocols are used to enhance Codex's code generation capabilities.</data>
  <data key="d7">training strategies, data preparation&lt;SEP&gt;training strategy, dataset preparation</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tokenization" target="Words">
  <data key="d5">9.0</data>
  <data key="d6">Tokenization is the process used to split the string into individual words for further analysis."|</data>
  <data key="d7">text preprocessing, NLP techniques</data>
  <data key="d8">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Language Modeling" target="Sample Selection">
  <data key="d5">8.0</data>
  <data key="d6">Sample selection techniques are based on heuristics like log probability to improve evaluation outcomes in language modeling.</data>
  <data key="d7">evaluation methodology, heuristics</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Language Modeling" target="GPT-Neo">
  <data key="d5">16.0</data>
  <data key="d6">GPT-Neo is a large-scale autoregressive language model used for NLP tasks, demonstrating transformer-based architecture and training techniques.&lt;SEP&gt;GPT-Neo is a large-scale autoregressive language model used for natural language processing tasks, demonstrating the application of transformer architectures.</data>
  <data key="d7">Tools, Applications/Implications</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Sample Selection" target="Log-Probability">
  <data key="d5">7.0</data>
  <data key="d6">Higher mean log probability scores are used to select better samples, impacting the evaluation of language models.</data>
  <data key="d7">sample quality, evaluation impact</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Temperature" target="Generated Solutions">
  <data key="d5">13.0</data>
  <data key="d6">Adjusting the temperature influences the diversity and correctness of solutions produced by the model."|&lt;SEP&gt;Adjusting the temperature parameter influences the diversity and correctness of solutions generated by the model.</data>
  <data key="d7">7&lt;SEP&gt;sampling, diversity</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Temperature" target="Sampling Methods">
  <data key="d5">6.0</data>
  <data key="d6">Temperature adjusts the randomness of token sampling, affecting the model's confidence and diversity of generated text.</data>
  <data key="d7">parameter control, randomness</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Temperature" target="Sampling Techniques">
  <data key="d5">7.0</data>
  <data key="d6">Temperature controls the randomness of token selection, affecting the diversity and confidence of generated text.</data>
  <data key="d7">parameter control, diversity</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Problems from Continuous Integration" target="Unit Tests">
  <data key="d5">7.0</data>
  <data key="d6">Problems curated from CI environments are used to generate and validate programming exercises, ensuring relevance and quality.</data>
  <data key="d7">problem curation, validation</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Unit Tests" target="sys.setprofile">
  <data key="d5">8.0</data>
  <data key="d6">sys.setprofile is used to trace function calls and collect inputs and outputs, which are then used to create unit tests for code validation.</data>
  <data key="d7">tracing, data collection</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Filtering Problems" target="Validation">
  <data key="d5">8.0</data>
  <data key="d6">Problems are filtered by testing generated samples against unit tests to remove ambiguous or non-deterministic problems, ensuring high-quality datasets.</data>
  <data key="d7">quality control, validation</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Sandboxed Environment" target="Function Testing">
  <data key="d5">8.0</data>
  <data key="d6">Running code in a sandbox ensures safe execution of untrusted code during testing and problem validation.</data>
  <data key="d7">security, testing</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Unit Testing" target="Problems from Examples">
  <data key="d5">7.0</data>
  <data key="d6">Unit testing is used to verify solutions derived from example problems, ensuring correctness and facilitating problem creation."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Total Problems Curated" target="Problems from Examples">
  <data key="d5">6.0</data>
  <data key="d6">Curated problems are used as the primary dataset for training and evaluating models."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Build and Test Commands" target="Virtual Environments">
  <data key="d5">8.0</data>
  <data key="d6">Build and test commands in CI configuration set up virtual environments and dependencies to execute tests in isolated, controlled setups."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Build and Test Commands" target="CI Frameworks">
  <data key="d5">7.0</data>
  <data key="d6">Commands automate the process of building environments and running tests during continuous integration."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Virtual Environments" target="Dependencies">
  <data key="d5">8.0</data>
  <data key="d6">Virtual environments contain dependencies needed for code execution and testing, ensuring consistent and isolated setups."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Filtering" target="Problems from Examples">
  <data key="d5">8.0</data>
  <data key="d6">Problems are filtered based on whether generated solutions pass unit tests, ensuring quality and reducing ambiguity."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Generated Samples" target="Validation">
  <data key="d5">9.0</data>
  <data key="d6">Generated code samples are tested against unit tests to verify correctness, informing problem filtering."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Validation" target="Solutions">
  <data key="d5">8.0</data>
  <data key="d6">Solutions are validated by passing them through unit tests to determine correctness and suitability for training datasets."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="sample selection heuristics" target="Models use heuristics like mean log probability or back-translation to select the best samples, impacting the overall success rate.">
  <data key="d5">6.0</data>
  <data key="d6">sample ranking, model optimization</data>
  <data key="d7">6</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="sample selection heuristics" target="Models use heuristics like mean log probability or back-translation to rank and select the best samples, impacting overall success rates.">
  <data key="d5">7.0</data>
  <data key="d6">sample ranking, model optimization</data>
  <data key="d7">7</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex-D" target="manual grading">
  <data key="d5">28.0</data>
  <data key="d6">Codex-D's generated docstrings are evaluated manually to determine correctness, as automatic evaluation metrics are lacking.&lt;SEP&gt;Generated docstrings are evaluated manually to determine correctness, compensating for the lack of automatic evaluation metrics.&lt;SEP&gt;Manual grading is used to evaluate the correctness of generated docstrings, which cannot be automatically assessed.</data>
  <data key="d7">evaluation method, quality assessment&lt;SEP&gt;evaluation method, quality control</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="back-translation" target="sample ranking">
  <data key="d5">6.0</data>
  <data key="d6">Back-translation is used as a technique to evaluate and rank generated samples based on their fidelity to the original code or problem.</data>
  <data key="d7">evaluation technique, sample selection</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="training problems" target="Codex and Codex-D">
  <data key="d5">9.0</data>
  <data key="d6">Training problems serve as the primary data for training models in code generation and docstring creation, containing function signatures, solutions, and annotations.</data>
  <data key="d7">training data, model training</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="performance margins" target="Models like Codex-S outperform Codex on pass@k metrics, with margins indicating the degree of improvement.">
  <data key="d5">8.0</data>
  <data key="d6">performance comparison, model effectiveness</data>
  <data key="d7">8</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="performance margins" target="Comparison">
  <data key="d5">8.0</data>
  <data key="d6">Performance margins quantify the difference in success metrics like pass@k between models, indicating relative improvements.</data>
  <data key="d7">performance evaluation, model comparison</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="performance comparison" target="Codex-S shows improved performance metrics over Codex, especially on pass@1 and pass@100.">
  <data key="d5">8.0</data>
  <data key="d6">model comparison, performance metrics</data>
  <data key="d7">8</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="model limitations" target="broader impacts">
  <data key="d5">16.0</data>
  <data key="d6">Understanding the broader impacts involves recognizing current model limitations and potential improvements.&lt;SEP&gt;Understanding the broader impacts involves recognizing current model limitations, potential societal effects, and avenues for improvement.</data>
  <data key="d7">impacts, limitations</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="risk mitigation" target="human oversight">
  <data key="d5">18.0</data>
  <data key="d6">Human oversight is essential for mitigating risks like insecure code and over-reliance, especially for less experienced users.</data>
  <data key="d7">monitoring, safety assurance</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="automation bias" target="users">
  <data key="d5">14.0</data>
  <data key="d6">Automation bias leads users to overly trust generated outputs, which can compromise safety and correctness.</data>
  <data key="d7">user behavior, trust in automation</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="empirical investigation" target="study designs">
  <data key="d5">16.0</data>
  <data key="d6">Empirical investigations are necessary to identify effective strategies for ensuring vigilance and safety in real-world applications.</data>
  <data key="d7">data collection, safety improvement</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="safety implications" target="applications/implications">
  <data key="d5">18.0</data>
  <data key="d6">Understanding safety implications guides responsible deployment and mitigation efforts to prevent harm.</data>
  <data key="d7">risk management, societal impact</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="societally beneﬁcial direction" target="applications/implications">
  <data key="d5">20.0</data>
  <data key="d6">Research aims to steer code generation towards societal benefits by addressing safety risks and promoting responsible AI use.</data>
  <data key="d7">ethical AI, societal impact</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation Models" target="Bias and Representation Issues">
  <data key="d5">8.0</data>
  <data key="d6">Code generation models tend to reflect societal stereotypes present in training data, raising safety and fairness concerns.</data>
  <data key="d7">bias, societal stereotypes</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias and Representation Issues" target="Filtration or Modulation">
  <data key="d5">15.0</data>
  <data key="d6">Applying filtering and documentation can help mitigate biases and reduce associated risks in generated code.&lt;SEP&gt;Applying filtering and intervention techniques can help mitigate societal biases and safety risks in generated code.</data>
  <data key="d7">bias mitigation, safety&lt;SEP&gt;mitigation, safety</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Economic and Labor Market Impacts" target="Software-Related Labor Markets">
  <data key="d5">8.0</data>
  <data key="d6">Advancements in code generation could influence labor demand and productivity, potentially altering the software industry landscape over time.</data>
  <data key="d7">labor market, productivity</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Security Implications" target="Malware Development">
  <data key="d5">7.0</data>
  <data key="d6">Code generation models can be exploited to develop malware, though current models do not significantly lower barriers to malicious code creation.</data>
  <data key="d7">cybersecurity, malicious code</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Security Implications" target="Model Capabilities">
  <data key="d5">16.0</data>
  <data key="d6">Advancements in model security could reduce vulnerabilities, while increased capabilities might enable more sophisticated malicious code.&lt;SEP&gt;Improvements in model security and robustness could reduce vulnerabilities, but future models may also enhance malicious capabilities.</data>
  <data key="d7">model security, malicious capabilities&lt;SEP&gt;security, model development</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Environmental Impacts" target="Compute Resources">
  <data key="d5">17.0</data>
  <data key="d6">Training and inference of large models consume significant energy, impacting environmental sustainability, though renewable energy sources can mitigate this.&lt;SEP&gt;Training and inference of large models consume significant energy, impacting environmental sustainability, though renewable sources can mitigate this.</data>
  <data key="d7">energy consumption, environmental impact&lt;SEP&gt;energy use, environmental impact</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Cybercrime" target="Malware">
  <data key="d5">7.0</data>
  <data key="d6">Malware development can be facilitated or complicated by AI-generated code, influencing cybercrime activities.</data>
  <data key="d7">cybercrime, malware</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Malware" target="Threat Actors">
  <data key="d5">8.0</data>
  <data key="d6">Threat actors may utilize Codex to assist in developing malware, leveraging its code generation abilities.</data>
  <data key="d7">malicious use, cybersecurity threat</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Neural Program Interpreter" target="Program Synthesis">
  <data key="d5">16.0</data>
  <data key="d6">Reed &amp; de Freitas (2016), Shin et al. (2018), and Pierrot et al. (2021) develop models like the Neural Program Interpreter, which are used for program induction and synthesis."|</data>
  <data key="d7">Methodologies, Theories/Models, Study Designs, Analytical Techniques, Applications/Implications</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Probabilistic Context-Free Grammar (PCFG)" target="Object of Study">
  <data key="d5">12.0</data>
  <data key="d6">A classical formalism used to generate program syntax trees in program synthesis."|</data>
  <data key="d7">Methodologies, Objects of Study, Results</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Hindle et al., 2012" target="Study">
  <data key="d5">10.0</data>
  <data key="d6">Found code more predictable than natural language using n-gram language models."|</data>
  <data key="d7">Study Designs, Results</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Ling et al., 2016" target="Study">
  <data key="d5">12.0</data>
  <data key="d6">Developed Hearthstone dataset involving game-related code for neural program learning."|</data>
  <data key="d7">Study, Study Populations/Dataset</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Feng et al., 2020" target="Study">
  <data key="d5">16.0</data>
  <data key="d6">Introduced CodeBERT, demonstrating its effectiveness for code search."|</data>
  <data key="d7">Study, Tools</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Devlin et al., 2017" target="Study">
  <data key="d5">16.0</data>
  <data key="d6">Showed that synthesizing multiple code samples through beam search improves functional correctness."|</data>
  <data key="d7">Study, Methodologies</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Lachaux et al., 2020" target="Study">
  <data key="d5">16.0</data>
  <data key="d6">Developed TransCoder for language translation, emphasizing functional correctness."|</data>
  <data key="d7">Study, Tools</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Jain et al., 2020" target="Study">
  <data key="d5">16.0</data>
  <data key="d6">Proposed ContraCode, leveraging the space of functionally correct programs to enhance model performance."|</data>
  <data key="d7">Study, Tools</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Hendrycks et al., 2021" target="Study">
  <data key="d5">34.0</data>
  <data key="d6">Created APPS benchmark for evaluating code generation based on competitive programming problems."|&lt;SEP&gt;Developed APPS benchmark for functional correctness evaluation."|</data>
  <data key="d7">Study, Analytical Techniques&lt;SEP&gt;Study, Applications/Implications</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Gulwani, 2011; Gulwani et al., 2012" target="Study">
  <data key="d5">14.0</data>
  <data key="d6">Early datasets like FlashFill used to benchmark neural code synthesis, focusing on string transformations."|</data>
  <data key="d7">Study, Study Populations/Dataset</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Barone &amp; Sennrich, 2017" target="Study">
  <data key="d5">16.0</data>
  <data key="d6">Compiled large datasets of Python code from GitHub for training neural models."|</data>
  <data key="d7">Study, Study Populations/Dataset</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Husain et al., 2019" target="Study">
  <data key="d5">18.0</data>
  <data key="d6">Built CodeSearchNet, a large corpus for code understanding across multiple languages."|</data>
  <data key="d7">Study, Study Populations/Dataset</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Lu et al., 2021" target="Study">
  <data key="d5">18.0</data>
  <data key="d6">Introduced CodeXGLUE, a benchmark suite with multiple code tasks."|</data>
  <data key="d7">Study, Study Populations/Dataset</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Ren et al., 2020" target="Study">
  <data key="d5">16.0</data>
  <data key="d6">Proposed CodeBLEU, a metric for evaluating code generation quality."|</data>
  <data key="d7">Study, Analytical Techniques</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Tufano et al., 2020" target="Study">
  <data key="d5">14.0</data>
  <data key="d6">Applied Transformers to generate unit tests, outperforming some commercial tools."|</data>
  <data key="d7">Study, Applications/Implications</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Aye et al., 2021" target="Study">
  <data key="d5">14.0</data>
  <data key="d6">Built an auto-complete tool at Facebook, improved by training on user data."|</data>
  <data key="d7">Study, Applications/Implications</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Agrawal et al., 1995" target="Study">
  <data key="d5">10.0</data>
  <data key="d6">Early static code analysis for bug detection."|</data>
  <data key="d7">Study, Methodologies</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Korel &amp; Rilling, 1997" target="Study">
  <data key="d5">10.0</data>
  <data key="d6">Dynamic analysis techniques for debugging code."|</data>
  <data key="d7">Study, Methodologies</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Korel &amp; Rilling, 1997" target="learned association rules">
  <data key="d5">7.0</data>
  <data key="d6">Korel &amp; Rilling, 1997" is a foundational reference to association rule methods applied in debugging contexts, establishing the basis for later techniques.</data>
  <data key="d7">reference, foundation</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Jeffrey et al., 2009" target="Study">
  <data key="d5">10.0</data>
  <data key="d6">Learned association rules for bug localization."|</data>
  <data key="d7">Study, Methodologies</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Goues et al., 2012" target="Study">
  <data key="d5">12.0</data>
  <data key="d6">Applied genetic programming for automatic bug fixing."|</data>
  <data key="d7">Study, Methodologies</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="learned association rules" target="test suite">
  <data key="d5">15.0</data>
  <data key="d6">Association rules are used to evaluate code correctness and detect problems in execution traces during debugging.&lt;SEP&gt;Association rules are used to evaluate code suggestions and detect issues during debugging by analyzing patterns in test results and execution traces.</data>
  <data key="d7">application, debugging&lt;SEP&gt;application, evaluation</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="genetic programming" target="test suite">
  <data key="d5">13.0</data>
  <data key="d6">Genetic programming approaches rely on test suites to evaluate the correctness of generated code fixes.&lt;SEP&gt;Genetic programming relies on test suites to evaluate whether generated code fixes are correct and functional.</data>
  <data key="d7">evaluation, correctness</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="test suite" target="human developers">
  <data key="d5">7.0</data>
  <data key="d6">Developers design targeted test suites with limited coverage, which may impact the effectiveness of bug detection and code evaluation.</data>
  <data key="d7">testing practices, evaluation</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="neural machine translation" target="buggy to correct programs">
  <data key="d5">16.0</data>
  <data key="d6">Models treat bug fixing as translating buggy code into correct code, assessing performance via code translation accuracy.&lt;SEP&gt;Models treat bug fixing as translating buggy code into correct code, with performance measured by translation accuracy and functional correctness.</data>
  <data key="d7">modeling, translation</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="exact match" target="reference">
  <data key="d5">17.0</data>
  <data key="d6">Exact match evaluation compares generated code against reference solutions to measure similarity and correctness.&lt;SEP&gt;Exact match metrics compare generated code to reference solutions to assess similarity, but may not fully capture functional correctness.</data>
  <data key="d7">evaluation, metrics</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="human developers" target="test suites">
  <data key="d5">7.0</data>
  <data key="d6">Developers create targeted test suites that may have limited coverage, impacting bug detection effectiveness.</data>
  <data key="d7">testing practices, evaluation</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="large language models" target="fine-tuning GPT">
  <data key="d5">16.0</data>
  <data key="d6">Models are fine-tuned on code datasets to enhance their ability to generate functionally correct code.&lt;SEP&gt;Models are fine-tuned on code datasets to improve their ability to generate functionally correct and contextually appropriate code.</data>
  <data key="d7">training, model development</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="distribution" target="evaluation set">
  <data key="d5">12.0</data>
  <data key="d6">Training on data distributions similar to evaluation datasets enhances model performance and generalization.&lt;SEP&gt;Training on data distributions similar to evaluation sets improves model performance.</data>
  <data key="d7">training data, evaluation</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="The Pile" target="Language Model Dataset">
  <data key="d5">18.0</data>
  <data key="d6">A comprehensive dataset used for training and benchmarking large language models, supporting diversity and robustness.&lt;SEP&gt;The Pile is a large, diverse dataset utilized for training and benchmarking language models, contributing to their generalization capabilities.</data>
  <data key="d7">Objects of Study, Applications/Implications</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Sourcefinder" target="Malware Source Code">
  <data key="d5">9.0</data>
  <data key="d6">Sourcefinder is used to find malware source code in repositories like GitHub.</data>
  <data key="d7">tool application, malware analysis</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Sourcefinder" target="Malware Source-Code">
  <data key="d5">9.0</data>
  <data key="d6">Sourcefinder is used to identify malware source code within repositories like GitHub.</data>
  <data key="d7">tool application, cybersecurity</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Biological Structure and Function" target="Scaling Unsupervised Learning">
  <data key="d5">8.0</data>
  <data key="d6">Scaling unsupervised learning to large protein datasets reveals insights into biological structure and function.</data>
  <data key="d7">application, biological modeling</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Neural Program Synthesis" target="Poisoning Vulnerabilities">
  <data key="d5">7.0</data>
  <data key="d6">Poisoning attacks threaten neural program synthesis systems by introducing vulnerabilities.</data>
  <data key="d7">security, neural models</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Neural Program Synthesis" target="Inferred Execution Traces">
  <data key="d5">16.0</data>
  <data key="d6">Inferred execution traces are used to improve the accuracy and reliability of neural program synthesis models.&lt;SEP&gt;Inferred execution traces improve the accuracy of neural program synthesis models.</data>
  <data key="d7">methodology, performance&lt;SEP&gt;methodology, performance enhancement</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Learning Bug-Fixing Patches" target="Neural Machine Translation">
  <data key="d5">16.0</data>
  <data key="d6">Neural machine translation can be employed to learn bug-fixing patches from real-world data.&lt;SEP&gt;Neural machine translation models can learn to produce bug-fixing patches from real-world code data.</data>
  <data key="d7">methodology, software engineering</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="GPT-J-6B" target="Code Generation from Natural Language">
  <data key="d5">18.0</data>
  <data key="d6">GPT-J-6B is a large language model used for code generation tasks from natural language prompts.&lt;SEP&gt;GPT-J-6B is a large language model used to generate code from natural language prompts.</data>
  <data key="d7">tool, application</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation from Natural Language" target="Research Challenges">
  <data key="d5">16.0</data>
  <data key="d6">Identifies promise and challenges in using AI models for code generation from natural language.&lt;SEP&gt;Identifies the promise and challenges of AI-driven code generation from natural language descriptions.</data>
  <data key="d7">application, research gap</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Poisoning Attacks" target="Neural Code Completion">
  <data key="d5">7.0</data>
  <data key="d6">Poisoning attacks exploit vulnerabilities in neural code completion systems, revealing security risks.</data>
  <data key="d7">security, neural models</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Words in String" target="Words">
  <data key="d5">9.0</data>
  <data key="d6">The phrase 'words in the string' indicates that the string contains multiple words that can be extracted for analysis."|</data>
  <data key="d7">text segmentation, linguistic units</data>
  <data key="d8">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Words" target="Text Analysis">
  <data key="d5">8.0</data>
  <data key="d6">Text analysis involves examining the extracted words to understand language structure and meaning."|</data>
  <data key="d7">linguistic analysis, data processing</data>
  <data key="d8">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="y" target="vowels_count">
  <data key="d5">16.0</data>
  <data key="d6">The function considers 'y' as a vowel only when it appears at the end of a word, demonstrating its contextual role.&lt;SEP&gt;The function counts 'y' as a vowel only when it appears at the end of a word, demonstrating the contextual rule for 'y'.</data>
  <data key="d7">linguistic rule, contextual classification</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="y" target="language rules">
  <data key="d5">10.0</data>
  <data key="d6">The rule that 'y' is a vowel only at the end of words reflects phonetic and linguistic classification.</data>
  <data key="d7">linguistics, phonetics</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="vowels_count" target="vowels">
  <data key="d5">14.0</data>
  <data key="d6">The counting function uses the set of vowels to determine if a character is a vowel, including 'a', 'e', 'i', 'o', 'u', and 'y' at the end of words.&lt;SEP&gt;The function uses a set of vowels to identify vowels in the string, including 'a', 'e', 'i', 'o', 'u', and 'y' at the end.</data>
  <data key="d7">vowel set, membership testing</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="vowels_count" target="string processing">
  <data key="d5">9.0</data>
  <data key="d6">The function employs string iteration and conditional logic to analyze and count vowels in text data.</data>
  <data key="d7">text analysis, computational linguistics</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="examples" target="The examples illustrate how the function counts vowels in different strings, showing the application of the linguistic rule for 'y'.">
  <data key="d5">6.0</data>
  <data key="d6">demonstration, function behavior</data>
  <data key="d7">6</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="examples" target="The sample inputs show how the function counts vowels, illustrating the application of the rule for 'y'.">
  <data key="d5">6.0</data>
  <data key="d6">demonstration, function behavior</data>
  <data key="d7">6</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="High-level specifications" target="Lower-level specifications">
  <data key="d5">14.0</data>
  <data key="d6">High-level specifications often require implicit derivation of lower-level details, increasing complexity and ambiguity in synthesis processes."|&lt;"specification abstraction, complexity&lt;SEP&gt;Higher-level specifications require implicit derivation of lower-level details, increasing complexity and ambiguity in synthesis.</data>
  <data key="d7">7&lt;SEP&gt;specification abstraction, complexity</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="alignment evaluations" target="Codex models">
  <data key="d5">16.0</data>
  <data key="d6">The alignment evaluations are conducted on Codex models to assess their ability to generate correct, safe code and follow instructions.</data>
  <data key="d7">evaluation, model performance</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex models" target="human feedback">
  <data key="d5">14.0</data>
  <data key="d6">Human feedback is used to guide and improve the alignment of Codex models by providing data on code correctness and helpfulness.</data>
  <data key="d7">training, supervision</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex models" target="RL from Human Feedback (RLHF)">
  <data key="d5">20.0</data>
  <data key="d6">RLHF</data>
  <data key="d7">Reinforcement Learning from Human Feedback is applied to Codex models to enhance their alignment by using human judgments as reward signals.</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex models" target="metrics for alignment">
  <data key="d5">16.0</data>
  <data key="d6">Metrics for alignment are used to quantitatively evaluate how well Codex models follow instructions and avoid bugs.</data>
  <data key="d7">evaluation metrics, performance assessment</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex models" target="transparency tools">
  <data key="d5">14.0</data>
  <data key="d6">Transparency tools</data>
  <data key="d7">Transparency tools are employed to understand model behavior and assess whether Codex models are aligned with safety and correctness standards.</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex models" target="model robustness">
  <data key="d5">7.0</data>
  <data key="d6">Model robustness</data>
  <data key="d7">Model robustness is crucial for ensuring that Codex models perform reliably across diverse inputs and scenarios, impacting their safety and alignment.</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Entity Recognition" target="Relationship Extraction">
  <data key="d5">9.0</data>
  <data key="d6">Entity recognition is a prerequisite for relationship extraction, as it identifies the entities that are then analyzed for potential links."|&gt;"Process dependency, sequential</data>
  <data key="d7">9</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Entity" target="Relationship">
  <data key="d5">10.0</data>
  <data key="d6">Entities are connected through relationships that describe how they interact or are associated within the text."|&gt;"conceptual link, interaction</data>
  <data key="d7">10</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Content Keywords" target="">
  <data key="d5">10.0</data>
  <data key="d6">The document emphasizes systematic extraction, NLP tools, analytical techniques, and the importance of structured analysis of text data.</data>
  <data key="d7">10</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="planet2" target="planet_names">
  <data key="d5">12.0</data>
  <data key="d6">planet2 is used as part of a list in code to reference or manipulate planet data, specifically as the endpoint in a slice operation."|&lt;SEP&gt;planet2 is used as part of the list in code to reference or manipulate planet data, specifically as the endpoint in a slice operation."|</data>
  <data key="d7">reference to data structure</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="planet_names" target="planet1_index">
  <data key="d5">14.0</data>
  <data key="d6">planet1_index is an index used to access a specific element in the planet_names list, indicating position of the first planet."|&lt;SEP&gt;planet1_index is used as an index to access the first planet's name in the list, indicating position of the first planet."|</data>
  <data key="d7">indexing</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="planet_names" target="planet2_index">
  <data key="d5">14.0</data>
  <data key="d6">planet2_index is an index used to access a specific element in the planet_names list, indicating position of the second planet."|&lt;SEP&gt;planet2_index is used as an index to access the second planet's name in the list, indicating position of the second planet."|</data>
  <data key="d7">indexing</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="anti_shuffle" target="s">
  <data key="d5">16.0</data>
  <data key="d6">The anti_shuffle function processes a string by sorting characters within each word, producing an ordered version while maintaining word order and spaces."|&lt;SEP&gt;The function anti_shuffle processes a string s by sorting characters within each word to produce an ordered version, maintaining original word order and spaces."|</data>
  <data key="d7">function behavior, string processing</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="count_up_to" target="prime numbers">
  <data key="d5">16.0</data>
  <data key="d6">The count_up_to function generates a list of prime numbers less than n, demonstrating prime number computation and list generation."|&lt;SEP&gt;The function count_up_to generates a list of prime numbers less than n, illustrating number theory and prime checking algorithms."|</data>
  <data key="d7">mathematical computation&lt;SEP&gt;mathematical computation, number theory</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="smallest_change" target="palindromic array">
  <data key="d5">18.0</data>
  <data key="d6">The smallest_change function determines the minimal number of element modifications needed to convert an array into a palindrome, relevant to array manipulation and symmetry."|&lt;SEP&gt;The smallest_change function determines the minimum number of element modifications needed to make an array palindromic, relevant to array transformation algorithms."|</data>
  <data key="d7">algorithm, array manipulation&lt;SEP&gt;algorithm, array transformation</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="F. Supplemental Bias Analysis" target="Bias">
  <data key="d5">20.0</data>
  <data key="d6">This section analyzes how models like Codex encode bias, which can cause societal harms, highlighting the need for bias assessment and mitigation in AI systems."|&lt;SEP&gt;This section discusses how models like Codex encode bias, which can lead to societal harms, emphasizing the importance of bias detection and mitigation."|</data>
  <data key="d7">conceptual analysis, model evaluation</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Model" target="Prompts related to protected classes">
  <data key="d5">17.0</data>
  <data key="d6">Prompts designed to probe model biases and harmful responses related to sensitive attributes.&lt;SEP&gt;Prompts designed to probe model biases and harmful tendencies.</data>
  <data key="d7">bias testing, bias detection&lt;SEP&gt;model testing, bias detection</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Model" target="Bias Reinforcement">
  <data key="d5">15.0</data>
  <data key="d6">Biased prompts and datasets can cause models to reinforce harmful stereotypes and biases in their outputs.&lt;SEP&gt;Biased prompts and training data can reinforce harmful stereotypes in generated code and text.</data>
  <data key="d7">bias reinforcement, social harm</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Model" target="Bias in Comments and Docstrings">
  <data key="d5">16.0</data>
  <data key="d6">Generated comments and docstrings can reflect biases, potentially denigrating groups or individuals.&lt;SEP&gt;Model comments and docstrings reflect biases, potentially denigrating groups.</data>
  <data key="d7">bias in documentation, harmful language</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Model" target="Code Datasets">
  <data key="d5">7.0</data>
  <data key="d6">Code datasets that encode social biases contribute to biased model outputs.</data>
  <data key="d7">training data bias, code bias</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Model" target="Bias in Text Generation">
  <data key="d5">8.0</data>
  <data key="d6">Both GPT-3 and Codex tend to produce biased terms when discussing certain groups, such as 'terrorist' or 'violent' for specific religions.</data>
  <data key="d7">bias in output, stereotypes</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Model" target="Bias Comparison">
  <data key="d5">7.0</data>
  <data key="d6">GPT-3 and Codex show similar bias tendencies, with GPT-3 often exhibiting more diversity in biased terms.</data>
  <data key="d7">model bias comparison</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Model" target="Prompt Framing">
  <data key="d5">7.0</data>
  <data key="d6">The framing and specificity of prompts influence the likelihood of biased responses from models.</data>
  <data key="d7">prompt sensitivity, bias</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Analysis in Text" target="Co-occurrence Tests">
  <data key="d5">10.0</data>
  <data key="d6">Co-occurrence tests measure how often group-related words appear near potentially prejudiced terms.</data>
  <data key="d7">bias detection, word association</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Threat Actors" target="Potential Exploitation">
  <data key="d5">7.0</data>
  <data key="d6">Threat actors may exploit biases in models for malicious purposes like causing harm or misinformation.</data>
  <data key="d7">exploitation, malicious use</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Threat Actors" target="Malicious Code Generation">
  <data key="d5">8.0</data>
  <data key="d6">Threat actors may utilize Codex to assist in creating malicious code components, such as malware or exploit payloads, leveraging its code generation capabilities.</data>
  <data key="d7">malicious use, cybersecurity threat</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Threat Actors" target="Phishing">
  <data key="d5">7.0</data>
  <data key="d6">Threat actors could use Codex to facilitate phishing attacks through generated scripts or code snippets.</data>
  <data key="d7">cyberattack facilitation</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Representation of Gender and Race" target="Discretization of Gender and Race">
  <data key="d5">6.0</data>
  <data key="d6">Discretization simplifies complex gender and race identities into categories, which can overlook nuances.</data>
  <data key="d7">categorization, nuance loss</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Malicious Code Generation" target="Model Limitations">
  <data key="d5">7.0</data>
  <data key="d6">Codex's current inability to reliably generate sophisticated malicious code limits immediate threats, but this may change.</data>
  <data key="d7">model constraints, security risk</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Vulnerability Discovery" target="Model Limitations">
  <data key="d5">6.0</data>
  <data key="d6">Current limitations of Codex restrict its effectiveness in discovering complex vulnerabilities, but future improvements are anticipated.</data>
  <data key="d7">security analysis, model improvement</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Limitations" target="Current limitations of Codex include difficulty in reliably detecting high-dimension vulnerabilities and preventing malicious suggestions, which pose ongoing security concerns.">
  <data key="d5">8.0</data>
  <data key="d6">model constraints, cybersecurity risks</data>
  <data key="d7">8</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="RSA keys" target="insecurity">
  <data key="d5">16.0</data>
  <data key="d6">RSA keys shorter than 2048 bits are considered insecure, and models like Codex produce such insecure keys, highlighting security risks.&lt;SEP&gt;RSA keys shorter than 2048 bits are insecure, and Codex often produces such insecure keys, highlighting security risks.</data>
  <data key="d7">cryptography, key length, security standards&lt;SEP&gt;cryptography, security standards, AI-generated cryptography</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="AES contexts" target="insecurity">
  <data key="d5">14.0</data>
  <data key="d6">AES contexts using ECB mode are insecure, and Codex models have produced such configurations, indicating security vulnerabilities.&lt;SEP&gt;Codex produces AES configurations using ECB mode, which is insecure, illustrating potential cryptographic vulnerabilities.</data>
  <data key="d7">cipher modes, security risks&lt;SEP&gt;cryptography, cipher modes, security evaluation</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Large Language Models trained on Code" target="security assessments">
  <data key="d5">9.0</data>
  <data key="d6">These models are evaluated for security risks such as producing insecure keys or configurations, impacting cryptography practices.</data>
  <data key="d7">model evaluation, security risks</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Large Language Models trained on Code" target="security risks">
  <data key="d5">10.0</data>
  <data key="d6">These models can generate insecure cryptographic configurations, posing security risks that need to be assessed.</data>
  <data key="d7">model evaluation, security risks</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="programmers and engineers" target="code generation tools">
  <data key="d5">16.0</data>
  <data key="d6">Programmers and engineers use tools like Codex to assist with coding tasks, which can influence productivity and security practices.&lt;SEP&gt;Programmers and engineers use tools like Codex to generate code, which impacts development workflows and security practices.</data>
  <data key="d7">workforce, productivity, security&lt;SEP&gt;workforce, productivity, security practices</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="security standards" target="security assessments">
  <data key="d5">20.0</data>
  <data key="d6">Evolving security standards influence how cryptographic configurations are evaluated, and AI-generated outputs must adhere to these standards to ensure security.&lt;SEP&gt;Security standards guide the evaluation of cryptographic configurations, and AI outputs should conform to these standards for security.&lt;SEP&gt;Security standards influence how cryptographic configurations are evaluated, and AI models' outputs need to align with these standards.</data>
  <data key="d7">standards, cryptography, evaluation&lt;SEP&gt;standards, evaluation&lt;SEP&gt;standards, security evaluation</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation Tools" target="Import Patterns">
  <data key="d5">15.0</data>
  <data key="d6">Code generation models import packages at different rates based on training data, affecting code robustness, security, and economic dynamics.&lt;SEP&gt;Models like Codex import packages at different rates based on training data, affecting code robustness, safety, and market dynamics.</data>
  <data key="d7">import behavior, economic impact</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation Tools" target="Safety and Security">
  <data key="d5">14.0</data>
  <data key="d6">Automated import suggestions and package choices by Codex can lead to errors or security vulnerabilities if not carefully managed.&lt;SEP&gt;Automated import suggestions can introduce errors or security vulnerabilities if not carefully managed, impacting safety.</data>
  <data key="d7">security risk, error potential</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Import Patterns" target="Economic Effects">
  <data key="d5">16.0</data>
  <data key="d6">Patterns in package importing influence market dominance, costs, and safety in software development.&lt;SEP&gt;Patterns in package imports influence the dominance of certain packages, market power, costs, and safety in software development.</data>
  <data key="d7">market dominance, safety&lt;SEP&gt;market dynamics, safety</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Biases in Training Data" target="Open-source Development">
  <data key="d5">8.0</data>
  <data key="d6">Biases may affect how Codex suggests open-source packages, influencing development practices and backward compatibility.</data>
  <data key="d7">development practices, compatibility</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Biases in Training Data" target="Bias in Suggestions">
  <data key="d5">8.0</data>
  <data key="d6">Biases originate from training data, influencing Codex's suggestions and potentially reinforcing existing market and package biases.</data>
  <data key="d7">bias propagation, influence</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Market Entrenchment" target="Users">
  <data key="d5">7.0</data>
  <data key="d6">Reliance on Codex may reinforce existing market dominance of certain packages, leading to entrenchment of preferences.</data>
  <data key="d7">market influence, preferences</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Documentation Practices" target="Testing and Bugs">
  <data key="d5">7.0</data>
  <data key="d6">Codex's assistance may improve documentation but could also propagate subtle errors, affecting software quality.</data>
  <data key="d7">quality, errors</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Time" target="Users">
  <data key="d5">7.0</data>
  <data key="d6">Time captures the ongoing process during which users learn, adapt, and integrate Codex into their workflows over time.</data>
  <data key="d7">learning, adaptation</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Open-source Developers" target="Biases in Suggestions">
  <data key="d5">8.0</data>
  <data key="d6">Open-source developers' work may be affected by Codex's suggestions, especially regarding deprecated methods or popular packages, impacting maintenance practices.</data>
  <data key="d7">development practices, biases</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Open-source Maintenance" target="Biases in Suggestions">
  <data key="d5">7.0</data>
  <data key="d6">Codex's suggestions can impact how open-source packages are maintained, especially regarding backward compatibility and updates.</data>
  <data key="d7">maintenance, biases</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Open Source Software" target="Women’s Participation">
  <data key="d5">12.0</data>
  <data key="d6">A survey of literature explores women's participation and gender diversity in open source communities.&lt;SEP&gt;A survey of literature explores women's participation in open source communities.</data>
  <data key="d7">study, social aspects</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="OpenMP Pragmas" target="HPC coding task">
  <data key="d5">16.0</data>
  <data key="d6">OpenMP pragmas are directives used to specify parallel regions in code, particularly decorating loops to enable multi-threaded execution in shared-memory environments.&lt;SEP&gt;OpenMP pragmas are used as directives within HPC code to specify parallel regions, particularly loops, enabling multi-threaded execution.</data>
  <data key="d7">parallel directives, HPC programming</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Completion" target="Pass@k Metric">
  <data key="d5">20.0</data>
  <data key="d6">The pass@k metric estimates the probability that at least one of k generated code samples is correct, based on correctness counts.&lt;SEP&gt;The pass@k metric estimates the probability that at least one of k generated code samples is correct, based on correctness counts."|&lt;"performance metric, probabilistic evaluation</data>
  <data key="d7">10&lt;SEP&gt;performance metric, probabilistic evaluation</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Completion" target="HPC Code Generation Problems">
  <data key="d5">16.0</data>
  <data key="d6">These custom problems serve as objects of study to evaluate the model's ability to generate parallel HPC code.&lt;SEP&gt;These custom problems serve as objects of study to evaluate the model's ability to generate parallel HPC code."|&lt;"application testing, model capability</data>
  <data key="d7">8&lt;SEP&gt;application testing, model capability</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="transfer learning" target="performance modeling">
  <data key="d5">9.0</data>
  <data key="d6">Transfer learning enables models trained on source code modeling to be adapted for performance prediction tasks, leveraging prior knowledge.</data>
  <data key="d7">knowledge transfer, task adaptation</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="transfer learning" target="source code modeling">
  <data key="d5">9.0</data>
  <data key="d6">Transfer learning enables models trained on large datasets of source code to be adapted for specific tasks like performance prediction and code labeling.</data>
  <data key="d7">knowledge transfer, task adaptation</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="transformer-based language models" target="source code">
  <data key="d5">16.0</data>
  <data key="d6">Transformer architectures are applied to model source code sequences, enabling tasks like code generation and labeling.&lt;SEP&gt;Transformer models are applied to source code sequences to perform tasks like code generation, labeling, and performance prediction.</data>
  <data key="d7">modeling techniques, source code analysis</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="code generation tasks" target="success rates">
  <data key="d5">8.0</data>
  <data key="d6">The model completes HPC-specific code generation tasks at a rate up to 53% higher than other models, demonstrating superior performance.</data>
  <data key="d7">task performance, benchmark evaluation</data>
  <data key="d8">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Perplexity" target="Text Generation">
  <data key="d5">7.0</data>
  <data key="d6">Perplexity is used to evaluate the confidence of language models in text generation tasks, influencing the selection of sampling strategies.</data>
  <data key="d7">model evaluation, confidence</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Perplexity" target="Model Confidence">
  <data key="d5">7.0</data>
  <data key="d6">Perplexity measures the model's confidence in its predictions, influencing the effectiveness of sampling methods during text generation.</data>
  <data key="d7">model evaluation, confidence</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Perplexity" target="Training Loss">
  <data key="d5">18.0</data>
  <data key="d6">Perplexity is calculated as the exponential of the training loss, serving as a performance indicator during training.&lt;SEP&gt;Perplexity is calculated as the exponential of the training loss, serving as a performance indicator during training."|&lt;"performance measurement, training evaluation</data>
  <data key="d7">9&lt;SEP&gt;performance measurement, training evaluation</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Perplexity" target="Validation Dataset">
  <data key="d5">16.0</data>
  <data key="d6">Perplexity is also computed on the validation dataset to evaluate model generalization.&lt;SEP&gt;Perplexity is also computed on the validation dataset to evaluate model generalization."|&lt;"model validation, performance assessment</data>
  <data key="d7">8&lt;SEP&gt;model validation, performance assessment</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Text Generation" target="Sampling Methods">
  <data key="d5">8.0</data>
  <data key="d6">Sampling methods like temperature, top-k, and nucleus sampling are applied during text generation to control diversity and coherence of output.</data>
  <data key="d7">generation control, diversity</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Text Generation" target="Sampling Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Sampling techniques such as temperature, top-k, and nucleus sampling are employed to balance diversity and relevance in generated text.</data>
  <data key="d7">generation quality, diversity</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Sampling Methods" target="Top-k Sampling">
  <data key="d5">7.0</data>
  <data key="d6">Top-k sampling limits token choices to the top k probable tokens, reducing off-topic outputs and improving quality.</data>
  <data key="d7">quality control, off-topic avoidance</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Top-k Sampling" target="Sampling Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Top-k sampling limits token choices to the k most probable tokens, reducing off-topic or low-quality outputs.</data>
  <data key="d7">quality control, relevance</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="LLMs for Code Generation" target="Left-to-Right Models">
  <data key="d5">14.0</data>
  <data key="d6">Left-to-right models generate code sequentially, predicting the next token based on prior context, suitable for natural language and code generation tasks.&lt;SEP&gt;Left-to-right models generate code sequentially, predicting the next token based on prior context, suitable for natural language and code tasks.</data>
  <data key="d7">sequential prediction, code generation</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="LLMs for Code Generation" target="Masked Models">
  <data key="d5">8.0</data>
  <data key="d6">Masked models predict tokens at randomly masked positions, enabling use of broader context for more accurate predictions.</data>
  <data key="d7">context utilization, prediction flexibility</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="LLMs for Code Generation" target="Encoder-Decoder Models">
  <data key="d5">14.0</data>
  <data key="d6">Encoder-decoder models process input sequences and generate output sequences, useful for tasks like code translation, summarization, or conversion.&lt;SEP&gt;Encoder-decoder models process input sequences and generate outputs, useful for tasks like code translation or summarization.</data>
  <data key="d7">sequence-to-sequence, translation&lt;SEP&gt;sequence-to-sequence, translation, summarization</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="LLMs for Code Generation" target="Masked Language Models">
  <data key="d5">8.0</data>
  <data key="d6">Masked models predict tokens at masked positions, enabling use of broader context for more accurate and flexible predictions.</data>
  <data key="d7">context utilization, prediction accuracy</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Confidence" target="Downstream Tasks">
  <data key="d5">6.0</data>
  <data key="d6">Lower perplexity generally correlates with better performance on downstream tasks like code generation or classification.</data>
  <data key="d7">performance, evaluation</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Downstream Tasks" target="Training Setup and Methodology">
  <data key="d5">7.0</data>
  <data key="d6">The training setup and methodology directly influence the effectiveness of downstream tasks such as code generation and performance prediction.</data>
  <data key="d7">training process, task performance</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Downstream Tasks" target="Section VI">
  <data key="d5">8.0</data>
  <data key="d6">Section VI describes the evaluation process of the trained models on specific tasks to measure their effectiveness.</data>
  <data key="d7">model evaluation, task performance</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Training Setup and Methodology" target="Performance Data Datasets">
  <data key="d5">6.0</data>
  <data key="d6">Performance datasets of code pairs with performance data are used to fine-tune and evaluate models on performance prediction tasks.</data>
  <data key="d7">performance modeling, dataset utility</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Training Setup and Methodology" target="Fig. 1">
  <data key="d5">7.0</data>
  <data key="d6">Figure 1 provides a visual overview of the entire process from data collection to model deployment on downstream tasks.</data>
  <data key="d7">workflow, process overview</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Preprocessed Data" target="Section V">
  <data key="d5">9.0</data>
  <data key="d6">The section details how raw source code datasets are cleaned and prepared for model training, including filtering and tokenization.</data>
  <data key="d7">data preparation, training pipeline</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Fig. 2" target="HPC source dataset">
  <data key="d5">6.0</data>
  <data key="d6">The distribution of code lines in Fig. 2 informs dataset diversity and structure, impacting model training.</data>
  <data key="d7">dataset analysis, data distribution</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Performance datasets" target="Kripke application">
  <data key="d5">8.0</data>
  <data key="d6">Performance data collected from Kripke application commits is used to train models to recognize regressions.</data>
  <data key="d7">performance regression, training data</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Performance datasets" target="Laghos application">
  <data key="d5">8.0</data>
  <data key="d6">Similarly, Laghos application data supports training models on HPC application performance.</data>
  <data key="d7">performance modeling, application data</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Performance datasets" target="Code contests dataset">
  <data key="d5">7.0</data>
  <data key="d6">Code solutions from contests are used to create pairs for performance comparison and modeling.</data>
  <data key="d7">performance prediction, dataset creation</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="programming competition solutions" target="code contests dataset">
  <data key="d5">16.0</data>
  <data key="d6">Solutions are aggregated from the code contests dataset, which includes multiple online competitions.</data>
  <data key="d7">dataset composition, data source&lt;SEP&gt;dataset source, data collection</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="run time" target="solutions">
  <data key="d5">18.0</data>
  <data key="d6">Each solution's run time is recorded when tested against test cases, serving as the basis for pairing and comparison.&lt;SEP&gt;Each solution's run time is recorded when tested against test cases, used to group solutions into pairs.</data>
  <data key="d7">performance measurement, data collection</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="solution pairs" target="slower and faster pairs">
  <data key="d5">20.0</data>
  <data key="d6">Solutions are grouped into pairs based on their run times, labeled as slower or faster to facilitate comparative analysis.&lt;SEP&gt;Solutions are grouped into pairs based on their run times, labeled as slower or faster.</data>
  <data key="d7">pairwise comparison, performance analysis</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="PolyCoder" target="OpenMP code">
  <data key="d5">14.0</data>
  <data key="d6">PolyCoder produces correct sequential code but fails to generate OpenMP pragmas, indicating limitations in parallel code generation capabilities.&lt;SEP&gt;PolyCoder produces correct sequential code but fails to generate OpenMP pragmas, showing limitations in parallel code annotation.</data>
  <data key="d7">parallel code generation, model limitation&lt;SEP&gt;parallel code generation, model limitations</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="DeepSpeed" target="fine-tuning setup and hyperparameters">
  <data key="d5">16.0</data>
  <data key="d6">DeepSpeed enables efficient training of large models by providing distributed training and memory optimization capabilities.&lt;SEP&gt;DeepSpeed framework is used to optimize training of large models on GPU hardware.</data>
  <data key="d7">distributed training, efficiency&lt;SEP&gt;distributed training, memory optimization</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="DeepSpeed" target="Model Training">
  <data key="d5">18.0</data>
  <data key="d6">DeepSpeed enables scalable training of large models by optimizing computational efficiency.&lt;SEP&gt;DeepSpeed facilitates scalable and efficient training of large models across multiple hardware resources, enabling training of billion-parameter models.</data>
  <data key="d7">Tools, Applications/Implications</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="AdamW" target="fine-tuning setup and hyperparameters">
  <data key="d5">18.0</data>
  <data key="d6">AdamW optimizer is employed to update model weights during fine-tuning.&lt;SEP&gt;AdamW optimizer is used to update the models' weights during training, minimizing the loss function.</data>
  <data key="d7">optimization, training process</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="validation dataset" target="fine-tuning setup and hyperparameters">
  <data key="d5">22.0</data>
  <data key="d6">A separate validation dataset is used to evaluate model performance during training.&lt;SEP&gt;The validation dataset is used to monitor model performance during training, ensuring generalization.</data>
  <data key="d7">model validation, performance assessment&lt;SEP&gt;model validation, performance monitoring</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Pass@k Metric" target="Evaluation Procedure">
  <data key="d5">18.0</data>
  <data key="d6">The procedure involves generating multiple code samples, compiling, and testing them to compute the pass@k score, reflecting the model's ability to produce correct code.&lt;SEP&gt;The procedure involves generating multiple code samples, compiling, and testing them to compute the pass@k score, reflecting the model's ability to produce correct code."|&lt;"assessment process, performance measurement</data>
  <data key="d7">9&lt;SEP&gt;assessment process, performance measurement</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Parallel Frameworks (OpenMP, MPI)" target="Code Samples">
  <data key="d5">9.0</data>
  <data key="d6">Generated code is evaluated for correct utilization of OpenMP or MPI frameworks to ensure functional parallelism."|&lt;"correctness verification, framework usage</data>
  <data key="d7">9</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Experiment Settings" target="Evaluation Procedure">
  <data key="d5">16.0</data>
  <data key="d6">Different temperature settings and sample sizes are used to optimize code generation and evaluate model performance.&lt;SEP&gt;Different temperature settings and sample sizes are used to optimize code generation and evaluate model performance."|&lt;"parameter tuning, experimental design</data>
  <data key="d7">8&lt;SEP&gt;parameter tuning, experimental design</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Functionally Correct Code" target="Generated Code Samples">
  <data key="d5">8.0</data>
  <data key="d6">Generated code samples are tested for correctness, and those that pass tests are used to compute metrics like pass@k."|&lt;"performance evaluation, correctness</data>
  <data key="d7">8</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Generated Code Samples" target="Compilation and Testing">
  <data key="d5">8.0</data>
  <data key="d6">Generated code samples are compiled and tested to determine their correctness, which influences the pass@k score."|&lt;"evaluation process, correctness assessment</data>
  <data key="d7">8</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Relative Performance Prediction" target="Code Pair Dataset">
  <data key="d5">9.0</data>
  <data key="d6">Pairs of code before and after modifications are used to train models to classify performance changes.</data>
  <data key="d7">performance classification, code comparison</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Relative Performance Prediction" target="Code pair dataset">
  <data key="d5">9.0</data>
  <data key="d6">Pairs of code before and after modifications are used to train models to classify whether code performance has slowed or improved.</data>
  <data key="d7">performance classification, code comparison</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="PolyCoder+HPC" target="OpenMP code">
  <data key="d5">16.0</data>
  <data key="d6">PolyCoder+HPC correctly tags loops with OpenMP pragmas, demonstrating improved parallel code annotation capability.&lt;SEP&gt;PolyCoder+HPC successfully tags loops with OpenMP pragmas, demonstrating its ability to generate correct parallel annotations.</data>
  <data key="d7">parallel programming, code correctness&lt;SEP&gt;parallelism, code correctness</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="PolyCoder+HPC" target="MPI code">
  <data key="d5">18.0</data>
  <data key="d6">PolyCoder+HPC generates correct MPI routines for parallel computation, showing improved understanding of distributed memory programming.&lt;SEP&gt;PolyCoder+HPC generates correct MPI routines, indicating better understanding of distributed memory parallel programming.</data>
  <data key="d7">distributed computing, MPI routines</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="PolyCoder+HPC" target="Speedups">
  <data key="d5">16.0</data>
  <data key="d6">PolyCoder+HPC achieves speedups over sequential code, showing effective parallel code generation.&lt;SEP&gt;PolyCoder+HPC achieves speedups over sequential implementations, indicating effective parallel code generation.</data>
  <data key="d7">performance, parallel efficiency</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Machine Learning for Code" target="Android Malware Detection">
  <data key="d5">16.0</data>
  <data key="d6">Machine learning techniques are systematically reviewed to evaluate their effectiveness in detecting malware on Android devices.</data>
  <data key="d7">methodology, evaluation</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Summarization" target="Semantic Similarity Metrics">
  <data key="d5">14.0</data>
  <data key="d6">Semantic similarity metrics are used to evaluate the quality of source code summaries generated by models.</data>
  <data key="d7">evaluation, metrics</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Summarization" target="Transformer-Based Approach">
  <data key="d5">16.0</data>
  <data key="d6">Transformers are employed as tools in approaches to improve the accuracy and quality of source code summarization.</data>
  <data key="d7">technology, application</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Bug Localization and Repair" target="Learning from Developer Mistakes">
  <data key="d5">14.0</data>
  <data key="d6">Research explores whether models can learn from real bug fixes to localize and repair bugs effectively.</data>
  <data key="d7">learning, application</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="AlphaCode" target="Competition-level code generation">
  <data key="d5">16.0</data>
  <data key="d6">AlphaCode aims to generate code solutions at a competitive level, advancing AI in programming challenges.&lt;SEP&gt;AlphaCode is designed to generate code at a competitive level, aiming to solve programming problems effectively.</data>
  <data key="d7">Theories/Models, Applications/Implications</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Openwebtext Corpus" target="Language Model Training">
  <data key="d5">7.0</data>
  <data key="d6">The Openwebtext corpus provides diverse textual data essential for training robust language models.</data>
  <data key="d7">Objects of Study, Applications/Implications</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Zero-offload" target="Model Training">
  <data key="d5">16.0</data>
  <data key="d6">Zero-offload techniques allow training of billion-scale models by offloading computations, reducing hardware requirements and increasing accessibility.&lt;SEP&gt;Zero-offload techniques facilitate training billion-scale models by offloading computations, making training more accessible.</data>
  <data key="d7">Methodologies, Applications/Implications</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Parallel and Distributed Deep Learning" target="Model Training">
  <data key="d5">18.0</data>
  <data key="d6">Parallel and distributed techniques allow training of large neural networks across multiple hardware units, improving scalability.&lt;SEP&gt;Parallel and distributed training techniques enable large models to be trained efficiently across multiple processors or machines, improving scalability.</data>
  <data key="d7">Methodologies, Applications/Implications</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="OpenWebText Corpus" target="Language Model Training">
  <data key="d5">7.0</data>
  <data key="d6">Provides a large, diverse textual dataset critical for training and evaluating language models.</data>
  <data key="d7">Objects of Study, Applications/Implications</data>
  <data key="d8">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Grounded Copilot" target="How programmers interact with code-generating models">
  <data key="d5">16.0</data>
  <data key="d6">Grounded Copilot studies the interaction patterns between programmers and AI models to improve usability and effectiveness.</data>
  <data key="d7">human-AI interaction, code generation</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="DeepDev-perf" target="Deep learning-based approach">
  <data key="d5">18.0</data>
  <data key="d6">DeepDev-perf employs deep learning techniques to analyze and improve software performance.</data>
  <data key="d7">performance optimization, machine learning</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Deepdev-perf" target="Software Performance">
  <data key="d5">16.0</data>
  <data key="d6">Deepdev-perf aims to improve software performance by applying deep learning techniques.&lt;SEP&gt;Deepdev-perf aims to improve software performance using deep learning techniques.</data>
  <data key="d7">application, performance optimization&lt;SEP&gt;application, software optimization</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Deepdev-perf" target="Deep Learning">
  <data key="d5">7.0</data>
  <data key="d6">Deepdev-perf is based on deep learning methodologies involving neural networks.</data>
  <data key="d7">theoretical foundation, methodology</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Deepdev-perf" target="Proceedings of the 30th ACM Conference">
  <data key="d5">6.0</data>
  <data key="d6">The conference proceedings document the research and evaluation of Deepdev-perf.</data>
  <data key="d7">study documentation, research dissemination</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Deepdev-perf" target="S. Garg">
  <data key="d5">7.0</data>
  <data key="d6">S. Garg is an author of the Deepdev-perf paper, contributing to methodology and research.</data>
  <data key="d7">authorship, research contribution</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Deepdev-perf" target="R. Z. Moghaddam">
  <data key="d5">7.0</data>
  <data key="d6">R. Z. Moghaddam co-authored the Deepdev-perf study, involved in developing the deep learning approach.</data>
  <data key="d7">collaboration, methodology</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Deepdev-perf" target="C. B. Clement">
  <data key="d5">6.0</data>
  <data key="d6">C. B. Clement is a co-author of the Deepdev-perf paper, involved in research activities.</data>
  <data key="d7">authorship, research role</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Deepdev-perf" target="N. Sundaresan">
  <data key="d5">6.0</data>
  <data key="d6">N. Sundaresan contributed to the research and evaluation of the Deepdev-perf methodology.</data>
  <data key="d7">contribution, research evaluation</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Deepdev-perf" target="C. Wu">
  <data key="d5">5.0</data>
  <data key="d6">C. Wu is involved in the study, focusing on software engineering aspects.</data>
  <data key="d7">research involvement, methodology</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="fine-tuning setup and hyperparameters" target="models selected for fine-tuning">
  <data key="d5">14.0</data>
  <data key="d6">The models are chosen based on their architecture, size, and pre-training data to optimize for language modeling tasks.&lt;SEP&gt;The selected models are based on architectures suitable for language modeling, with specific configurations for size and data pre-training.</data>
  <data key="d7">model selection, training setup</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Samples" target="Parallel Frameworks">
  <data key="d5">9.0</data>
  <data key="d6">Generated code is evaluated for correct utilization of OpenMP or MPI frameworks to ensure functional parallelism.</data>
  <data key="d7">correctness verification, framework usage</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
</graph></graphml>