<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d9" for="edge" attr.name="file_path" attr.type="string"/>
<key id="d8" for="edge" attr.name="source_id" attr.type="string"/>
<key id="d7" for="edge" attr.name="keywords" attr.type="string"/>
<key id="d6" for="edge" attr.name="description" attr.type="string"/>
<key id="d5" for="edge" attr.name="weight" attr.type="double"/>
<key id="d4" for="node" attr.name="file_path" attr.type="string"/>
<key id="d3" for="node" attr.name="source_id" attr.type="string"/>
<key id="d2" for="node" attr.name="description" attr.type="string"/>
<key id="d1" for="node" attr.name="entity_type" attr.type="string"/>
<key id="d0" for="node" attr.name="entity_id" attr.type="string"/>
<graph edgedefault="undirected"><node id="Large Language Models">
  <data key="d0">Large Language Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Advanced models capable of zero-shot reasoning and understanding complex instructions.&lt;SEP&gt;Transformational AI technology that automates coding tasks, connects natural language descriptions to code, and enhances developer productivity.&lt;SEP&gt;Advanced neural network-based models designed to understand, process, and generate human language, including source code, with applications in software development tasks such as code completion, translation, and generation.&lt;SEP&gt;Large Language Models (LLMs) are advanced neural network-based models designed to understand and generate human language, including source code, and are increasingly used in software development for tasks like code completion and translation.&lt;SEP&gt;Advanced neural network models trained on large-scale text corpora capable of performing a variety of NLP tasks, such as GPT, BERT, and similar models.&lt;SEP&gt;Advanced neural network models trained on vast text corpora to perform a variety of NLP tasks, including GPT models.&lt;SEP&gt;Artificial general intelligence models capable of performing a wide range of tasks across various domains, exhibiting cognitive and linguistic capabilities.&lt;SEP&gt;Artificial general intelligence models that demonstrate versatility across a wide range of tasks and domains, exhibiting cognitive capabilities and adaptability.&lt;SEP&gt;Large Language Models (LLMs) are advanced NLP models that serve as foundational tools across various applications, characterized by their task-agnostic capabilities and significant impact on natural language processing.&lt;SEP&gt;Large Language Models (LLMs) are advanced neural network-based models trained on large-scale textual data to understand and generate human-like language, enabling various NLP tasks and facilitating research across disciplines.&lt;SEP&gt;Advanced predictive models trained on extensive source code datasets that can generate, complete, and analyze code, and are applied here to HPC and scientific computing contexts.&lt;SEP&gt;Advanced predictive models trained on large datasets of source code that can generate, complete, and analyze code snippets, used here to automate HPC code tasks.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-130e4012ca037ccaf70ac4ffd0928777&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-d8772ec3475b4e5b1b113032265f9d74&lt;SEP&gt;chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Code Generation">
  <data key="d0">Code Generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Code generation involves AI systems producing code snippets and supporting software development, which can enhance productivity but may introduce security vulnerabilities if insecure configurations are generated.&lt;SEP&gt;Code generation involves AI tools automating programming tasks, which can improve productivity but also introduce security vulnerabilities if insecure configurations are produced.&lt;SEP&gt;Code generation involves translating intermediate representations into executable code, with optimizations like inlining and loop unrolling to improve performance.&lt;SEP&gt;Code generation translates intermediate representations into executable code, applying optimizations like inlining and loop unrolling to improve performance.&lt;SEP&gt;The final stage generates optimized C++ code from the AMT, ready for deployment.&lt;SEP&gt;The process of automatically producing source code from natural language descriptions or other specifications, often using machine learning models like LLMs.&lt;SEP&gt;The task of automatically generating source code from natural language descriptions or specifications.&lt;SEP&gt;The task of automatically producing source code based on specifications or natural language descriptions.&lt;SEP&gt;The process of automatically generating source code using trained language models, evaluated through pass@k metrics and compilation success rates.&lt;SEP&gt;The task where the model generates syntactically and semantically correct HPC code based on prompts or context.&lt;SEP&gt;Using trained models to automatically generate source code, aiding development, automation, and code synthesis tasks.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-3487322ee335c5f4b3b40717a7de46d1&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="HPC-specific models">
  <data key="d0">HPC-specific models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Language models like HPCCoder, fine-tuned specifically on HPC codebases to generate HPC code, label pragmas, and predict performance.&lt;SEP&gt;Models like HPCCoder, trained specifically on HPC codebases to generate HPC code, label OpenMP pragmas, and predict performance metrics.&lt;SEP&gt;Specialized models tailored to high-performance computing domains to improve code generation, especially for parallel code.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Code">
  <data key="d0">Parallel Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code designed for parallel computing architectures, serving as the primary subject for model training, fine-tuning, and evaluation.&lt;SEP&gt;Code designed to execute multiple operations simultaneously to improve performance, a key focus of the study.&lt;SEP&gt;Code designed to run concurrently across multiple processors or cores, the focus of HPC code generation models.&lt;SEP&gt;Code that executes multiple tasks simultaneously to improve performance, which is challenging for LLMs to generate accurately.&lt;SEP&gt;Code written for parallel computing architectures, used as the primary subject for training and evaluation of models.&lt;SEP&gt;Parallel code refers to source code written to execute computations simultaneously across multiple processing units, involving reasoning about data distribution and parallel algorithms.&lt;SEP&gt;Source code written to perform computations simultaneously across multiple processing units, involving reasoning about data distribution, parallel algorithms, and parallel programming models.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Fine-tuning">
  <data key="d0">Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Fine-tuning is a process of adapting pre-trained language models to specific tasks or domains by further training on task- or domain-specific datasets. This technique involves adjusting the internal parameters of large language models, such as Codex, using domain-relevant data like HPC source code, scientific codes, MPI samples, or correctly implemented functions, to enhance their performance and specialization. Fine-tuning leads to more profound and persistent changes in the model's behavior, enabling it to generate accurate, domain-specific outputs such as parallel code snippets, OpenMP pragmas, or HPC performance predictions. It is particularly effective for tasks like HPC code generation, parallel code development, and performance prediction, by training the models on datasets like HPC-INSTRUCT or other scientific and HPC-related code repositories. Overall, fine-tuning significantly improves a pre-trained model's ability to perform targeted, domain-specific tasks through additional, focused training on relevant datasets.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-cfcd5a8798f30da73fdaa3033d579b42&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-4bb8bb2fc231e52a13ed0e91512e55eb&lt;SEP&gt;chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="HPC datasets">
  <data key="d0">HPC datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Large collections of high-performance computing code data used to train and evaluate models for HPC applications.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-INSTRUCT">
  <data key="d0">HPC-INSTRUCT</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large synthetic dataset of high-quality instruct-answer pairs for HPC parallel code, used for fine-tuning models.&lt;SEP&gt;A large synthetic dataset of high-quality parallel code instruction data created to improve training of HPC code LLMs.&lt;SEP&gt;A large synthetic dataset of parallel code instruction-response pairs created to fine-tune HPC capable code LLMs for high-performance computing applications.&lt;SEP&gt;HPC-INSTRUCT is a large synthetic dataset of parallel code instruction-response pairs created to fine-tune code LLMs for high-performance computing applications.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="ParEval">
  <data key="d0">ParEval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A benchmark designed to evaluate LLMs' ability to generate parallel code across various problems and execution models, using standardized prompts and evaluation techniques.&lt;SEP&gt;A benchmark for evaluating the performance of code LLMs on parallel code generation tasks.&lt;SEP&gt;A state-of-the-art benchmark for evaluating the performance of code LLMs on parallel code generation tasks.&lt;SEP&gt;ParEval is a benchmarking tool that contains 420 coding problems across multiple problem types and execution models, used to evaluate code correctness of language models.&lt;SEP&gt;ParEval is a correctness evaluation metric that estimates the success rate (pass@1) of code generation models across various problem types and models, indicating their accuracy.&lt;SEP&gt;ParEval is a performance evaluation metric that estimates the success rate (pass@1) of code generation models across various problem types and models, measuring their accuracy.&lt;SEP&gt;ParEval is a benchmark designed to evaluate the ability of large language models (LLMs) to generate parallel code, including metrics for runtime performance and scalability.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="StarCoder2">
  <data key="d0">StarCoder2</data>
  <data key="d1">Tools</data>
  <data key="d2">A code LLM trained on The Stack v2 dataset, used as a benchmark for code generation performance.&lt;SEP&gt;A code language model trained on The Stack v2 dataset, used as a baseline for performance comparison.&lt;SEP&gt;StarCoder2 is a family of large language models (LLMs) with sizes 1.3B, 7B, and 15B, pre-trained on a large corpus of code data from The Stack V2, used for code generation tasks.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="The Stack v2">
  <data key="d0">The Stack v2</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A comprehensive dataset of permissively licensed code and related data used for training code LLMs.&lt;SEP&gt;A comprehensive dataset of permissively licensed code and related data used to train and evaluate code models.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2">
  <data key="d0">HPC-Coder-V2</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A fine-tuned code language model designed for parallel code generation, developed by training on the HPC-I NSTRUCT dataset.&lt;SEP&gt;A specialized code language model fine-tuned on HPC-I NSTRUCT dataset to generate parallel code effectively.&lt;SEP&gt;A specialized open-source language model fine-tuned for parallel code generation in high-performance computing (HPC) environments.&lt;SEP&gt;A specific fine-tuned large language model designed for HPC code generation, evaluated for throughput, accuracy, and resource requirements.&lt;SEP&gt;Can fine-tuning on high-quality synthetic HPC parallel code data improve the performance of open-source code LLMs for parallel code generation?&lt;SEP&gt;HPC-Coder-V2 is a large language model (LLM) designed for code generation tasks in high-performance computing (HPC), evaluated across multiple problem types and parallel execution models to assess its performance and capabilities.&lt;SEP&gt;HPC-Coder-V2 is a large language model designed for code generation in high-performance computing (HPC), evaluated across various problem types and execution models.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-aec2ac03d71774b2a191de2c6ebcd45e&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Performance">
  <data key="d0">Model Performance</data>
  <data key="d1">Results</data>
  <data key="d2">Evaluation of how retrieval strategies (number of documents) influence model outputs, such as QA accuracy and Rouge-L/Bleu scores.&lt;SEP&gt;HPC-Coder-V2 achieves the best performance among open-source models for parallel code generation, approaching GPT-4 levels.&lt;SEP&gt;HPC-Coder-V2 achieves the best performance among open-source models for parallel code generation, nearing GPT-4 levels.&lt;SEP&gt;Metrics and outcomes measuring how well the fine-tuned code LLM generates accurate and efficient parallel code.&lt;SEP&gt;Metrics and outcomes measuring the accuracy, efficiency, and quality of code generated by fine-tuned models in parallel programming contexts.&lt;SEP&gt;Model performance is evaluated through metrics like pass@k, memory requirements, and throughput on hardware such as H100, reflecting efficiency and accuracy.&lt;SEP&gt;The effectiveness of models in generating accurate parallel code, evaluated through metrics like Pass@1 across different data sources, model sizes, and training configurations.&lt;SEP&gt;The measure of a model's ability to generate accurate parallel code, evaluated across different data sources and model sizes.&lt;SEP&gt;Quantitative outcomes such as pass@k scores and speedup metrics indicating the effectiveness of each model.&lt;SEP&gt;Performance metrics such as pass@1 and pass@100 demonstrate the effectiveness of models like Codex, GPT-Neo, and GPT-J on coding tasks.&lt;SEP&gt;High accuracy in predicting code performance impacts, demonstrating models' ability to leverage prior language understanding for performance modeling.&lt;SEP&gt;Perplexity scores after fine-tuning show the effectiveness of different models in modeling HPC source code, with lower scores indicating better performance.&lt;SEP&gt;The overall effectiveness of the models in code generation tasks, measured through pass@k and compile success rates.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-7d9c04128411fd2962a424d26641c6ad&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="HPC">
  <data key="d0">HPC</data>
  <data key="d1">Disciplines</data>
  <data key="d2">High-performance computing encompasses the use of advanced computing techniques and programming models for scientific and engineering computations.&lt;SEP&gt;High-performance computing, focusing on optimizing computational tasks and parallel processing techniques.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Synthetic Dataset">
  <data key="d0">Synthetic Dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A constructed dataset generated to train models, specifically HPC-I NSTRUCT, containing high-quality parallel code instructions.&lt;SEP&gt;A large artificially generated dataset of high-quality parallel code instruction data created to improve model training.&lt;SEP&gt;A large, artificially generated collection of high-quality parallel code instructions (HPC-I NSTRUCT) used for training and evaluating code language models.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Evaluation">
  <data key="d0">Model Evaluation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Assessing models' code generation performance using benchmarks like ParEval to measure success rates and compare different models.&lt;SEP&gt;Assessing the performance of models like HPC-Coder-V2 against benchmarks such as ParEval to determine effectiveness.&lt;SEP&gt;Evaluation metrics and experiments demonstrate the effectiveness of RAG models in improving factual accuracy and response relevance.&lt;SEP&gt;Evaluation of language models involves assessing performance metrics such as pass@k and BLEU scores on datasets like HumanEval.&lt;SEP&gt;Model evaluation includes measuring pass@k metrics and manual grading to assess the quality and accuracy of generated code and docstrings.&lt;SEP&gt;The process of assessing models using metrics like pass@k and compile success to determine their effectiveness in code generation.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Quality">
  <data key="d0">Data Quality</data>
  <data key="d1">Variables</data>
  <data key="d2">Attributes of the data, such as correctness, relevance, and high-quality instruction-answer pairs, critical for effective model training.&lt;SEP&gt;Data quality indicates the relevance, accuracy, and realism of training data, which influences the effectiveness of model fine-tuning.&lt;SEP&gt;Data quality refers to the accuracy, relevance, and synthetic realism of training data, impacting model performance.&lt;SEP&gt;The intrinsic attributes of training data, such as correctness, diversity, and realism, which significantly influence model performance.&lt;SEP&gt;The relevance, accuracy, and consistency of training data, which directly influence the success of fine-tuning models for HPC code generation.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Collection">
  <data key="d0">Data Collection</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of gathering high-quality parallel code data, including synthetic data creation, to improve model training.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Research Contributions">
  <data key="d0">Research Contributions</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Can fine-tuning on high-quality synthetic HPC parallel code data significantly improve open-source code LLMs' ability to generate parallel code?</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Challenges in HPC Code Generation">
  <data key="d0">Challenges in HPC Code Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The intrinsic difficulty of generating correct and efficient parallel code, compounded by limited high-quality data and the need for specialized models.</data>
  <data key="d3">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Limitations">
  <data key="d0">Limitations</data>
  <data key="d1">Limitations</data>
  <data key="d2">The entity "Limitations" encompasses a broad range of constraints and weaknesses affecting various AI and computational models, particularly in the context of code generation and high-performance computing (HPC). These limitations include inefficiencies in sampling, difficulties with long or complex docstrings, and challenges in reliably handling system-level tasks. Specific issues such as syntactic errors, binding errors with variables and functions, and suboptimal utilization of parallel computing frameworks like MPI are noted. Additionally, current models exhibit scalability issues, memory overhead, and limited capabilities in system-level synthesis, which reduce their effectiveness in HPC software development.

Further constraints stem from the quality and diversity of training datasets, which impact model performance, generalization, and reproducibility. Concerns about dataset biases, lack of transparency in training data, and variability in evaluation metrics are acknowledged as factors that may influence the interpretation and validity of results. The performance of models varies depending on their size, the complexity of tasks, and the quality of modules used, with some strategies being computationally expensive.

Limitations also include challenges in generating complex parallel code, support gaps for specific frameworks such as HIP, and issues related to data scarcity and model biases. The inherent complexity of programming tasks, potential overfitting during fine-tuning, and increased complexity of certain approaches further restrict model applicability. Reproducibility of synthetic data generation processes and the maturity level of different models are additional concerns.

Overall, these limitations collectively impact the accuracy, reliability, and scalability of AI-generated code, highlighting the need for ongoing improvements in data quality, model training, and system optimization to overcome current constraints in the domain of AI-assisted HPC software development.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-04aecdc2586d2c7966e70e02cac846b0&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-8184ca90cae86b58652f2117d440bd17&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-d25502af8737c59d857916af40cc4020&lt;SEP&gt;chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="HPC-I NSTRUCT">
  <data key="d0">HPC-I NSTRUCT</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset created using synthetic data generated from language models and open-source parallel code, used for studying model fine-tuning and code generation capabilities.&lt;SEP&gt;A large synthetic dataset of high-quality parallel code instruction data created for training and evaluating code language models.&lt;SEP&gt;A synthetic dataset consisting of parallel code instructions, designed to facilitate the training of models like HPC-Coder-V2.&lt;SEP&gt;HPC-I NSTRUCT is a dataset or resource used for training and fine-tuning language models in high-performance computing contexts.&lt;SEP&gt;HPC-I NSTRUCT is a dataset used for training and fine-tuning models in high-performance computing contexts, comprising synthetic and real code samples.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Representation">
  <data key="d0">Data Representation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The way data, particularly parallel code, is formatted and structured to facilitate efficient learning by models.&lt;SEP&gt;The way in which data, especially parallel code instructions, are formatted, structured, and represented to facilitate effective learning and model training.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Training Parameters">
  <data key="d0">Training Parameters</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Settings and configurations such as learning rate, batch size, and epochs used during model fine-tuning to optimize performance.&lt;SEP&gt;Settings such as learning rate, batch size, number of epochs, and other hyperparameters used during model fine-tuning to optimize performance on parallel code generation tasks.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Research Questions">
  <data key="d0">Research Questions</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Questions aimed at understanding how model choice, data quality, and training parameters influence the performance of code LLMs in parallel code generation.&lt;SEP&gt;Specific questions aimed at understanding how factors such as model choice, data quality, and training techniques influence the effectiveness of code LLMs in parallel code generation.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Fine-tuning Base Model">
  <data key="d0">Fine-tuning Base Model</data>
  <data key="d1">Variables</data>
  <data key="d2">The initial pre-trained language model selected for further training, affecting the model's capacity and effectiveness.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Instruction Masking">
  <data key="d0">Instruction Masking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A fine-tuning technique where instruction tokens are masked during training to prevent the model from learning to reproduce instructions, thereby focusing on generating correct responses.&lt;SEP&gt;A fine-tuning technique where instruction tokens are masked to prevent the model from learning to generate instructions, focusing instead on response generation.&lt;SEP&gt;Instruction masking is a technique used during training to hide or mask the instruction part of input data to prevent the model from learning undesirable patterns and focus on response data.&lt;SEP&gt;Instruction masking is a training technique where parts of the input, such as instructions, are masked to prevent the model from learning undesired patterns, aiming to improve response quality.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Size">
  <data key="d0">Model Size</data>
  <data key="d1">Variables</data>
  <data key="d2">Model size indicates the number of parameters in a model, influencing its capabilities, propensity for misalignment, and risks of generating harmful or biased outputs.&lt;SEP&gt;Model size refers to the number of parameters in a language model, such as 1.3 billion (1.3B), 6.7 billion (6.7B), 16 billion (16B), 34 billion (34B), or 70 billion (70B). The size of the model significantly impacts its performance, capacity to learn and generalize, and resource requirements. Larger models generally perform better across a variety of tasks, including language understanding and code generation, due to their increased capacity to learn complex patterns. However, there are exceptions, such as certain geometric problem types where larger models may not outperform smaller ones. The number of parameters also influences the computational cost, practicality, and feasibility of fine-tuning or prompt tuning efforts. Additionally, model size affects the robustness of prompt initialization, the effectiveness of prompt tuning, and the ability to learn from synthetic data, especially in parallel code tasks. Overall, the scale of the language model, determined by its parameter count, plays a crucial role in its performance, learning capabilities, and resource demands.&lt;SEP&gt;Model size, measured in parameters, correlates with performance in code generation tasks.&lt;SEP&gt;The number of parameters in a model (e.g., 12M to 12B), influencing its performance and capacity for code generation.&lt;SEP&gt;Number of parameters in models like GPT-2, GPT-Neo, and PolyCoder, affecting their capacity to learn complex code patterns and generalize.&lt;SEP&gt;The number of parameters in the model, which can be reduced through fine-tuning to optimize efficiency.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4&lt;SEP&gt;chunk-b15d5bb768f451028654d71370cc6879&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-aec2ac03d71774b2a191de2c6ebcd45e&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-6f045498b0e63780c3aef4b9daf795b6&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-eec372249525c58f53cd0e9c24744ffb&lt;SEP&gt;chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Synthetic Data Quality">
  <data key="d0">Synthetic Data Quality</data>
  <data key="d1">Variables</data>
  <data key="d2">The level of accuracy and relevance of generated training data, influencing the effectiveness of fine-tuning and model performance.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Base Model">
  <data key="d0">Base Model</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The Base Model refers to the initial pre-trained language model used as a starting point for fine-tuning, such as Deepseek-Coder 1.3B and 6.7B.&lt;SEP&gt;The base model refers to the initial pre-trained language model (e.g., Deepseek-Coder 1.3B, 6.7B) used as the starting point for fine-tuning experiments.&lt;SEP&gt;The initial pre-trained language model selected as the starting point for fine-tuning, affecting the capacity and adaptability of the final model.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Quality of Fine-tuning Data">
  <data key="d0">Quality of Fine-tuning Data</data>
  <data key="d1">Variables</data>
  <data key="d2">The relevance, accuracy, and richness of the synthetic data used for fine-tuning, influencing the model's subsequent performance.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Synthetic Data Generation">
  <data key="d0">Synthetic Data Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of creating large-scale artificial datasets, such as HPC-I NSTRUCT, to facilitate effective training of code LLMs.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Data Quality">
  <data key="d0">Impact of Data Quality</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">High-quality synthetic data enhances model performance; poor data hampers learning and results in lower accuracy.&lt;SEP&gt;The investigation into how the quality, source, and diversity of training data affect the ability of code LLMs to generate accurate parallel code.&lt;SEP&gt;The study investigates how the quality and source of training data affect the ability of code LLMs to generate accurate parallel code.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Fine-tuning Parameters">
  <data key="d0">Impact of Fine-tuning Parameters</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Optimized training settings improve the effectiveness of model adaptation for parallel code generation.</data>
  <data key="d3">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Model Size">
  <data key="d0">Impact of Model Size</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring how different model sizes influence the capacity to learn and produce high-quality parallel code.&lt;SEP&gt;How the size of the language model (e.g., 1.3B vs 6.7B) influences the final performance after fine-tuning is examined.&lt;SEP&gt;Larger models generally exhibit better learning capacity, leading to improved performance in parallel code tasks.&lt;SEP&gt;The research explores how the size of the model influences its capacity to learn and generate parallel code effectively.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Evaluation Metrics">
  <data key="d0">Evaluation Metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Criteria or metrics used to assess the accuracy, trustworthiness, and quality of AI-generated HPC results.&lt;SEP&gt;Metrics measuring factual accuracy, diversity, and relevance of generated responses, demonstrating RAG's superior performance.&lt;SEP&gt;Metrics such as accuracy improvements from 4–20% to 49–88% when utilizing compiled modules instead of string prompts, indicating enhanced performance.&lt;SEP&gt;Metrics such as accuracy percentages on GSM8K, showing improvements from 4–20% to 49–88% when using compiled modules instead of string prompts, indicating performance gains.&lt;SEP&gt;Quantitative measures such as accuracy, BLEU score, or other benchmarks used to assess the quality of generated parallel code.&lt;SEP&gt;Metrics used to assess code generation performance, including pass@k for correctness, and speedup n@k and efficiency n@k for performance of generated code.&lt;SEP&gt;Metrics used to assess the correctness and performance of code generated by language models, including pass@k, speedup n@k, and efficiency n@k.&lt;SEP&gt;Specific metrics designed to evaluate correctness, performance, and robustness of generated code, including novel problem-specific success measures.&lt;SEP&gt;The metrics used to assess the performance of models in code generation and translation tasks, such as correctness and similarity scores.&lt;SEP&gt;Metrics to assess the correctness and quality of AI-generated code, including a simple metric for correctness evaluation.&lt;SEP&gt;Quantitative measures used to assess model performance, interpretability, and domain adaptation success.&lt;SEP&gt;Evaluation metrics are quantitative measures used to assess model safety, accuracy, bias, and alignment during testing and deployment.&lt;SEP&gt;Evaluation metrics include pass@k and BLEU scores to measure model performance and solution correctness.&lt;SEP&gt;Metrics such as pass@k and filtered pass@k used to quantify model performance on code generation tasks.&lt;SEP&gt;Metrics like pass@k and success rate after compilation are used to evaluate the correctness and functional accuracy of generated code.&lt;SEP&gt;Metrics such as pass@k and compile success rates used to quantify the models' code generation accuracy and syntactic correctness.&lt;SEP&gt;Metrics such as pass@k, success rate after compilation, and correctness tests used to assess generated code quality.&lt;SEP&gt;Metrics used to assess the performance of the trained models on code correctness, labeling accuracy, and prediction quality.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb&lt;SEP&gt;chunk-b15d5bb768f451028654d71370cc6879&lt;SEP&gt;chunk-04aecdc2586d2c7966e70e02cac846b0&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-eec372249525c58f53cd0e9c24744ffb&lt;SEP&gt;chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-0696a875ae026175ba36c9e8529f7efd&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Code LLMs">
  <data key="d0">Code LLMs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code Large Language Models (LLMs) are advanced AI models trained to understand and generate programming code, used to improve performance on code-related tasks such as parallel code generation.&lt;SEP&gt;Large Language Models trained specifically for understanding and generating programming code, used to improve performance on code-related tasks such as parallel code generation.&lt;SEP&gt;Language models specifically trained on code datasets to generate or predict code snippets in various programming languages.&lt;SEP&gt;Language models specifically trained on code datasets to generate or predict code snippets, often used in software development and code analysis.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Synthetic Data">
  <data key="d0">Synthetic Data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Artificially generated data used for training models, with data quality impacting model performance.&lt;SEP&gt;Artificially generated data used to augment training datasets, especially when real data is limited or expensive to obtain.&lt;SEP&gt;Artificially generated datasets used to fine-tune models, with their quality impacting the models' ability to generate high-quality parallel code.&lt;SEP&gt;Artificially generated datasets, in this case, code samples created using LLMs to augment training data for better model performance in HPC contexts.&lt;SEP&gt;Synthetic data generated based on open-source code used for fine-tuning models like Magicoder.&lt;SEP&gt;Synthetic data is artificially generated data used for training models, whose quality and quantity impact model performance.&lt;SEP&gt;Synthetic data is artificially generated data used for training models; its quality and quantity are critical factors influencing model performance.&lt;SEP&gt;Synthetic data refers to artificially generated datasets, in this case, code samples created using LLMs to enhance training data quality and diversity for fine-tuning HPC capable code LLMs.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Parallel Code Samples">
  <data key="d0">Parallel Code Samples</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code snippets that perform computations concurrently, used as seed data and for synthetic data generation in training and evaluation.&lt;SEP&gt;Parallel code samples are code snippets that perform computations concurrently, used as seed data and for generating synthetic datasets in the study.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Representation and Quality">
  <data key="d0">Data Representation and Quality</data>
  <data key="d1">Variables</data>
  <data key="d2">Attributes of the training data, such as diversity, accuracy, and structure, that impact the model's learning effectiveness.&lt;SEP&gt;Data representation and quality are critical factors studied to understand their impact on the ability of code LLMs to generate accurate parallel code.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Prompt Construction">
  <data key="d0">Prompt Construction</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Design of input prompts to guide the LLM in generating relevant, diverse, and accurate code outputs.&lt;SEP&gt;Prompt construction involves designing input prompts to guide LLMs in generating diverse and relevant code outputs.&lt;SEP&gt;The process of designing prompts, including positioning, length, and templates, to effectively guide model outputs.&lt;SEP&gt;The process of designing prompts, including positioning, length, templates, and combinations with additional templates or discrete prompts, to improve model performance.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ablation Studies">
  <data key="d0">Ablation Studies</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Ablation studies are experimental approaches that systematically vary specific components or axes of models, datasets, or training strategies to understand their individual contributions to overall model performance.&lt;SEP&gt;Ablation studies are experiments that systematically vary specific components, such as model axes or data parameters, to understand their individual contributions to model performance.&lt;SEP&gt;Ablation studies systematically remove or alter components of the training process to assess their impact on the model's ability to generate parallel code.&lt;SEP&gt;Experimental studies where components such as data, model size, and prompts are systematically varied to assess their impact on code generation performance.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="ParEval Benchmark">
  <data key="d0">ParEval Benchmark</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A standardized benchmark dataset used to evaluate and compare the performance of fine-tuned code LLMs on parallel code generation tasks.&lt;SEP&gt;ParEval is a benchmark dataset used to evaluate the performance of fine-tuned code LLMs on parallel code generation tasks.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Performance Evaluation">
  <data key="d0">Performance Evaluation</data>
  <data key="d1">Results</data>
  <data key="d2">Analysis of how well each language model performs on different task types and parallel programming models, providing insights into strengths, limitations, and areas for improvement.&lt;SEP&gt;Assessment of models based on metrics like pass@1, throughput, and resource consumption to determine effectiveness.&lt;SEP&gt;Assessment of models' ability to generate parallel code, measured against benchmarks like ParEval to determine effectiveness.&lt;SEP&gt;Performance evaluation assesses how well models generate parallel code, influenced by data amount, quality, and model size.&lt;SEP&gt;Performance evaluation involves measuring how well models generate parallel code, assessing the impact of different data amounts, data quality, and model size.&lt;SEP&gt;Performance evaluation measures how well the fine-tuned models generate parallel code, assessed against benchmarks like ParEval.&lt;SEP&gt;The study assesses how well each language model performs on different problem types and models, providing insights into their strengths and limitations in parallel code generation.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4&lt;SEP&gt;chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="State-of-the-art HPC Capable Code LLMs">
  <data key="d0">State-of-the-art HPC Capable Code LLMs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Advanced language models specifically optimized and fine-tuned for high-performance computing code generation tasks.&lt;SEP&gt;These are the advanced language models specifically optimized for high-performance computing code generation, fine-tuned using the HPC-INSTRUCT dataset.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Open-source Codebases">
  <data key="d0">Open-source Codebases</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Open-source codebases like The Stack V2 provide seed snippets in HPC languages used for generating synthetic data and training models.&lt;SEP&gt;Publicly available repositories such as The Stack V2, providing seed code snippets in HPC languages used for synthetic data generation.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Seed Snippets">
  <data key="d0">Seed Snippets</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Initial code samples extracted from open-source repositories, used to inspire diverse outputs during synthetic data generation.&lt;SEP&gt;Seed snippets are initial code samples used to inspire diverse outputs from LLMs during synthetic data generation.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Diversity in Data">
  <data key="d0">Diversity in Data</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Diversity in data, achieved through seed snippets and multiple sample types, improves the robustness and generalization of fine-tuned code LLMs.&lt;SEP&gt;The concept that increasing variability in training data (via seed snippets, multiple sample types) improves model robustness and generalization.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Prompt Construction">
  <data key="d0">Impact of Prompt Construction</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Studying how prompt design affects the diversity, relevance, and accuracy of generated code outputs.&lt;SEP&gt;The study examines how different prompt designs affect the diversity and accuracy of generated code outputs.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Evaluation Against Benchmarks">
  <data key="d0">Evaluation Against Benchmarks</data>
  <data key="d1">Results</data>
  <data key="d2">Models are assessed using the ParEval benchmark to quantify their performance on parallel code generation tasks.&lt;SEP&gt;Models are evaluated on the ParEval benchmark to measure their effectiveness in parallel code generation.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Study of Data and Model Impact">
  <data key="d0">Study of Data and Model Impact</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research employing ablation studies and performance metrics to understand how variations in data, model size, and prompts influence outcomes.&lt;SEP&gt;The research employs ablation studies and performance evaluations to understand how data quality, model size, and prompt design influence model performance.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Implications for Fine-tuning HPC Code LLMs">
  <data key="d0">Implications for Fine-tuning HPC Code LLMs</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Guidelines and insights derived from the study to optimize training practices and improve deployment of HPC-focused code LLMs in real-world scenarios.&lt;SEP&gt;Insights from this research guide best practices for training and deploying HPC-focused code LLMs for real-world applications.</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="generation model">
  <data key="d0">generation model</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A generation model is a type of AI system designed to produce human-like text or code based on input prompts, often used in natural language processing and code synthesis.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Pre-trained Model">
  <data key="d0">Pre-trained Model</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A pre-trained model is an AI model trained on large datasets prior to task-specific fine-tuning, providing foundational knowledge for specialized applications like code generation.&lt;SEP&gt;A pre-trained model refers to a machine learning model that has been trained on large datasets prior to fine-tuning for specific tasks, such as code generation.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="fine-tuning">
  <data key="d0">fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Fine-tuning involves further training the model on curated or human-labeled datasets to enhance specific behaviors like reducing bugs.&lt;SEP&gt;Fine-tuning involves further training the model on curated or human-labeled datasets to enhance specific behaviors, such as reducing bugs and improving helpfulness.&lt;SEP&gt;Fine-tuning is a process of further training a pre-trained model on task-specific data to improve performance on particular applications.&lt;SEP&gt;Fine-tuning is the process of further training a pre-trained model on specific datasets to adapt it for particular tasks, such as improving code synthesis capabilities.&lt;SEP&gt;The process of adapting pre-trained language models to specific tasks or domains, such as HPC code generation, by training on task-specific data to improve performance.&lt;SEP&gt;The process of training a pre-trained model on specific data to adapt it for particular tasks or domains."|&lt;"method&lt;SEP&gt;The process of adapting pre-trained language models to specific datasets through additional training, hyperparameter optimization, and evaluation to improve performance on targeted tasks.&lt;SEP&gt;The process of adapting pre-trained models to the specific dataset by training further with hyperparameter optimization, using tools like HuggingFace and DeepSpeed.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-93a5a4d02febb50f7431a4688bb7fe2f&lt;SEP&gt;chunk-acc067e535432960edbc682652b521e0&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="DeepSeek-Coder">
  <data key="d0">DeepSeek-Coder</data>
  <data key="d1">Models/Architectures</data>
  <data key="d2">DeepSeek-Coder is a family of large language models specialized for code tasks, trained on datasets with a mixture of code and natural language, and utilizing architecture variants like llama and mixture-of-experts (MOE).&lt;SEP&gt;DeepSeek-Coder is a family of state-of-the-art models specialized for code modeling, trained on datasets with code and natural language, utilizing architectures like llama and mixture-of-experts (MOE).</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="code modeling">
  <data key="d0">code modeling</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Code modeling involves designing and training models to understand, generate, and optimize programming code, often evaluated through benchmarks and performance metrics.&lt;SEP&gt;Code modeling involves training models to understand and generate programming code, often evaluated through benchmarks.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="synthetic HPC code data">
  <data key="d0">synthetic HPC code data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Synthetic HPC code data consists of artificially generated code samples used to enhance model training and improve generalization to HPC-specific tasks.&lt;SEP&gt;Synthetic HPC code data consists of artificially generated code samples used to train or evaluate code models, enhancing their generalization capabilities.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="dataset">
  <data key="d0">dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset is a collection of data samples used for training or evaluating models, such as the 277k samples used in fine-tuning.&lt;SEP&gt;A dataset is a collection of data samples, such as code snippets, used for training or evaluating models, exemplified by the 277k samples used for fine-tuning.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="AxoNN">
  <data key="d0">AxoNN</data>
  <data key="d1">Tools</data>
  <data key="d2">AxoNN is a deep learning framework that facilitates parallel training across multiple GPUs, used for fine-tuning large models.&lt;SEP&gt;AxoNN is a parallel deep learning framework built around PyTorch, enabling efficient multi-GPU training of large models like those used in code fine-tuning.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="hyperparameters">
  <data key="d0">hyperparameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Hyperparameters are adjustable parameters in training models, such as batch size, sequence length, and optimizer settings, that influence training performance.&lt;SEP&gt;Hyperparameters are adjustable training parameters such as batch size, sequence length, and optimizer settings that influence model training performance and outcomes.&lt;SEP&gt;Settings such as learning rate, optimizer parameters, batch size, and precision used to control and optimize the training process during fine-tuning.&lt;SEP&gt;Settings such as learning rate, optimizer parameters, batch size, and precision used to control the training process during fine-tuning.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f&lt;SEP&gt;chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="bfloat16">
  <data key="d0">bfloat16</data>
  <data key="d1">Tools</data>
  <data key="d2">bfloat16 is a numerical format that reduces memory usage and accelerates training, used here to optimize large model fine-tuning.&lt;SEP&gt;bfloat16 is a numerical format used to optimize training efficiency and memory usage during model fine-tuning.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="performance hyperparameters">
  <data key="d0">performance hyperparameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Performance hyperparameters include batch size, sequence length, and other settings that directly impact training efficiency and model quality.&lt;SEP&gt;Performance hyperparameters refer to settings like batch size and context window length that affect the training speed and model performance.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="ablation studies">
  <data key="d0">ablation studies</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Ablation studies are experimental procedures where components or parameters of the training process are systematically altered or removed to assess their impact on model performance.&lt;SEP&gt;Ablation studies systematically modify or remove components of a model or training process to assess their impact on performance.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="model architecture">
  <data key="d0">model architecture</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Model architecture defines the structural design of a neural network, such as llama or mixture-of-experts (MOE), affecting its capacity, scalability, and performance.&lt;SEP&gt;Model architecture defines the structure and design of a neural network, such as llama or mixture-of-experts, influencing its capacity and scalability.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="prompt formatting">
  <data key="d0">prompt formatting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Prompt formatting involves designing input prompts to effectively guide the model's output during fine-tuning and inference.&lt;SEP&gt;Prompt formatting involves designing input prompts to effectively guide the model's output during training and inference, crucial for task accuracy.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="performance evaluation">
  <data key="d0">performance evaluation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Performance evaluation assesses how well the fine-tuned models generate accurate, relevant code, typically using benchmarks and metrics.&lt;SEP&gt;Performance evaluation measures how well the fine-tuned models generate accurate, efficient, and relevant code or text, often using benchmarks.&lt;SEP&gt;Performance evaluation assesses the correctness, speedup, and scalability of generated and translated parallel code using benchmarks and metrics.&lt;SEP&gt;Performance evaluation involves systematically measuring and analyzing the runtime, correctness, and other metrics of generated code across different models and hardware configurations.&lt;SEP&gt;Performance evaluation involves systematically measuring and analyzing the runtime, correctness, and other metrics of generated code across different models and hardware setups.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30&lt;SEP&gt;chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="training hyperparameters">
  <data key="d0">training hyperparameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters such as learning rate, optimizer settings, and precision that are tuned to improve model training efficiency and performance.&lt;SEP&gt;Training hyperparameters include batch size, sequence length, optimizer type, and learning rate, which are tuned to optimize model training.&lt;SEP&gt;Training hyperparameters like learning rate, batch size, and sequence length are tuned to optimize model training and performance.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f&lt;SEP&gt;chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="generation">
  <data key="d0">generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Generation refers to the process of producing new data, such as text or code, by a language model based on input prompts, enabling automation and assistance in tasks like coding or content creation.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="model">
  <data key="d0">model</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A model is a computational system, such as a large language model (LLM), trained to understand and generate human-like language or code, used in various AI applications.</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Fine-tuning">
  <data key="d0">Model Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process of updating LLM parameters through additional training on domain-specific data to enhance performance.&lt;SEP&gt;Adjusting the internal parameters of a pre-trained language model using domain-specific data to specialize its responses.&lt;SEP&gt;Fine-tuning involves adjusting a pre-trained language model on specific datasets to improve its performance on targeted tasks, such as code generation.&lt;SEP&gt;Fine-tuning is a transfer learning process where a pre-trained language model is further trained on task-specific data to improve its performance in generating code or other outputs.&lt;SEP&gt;The process of adapting a pre-trained model to specific tasks or data sources to improve performance.&lt;SEP&gt;The process of training pre-trained models on specific datasets to adapt them for particular tasks like parallel code generation, enhancing performance.&lt;SEP&gt;Fine-tuning involves training pre-existing language models on specialized datasets to improve their performance on specific tasks such as code pragma generation or performance prediction.&lt;SEP&gt;The process of adjusting a pre-trained language model on specific datasets to improve task-specific performance, such as reducing model size or improving perplexity.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Parallel Code Data">
  <data key="d0">Parallel Code Data</data>
  <data key="d1">Variables</data>
  <data key="d2">Parallel code data consists of code samples that implement the same functionality across different models or datasets, used to evaluate or enhance model performance in code generation.&lt;SEP&gt;Parallel code data consists of code samples that implement the same functionality across different models or datasets, used to train or evaluate models' ability to generate specific code types.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="MPI Code Samples">
  <data key="d0">MPI Code Samples</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">MPI code samples are specific code snippets involving Message Passing Interface (MPI) used to assess the model's ability to generate parallel programming code.&lt;SEP&gt;MPI code samples are specific code snippets involving Message Passing Interface (MPI), used to assess the model's ability to generate parallel programming code.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Quantity">
  <data key="d0">Data Quantity</data>
  <data key="d1">Variables</data>
  <data key="d2">Data quantity pertains to the amount of training data (e.g., 0k, 2k, 4k, etc.) used to fine-tune models, affecting their learning and generalization.&lt;SEP&gt;Data quantity refers to the amount of training data (e.g., 0k, 2k, 4k, etc.) used for fine-tuning, impacting the model's learning potential.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Trade-off between Data and Quality">
  <data key="d0">Trade-off between Data and Quality</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The trade-off between the amount of data and the quality of data reflects the hypothesis that more data can improve performance up to a point, after which data quality becomes more critical.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Cost of Fine-tuning">
  <data key="d0">Cost of Fine-tuning</data>
  <data key="d1">Limitations</data>
  <data key="d2">Fine-tuning large models, especially at high scales like 16B parameters, incurs significant computational cost, limiting experimental scope.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Data on Performance">
  <data key="d0">Impact of Data on Performance</data>
  <data key="d1">Research Questions</data>
  <data key="d2">The impact of the amount and quality of training data on model performance in code generation tasks, especially MPI code, is a key research question.</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="RX">
  <data key="d0">RX</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">RX is a dataset or a model used in the context of fine-tuning language models for code generation, representing key resources in the study.&lt;SEP&gt;RX refers to a dataset or a model used in the context of fine-tuning language models for code generation.</data>
  <data key="d3">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Llama-3-70B">
  <data key="d0">Llama-3-70B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Llama-3-70B is a large language model with 70 billion parameters, used as one of the models fine-tuned and evaluated in the study.</data>
  <data key="d3">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Mixtral-8x7B">
  <data key="d0">Mixtral-8x7B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Mixtral-8x7B is a large language model with 8x7 billion parameters, included in the models compared for performance.</data>
  <data key="d3">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-I NSTRUCT dataset">
  <data key="d0">HPC-I NSTRUCT dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">HPC-I NSTRUCT dataset is a collection of problem statements and solutions used for training and evaluating code generation models, facilitating research reproducibility.&lt;SEP&gt;HPC-I NSTRUCT dataset is a collection of problem statements and solutions used for training and evaluating high-performance computing code models, supporting reproducibility and benchmarking.&lt;SEP&gt;The HPC-I NSTRUCT dataset is a benchmark dataset used for fine-tuning models to evaluate their performance across different sizes.&lt;SEP&gt;The HPC-I NSTRUCT dataset is a dataset used for fine-tuning models to evaluate their performance across different sizes.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="pass@k">
  <data key="d0">pass@k</data>
  <data key="d1">Results</data>
  <data key="d2">A correctness metric estimating the probability that a model will generate a correct solution within k attempts, used to evaluate code generation accuracy.&lt;SEP&gt;A correctness metric estimating the probability that a model will generate a correct solution within k attempts; commonly used to evaluate code accuracy.&lt;SEP&gt;pass@k indicates the probability that at least one correct answer is generated within k attempts, providing insight into LLMs' performance with multiple tries.&lt;SEP&gt;pass@k indicates the probability that at least one correct answer is produced within k attempts, providing insight into model performance over multiple tries.&lt;SEP&gt;pass@k is a probabilistic metric that estimates the likelihood that an LLM generates at least one correct solution within k attempts, used to evaluate code generation accuracy.&lt;SEP&gt;pass@k is a probabilistic metric that estimates the probability that an LLM generates at least one correct solution within k attempts, used to evaluate code generation accuracy.&lt;SEP&gt;A performance metric indicating the percentage of correct solutions within the top k outputs generated by models, used to assess code generation success.&lt;SEP&gt;Pass@k is a metric indicating the percentage of programs that pass the unit tests within the top k generated samples, used to evaluate model performance.&lt;SEP&gt;Performance metric indicating the percentage of generated programs passing unit tests within top k samples, used to evaluate model accuracy.&lt;SEP&gt;pass@k is a performance metric used to evaluate the success rate of code generation models at different sample sizes, such as pass@1 and pass@100.&lt;SEP&gt;A metric indicating the probability that at least one of k generated samples is correct, based on multiple samples per prompt.&lt;SEP&gt;A metric indicating the probability that at least one of k samples generated by the model is correct, based on multiple samples per prompt.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda&lt;SEP&gt;chunk-b15d5bb768f451028654d71370cc6879&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Benchmark Metrics">
  <data key="d0">Benchmark Metrics</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Metrics such as pass@k are used to assess the efficacy of models in code correctness, considering probabilistic outputs and multiple samples.</data>
  <data key="d3">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code Correctness">
  <data key="d0">Code Correctness</data>
  <data key="d1">Results</data>
  <data key="d2">A measure of whether the generated code functions correctly for the given task, used as a primary evaluation metric.&lt;SEP&gt;Code correctness is the primary measure of success in the evaluation, indicating whether generated solutions meet correctness criteria.&lt;SEP&gt;Code correctness is the primary result measured by the benchmark, indicating whether generated solutions meet correctness criteria.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Code Generation">
  <data key="d0">Parallel Code Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques using LLMs to generate or complete parallel code constructs, such as inserting OpenMP pragmas, to improve performance and developer productivity.&lt;SEP&gt;Techniques utilizing large language models to automatically generate parallel code constructs, such as OpenMP pragmas, to optimize performance and ease development burdens.&lt;SEP&gt;The ability of large language models (LLMs) to generate code in various parallel programming paradigms based on prompts, evaluated through code completion and execution.&lt;SEP&gt;The process of creating code that executes tasks concurrently across multiple processing units to improve performance.&lt;SEP&gt;The process of generating code that can run in parallel, such as MPI code, which is more complex and challenging for models.&lt;SEP&gt;The study investigates how different fine-tuning setups and model sizes impact the ability of LLMs to generate correct parallel code across various problem types and execution models.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Trade-offs">
  <data key="d0">Trade-offs</data>
  <data key="d1">Results</data>
  <data key="d2">Different approaches involve trade-offs in computational cost, ease of implementation, and generalization, with some methods offering performance gains at the expense of complexity or risk of overfitting.&lt;SEP&gt;Different approaches involve trade-offs regarding computational cost, ease of implementation, and generalization, with some methods offering performance gains at increased complexity or overfitting risk.&lt;SEP&gt;Retrieving more documents increases certain performance metrics like Rouge-L but may decrease others like Bleu-1, indicating a trade-off in retrieval strategies.&lt;SEP&gt;The balance between model size, performance, cost, and practicality when deploying code LLMs in real-world scenarios.&lt;SEP&gt;The balancing act between model size, performance, computational cost, and deployment feasibility in practical applications of code LLMs.&lt;SEP&gt;The research explores trade-offs between model size, resource consumption, and performance, informing practical choices for deploying code generation models.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Performance Metrics">
  <data key="d0">Performance Metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics like Pass@1 used to evaluate the success of code generation models on benchmarks.&lt;SEP&gt;Metrics such as Pass@1, throughput, memory requirements, and speed are used to evaluate the models' code generation accuracy and efficiency.&lt;SEP&gt;Metrics such as pass@k are used to assess the efficacy of models in code correctness, considering probabilistic outputs and multiple samples.&lt;SEP&gt;Quantitative measures such as NQ, Rouge-L, Bleu-1 used to evaluate the effectiveness of retrieval strategies and model outputs.&lt;SEP&gt;Metrics such as execution time, resource utilization, and data transfer volume evaluate the effectiveness of the optimization.&lt;SEP&gt;Metrics such as runtime in seconds over multiple runs are used to compare parallel, hand-tuned, and generated code across various computational kernels.&lt;SEP&gt;Performance metrics such as runtime in seconds over multiple runs are used to compare different code versions (parallel, hand-tuned, generated) across various kernels.&lt;SEP&gt;Metrics like pass@1, pass@100, and BLEU scores quantify the success rate and quality of generated solutions.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-aec2ac03d71774b2a191de2c6ebcd45e&lt;SEP&gt;chunk-7d9c04128411fd2962a424d26641c6ad&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Magicoder">
  <data key="d0">Magicoder</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A source code-focused model or framework that emphasizes the importance of source code in language model training, proposed in 2023.&lt;SEP&gt;Magicoder is a fine-tuned version of DeepseekCoder-6.7B model, trained on synthetic open-source code data, aimed at improving code modeling performance.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Phind-V2">
  <data key="d0">Phind-V2</data>
  <data key="d1">Models</data>
  <data key="d2">An LLM model evaluated for efficiency in MPI prompts and translation tasks, with noted performance differences across execution models.&lt;SEP&gt;An LLM modeled for efficiency in MPI prompts and translation tasks, showing performance differences across execution models.&lt;SEP&gt;Phind-V2 is a fine-tuned 34B model based on CodeLlama, trained on a proprietary dataset, recognized as top-performing on the BigCode leaderboard at release.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Gemini-1.5-flash">
  <data key="d0">Gemini-1.5-flash</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Gemini-1.5-flash is a commercial model from Google accessible via API, used for code generation and related tasks.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="GPT-3.5">
  <data key="d0">GPT-3.5</data>
  <data key="d1">Models</data>
  <data key="d2">A large language model used in experiments to evaluate DSPy pipeline performance, especially in reasoning and question answering tasks.&lt;SEP&gt;A state-of-the-art language model by OpenAI, used as a baseline for performance comparison in question answering and reasoning tasks.&lt;SEP&gt;A state-of-the-art language model by OpenAI, used as a benchmark for performance comparison in the study.&lt;SEP&gt;GPT-3.5 is a state-of-the-art commercial large language model from OpenAI, accessible via API, used for advanced language understanding and generation.&lt;SEP&gt;Large language model used to evaluate DSPy pipelines, showing performance improvements over standard prompting.&lt;SEP&gt;A version of OpenAI's language model used for evaluation purposes in the study.&lt;SEP&gt;An advanced LLM with high pass@1 scores for parallel prompts, but generally low efficiency in parallel code execution.&lt;SEP&gt;An advanced LLM with the highest pass@1 scores for parallel prompts but generally low efficiency in parallel code execution.&lt;SEP&gt;An open-source LLM assessed for its ability to generate correct and efficient parallel code across models and tasks.&lt;SEP&gt;Examines the performance of GPT-3.5 in translating and generating parallel code across various models and tasks.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-ed0f2ed4617819fd44b380fe3e3951f0&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GPT-4">
  <data key="d0">GPT-4</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A more advanced version of OpenAI's language model used alongside GPT-3.5 for evaluation.&lt;SEP&gt;A state-of-the-art LLM evaluated for performance, correctness, and scalability in parallel code generation.&lt;SEP&gt;A state-of-the-art large language model capable of complex reasoning, instruction following, and multi-modal tasks.&lt;SEP&gt;A state-of-the-art large language model developed by OpenAI, capable of advanced reasoning and instruction following.&lt;SEP&gt;An advanced OpenAI language model that outperforms GPT-3.5 in accuracy, but pre-trained on a subset of GSM8K training data.&lt;SEP&gt;An advanced OpenAI language model, outperforming previous models with a higher reported accuracy, but pre-trained on a subset of GSM8K training data.&lt;SEP&gt;GPT-4 is a language model evaluated on the ParEval benchmark, with pass@1 scores reported for different problem types and models.&lt;SEP&gt;GPT-4 is a large language model evaluated on the ParEval benchmark, with pass@1 scores reported for different problem types and parallel execution models, used to assess AI performance.&lt;SEP&gt;GPT-4 is an advanced version of OpenAI's large language model, providing improved performance over GPT-3.5 for various tasks.&lt;SEP&gt;Assesses GPT-4's ability to generate efficient and correct parallel code compared to other LLMs.&lt;SEP&gt;GPT-4 is a large language model developed by OpenAI, used here to evaluate code generation and translation capabilities in high-performance computing contexts.&lt;SEP&gt;GPT-4 is a large language model used for evaluating the ability of models to generate code and perform translation tasks in HPC contexts.&lt;SEP&gt;GPT-4 is an advanced language model developed by OpenAI, capable of natural language understanding and generation, with a detailed technical report describing its capabilities.&lt;SEP&gt;The most efficient LLM among those evaluated, achieving the highest speedup and relatively better efficiency in parallel code generation.&lt;SEP&gt;The most efficient LLM in the evaluation, achieving the highest speedup and relatively better efficiency across various parallel code tasks.&lt;SEP&gt;GPT-4 is a large language model developed by OpenAI, designed to follow instructions and perform complex language tasks with high accuracy.&lt;SEP&gt;GPT-4 is a large, advanced language model designed for instruction following, reasoning, and complex language tasks, developed by OpenAI.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7&lt;SEP&gt;chunk-727ea750122a5bed30ad781918446611&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Results of Ablation Studies">
  <data key="d0">Results of Ablation Studies</data>
  <data key="d1">Results</data>
  <data key="d2">The results of ablation studies analyze how different training configurations and data affect the performance of code LLMs, especially in parallel code generation.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Parallel Code Generation Performance">
  <data key="d0">Parallel Code Generation Performance</data>
  <data key="d1">Results</data>
  <data key="d2">Parallel code generation performance measures how effectively models generate code in parallel, evaluated through metrics like Pass@1 on benchmarks.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Choice of Base Model and Instruction Masking">
  <data key="d0">Choice of Base Model and Instruction Masking</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">This investigates how the choice of base model and use of instruction masking impact code generation performance.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Fine-Tuning Data Quantity and Quality">
  <data key="d0">Impact of Fine-Tuning Data Quantity and Quality</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">This examines how the amount and quality of parallel code data used for fine-tuning influence the models' code generation capabilities.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="MPI Code Generation">
  <data key="d0">MPI Code Generation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">MPI (Message Passing Interface) code generation performance assesses the models' ability to generate MPI parallel programming code, which is typically more challenging.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Sizes (1.3B and 6.7B)">
  <data key="d0">Model Sizes (1.3B and 6.7B)</data>
  <data key="d1">Variables</data>
  <data key="d2">Model size affects the impact of training data quantity on performance, with smaller models showing more benefit from increased data.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Training Data Amount (0k to 12k MPI samples)">
  <data key="d0">Training Data Amount (0k to 12k MPI samples)</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of MPI training samples used for fine-tuning influences the models' MPI code generation performance, with diminishing returns on larger models.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Fine-Tuning Configurations">
  <data key="d0">Fine-Tuning Configurations</data>
  <data key="d1">Tools</data>
  <data key="d2">Different fine-tuning strategies, such as using masked or unmasked gradients and instruct vs. base models, are tools to optimize model performance.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code Benchmarks">
  <data key="d0">Code Benchmarks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">ParEval is a benchmark used to evaluate parallel code generation performance of models, including MPI code.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Open-Source Code Data">
  <data key="d0">Open-Source Code Data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Open-source code data from The Stack V2 used for pre-training models like StarCoder2.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Proprietary Dataset">
  <data key="d0">Proprietary Dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A proprietary dataset used to fine-tune Phind-V2, enhancing its performance.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="BigCode Leaderboard">
  <data key="d0">BigCode Leaderboard</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark leaderboard where Phind-V2 was the top model at the time of its release.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Masked Gradients">
  <data key="d0">Masked Gradients</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A fine-tuning technique where gradients are masked during training, tested for its impact on performance.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Unmasked Gradients">
  <data key="d0">Unmasked Gradients</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A fine-tuning technique where gradients are not masked, used as a comparison to masked approaches.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Instruct vs. Base Models">
  <data key="d0">Instruct vs. Base Models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Different model variants, where instruct models are fine-tuned for instruction following, and base models are the original versions.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Diminishing Returns">
  <data key="d0">Diminishing Returns</data>
  <data key="d1">Results</data>
  <data key="d2">Observation that increasing training data yields less performance gain beyond a certain point, especially for larger models.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Training Configuration Impact">
  <data key="d0">Training Configuration Impact</data>
  <data key="d1">Results</data>
  <data key="d2">Analysis of how different fine-tuning strategies and data sizes influence model performance.</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Training Data">
  <data key="d0">Training Data</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Data used to train models that contains social biases and encoded class representations, influencing model outputs.&lt;SEP&gt;Public source code repositories used to train Codex, containing patterns and potential sensitive data.&lt;SEP&gt;The dataset of public repositories used to train GitHub Copilot, influencing suggestion quality depending on language and data volume.&lt;SEP&gt;The datasets used for training models, including The Stack and other code corpora, which influence model capabilities and biases.&lt;SEP&gt;Training data refers to datasets used to fine-tune language models, impacting their ability to learn specific tasks and influencing performance, overfitting, and data quality.&lt;SEP&gt;Training data refers to the datasets used to fine-tune language models, impacting their performance and overfitting susceptibility.&lt;SEP&gt;Training data comprises the datasets used to train models, directly affecting their behavior, biases, and alignment with user needs.&lt;SEP&gt;Large datasets of C/C++ code, including open-source repositories and code competitions, used to train models for performance prediction.&lt;SEP&gt;The dataset used during the model's training phase, comprising data on which the model is fine-tuned and evaluated.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3&lt;SEP&gt;chunk-96b489f22f60397ff887486ccf77f457&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-10b08670a9cf75866c6b05fa5b5cfc12&lt;SEP&gt;chunk-eec372249525c58f53cd0e9c24744ffb&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Parallel Execution Model">
  <data key="d0">Parallel Execution Model</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A computational approach that allows parallel processing to improve performance and efficiency in code generation tasks.&lt;SEP&gt;A computational approach that enables multiple processes to run simultaneously, improving efficiency in code generation and performance.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Performance">
  <data key="d0">Performance</data>
  <data key="d1">Results</data>
  <data key="d2">Performance refers to the efficiency and speed of computational applications, often measured by speedups and overhead reductions, especially relevant for scientific and benchmark applications.&lt;SEP&gt;The effectiveness of code LLMs measured by metrics like Pass@1, indicating their ability to generate correct code.&lt;SEP&gt;The measure of a model's effectiveness in generating correct or high-quality code, assessed through metrics like Pass@1, reflecting success rates in code generation tasks.&lt;SEP&gt;The effectiveness of different prompting strategies in enabling LLMs to perform well on various reasoning and domain-specific tasks.&lt;SEP&gt;The measurable effectiveness of different prompting strategies in enabling LLMs to successfully perform various reasoning and domain-specific tasks.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc&lt;SEP&gt;chunk-daac5179ef8fa77fe775da37eb1276f3&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MPI Fine-tuning Data">
  <data key="d0">MPI Fine-tuning Data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data specifically used to fine-tune models for MPI code generation, affecting model performance and overfitting.&lt;SEP&gt;Synthetic or real datasets used to adapt models specifically for MPI code generation, with data quality influencing model performance.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Knowledge Distillation">
  <data key="d0">Knowledge Distillation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A process to transfer knowledge from a large model to a smaller one, often used for domain-specific adaptation.&lt;SEP&gt;A training technique where a large, high-performing 'teacher' model guides the training of a smaller 'student' model to transfer knowledge and improve efficiency.&lt;SEP&gt;A training technique where a larger 'teacher' model guides a smaller 'student' model, used to improve performance while managing costs.&lt;SEP&gt;Knowledge Distillation involves transferring knowledge from a large, pre-trained model to a smaller model to reduce inference latency and improve efficiency.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Overfitting">
  <data key="d0">Overfitting</data>
  <data key="d1">Limitations</data>
  <data key="d2">A phenomenon where a model learns noise in the training data, leading to decreased generalization performance, especially in smaller models.&lt;SEP&gt;A phenomenon where models learn noise or specific patterns in training data too well, leading to poor generalization on unseen data, especially in smaller models.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Benchmark">
  <data key="d0">Benchmark</data>
  <data key="d1">Tools</data>
  <data key="d2">A collection of prompts designed to evaluate LLM performance on parallel code generation across multiple problem types and execution models.&lt;SEP&gt;A collection of prompts designed to evaluate LLM performance on parallel code generation across multiple problem types and models.&lt;SEP&gt;A standardized suite of tests (e.g., ParEval) used to evaluate and compare code generation performance of models.&lt;SEP&gt;Standardized evaluation suite (e.g., ParEval) used to assess and compare the performance of different code generation models across various problem types.&lt;SEP&gt;A standard test or set of tests used to evaluate the performance of models on specific tasks, such as code generation benchmarks.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Model Training">
  <data key="d0">Model Training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of adjusting model parameters using training data to improve code generation capabilities.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Comparison">
  <data key="d0">Model Comparison</data>
  <data key="d1">Results</data>
  <data key="d2">Analysis contrasting the performance of models with different sizes, data sources, and training strategies, highlighting diminishing returns and data quality effects.&lt;SEP&gt;Codex outperforms free models like Tabnine, which achieves lower pass rates, indicating the advantage of larger models.&lt;SEP&gt;Evaluation of multiple pre-trained large language models, including the newly introduced HPC-Coder, on their effectiveness in code completion, parallelization, and performance prediction tasks.&lt;SEP&gt;Evaluation of several pre-trained large language models, including the newly introduced HPC-Coder, on their ability to perform HPC-related tasks such as code completion and performance prediction.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-4a6314582e8689e73a9ecc2fc735a9ad&lt;SEP&gt;chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Data Source">
  <data key="d0">Data Source</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The origin of synthetic data (e.g., Llama, DBRX, Mixtral, Gemini) used for training models, affecting the quality and performance outcomes.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Size Impact">
  <data key="d0">Model Size Impact</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigating how increasing model size (from 1.3B to 16B parameters) influences the ability to learn from synthetic data and the resulting code generation performance.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Performance Plateau">
  <data key="d0">Model Performance Plateau</data>
  <data key="d1">Results</data>
  <data key="d2">Observation that performance gains diminish as model size increases beyond a certain point (e.g., from 6.7B to 16B), approaching the performance of larger foundation models like GPT-3.5 and GPT-4.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="State-of-the-art Models">
  <data key="d0">State-of-the-art Models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Advanced models like HPC-Coder-V2-16B, GPT-3.5, GPT-4 designed for high performance in parallel code generation.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Performance Trends">
  <data key="d0">Model Performance Trends</data>
  <data key="d1">Results</data>
  <data key="d2">Performance improves significantly from smaller to medium-sized models but plateaus or marginally improves with larger models due to knowledge distillation limits.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Application">
  <data key="d0">Application</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using optimized, high-performance code LLMs for parallel code generation tasks in HPC environments, with considerations for model size and data quality.</data>
  <data key="d3">chunk-4a6314582e8689e73a9ecc2fc735a9ad</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="ParEval benchmark">
  <data key="d0">ParEval benchmark</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A benchmark suite used to evaluate the code generation performance of various models across different problem types and parallel execution models in HPC.&lt;SEP&gt;A benchmarking tool used to evaluate the performance of the fine-tuned HPC code LLMs in generating parallel code.&lt;SEP&gt;The ParEval benchmark suite is used to evaluate the performance of code generation models across different problem types and execution models.&lt;SEP&gt;The ParEval benchmark is a set of prompts and problems designed to evaluate how well LLMs generate parallel code across different models and problem types.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Generation Performance">
  <data key="d0">Code Generation Performance</data>
  <data key="d1">Results</data>
  <data key="d2">Copilot helps generate code faster but with lower quality compared to human programmers, especially in terms of correctness and security.&lt;SEP&gt;The performance of HPC-Coder-V2 across problem types and execution models, showing higher performance compared to previous models, with specific strengths and weaknesses depending on problem structure and parallelization model.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3&lt;SEP&gt;chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Problem Types">
  <data key="d0">Problem Types</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">Different categories of computational problems, such as sparse linear algebra, geometric problems, dense linear algebra, stencil, and data transformation, used to evaluate model performance.&lt;SEP&gt;Different computational problem categories evaluated, including serial, parallel, and hybrid types.&lt;SEP&gt;Different problem types such as serial, with various problem categories evaluated for performance.&lt;SEP&gt;Different classes of computational problems (transform, dense, sparse, graph, etc.) used to evaluate LLM performance in parallel code generation.&lt;SEP&gt;Different classes of computational tasks such as transform, search, reduce, and pass@1 problems used to evaluate model performance.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611&lt;SEP&gt;chunk-aec2ac03d71774b2a191de2c6ebcd45e&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Execution Models">
  <data key="d0">Execution Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Different code execution paradigms like serial, OpenMP, CUDA, HIP, Kokkos, MPI, and MPI+OpenMP, used to assess model performance in parallel computing contexts.&lt;SEP&gt;Execution models specify different paradigms for parallel and distributed programming, such as serial, OpenMP, MPI, Kokkos, CUDA, and HIP, used in code generation tasks.&lt;SEP&gt;Frameworks such as OpenMP, MPI, Kokkos, CUDA, and HIP used to implement parallel computing strategies in code.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Fine-tuning Strategies">
  <data key="d0">Fine-tuning Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Data and training techniques used to improve the models' ability to generate parallel code efficiently and accurately.&lt;SEP&gt;Techniques such as adapter-based, neural, low-rank, and instruction-based fine-tuning used to adapt LLMs to specific domains.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25&lt;SEP&gt;chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Comparison with Other Models">
  <data key="d0">Comparison with Other Models</data>
  <data key="d1">Results</data>
  <data key="d2">HPC-Coder-V2 models outperform some existing models like StarCoder2-3B and Phind-V2-34B in parallel code generation, demonstrating competitive performance and efficiency.&lt;SEP&gt;Models like GPT-Neo and GPT-J outperform previous GPT systems in qualitative programming evaluations, approaching Codex performance.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Trade-offs in Model Design">
  <data key="d0">Trade-offs in Model Design</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigation into balancing model size, speed, memory use, and accuracy for practical deployment in HPC environments.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Related Literature">
  <data key="d0">Related Literature</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Discussion of prior work on code LLMs for HPC, including the development, fine-tuning, and application of specialized models.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="code generation performance">
  <data key="d0">code generation performance</data>
  <data key="d1">Results</data>
  <data key="d2">The measured effectiveness of HPC-Coder-V2 in generating correct and efficient code across different problem types and execution models, showing higher performance than previous models.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="problem types">
  <data key="d0">problem types</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Different categories of computational problems such as sparse linear algebra, geometric problems, dense linear algebra, stencil, and data transformation, used to evaluate model performance.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="execution models">
  <data key="d0">execution models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Execution models such as serial, OpenMP, Kokkos, MPI, CUDA, HIP define how parallel code is executed, influencing LLM training and evaluation.&lt;SEP&gt;Parallel code execution paradigms including serial, OpenMP, CUDA, HIP, Kokkos, MPI, and MPI+OpenMP, used to test the models' ability to generate code in various HPC environments.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model sizes">
  <data key="d0">model sizes</data>
  <data key="d1">Variables</data>
  <data key="d2">Different sizes of models (e.g., 1.3B, 6.7B, 16B) that influence performance, with larger models generally performing better except on specific problem types like geometric problems.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="performance metrics">
  <data key="d0">performance metrics</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics like pass@1, speedup n@k, and efficiency n@k are used to quantify the correctness, performance, and scalability of code generated by LLMs.&lt;SEP&gt;Metrics such as runtime, pass@1, accuracy, and correctness are used as evidence to evaluate the quality of generated code.&lt;SEP&gt;Pass@1 scores, speedup, efficiency, used to quantitatively evaluate LLMs' code generation and translation performance.&lt;SEP&gt;Performance metrics include measures such as runtime, pass@1 scores, and correctness checks that evaluate the efficiency and accuracy of generated code.&lt;SEP&gt;Performance metrics include measures such as runtime, pass@1 scores, and correctness checks, which evaluate the quality and effectiveness of generated code.&lt;SEP&gt;Performance metrics include pass@1, efficiency@1, speedup@1, and scalability measures used to evaluate generated code.&lt;SEP&gt;Quantitative measures such as Pass@1, throughput, memory requirements, and speed, used to evaluate the accuracy and efficiency of code generation.&lt;SEP&gt;Quantitative measures used to evaluate the effectiveness of models, such as accuracy, F1 score, or task-specific scores."|&lt;"variable</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-aec2ac03d71774b2a191de2c6ebcd45e&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-0263fe0a192189f09d40327b5d776e30&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="fine-tuning strategies">
  <data key="d0">fine-tuning strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Data collection, training procedures, and techniques applied to improve the models' ability to generate parallel and correct code efficiently.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="comparison with other models">
  <data key="d0">comparison with other models</data>
  <data key="d1">Results</data>
  <data key="d2">Performance comparison showing HPC-Coder-V2 models outperform some existing models like StarCoder2-3B and Phind-V2-34B in parallel code generation, indicating competitiveness.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="trade-offs in model design">
  <data key="d0">trade-offs in model design</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigation into how model size, speed, memory, and accuracy balance to optimize practical deployment and usability in HPC contexts.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="related work">
  <data key="d0">related work</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Literature review discussing prior research on code LLMs for HPC, fine-tuning of specialized models, and their applications.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="performance on problem types">
  <data key="d0">performance on problem types</data>
  <data key="d1">Results</data>
  <data key="d2">Models perform better on dense, structured problems such as dense linear algebra, stencil, and data transformation, but struggle with sparse, unstructured problems like sparse linear algebra and geometric problems, with performance varying by model size.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="performance on execution models">
  <data key="d0">performance on execution models</data>
  <data key="d1">Results</data>
  <data key="d2">Models perform best on serial and OpenMP code, with decreasing performance on GPU (CUDA, HIP) and MPI-based models, indicating challenges in generating complex parallel code.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="model size effects">
  <data key="d0">model size effects</data>
  <data key="d1">Variables</data>
  <data key="d2">Larger models (e.g., 16B) generally outperform smaller ones (e.g., 1.3B, 6.7B) across most problem types, but may perform worse on specific problems like geometric ones, showing size-performance trade-offs.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="speed and memory efficiency">
  <data key="d0">speed and memory efficiency</data>
  <data key="d1">Results</data>
  <data key="d2">The models are evaluated for throughput, required memory, and speed, with larger models requiring more resources but providing better performance, and smaller models offering faster inference with acceptable accuracy.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="model comparison">
  <data key="d0">model comparison</data>
  <data key="d1">Results</data>
  <data key="d2">HPC-Coder-V2-6.7B outperforms larger models like Phind-V2-34B in parallel code generation while being faster and more memory-efficient; HPC-Coder-V2-1.3B is the fastest and most resource-efficient, outperforming comparable models in its size class.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="training and data strategies">
  <data key="d0">training and data strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques used to enhance model performance, including high-quality fine-tuning data tailored for parallel code generation.</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="limitations">
  <data key="d0">limitations</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Challenges include reduced performance on geometric problems as model size increases and difficulties in generating MPI code, highlighting areas for further improvement.&lt;SEP&gt;Current LLMs struggle with generating efficient MPI code and unstructured problems, and often produce code with poor speedup and efficiency.&lt;SEP&gt;Current constraints include the inability to assign tasklets explicitly to specific cores in some models, which affects fine-grained optimization and load balancing.&lt;SEP&gt;Current constraints include the inability to explicitly assign tasklets to specific cores in some models, affecting fine-grained optimization and load balancing.&lt;SEP&gt;Limitations refer to current constraints in the code generator, such as suboptimal MPI utilization and memory overhead.&lt;SEP&gt;Limitations refer to the constraints, shortcomings, or boundaries that affect the potential and application of the new technology, including issues related to quality, datasets, and reliance.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-b943bff32a36cd0ce9ab43893da92b5b&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-aec2ac03d71774b2a191de2c6ebcd45e&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC code LLMs">
  <data key="d0">HPC code LLMs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Large language models specialized for high-performance computing tasks, designed to generate or assist in parallel code development.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC tasks">
  <data key="d0">HPC tasks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">High-performance computing activities involving complex computations, parallel processing, and optimized code execution.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="synthetic data">
  <data key="d0">synthetic data</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Artificially generated data used to augment training datasets for improving model quality, especially in data-limited scenarios.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="model performance metrics">
  <data key="d0">model performance metrics</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics such as pass@1 and pass@k used to quantify the accuracy and robustness of code generation models.&lt;SEP&gt;Quantitative measures such as pass@1, throughput, and memory usage used to evaluate the effectiveness of HPC LLMs.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="data quality">
  <data key="d0">data quality</data>
  <data key="d1">Variables</data>
  <data key="d2">Challenges related to the quality of training data, which can limit the effectiveness of fine-tuning HPC code models.&lt;SEP&gt;The quality of training data, including accuracy and relevance, impacting the performance of fine-tuned models.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="parallel code generation">
  <data key="d0">parallel code generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Parallel code generation involves creating code that can execute across multiple processors or cores, requiring specific models, tools, and evaluation techniques.&lt;SEP&gt;The process of automatically generating code that executes tasks concurrently across multiple processing units, assessed here through various models and metrics.&lt;SEP&gt;The process of generating code that executes tasks concurrently across multiple processing units, evaluated here through various models and metrics.&lt;SEP&gt;The use of LLMs to generate code that runs efficiently in parallel computing environments, reducing development time and improving performance.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HPC instruction dataset">
  <data key="d0">HPC instruction dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset, HPC-INSTRUCT, created from synthetic and open-source data to facilitate model fine-tuning for HPC tasks.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="model throughput">
  <data key="d0">model throughput</data>
  <data key="d1">Variables</data>
  <data key="d2">The speed at which a model can generate code, measured in tokens per second, influencing practical usability in HPC workflows.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="prompt configuration">
  <data key="d0">prompt configuration</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The setup and design of prompts used to elicit desired outputs from language models during fine-tuning and evaluation.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="model size">
  <data key="d0">model size</data>
  <data key="d1">Variables</data>
  <data key="d2">Model size indicates the number of parameters in the model, affecting its capabilities, risks of misalignment, and potential for harmful outputs.&lt;SEP&gt;Model size refers to the number of parameters in the AI model, which does not show a clear trend in reducing insecure outputs according to the study.&lt;SEP&gt;Model size refers to the number of parameters in the model; however, no consistent trend shows larger models reducing insecure outputs.&lt;SEP&gt;The number of parameters in a language model (e.g., 1.3B, 6.7B, 34B), affecting performance, resource requirements, and accuracy.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2&lt;SEP&gt;chunk-eec372249525c58f53cd0e9c24744ffb&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="pass@1">
  <data key="d0">pass@1</data>
  <data key="d1">Results</data>
  <data key="d2">A performance metric indicating the percentage of correct outputs on the first attempt, used to evaluate code generation accuracy.&lt;SEP&gt;pass@1 is a metric indicating the probability that the LLM generates a correct code output on the first attempt, used to assess code correctness.&lt;SEP&gt;pass@1 is a metric indicating the probability that the LLM generates a correct code output on the first attempt, used to evaluate correctness.&lt;SEP&gt;pass@1 measures the accuracy of large language models (LLMs) in generating correct parallel code within one attempt, serving as a key performance metric.&lt;SEP&gt;pass@1 measures the percentage of correct answers generated by large language models (LLMs) in a single attempt, serving as a primary performance metric in the evaluation.&lt;SEP&gt;pass@1 measures the percentage of successful code generations when selecting the top sample, indicating the model's precision.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="High-Quality Fine-Tuning Data">
  <data key="d0">High-Quality Fine-Tuning Data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">High-quality data used to train or fine-tune models, crucial for achieving optimal model performance without compromising memory or throughput.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Memory and Throughput">
  <data key="d0">Memory and Throughput</data>
  <data key="d1">Variables</data>
  <data key="d2">Key performance metrics representing the model's resource efficiency and processing speed, respectively, affected by data quality and model design.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC and Parallel Code">
  <data key="d0">HPC and Parallel Code</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">High-performance computing activities involving parallel processing, requiring specialized code generation and optimization.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code LLMs for HPC">
  <data key="d0">Code LLMs for HPC</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Large language models tailored for high-performance computing tasks, including code generation and optimization.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Fine-tuning Specialized Code LLMs">
  <data key="d0">Fine-tuning Specialized Code LLMs</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for adapting language models to specific programming domains or tasks, such as biological or hardware description languages.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-INSTRUCT Dataset">
  <data key="d0">HPC-INSTRUCT Dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset created from synthetic and open-source parallel code to facilitate model fine-tuning for HPC tasks.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Performance Metrics">
  <data key="d0">Model Performance Metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics such as pass@1, indicating the percentage of correct code completions, are used to compare models like CodeLlama, StarCoder, GPT-3.5, and GPT-4.&lt;SEP&gt;Quantitative measures such as pass@1, throughput, and accuracy used to evaluate and compare model effectiveness in code generation.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Prompt Configuration">
  <data key="d0">Prompt Configuration</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Design and setup of prompts used during model training and evaluation to elicit desired outputs.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Pass@1">
  <data key="d0">Pass@1</data>
  <data key="d1">Results</data>
  <data key="d2">A performance metric indicating the percentage of correct first-attempt outputs in code generation tasks.&lt;SEP&gt;A performance metric indicating the percentage of correct top-1 predictions made by the model on a given task.</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Model Throughput">
  <data key="d0">Model Throughput</data>
  <data key="d1">Variables</data>
  <data key="d2">Rate at which a model generates tokens per second, affecting practical usability in real-time HPC code synthesis.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Fine-tuning Approach">
  <data key="d0">Fine-tuning Approach</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Strategies and procedures for adapting general LLMs to specialized tasks like HPC code generation.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Architecture">
  <data key="d0">Model Architecture</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Underlying design of the language model, such as GPT-2 architecture or newer models, influencing capabilities and performance.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Resource Requirements">
  <data key="d0">Model Resource Requirements</data>
  <data key="d1">Variables</data>
  <data key="d2">Memory and computational resources needed for training and inference, impacted by model size and data quality.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Collection Methods">
  <data key="d0">Data Collection Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Processes used to gather or generate training data, including synthetic data generation and scraping from repositories.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Generalization">
  <data key="d0">Model Generalization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ability of a trained model to perform well on unseen data or tasks beyond its training set.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model Evaluation Benchmarks">
  <data key="d0">Model Evaluation Benchmarks</data>
  <data key="d1">Results</data>
  <data key="d2">Standardized tests like HumanEval used to measure and compare code generation performance.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data Limitations">
  <data key="d0">Data Limitations</data>
  <data key="d1">Limitations</data>
  <data key="d2">Challenges such as insufficient data quantity or quality that hinder effective model training or fine-tuning.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Synthetic Data Generation Techniques">
  <data key="d0">Synthetic Data Generation Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approaches for creating artificial training data, including semi-synthetic methods and LLM-generated data, to overcome data scarcity.</data>
  <data key="d3">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2-1.3B">
  <data key="d0">HPC-Coder-V2-1.3B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A state-of-the-art HPC code language model fine-tuned on the HPC-I NSTRUCT dataset, evaluated for parallel code generation performance.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2-6.7B">
  <data key="d0">HPC-Coder-V2-6.7B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A larger HPC code language model, fine-tuned on the HPC-I NSTRUCT dataset, evaluated for improved parallel code generation capabilities.&lt;SEP&gt;HPC-Coder-V2-6.7B is a computational model or system evaluated for performance across various problem types and execution models, used in high-performance computing benchmarks.&lt;SEP&gt;HPC-Coder-V2-6.7B is a computational model or system evaluated for performance across various problem types and execution models.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2-16B">
  <data key="d0">HPC-Coder-V2-16B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An even larger HPC code language model, fine-tuned on the HPC-I NSTRUCT dataset, assessed for performance and efficiency in parallel code generation.&lt;SEP&gt;HPC-Coder-V2-16B is a computational system assessed similarly to the 6.7B version, with performance metrics reported.&lt;SEP&gt;HPC-Coder-V2-16B is a computational system similar to the 6.7B version, assessed for performance on multiple problem types and execution models in high-performance computing contexts.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model fine-tuning">
  <data key="d0">Model fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of training the language models on the HPC-I NSTRUCT dataset with various configurations to improve their code generation capabilities.&lt;SEP&gt;Training models on domain-specific datasets like HPC code to enhance their ability to generate and analyze HPC applications.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Synthetic data">
  <data key="d0">Synthetic data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data generated from language models and open-source parallel code, used for training and fine-tuning the HPC code LLMs.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Parallel code generation">
  <data key="d0">Parallel code generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The activity of generating code that can execute tasks concurrently in high-performance computing environments, a primary focus of the study.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data quality">
  <data key="d0">Data quality</data>
  <data key="d1">Variables</data>
  <data key="d2">The measure of the relevance and accuracy of the fine-tuning data, which significantly impacts the performance of the code LLMs.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model size">
  <data key="d0">Model size</data>
  <data key="d1">Variables</data>
  <data key="d2">Model size, such as 12B or 300M parameters, influences the performance of models like GPT-J and Codex in solving programming problems.&lt;SEP&gt;The number of parameters in a model (e.g., 12B, 300M) that impacts its capacity and performance in code generation tasks.&lt;SEP&gt;The number of parameters in the language models (small, medium, large), influencing the performance gains and diminishing returns observed.&lt;SEP&gt;The size of the models (small, medium, large) affecting performance and diminishing returns.&lt;SEP&gt;The number of parameters in a model (e.g., GPT-2, GPT-Neo, PolyCoder) affecting its capacity to learn language patterns.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Training data amount">
  <data key="d0">Training data amount</data>
  <data key="d1">Variables</data>
  <data key="d2">The quantity of data used during fine-tuning, affecting the models' ability to generate parallel code effectively.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model performance">
  <data key="d0">Model performance</data>
  <data key="d1">Results</data>
  <data key="d2">Model performance indicates how well RAG models perform on knowledge-intensive tasks, surpassing previous architectures.&lt;SEP&gt;The effectiveness of the models in generating parallel code, evaluated on benchmarks like ParEval, with medium-sized models showing significant improvements.&lt;SEP&gt;The models evaluated achieved top performance in parallel code generation among open-source options, with improved speed and efficiency.&lt;SEP&gt;The ability of models like Codex to generate correct code, measured by pass@k, with improvements seen through fine-tuning and multiple sampling.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-4bb8bb2fc231e52a13ed0e91512e55eb&lt;SEP&gt;chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Insights">
  <data key="d0">Insights</data>
  <data key="d1">Results</data>
  <data key="d2">Key findings about the impact of instruction masking, data quality, model size, and training data volume on model performance.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Open-source models">
  <data key="d0">Open-source models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">AI models whose source code is publicly available, including Phind-V2, StarCoderBase, and CodeLlama, compared against closed-source models.&lt;SEP&gt;AI models with publicly available source code such as Phind-V2, StarCoderBase, and CodeLlama, compared against closed-source models.&lt;SEP&gt;Large language models that are publicly available for use and modification, such as Llama 2.&lt;SEP&gt;The HPC code LLMs evaluated for speed, memory usage, and parallel code generation capabilities, compared to other models.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Benchmark evaluation">
  <data key="d0">Benchmark evaluation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of assessing model performance using benchmarks like ParEval to compare capabilities in parallel code generation.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model efficiency">
  <data key="d0">Model efficiency</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics and attributes related to the computational and performance efficiency of models.&lt;SEP&gt;Speed and memory usage of models, with the study highlighting faster and less memory-intensive models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Research implications">
  <data key="d0">Research implications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The findings are valuable for HPC developers and future research into code LLMs for high-performance computing.</data>
  <data key="d3">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code llama">
  <data key="d0">Code llama</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Open foundation models for code, representing large-scale pre-trained language models designed specifically for programming tasks, introduced in 2023.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Gpt-4o system card">
  <data key="d0">Gpt-4o system card</data>
  <data key="d1">Tools</data>
  <data key="d2">A documentation or technical report describing the GPT-4O system, released in 2024, detailing its capabilities and features.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Knowledge distillation of large language models">
  <data key="d0">Knowledge distillation of large language models</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A survey examining methods to transfer knowledge from large language models to smaller or more efficient models, aiming to improve performance and efficiency, published in 2024.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Big code models leaderboard">
  <data key="d0">Big code models leaderboard</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmarking platform on Hugging Face for large code models, providing performance metrics.&lt;SEP&gt;A leaderboard hosted on Hugging Face that benchmarks various large code models, providing performance metrics and comparisons, active in 2023.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Deepseek-coder">
  <data key="d0">Deepseek-coder</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large language model focused on code understanding and intelligence, studied in 2024 for its impact on programming and code analysis tasks.&lt;SEP&gt;A large language model focused on programming and code intelligence, examined in 2024 for its impact on code understanding.&lt;SEP&gt;A large language model specialized in code intelligence, introduced in 2024, aiming to enhance code understanding and generation.&lt;SEP&gt;Deepseek-coder is a large language model designed for code intelligence, particularly in understanding and generating code using natural language processing techniques.&lt;SEP&gt;Deepseek-coder is a large language model designed for meeting the challenges of code intelligence, integrating natural language processing with programming tasks.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Deepseek-coder-v2">
  <data key="d0">Deepseek-coder-v2</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An advanced version of Deepseek-coder that aims to break barriers of closed-source models in code intelligence, released in 2024.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Llama 2">
  <data key="d0">Llama 2</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An open foundation and fine-tuned chat model designed for natural language processing, emphasizing large language model architecture and fine-tuning methods.&lt;SEP&gt;Llama 2 is an open foundation and fine-tuned chat model developed for natural language processing tasks, emphasizing large language model architecture and fine-tuning methodologies.&lt;SEP&gt;Open foundation and fine-tuned chat models developed in 2023, serving as open-source large language models for various applications.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Efficient large scale language modeling with mixtures of experts">
  <data key="d0">Efficient large scale language modeling with mixtures of experts</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique involving the use of mixture of experts to scale large language models efficiently, published in 2021.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Wizardcoder">
  <data key="d0">Wizardcoder</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A model designed to empower code large language models using evol-instruct, introduced in 2023, enhancing code generation capabilities.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Exploiting sparsity in pruned neural networks">
  <data key="d0">Exploiting sparsity in pruned neural networks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to optimize large model training by leveraging sparsity in neural networks, presented at IPDPS 2023.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="PyTorch">
  <data key="d0">PyTorch</data>
  <data key="d1">Tools</data>
  <data key="d2">A high-performance deep learning library used for building and training neural networks, developed with an imperative programming style, released in 2019.&lt;SEP&gt;A high-performance deep learning library used for developing and training neural models.&lt;SEP&gt;A high-performance deep learning library used for developing and training neural network models.&lt;SEP&gt;Deep learning library used as the backend for inference of language models, facilitating model execution on GPUs.&lt;SEP&gt;PyTorch is an open-source deep learning library emphasizing flexibility and high performance, widely used for training neural networks.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-d1ed35f0489d99675c43fbbee04d61fd&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Adam optimizer with fixed weight decay">
  <data key="d0">Adam optimizer with fixed weight decay</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An optimization technique for training neural networks that involves fixing weight decay regularization, proposed in 2017.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="J. Bitton">
  <data key="d0">J. Bitton</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of a publication on foundation models for code, contributing to the field of artificial intelligence and machine learning.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="M. Bhatt">
  <data key="d0">M. Bhatt</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in research on foundation models for code, supporting advancements in AI for programming.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. C. Ferrer">
  <data key="d0">C. C. Ferrer</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author contributing to foundational research on code models, enhancing understanding of AI in coding.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A. Grattafiori">
  <data key="d0">A. Grattafiori</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in the development and analysis of open foundation models for code.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="W. Xiong">
  <data key="d0">W. Xiong</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author contributing to research on large-scale code models and their applications.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A. D ´efossez">
  <data key="d0">A. D ´efossez</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in foundational AI research for code models, supporting open model initiatives.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="J. Copet">
  <data key="d0">J. Copet</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author contributing to the development of code foundation models, aiding in AI code understanding.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="F. Azhar">
  <data key="d0">F. Azhar</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in research on AI models for code, supporting open-source AI initiatives.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="H. Touvron">
  <data key="d0">H. Touvron</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in developing Llama 2, an open foundation and chat model, advancing open-source AI.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="L. Martin">
  <data key="d0">L. Martin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher contributing to large language models and foundation models for AI applications.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="N. Usunier">
  <data key="d0">N. Usunier</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in AI and language modeling research, supporting foundation model development.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="T. Scialom">
  <data key="d0">T. Scialom</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher contributing to large language models and AI research, supporting open foundation models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="G. Synnaeve">
  <data key="d0">G. Synnaeve</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in AI and foundation model research, supporting advancements in code AI models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="OpenAI">
  <data key="d0">OpenAI</data>
  <data key="d1">Organization</data>
  <data key="d2">A leading AI research organization responsible for developing GPT-4 and advancing large language models.&lt;SEP&gt;A leading AI research organization responsible for developing GPT-4 and related models.&lt;SEP&gt;An AI research organization known for developing advanced language models like GPT series, including GPT-4.&lt;SEP&gt;OpenAI is a leading AI research organization that develops large language models (like GPT-4), offers tools such as ChatGPT plugins, and publishes technical reports.&lt;SEP&gt;OpenAI is an organization developing advanced AI models like GPT-4 and ChatGPT, and providing resources such as plugins and technical reports.&lt;SEP&gt;OpenAI is an AI research organization known for creating advanced large language models such as GPT-3 and GPT-4.&lt;SEP&gt;OpenAI is an AI research organization known for developing advanced language models such as GPT-3 and GPT-4.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="A. Hurst">
  <data key="d0">A. Hurst</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher associated with OpenAI, involved in system documentation and AI model development, notably GPT-4O.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="X. Xu">
  <data key="d0">X. Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher conducting surveys on knowledge distillation of large language models, contributing to model efficiency research.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="M. Li">
  <data key="d0">M. Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in the survey of knowledge distillation techniques for large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. Tao">
  <data key="d0">C. Tao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher contributing to knowledge distillation research, supporting large language model optimization.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="T. Shen">
  <data key="d0">T. Shen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in the survey on knowledge distillation of large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="R. Cheng">
  <data key="d0">R. Cheng</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher supporting research on knowledge distillation methods for large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="J. Li">
  <data key="d0">J. Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in large language model knowledge distillation and efficiency improvement.&lt;SEP&gt;Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. Xu">
  <data key="d0">C. Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">C. Xu is a researcher working on NLP datasets and transformer architectures.&lt;SEP&gt;Researcher contributing to the survey on knowledge distillation of large language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="D. Tao">
  <data key="d0">D. Tao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher supporting knowledge distillation research for large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="T. Zhou">
  <data key="d0">T. Zhou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in the survey on large language models and knowledge distillation.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. Wei">
  <data key="d0">Y. Wei</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of a preprint on MagicCoder, a model emphasizing source code in AI.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Z. Wang">
  <data key="d0">Z. Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of MagicCoder, contributing to source code-focused AI models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="J. Liu">
  <data key="d0">J. Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of MagicCoder, advancing source code integration in language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. Ding">
  <data key="d0">Y. Ding</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of MagicCoder, supporting source code AI research.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="L. Zhang">
  <data key="d0">L. Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in MagicCoder development, emphasizing source code in AI models.&lt;SEP&gt;Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A. Guo">
  <data key="d0">A. Guo</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in Deepseek-coder, a code intelligence large language model, published in 2024.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Q. Zhu">
  <data key="d0">Q. Zhu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher supporting Deepseek-coder and Deepseek-coder-v2, focusing on code intelligence.&lt;SEP&gt;See above, supporting Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="D. Yang">
  <data key="d0">D. Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in Deepseek projects, advancing code AI technologies.&lt;SEP&gt;See above, supporting Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Z. Xie">
  <data key="d0">Z. Xie</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher supporting Deepseek-coder models in code intelligence.&lt;SEP&gt;Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="K. Dong">
  <data key="d0">K. Dong</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher contributing to Deepseek-coder development.&lt;SEP&gt;Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="W. Zhang">
  <data key="d0">W. Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in Deepseek-coder research, focusing on code intelligence.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="G. Chen">
  <data key="d0">G. Chen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher supporting Deepseek-coder models for code understanding.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="X. Bi">
  <data key="d0">X. Bi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in Deepseek projects, enhancing code AI capabilities.&lt;SEP&gt;Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. Wu">
  <data key="d0">Y. Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher supporting Deepseek-coder in code intelligence tasks.&lt;SEP&gt;Supporting researcher in Deepseek projects.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. K. Li">
  <data key="d0">Y. K. Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in Deepseek-coder research, focusing on code models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="F. Luo">
  <data key="d0">F. Luo</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher supporting Deepseek-coder development.&lt;SEP&gt;Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. Xiong">
  <data key="d0">Y. Xiong</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher contributing to foundational AI models for code.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="W. Liang">
  <data key="d0">W. Liang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher involved in Deepseek-coder projects, advancing code intelligence.&lt;SEP&gt;Supporting researcher in Deepseek-coder.&lt;SEP&gt;W. Liang is an author collaborating on studies involving large language models and their intersection with programming tasks.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="DeepSeek-AI">
  <data key="d0">DeepSeek-AI</data>
  <data key="d1">Organization</data>
  <data key="d2">The organization behind DeepSeek-AI, developing code intelligence models like Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="D. Guo">
  <data key="d0">D. Guo</data>
  <data key="d1">Researcher</data>
  <data key="d2">See above, supporting Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Z. Shao">
  <data key="d0">Z. Shao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher supporting Deepseek-coder in code intelligence.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="P. Wang">
  <data key="d0">P. Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">P. Wang is a researcher involved in NLP and language modeling studies.&lt;SEP&gt;P. Wang is an author involved in NLP datasets and language modeling.&lt;SEP&gt;Supporting researcher in Deepseek projects.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="R. Xu">
  <data key="d0">R. Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder development.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. Li">
  <data key="d0">Y. Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.&lt;SEP&gt;Y. Li is an author contributing to research on code generation and artificial intelligence, involved in multiple publications.&lt;SEP&gt;Y. Li is an author involved in research related to code generation and artificial intelligence, contributing to scientific publications.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="H. Gao">
  <data key="d0">H. Gao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder-v2.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="S. Ma">
  <data key="d0">S. Ma</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="W. Zeng">
  <data key="d0">W. Zeng</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Z. Gu">
  <data key="d0">Z. Gu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="H. Xu">
  <data key="d0">H. Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="D. Dai">
  <data key="d0">D. Dai</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. Piao">
  <data key="d0">Y. Piao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Z. Gou">
  <data key="d0">Z. Gou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Z. Hao">
  <data key="d0">Z. Hao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="B. Wang">
  <data key="d0">B. Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="J. Song">
  <data key="d0">J. Song</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="D. Chen">
  <data key="d0">D. Chen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="X. Xie">
  <data key="d0">X. Xie</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="K. Guan">
  <data key="d0">K. Guan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. You">
  <data key="d0">Y. You</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A. Liu">
  <data key="d0">A. Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Q. Du">
  <data key="d0">Q. Du</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="W. Gao">
  <data key="d0">W. Gao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="X. Lu">
  <data key="d0">X. Lu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Q. Chen">
  <data key="d0">Q. Chen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Y. Wang">
  <data key="d0">Y. Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. Deng">
  <data key="d0">C. Deng</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. Zhao">
  <data key="d0">C. Zhao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="C. Ruan">
  <data key="d0">C. Ruan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Supporting researcher in Deepseek-coder.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Large language models">
  <data key="d0">Large language models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Models capable of understanding and generating human language at scale, central to AI research and applications.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Code intelligence">
  <data key="d0">Code intelligence</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ability of AI models to understand, analyze, and generate source code, a key focus in AI for programming.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model optimization">
  <data key="d0">Model optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques aimed at improving the efficiency, accuracy, and scalability of large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Training techniques">
  <data key="d0">Training techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods used to train large language models, including knowledge distillation, sparsity exploitation, and instruction tuning.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model evaluation">
  <data key="d0">Model evaluation</data>
  <data key="d1">Results</data>
  <data key="d2">Processes and benchmarks used to assess the performance of large language models.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model scalability">
  <data key="d0">Model scalability</data>
  <data key="d1">Variables</data>
  <data key="d2">Attributes that describe how well models perform as size and complexity increase.</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Pytorch">
  <data key="d0">Pytorch</data>
  <data key="d1">Tools</data>
  <data key="d2">A high-performance deep learning library developed by Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala in 2019, used for building neural networks and deep learning models.&lt;SEP&gt;An imperative style, high-performance deep learning library developed by Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala in 2019, used for building and training neural networks.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Fixing weight decay regularization in adam">
  <data key="d0">Fixing weight decay regularization in adam</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A research methodology proposed by I. Loshchilov and F. Hutter in 2017 to improve the Adam optimizer by addressing weight decay regularization issues.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Large language models trained on code">
  <data key="d0">Large language models trained on code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Models like GPT and similar architectures trained specifically on programming code to evaluate their performance in understanding and generating code, as studied in 2021.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Phind-codellama-34b-v2">
  <data key="d0">Phind-codellama-34b-v2</data>
  <data key="d1">Tools</data>
  <data key="d2">A specific large language model designed for code tasks, available on Hugging Face in 2023, used for code generation and understanding.&lt;SEP&gt;A specific large language model for code, available on Hugging Face, designed for code-related tasks as of 2023.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Gemini">
  <data key="d0">Gemini</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A family of highly capable multimodal models introduced in 2023, capable of processing and integrating multiple data modalities for advanced AI applications.&lt;SEP&gt;A family of highly capable multimodal models introduced in 2023, integrating multiple data modalities for advanced AI applications.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Language models are few-shot learners">
  <data key="d0">Language models are few-shot learners</data>
  <data key="d1">Results</data>
  <data key="d2">A foundational concept demonstrated by T. B. Brown et al. in 2020 that large language models can perform new tasks with minimal examples, highlighting their few-shot learning ability.&lt;SEP&gt;A foundational research paper by T. B. Brown et al. in 2020 demonstrating that large language models can perform tasks with minimal examples, highlighting few-shot learning capabilities.&lt;SEP&gt;A key finding that large language models like GPT-3 can perform tasks with minimal examples, indicating their versatility.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb&lt;SEP&gt;chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Gpt-4 technical report">
  <data key="d0">Gpt-4 technical report</data>
  <data key="d1">Results</data>
  <data key="d2">A comprehensive report published by OpenAI in 2023 detailing the capabilities, architecture, and performance of GPT-4.&lt;SEP&gt;A comprehensive technical report published by OpenAI in 2023 detailing GPT-4's architecture, capabilities, and performance benchmarks.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Mpirigen">
  <data key="d0">Mpirigen</data>
  <data key="d1">Tools</data>
  <data key="d2">A tool for MPI code generation through domain-specific language models, described in a 2024 publication, facilitating automated parallel code development.&lt;SEP&gt;A tool for MPI code generation via domain-specific language models, described in 2024, facilitating automated parallel code development for high-performance computing.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Llm4vv">
  <data key="d0">Llm4vv</data>
  <data key="d1">Tools</data>
  <data key="d2">A large language model-driven test suite for compiler validation, developed in 2023 to improve compiler testing processes.&lt;SEP&gt;An LLM-driven test suite for compiler validation, developed in 2023 to automate and improve compiler testing processes.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Data race detection using large language models">
  <data key="d0">Data race detection using large language models</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A research approach in 2023 exploring how large language models can be utilized to detect data races in parallel programming environments.&lt;SEP&gt;Research exploring how large language models can be utilized to detect data races in parallel programming, conducted in 2023.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Scope is all you need: Transforming llms for hpc code">
  <data key="d0">Scope is all you need: Transforming llms for hpc code</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A 2023 hypothesis proposing that transforming large language models can optimize high-performance computing (HPC) code for better efficiency and performance.&lt;SEP&gt;A 2023 study hypothesizing that transforming large language models can optimize HPC (High-Performance Computing) code for better performance.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Modeling parallel programs using large language models">
  <data key="d0">Modeling parallel programs using large language models</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A 2024 research study applying large language models to simulate, analyze, and optimize parallel programs in scientific computing.&lt;SEP&gt;A 2024 study on applying large language models to simulate and analyze parallel programs.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Performance-aligned llms for generating fast code">
  <data key="d0">Performance-aligned llms for generating fast code</data>
  <data key="d1">Results</data>
  <data key="d2">A 2024 research demonstrating that aligning large language models with performance metrics can generate more efficient code.&lt;SEP&gt;A 2024 study demonstrating that aligning large language models with performance metrics results in faster, more efficient code generation.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="chathpc">
  <data key="d0">chathpc</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">A 2025 application aimed at empowering HPC users with large language models to improve supercomputing workflows and user productivity.&lt;SEP&gt;A 2025 application of large language models to empower HPC users, enhancing their ability to interact with supercomputing resources.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Lassi">
  <data key="d0">Lassi</data>
  <data key="d1">Tools</data>
  <data key="d2">An LLM-based automated self-correcting pipeline for translating parallel scientific codes, introduced in 2024 to improve scientific computing workflows.&lt;SEP&gt;An LLM-based automated self-correcting pipeline introduced in 2024 for translating parallel scientific codes, enhancing scientific computing workflows.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Ompgpt">
  <data key="d0">Ompgpt</data>
  <data key="d1">Tools</data>
  <data key="d2">A generative pre-trained transformer model for OpenMP, designed in 2024 to facilitate parallel programming and code generation.&lt;SEP&gt;A transformer-based model developed in 2024 for OpenMP code, facilitating parallel programming and code generation in high-performance computing.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="A systematic evaluation of large language models of code">
  <data key="d0">A systematic evaluation of large language models of code</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A 2022 comprehensive evaluation study assessing the capabilities, strengths, and limitations of large language models applied to programming code.&lt;SEP&gt;A 2022 systematic study evaluating the performance and capabilities of large language models applied to code understanding and generation.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Biocoder">
  <data key="d0">Biocoder</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark dataset for bioinformatics code generation, used to evaluate models on bioinformatics tasks involving code generation.&lt;SEP&gt;A benchmark dataset for evaluating bioinformatics code generation models, used to assess the performance of models on bioinformatics coding tasks.&lt;SEP&gt;Biocoder is a benchmark dataset aimed at evaluating bioinformatics code generation, emphasizing the importance of contextual pragmatic knowledge in generating accurate bioinformatics code.&lt;SEP&gt;Biocoder is a benchmark dataset created for evaluating bioinformatics code generation, emphasizing the integration of contextual pragmatic knowledge.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Weight Decay Regularization in Adam">
  <data key="d0">Weight Decay Regularization in Adam</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique proposed by I. Loshchilov and F. Hutter in 2017 to improve the Adam optimizer by properly fixing weight decay regularization, enhancing training stability.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Large Language Models trained on Code">
  <data key="d0">Large Language Models trained on Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Models trained on programming code, evaluated for their ability to understand, generate, and evaluate code, as studied in 2021.</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Verilogeval">
  <data key="d0">Verilogeval</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Verilogeval is an evaluation framework for assessing large language models' performance in generating Verilog code, a hardware description language.&lt;SEP&gt;Verilogeval is an evaluation framework used to assess the performance of large language models in generating Verilog hardware description language code.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Knowledge transfer from high-resource to low-resource programming languages">
  <data key="d0">Knowledge transfer from high-resource to low-resource programming languages</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This concept involves transferring knowledge from programming languages with abundant resources to those with fewer resources, enhancing code generation capabilities across diverse languages.&lt;SEP&gt;This concept involves transferring knowledge learned from programming languages with abundant resources to those with fewer resources to improve code generation capabilities.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Reproducibility">
  <data key="d0">Reproducibility</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Reproducibility refers to the ability to replicate research results using shared scripts, datasets, and models, ensuring transparency and validation in scientific studies.&lt;SEP&gt;Reproducibility refers to the ability to replicate the results of a study or experiment using the provided scripts and datasets, ensuring transparency and validation of research findings.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2 models">
  <data key="d0">HPC-Coder-V2 models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">HPC-Coder-V2 models are advanced code generation models evaluated for their correctness in generating code solutions for high-performance computing tasks.&lt;SEP&gt;HPC-Coder-V2 models are large language models designed for code generation tasks in high-performance computing contexts, evaluated for correctness and performance.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="HPC-Coder-V2-1.3B, StarCoder2-3B, HPC-Coder-V2-6.7B, Magicoder-6.7B, StarCoder2-7B, CodeLlama-7B, CodeLlama-13B, StarCoder2-15B, StarCoderBase, HPC-Coder-V2-16B, Phind-V2-34B, CodeLlama-34B, Gemini-Pro, GPT-3.5, GPT-4">
  <data key="d0">HPC-Coder-V2-1.3B, StarCoder2-3B, HPC-Coder-V2-6.7B, Magicoder-6.7B, StarCoder2-7B, CodeLlama-7B, CodeLlama-13B, StarCoder2-15B, StarCoderBase, HPC-Coder-V2-16B, Phind-V2-34B, CodeLlama-34B, Gemini-Pro, GPT-3.5, GPT-4</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">These are various large language models with different sizes and architectures evaluated for code generation performance, serving as the primary objects of study in the research.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="parallelize the aggregation process">
  <data key="d0">parallelize the aggregation process</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The hypothesis is that parallelizing the aggregation process using OpenMP will significantly reduce processing time in high-performance computing applications.&lt;SEP&gt;The main hypothesis is that parallelizing the data aggregation process using OpenMP will significantly reduce processing time in high-performance computing applications.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="compute_metric">
  <data key="d0">compute_metric</data>
  <data key="d1">Tools</data>
  <data key="d2">compute_metric is a function that performs complex calculations on individual data points to produce a metric value, used as a core component in data aggregation tasks.&lt;SEP&gt;compute_metric is a function that performs complex computations on individual data points, used as a building block in data aggregation tasks.&lt;SEP&gt;compute_metric is a function used to perform complex calculations on individual data points, and remains unchanged in the parallelization process.&lt;SEP&gt;compute_metric is a function used to perform complex calculations on individual data points, remaining unchanged during parallelization.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="aggregate_metrics">
  <data key="d0">aggregate_metrics</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The aggregate_metrics function calculates the sum of metrics across a dataset, which can be parallelized for efficiency.&lt;SEP&gt;The aggregate_metrics function calculates the total sum of metrics across a dataset, which can be parallelized for efficiency.&lt;SEP&gt;The aggregate_metrics function computes the sum of metrics over a 2D array of data points, which can be optimized through parallelization to improve efficiency.&lt;SEP&gt;The aggregate_metrics function computes the sum of metrics over a 2D dataset, which can be optimized via parallelization to improve performance.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c&lt;SEP&gt;chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Luo, Y">
  <data key="d0">Luo, Y</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Luo, Y is an author contributing to research on code intelligence, focusing on large language models and their applications in programming.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Xiong, W">
  <data key="d0">Xiong, W</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Xiong, W is an author involved in research related to code generation and large language models.</data>
  <data key="d3">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="sum">
  <data key="d0">sum</data>
  <data key="d1">Variables</data>
  <data key="d2">Sum is an accumulator variable used to store the total of computed metrics during dataset processing, updated within the loop.&lt;SEP&gt;Sum is an accumulator variable used to store the total of computed metrics during the dataset processing.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="data">
  <data key="d0">data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data is a 2D array containing data points to be processed by compute_metric.&lt;SEP&gt;Data is a two-dimensional array containing data points to be processed by the compute_metric function.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="rows">
  <data key="d0">rows</data>
  <data key="d1">Variables</data>
  <data key="d2">Rows represent the number of data entries in the dataset, controlling the outer loop iteration.&lt;SEP&gt;Rows represent the number of data entries in the dataset, used to control the outer loop.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="cols">
  <data key="d0">cols</data>
  <data key="d1">Variables</data>
  <data key="d2">Columns represent the number of data points in each data entry, used in the inner loop.&lt;SEP&gt;Columns represent the number of data points per data entry, controlling the inner loop iteration.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="parallelization">
  <data key="d0">parallelization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Parallelization refers to the process of executing multiple computations simultaneously, here achieved using OpenMP directives.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="OpenMP">
  <data key="d0">OpenMP</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A parallel programming API used in conjunction with GCC to compile parallel code, utilizing flags like -fopenmp.&lt;SEP&gt;OpenMP is a parallel programming API that enables multi-threaded execution of code segments in C/C++ programs.&lt;SEP&gt;OpenMP is a parallel programming model used to write multi-threaded applications, often for shared-memory architectures, enabling code parallelization.&lt;SEP&gt;OpenMP is a shared-memory parallel programming API, often used as a high-level abstraction for parallelization, and compared with other models in the study.&lt;SEP&gt;OpenMP is a shared-memory parallel programming model that enables multi-threaded execution, widely used for parallelizing serial code.&lt;SEP&gt;A parallel programming discipline for shared-memory architectures."&gt;&lt;SEP&gt;A widely used parallel programming model for shared-memory architectures, providing directives for parallel execution, synchronization, and data sharing.&lt;SEP&gt;OpenMP is a parallel programming model designed for shared-memory architectures, enabling multi-threaded execution with directives for parallelism, synchronization, and data sharing.&lt;SEP&gt;OpenMP is a widely used parallel programming model for shared-memory architectures, enabling multi-threaded execution and synchronization."&gt;&lt;SEP&gt;OpenMP is an API supporting multi-platform shared memory parallel programming in C, C++, and Fortran, used to implement parallelism.&lt;SEP&gt;OpenMP is an API that supports multi-platform shared memory multiprocessing programming in C, C++, and Fortran, used for parallelization.&lt;SEP&gt;A parallel programming model used in experiments to evaluate code suggestion accuracy for various kernels and prompts.&lt;SEP&gt;OpenMP is a mature parallel programming model widely used in high-performance computing, providing better results due to its availability and established implementation.&lt;SEP&gt;OpenMP is a parallel programming model used in HPC and scientific computing, offering better results due to its maturity and availability in public code.&lt;SEP&gt;OpenMP is a parallel programming model used in experiments to evaluate code suggestion accuracy for different kernels and prompts.&lt;SEP&gt;OpenMP is an API specification for multi-platform shared-memory parallel programming in C, C++, and Fortran, enabling efficient use of multi-core CPUs.&lt;SEP&gt;An API supporting multi-platform shared memory multiprocessing programming in C, C++, and Fortran, used to parallelize loops and sections of code.&lt;SEP&gt;An API that supports multi-platform shared memory multiprocessing programming in C, C++, and Fortran, used to parallelize loops and sections of code.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482&lt;SEP&gt;chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-d1ed35f0489d99675c43fbbee04d61fd&lt;SEP&gt;chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="reduction">
  <data key="d0">reduction</data>
  <data key="d1">Techniques</data>
  <data key="d2">The reduction clause in OpenMP ensures safe accumulation of partial sums from multiple threads into a single total.</data>
  <data key="d3">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Phind-V2-34B">
  <data key="d0">Phind-V2-34B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Phind-V2-34B is a computational model evaluated on various problem types and execution models, with performance scores documented, used in benchmarking AI models.&lt;SEP&gt;Phind-V2-34B is a computational model tested across different problem types and execution models, with performance scores documented.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="sparse_la fftgeometry scan sort stencil hist. dense_la graph reduce search transf.">
  <data key="d0">sparse_la fftgeometry scan sort stencil hist. dense_la graph reduce search transf.</data>
  <data key="d1">Variables</data>
  <data key="d2">Various computational problem types and algorithm categories, including sparse linear algebra, FFT, geometry, scan, sort, stencil, histogram, dense linear algebra, graph algorithms, reduce, search, and transfer operations.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Execution Model">
  <data key="d0">Execution Model</data>
  <data key="d1">Variables</data>
  <data key="d2">Different parallel execution models including serial, OpenMP (omp), Kokkos, CUDA, HIP, MPI, and MPI+OMP, used to assess system performance.&lt;SEP&gt;Parallel computing paradigms such as serial, OpenMP (omp), Kokkos, CUDA, HIP, MPI, and MPI+OMP, used to test system performance and scalability.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="sparse_la">
  <data key="d0">sparse_la</data>
  <data key="d1">Variables</data>
  <data key="d2">Sparse linear algebra operations, a category of computational problems involving sparse matrices and related algorithms.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="fftgeometry">
  <data key="d0">fftgeometry</data>
  <data key="d1">Variables</data>
  <data key="d2">Fourier transforms and geometric computations, categories of problem types in high-performance computing tasks.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="scan">
  <data key="d0">scan</data>
  <data key="d1">Variables</data>
  <data key="d2">Scan operations, a class of parallel algorithms for prefix sums and related computations.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="sort">
  <data key="d0">sort</data>
  <data key="d1">Variables</data>
  <data key="d2">Sorting algorithms, critical for data organization and processing in computational tasks.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="stencil">
  <data key="d0">stencil</data>
  <data key="d1">Variables</data>
  <data key="d2">Stencil computations, used in numerical simulations involving grid-based methods.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="hist">
  <data key="d0">hist</data>
  <data key="d1">Variables</data>
  <data key="d2">Histogram computations, used for data analysis and statistical summaries in computational workflows.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="dense_la">
  <data key="d0">dense_la</data>
  <data key="d1">Variables</data>
  <data key="d2">Dense linear algebra operations, involving matrices with dense data structures.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="graph">
  <data key="d0">graph</data>
  <data key="d1">Variables</data>
  <data key="d2">Graph algorithms, used in network analysis, pathfinding, and related computations.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="reduce">
  <data key="d0">reduce</data>
  <data key="d1">Variables</data>
  <data key="d2">Reduce operations, aggregating data across datasets or computational steps.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="search">
  <data key="d0">search</data>
  <data key="d1">Variables</data>
  <data key="d2">Search algorithms, used to locate specific data or patterns within datasets.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="transf">
  <data key="d0">transf</data>
  <data key="d1">Variables</data>
  <data key="d2">Transfer operations, involving data movement between memory or processing units.</data>
  <data key="d3">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Generation Quality">
  <data key="d0">Generation Quality</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d2">Careful design of prompts influences the diversity, relevance, and correctness of generated code outputs.&lt;SEP&gt;Careful prompt design influences the diversity and correctness of generated code outputs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Data and Model">
  <data key="d0">Impact of Data and Model</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d2">Ablation studies analyze how changes in data, model size, and prompts affect code generation capabilities.&lt;SEP&gt;Ablation studies systematically assess how variations in data, model size, and prompts affect code generation capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Models">
  <data key="d0">Models</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d2">GPT-3.5, Llama2-13B-chat, and other large language models evaluated for their problem-solving performance.&lt;SEP&gt;Models are evaluated against the ParEval benchmark to assess their effectiveness in parallel code generation.&lt;SEP&gt;Models are evaluated against the ParEval benchmark to quantify their effectiveness in parallel code generation.&lt;SEP&gt;Specific AI models evaluated for their ability to generate correct parallel code, including proprietary and open-source models.&lt;SEP&gt;Specific AI models such as GPT-3.5, GPT-4, Phind-V2, StarCoderBase, and CodeLlama evaluated for their code generation capabilities.&lt;SEP&gt;The research investigates how effectively different LLMs can produce parallel code from prompts across multiple models and languages.</data>
  <data key="d1">Objects of Study</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Implications">
  <data key="d0">Implications</data>
  <data key="d3">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d2">Findings inform best practices for fine-tuning HPC code LLMs, guiding future research and deployment.&lt;SEP&gt;Findings inform best practices for fine-tuning HPC code LLMs, guiding future research, and deployment strategies.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="training data">
  <data key="d0">training data</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d2">Curated programming problems and solutions used to train models like Codex, providing real-world code examples.&lt;SEP&gt;Synthetic HPC code data is used to fine-tune models like DeepSeek-Coder, enhancing their ability to generate HPC-related code.&lt;SEP&gt;Synthetic HPC code data is used to train or fine-tune models like DeepSeek-Coder, enhancing their ability to generate HPC-specific code.&lt;SEP&gt;The datasets used to train LLMs, which influence models' familiarity with certain parallel programming paradigms like Kokkos or OpenMP.&lt;SEP&gt;Training data includes large code corpora used to train LLMs for code generation tasks.&lt;SEP&gt;Training data consists of large datasets used for pre-training and fine-tuning models, which may contain insecure code, leading to insecure outputs.&lt;SEP&gt;Training data refers to the large, untrusted datasets used to pre-train and fine-tune models, which can contain insecure code and lead to insecure output.</data>
  <data key="d1">Objects of Study</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model performance">
  <data key="d0">model performance</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83&lt;SEP&gt;chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f&lt;SEP&gt;chunk-acc067e535432960edbc682652b521e0&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d2">Adjusting hyperparameters like batch size and sequence length directly impacts the training efficiency and the quality of the resulting models.&lt;SEP&gt;Model performance indicates how well LLMs generate correct, efficient, and scalable parallel code across different models and problem types.&lt;SEP&gt;Model performance is measured by the accuracy and helpfulness of generated code, including ability to produce bug-free, aligned outputs.&lt;SEP&gt;The effectiveness of the trained models in generating correct code from natural language descriptions.&lt;SEP&gt;The effectiveness of trained models in generating correct code from natural language prompts and vice versa.</data>
  <data key="d1">Results</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model components">
  <data key="d0">model components</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d2">Ablation studies help determine the importance of different model components or training choices by systematically removing or altering them.&lt;SEP&gt;Ablation studies systematically evaluate the importance of different components or parameters in the training process.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="training process">
  <data key="d0">training process</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d2">Adjustments to hyperparameters like batch size and sequence length influence training speed and model quality.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="performance">
  <data key="d0">performance</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f&lt;SEP&gt;chunk-cfcd5a8798f30da73fdaa3033d579b42&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-9596cd861216e68aa0fdb35edbc9a132&lt;SEP&gt;chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d2">Performance refers to the ability of developers to write efficient parallel code, emphasizing the importance of benchmarks and metrics to evaluate code usefulness.&lt;SEP&gt;Performance refers to the efficiency, correctness, and scalability of the code generated by LLMs, evaluated through the ParEval benchmark.&lt;SEP&gt;The ability of LLMs to generate correct parallel code and improve translation accuracy, with performance metrics indicating strengths and weaknesses.&lt;SEP&gt;The choice of model architecture impacts the scalability, efficiency, and effectiveness of code modeling performance.&lt;SEP&gt;The overall accuracy and effectiveness of models evaluated through various benchmarks and metrics.&lt;SEP&gt;The models' ability to generate correct parallel code and improve translation accuracy with examples.&lt;SEP&gt;The overall efficiency, correctness, and scalability of the generated parallel code as measured by the ParEval benchmark.&lt;SEP&gt;The study investigates how different programming languages and GPU programming models affect the correctness and efficiency of computational kernels.&lt;SEP&gt;The study investigates how different programming languages and models affect the performance and correctness of GPU kernels for scientific computing tasks.&lt;SEP&gt;Performance refers to the effectiveness and efficiency of code execution, particularly in high-performance computing (HPC), and is a central focus for performance modeling and analysis.&lt;SEP&gt;Performance refers to the effectiveness and efficiency of code execution, which can be studied through various analytical methods and models.</data>
  <data key="d1">Core Concepts</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="training methodology">
  <data key="d0">training methodology</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d2">Proper prompt formatting is essential for guiding the model during training and improving output quality.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="results">
  <data key="d0">results</data>
  <data key="d3">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d2">Evaluation metrics and benchmarks measure the effectiveness of fine-tuned models in generating accurate code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Impact of Data and Model Size">
  <data key="d0">Impact of Data and Model Size</data>
  <data key="d3">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d2">Both the amount and quality of data, along with model size, jointly influence the final performance of fine-tuned models in code generation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Research Questions/Hypotheses">
  <data key="d0">Research Questions/Hypotheses</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-1ee2903e9d138e70e07c1af3cf2fa9a3&lt;SEP&gt;chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d2">Can large language models effectively generate correct, efficient, and complex parallel code across diverse tasks and programming models?&lt;SEP&gt;Research explores whether automated prompt engineering can outperform manual methods, hypothesizing improvements in modularity, efficiency, and response quality.&lt;SEP&gt;Research questions explore how automated prompt engineering can outperform manual methods, hypothesizing improvements in modularity, efficiency, and response quality.&lt;SEP&gt;The study aims to assess how different model sizes and fine-tuning strategies affect parallel code generation capabilities.&lt;SEP&gt;Specific inquiries or testable statements formulated to guide the research process and objectives.&lt;SEP&gt;Research Questions and Hypotheses are specific inquiries or propositions that guide the focus of a study, aiming to be tested or explored.&lt;SEP&gt;Specific questions or propositions that guide the research process, aiming to be tested or explored.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Theories/Models">
  <data key="d0">Theories/Models</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d2">Conceptual frameworks explaining how large language models learn, adapt, and can be guided or improved through techniques like distribution alignment and prompt engineering.&lt;SEP&gt;DSPy posits that composing generic modules rather than prompt manipulation enhances language model reasoning capabilities.&lt;SEP&gt;DSPy posits that module composition rather than prompt engineering is the key to improving reasoning in language models.&lt;SEP&gt;StarCoder2 is a foundational model used as a baseline for code generation tasks.&lt;SEP&gt;StarCoder2 serves as a foundational model trained on large code datasets, providing baseline performance for code tasks.&lt;SEP&gt;Structured frameworks or conceptual models used to explain phenomena, guide research, or interpret data within the study.&lt;SEP&gt;Formal representations or frameworks that explain, predict, or simulate phenomena within a discipline.&lt;SEP&gt;Theories or Models refer to conceptual frameworks or formal representations used to understand, explain, or predict phenomena within a field.</data>
  <data key="d1">Theories/Models</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Results">
  <data key="d0">Results</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d2">Codex demonstrates power-law scaling in test loss with model size and achieves high pass@k performance on programming tasks, showing the effectiveness of fine-tuning large language models on code.&lt;SEP&gt;Compilation methods, especially bootstrap and ensembling, significantly increase accuracy from 4-20% to 49-88%, with reflection programs and DSPy modules being particularly effective.&lt;SEP&gt;Compilation, especially bootstrap and ensemble methods, significantly improves model accuracy from 4-20% to 49-88%, with reflection programs and DSPy modules being particularly effective.&lt;SEP&gt;Performance metrics evaluate how well models generate parallel code, such as MPI, in benchmarks like ParEval."|&gt;"performance metrics, code benchmarks&lt;SEP&gt;Performance scores such as Pass@1 measure the models' ability to generate correct parallel code like MPI in benchmarks.&lt;SEP&gt;Outcomes or findings derived from data analysis, indicating the outcomes of applying methodologies to the study.&lt;SEP&gt;Outcomes or findings derived from research or analysis, indicating evidence supporting or refuting hypotheses.&lt;SEP&gt;Results are the outcomes or findings derived from research or analysis, indicating the evidence supporting or refuting hypotheses.</data>
  <data key="d1">Results</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Objects of Study">
  <data key="d0">Objects of Study</data>
  <data key="d3">chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">Entities or phenomena that are examined or analyzed within the research, such as datasets, models, or systems.&lt;SEP&gt;MPI code generation performance assesses models' ability to generate Message Passing Interface code, which is crucial for parallel computing."|&gt;"parallel programming, code generation&lt;SEP&gt;MPI code generation performance assesses the models' ability to generate Message Passing Interface code, a complex parallel programming task.&lt;SEP&gt;Entities, phenomena, or concepts that are examined within research, such as processes, systems, populations, or events.&lt;SEP&gt;Objects of Study are the entities, phenomena, or concepts that are examined within a research, such as processes, systems, or populations.</data>
  <data key="d1">Objects of Study</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Variables">
  <data key="d0">Variables</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d2">Attributes or factors that can vary within the study, measured or manipulated to assess their effects or relationships.&lt;SEP&gt;Model accuracy, self-correction effectiveness, complexity of the text-to-SQL tasks.&lt;SEP&gt;Model size impacts how training data quantity affects performance, with smaller models benefiting more from additional data.&lt;SEP&gt;Model size impacts how training data quantity affects performance, with smaller models benefiting more from increased data."|&gt;"model capacity, data effectiveness&lt;SEP&gt;Variables involved include model accuracy, self-correction effectiveness, and task complexity.&lt;SEP&gt;Measurable attributes or properties that can vary across entities or conditions within a study, used to examine relationships or effects.&lt;SEP&gt;Variables are measurable attributes or properties that can vary across entities or conditions within a study, used to examine relationships or effects.&lt;SEP&gt;Variables involve model size (number of parameters), sampling temperature, number of samples (k), and dataset size, which influence performance metrics like test loss and pass@k.</data>
  <data key="d1">Variables</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Tools">
  <data key="d0">Tools</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-87968a35d8273787998be04f169d03c8&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">Different fine-tuning strategies, such as gradient masking and instruct vs. base models, serve as tools to enhance model performance."|&gt;"fine-tuning methods, performance optimization&lt;SEP&gt;Different fine-tuning strategies, such as masked/unmasked gradients and instruct/base models, are tools to optimize performance.&lt;SEP&gt;Instruments, software, or devices used to facilitate data collection, analysis, or implementation in the research.&lt;SEP&gt;Instruments, software, or devices used to facilitate data collection, analysis, or research activities.&lt;SEP&gt;Tools are instruments, software, or devices utilized to facilitate research activities, data collection, or analysis.&lt;SEP&gt;Tools include the GPT-3 text tokenizer, Adam optimizer, and nucleus sampling for code generation evaluation.</data>
  <data key="d1">Tools</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="parEval benchmark">
  <data key="d0">parEval benchmark</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d2">HPC-Coder-V2 is evaluated using the ParEval benchmark to measure its performance across different problem types and execution models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="performance comparison">
  <data key="d0">performance comparison</data>
  <data key="d3">chunk-aec2ac03d71774b2a191de2c6ebcd45e&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d2">Assessment of different models' effectiveness across various parallel execution models, with serial being easiest and MPI/MPI+OpenMP being most challenging.&lt;SEP&gt;Assessment of model accuracy across different parallel execution models, revealing which models perform better or worse depending on the environment.&lt;SEP&gt;Comparing the performance of different models, such as GPT-3.5 versus GPT-4, reveals insights into their relative strengths in parallel code generation tasks.&lt;SEP&gt;HPC-Coder-V2 models outperform some existing models like StarCoder2-3B and Phind-V2-34B in parallel code generation, demonstrating competitiveness.&lt;SEP&gt;Performance comparison assesses the differences in correctness and efficiency between models like GPT-3.5 and GPT-4 in generating parallel code.</data>
  <data key="d1">Results</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Applications/Implications">
  <data key="d0">Applications/Implications</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d2">Applications and Implications refer to the practical uses or consequences of research findings in real-world contexts.&lt;SEP&gt;Effective fine-tuned HPC models can generate parallel code efficiently, impacting HPC workflows."|&lt;SEP&gt;Real-world uses or consequences derived from the research findings, informing practice, policy, or future research.&lt;SEP&gt;Practical uses or consequences of research findings, including policy, technology, or societal impact.</data>
  <data key="d1">Applications/Implications</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Open foundation and fine-tuned chat models">
  <data key="d0">Open foundation and fine-tuned chat models</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d2">Llama 2 serves as the basis for open foundation models and can be fine-tuned for specific tasks, establishing a relationship of foundational architecture and customization.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="large language models">
  <data key="d0">large language models</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d2">This methodology is used to develop or optimize large language models, indicating a relationship of technical approach to model scalability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="evol-instruct">
  <data key="d0">evol-instruct</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d2">Wizardcoder leverages evol-instruct techniques to enhance code modeling capabilities, showing a relationship of instructional training methods to model performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="large model training">
  <data key="d0">large model training</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d2">This technique aims to optimize training of large models by exploiting sparsity, indicating a relationship of optimization to model training efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="GPT-4o system card">
  <data key="d0">GPT-4o system card</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d2">The GPT-4o system card documents the features, capabilities, and specifications of the GPT-4O model, associated with OpenAI.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Source code">
  <data key="d0">Source code</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d2">MagicCoder emphasizes source code as a core component of its architecture, highlighting the importance of source code in AI models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Model training techniques">
  <data key="d0">Model training techniques</data>
  <data key="d3">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d2">Training techniques like knowledge distillation and sparsity exploitation are aimed at improving model efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Deep learning library">
  <data key="d0">Deep learning library</data>
  <data key="d3">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d2">Pytorch is a deep learning library used for building neural networks and training models, as described in 2019.&lt;SEP&gt;Pytorch is a deep learning library used for constructing neural network models, as described in 2019.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</node>
<node id="Optimization">
  <data key="d0">Optimization</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-71ae4149c46ebd3eaae68a58bc6a57e2&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-3487322ee335c5f4b3b40717a7de46d1&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d2">A methodology aimed at improving the Adam optimizer by addressing regularization issues, proposed in 2017.&lt;SEP&gt;Process of tuning DSPy modules and pipelines to enhance task performance, guided by the compiler.&lt;SEP&gt;The process of tuning DSPy modules and pipelines to maximize metrics like accuracy or reasoning quality, facilitated by the compiler.&lt;SEP&gt;Global optimization involves reordering and hardware mapping to improve parallel execution efficiency.&lt;SEP&gt;Optimization involves improving the efficiency and performance of computational processes, such as data handling, parallel execution, and code generation.&lt;SEP&gt;Optimization strategies involve recognizing parallelism potential, inlining functions, loop unrolling, and flattening hierarchical code structures to generate efficient parallel code.&lt;SEP&gt;Processes applied to improve code performance, including kernel tuning, parallelism enhancements, and code rewriting.&lt;SEP&gt;Strategies that recognize potential parallelism, enable inlining and loop unrolling, and flatten code hierarchies to generate efficient parallel code respecting semantic constraints.&lt;SEP&gt;Stage focused on enhancing model performance via techniques like gradient descent, prompt refinement, or output post-processing.&lt;SEP&gt;Stage focused on enhancing the model's performance through techniques like gradient descent, prompt refinement, or output post-processing.</data>
  <data key="d1">Methodologies</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Study Designs">
  <data key="d0">Study Designs</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">A 2023 study exploring how LLMs can be used to detect data races in parallel programs.&lt;SEP&gt;Research exploring the application of LLMs to detect data races in parallel code, conducted in 2023.&lt;SEP&gt;Plans or structures for conducting research to investigate specific questions, including experimental, observational, or computational approaches.&lt;SEP&gt;Structured plans for conducting research, such as experiments, observational studies, or surveys, to answer specific questions.&lt;SEP&gt;Study Designs are structured approaches to planning research, such as experiments, observational studies, or surveys, to answer specific research questions.</data>
  <data key="d1">Study Designs</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Evidence Types">
  <data key="d0">Evidence Types</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-9605dfcbeda0fc2efdc5d6c829baafeb&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">A 2022 comprehensive evaluation assessing LLMs' capabilities in code understanding and generation.&lt;SEP&gt;A 2022 study systematically evaluating LLMs' capabilities in code understanding and generation.&lt;SEP&gt;Various forms of data or proof used to support findings, such as quantitative measurements, qualitative observations, or computational results.&lt;SEP&gt;Different forms of data or proof, including qualitative, quantitative, experimental, observational, or mixed methods, used to support findings.&lt;SEP&gt;Evidence Types include various forms of data and proof, such as experimental results, observational data, or qualitative insights, used to support scientific conclusions.</data>
  <data key="d1">Evidence Types</data>
  <data key="d4">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Language Models (LMs)">
  <data key="d0">Language Models (LMs)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">AI systems capable of understanding and generating human language, central to the pipelines developed in DSPy.&lt;SEP&gt;Language models are AI systems capable of understanding and generating human language, which can be prompted and composed into pipelines to solve complex tasks.&lt;SEP&gt;Language models are large neural networks trained on vast textual data, capable of generating coherent text and performing various NLP tasks.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt Templates">
  <data key="d0">Prompt Templates</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Hard-coded strings used to instruct LMs in existing pipelines; their brittleness motivates the development of DSPy for more systematic pipeline design.&lt;SEP&gt;Manual, hard-coded instruction strings used in traditional LM pipelines, which DSPy aims to replace with modular, learnable components.&lt;SEP&gt;Prompt templates are predefined text structures used to guide language models in generating responses, often lengthy and task-specific, requiring careful engineering for effectiveness.&lt;SEP&gt;Prompt templates are predefined text structures used to guide language models, often lengthy and complex, to produce consistent and accurate responses for specific tasks.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Text Transformation Graphs">
  <data key="d0">Text Transformation Graphs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A formal representation of LM pipelines as graphs where nodes are text transformations, facilitating modular composition and optimization.&lt;SEP&gt;Formal representations of LM pipelines as graphs where nodes are text transformations, enabling modular composition and optimization.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Declarative Modules">
  <data key="d0">Declarative Modules</data>
  <data key="d1">Tools</data>
  <data key="d2">Components in DSPy representing LM operations, parameterized to learn and optimize prompting, finetuning, augmentation, and reasoning techniques.&lt;SEP&gt;Components in DSPy that encapsulate LM operations, parameterized to learn and optimize prompting, reasoning, and augmentation techniques.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Compiler">
  <data key="d0">Compiler</data>
  <data key="d1">Tools</data>
  <data key="d2">A system that automatically optimizes DSPy pipelines to maximize specified metrics, improving performance over manual prompt engineering.&lt;SEP&gt;Automated system that optimizes DSPy pipelines to maximize performance metrics, enabling systematic pipeline development.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Math Word Problems">
  <data key="d0">Math Word Problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Complex reasoning tasks involving mathematical problems used as case studies to evaluate DSPy pipelines.&lt;SEP&gt;Complex reasoning tasks used as case studies to evaluate DSPy’s ability to improve reasoning performance.&lt;SEP&gt;The specific questions in GSM8K used to assess reasoning, numerical accuracy, and the impact of different program and prompt strategies.&lt;SEP&gt;The specific type of questions in GSM8K used to assess reasoning and numerical answer accuracy.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Multi-hop Retrieval">
  <data key="d0">Multi-hop Retrieval</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A task involving retrieving multiple pieces of information across sources, demonstrating DSPy's ability to handle multi-stage reasoning.&lt;SEP&gt;Task involving retrieving and combining information from multiple sources, demonstrating DSPy’s capacity for multi-stage reasoning.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Llama2-13b-chat">
  <data key="d0">Llama2-13b-chat</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A smaller open-source language model tested with DSPy pipelines to compare performance with proprietary models.&lt;SEP&gt;Open-source language model tested with DSPy, demonstrating effectiveness in smaller models.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompting Techniques">
  <data key="d0">Prompting Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods such as few-shot prompting, Chain of Thought, and ReAct that guide LMs to produce desired outputs, now formalized in DSPy modules.&lt;SEP&gt;Methods such as few-shot prompting, Chain of Thought, and ReAct, formalized within DSPy modules to improve reasoning and task performance.&lt;SEP&gt;Zero-shot or few-shot prompting methods used to elicit executable commands or code from LLMs with minimal examples.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Self-bootstrap Pipelines">
  <data key="d0">Self-bootstrap Pipelines</data>
  <data key="d1">Results</data>
  <data key="d2">DSPy enables LMs like GPT-3.5 and Llama2-13b-chat to generate effective pipelines that outperform standard prompting and expert demonstrations.&lt;SEP&gt;DSPy enables LMs like GPT-3.5 and Llama2-13b-chat to generate effective pipelines that outperform standard prompts and expert demonstrations.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Performance Improvement">
  <data key="d0">Performance Improvement</data>
  <data key="d1">Results</data>
  <data key="d2">Quantitative gains (over 25%, 65%, etc.) in task performance demonstrate DSPy's effectiveness in optimizing LM pipelines.&lt;SEP&gt;Quantitative gains demonstrating DSPy's effectiveness, such as over 25%, 65%, or higher improvements in task accuracy.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Systematic Approach">
  <data key="d0">Systematic Approach</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">By replacing brittle prompt templates with optimized, modular pipelines, DSPy enables scalable, adaptable NLP systems with improved robustness.&lt;SEP&gt;Replacing brittle prompt templates with optimized, modular pipelines enables scalable, robust NLP systems.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Preprint">
  <data key="d0">Preprint</data>
  <data key="d1">Study Design</data>
  <data key="d2">A preliminary version of a scientific paper shared publicly before formal peer review, used here to introduce the DSPy methodology.&lt;SEP&gt;A prepublication version of research work shared publicly to disseminate findings prior to peer review.&lt;SEP&gt;Preprint refers to a preliminary version of a scientific paper shared publicly before formal peer review, often used to disseminate early findings and gather feedback.&lt;SEP&gt;Preprint refers to a preliminary version of a scientific paper shared publicly before peer review, indicating the type of document being discussed.&lt;SEP&gt;Preprint refers to a version of a scientific paper that has not yet undergone peer review, used here to indicate the type of document.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-d47a0e3d5d118be72a9f7b527b440956&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="COMPLILING DECLARATIVE LANGUAGE">
  <data key="d0">COMPLILING DECLARATIVE LANGUAGE</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The main focus of the paper, referring to the approach of developing a declarative language for constructing and optimizing language model pipelines.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Omar Khattab">
  <data key="d0">Omar Khattab</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in multiple studies on neural information processing and NLP models.&lt;SEP&gt;An author involved in research on neural reasoning, retrieval models, and NLP techniques.&lt;SEP&gt;Author of the paper, involved in developing the DSPy methodology and conducting case studies.&lt;SEP&gt;Omar Khattab is a researcher supported by the Apple Scholars in AI/ML fellowship, contributing to AI research projects.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-583d728170557abef78a4cab2b68abb2&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Arnav Singhvi">
  <data key="d0">Arnav Singhvi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Paridhi Maheshwari">
  <data key="d0">Paridhi Maheshwari</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zhiyuan Zhang">
  <data key="d0">Zhiyuan Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Keshav Santhanam">
  <data key="d0">Keshav Santhanam</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sri Vardhamanan">
  <data key="d0">Sri Vardhamanan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Saiful Haq">
  <data key="d0">Saiful Haq</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ashutosh Sharma">
  <data key="d0">Ashutosh Sharma</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Thomas T. Joshi">
  <data key="d0">Thomas T. Joshi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Hanna Moazam">
  <data key="d0">Hanna Moazam</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Heather Miller">
  <data key="d0">Heather Miller</data>
  <data key="d1">Researcher</data>
  <data key="d2">Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Matei Zaharia">
  <data key="d0">Matei Zaharia</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in research on retrieval and NLP models.&lt;SEP&gt;An author involved in research on retrieval models and large-scale neural reasoning.&lt;SEP&gt;Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Christopher Potts">
  <data key="d0">Christopher Potts</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author contributing to relevance-guided supervision and language model research.&lt;SEP&gt;An author contributing to research on relevance-guided supervision and language models.&lt;SEP&gt;Co-author involved in the research and development of DSPy.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Stanford University">
  <data key="d0">Stanford University</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Academic institution where some authors are affiliated, indicating a research context.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="UC Berkeley">
  <data key="d0">UC Berkeley</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Academic institution where some authors are affiliated, indicating a research context.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Carnegie Mellon University">
  <data key="d0">Carnegie Mellon University</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Academic institution where some authors are affiliated, indicating a research context.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Amazon Alexa AI">
  <data key="d0">Amazon Alexa AI</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Industry research lab involved in the study, indicating applied AI research.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Dashworks Technologies, Inc.">
  <data key="d0">Dashworks Technologies, Inc.</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Industry company involved in the research, indicating applied AI development.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="IIT Bombay">
  <data key="d0">IIT Bombay</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Academic institution involved in the research, indicating a diverse research collaboration.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Calera Capital">
  <data key="d0">Calera Capital</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Investment firm associated with one of the authors, indicating industry involvement.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Microsoft">
  <data key="d0">Microsoft</data>
  <data key="d1">Organization</data>
  <data key="d2">Industry technology company involved in the research, indicating corporate AI research.&lt;SEP&gt;Microsoft is a technology company providing tools and infrastructure like Deepspeed for training large AI models.&lt;SEP&gt;Microsoft provides infrastructure and tools, such as Deepspeed, for training large-scale AI models efficiently.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Two Sigma Investments">
  <data key="d0">Two Sigma Investments</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Financial firm involved in the research, indicating interdisciplinary application.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="https://github.com/stanfordnlp/dspy">
  <data key="d0">https://github.com/stanfordnlp/dspy</data>
  <data key="d1">Tools</data>
  <data key="d2">Online repository hosting DSPy, providing access to the implementation and resources.</data>
  <data key="d3">chunk-5ff9371dcd9f0dcbeb25583bbba6123c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="layers">
  <data key="d0">layers</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Layers are modular components that can be assembled into complex architectures, enabling flexible design and composition in machine learning models.&lt;SEP&gt;Layers refer to modular components that can be assembled into complex architectures, with the capability for model weights to be trained using optimizers rather than manual tuning.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy programming model">
  <data key="d0">DSPy programming model</data>
  <data key="d1">Methodologies</data>
  <data key="d2">DSPy is a programming framework designed to translate prompting techniques into parameterized modules, enabling task-adaptive, composable text transformations and self-improving NLP systems.&lt;SEP&gt;DSPy is a programming framework that translates prompting techniques into modular, parameterized components for NLP systems, facilitating automation and self-improvement.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="string-based prompting techniques">
  <data key="d0">string-based prompting techniques</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Techniques such as Chain of Thought and ReAct that involve complex, task-dependent prompts used to guide language model outputs.&lt;SEP&gt;Techniques such as Chain of Thought and ReAct that involve structured prompts to guide language model reasoning and output generation.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="declarative modules">
  <data key="d0">declarative modules</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Modules that carry natural-language typed signatures, representing text transformation components within DSPy, which can be learned and adapted.&lt;SEP&gt;Modules within DSPy that carry natural-language signatures, representing specific text transformation functions that can be learned and adapted.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="neural network layers">
  <data key="d0">neural network layers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Fundamental components of neural architectures that DSPy modules abstract and emulate in task-adaptive pipelines.&lt;SEP&gt;Fundamental units of neural architectures that DSPy modules abstract to enable flexible composition.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="bootstrapping demonstrations">
  <data key="d0">bootstrapping demonstrations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Iterative examples provided within the pipeline that help modules learn desired behaviors through self-supervised signals.&lt;SEP&gt;Iterative process of providing useful examples within the pipeline to enable modules to learn desired behaviors.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="expressive define-by-run computational graphs">
  <data key="d0">expressive define-by-run computational graphs</data>
  <data key="d1">Tools</data>
  <data key="d2">Dynamic graph frameworks used in DSPy to declare and connect modules during execution, allowing flexible pipeline design.&lt;SEP&gt;Frameworks used in DSPy to declare and connect modules dynamically during execution, facilitating flexible pipeline design.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy compiler">
  <data key="d0">DSPy compiler</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A system that optimizes DSPy programs by simulating versions, constructing effective prompts, and fine-tuning small language models for improved performance.&lt;SEP&gt;A system that optimizes DSPy programs by simulating, evaluating, and refining pipeline components, including prompt generation and model fine-tuning.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="teleprompters">
  <data key="d0">teleprompters</data>
  <data key="d1">Tools</data>
  <data key="d2">General-purpose optimization strategies within DSPy that guide how modules learn from data to improve quality or reduce costs.&lt;SEP&gt;Optimization strategies within DSPy that automatically guide module learning and pipeline improvement, reducing manual prompting.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="multi-hop question answering (HotPotQA)">
  <data key="d0">multi-hop question answering (HotPotQA)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A dataset and task involving reasoning across multiple pieces of information to answer complex questions, used here for evaluating DSPy.&lt;SEP&gt;A dataset and task involving reasoning across multiple pieces of information, used to evaluate DSPy in multi-step reasoning scenarios.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="math word problems (GMS8K)">
  <data key="d0">math word problems (GMS8K)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A dataset comprising mathematical word problems used to assess the effectiveness of DSPy in solving structured reasoning tasks.&lt;SEP&gt;A dataset of mathematical word problems used to assess DSPy's reasoning and problem-solving capabilities.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="small language models (e.g., llama2-13b-chat, T5-Large)">
  <data key="d0">small language models (e.g., llama2-13b-chat, T5-Large)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Language models of varying sizes used to evaluate the effectiveness of DSPy pipelines in resource-constrained settings.&lt;SEP&gt;Language models of varying sizes used to evaluate the performance of DSPy pipelines in resource-constrained settings.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="prompting techniques">
  <data key="d0">prompting techniques</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Methods like Chain of Thought that guide language models' reasoning processes through structured prompts.&lt;SEP&gt;Structured prompts like Chain of Thought that guide models' reasoning processes to improve performance.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="self-improving NLP systems">
  <data key="d0">self-improving NLP systems</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Systems capable of enhancing their performance iteratively through modular, automated pipelines like DSPy.&lt;SEP&gt;Systems capable of iteratively enhancing their performance through modular pipelines like DSPy, reducing reliance on manual prompt engineering.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="optimization strategies (teleprompters)">
  <data key="d0">optimization strategies (teleprompters)</data>
  <data key="d1">Tools</data>
  <data key="d2">Automated strategies within DSPy that improve pipeline quality and efficiency by guiding learning and refinement processes.&lt;SEP&gt;Strategies used within DSPy to improve pipeline quality and efficiency by guiding learning and adaptation processes.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="model weights">
  <data key="d0">model weights</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Model weights are parameters within neural networks that determine the model's behavior; they can be trained using optimizers instead of manual tuning.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="optimizers">
  <data key="d0">optimizers</data>
  <data key="d1">Tools</data>
  <data key="d2">Optimizers are algorithms used to adjust model weights during training to minimize error and improve performance.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Chain of Thought">
  <data key="d0">Chain of Thought</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A prompting technique that encourages models to generate intermediate reasoning steps to improve complex problem solving.</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ReAct">
  <data key="d0">ReAct</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A prompting approach combining reasoning and acting, enabling models to perform actions based on reasoning steps during tasks.&lt;SEP&gt;ReAct is a prompting technique that combines reasoning and acting, allowing models to think and act iteratively for better task performance.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Radford et al. 2018">
  <data key="d0">Radford et al. 2018</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Radford et al. 2018 is a foundational publication that discusses key mechanisms for foundation model programming, emphasizing the role of instruction tuning and prompting in eliciting complex model behaviors.&lt;SEP&gt;Radford et al. 2018 is a foundational work that introduces key mechanisms for foundation model programming, emphasizing the importance of instruction tuning and prompting to elicit sophisticated behaviors in language models.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Brown et al. 2020">
  <data key="d0">Brown et al. 2020</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Brown et al. 2020 is a significant publication contributing to understanding foundation models and their programming mechanisms.&lt;SEP&gt;Brown et al. 2020 is a significant work contributing to understanding how foundation models are developed and utilized, providing insights into model training and capabilities.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Instruction Tuning">
  <data key="d0">Instruction Tuning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Instruction tuning involves fine-tuning models with specific instructions to improve their ability to follow prompts and perform tasks effectively.&lt;SEP&gt;Instruction tuning is a method to train language models to follow instructions better, thereby eliciting more sophisticated behaviors when prompted.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompting">
  <data key="d0">Prompting</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Prompting is a technique used to elicit desired outputs from language models by providing carefully designed input cues or instructions.&lt;SEP&gt;Prompting is a technique used to elicit desired responses from language models by providing specific input instructions or cues.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Weak Supervision">
  <data key="d0">Weak Supervision</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Weak supervision involves using heuristic or indirect signals to train models, reducing reliance on task-specific labeled data, and can be automated via language models.&lt;SEP&gt;Weak supervision refers to training or guiding models using less explicit, often heuristic-based signals, which can be automated via language models without task-specific heuristics.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="In-context Learning">
  <data key="d0">In-context Learning</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A research question examining whether fine-tuning or parameter updates can enhance the innate few-shot learning abilities of LLMs without destroying their contextual understanding.&lt;SEP&gt;In-context learning allows language models to adapt to new tasks based on examples provided in the prompt, without additional training.&lt;SEP&gt;In-context learning is a method where language models learn to perform tasks based on provided examples or prompts without explicit retraining, leveraging their pre-trained knowledge.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Language Model Pipelines">
  <data key="d0">Language Model Pipelines</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Language model pipelines involve integrating various models and tools such as retrieval models, multimodal foundation models, APIs, and calculators to perform complex tasks.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Toolkits (e.g., LangChain, Semantic Kernel, LlamaIndex)">
  <data key="d0">Toolkits (e.g., LangChain, Semantic Kernel, LlamaIndex)</data>
  <data key="d1">Tools</data>
  <data key="d2">Frameworks that facilitate connecting language models with external tools, enabling multi-stage processing and automation.&lt;SEP&gt;Toolkit frameworks facilitate connecting language models with external tools, enabling multi-stage processing and automation in language model applications.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt Engineering Challenges">
  <data key="d0">Prompt Engineering Challenges</data>
  <data key="d1">Limitations</data>
  <data key="d2">Challenges include managing large prompt sizes, manual prompt crafting, and maintaining modularity, which DSPy aims to address by automating prompt generation and improving structure.&lt;SEP&gt;Challenges include managing large prompt sizes, manual prompt crafting, and maintaining modularity; DSPy aims to address these by automating prompt generation and improving system structure.&lt;SEP&gt;Prompt engineering challenges refer to the difficulties in designing effective prompts, which are addressed by the DSPy framework through modular, high-level abstractions.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy Compiler">
  <data key="d0">DSPy Compiler</data>
  <data key="d1">Tools</data>
  <data key="d2">The DSPy compiler automates the construction of modular language model systems, allowing for optimization techniques like cross-validation, reinforcement learning, and Bayesian hyperparameter tuning.&lt;SEP&gt;The DSPy compiler automates the construction, optimization, and management of modular language model pipelines, supporting techniques like cross-validation, RL, and Bayesian hyperparameter tuning.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Model Selection Techniques (e.g., Cross-Validation, RL, Bayesian Optimization)">
  <data key="d0">Model Selection Techniques (e.g., Cross-Validation, RL, Bayesian Optimization)</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">These techniques are used within DSPy to optimize language model pipelines by selecting the best modules or configurations based on performance metrics.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Benchmark Numbers and Qualitative Measures">
  <data key="d0">Benchmark Numbers and Qualitative Measures</data>
  <data key="d1">Results</data>
  <data key="d2">Empirical evaluation of DSPy demonstrates its ability to build high-quality language model systems without hand-crafted prompts, validated through benchmarks and qualitative analysis.&lt;SEP&gt;The paper reports empirical findings showing DSPy’s effectiveness in building high-quality LM systems without hand-crafted prompts, validated through benchmark comparisons and qualitative assessments.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Formative Work by Bergstra, Paszke, Wolf">
  <data key="d0">Formative Work by Bergstra, Paszke, Wolf</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Foundational research supporting the development of modular, high-level programming models for machine learning and language models, emphasizing benchmarking and qualitative measures.&lt;SEP&gt;These foundational works support the development of programming models that combine benchmark performance with qualitative evaluation for language model systems.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="High-level Declarative Signatures">
  <data key="d0">High-level Declarative Signatures</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Signatures are high-level, declarative descriptions of tasks that abstract away from prompt engineering, enabling systematic pipeline optimization.&lt;SEP&gt;Signatures in DSPy are high-level, natural language descriptions of tasks that abstract prompting and finetuning, enabling systematic pipeline optimization.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Foundation Model Programming">
  <data key="d0">Foundation Model Programming</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Foundation model programming refers to methods and mechanisms for developing and controlling large pre-trained models, including instruction tuning and prompting techniques.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Instruction Tuning with LMs">
  <data key="d0">Instruction Tuning with LMs</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Instruction tuning applied to language models enhances their ability to follow complex instructions and produce sophisticated behaviors.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt Engineering">
  <data key="d0">Prompt Engineering</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Designing input prompts to guide language models toward desired outputs, especially under limited model access.&lt;SEP&gt;Designing prompts to steer LLM outputs for specific tasks, enabling domain-specific applications without extensive retraining.&lt;SEP&gt;Prompt engineering involves crafting specific input instructions or prompts to steer the model's inference process towards domain-relevant outputs without altering internal parameters.&lt;SEP&gt;Prompt engineering involves designing and structuring prompts to effectively guide language models in generating desired outputs, addressing challenges related to prompt formulation and optimization.&lt;SEP&gt;Prompt engineering involves designing effective prompts, including templates and instructions, to elicit desired responses from language models.&lt;SEP&gt;Prompt engineering involves designing prompts to effectively guide language models, addressing challenges related to prompt formulation, size, and modularity to improve task performance.&lt;SEP&gt;Prompt engineering involves designing prompts to guide model output, but faces challenges such as prompt sensitivity and labor-intensive design, which DSPy aims to address.&lt;SEP&gt;The practice of designing and optimizing prompts to guide language models' responses, emphasizing the importance of task-specific and modular prompts in current evaluation pipelines.&lt;SEP&gt;The practice of designing prompts to guide language models' responses, emphasizing the importance of task-specific prompts in current evaluation pipelines.&lt;SEP&gt;The practice of designing and optimizing prompts to improve large language models' performance on specific tasks.&lt;SEP&gt;Prompt engineering involves designing precise prompts to guide AI models like Codex to produce desired and secure outputs, impacting security and effectiveness.&lt;SEP&gt;Prompt engineering involves designing precise prompts to guide AI models toward producing desired, secure, and accurate code outputs, affecting security and effectiveness.&lt;SEP&gt;Prompt engineering involves designing prompts to elicit specific behaviors or outputs from models, used to harness latent capabilities.&lt;SEP&gt;Techniques for designing prompts to activate or demonstrate a model's latent capabilities.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9&lt;SEP&gt;chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85&lt;SEP&gt;chunk-50450e84744379a5c4f059c7d4f84019&lt;SEP&gt;chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-0696a875ae026175ba36c9e8529f7efd&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Tools (e.g., APIs, Retrieval Models, Multimodal Models)">
  <data key="d0">Tools (e.g., APIs, Retrieval Models, Multimodal Models)</data>
  <data key="d1">Tools</data>
  <data key="d2">External tools like APIs, retrieval systems, and multimodal models are integrated with language models to extend their capabilities in complex pipelines.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Signatures in DSPy">
  <data key="d0">Signatures in DSPy</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Signatures are high-level, natural language descriptions of tasks that abstract prompting, enabling flexible and systematic pipeline design.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Modules in DSPy">
  <data key="d0">Modules in DSPy</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Modules are modular units representing specific tasks or transformations in the pipeline, replacing traditional prompt strings and enabling composition.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Teleprompters in DSPy">
  <data key="d0">Teleprompters in DSPy</data>
  <data key="d1">Tools</data>
  <data key="d2">Teleprompters are components that optimize the modules in a pipeline to maximize performance according to specified metrics.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Optimization Techniques (e.g., Cross-validation, RL, Bayesian Optimization)">
  <data key="d0">Optimization Techniques (e.g., Cross-validation, RL, Bayesian Optimization)</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">These techniques are used within DSPy to select and tune modules and pipelines for optimal performance based on metrics.</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Signatures">
  <data key="d0">Signatures</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Signatures define structured interfaces for language model tasks, specifying input and output formats to enable consistent and modular prompting.&lt;SEP&gt;Signatures define structured interfaces for language model tasks, specifying input and output formats to standardize prompting and facilitate modularity.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Predict">
  <data key="d0">Predict</data>
  <data key="d1">Tools</data>
  <data key="d2">Predict is a core module within DSPy that executes prompts based on defined signatures, manages demonstrations, and parses outputs to produce structured responses.&lt;SEP&gt;Predict is a core module within DSPy that executes prompts based on defined signatures, manages demonstrations, and parses outputs.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ChainOfThought">
  <data key="d0">ChainOfThought</data>
  <data key="d1">Methodology</data>
  <data key="d2">A reasoning framework that involves generating a step-by-step rationale before producing the final answer, enhancing interpretability and reasoning."|&lt;SEP&gt;ChainOfThought is a module that guides language models to reason step-by-step before producing final outputs, enhancing reasoning capabilities.&lt;SEP&gt;ChainOfThought is a module that guides language models to reason step-by-step before producing final outputs, improving reasoning accuracy and interpretability.</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Modules">
  <data key="d0">Modules</data>
  <data key="d1">Tools</data>
  <data key="d2">Modules like ChainOfThought, ProgramOfThought, MultiChainComparison, and ReAct are specialized components that extend DSPy's prompting techniques for various reasoning and multi-stage tasks.&lt;SEP&gt;Modules like ChainOfThought, ProgramOfThought, MultiChainComparison, and ReAct extend DSPy's prompting techniques for various reasoning and multi-stage tasks.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Structured Prompting">
  <data key="d0">Structured Prompting</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Structured prompting involves designing prompts with explicit fields and formats to enhance model understanding, consistency, and output quality.&lt;SEP&gt;Structured prompting involves designing prompts with explicit formats and fields to improve model understanding and output accuracy.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Parameterization">
  <data key="d0">Parameterization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Parameterization allows customization of prompts, modules, and signatures, enabling task-specific configurations and flexible prompt design.&lt;SEP&gt;Parameterization in DSPy allows customization of prompting modules and signatures, enabling flexible and task-specific configurations.&lt;SEP&gt;Refers to the process of defining and adjusting parameters that customize the behavior of prompting techniques or models.&lt;SEP&gt;The process of defining and adjusting parameters that control the behavior, configuration, or customization of prompting techniques and models.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bootstrapping">
  <data key="d0">Bootstrapping</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A statistical resampling technique mentioned as a potential approach for dynamic, test-time adaptation in evaluation processes.&lt;SEP&gt;A statistical resampling technique mentioned as a potential approach for dynamic, test-time evaluation and adaptation processes in model performance assessment.&lt;SEP&gt;Bootstrapping involves using demonstrations, examples, or iterative prompting to improve language model performance on specific tasks.&lt;SEP&gt;Bootstrapping refers to the process of using demonstrations and examples to improve the performance of language models on specific tasks.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Self-Improving">
  <data key="d0">Self-Improving</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Self-improving techniques involve refining prompts and modules through feedback, demonstrations, and structured interfaces to enhance output quality over iterations.&lt;SEP&gt;Self-improving techniques involve refining prompts and modules through iterative demonstrations and structured interfaces to enhance model outputs.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy">
  <data key="d0">dspy</data>
  <data key="d1">Methodology</data>
  <data key="d2">dspy is a framework that supports structured prompting, modular design, and parsing for language models, enabling flexible and efficient task execution.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Modularity">
  <data key="d0">Modularity</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Modularity in DSPy refers to designing prompts and components that can be combined, reused, and adapted across different tasks and contexts.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Demonstrations">
  <data key="d0">Demonstrations</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Demonstrations are example inputs and outputs used to guide language models, especially in few-shot learning, to improve task performance.&lt;SEP&gt;Demonstrations refer to specific examples or instances used to illustrate or evaluate a program, often involving a sequence of steps or actions.&lt;SEP&gt;Specific examples or instances used to illustrate, evaluate, or test a program, often involving sequences of steps or actions, which serve as a basis for comparison or optimization.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Outputs">
  <data key="d0">Outputs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Outputs are the generated responses from language models, which are parsed and structured according to signatures and modules.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Parsing">
  <data key="d0">Parsing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Parsing involves extracting structured information from language model outputs based on predefined formats and signatures.&lt;SEP&gt;Parsing is the first stage where user input, including DSL code and hardware description, is evaluated to prepare for further processing.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Task-Specific Modules">
  <data key="d0">Task-Specific Modules</data>
  <data key="d1">Tools</data>
  <data key="d2">Task-specific modules in DSPy are designed to handle particular reasoning or multi-stage processes, improving accuracy and efficiency.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Multi-Stage Reasoning">
  <data key="d0">Multi-Stage Reasoning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Multi-stage reasoning involves breaking complex tasks into multiple steps or modules to improve reasoning and accuracy.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Meta-Prompting">
  <data key="d0">Meta-Prompting</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Meta-prompting involves prompts that instruct models to generate reasoning, plan, or structure before producing final answers, enhancing interpretability.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Evaluation">
  <data key="d0">Evaluation</data>
  <data key="d1">Study Design</data>
  <data key="d2">An assessment process of the current state of the prototype, focusing on issues with global optimization and code generation, including performance and scalability analysis.&lt;SEP&gt;Evaluation assesses the effectiveness of the code generator and optimization toolchain through benchmark comparisons, measuring runtime and performance metrics.&lt;SEP&gt;Evaluation in DSPy involves assessing prompt effectiveness, module performance, and output quality across tasks.&lt;SEP&gt;Evaluation involves assessing the performance of a program using metrics like score, often through functions like evaluate_program.&lt;SEP&gt;The process of assessing the performance of a program using metrics like scores, often through functions like evaluate_program, to determine effectiveness.&lt;SEP&gt;The evaluation measures the accuracy and quality of generated code, including compilation and execution success, to assess LLM performance.&lt;SEP&gt;Assessment of LLMs' performance on reasoning tasks, showing that zero-shot-CoT significantly enhances logical reasoning capabilities without additional training data.&lt;SEP&gt;The final stage where the performance of the adapted model is tested against benchmarks, and feedback is used for further refinement.&lt;SEP&gt;The final stage where the specialized model's performance is tested against benchmarks, and feedback is used for refinement.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-daac5179ef8fa77fe775da37eb1276f3&lt;SEP&gt;chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Generalization">
  <data key="d0">Generalization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Generalization refers to the ability of DSPy-designed prompts and modules to perform well across different tasks and domains.&lt;SEP&gt;The ability of an LLM to apply learned knowledge to new, unseen tasks or domains effectively, crucial for zero-shot and few-shot performance.</data>
  <data key="d3">chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="forward the inputs to the sub-module">
  <data key="d0">forward the inputs to the sub-module</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An instruction indicating that input data should be processed through a designated sub-module within a computational pipeline.&lt;SEP&gt;Represents a procedural instruction to process inputs through a sub-module within a system or workflow.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="12 return self.predict(**kwargs)">
  <data key="d0">12 return self.predict(**kwargs)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A code statement indicating a method call to generate predictions, typical in programming for machine learning models.&lt;SEP&gt;A programming statement invoking a prediction method with flexible keyword arguments, typical in machine learning workflows.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="This is a fully-fledged module capable of learning effective few-shot prompting for any LM or task">
  <data key="d0">This is a fully-fledged module capable of learning effective few-shot prompting for any LM or task</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Describes a comprehensive module designed to learn and optimize few-shot prompting techniques applicable across language models and tasks.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Appendix C">
  <data key="d0">Appendix C</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A referenced section in a document that contains examples or supplementary information related to prompting techniques.&lt;SEP&gt;A referenced section in a document that contains supplementary information or examples related to prompting techniques.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="long reasoning prompts hand-written by sources">
  <data key="d0">long reasoning prompts hand-written by sources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Manually crafted prompts created by various sources, used as benchmarks or examples in prompting research.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="parameterizes these prompting techniques">
  <data key="d0">parameterizes these prompting techniques</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Indicates that DSPy enables customization and configuration of prompting methods through parameter settings.&lt;SEP&gt;Indicates that DSPy enables customization of prompting strategies via parameter settings.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="LM call seeking to implement a particular signature">
  <data key="d0">LM call seeking to implement a particular signature</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A specific invocation of a language model with a defined input-output signature to perform a task.&lt;SEP&gt;A specific invocation of a language model with defined input-output signatures to perform tasks.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="parameters that include: (1) the specific LM to call (Chen et al., 2023), (2) the prompt instructions (Yang et al., 2023) and the string prefix of each signature field and, most importantly, (3) the demonstrations used as few-shot prompts">
  <data key="d0">parameters that include: (1) the specific LM to call (Chen et al., 2023), (2) the prompt instructions (Yang et al., 2023) and the string prefix of each signature field and, most importantly, (3) the demonstrations used as few-shot prompts</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters that specify the language model used, instructions for prompting, and demonstration data for few-shot learning.&lt;SEP&gt;Parameters that specify which language model to use, how to instruct it, and which demonstrations to include for few-shot learning.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="automatically generating and selecting useful demonstrations">
  <data key="d0">automatically generating and selecting useful demonstrations</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of creating and choosing effective example prompts to improve language model performance in few-shot settings.&lt;SEP&gt;The process of creating and choosing example prompts that effectively teach the model desired behaviors, often through automation.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="bootstrapping good demonstrations">
  <data key="d0">bootstrapping good demonstrations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to iteratively generate and refine example prompts that teach the model desired behaviors.&lt;SEP&gt;A technique where initial demonstrations are generated or refined iteratively to improve model performance in few-shot settings.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Tools DSPy programs may use tools">
  <data key="d0">Tools DSPy programs may use tools</data>
  <data key="d1">Tools</data>
  <data key="d2">Modules within DSPy that execute computations or retrieve information, such as retrieval models or code execution modules.&lt;SEP&gt;Modules within DSPy that execute computations, retrieve data, or run code, supporting various pipeline activities.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="retrieval models through a dspy.Retrieve module">
  <data key="d0">retrieval models through a dspy.Retrieve module</data>
  <data key="d1">Tools</data>
  <data key="d2">Modules used for fetching relevant data passages from external sources or databases.&lt;SEP&gt;Modules used to fetch relevant data passages from external sources or databases.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ColBERTv2, Pyserini, and Pinecone retrievers">
  <data key="d0">ColBERTv2, Pyserini, and Pinecone retrievers</data>
  <data key="d1">Tools</data>
  <data key="d2">Specific retrieval system implementations supported by DSPy for information retrieval tasks.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="experimental dspy.SQL for executing SQL queries">
  <data key="d0">experimental dspy.SQL for executing SQL queries</data>
  <data key="d1">Tools</data>
  <data key="d2">A module supporting execution of SQL commands within DSPy workflows.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.PythonInterpreter for executing Python code in a sandbox">
  <data key="d0">dspy.PythonInterpreter for executing Python code in a sandbox</data>
  <data key="d1">Tools</data>
  <data key="d2">A module allowing safe execution of Python code snippets during pipeline processing.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Programs DSPy modules can be composed in arbitrary pipelines">
  <data key="d0">Programs DSPy modules can be composed in arbitrary pipelines</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Describes the flexible, modular design of DSPy enabling complex workflows by chaining modules.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="define-by-run interface">
  <data key="d0">define-by-run interface</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An approach where pipeline components are declared and executed dynamically, allowing customization and optimization.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="simple illustration, retrieval-augmented generation (RAG) system">
  <data key="d0">simple illustration, retrieval-augmented generation (RAG) system</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A sample system combining retrieval and generation modules to answer questions based on external data.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="class RAG(dspy.Module)">
  <data key="d0">class RAG(dspy.Module)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A class definition illustrating a retrieval-augmented generation pipeline in DSPy with configurable components.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="def __init__(self, num_passages=3)">
  <data key="d0">def __init__(self, num_passages=3)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Constructor method initializing the RAG system with a specified number of retrieved passages.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="self.retrieve = dspy.Retrieve(k=num_passages)">
  <data key="d0">self.retrieve = dspy.Retrieve(k=num_passages)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Assignment of a retrieval module for fetching data passages in the RAG pipeline.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="self.generate_answer = dspy.ChainOfThought('context, question -&gt; answer')">
  <data key="d0">self.generate_answer = dspy.ChainOfThought('context, question -&gt; answer')</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Assignment of a generation module that produces answers based on retrieved context and questions.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="def forward(self, question)">
  <data key="d0">def forward(self, question)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Defines the forward pass of the RAG system, processing a question through retrieval and generation modules.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="context = self.retrieve(question).passages">
  <data key="d0">context = self.retrieve(question).passages</data>
  <data key="d1">Variables</data>
  <data key="d2">Retrieves relevant passages based on the question for use in answer generation.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="return self.generate_answer(context=context, question=question)">
  <data key="d0">return self.generate_answer(context=context, question=question)</data>
  <data key="d1">Results</data>
  <data key="d2">Outputs the generated answer based on retrieved context, completing the pipeline process.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="To highlight modularity, we use ChainOfThought as a drop-in replacement of the basic Predict">
  <data key="d0">To highlight modularity, we use ChainOfThought as a drop-in replacement of the basic Predict</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Emphasizes the interchangeable nature of modules within DSPy pipelines, facilitating experimentation.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="One can now simply write RAG()('Where is Guaraní spoken?')">
  <data key="d0">One can now simply write RAG()('Where is Guaraní spoken?')</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Demonstrates ease of use and practical application of the RAG system for answering questions.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Notice that, if we use a signature 'context, question -&gt; search query', we get a system that generates search queries rather than answers">
  <data key="d0">Notice that, if we use a signature 'context, question -&gt; search query', we get a system that generates search queries rather than answers</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Shows the flexibility of the pipeline configuration to produce different outputs based on signature design.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="When compiling a DSPy program, we generally invoke a teleprompter">
  <data key="d0">When compiling a DSPy program, we generally invoke a teleprompter</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A component that optimizes DSPy programs based on training data and metrics to improve performance.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="which is an optimizer that takes the program, a training set, and a metric—and returns a new optimized program">
  <data key="d0">which is an optimizer that takes the program, a training set, and a metric—and returns a new optimized program</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The teleprompter as an optimization tool that refines DSPy workflows.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="training sets may be small, potentially a handful of examples">
  <data key="d0">training sets may be small, potentially a handful of examples</data>
  <data key="d1">Variables</data>
  <data key="d2">Small datasets used for training and optimizing DSPy pipelines.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="training examples may be incomplete, i.e., only input values are necessary">
  <data key="d0">training examples may be incomplete, i.e., only input values are necessary</data>
  <data key="d1">Variables</data>
  <data key="d2">Training data that may lack labels for intermediate steps, relying only on inputs and final outputs.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="labels for the pipeline steps are not required, unless they need to be used in the metric">
  <data key="d0">labels for the pipeline steps are not required, unless they need to be used in the metric</data>
  <data key="d1">Variables</data>
  <data key="d2">Labels that are optional unless evaluation metrics depend on intermediate outputs.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="assume labels only for (at most) the program’s final output">
  <data key="d0">assume labels only for (at most) the program’s final output</data>
  <data key="d1">Variables</data>
  <data key="d2">Focus on labels for final results to reduce annotation effort during pipeline training.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="behavior like this might be more accurately checked by another DSPy program that checks for faithful grounding of answers">
  <data key="d0">behavior like this might be more accurately checked by another DSPy program that checks for faithful grounding of answers</data>
  <data key="d1">Content_keywords</data>
  <data key="d2">Answer verification, grounding, evaluation metrics, pipeline robustness&lt;SEP&gt;Describes the potential for specialized DSPy programs to verify answer correctness and grounding.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Metrics can be simple notions like exact match (EM) or F1">
  <data key="d0">Metrics can be simple notions like exact match (EM) or F1</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Evaluation metrics used to assess the accuracy of model outputs, such as exact match or F1 score.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="they can be entire DSPy programs that balance multiple concerns">
  <data key="d0">they can be entire DSPy programs that balance multiple concerns</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Complex evaluation strategies that incorporate multiple metrics or constraints for optimization.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="bootstrap missing labels: reasoning chains and retrieval contexts">
  <data key="d0">bootstrap missing labels: reasoning chains and retrieval contexts</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Technique where the teleprompter generates or infers labels and demonstrations to bootstrap the training process.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="qa_trainset = [dspy.Example(question='What is the capital of France?', answer='Paris')]">
  <data key="d0">qa_trainset = [dspy.Example(question='What is the capital of France?', answer='Paris')]</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A small training dataset containing question-answer pairs used to bootstrap the DSPy pipeline.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="The teleprompter will bootstrap missing labels: reasoning chains and retrieval contexts">
  <data key="d0">The teleprompter will bootstrap missing labels: reasoning chains and retrieval contexts</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Describes the process by which the teleprompter generates additional supervision signals for training.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="compiled_rag = teleprompter.compile(RAG(), trainset=qa_trainset)">
  <data key="d0">compiled_rag = teleprompter.compile(RAG(), trainset=qa_trainset)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The resulting optimized RAG pipeline after teleprompter compilation, ready for deployment.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="answer_and_context_match(example, pred, trace=None)">
  <data key="d0">answer_and_context_match(example, pred, trace=None)</data>
  <data key="d1">Methods</data>
  <data key="d2">A custom evaluation function that checks if the answer and context match the expected output, used as a metric during training.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="answer_match = dspy.evaluate.answer_exact_match(example, pred)">
  <data key="d0">answer_match = dspy.evaluate.answer_exact_match(example, pred)</data>
  <data key="d1">Variables</data>
  <data key="d2">Calculates whether the predicted answer exactly matches the ground truth.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="context_match = any((pred.answer.lower() in c) for c in pred.context)">
  <data key="d0">context_match = any((pred.answer.lower() in c) for c in pred.context)</data>
  <data key="d1">Variables</data>
  <data key="d2">Checks if the predicted answer appears within the retrieved context passages.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="return answer_match and context_match">
  <data key="d0">return answer_match and context_match</data>
  <data key="d1">Results</data>
  <data key="d2">Returns a combined boolean indicating whether both answer and context are correctly matched.</data>
  <data key="d3">chunk-ccadaa64b5b17c98386463d79a2cfaca</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="answer_exact_match">
  <data key="d0">answer_exact_match</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric measuring the exact string match accuracy of model answers against ground truth.&lt;SEP&gt;A metric used to evaluate the accuracy of the model's answers by exact string matching.&lt;SEP&gt;The function evaluate.answer_exact_match compares predicted answers with reference answers to determine exact matches, used for evaluating answer accuracy.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4&lt;SEP&gt;chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="context_match">
  <data key="d0">context_match</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A metric that checks if the predicted answer is a substring of the context passage, used to assess grounding fidelity.&lt;SEP&gt;A metric that checks whether the predicted answer is a substring of the context passage, used to assess whether the answer is grounded in the context.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="teleprompter">
  <data key="d0">teleprompter</data>
  <data key="d1">Tools</data>
  <data key="d2">An optimizer component within DSPy that enhances modules via prompting or finetuning, aiming to improve the quality and efficiency of program components.&lt;SEP&gt;An optimizer within DSPy that enhances program modules through prompting or finetuning, improving solution quality and cost efficiency.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="predict modules">
  <data key="d0">predict modules</data>
  <data key="d1">Tools</data>
  <data key="d2">Modules in DSPy responsible for generating predictions, which can be optimized or replaced during compilation or training.&lt;SEP&gt;Modules in DSPy that generate predictions or outputs, which can be optimized or replaced during compilation.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="BootstrapFewShot">
  <data key="d0">BootstrapFewShot</data>
  <data key="d1">Methodology</data>
  <data key="d2">A stage in DSPy where a teacher-like program generates demonstrations by simulating on training inputs, facilitating few-shot learning without explicit labels.&lt;SEP&gt;A technique that creates a large number of potential demonstrations by sampling or generating examples to enhance training or evaluation processes.&lt;SEP&gt;A teleprompter stage that simulates a teacher program on training inputs to generate demonstrations for few-shot learning.&lt;SEP&gt;BootstrapFewShot is a technique used to generate a large number of potential demonstrations to improve program training or evaluation.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4&lt;SEP&gt;chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="candidate generation">
  <data key="d0">candidate generation</data>
  <data key="d1">Methodology</data>
  <data key="d2">The process of creating candidate demonstrations, instructions, or parameters for model training, tuning, or optimization within DSPy.&lt;SEP&gt;The process of identifying unique predictors and generating candidate demonstrations, instructions, or parameters for model training and optimization.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="parameter optimization">
  <data key="d0">parameter optimization</data>
  <data key="d1">Methodology</data>
  <data key="d2">Techniques such as random search or hyperparameter tuning algorithms (e.g., HyperOpt, Optuna) used to select the best candidate parameters for models or demonstrations.&lt;SEP&gt;Techniques such as random search or hyperparameter tuning algorithms (e.g., HyperOpt, Optuna) used to select the best candidates for model parameters or demonstrations.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="finetuning">
  <data key="d0">finetuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A process where the language model's weights are updated using demonstrations to improve performance, often applied in bootstrap or ensemble stages.&lt;SEP&gt;A process where the language model's weights are updated using demonstrations, improving performance, often within bootstrap or ensemble stages.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ensemble">
  <data key="d0">ensemble</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique that combines multiple copies of a program to run predictions in parallel and aggregate their outputs, enhancing robustness and accuracy.&lt;SEP&gt;A technique that combines multiple instances of a program or model to run predictions in parallel and aggregate outputs, increasing robustness and accuracy.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Higher-Order Program Optimization">
  <data key="d0">Higher-Order Program Optimization</data>
  <data key="d1">Methodology</data>
  <data key="d2">Methods that modify the control flow of programs, such as creating ensembles, to enhance efficiency and prediction quality in DSPy.&lt;SEP&gt;Modifying control flow structures, such as ensembles, to improve program efficiency and prediction quality in DSPy.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Goals of Evaluation">
  <data key="d0">Goals of Evaluation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Main evaluation focus on computational efficiency, developer efficiency, and the effectiveness of language model pipelines, especially in grounding and optimization.&lt;SEP&gt;The main focus is on evaluating the efficiency, intuitiveness, and effectiveness of LM pipelines, particularly in terms of computational and developer efficiency.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="evaluate.answer_exact_match">
  <data key="d0">evaluate.answer_exact_match</data>
  <data key="d1">Methodology</data>
  <data key="d2">A function that compares predicted answers to reference answers for exact match, used to evaluate answer correctness.</data>
  <data key="d3">chunk-8e85c7ed399116091462832c72381ba4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Majority Voting">
  <data key="d0">Majority Voting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique that combines multiple model outputs to determine the most probable answer, used here as a custom ensemble decision method to improve accuracy and robustness.&lt;SEP&gt;A technique that combines multiple outputs to determine the most probable answer, used here as a custom function for ensemble decision-making.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Program Modules">
  <data key="d0">Program Modules</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Reusable components such as Predict, ChainOfThought, MultiChainComparison, and other modules that can be assembled into complex reasoning pipelines for evaluation and task solving.&lt;SEP&gt;Reusable components such as Predict, ChainOfThought, and MultiChainComparison that can be assembled to perform complex reasoning tasks.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Task-Specific Prompts">
  <data key="d0">Task-Specific Prompts</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Handcrafted prompts tailored for specific tasks, whose replacement with modular components is a key focus of the evaluation.&lt;SEP&gt;Questions regarding whether replacing handcrafted prompts with modular components affects performance and adaptability across different language models.&lt;SEP&gt;Task-specific prompts are designed templates tailored for particular tasks like math problems or QA, often lengthy, requiring careful engineering for effectiveness.&lt;SEP&gt;Task-specific prompts are tailored templates designed for particular tasks like math problems or QA, often lengthy, requiring careful design to maximize effectiveness.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd&lt;SEP&gt;chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GSM8K Dataset">
  <data key="d0">GSM8K Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A benchmark dataset consisting of grade school math word problems used to evaluate the effectiveness of different prompting strategies and program modules.&lt;SEP&gt;A benchmark dataset of grade school math word problems used to evaluate the effectiveness of different prompting strategies and program modules.&lt;SEP&gt;A benchmark dataset of math word problems used to evaluate the effectiveness of compilation and prompting strategies.&lt;SEP&gt;A benchmark dataset of math word problems used to evaluate the performance of different program compilation strategies and models.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Program Compilation Strategies">
  <data key="d0">Program Compilation Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Various approaches for converting modular programs into optimized forms, including zero-shot, few-shot, bootstrap, and ensemble methods for enhancing model performance and robustness.&lt;SEP&gt;Various approaches for converting modular programs into optimized forms, including zero-shot, few-shot, bootstrap, and ensemble methods.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Evaluation Results">
  <data key="d0">Evaluation Results</data>
  <data key="d1">Results</data>
  <data key="d2">Compilation of accuracy improvements and performance metrics demonstrating the benefit of modular, compiled approaches over traditional string prompts.&lt;SEP&gt;Data demonstrating that compiling programs into optimized forms significantly improves accuracy and performance over traditional string prompt methods.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Hypotheses">
  <data key="d0">Hypotheses</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The core hypotheses tested are that modular programs can replace handcrafted prompts without loss of quality, improve adaptability across models, and enable exploration of complex pipelines with nuanced metrics.</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Compilation Strategies">
  <data key="d0">Compilation Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Various compilation strategies such as zero-shot, labeled few-shot, bootstrap few-shot with random search, nested bootstrap, and ensembling are used to optimize DSPy programs for better performance.&lt;SEP&gt;Various strategies such as zero-shot, labeled few-shot, bootstrap few-shot with random search, nested bootstrap, and ensembling are used to optimize DSPy programs for improved performance.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zero-Shot Evaluation">
  <data key="d0">Zero-Shot Evaluation</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Assessment of language models' baseline performance on math problems without any compilation or prompting enhancements.&lt;SEP&gt;Assessment of language models' performance on math problems without any compilation or prompting strategies, serving as a baseline.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bootstrapping with Random Search">
  <data key="d0">Bootstrapping with Random Search</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to generate demonstration chains and optimize selection of examples to improve model reasoning through random search.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ensembling">
  <data key="d0">Ensembling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Combining multiple top candidate programs via majority voting to boost accuracy and robustness.&lt;SEP&gt;Combining multiple top candidate programs via majority voting to enhance accuracy and robustness.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GPT-3.5 and Llama2-13B-Chat">
  <data key="d0">GPT-3.5 and Llama2-13B-Chat</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Language models evaluated for their ability to solve math problems with various compilation and prompting techniques.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Human Reasoning Chains (humanCoT)">
  <data key="d0">Human Reasoning Chains (humanCoT)</data>
  <data key="d1">Tools</data>
  <data key="d2">Human-provided reasoning chains added to training data to enhance model reasoning capabilities.&lt;SEP&gt;Human-provided reasoning chains incorporated into training data to boost model performance on complex reasoning tasks.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Labeled Few-Shot">
  <data key="d0">Labeled Few-Shot</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A compilation method sampling k=8 demonstrations from the training set to improve reasoning, used in DSPy.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bootstrap Few-Shot with Random Search">
  <data key="d0">Bootstrap Few-Shot with Random Search</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Technique to generate demonstration chains and optimize selection via random search to self-improve the program modules.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Nested Bootstrap">
  <data key="d0">Nested Bootstrap</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Using the optimized bootstrap program to further bootstrap another program, creating iterative improvements.</data>
  <data key="d3">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="llama2-34b">
  <data key="d0">llama2-34b</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large language model variant with 34 billion parameters, evaluated for performance metrics in NLP tasks.&lt;SEP&gt;A large language model variant with 34 billion parameters, evaluated in performance benchmarks for natural language processing tasks.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="llama2-70b">
  <data key="d0">llama2-70b</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large language model with 70 billion parameters, assessed for capabilities and performance in NLP tasks.&lt;SEP&gt;A larger language model with 70 billion parameters, assessed for its performance in comparison to other models.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="program">
  <data key="d0">program</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A set of computational procedures or code used to evaluate language models' performance, including variants like the 13b, 34b, and 70b models.&lt;SEP&gt;A set of computational procedures, including different model variants and prompting techniques, used to evaluate model performance.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="CoT (Chain of Thought)">
  <data key="d0">CoT (Chain of Thought)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A reasoning approach involving step-by-step logical chains to improve model reasoning capabilities, reported with specific performance percentages.&lt;SEP&gt;A reasoning methodology involving step-by-step logical chains to improve model accuracy, with performance metrics reported.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GPT-3.5-turbo">
  <data key="d0">GPT-3.5-turbo</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An OpenAI language model used as a benchmark, with performance scores reported for reasoning tasks.&lt;SEP&gt;An OpenAI language model variant used as a benchmark for performance in tasks like GSM8K.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GSM8K">
  <data key="d0">GSM8K</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark dataset for evaluating mathematical reasoning and problem-solving capabilities of language models.&lt;SEP&gt;A dataset used for evaluating mathematical reasoning capabilities of language models.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="HotPotQA">
  <data key="d0">HotPotQA</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset designed for multi-hop question answering in an open-domain setting, used to evaluate reasoning and retrieval methods.&lt;SEP&gt;A dataset for multi-hop question answering in open-domain Wikipedia setting, used to evaluate reasoning and retrieval methods.&lt;SEP&gt;A dataset for multi-hop question answering that involves reasoning across multiple passages, used to evaluate system performance.&lt;SEP&gt;A dataset for multi-hop question answering that involves reasoning across multiple passages, used to evaluate the system's performance.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0&lt;SEP&gt;chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Wikipedia 2017 Abstracts Dump">
  <data key="d0">Wikipedia 2017 Abstracts Dump</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset comprising Wikipedia abstracts used as the retrieval source for the HotPotQA question answering task.&lt;SEP&gt;A dataset used as a retrieval source for the HotPotQA question answering task.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ColBERTv2">
  <data key="d0">ColBERTv2</data>
  <data key="d1">Tools</data>
  <data key="d2">A retrieval model used to search and rank relevant passages from Wikipedia abstracts, facilitating multi-hop reasoning.&lt;SEP&gt;A retrieval model used to search relevant passages from Wikipedia abstracts for the HotPotQA dataset.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.ReAct">
  <data key="d0">dspy.ReAct</data>
  <data key="d1">Tools</data>
  <data key="d2">A multi-step agent for tool use implemented in DSPy, used for question answering with iterative retrieval and reasoning.&lt;SEP&gt;A multi-step reasoning agent in DSPy that combines retrieval and reasoning, used for complex question answering.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.Retrieve">
  <data key="d0">dspy.Retrieve</data>
  <data key="d1">Tools</data>
  <data key="d2">A component in DSPy for retrieving relevant passages given a search query, with configurable parameters like number of passages.&lt;SEP&gt;A component in DSPy responsible for retrieving relevant passages given a query, configurable by number of passages.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="BasicMultiHop">
  <data key="d0">BasicMultiHop</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A custom DSPy module that performs multi-hop retrieval and reasoning by generating queries and answers iteratively over multiple hops.&lt;SEP&gt;A custom DSPy module that performs multi-hop retrieval and reasoning by generating queries and answers over multiple steps.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="BootstrapFewShotWithRandomSearch">
  <data key="d0">BootstrapFewShotWithRandomSearch</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A bootstrapping and fine-tuning approach combining few-shot prompts with random search strategies to improve model performance.&lt;SEP&gt;A technique for bootstrapping models with few-shot prompts combined with random search for improved performance.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="T5-Large">
  <data key="d0">T5-Large</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A 770 million parameter language model used for fine-tuning and evaluation in multi-hop question answering.&lt;SEP&gt;A 770 million parameter language model used for fine-tuning in the multi-hop question answering task.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="13b variant">
  <data key="d0">13b variant</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A smaller model variant with 13 billion parameters, evaluated for competitiveness despite not using human reasoning chains.</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="answer EM">
  <data key="d0">answer EM</data>
  <data key="d1">Results</data>
  <data key="d2">Answer Exact Match score indicating the accuracy of the system's responses compared to correct answers, used as a performance metric.&lt;SEP&gt;Answer Exact Match score measuring the percentage of responses that exactly match the correct answers, used as a key performance metric.&lt;SEP&gt;The exact match score indicating the percentage of answers that precisely match the correct answers.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0&lt;SEP&gt;chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="expert human reasoning">
  <data key="d0">expert human reasoning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Expert human reasoning involves cognitive processes used by humans to analyze, interpret, and make decisions or inferences, often adapted for specific tasks such as retrieval and problem-solving in AI systems.&lt;SEP&gt;Expert human reasoning refers to the cognitive process of analyzing, interpreting, and making decisions based on complex information, often adapted for specific tasks such as retrieval or problem-solving.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yao et al. (2022)">
  <data key="d0">Yao et al. (2022)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A scholarly work that discusses the adaptation of expert reasoning to retrieval settings, providing foundational concepts for the current methodology.&lt;SEP&gt;A scholarly work that discusses the adaptation of expert reasoning to retrieval settings, serving as a foundational reference for the current methodology.&lt;SEP&gt;Research demonstrating 27.4% EM with ReAct and PaLM-540B, and 30.8% with text-davinci-002, utilizing a Wikipedia API for search.&lt;SEP&gt;Research that achieved 27.4% EM with ReAct and PaLM-540B, and 30.8% with text-davinci-002, utilizing a Wikipedia API for search.&lt;SEP&gt;Yao et al. (2022) is a referenced research or publication, likely involving experimental or analytical methods.&lt;SEP&gt;Yao et al. (2022) is a research publication that explores methodologies like ReAct, possibly involving experimental design or theoretical analysis.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0&lt;SEP&gt;chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="llama2-13b-chat">
  <data key="d0">llama2-13b-chat</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large language model with 13 billion parameters, evaluated for its competitive performance against GPT-3.5 through fine-tuning and program compilation.&lt;SEP&gt;A large language model with 13 billion parameters, used as a competitive baseline in evaluating fine-tuning capacity and performance in the described system.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="multihop t5defined">
  <data key="d0">multihop t5defined</data>
  <data key="d1">Tools</data>
  <data key="d2">A specific program utilizing T5-Large (770M parameters) that evaluates the finetuning capacity of DSPy, producing answer EM and passage accuracy scores.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="passage accuracy">
  <data key="d0">passage accuracy</data>
  <data key="d1">Results</data>
  <data key="d2">A metric indicating the correctness of retrieved passages in multi-hop question answering tasks.&lt;SEP&gt;A metric measuring the correctness of passage retrieval in question answering tasks, indicating passage-level precision.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="answer exact match (Ans)">
  <data key="d0">answer exact match (Ans)</data>
  <data key="d1">Variables</data>
  <data key="d2">A variable representing the percentage of responses that exactly match the ground truth answers in evaluation.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="pair-retrieval accuracy (Psg)">
  <data key="d0">pair-retrieval accuracy (Psg)</data>
  <data key="d1">Variables</data>
  <data key="d2">A variable indicating the accuracy of correctly retrieving relevant passage pairs in multi-hop QA tasks.&lt;SEP&gt;A variable indicating the accuracy of retrieving relevant passage pairs correctly in the context of multi-hop QA.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="programs, compilers, training sets">
  <data key="d0">programs, compilers, training sets</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Components involved in the evaluation pipeline, where programs are compiled against training examples to perform question answering.&lt;SEP&gt;Components used in the evaluation pipeline, where programs are compiled against training examples to perform question answering.&lt;SEP&gt;Core components of DSPy that enable building and evaluating AI systems through compiled programs trained on specific datasets.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="in-context learning">
  <data key="d0">in-context learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A learning paradigm where models learn to perform tasks by conditioning on examples provided within the input context, crucial for few-shot learning.&lt;SEP&gt;A paradigm where models learn to perform tasks by conditioning on examples provided within the input context, especially in few-shot settings.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="CoT prompting">
  <data key="d0">CoT prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Chain-of-thought prompting guides models to produce intermediate reasoning steps to improve accuracy in complex tasks.&lt;SEP&gt;Chain-of-thought prompting technique that guides models to produce intermediate reasoning steps to improve performance.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="self-consistency">
  <data key="d0">self-consistency</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An approach where multiple reasoning paths are generated and aggregated to enhance answer accuracy.&lt;SEP&gt;An approach where multiple reasoning paths are generated and aggregated to improve answer accuracy.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="PaLM-62B">
  <data key="d0">PaLM-62B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large language model with 62 billion parameters, used for evidence recitation and question answering in referenced studies.&lt;SEP&gt;A large language model with 62 billion parameters, used for evidence recitation and reasoning in question-answering systems.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="recite-and-answer">
  <data key="d0">recite-and-answer</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique where models first recite evidence passages before generating answers, improving reasoning and accuracy.&lt;SEP&gt;A technique where models recite evidence passages before answering, enhancing reasoning and accuracy.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Wang et al. (2022a)">
  <data key="d0">Wang et al. (2022a)</data>
  <data key="d1">Studies</data>
  <data key="d2">Research demonstrating improved EM and F1 scores on HotPotQA using advanced prompting and self-consistency techniques with large models.&lt;SEP&gt;Research paper that achieved 33.8% EM and 44.6% F1 on HotPotQA using self-consistency with PaLM-540B.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sun et al. (2022)">
  <data key="d0">Sun et al. (2022)</data>
  <data key="d1">Studies</data>
  <data key="d2">Research showing that recite-and-answer methods achieve certain EM scores on HotPotQA, emphasizing evidence recitation.&lt;SEP&gt;Research work that applied recite-and-answer techniques achieving 26.5% EM on HotPotQA.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Trivedi et al. (2022)">
  <data key="d0">Trivedi et al. (2022)</data>
  <data key="d1">Studies</data>
  <data key="d2">Research reporting 49% EM on HotPotQA using a pipeline with code-davinci-002.&lt;SEP&gt;Research that reported 49% EM on HotPotQA using a pipeline with code-davinci-002, highlighting pipeline effectiveness.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="signatures, modules, teleprompters">
  <data key="d0">signatures, modules, teleprompters</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Innovative concepts introduced in DSPy for structuring and controlling AI system design, enabling modularity and systematic reasoning.&lt;SEP&gt;New concepts introduced in DSPy that structure the system design, including signatures for modules, modular components, and teleprompters for control.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="case studies">
  <data key="d0">case studies</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Examples demonstrating DSPy's capability to develop systems for tasks like information extraction and synthetic data generation, showing versatility and effectiveness.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="open-source">
  <data key="d0">open-source</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The open-source availability of DSPy allows community development and broader application of the framework.&lt;SEP&gt;The open-source release of DSPy promotes community-driven development and wider adoption of the framework.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="text transformation graph">
  <data key="d0">text transformation graph</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A computational graph abstraction that structures and organizes modules and optimizers to systematically leverage language models in text processing tasks.&lt;SEP&gt;A conceptual framework describing how modules and optimizers (teleprompters) are composed to leverage language models systematically and reliably.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0&lt;SEP&gt;chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="evaluation">
  <data key="d0">evaluation</data>
  <data key="d1">Study Design</data>
  <data key="d2">The process of assessing system performance on datasets like HotPotQA using metrics such as EM and passage accuracy.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="system">
  <data key="d0">system</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The AI systems built using DSPy, including their components, pipelines, and evaluation results.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="model evaluation">
  <data key="d0">model evaluation</data>
  <data key="d1">Results</data>
  <data key="d2">Assessing model performance through perplexity and accuracy metrics on validation data to determine effectiveness of fine-tuning.&lt;SEP&gt;Evaluation of models based on their ability to produce correct, safe, and helpful code, often involving metrics and datasets.&lt;SEP&gt;The process of testing AI systems' performance on specific datasets and tasks to measure effectiveness and improvements.&lt;SEP&gt;The systematic assessment of model performance on benchmarks like HumanEval, using metrics and test datasets to measure capabilities.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0&lt;SEP&gt;chunk-f37ccebb4e61f6d64cd2096830d27b04&lt;SEP&gt;chunk-acc067e535432960edbc682652b521e0&lt;SEP&gt;chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="task-specific systems">
  <data key="d0">task-specific systems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">AI systems designed for specific tasks such as information extraction, synthetic data generation, or question answering, developed within DSPy.</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="building sophisticated text transformation graphs">
  <data key="d0">building sophisticated text transformation graphs</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Building sophisticated text transformation graphs involves creating modular and optimizer-driven frameworks to enhance the use of language models (LMs) in systematic and reliable ways.&lt;SEP&gt;Building sophisticated text transformation graphs involves designing modular components and optimizer mechanisms (teleprompters) to systematically and reliably leverage language models in various tasks.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="composable modules">
  <data key="d0">composable modules</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Composable modules are modular components designed to be combined within text transformation graphs to facilitate flexible and systematic language model applications.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="optimizers (teleprompters)">
  <data key="d0">optimizers (teleprompters)</data>
  <data key="d1">Tools</data>
  <data key="d2">Optimizers, also referred to as teleprompters, are tools used within the graphs to manage and improve the performance and reliability of language models.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Stanford Institute for Human-Centered Artificial Intelligence (HAI)">
  <data key="d0">Stanford Institute for Human-Centered Artificial Intelligence (HAI)</data>
  <data key="d1">Disciplines</data>
  <data key="d2">An academic institute supporting research in human-centered AI, including the development of systematic frameworks like text transformation graphs.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="IBM">
  <data key="d0">IBM</data>
  <data key="d1">Organizations</data>
  <data key="d2">IBM is a corporate supporter providing support and resources for research projects related to AI and text transformation graphs.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Oracle">
  <data key="d0">Oracle</data>
  <data key="d1">Organizations</data>
  <data key="d2">Oracle is a corporate supporter contributing to research on systematic AI frameworks.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Virtusa">
  <data key="d0">Virtusa</data>
  <data key="d1">Organizations</data>
  <data key="d2">Virtusa is a supporter involved in advancing research on text transformation systems.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Cigna Healthcare">
  <data key="d0">Cigna Healthcare</data>
  <data key="d1">Organizations</data>
  <data key="d2">Cigna Healthcare supports research initiatives aimed at AI applications in healthcare contexts.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Stanford DAWN project">
  <data key="d0">Stanford DAWN project</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The Stanford DAWN project is a collaborative research initiative that supports AI research, including work on text transformation graphs, with support from industry members like Facebook, Google, and VMware.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Facebook, Google, VMware">
  <data key="d0">Facebook, Google, VMware</data>
  <data key="d1">Organizations</data>
  <data key="d2">Industry supporters of the Stanford DAWN project, contributing resources and expertise to AI research.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="NSF CAREER grant CNS-1651570">
  <data key="d0">NSF CAREER grant CNS-1651570</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A specific grant from the National Science Foundation supporting research in AI, including the development of systematic frameworks like text transformation graphs.</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Wenhu Chen">
  <data key="d0">Wenhu Chen</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher developing methods like recall and learn to reduce catastrophic forgetting during fine-tuning.&lt;SEP&gt;Researcher investigating techniques like recall and learning to enhance model fine-tuning with minimal forgetting.&lt;SEP&gt;Wenhu Chen is an author involved in research on program of thoughts prompting and numerical reasoning tasks.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Xueguang Ma">
  <data key="d0">Xueguang Ma</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in research on deep language models and methods to reduce catastrophic forgetting.&lt;SEP&gt;Researcher working on strategies for less forgetting in deep language model fine-tuning.&lt;SEP&gt;Xueguang Ma is an author contributing to research on computational and reasoning methods for numerical tasks.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Xinyi Wang">
  <data key="d0">Xinyi Wang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to methods for efficient fine-tuning of pretrained models.&lt;SEP&gt;Researcher contributing to techniques that enhance fine-tuning efficiency with minimal knowledge loss.&lt;SEP&gt;Xinyi Wang is an author working on disentangling computation from reasoning in AI models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="William W Cohen">
  <data key="d0">William W Cohen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on datasets for multi-hop question answering and explainability.&lt;SEP&gt;William W Cohen is an author contributing to research on reasoning and computation in AI.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Program of thoughts prompting">
  <data key="d0">Program of thoughts prompting</data>
  <data key="d1">Core Concept</data>
  <data key="d2">A methodology or approach aimed at separating computation from reasoning in AI models to improve numerical reasoning tasks.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Scaling language modeling with pathways">
  <data key="d0">Scaling language modeling with pathways</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A framework or model described in the Palm preprint that involves scaling language models using pathways for improved performance.&lt;SEP&gt;A model proposing scalable language model training using pathway-based architectures to enhance efficiency and capacity.&lt;SEP&gt;A scalable architecture for language models that uses pathway-based training to improve efficiency, capacity, and generalization.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Training verifiers to solve math word problems">
  <data key="d0">Training verifiers to solve math word problems</data>
  <data key="d1">Methodology</data>
  <data key="d2">A methodological approach involving training models to verify solutions to math word problems, enhancing reasoning accuracy.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Torch">
  <data key="d0">Torch</data>
  <data key="d1">Tools</data>
  <data key="d2">A modular machine learning software library developed by Ronan Collobert used for building and training ML models.&lt;SEP&gt;A modular machine learning software library developed by Ronan Collobert, used for building and training ML models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Language model cascades">
  <data key="d0">Language model cascades</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique involving sequential or layered language models to improve performance on complex tasks.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Rarr: Researching and revising what language models say, using language models">
  <data key="d0">Rarr: Researching and revising what language models say, using language models</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">An investigation into how language models can be used to evaluate and revise their own outputs, aiming to improve reliability.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Pal: Program-aided language models">
  <data key="d0">Pal: Program-aided language models</data>
  <data key="d1">Methodology</data>
  <data key="d2">A methodology integrating programmatic reasoning into language models to enhance their reasoning capabilities.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Connecting large language models with evolutionary algorithms yields powerful prompt optimizers">
  <data key="d0">Connecting large language models with evolutionary algorithms yields powerful prompt optimizers</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">Explores whether combining language models with evolutionary algorithms can optimize prompts effectively.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Realm: Retrieval-augmented language model pre-training">
  <data key="d0">Realm: Retrieval-augmented language model pre-training</data>
  <data key="d1">Methodology</data>
  <data key="d2">A pre-training approach that incorporates retrieval mechanisms to improve language model knowledge and performance.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Training classifiers with natural language explanations">
  <data key="d0">Training classifiers with natural language explanations</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique for training classifiers that leverage natural language explanations to improve interpretability and accuracy.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Enabling intelligent interactions between an agent and an LLM: A reinforcement learning approach">
  <data key="d0">Enabling intelligent interactions between an agent and an LLM: A reinforcement learning approach</data>
  <data key="d1">Methodology</data>
  <data key="d2">An approach using reinforcement learning to facilitate intelligent interactions between agents and large language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Large language models can self-improve">
  <data key="d0">Large language models can self-improve</data>
  <data key="d1">Results</data>
  <data key="d2">Research indicating that large language models have the capacity to improve their own performance through various mechanisms.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Few-shot learning with retrieval augmented language models">
  <data key="d0">Few-shot learning with retrieval augmented language models</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique leveraging retrieval-augmented models to perform few-shot learning effectively.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Mrkl systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning">
  <data key="d0">Mrkl systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A neuro-symbolic system architecture integrating language models with external knowledge and reasoning modules.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Robust Multi-Hop Reasoning at Scale via Condensed Retrieval">
  <data key="d0">Robust Multi-Hop Reasoning at Scale via Condensed Retrieval</data>
  <data key="d1">Methodology</data>
  <data key="d2">A retrieval-based reasoning approach designed to perform large-scale multi-hop reasoning efficiently.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Relevance-guided supervision for openqa with ColBERT">
  <data key="d0">Relevance-guided supervision for openqa with ColBERT</data>
  <data key="d1">Methodology</data>
  <data key="d2">A supervision technique for open-domain question answering utilizing relevance feedback with ColBERT models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2211.12588">
  <data key="d0">arXiv preprint arXiv:2211.12588</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint on program of thoughts prompting for numerical reasoning, discussing disentangling computation from reasoning.&lt;SEP&gt;A preprint on program of thoughts prompting for numerical reasoning, disentangling computation from reasoning.&lt;SEP&gt;A preprint paper presenting research on program of thoughts prompting for numerical reasoning, indicating early dissemination of findings.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2204.02311">
  <data key="d0">arXiv preprint arXiv:2204.02311</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint on scaling language models with pathways, proposing a scalable architecture.&lt;SEP&gt;A preprint on scaling language models with pathways, proposing a scalable model architecture.&lt;SEP&gt;A preprint paper describing scaling language modeling with pathways, proposing a model for large-scale language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2110.14168">
  <data key="d0">arXiv preprint arXiv:2110.14168</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">A preprint on training verifiers to solve math word problems, focusing on improving reasoning accuracy.&lt;SEP&gt;A preprint on training verifiers to solve math word problems, focusing on reasoning accuracy.&lt;SEP&gt;A preprint paper on training verifiers to solve math word problems, focusing on improving reasoning in models.&lt;SEP&gt;Preprint publication on arXiv detailing the methodology and results of training verifiers for math problems.&lt;SEP&gt;Preprint publication on arXiv with preliminary research results.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2207.10342">
  <data key="d0">arXiv preprint arXiv:2207.10342</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint on language model cascades, describing a layered approach to improve model performance.&lt;SEP&gt;A preprint on language model cascades, involving layered model architectures.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2208.03299">
  <data key="d0">arXiv preprint arXiv:2208.03299</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint on few-shot learning with retrieval-augmented language models, emphasizing improved performance with retrieval mechanisms.&lt;SEP&gt;A preprint on few-shot learning with retrieval-augmented language models, exploring enhanced few-shot capabilities.&lt;SEP&gt;A preprint on retrieval-augmented language models, demonstrating few-shot learning capabilities.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Thirty-Fifth Conference on Neural Information Processing Systems">
  <data key="d0">Thirty-Fifth Conference on Neural Information Processing Systems</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A conference presenting research on robust multi-hop reasoning at scale via condensed retrieval.&lt;SEP&gt;A conference presenting research on robust multi-hop reasoning via condensed retrieval.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Transactions of the Association for Computational Linguistics">
  <data key="d0">Transactions of the Association for Computational Linguistics</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A journal publishing research on relevance-guided supervision for open QA with ColBERT.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2309.08532">
  <data key="d0">arXiv preprint arXiv:2309.08532</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint investigating connecting large language models with evolutionary algorithms for prompt optimization.&lt;SEP&gt;A preprint on connecting large language models with evolutionary algorithms for prompt optimization.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2002.08909">
  <data key="d0">arXiv preprint arXiv:2002.08909</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint on Realm, a retrieval-augmented language model pre-training technique.&lt;SEP&gt;A preprint on Realm, a retrieval-augmented pre-training approach for language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics">
  <data key="d0">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A conference proceeding describing research on RARR: researching and revising language model outputs using language models.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics">
  <data key="d0">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference proceeding on training classifiers with natural language explanations.&lt;SEP&gt;Conference proceedings documenting NLP research including hierarchical story generation.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2306.03604">
  <data key="d0">arXiv preprint arXiv:2306.03604</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint on enabling intelligent interactions between an agent and an LLM via reinforcement learning.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2210.11610">
  <data key="d0">arXiv preprint arXiv:2210.11610</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint indicating that large language models can self-improve their performance.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2205.00445">
  <data key="d0">arXiv preprint arXiv:2205.00445</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint describing MRKL systems, a neuro-symbolic architecture combining large language models, external knowledge, and discrete reasoning.&lt;SEP&gt;A preprint describing MRKL systems, integrating language models with external knowledge sources and reasoning modules.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Transactions of the the Association for Computational Linguistics">
  <data key="d0">Transactions of the the Association for Computational Linguistics</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A journal publishing research on relevance-guided supervision for open QA with ColBERT.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Robust Multi-Hop Reasoning at Scale">
  <data key="d0">Robust Multi-Hop Reasoning at Scale</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A research paper discussing scalable multi-hop reasoning techniques in neural information processing.&lt;SEP&gt;A research work discussing scalable multi-hop reasoning techniques in neural information processing systems.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Condensed Retrieval">
  <data key="d0">Condensed Retrieval</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model or approach designed to improve information retrieval efficiency in neural networks, enabling large-scale reasoning.&lt;SEP&gt;A model or approach for efficient retrieval of information in neural systems.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Relevance-guided Supervision">
  <data key="d0">Relevance-guided Supervision</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A supervised learning approach that guides models based on relevance signals, applied to open question answering.&lt;SEP&gt;A supervision technique that guides models based on relevance signals to improve open question answering performance.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="OpenQA">
  <data key="d0">OpenQA</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Open Question Answering systems that utilize relevance guidance for improved performance.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ColBERT">
  <data key="d0">ColBERT</data>
  <data key="d1">Tools</data>
  <data key="d2">A retrieval model optimized for relevance-guided information retrieval in open-domain QA tasks.&lt;SEP&gt;A retrieval model used for relevance-guided open question answering, emphasizing efficiency and effectiveness.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="demonstrate-search-predict">
  <data key="d0">demonstrate-search-predict</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A framework combining retrieval and language models for knowledge-intensive NLP tasks.&lt;SEP&gt;A framework combining retrieval and language models to handle knowledge-intensive NLP tasks effectively.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Knowledge-Intensive NLP">
  <data key="d0">Knowledge-Intensive NLP</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A field focusing on NLP tasks that require extensive external knowledge and reasoning.&lt;SEP&gt;A subfield of NLP focusing on tasks requiring external knowledge, reasoning, and large-scale information processing.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Decomposed Prompting">
  <data key="d0">Decomposed Prompting</data>
  <data key="d1">Methodology</data>
  <data key="d2">A modular approach to prompt design that decomposes complex tasks into simpler components for better performance.&lt;SEP&gt;A modular approach to prompt design that decomposes complex tasks into simpler components for improved performance and interpretability.&lt;SEP&gt;A modular prompting approach for solving complex tasks in NLP by breaking them into sub-tasks.&lt;SEP&gt;A modular prompting approach that decomposes complex tasks into simpler sub-tasks for improved reasoning and performance.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zero-Shot Reasoning">
  <data key="d0">Zero-Shot Reasoning</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates whether large language models can perform reasoning tasks without explicit training examples for those tasks, demonstrating capabilities like GPT-3's zero-shot reasoning.&lt;SEP&gt;Investigates whether large language models can perform reasoning tasks without explicit training on specific reasoning examples, as demonstrated by models like GPT-3.&lt;SEP&gt;The capability of large language models to perform reasoning tasks without explicit training on specific examples.&lt;SEP&gt;The capability of large language models to perform reasoning tasks without task-specific training data.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Internet-Augmented Language Models">
  <data key="d0">Internet-Augmented Language Models</data>
  <data key="d1">Tools</data>
  <data key="d2">Language models enhanced with internet access or external data sources to improve open-domain question answering.&lt;SEP&gt;Language models enhanced with internet access via few-shot prompting to improve open-domain question answering.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Few-Shot Prompting">
  <data key="d0">Few-Shot Prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique where models are given a few examples to guide their responses, used to augment language models with external information.&lt;SEP&gt;A technique where models are provided with a few examples to guide their responses and improve task performance.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Retrieval-Augmented Generation (RAG)">
  <data key="d0">Retrieval-Augmented Generation (RAG)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A general-purpose approach that combines parametric memory from pre-trained models with non-parametric memory accessed via retrieval, enabling knowledge-intensive generation tasks.&lt;SEP&gt;A hybrid approach combining retrieval systems with generative models to improve knowledge-based NLP tasks.&lt;SEP&gt;A method combining retrieval systems with generative models to enhance knowledge-based NLP tasks.&lt;SEP&gt;A novel approach that integrates retrieval mechanisms with generative models to improve factuality and knowledge coverage in NLP tasks.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf">
  <data key="d0">https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf</data>
  <data key="d1">Tools</data>
  <data key="d2">A reference link to a NeurIPS paper detailing retrieval-augmented generation techniques.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="LlamaIndex">
  <data key="d0">LlamaIndex</data>
  <data key="d1">Tools</data>
  <data key="d2">A toolkit or framework for building language models with retrieval capabilities, as developed by Jerry Liu.&lt;SEP&gt;A toolkit or framework for building retrieval-augmented language models, developed by Jerry Liu.&lt;SEP&gt;LlamaIndex is a library offering tools for building applications with language models, focusing on data retrieval and management, often utilizing prompt templates for tasks.&lt;SEP&gt;LlamaIndex is a library similar to LangChain that offers tools for building applications with language models, emphasizing retrieval and data management, often using prompt templates.&lt;SEP&gt;LlamaIndex is a tool or platform used for document retrieval and management, supporting applications like relevant document retrieval and chatbots.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Self-Refine">
  <data key="d0">Self-Refine</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An iterative process where models refine their outputs through self-feedback to improve accuracy and coherence.&lt;SEP&gt;An iterative refinement process with self-feedback to improve model outputs in NLP tasks.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bryan McCann">
  <data key="d0">Bryan McCann</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in multitask learning and question answering research in NLP.&lt;SEP&gt;An author involved in research on multitask learning, question answering, and NLP evaluation methods.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Natural Language Decathlon">
  <data key="d0">Natural Language Decathlon</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A benchmark suite for evaluating multitask learning models across diverse NLP tasks, including question answering.&lt;SEP&gt;A multitask learning benchmark for question answering, testing models across multiple NLP tasks.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Semantic Kernel">
  <data key="d0">Semantic Kernel</data>
  <data key="d1">Tools</data>
  <data key="d2">A Microsoft tool for semantic understanding and integration in NLP applications.&lt;SEP&gt;A Microsoft-developed platform for semantic understanding and integration in NLP workflows.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="WebGPT">
  <data key="d0">WebGPT</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A browser-assisted question-answering system that incorporates human feedback to improve responses.&lt;SEP&gt;An AI system that uses web browsing and human feedback to improve open-domain question answering capabilities.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="https://arxiv.org/abs/2112.09332">
  <data key="d0">https://arxiv.org/abs/2112.09332</data>
  <data key="d1">Tools</data>
  <data key="d2">A reference link to the WebGPT paper describing its architecture, training, and feedback mechanisms.&lt;SEP&gt;A reference link to the WebGPT paper detailing its architecture and methodology.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Training Language Models to Follow Instructions">
  <data key="d0">Training Language Models to Follow Instructions</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates methods to improve how language models understand and execute human instructions using feedback.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="https://arxiv.org/abs/2203.02155">
  <data key="d0">https://arxiv.org/abs/2203.02155</data>
  <data key="d1">Tools</data>
  <data key="d2">A reference link to the OpenAI paper on training language models with human feedback.&lt;SEP&gt;A reference link to the paper on training language models with human feedback.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Din-sql">
  <data key="d0">Din-sql</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A decomposed in-context learning approach for text-to-SQL tasks with self-correction mechanisms.&lt;SEP&gt;A decomposed in-context learning approach for translating natural language to SQL with self-correction mechanisms.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Neural Information Processing Systems (NeurIPS)">
  <data key="d0">Neural Information Processing Systems (NeurIPS)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An academic conference where research on neural information processing, machine learning, and AI methodologies is presented.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="OpenQA (Open Question Answering)">
  <data key="d0">OpenQA (Open Question Answering)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Systems designed to answer questions by retrieving and reasoning over large knowledge bases or documents.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Large Language Models (LLMs)">
  <data key="d0">Large Language Models (LLMs)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Advanced AI models trained on extensive datasets to understand, generate, and translate natural language and code, including GPT-3.5, GPT-4, Phind-V2, StarCoderBase, and CodeLlama.&lt;SEP&gt;Advanced AI models trained on large corpora of text data to generate, understand, and manipulate language-based tasks.&lt;SEP&gt;Advanced AI models trained on vast datasets to understand and generate human-like text and code, including GPT-3.5, GPT-4, Phind-V2, StarCoderBase, and CodeLlama.&lt;SEP&gt;Advanced neural models capable of zero-shot reasoning, understanding, and generating human-like text.&lt;SEP&gt;LLMs are advanced AI models trained on extensive textual data to perform tasks such as code generation, translation, and natural language understanding.&lt;SEP&gt;LLMs are advanced AI models trained on vast text data to generate human-like language, used in code generation, translation, and understanding.&lt;SEP&gt;Large Language Models (LLMs) are advanced neural network models trained on extensive text data to understand, generate, and perform NLP tasks with human-like language capabilities.&lt;SEP&gt;Large Language Models (LLMs) are advanced neural network-based models trained on vast text corpora to perform various NLP tasks, characterized by their capacity to understand and generate human-like language.&lt;SEP&gt;Large Language Models are advanced AI systems capable of understanding and generating human language, but face challenges in maintaining relevance due to dynamic knowledge environments.&lt;SEP&gt;Large Language Models are advanced NLP models that serve as foundational, task-agnostic tools capable of supporting a wide range of applications, significantly impacting the field of natural language processing.&lt;SEP&gt;LLMs are advanced neural network models trained on vast textual data, capable of modeling language and source code, and used for tasks like code generation, labeling, and performance prediction.&lt;SEP&gt;Pre-trained models such as GPT-Neo, PolyCoder, and GPT2 are employed to generate code, predict performance, and classify code changes in HPC contexts.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c&lt;SEP&gt;chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-bb9f9f9e90a0c162892181da55ffb7b4&lt;SEP&gt;chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Training language models to follow instructions with human feedback">
  <data key="d0">Training language models to follow instructions with human feedback</data>
  <data key="d1">Study Design</data>
  <data key="d2">An investigation into methods for improving language models' ability to understand and execute human instructions via human feedback.&lt;SEP&gt;This research investigates methods for training language models with human feedback to improve instruction adherence and performance.&lt;SEP&gt;This study involves training language models using human feedback to improve their ability to follow instructions, contributing to the development of more aligned AI systems.</data>
  <data key="d3">chunk-ebb9fff9b6ca895234d2fcb26b588fe4&lt;SEP&gt;chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Associates, Inc.">
  <data key="d0">Associates, Inc.</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Associates, Inc. is referenced as the organization associated with a research paper, indicating its role in providing research data or context.&lt;SEP&gt;Associates, Inc. is referenced as the source of a paper, indicating its involvement in research datasets or organizational context.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Davood Rafiei">
  <data key="d0">Davood Rafiei</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Rafiei collaborates with Pourreza on the same research, indicating joint investigation into text-to-SQL and self-correction methodologies.</data>
  <data key="d3">chunk-d7fb767860f2acfdf6c421fa6f949b0b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2307.09288">
  <data key="d0">arXiv preprint arXiv:2307.09288</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint publication presenting research findings on Llama 2, including its development and applications.&lt;SEP&gt;A preprint publication presenting research findings related to Llama 2, including its development and applications.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Interleaving retrieval with chain-of-thought reasoning">
  <data key="d0">Interleaving retrieval with chain-of-thought reasoning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A methodology that combines information retrieval with chain-of-thought reasoning to enhance knowledge-intensive multi-step question answering processes.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2212.10509">
  <data key="d0">arXiv preprint arXiv:2212.10509</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint detailing a methodology that combines retrieval with chain-of-thought reasoning to improve multi-step question answering.&lt;SEP&gt;A preprint detailing a research approach that integrates retrieval mechanisms with chain-of-thought reasoning for improved question answering.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Backpropagation with callbacks">
  <data key="d0">Backpropagation with callbacks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A foundational concept in neural network training that introduces callback functions to improve efficiency and expressiveness in differentiable programming.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Advances in Neural Information Processing Systems (NeurIPS)">
  <data key="d0">Advances in Neural Information Processing Systems (NeurIPS)</data>
  <data key="d1">Discipline</data>
  <data key="d2">A leading conference in machine learning and neural information processing, publishing research on topics like backpropagation and differentiable programming.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Rationale-augmented ensembles in language models">
  <data key="d0">Rationale-augmented ensembles in language models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A modeling approach that enhances language models by incorporating rationales through ensemble techniques to improve reasoning and performance.&lt;SEP&gt;An ensemble approach that incorporates rationale generation to enhance reasoning and interpretability in language models.&lt;SEP&gt;An ensemble technique that incorporates rationale generation to improve reasoning and interpretability in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Self-consistency improves chain of thought reasoning in language models">
  <data key="d0">Self-consistency improves chain of thought reasoning in language models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A methodological concept where self-consistency mechanisms are applied to improve reasoning accuracy in large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Chain of thought prompting">
  <data key="d0">Chain of thought prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique used to elicit reasoning in large language models by guiding them through structured thought processes.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Transformers: State-of-the-art natural language processing">
  <data key="d0">Transformers: State-of-the-art natural language processing</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A foundational model architecture that underpins many modern NLP systems, emphasizing attention mechanisms and scalability.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Large language models as optimizers">
  <data key="d0">Large language models as optimizers</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">An emerging application of large language models where they are utilized to perform optimization tasks, impacting AI efficiency and problem-solving approaches.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="HotpotQA: A dataset for diverse, explainable multi-hop question answering">
  <data key="d0">HotpotQA: A dataset for diverse, explainable multi-hop question answering</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark dataset designed to evaluate multi-hop reasoning and explainability in question answering systems.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="React: Synergizing reasoning and acting in language models">
  <data key="d0">React: Synergizing reasoning and acting in language models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A framework that combines reasoning and action in language models to improve their interactive and problem-solving capabilities.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Answering questions by meta-reasoning over multiple chains of thought">
  <data key="d0">Answering questions by meta-reasoning over multiple chains of thought</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A research approach that involves meta-reasoning techniques over multiple reasoning chains to enhance question-answering accuracy.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Automatic chain of thought prompting in large language models">
  <data key="d0">Automatic chain of thought prompting in large language models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique for automatically generating prompts that induce chain-of-thought reasoning in large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ExpeL: LLM agents are experiential learners">
  <data key="d0">ExpeL: LLM agents are experiential learners</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">A framework where large language model agents learn through experience, influencing AI training paradigms.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Automatic model selection with large language models for reasoning">
  <data key="d0">Automatic model selection with large language models for reasoning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process that employs large language models to automatically select appropriate models for specific reasoning tasks.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yoshua Bengio">
  <data key="d0">Yoshua Bengio</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A pioneering researcher in deep learning, contributing foundational theories to neural networks and AI.&lt;SEP&gt;A prominent researcher in deep learning and neural networks, contributing to foundational theories and models in AI.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Transformers">
  <data key="d0">Transformers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Transformers are a neural network architecture central to modern NLP, enabling scalable, attention-based processing.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bhargava, Shruti Bhosale, et al.">
  <data key="d0">Bhargava, Shruti Bhosale, et al.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of a study on Llama 2, contributing to foundational research in large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Harsh Trivedi">
  <data key="d0">Harsh Trivedi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on retrieval and chain-of-thought reasoning for knowledge-intensive questioning.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Niranjan Balasubramanian">
  <data key="d0">Niranjan Balasubramanian</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on retrieval and chain-of-thought reasoning for knowledge-intensive questioning.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Tushar Khot">
  <data key="d0">Tushar Khot</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on retrieval and chain-of-thought reasoning for knowledge-intensive questioning.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ashish Sabharwal">
  <data key="d0">Ashish Sabharwal</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on retrieval and chain-of-thought reasoning for knowledge-intensive questioning.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Fei Wang">
  <data key="d0">Fei Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on backpropagation with callbacks for efficient differentiable programming.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="James Decker">
  <data key="d0">James Decker</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on backpropagation with callbacks for efficient differentiable programming.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Xilun Wu">
  <data key="d0">Xilun Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on backpropagation with callbacks for efficient differentiable programming.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Gregory Essertel">
  <data key="d0">Gregory Essertel</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on backpropagation with callbacks for efficient differentiable programming.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Tiark Rompf">
  <data key="d0">Tiark Rompf</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on backpropagation with callbacks for efficient differentiable programming.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Advances in Neural Information Processing Systems">
  <data key="d0">Advances in Neural Information Processing Systems</data>
  <data key="d1">Discipline</data>
  <data key="d2">A conference proceedings publishing research on neural networks and machine learning advancements.&lt;SEP&gt;A conference proceedings where research on neural information processing and machine learning models is published.&lt;SEP&gt;A leading conference publishing research on neural networks, deep learning, and differentiable programming techniques.&lt;SEP&gt;A leading conference publishing cutting-edge research on neural networks and machine learning.&lt;SEP&gt;A leading conference publishing research on neural networks and machine learning techniques.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Xuezhi Wang">
  <data key="d0">Xuezhi Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on rationale-augmented ensembles in language models and self-consistency in reasoning.&lt;SEP&gt;Xuezhi Wang is an author involved in NLP research and model training.&lt;SEP&gt;Xuezhi Wang is an author involved in NLP research.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jason Wei">
  <data key="d0">Jason Wei</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on rationale-augmented ensembles, self-consistency, and chain of thought prompting in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Dale Schuurmans">
  <data key="d0">Dale Schuurmans</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Author involved in research on rationale-augmented ensembles and reasoning techniques in language models.&lt;SEP&gt;Dale Schuurmans studies memory-augmented large language models and their computational universality.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Quoc Le">
  <data key="d0">Quoc Le</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Author involved in research on rationale-augmented ensembles and chain of thought prompting in language models.&lt;SEP&gt;Quoc Le is a researcher involved in deep learning and NLP research.&lt;SEP&gt;Quoc Le is a researcher working on deep learning models for NLP.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ed Chi">
  <data key="d0">Ed Chi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on rationale-augmented ensembles and reasoning in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Denny Zhou">
  <data key="d0">Denny Zhou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on rationale-augmented ensembles, self-consistency, and reasoning techniques in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2207.00747">
  <data key="d0">arXiv preprint arXiv:2207.00747</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint detailing ensemble methods with rationale augmentation.&lt;SEP&gt;A preprint detailing rationale-augmented ensemble methodologies.&lt;SEP&gt;A preprint on rationale-augmented ensembles in language models, improving reasoning accuracy.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2203.11171">
  <data key="d0">arXiv preprint arXiv:2203.11171</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint demonstrating how self-consistency improves chain-of-thought reasoning in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2201.11903">
  <data key="d0">arXiv preprint arXiv:2201.11903</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint showing how chain of thought prompting elicits reasoning in large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Thomas Wolf">
  <data key="d0">Thomas Wolf</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Author involved in research on state-of-the-art NLP models, notably transformers.&lt;SEP&gt;Thomas Wolf is an author involved in AI models and natural language processing.&lt;SEP&gt;Thomas Wolf is an author specializing in natural language processing and AI models.&lt;SEP&gt;Thomas Wolf contributes to prompt engineering and multitask training methods.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Lysandre Debut">
  <data key="d0">Lysandre Debut</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Victor Sanh">
  <data key="d0">Victor Sanh</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.&lt;SEP&gt;Victor Sanh researches in NLP, focusing on multitask prompt training and zero-shot generalization in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Julien Chaumond">
  <data key="d0">Julien Chaumond</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Clement Delangue">
  <data key="d0">Clement Delangue</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Anthony Moi">
  <data key="d0">Anthony Moi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Pierric Cistac">
  <data key="d0">Pierric Cistac</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Tim Rault">
  <data key="d0">Tim Rault</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Remi Louf">
  <data key="d0">Remi Louf</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Morgan Funtowicz">
  <data key="d0">Morgan Funtowicz</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Joe Davison">
  <data key="d0">Joe Davison</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sam Shleifer">
  <data key="d0">Sam Shleifer</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Patrick von Platen">
  <data key="d0">Patrick von Platen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Clara Ma">
  <data key="d0">Clara Ma</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yacine Jernite">
  <data key="d0">Yacine Jernite</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher contributing to NLP research on story generation.&lt;SEP&gt;A researcher contributing to NLP, especially in language modeling and story generation.&lt;SEP&gt;Author involved in research on transformers and NLP advancements.&lt;SEP&gt;Yacine Jernite is an author contributing to machine learning models for source code.&lt;SEP&gt;Yacine Jernite is an author involved in machine learning and source code analysis.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Julien Plu">
  <data key="d0">Julien Plu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Canwen Xu">
  <data key="d0">Canwen Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Teven Le Scao">
  <data key="d0">Teven Le Scao</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.&lt;SEP&gt;Teven Le Scao researches prompt strategies and model generalization.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sylvain Gugger">
  <data key="d0">Sylvain Gugger</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Mariama Drame">
  <data key="d0">Mariama Drame</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Quentin Lhoest">
  <data key="d0">Quentin Lhoest</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Alexander Rush">
  <data key="d0">Alexander Rush</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on transformers and NLP advancements.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zhilin Yang">
  <data key="d0">Zhilin Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on HotpotQA and multi-hop reasoning datasets.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Peng Qi">
  <data key="d0">Peng Qi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on HotpotQA and multi-hop reasoning datasets.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Saizheng Zhang">
  <data key="d0">Saizheng Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on HotpotQA and multi-hop reasoning datasets.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ruslan Salakhutdinov">
  <data key="d0">Ruslan Salakhutdinov</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on datasets for multi-hop question answering and neural network models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Christopher D Manning">
  <data key="d0">Christopher D Manning</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author contributing to research on scalable model editing and knowledge management.&lt;SEP&gt;Author contributing to scalable model editing research.&lt;SEP&gt;Author involved in research on datasets for multi-hop question answering and NLP benchmarks.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:1809.09600">
  <data key="d0">arXiv preprint arXiv:1809.09600</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A dataset designed for multi-hop, explainable question answering, used as a benchmark in NLP.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Shunyu Yao">
  <data key="d0">Shunyu Yao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on reasoning and acting in language models, integrating reasoning with action.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jeffrey Zhao">
  <data key="d0">Jeffrey Zhao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on reasoning and acting in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Dian Yu">
  <data key="d0">Dian Yu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on reasoning and acting in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Nan Du">
  <data key="d0">Nan Du</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on reasoning and acting in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Izhak Shafran">
  <data key="d0">Izhak Shafran</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on reasoning and acting in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Karthik Narasimhan">
  <data key="d0">Karthik Narasimhan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on reasoning and acting in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yuan Cao">
  <data key="d0">Yuan Cao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on reasoning and acting in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2210.03629">
  <data key="d0">arXiv preprint arXiv:2210.03629</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint detailing the React framework that combines reasoning and acting in language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ori Yoran">
  <data key="d0">Ori Yoran</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in meta-reasoning research over multiple chains of thought for question answering.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Tomer Wolfson">
  <data key="d0">Tomer Wolfson</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in meta-reasoning research for question answering.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ben Bogin">
  <data key="d0">Ben Bogin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in meta-reasoning research for question answering.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Uri Katz">
  <data key="d0">Uri Katz</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in meta-reasoning research for question answering.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Daniel Deutch">
  <data key="d0">Daniel Deutch</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in meta-reasoning research for question answering.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jonathan Berant">
  <data key="d0">Jonathan Berant</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP, question answering, and semantic understanding.&lt;SEP&gt;A researcher contributing to question answering and NLP research.&lt;SEP&gt;Author involved in meta-reasoning research for question answering.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2304.13007">
  <data key="d0">arXiv preprint arXiv:2304.13007</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint on meta-reasoning over multiple chains of thought to improve question answering.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Eric Zelikman">
  <data key="d0">Eric Zelikman</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on bootstrapping reasoning with models, enhancing reasoning capabilities.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yuhuai Wu">
  <data key="d0">Yuhuai Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on bootstrapping reasoning with models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Noah D Goodman">
  <data key="d0">Noah D Goodman</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on bootstrapping reasoning with models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2203.14465">
  <data key="d0">arXiv preprint arXiv:2203.14465</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint describing the Star methodology for bootstrapping reasoning in models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Zhuosheng Zhang">
  <data key="d0">Zhuosheng Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on automatic chain of thought prompting in large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Aston Zhang">
  <data key="d0">Aston Zhang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher investigating hypercomplex parameterizations in language models.&lt;SEP&gt;Author involved in research on automatic chain of thought prompting in large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Mu Li">
  <data key="d0">Mu Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on automatic chain of thought prompting in large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Alex Smola">
  <data key="d0">Alex Smola</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on automatic chain of thought prompting in large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2210.03493">
  <data key="d0">arXiv preprint arXiv:2210.03493</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint on automatic chain of thought prompting techniques for large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Andrew Zhao">
  <data key="d0">Andrew Zhao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on ExpeL, LLM agents as experiential learners.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Daniel Huang">
  <data key="d0">Daniel Huang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on ExpeL, LLM agents as experiential learners.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Matthieu Lin">
  <data key="d0">Matthieu Lin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on ExpeL, LLM agents as experiential learners.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yong-Jin Liu">
  <data key="d0">Yong-Jin Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on ExpeL, LLM agents as experiential learners.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Gao Huang">
  <data key="d0">Gao Huang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on ExpeL, LLM agents as experiential learners.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2308.10144">
  <data key="d0">arXiv preprint arXiv:2308.10144</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint discussing LLM agents as experiential learners, impacting AI training methods.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Xu Zhao">
  <data key="d0">Xu Zhao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on automatic model selection with large language models for reasoning.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Yuxi Xie">
  <data key="d0">Yuxi Xie</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on automatic model selection with large language models for reasoning.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Kenji Kawaguchi">
  <data key="d0">Kenji Kawaguchi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on automatic model selection with large language models for reasoning.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Junxian He">
  <data key="d0">Junxian He</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on automatic model selection with large language models for reasoning.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Qizhe Xie">
  <data key="d0">Qizhe Xie</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author involved in research on automatic model selection with large language models for reasoning.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2305.14333">
  <data key="d0">arXiv preprint arXiv:2305.14333</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint on automating model selection for reasoning tasks using large language models.</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Python Classes for Signatures">
  <data key="d0">Python Classes for Signatures</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Python classes are used to explicitly define signatures that specify instructions for data transformation and describe the format or role of each field, enabling controlled and transparent data processing.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Signature">
  <data key="d0">Signature</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A Signature defines a structured template or schema for data transformations within the system, specifying input and output fields with descriptions and data types.&lt;SEP&gt;A Signature is a formalized schema used to specify instructions for data transformations, including the description of each field's role and format, enabling explicit control over data processing workflows.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.Signature">
  <data key="d0">dspy.Signature</data>
  <data key="d1">Tools</data>
  <data key="d2">dspy.Signature is a class that defines structured templates for specifying input and output fields, facilitating explicit and modular data transformations within language model pipelines.&lt;SEP&gt;dspy.Signature is a class used to create signatures that formalize the structure and instructions for data transformations in the context of prompt engineering and language model workflows.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="InputField">
  <data key="d0">InputField</data>
  <data key="d1">Tools</data>
  <data key="d2">InputField is a component used within a Signature to define an input parameter, including its description and data type, allowing clear specification of data inputs for processing tasks.&lt;SEP&gt;InputField is a component used within a Signature to specify an input parameter, including its description and data type, facilitating explicit instructions for data input in system workflows.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="OutputField">
  <data key="d0">OutputField</data>
  <data key="d1">Tools</data>
  <data key="d2">OutputField is a component used within a Signature to define an output parameter, including its data type and description, ensuring clarity in the expected results of a transformation.&lt;SEP&gt;OutputField is a component used within a Signature to specify an output parameter, including its data type and description, ensuring clarity in the expected output structure.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.OutputField">
  <data key="d0">dspy.OutputField</data>
  <data key="d1">Tools</data>
  <data key="d2">dspy.OutputField specifies the structure and data type of the output generated by a signature, aiding in consistent and explicit output definitions.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="SearchQuery">
  <data key="d0">SearchQuery</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">SearchQuery represents a query string used to retrieve information or data from a search engine or database, often generated by language models based on input context and questions.&lt;SEP&gt;SearchQuery represents a structured query string generated to retrieve information from search engines or databases, often produced by language models based on context and questions.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="dspy.Predict">
  <data key="d0">dspy.Predict</data>
  <data key="d1">Methodologies</data>
  <data key="d2">dspy.Predict is a method that generates predictions or outputs based on a specified Signature, enabling structured and controlled language model responses.&lt;SEP&gt;dspy.Predict is a method used to generate predictions or outputs based on a specified Signature, enabling the creation of structured and controlled language model outputs.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GenerateSearchQuery">
  <data key="d0">GenerateSearchQuery</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">GenerateSearchQuery is a Signature designed to produce search queries that help answer complex questions by combining context and optional questions into effective search strings.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="System for Synthetic IR Dataset">
  <data key="d0">System for Synthetic IR Dataset</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The system described uses signatures and language models to generate search queries, facilitating the creation of synthetic information retrieval datasets, which can improve information retrieval tasks and research workflows.&lt;SEP&gt;This system employs signatures and language models to generate search queries, facilitating the creation of synthetic information retrieval datasets, which can enhance research and application in IR tasks.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="LangChain">
  <data key="d0">LangChain</data>
  <data key="d1">Tools</data>
  <data key="d2">LangChain is a library that provides pre-packaged components and pipelines for prompt engineering, retrieval, and application development with language models, focusing on ease of use and modularity.&lt;SEP&gt;LangChain is a library that provides reusable components and pipelines for prompt management, retrieval, and application development, emphasizing ease of use and modularity in prompt engineering workflows.&lt;SEP&gt;LangChain is a software framework or tool used for building language model applications, such as question answering or retrieval.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Self-Improvement">
  <data key="d0">Self-Improvement</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Self-improvement in DSPy refers to its ability to automatically optimize and compile language model pipelines, decreasing manual intervention and increasing efficiency.&lt;SEP&gt;Self-improvement in DSPy refers to the system's ability to automatically optimize and compile language model pipelines, reducing manual intervention and increasing performance.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt Length">
  <data key="d0">Prompt Length</data>
  <data key="d1">Variables</data>
  <data key="d2">Prompt length refers to the number of words or characters in prompt templates, impacting complexity, computational cost, and effectiveness of language model responses.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt Size and Effectiveness">
  <data key="d0">Prompt Size and Effectiveness</data>
  <data key="d1">Results</data>
  <data key="d2">Studies indicate that large prompt sizes (over 1000 characters) are common in existing libraries, and that automated prompt generation can lead to more modular and effective workflows than manually written prompts.&lt;SEP&gt;Studies show that large prompts (over 1000 characters) are common in current libraries, and automated prompt generation can lead to more modular, effective workflows than manual prompts.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt Size">
  <data key="d0">Prompt Size</data>
  <data key="d1">Variables</data>
  <data key="d2">Prompt size, measured in words or characters, impacts the complexity, cost, and effectiveness of prompts, influencing model performance and response quality.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Gao et al. (2023a)">
  <data key="d0">Gao et al. (2023a)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Gao et al. (2023a) is a referenced study or publication, likely involving research or evidence collection.&lt;SEP&gt;Gao et al. (2023a) is a research publication or study that provides evidence or data related to the activity, possibly involving experimental or observational research.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="LangChain &amp; Gao et al. (2023b)">
  <data key="d0">LangChain &amp; Gao et al. (2023b)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">LangChain &amp; Gao et al. (2023b) refers to a collaborative research effort involving language models and Gao et al., focused on mathematical word problems and reasoning tasks.&lt;SEP&gt;LangChain &amp; Gao et al. (2023b) refers to a collaborative work or research involving language models and Gao et al., possibly focusing on mathematical word problems.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Nasal Cycle">
  <data key="d0">Nasal Cycle</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The nasal cycle is a physiological process involving alternating congestion and decongestion of nostrils approximately every 2 hours, regulating airflow and mucus buildup.&lt;SEP&gt;The nasal cycle is a physiological process where airflow switches between nostrils approximately every 2 hours, involving congestion and decongestion patterns to prevent mucus buildup.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sleep and Nasal Cycle">
  <data key="d0">Sleep and Nasal Cycle</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The research investigates how often nostrils switch during sleep and the physiological mechanisms controlling this process.&lt;SEP&gt;The research question involves understanding how often nostrils switch during sleep and the physiological mechanisms behind it.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Nasal Congestion Pattern">
  <data key="d0">Nasal Congestion Pattern</data>
  <data key="d1">Results</data>
  <data key="d2">The pattern of congestion switching approximately every 2 hours was observed, based on a 2016 study, indicating a physiological rhythm.&lt;SEP&gt;The pattern of nasal congestion switches approximately every 2 hours, based on a 2016 study published in PLOS One.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Laura Ingalls Wilder">
  <data key="d0">Laura Ingalls Wilder</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Laura Ingalls Wilder is the author of the Little House books, which are a series of children's books based on her life.&lt;SEP&gt;Laura Ingalls Wilder is the author of the Little House children's books, based on her life experiences.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="HarperCollins">
  <data key="d0">HarperCollins</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">HarperCollins is the publishing company that published the Little House books.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Stanford Prison Experiment">
  <data key="d0">Stanford Prison Experiment</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A famous psychological study conducted in 1971 to examine authority and obedience, conducted in Jordan Hall, Stanford University.&lt;SEP&gt;The Stanford Prison Experiment was a psychological study conducted in 1971 to examine authority and power dynamics in a simulated prison environment, conducted in Jordan Hall, Stanford.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jordan Hall">
  <data key="d0">Jordan Hall</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Jordan Hall is the location where the Stanford Prison Experiment took place, part of Stanford University.&lt;SEP&gt;Jordan Hall is the location where the Stanford Prison Experiment was conducted, part of Stanford University.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Social Work">
  <data key="d0">Social Work</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Social work is a profession rooted in humanism, focusing on helping individuals and communities through social services, with historical roots in the 1880s charity and settlement movements.&lt;SEP&gt;Social work is a professional discipline focused on helping individuals and communities through social services, with roots in the 1880s charity and settlement movements.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Havel-Hakimi Algorithm">
  <data key="d0">Havel-Hakimi Algorithm</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The Havel-Hakimi algorithm is a recursive method for constructing or proving the existence of a simple graph with a given degree sequence, based on published work by Havel (1955) and Hakimi (1962).&lt;SEP&gt;The Havel-Hakimi algorithm is a recursive procedure for constructing or verifying the existence of a simple graph with a given degree sequence, published by Havel (1955) and Hakimi (1962).</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Time of My Life">
  <data key="d0">Time of My Life</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A popular song by Bill Medley from the 1987 film Dirty Dancing, produced by Michael Lloyd, known for its soundtrack success.&lt;SEP&gt;Time of My Life is a song by Bill Medley from the 1987 film Dirty Dancing, produced by Michael Lloyd, known for its popularity and soundtrack inclusion.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Bill Medley">
  <data key="d0">Bill Medley</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Bill Medley is an American singer-songwriter who performed "Time of My Life".&lt;SEP&gt;Bill Medley is an American singer-songwriter, performer of the song "Time of My Life".</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Michael Lloyd">
  <data key="d0">Michael Lloyd</data>
  <data key="d1">Tools</data>
  <data key="d2">Michael Lloyd is a music producer who produced and remixed "Time of My Life".&lt;SEP&gt;Michael Lloyd is a music producer who produced the song "Time of My Life" and its remix.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Kelvin Hopins">
  <data key="d0">Kelvin Hopins</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Kelvin Hopins was a former Labour MP suspended due to allegations of sexual harassment and misconduct involving activist Ava Etemadzadeh.&lt;SEP&gt;Kelvin Hopins was a former Labour MP suspended from the party due to allegations of sexual harassment and inappropriate behavior towards activist Ava Etemadzadeh.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ava Etemadzadeh">
  <data key="d0">Ava Etemadzadeh</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Ava Etemadzadeh is a Labour Party activist allegedly targeted by Kelvin Hopkins for inappropriate behavior.&lt;SEP&gt;Ava Etemadzadeh is a Labour Party activist involved in allegations against Kelvin Hopins, leading to his suspension.&lt;SEP&gt;Ava Etemadzadeh is a Labour Party activist involved in allegations leading to Kelvin Hopins' suspension.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e&lt;SEP&gt;chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 1">
  <data key="d0">Prompt 1</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Text-evidence checker Gao et al. (2023a) addresses questions about verifying factual information in texts, examining the accuracy of statements.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 2">
  <data key="d0">Prompt 2</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Math word problems (PAL) LangChain &amp; Gao et al. (2023b) investigates the capability of language models to solve math problems, testing reasoning and comprehension.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 3">
  <data key="d0">Prompt 3</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">ReAct Yao et al. (2022) explores the ReAct methodology, focusing on reasoning and action-based language model interactions.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 4">
  <data key="d0">Prompt 4</data>
  <data key="d1">Tools</data>
  <data key="d2">Zero-shot ReAct LangChain is a framework or tool used to implement zero-shot reasoning tasks, enabling language models to perform tasks without prior training on specific data.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 5">
  <data key="d0">Prompt 5</data>
  <data key="d1">Tools</data>
  <data key="d2">QA with sources LangChain supports question-answering systems that incorporate source retrieval, enhancing answer accuracy and traceability.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 6">
  <data key="d0">Prompt 6</data>
  <data key="d1">Tools</data>
  <data key="d2">SQL MyScale querying LangChain facilitates SQL-based data querying, enabling retrieval and analysis of structured data from databases.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 7">
  <data key="d0">Prompt 7</data>
  <data key="d1">Tools</data>
  <data key="d2">Relevant docs retrieval LlamaIndex is a tool for retrieving relevant documents or sources, supporting document-based AI applications and information extraction.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prompt 8">
  <data key="d0">Prompt 8</data>
  <data key="d1">Tools</data>
  <data key="d2">IRS chatbot LlamaIndex is used to develop chatbots for IRS or similar organizations, supporting conversational AI for information dissemination.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Little House Books">
  <data key="d0">Little House Books</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The Little House series are children's books authored by Laura Ingalls Wilder, depicting frontier life.</data>
  <data key="d3">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Kelvin Hopkins">
  <data key="d0">Kelvin Hopkins</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Kelvin Hopkins is a person accused of inappropriate physical contact and sexual harassment in 2017, leading to suspension by the Labour party pending investigation.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="2017">
  <data key="d0">2017</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research on data-parallel IRs and their role in optimizing GPU code.&lt;SEP&gt;Research on functional IR techniques for high-performance GPU code generation.&lt;SEP&gt;Research on functional IRs and their role in optimizing GPU code for high-performance applications.&lt;SEP&gt;Research on the design and application of Lift for high-performance GPU code generation.&lt;SEP&gt;The year when Kelvin Hopkins was accused of misconduct and suspended from the Labour party.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Labour Party">
  <data key="d0">Labour Party</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The Labour Party is a political organization involved in disciplinary procedures and investigations related to misconduct allegations.&lt;SEP&gt;The Labour Party is a political organization that suspended Kelvin Hopkins following allegations of misconduct.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Inappropriate Physical Contact">
  <data key="d0">Inappropriate Physical Contact</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Refers to physical behavior considered unacceptable or sexual harassment, as alleged against Kelvin Hopkins.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sexual Harassment Allegations">
  <data key="d0">Sexual Harassment Allegations</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Allegations of sexual harassment against Kelvin Hopkins, which prompted investigation and suspension.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Investigation">
  <data key="d0">Investigation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An official process to examine allegations of misconduct, conducted by the Labour Party in this case.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Suspension">
  <data key="d0">Suspension</data>
  <data key="d1">Results</data>
  <data key="d2">Disciplinary action taken by the Labour Party against Kelvin Hopkins pending investigation.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Disciplinary Action">
  <data key="d0">Disciplinary Action</data>
  <data key="d1">Results</data>
  <data key="d2">The Labour Party suspended Kelvin Hopkins as a result of the allegations and pending investigation.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Inquirer">
  <data key="d0">Inquirer</data>
  <data key="d1">Tools</data>
  <data key="d2">The process or person conducting the investigation into Kelvin Hopkins' misconduct.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Alleged Misconduct">
  <data key="d0">Alleged Misconduct</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Refers to the inappropriate physical contact and sexual harassment allegations against Kelvin Hopkins.</data>
  <data key="d3">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Leah">
  <data key="d0">Leah</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Leah is a person who initially has 32 chocolates, and her total chocolates are calculated after some are eaten.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sister">
  <data key="d0">Sister</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Leah's sister is a person who initially has 42 chocolates, and her total chocolates are calculated after some are eaten.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Total Chocolates">
  <data key="d0">Total Chocolates</data>
  <data key="d1">Variables</data>
  <data key="d2">Total chocolates represent the sum of Leah's and her sister's chocolates before consumption.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Chocolates Eaten">
  <data key="d0">Chocolates Eaten</data>
  <data key="d1">Variables</data>
  <data key="d2">Chocolates eaten refers to the quantity of chocolates consumed by Leah and her sister, affecting the remaining count.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Remaining Chocolates">
  <data key="d0">Remaining Chocolates</data>
  <data key="d1">Variables</data>
  <data key="d2">Remaining chocolates are calculated by subtracting the chocolates eaten from the total chocolates.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Parking Lot">
  <data key="d0">Parking Lot</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The parking lot initially has 3 cars, with 2 more arriving, leading to a total count of cars.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Cars Initial">
  <data key="d0">Cars Initial</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of cars initially in the parking lot before new arrivals.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Cars Arrived">
  <data key="d0">Cars Arrived</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of new cars arriving at the parking lot.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Total Cars">
  <data key="d0">Total Cars</data>
  <data key="d1">Variables</data>
  <data key="d2">Total cars in the parking lot after arrivals are summed.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Trees in Grove">
  <data key="d0">Trees in Grove</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The grove initially has 15 trees, and after planting, the total increases to 21, indicating the number of trees planted.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Initial Trees">
  <data key="d0">Initial Trees</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of trees initially present in the grove.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Trees After">
  <data key="d0">Trees After</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of trees in the grove after planting.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Trees Planted">
  <data key="d0">Trees Planted</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of trees planted by grove workers, calculated by the difference between after and initial trees.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Solution Function">
  <data key="d0">Solution Function</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A Python function used to solve the presented math problems by performing calculations based on input variables.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Chocolates Left">
  <data key="d0">Chocolates Left</data>
  <data key="d1">Variables</data>
  <data key="d2">Chocolates left are the remaining chocolates after subtracting the eaten chocolates from the total.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Trees Added">
  <data key="d0">Trees Added</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of trees planted by grove workers, calculated by the difference between trees after and initial trees.</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Elia Kazan">
  <data key="d0">Elia Kazan</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Elia Kazan was an American film and theatre director, producer, screenwriter, and actor known for his influential work in film and theater.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Rebel Without a Cause">
  <data key="d0">Rebel Without a Cause</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A 1955 film directed by Elia Kazan, notable for its cultural significance in depicting youth rebellion.&lt;SEP&gt;Rebel Without a Cause is a 1955 film directed by Elia Kazan, notable for its cultural impact and portrayal of youth rebellion.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Arthur’s Magazine">
  <data key="d0">Arthur’s Magazine</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A literary periodical published in Philadelphia from 1844 to 1846, contributing to American literary history.&lt;SEP&gt;Arthur’s Magazine was an American literary periodical published in Philadelphia from 1844 to 1846, contributing to 19th-century American literature.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="First for Women">
  <data key="d0">First for Women</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A women's magazine published by Bauer Media Group in the USA, started in 1989, focusing on women's interests.&lt;SEP&gt;First for Women is a women's magazine published by Bauer Media Group in the USA, started in 1989, focusing on women's interests.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Pavel Urysohn">
  <data key="d0">Pavel Urysohn</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A Soviet mathematician known for his work in dimension theory, active in early 20th century.&lt;SEP&gt;Pavel Urysohn was a Soviet mathematician known for his contributions to dimension theory, active in the early 20th century.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Leonid Levin">
  <data key="d0">Leonid Levin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A Soviet-American mathematician and computer scientist recognized for contributions to computational complexity and algorithms.&lt;SEP&gt;Leonid Levin is a Soviet-American mathematician and computer scientist recognized for his work in computational complexity and algorithms.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="1911">
  <data key="d0">1911</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Refers to the date 1911, indicating a historical time point relevant to the context of the film director.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="June 16, 1979">
  <data key="d0">June 16, 1979</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Refers to the date June 16, 1979, associated with a specific event or context in the document.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="American film director">
  <data key="d0">American film director</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An individual involved in directing films in the United States, exemplified by Elia Kazan.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Screenwriter">
  <data key="d0">Screenwriter</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A person who writes scripts for films or theater, associated with Elia Kazan.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Actor">
  <data key="d0">Actor</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A performer in films or theater, associated with Elia Kazan.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Publication Timeline">
  <data key="d0">Publication Timeline</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Refers to the chronological order of magazine publications: Arthur’s Magazine (1844-1846) predates First for Women (started in 1989).</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Mathematician">
  <data key="d0">Mathematician</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Refers to Pavel Urysohn and Leonid Levin, both mathematicians but specializing in different areas.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Dimension Theory">
  <data key="d0">Dimension Theory</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A field of mathematics associated with Pavel Urysohn, focusing on the properties of dimensions in mathematical spaces.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Computational Complexity">
  <data key="d0">Computational Complexity</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A field of computer science associated with Leonid Levin, studying the resource requirements of algorithms.</data>
  <data key="d3">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ukrainian People">
  <data key="d0">Ukrainian People</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The Ukrainian people are characterized by their fearlessness, courage, and determination, which inspire the world.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Groups of Citizens Blocking Tanks">
  <data key="d0">Groups of Citizens Blocking Tanks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Thirty-two groups of citizens demonstrating bravery by physically blocking tanks, representing collective resistance.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="COVID-19">
  <data key="d0">COVID-19</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">COVID-19 is a highly impactful, deadly disease that has caused significant loss and societal disruption, prompting a call for a reset and unified response.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Loss of Life">
  <data key="d0">Loss of Life</data>
  <data key="d1">Results</data>
  <data key="d2">The pandemic has resulted in a substantial loss of human lives, emphasizing its severity and impact.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Reset Moment">
  <data key="d0">Reset Moment</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The current moment is viewed as an opportunity to reset societal perspectives, moving beyond partisan divides to address COVID-19 and other issues collaboratively.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="COVID-19 as a Disease">
  <data key="d0">COVID-19 as a Disease</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">COVID-19 is described as a 'God-awful disease,' highlighting its destructive nature and the need for collective acknowledgment.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Fellow Americans">
  <data key="d0">Fellow Americans</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The collective identity of Americans, emphasizing unity beyond divisions, especially in the context of pandemic response.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Trust and Safety">
  <data key="d0">Trust and Safety</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Restoring trust and safety within communities is a central goal, exemplified by honoring fallen officers and community service.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="New York City Police Department">
  <data key="d0">New York City Police Department</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Police department involved in responding to violent incidents, symbolizing law enforcement and community safety.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Officer Wilbert Mora">
  <data key="d0">Officer Wilbert Mora</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A police officer who was killed in the line of duty, representing sacrifice and loss in law enforcement.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Officer Jason Rivera">
  <data key="d0">Officer Jason Rivera</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A police officer who was killed in the line of duty, symbolizing sacrifice and community service.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Dominican Americans">
  <data key="d0">Dominican Americans</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The officers' backgrounds, illustrating cultural identity and community ties.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sacrifice">
  <data key="d0">Sacrifice</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The sacrifice of officers Mora and Rivera exemplifies service and the ultimate commitment to community safety.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Restoring Trust and Safety">
  <data key="d0">Restoring Trust and Safety</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Efforts to rebuild community trust and ensure safety after tragic losses.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Russia">
  <data key="d0">Russia</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Russia is depicted as an aggressor, with its invasion of Ukraine causing worldwide costs and geopolitical instability.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Ukraine">
  <data key="d0">Ukraine</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Ukraine is portrayed as a nation resilient in its 30-year independence, refusing to be taken backwards by external forces.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Russian Dictator">
  <data key="d0">Russian Dictator</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Refers to the leader of Russia whose invasion of Ukraine has significant global repercussions.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Sanctions">
  <data key="d0">Sanctions</data>
  <data key="d1">Tools</data>
  <data key="d2">Economic sanctions are employed as targeted measures against Russia's economy to exert pressure and influence.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Oil Reserves">
  <data key="d0">Oil Reserves</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The United States and its allies have released 60 million barrels of oil from reserves to mitigate energy prices.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Strategic Petroleum Reserve">
  <data key="d0">Strategic Petroleum Reserve</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A key resource used by the U.S. to stabilize gas prices and respond to global energy crises.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Gas Prices">
  <data key="d0">Gas Prices</data>
  <data key="d1">Variables</data>
  <data key="d2">Gas prices are affected by geopolitical actions, energy reserves, and international cooperation.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="International Cooperation">
  <data key="d0">International Cooperation</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The effort to release oil involves multiple countries working together, demonstrating international collaboration.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Support for Patients and Families">
  <data key="d0">Support for Patients and Families</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Increased support systems are emphasized to aid those affected by health crises.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ARPA-H">
  <data key="d0">ARPA-H</data>
  <data key="d1">Tools</data>
  <data key="d2">The Advanced Research Projects Agency for Health is a U.S. agency modeled after DARPA, focused on driving breakthroughs in health sciences.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DARPA">
  <data key="d0">DARPA</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The Defense Advanced Research Projects Agency, which led to innovations like the Internet and GPS, serves as a model for ARPA-H.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Health Breakthroughs">
  <data key="d0">Health Breakthroughs</data>
  <data key="d1">Results</data>
  <data key="d2">ARPA-H aims to achieve significant advances in cancer, Alzheimer’s, diabetes, and other diseases.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Unity Agenda">
  <data key="d0">Unity Agenda</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A national initiative emphasizing unity, responsibility, and resilience in the face of great challenges.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="American Democracy">
  <data key="d0">American Democracy</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The Capitol symbolizes the democratic process, where debates on freedom, liberty, and national strength occur.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Freedom, Liberty, Totalitarianism, Terror">
  <data key="d0">Freedom, Liberty, Totalitarianism, Terror</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Fundamental principles and threats that have shaped American history and identity.</data>
  <data key="d3">chunk-5aca7edc6ce1296a9dd4c03894ff63de</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.">
  <data key="d0">Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Instruction emphasizing careful use of column names and table schema awareness in SQL querying.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Use the following format: ======== table info ======== {table info} Question: {input } SQLQuery: {SQL statement} ...">
  <data key="d0">Use the following format: ======== table info ======== {table info} Question: {input } SQLQuery: {SQL statement} ...</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Instruction providing format and procedural guidelines for SQL query generation based on table schema and questions.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Let’s begin:">
  <data key="d0">Let’s begin:</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Instruction indicating the start of the task or process.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="{table info}">
  <data key="d0">{table info}</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Placeholder for specific table schema details relevant to the task.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="{input }">
  <data key="d0">{input }</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Placeholder for the specific question or prompt provided for SQL query generation.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Here are some examples:">
  <data key="d0">Here are some examples:</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Introduction to sample scenarios demonstrating SQL querying and response formatting.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="===== the table info =====">
  <data key="d0">===== the table info =====</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Header indicating the start of schema details for a specific database or table.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="CREATE TABLE &quot;ChatPaper&quot; (">
  <data key="d0">CREATE TABLE "ChatPaper" (</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Schema definition for the ChatPaper table, including columns like abstract, id, vector.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Question: What is Feature Pyramid Network?">
  <data key="d0">Question: What is Feature Pyramid Network?</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Sample question asking for information about a specific concept.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="SQLQuery: SELECT ChatPaper.title, ChatPaper.id, ChatPaper.authors FROM ChatPaper ORDER BY DISTANCE(vector, NeuralArray(PaperRank contribution)) LIMIT {topk}">
  <data key="d0">SQLQuery: SELECT ChatPaper.title, ChatPaper.id, ChatPaper.authors FROM ChatPaper ORDER BY DISTANCE(vector, NeuralArray(PaperRank contribution)) LIMIT {topk}</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Sample SQL query demonstrating retrieval of data based on vector similarity and ranking.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Let’s try this now:">
  <data key="d0">Let’s try this now:</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Directive to proceed with the task using the provided schema and question.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="{context str}">
  <data key="d0">{context str}</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Placeholder for the context or dataset relevant to the question.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Question: {query str}">
  <data key="d0">Question: {query str}</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The specific question posed to generate an SQL query.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Answer:">
  <data key="d0">Answer:</data>
  <data key="d1">Results</data>
  <data key="d2">Placeholder indicating where the generated answer or SQL query will be provided.</data>
  <data key="d3">chunk-9cee6a97737c75b57f27605ea82e4163</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ParameterLM">
  <data key="d0">ParameterLM</data>
  <data key="d1">Tools</data>
  <data key="d2">A language model used to generate text completions based on input prompts, serving as a core component for natural language processing tasks."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="ParameterDemonstrations">
  <data key="d0">ParameterDemonstrations</data>
  <data key="d1">Tools</data>
  <data key="d2">A collection of example inputs and outputs used to guide, prompt, or demonstrate the behavior of language models during training or inference."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Prediction">
  <data key="d0">Prediction</data>
  <data key="d1">Results</data>
  <data key="d2">The output generated by the language model in response to a prompt, encapsulating the predicted text or response."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="SimplifiedBootstrapFewShot">
  <data key="d0">SimplifiedBootstrapFewShot</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique that involves collecting demonstrations from a teacher model over a dataset to improve a student model's performance in few-shot learning scenarios."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="SimplifiedBootstrapFewShotWithRandomSearch">
  <data key="d0">SimplifiedBootstrapFewShotWithRandomSearch</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An extension of bootstrap few-shot learning that performs multiple trials with random seeds to select the best demonstration set based on a scoring metric."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="SimplifiedBootstrapFewShotWithOptuna">
  <data key="d0">SimplifiedBootstrapFewShotWithOptuna</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A hyperparameter optimization approach that employs the Optuna framework to select demonstrations and optimize the bootstrap few-shot process."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="trainset">
  <data key="d0">trainset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset comprising training examples used to bootstrap demonstrations and evaluate model performance."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="valset">
  <data key="d0">valset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A validation dataset used to evaluate the effectiveness of demonstration selections during hyperparameter tuning."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="metric">
  <data key="d0">metric</data>
  <data key="d1">Variables</data>
  <data key="d2">A scoring function or criterion used to assess the quality of predictions or demonstration sets during optimization."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="name2predictor">
  <data key="d0">name2predictor</data>
  <data key="d1">Tools</data>
  <data key="d2">A mapping between predictor names and their corresponding predictor objects, used internally to manage demonstration collection."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="predictor2name">
  <data key="d0">predictor2name</data>
  <data key="d1">Tools</data>
  <data key="d2">A reverse mapping from predictor objects to their names, facilitating demonstration association."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="candidate_program">
  <data key="d0">candidate_program</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A program or model configuration generated during hyperparameter search, representing a specific set of demonstration selections."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="score">
  <data key="d0">score</data>
  <data key="d1">Results</data>
  <data key="d2">A numerical value evaluating the performance of a candidate program on the validation set, used to compare and select the best model."|</data>
  <data key="d3">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Predictors">
  <data key="d0">Predictors</data>
  <data key="d1">Variables</data>
  <data key="d2">Predictors are variables used to predict or influence the outcome of a program or model, such as predictor1 and predictor2 in the code.&lt;SEP&gt;Variables such as predictor1 and predictor2 used within the program to influence or predict outcomes, representing features or inputs in the model.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Program">
  <data key="d0">Program</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A program in this context is a set of instructions or code designed to perform a specific task or evaluation, which is being optimized and evaluated.&lt;SEP&gt;A set of instructions or code designed to perform a specific task, which is subject to evaluation and optimization to improve performance.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Optuna">
  <data key="d0">Optuna</data>
  <data key="d1">Tools</data>
  <data key="d2">An automatic hyperparameter optimization framework used to find the best configuration of a program by maximizing evaluation scores.&lt;SEP&gt;Optuna is an automatic hyperparameter optimization framework used to find the best program configuration by maximizing the evaluation score.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Training Set">
  <data key="d0">Training Set</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The dataset used to train or develop the program, referenced as trainset, containing input-output pairs or examples.&lt;SEP&gt;The training set is a dataset used to train or develop the model or program, referenced here as trainset.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Validation Set">
  <data key="d0">Validation Set</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset used to evaluate the program during tuning, referenced as valset, to assess generalization and performance.&lt;SEP&gt;The validation set is used to evaluate the performance of the program during training or tuning, referenced as valset.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Score">
  <data key="d0">Score</data>
  <data key="d1">Results</data>
  <data key="d2">A quantitative measure of program performance obtained via evaluation functions, used to compare and select optimal configurations.&lt;SEP&gt;The score is a quantitative measure of the program's performance, obtained through evaluation functions like evaluate_program.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Best Program">
  <data key="d0">Best Program</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The best program is the configuration or instance of the program that achieves the highest score during optimization.&lt;SEP&gt;The configuration or instance of the program that achieves the highest evaluation score after optimization, representing the optimal solution.</data>
  <data key="d3">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="GSM8K Llama2-13b-chat CoT program">
  <data key="d0">GSM8K Llama2-13b-chat CoT program</data>
  <data key="d1">Tools</data>
  <data key="d2">A language model-based program designed to solve math problems step-by-step, used in conjunction with DSPy for demonstration and testing.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Vampire-themed fantasy romance novels">
  <data key="d0">Vampire-themed fantasy romance novels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Literary works characterized by themes of vampires, romance, and fantasy, including Twilight, Harper Connelly Mysteries, and The Dark Heroine.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Twilight">
  <data key="d0">Twilight</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A series of vampire-themed fantasy romance novels by Stephenie Meyer, serving as a primary example within the context.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Harper Connelly Mysteries">
  <data key="d0">Harper Connelly Mysteries</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A fantasy mystery novel series by Charlaine Harris, included as part of thematic context.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="The Dark Heroine">
  <data key="d0">The Dark Heroine</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A series of vampire-themed fantasy romance novels, illustrating contemporary genre themes.&lt;SEP&gt;A vampire-themed fantasy romance novel series by Abigail Gibbs, exemplifying genre themes.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Victorian art and culture">
  <data key="d0">Victorian art and culture</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The cultural and artistic practices of the Victorian era, which are the focus of the documentary series 'The Victorians - Their Story In Pictures'.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Jeremy Paxman">
  <data key="d0">Jeremy Paxman</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">Jeremy Paxman is the author and presenter of the Victorian documentary series, and the inquiry concerns his birth year, which is relevant to understanding the context of the series.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Victorian (comics)">
  <data key="d0">Victorian (comics)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A comic book series published starting in 1999 that explores Victorian themes, included to illustrate Victorian influence in media.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="The Caxtons">
  <data key="d0">The Caxtons</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An 1849 Victorian novel by Edward Bulwer-Lytton, representing Victorian literature.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="The Victorians - Their Story In Pictures">
  <data key="d0">The Victorians - Their Story In Pictures</data>
  <data key="d1">Study Design</data>
  <data key="d2">A documentary series focusing on Victorian art and culture, serving as a primary source for understanding Victorian era representations.</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy">
  <data key="d0">DSPy</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">DSPy is a comprehensive modular programming framework designed to facilitate the creation, compilation, optimization, and evaluation of language model pipelines. It abstracts language model workflows into high-level, reusable modules such as teleprompters, bootstrapping techniques, retrieval components, and ensemble methods, enabling systematic development of complex NLP tasks. DSPy emphasizes structured prompting and parsing, supporting parameterized prompting and signatures to automate prompt engineering, thereby reducing manual prompt crafting and enhancing pipeline quality. It introduces the concept of text transformation graphs, allowing developers to model, analyze, and optimize language model systems declaratively. The framework is particularly focused on moving away from traditional prompt engineering by enabling module composition to improve reasoning capabilities, especially on tasks like math word problems. Additionally, DSPy supports high-level pipeline configuration and systematic exploration to accelerate AI system development, making it a versatile tool for designing efficient, effective, and scalable AI systems that leverage pretrained language models and tools.</data>
  <data key="d3">chunk-05507b9dde03ab6b84f0583f82e0877a&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85&lt;SEP&gt;chunk-ccadaa64b5b17c98386463d79a2cfaca&lt;SEP&gt;chunk-5ff9371dcd9f0dcbeb25583bbba6123c&lt;SEP&gt;chunk-66e5a3f496b5e1530da70355696b5224&lt;SEP&gt;chunk-0696a875ae026175ba36c9e8529f7efd&lt;SEP&gt;chunk-8e85c7ed399116091462832c72381ba4&lt;SEP&gt;chunk-ed0f2ed4617819fd44b380fe3e3951f0&lt;SEP&gt;chunk-484caa2ba6025add81052bdcfed482a4&lt;SEP&gt;chunk-583d728170557abef78a4cab2b68abb2&lt;SEP&gt;chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="DSPy modules">
  <data key="d0">DSPy modules</data>
  <data key="d3">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d2">DSPy modules abstract and emulate neural network layers, enabling flexible composition of text transformations.&lt;SEP&gt;DSPy modules are abstractions of neural network layers, allowing flexible composition of text transformation components.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Language Models">
  <data key="d0">Language Models</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d2">Language models are AI systems designed to understand, generate, and process human language using unsupervised multitask learning approaches, enabling versatile applications in natural language understanding and generation.&lt;SEP&gt;Weak supervision signals are generated or processed by language models to automate task-specific heuristics, reducing manual effort."|&gt;"supervision, automation&lt;SEP&gt;Weak supervision techniques are implemented via language models to replace traditional heuristics, enabling task-specific or heuristic-based training through models.&lt;SEP&gt;Language models are algorithms that predict and generate text based on learned patterns, forming the basis for models like GPT and T5.</data>
  <data key="d1">Core Concepts</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Methodology">
  <data key="d0">Methodology</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d2">DSPy is a framework that abstracts language model operations into modular units, enabling systematic pipeline optimization without hand-crafted prompts.&lt;SEP&gt;DSPy is a framework that enables modular, high-level pipeline construction and optimization for language models, replacing traditional prompt engineering."|&gt;"system design, abstraction</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Model Selection Techniques">
  <data key="d0">Model Selection Techniques</data>
  <data key="d3">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d2">Model selection techniques such as cross-validation, RL, and Bayesian optimization are employed within DSPy to enhance pipeline performance.&lt;SEP&gt;Techniques like cross-validation, RL, and Bayesian optimization are employed within DSPy to improve pipeline performance based on empirical metrics."|&gt;"performance tuning, model selection</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Core Concepts">
  <data key="d0">Core Concepts</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d2">Fundamental ideas or principles that underpin the field or subject area, providing foundational understanding.&lt;SEP&gt;Fundamental ideas or principles that underpin the study or analysis, representing essential building blocks or foundational notions.&lt;SEP&gt;These foundational studies support the development of high-level, modular programming models that combine quantitative benchmarks with qualitative measures."|&gt;"literature, foundational research&lt;SEP&gt;These foundational studies support the development of programming models that combine quantitative benchmarks with qualitative evaluation for language systems.</data>
  <data key="d1">Core Concepts</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ensemble Decision">
  <data key="d0">Ensemble Decision</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d2">Majority voting is used as a custom ensemble method to aggregate multiple model outputs for more reliable answers.&lt;SEP&gt;Majority voting is used as an ensemble method to aggregate multiple outputs from different model runs, improving overall answer reliability and accuracy."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Evaluation Technique">
  <data key="d0">Evaluation Technique</data>
  <data key="d3">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d2">Bootstrapping is discussed as a future method to dynamically improve model adaptation and evaluation robustness.&lt;SEP&gt;Bootstrapping is mentioned as a future technique to dynamically adapt and evaluate model performance, especially for test-time improvements."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="CoT">
  <data key="d0">CoT</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d2">GPT-4 reportedly outperforms CoT with a higher score of 92%, indicating an improved reasoning approach.".&lt;SEP&gt;GPT-4's performance surpasses that with CoT reasoning, achieving 92%, indicating enhanced reasoning capabilities.".</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Models evaluated for their accuracy and effectiveness on benchmarks like GSM8K and HotPotQA.&quot;.">
  <data key="d0">Models evaluated for their accuracy and effectiveness on benchmarks like GSM8K and HotPotQA.".</data>
  <data key="d3">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d2">model evaluation, benchmark performance</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="programs, training sets">
  <data key="d0">programs, training sets</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d2">The development and evaluation of programs against training sets are core to the methodology for system validation.&lt;SEP&gt;The development of programs against training sets is part of the methodology for system evaluation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="study">
  <data key="d0">study</data>
  <data key="d3">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d2">The case studies demonstrate DSPy's practical application in various tasks, validating its effectiveness and versatility.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Building">
  <data key="d0">Building</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">The work involves building and developing text transformation graphs to improve systematic use of language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Stanford Institute for Human-Centered AI">
  <data key="d0">Stanford Institute for Human-Centered AI</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">Supports</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Support">
  <data key="d0">Support</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">Supports&lt;SEP&gt;The hypothesis that RAG models can outperform existing models on open-domain QA and fact verification tasks.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="IBM, Oracle, Virtusa, Cigna Healthcare">
  <data key="d0">IBM, Oracle, Virtusa, Cigna Healthcare</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">Support</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Funding">
  <data key="d0">Funding</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">Supports</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="building">
  <data key="d0">building</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">The process of designing and developing text transformation graphs to improve the systematic use of language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Stanford Institute for Human-Centered Artificial Intelligence">
  <data key="d0">Stanford Institute for Human-Centered Artificial Intelligence</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">Supports</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="supports">
  <data key="d0">supports</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">Supports</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="funding">
  <data key="d0">funding</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">Supports</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="contribution">
  <data key="d0">contribution</data>
  <data key="d3">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d2">Supports</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Wenhu Chen et al.">
  <data key="d0">Wenhu Chen et al.</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d2">The preprint presents research on program of thoughts prompting and numerical reasoning tasks, authored by Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Disentangling computation from reasoning">
  <data key="d0">Disentangling computation from reasoning</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d2">The methodology aims to separate computation from reasoning processes in AI models to improve numerical reasoning.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Methods">
  <data key="d0">Methods</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d2">A method involving training models to verify solutions to math problems, enhancing reasoning accuracy.&lt;SEP&gt;Methods include training Codex with specific learning rates, warmup, decay, and tokenizer modifications to optimize code representation and model performance.</data>
  <data key="d1">Methodologies</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Rarr">
  <data key="d0">Rarr</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d2">Researching how language models can be used to evaluate and revise their own outputs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Research Question/Hypotheses">
  <data key="d0">Research Question/Hypotheses</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d2">Researching how language models can be used to evaluate and revise their own outputs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Pal">
  <data key="d0">Pal</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d2">Integrates programmatic reasoning into language models to enhance their reasoning capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Connecting large language models with evolutionary algorithms">
  <data key="d0">Connecting large language models with evolutionary algorithms</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d2">Investigates whether combining language models with evolutionary algorithms can optimize prompts.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Realm">
  <data key="d0">Realm</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d2">Uses retrieval mechanisms during pre-training to augment language model knowledge and performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Enabling intelligent interactions between an agent and an LLM">
  <data key="d0">Enabling intelligent interactions between an agent and an LLM</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d2">Applies reinforcement learning to facilitate interactions between agents and language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Few-shot learning with retrieval-augmented language models">
  <data key="d0">Few-shot learning with retrieval-augmented language models</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d2">Employs retrieval mechanisms to enhance few-shot learning performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Mrkl systems">
  <data key="d0">Mrkl systems</data>
  <data key="d3">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d2">A neuro-symbolic architecture combining language models with external knowledge sources and reasoning modules.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Proceedings of EMNLP 2020">
  <data key="d0">Proceedings of EMNLP 2020</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d2">This publication details the transformer architecture as a state-of-the-art NLP model.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="arXiv preprint arXiv:2309.03409">
  <data key="d0">arXiv preprint arXiv:2309.03409</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d2">This research explores the application of large language models in optimization tasks, with implications for AI capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Star: Bootstrapping reasoning with reasoning">
  <data key="d0">Star: Bootstrapping reasoning with reasoning</data>
  <data key="d3">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d2">This approach uses iterative reasoning to bootstrap and improve model reasoning capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Cars in Parking Lot">
  <data key="d0">Cars in Parking Lot</data>
  <data key="d3">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d2">The initial number of cars in the parking lot is 3, before new cars arrive.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="The Victorian (comics)">
  <data key="d0">The Victorian (comics)</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d2">The comic series is based on Victorian themes, connecting media to historical era.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Victorian">
  <data key="d0">Victorian</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d2">The comic series is based on Victorian themes, connecting media to historical era.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Content of Series">
  <data key="d0">Content of Series</data>
  <data key="d3">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d2">Jeremy Paxman is the presenter and likely the author of the Victorian-themed documentary series, connecting his biography and expertise to the content."|"&lt;biography, content creation</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</node>
<node id="Retrieval-Augmented Generation">
  <data key="d0">Retrieval-Augmented Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Retrieval-Augmented Generation (RAG) is a model architecture that combines pre-trained parametric and non-parametric memory for language generation, aimed at improving knowledge access and manipulation in NLP tasks.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Pre-trained language models">
  <data key="d0">Pre-trained language models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Pre-trained neural language models are models trained on large datasets to learn language representations and store factual knowledge within their parameters.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Explicit non-parametric memory">
  <data key="d0">Explicit non-parametric memory</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Explicit non-parametric memory refers to external memory components, such as dense vector indexes, that can be accessed during language generation to supplement model knowledge.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wikipedia">
  <data key="d0">Wikipedia</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A knowledge base used as the evidence source for fact verification tasks.&lt;SEP&gt;A knowledge base used as the evidence source for retrieving information to support or refute claims in the FEVER task.&lt;SEP&gt;The source of evidence used in FEVER to support or refute claims.&lt;SEP&gt;Wikipedia is a large, collaboratively edited online encyclopedia serving as a primary external knowledge base for grounding models in factual data.&lt;SEP&gt;Wikipedia is an online encyclopedia used as a source for generating answers and evaluating factual correctness.&lt;SEP&gt;Wikipedia serves as a dense vector index used as non-parametric memory in RAG models, providing external factual information.&lt;SEP&gt;Wikipedia serves as a large, publicly available knowledge base used as an external source for grounding language models in factual information.&lt;SEP&gt;Wikipedia serves as the source of evidence for classifying claims as supported, refuted, or unverifiable in FEVER.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-99d4d675d4565ed5a3ce6fb12d24e2ee&lt;SEP&gt;chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Neural retriever">
  <data key="d0">Neural retriever</data>
  <data key="d1">Tools</data>
  <data key="d2">A pre-trained neural retriever is used to access relevant passages from Wikipedia, facilitating retrieval-augmented language generation.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge-intensive NLP tasks">
  <data key="d0">Knowledge-intensive NLP tasks</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The research investigates whether RAG models outperform traditional parametric models on knowledge-intensive NLP tasks, including open-domain question answering and language generation.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="State-of-the-art results">
  <data key="d0">State-of-the-art results</data>
  <data key="d1">Results</data>
  <data key="d2">RAG models achieve state-of-the-art performance on three open domain QA tasks, surpassing parametric seq2seq models and retrieve-and-extract architectures.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Parametric memory">
  <data key="d0">Parametric memory</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Parametric memory refers to the stored knowledge within pre-trained models' parameters, which can be accessed during generation.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Seq2seq model">
  <data key="d0">Seq2seq model</data>
  <data key="d1">Tools</data>
  <data key="d2">A sequence-to-sequence (seq2seq) model is used as the parametric memory component in RAG, enabling language generation based on learned representations.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge manipulation">
  <data key="d0">Knowledge manipulation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study explores how retrieval-augmented models can provide more specific, diverse, and factual language compared to traditional models.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Factual language">
  <data key="d0">Factual language</data>
  <data key="d1">Results</data>
  <data key="d2">RAG models generate more specific, diverse, and factually accurate language than baseline parametric seq2seq models.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Provenance of decisions">
  <data key="d0">Provenance of decisions</data>
  <data key="d1">Limitations</data>
  <data key="d2">Providing provenance for model decisions remains an open challenge, indicating limitations in interpretability and transparency.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Updating world knowledge">
  <data key="d0">Updating world knowledge</data>
  <data key="d1">Limitations</data>
  <data key="d2">Updating the external knowledge base or model parameters to reflect new information is an ongoing research challenge.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Training data">
  <data key="d0">Training data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The corpus of text data used to pre-train LLMs, which influences their knowledge base and reasoning abilities.&lt;SEP&gt;Training data encompasses the large datasets used to pre-train language models, including Wikipedia and other corpora.&lt;SEP&gt;Training data consists of internet-sourced code repositories like GitHub, used to teach AI models programming tasks.&lt;SEP&gt;Training data consists of publicly available internet code repositories, such as GitHub, used to teach models programming tasks and language understanding."|</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3&lt;SEP&gt;chunk-4bb8bb2fc231e52a13ed0e91512e55eb&lt;SEP&gt;chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Evaluation metrics">
  <data key="d0">Evaluation metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Evaluation metrics are quantitative measures used to assess the performance of models on tasks, such as accuracy or F1 score.&lt;SEP&gt;Quantitative measures such as accuracy, success rate, and correctness used to assess model performance on code benchmarks.&lt;SEP&gt;Quantitative measures such as accuracy, success rate, or code correctness used to evaluate LLM performance on code generation benchmarks.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Knowledge access">
  <data key="d0">Knowledge access</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Knowledge access refers to the ability of models to retrieve and utilize external factual information during language generation.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Interpretability">
  <data key="d0">Interpretability</data>
  <data key="d1">Limitations</data>
  <data key="d2">A criticism of soft prompt tuning, indicating that optimized prompts often lack meaningful content and are difficult to interpret coherently, especially when discreted into token vectors.&lt;SEP&gt;A criticism of soft prompt tuning, indicating that optimized prompts often lack meaningful content and are difficult to interpret coherently.&lt;SEP&gt;Enhanced interpretability allows users to understand, trust, and verify model outputs, especially important in sensitive areas like healthcare or legal applications.&lt;SEP&gt;Enhanced interpretability of models allows users to understand and trust generated content, facilitating safer deployment in sensitive areas like healthcare.&lt;SEP&gt;Interpretability concerns how easily the model's decision process can be understood, with provenance providing transparency.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-4bb8bb2fc231e52a13ed0e91512e55eb&lt;SEP&gt;chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge updating">
  <data key="d0">Knowledge updating</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The paper investigates how models can efficiently update their external or internal knowledge bases.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open domain QA tasks">
  <data key="d0">Open domain QA tasks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Open domain question-answering tasks test a model's ability to answer questions based on external knowledge sources.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Diverse language generation">
  <data key="d0">Diverse language generation</data>
  <data key="d1">Results</data>
  <data key="d2">RAG models produce more diverse language outputs, indicating improved creativity and factuality.</data>
  <data key="d3">chunk-4bb8bb2fc231e52a13ed0e91512e55eb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Sequence-to-Sequence Models">
  <data key="d0">Sequence-to-Sequence Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Sequence-to-sequence (seq2seq) models are neural network architectures designed for tasks involving input-to-output sequence mapping, such as translation and question answering.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Pre-trained Seq2seq Transformer">
  <data key="d0">Pre-trained Seq2seq Transformer</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A transformer-based model pre-trained on large corpora, used as the parametric memory component in RAG models.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Dense Passage Retriever (DPR)">
  <data key="d0">Dense Passage Retriever (DPR)</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural retrieval system that fetches relevant text passages from a dense vector index, providing non-parametric memory for RAG.&lt;SEP&gt;A neural retriever that fetches relevant text passages from a dense vector index, providing non-parametric memory for RAG models.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="BART">
  <data key="d0">BART</data>
  <data key="d1">Tools</data>
  <data key="d2">A generative language model used as a baseline for comparison in question answering and text generation tasks.&lt;SEP&gt;A pre-trained seq2seq model used as the generator component in RAG, capable of fine-tuning on various tasks.&lt;SEP&gt;A pre-trained seq2seq transformer model used as the generator component in RAG, capable of fine-tuning for various tasks.&lt;SEP&gt;BART is a generative model used as a baseline for comparison in question answering and generation tasks.&lt;SEP&gt;BART is a sequence-to-sequence transformer model used for generative tasks, such as question generation.&lt;SEP&gt;BART is a transformer-based sequence-to-sequence model used for text generation tasks, known for generating fluent and coherent text but prone to hallucinations.&lt;SEP&gt;BART is a denoising sequence-to-sequence pre-training model designed for tasks such as language generation, translation, and comprehension, utilizing transformer architecture.&lt;SEP&gt;BART is a denoising sequence-to-sequence pre-training model designed to improve natural language generation, translation, and comprehension tasks using transformer architecture.&lt;SEP&gt;BART is a transformer-based model architecture used as the foundation for DeepDevPERF.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb&lt;SEP&gt;chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-cfcd5a8798f30da73fdaa3033d579b42&lt;SEP&gt;chunk-25ebcde4744e2b19ba1d5d1fd25807b0&lt;SEP&gt;chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Knowledge-Intensive Tasks">
  <data key="d0">Knowledge-Intensive Tasks</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Tasks requiring external knowledge, such as open QA and fact verification, benefit from combined parametric and non-parametric memory approaches.&lt;SEP&gt;Tasks such as open QA, fact verification, and question generation that require external knowledge sources for accurate responses.&lt;SEP&gt;Tasks such as question answering that require external knowledge sources, leveraging the RAG framework for improved accuracy.&lt;SEP&gt;Tasks that require external knowledge, such as question answering, where RAG leverages a non-parametric knowledge source (Wikipedia dump) for improved performance.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="State-of-the-Art Results">
  <data key="d0">State-of-the-Art Results</data>
  <data key="d1">Results</data>
  <data key="d2">RAG models achieve leading performance on datasets like Natural Questions, WebQuestions, CuratedTrec, surpassing previous models especially in factuality, diversity, and robustness.&lt;SEP&gt;The RAG models achieve leading performance on datasets like Natural Questions, WebQuestions, and CuratedTrec, outperforming previous models, especially in factuality and diversity.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open Natural Questions, WebQuestions, CuratedTrec, TriviaQA, MS-MARCO, Jeopardy questions, FEVER">
  <data key="d0">Open Natural Questions, WebQuestions, CuratedTrec, TriviaQA, MS-MARCO, Jeopardy questions, FEVER</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Various datasets used to evaluate the models' effectiveness in knowledge-intensive tasks.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="End-to-End Training">
  <data key="d0">End-to-End Training</data>
  <data key="d1">Methodology</data>
  <data key="d2">Training approach where retriever and generator components are jointly optimized, marginalizing over retrieved documents to improve overall performance.&lt;SEP&gt;Training approach where retriever and generator components are jointly optimized, marginalizing over retrieved documents.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Top-K Approximation">
  <data key="d0">Top-K Approximation</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique to marginalize over the top K retrieved documents, either on a per-output or per-token basis, to approximate the distribution over generated text.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Unconstrained Generation">
  <data key="d0">Unconstrained Generation</data>
  <data key="d1">Results</data>
  <data key="d2">Generating responses without strict extractive constraints leads to more factual, specific, and diverse outputs than purely extractive methods.&lt;SEP&gt;Generation without strict extractive constraints leads to responses that are more factual, specific, and diverse compared to purely extractive approaches.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge Updating">
  <data key="d0">Knowledge Updating</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The ability to hot-swap retrieval indexes allows models to update their knowledge base dynamically without retraining, facilitating real-time knowledge refreshment.&lt;SEP&gt;The non-parametric memory can be replaced or updated to reflect changes in world knowledge, maintaining model relevance.&lt;SEP&gt;The non-parametric memory component can be replaced or updated to reflect new information, allowing models to adapt to changing world knowledge.&lt;SEP&gt;The process of improving model knowledge by replacing or editing the document index, enabling models to stay current without retraining.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad&lt;SEP&gt;chunk-6c82d084cc6bf7773cde2e068c3bcedc&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open-Domain Extractive Question Answering">
  <data key="d0">Open-Domain Extractive Question Answering</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A task in NLP focused on retrieving relevant information from large text corpora to answer questions accurately.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Hybrid Parametric and Non-Parametric Memory">
  <data key="d0">Hybrid Parametric and Non-Parametric Memory</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A combined memory approach that leverages pre-trained models (parametric) and external retrieval (non-parametric) to enhance knowledge access in NLP models.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Sequence-to-Sequence (seq2seq) Models">
  <data key="d0">Sequence-to-Sequence (seq2seq) Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Neural network architectures designed to map input sequences to output sequences, foundational in tasks like translation and question answering.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Pre-trained Transformer Models">
  <data key="d0">Pre-trained Transformer Models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Transformers like BART and T5 that have been trained on large datasets, serving as the backbone for the generator in RAG.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Datasets">
  <data key="d0">Datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Multiple datasets including Natural Questions, WebQuestions, CuratedTrec, TriviaQA, MS-MARCO, Jeopardy questions, and FEVER used to evaluate model performance.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Comparison with Previous Approaches">
  <data key="d0">Comparison with Previous Approaches</data>
  <data key="d1">Results</data>
  <data key="d2">RAG models outperform architectures like memory networks, stack-augmented networks, and memory layers, especially in knowledge-intensive tasks.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Components">
  <data key="d0">Model Components</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The retriever p⧸(z|x) with parameters ⧸ that retrieves relevant documents, and the generator p⧸(yi|x, z, y1:i−1) that produces output conditioned on retrieved documents and input.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Variants">
  <data key="d0">Model Variants</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">RAG-Sequence uses the same document for all tokens, marginalizing over top-K documents; RAG-Token predicts each token based on different documents, allowing more flexible content generation.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge-Intensive Generation">
  <data key="d0">Knowledge-Intensive Generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Models that generate responses based on external knowledge sources, producing more factual and specific answers.</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Flexibility">
  <data key="d0">Model Flexibility</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The ability to adjust the number of retrieved documents at test time influences model performance and runtime, offering flexibility in deployment.&lt;SEP&gt;The ability to replace or update non-parametric memory enables models to adapt to new information and changing facts.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG-Token Model">
  <data key="d0">RAG-Token Model</data>
  <data key="d1">Methodology</data>
  <data key="d2">A model that retrieves relevant documents and marginalizes over them to generate content, enabling the generator to select information from multiple documents when producing answers.&lt;SEP&gt;A retrieval-augmented generation model that combines document retrieval and sequence generation, allowing flexible content selection from multiple documents.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval Component p⌘(z|x)">
  <data key="d0">Retrieval Component p⌘(z|x)</data>
  <data key="d1">Tools</data>
  <data key="d2">A component based on DPR that encodes documents and queries into dense representations to retrieve relevant documents through maximum inner product search.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generator Component p✓(yi|x, z, y 1:i1)">
  <data key="d0">Generator Component p✓(yi|x, z, y 1:i1)</data>
  <data key="d1">Tools</data>
  <data key="d2">A seq2seq transformer (BART-large) that generates output sequences conditioned on input and retrieved documents, combining content for answer generation.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="DPR (Dense Passage Retrieval)">
  <data key="d0">DPR (Dense Passage Retrieval)</data>
  <data key="d1">Tools</data>
  <data key="d2">A bi-encoder architecture that encodes documents and queries into dense vectors to efficiently retrieve relevant documents, trained on datasets like TriviaQA and Natural Questions.&lt;SEP&gt;A retrieval system trained with supervised signals from datasets like Natural Questions and TriviaQA, used to initialize retrievers in RAG models.&lt;SEP&gt;DPR is a retrieval system that uses supervised signals from datasets like Natural Questions and TriviaQA to initialize retrievers in RAG models.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="BART-large">
  <data key="d0">BART-large</data>
  <data key="d1">Tools</data>
  <data key="d2">A pre-trained sequence-to-sequence transformer model used as the generator in RAG, known for state-of-the-art performance on various generation tasks.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Sequence Classification Tasks">
  <data key="d0">Sequence Classification Tasks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Use of RAG for sequence classification by considering target classes as sequences of length one, demonstrating the model's flexibility.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Training">
  <data key="d0">Training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Joint training of retriever and generator components using negative log-likelihood minimization, without supervision on specific documents to retrieve.&lt;SEP&gt;Joint training of retriever and generator components using negative marginal log-likelihood minimization with stochastic gradient descent, without supervision on specific documents to retrieve.&lt;SEP&gt;The process of optimizing the retrieval and generation components together to improve performance on knowledge-intensive tasks.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Decoding">
  <data key="d0">Decoding</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Different decoding strategies for RAG: RAG-Token employs autoregressive beam search, while RAG-Sequence uses thorough or fast decoding by scoring hypotheses across multiple documents.&lt;SEP&gt;Strategies for generating output sequences in RAG, including RAG-Token (autoregressive) and RAG-Sequence (hypothesis scoring across documents).</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="z2top-k(p(·|x))p⌘(z|x)NY">
  <data key="d0">z2top-k(p(·|x))p⌘(z|x)NY</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A mathematical expression representing the probability distribution used in the RAG-Token model, involving top-k retrieval and marginalization over latent variables.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="ip✓(yi|x, z, y 1:i1)">
  <data key="d0">ip✓(yi|x, z, y 1:i1)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A conditional probability function defining the likelihood of the output token yi given input x, retrieved document z, and previous output tokens.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="retriever">
  <data key="d0">retriever</data>
  <data key="d1">Tools</data>
  <data key="d2">Component based on DPR that retrieves relevant documents using dense representations and maximum inner product search.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="generator">
  <data key="d0">generator</data>
  <data key="d1">Tools</data>
  <data key="d2">Component based on BART-large that generates output sequences conditioned on input and retrieved documents.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="pRAG-Token(y|x)">
  <data key="d0">pRAG-Token(y|x)</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">The probability distribution used during decoding in RAG-Token, combining retrieval probabilities and generator outputs to produce answers.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="p✓(yi|x, z, y 1:i1)">
  <data key="d0">p✓(yi|x, z, y 1:i1)</data>
  <data key="d1">Variables</data>
  <data key="d2">The conditional probability of generating token yi based on input x, retrieved document z, and previous tokens, parameterized by the generator model.&lt;SEP&gt;The sequence generation probability function conditioned on input, retrieved document, and previous tokens.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="p⌘(z|x)">
  <data key="d0">p⌘(z|x)</data>
  <data key="d1">Variables</data>
  <data key="d2">The document retrieval probability function within the RAG framework, based on dense representations.&lt;SEP&gt;The probability of retrieving document z given input x, modeled by the retriever component based on DPR.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG-Sequence">
  <data key="d0">RAG-Sequence</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A decoding approach that runs beam search for each retrieved document, combining hypothesis scores across documents to produce final output.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG-Token">
  <data key="d0">RAG-Token</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A decoding approach that models output token probabilities conditioned on input, retrieved document, and previous tokens, enabling efficient generation.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wikipedia dump">
  <data key="d0">Wikipedia dump</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A large-scale knowledge source used as the non-parametric memory for document retrieval in RAG.</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Fast Decoding">
  <data key="d0">Fast Decoding</data>
  <data key="d1">Methodology</data>
  <data key="d2">A decoding procedure designed to avoid redundant computations by utilizing previous information, thereby improving efficiency in sequence generation.&lt;SEP&gt;A decoding procedure designed to avoid redundant forward passes by utilizing information from previous steps, thereby improving efficiency in sequence generation.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Experiments">
  <data key="d0">Experiments</data>
  <data key="d1">Study Design</data>
  <data key="d2">A series of tests conducted to evaluate the performance of RAG across various knowledge-intensive tasks using a specific dataset and evaluation metrics.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wikipedia dump (December 2018)">
  <data key="d0">Wikipedia dump (December 2018)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large corpus of Wikipedia articles split into disjoint 100-word chunks used as a non-parametric knowledge source for retrieval in experiments.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document encoder">
  <data key="d0">Document encoder</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural network component used to compute embeddings for Wikipedia documents, facilitating fast retrieval via FAISS index.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="FAISS">
  <data key="d0">FAISS</data>
  <data key="d1">Tools</data>
  <data key="d2">A library for efficient similarity search and clustering, used here to build a MIPS index for document retrieval.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Hierarchical Navigable Small World (HNSW)">
  <data key="d0">Hierarchical Navigable Small World (HNSW)</data>
  <data key="d1">Tools</data>
  <data key="d2">An approximate nearest neighbor algorithm used within FAISS for fast and scalable document retrieval.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open-domain Question Answering (QA)">
  <data key="d0">Open-domain Question Answering (QA)</data>
  <data key="d1">Research Question/Hypothesis</data>
  <data key="d2">The study investigates the effectiveness of RAG in answering questions by retrieving relevant documents and generating answers, compared to extractive and closed-book methods.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Natural Questions (NQ)&quot;,">
  <data key="d0">Natural Questions (NQ)",</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">A dataset comprising real user questions and answers used to evaluate open-domain QA performance.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="TriviaQA (TQA)&quot;,">
  <data key="d0">TriviaQA (TQA)",</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">A dataset of trivia questions and answers used for evaluating QA models.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="WebQuestions (WQ)&quot;,">
  <data key="d0">WebQuestions (WQ)",</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">A dataset of questions from the web used for QA evaluation.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="CuratedTrec (CT)&quot;,">
  <data key="d0">CuratedTrec (CT)",</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">A small dataset of curated questions and answers for QA testing.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Exact Match (EM) scores">
  <data key="d0">Exact Match (EM) scores</data>
  <data key="d1">Results</data>
  <data key="d2">A metric used to evaluate the accuracy of answers generated by QA models by comparing them to ground truth answers.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Abstractive Question Answering">
  <data key="d0">Abstractive Question Answering</data>
  <data key="d1">Research Question/Hypothesis</data>
  <data key="d2">The study explores RAG’s capability to generate free-form answers that go beyond span extraction, assessing its performance on a knowledge-intensive NLG task.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="MSMARCO NLG task v2.1">
  <data key="d0">MSMARCO NLG task v2.1</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset consisting of questions, retrieved passages, and annotated full-sentence answers used to evaluate abstractive QA performance.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jeopardy Question Generation">
  <data key="d0">Jeopardy Question Generation</data>
  <data key="d1">Research Question/Hypothesis</data>
  <data key="d2">A specific task designed to evaluate models' ability to generate questions similar to those in the game show Jeopardy, involving comparison of different models' performance.&lt;SEP&gt;A task involving generating questions in the style of Jeopardy for evaluating model capabilities.&lt;SEP&gt;The task aims to generate factual Jeopardy-style questions conditioned on entity answers, testing RAG’s knowledge-intensive generation abilities.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-99d4d675d4565ed5a3ce6fb12d24e2ee&lt;SEP&gt;chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="SearchQA">
  <data key="d0">SearchQA</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">A dataset of search engine snippets used for training and evaluating question generation models.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Q-BLEU-1">
  <data key="d0">Q-BLEU-1</data>
  <data key="d1">Tools</data>
  <data key="d2">A variant of BLEU metric emphasizing entity matching, used to evaluate the factuality and quality of generated questions in the Jeopardy task.&lt;SEP&gt;Q-BLEU-1 is a metric used to evaluate the quality of generated questions by measuring similarity to reference questions.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee&lt;SEP&gt;chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Human Evaluation">
  <data key="d0">Human Evaluation</data>
  <data key="d1">Methods</data>
  <data key="d2">A process involving human judges comparing questions generated by different models to assess factuality and specificity.&lt;SEP&gt;A process where human judges assess the factuality, specificity, and overall quality of model-generated responses.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee&lt;SEP&gt;chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Fact Veriﬁcation (FEVER)">
  <data key="d0">Fact Veriﬁcation (FEVER)</data>
  <data key="d1">Research Question/Hypothesis</data>
  <data key="d2">The task assesses the ability of models to retrieve evidence from Wikipedia and classify claims as supported, refuted, or unverifiable.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Y">
  <data key="d0">Y</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The letter 'y' is classified as a vowel only when it appears at the end of a word, emphasizing its contextual phonetic role in language.&lt;SEP&gt;Y is a variable representing the output of a process or function, not generated during beam search, used in decoding procedures.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee&lt;SEP&gt;chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Beam Search">
  <data key="d0">Beam Search</data>
  <data key="d1">Methodology</data>
  <data key="d2">A decoding algorithm used in sequence generation tasks to explore multiple candidate sequences efficiently, often balancing exploration and exploitation.&lt;SEP&gt;A pruning search algorithm that limits the search space in scheduling problems, providing more predictable and stable solutions.&lt;SEP&gt;A search algorithm used to prune the solution space in scheduling problems, providing more predictable and stable results by limiting the search space with pruning strategies like n-best.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc&lt;SEP&gt;chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Natural Questions (NQ)">
  <data key="d0">Natural Questions (NQ)</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">A dataset comprising real user questions and answers used to evaluate open-domain QA performance.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="TriviaQA (TQA)">
  <data key="d0">TriviaQA (TQA)</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">A dataset of trivia questions and answers used for evaluating QA models.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="WebQuestions (WQ)">
  <data key="d0">WebQuestions (WQ)</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">A dataset of questions from the web used for QA evaluation.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="CuratedTrec (CT)">
  <data key="d0">CuratedTrec (CT)</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">A small dataset of curated questions and answers for QA testing.</data>
  <data key="d3">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="FEVER">
  <data key="d0">FEVER</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A benchmark task involving classifying whether a natural language claim is supported, refuted, or has insufficient information based on evidence retrieved from Wikipedia, combining retrieval and reasoning.&lt;SEP&gt;FEVER is a benchmark task that involves classifying whether a natural language claim is supported, refuted, or lacks enough information based on evidence retrieved from Wikipedia, combining retrieval and reasoning components.&lt;SEP&gt;FEVER is a dataset and benchmark for fact extraction and verification, used to evaluate models' ability to retrieve and verify evidence.&lt;SEP&gt;Fact Extraction and VERification (FEVER) is a dataset and benchmark for evaluating fact verification models.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd&lt;SEP&gt;chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="3.4 Fact Verification">
  <data key="d0">3.4 Fact Verification</data>
  <data key="d1">Study Design</data>
  <data key="d2">A specific task within FEVER focused on classifying claims using evidence retrieval and entailment reasoning.&lt;SEP&gt;The section describes a specific task within the FEVER benchmark, focusing on fact verification through evidence retrieval and entailment reasoning.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Natural Language Claim">
  <data key="d0">Natural Language Claim</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A natural language claim is a statement that needs to be verified against evidence from Wikipedia in the FEVER task.&lt;SEP&gt;A statement in natural language that needs to be verified against evidence in the FEVER task.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval Problem">
  <data key="d0">Retrieval Problem</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">FEVER frames claim verification as a retrieval problem coupled with entailment reasoning to determine claim support or refutation.&lt;SEP&gt;FEVER frames the task as a retrieval problem coupled with entailment reasoning, emphasizing the importance of evidence retrieval in claim verification.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Entailment Reasoning">
  <data key="d0">Entailment Reasoning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A logical process to determine if evidence supports or refutes a claim, central to FEVER.&lt;SEP&gt;Entailment reasoning involves determining whether evidence logically supports or refutes a claim, central to FEVER's classification process.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Label Accuracy">
  <data key="d0">Label Accuracy</data>
  <data key="d1">Results</data>
  <data key="d2">An evaluation metric measuring the correctness of model classifications in FEVER.&lt;SEP&gt;The evaluation metric used in FEVER to measure the performance of models on classifying claims correctly.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG Models">
  <data key="d0">RAG Models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Retrieval-Augmented Generation (RAG) models combine retrieval of evidence with generative capabilities to perform classification and question answering tasks without supervision on retrieved evidence.&lt;SEP&gt;Retrieval-Augmented Generation models that combine retrieval of evidence with generative capabilities to perform classification tasks without supervision on evidence.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Supervision Signals">
  <data key="d0">Supervision Signals</data>
  <data key="d1">Variables</data>
  <data key="d2">Supervision signals refer to the training signals used to guide models, which in many real-world applications may be absent, affecting the training approach.&lt;SEP&gt;Training signals guiding model learning; their absence in many real-world scenarios influences model design and applicability.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="State-of-the-Art Models">
  <data key="d0">State-of-the-Art Models</data>
  <data key="d1">Results</data>
  <data key="d2">Models like RAG that achieve leading performance on benchmarks such as FEVER and open-domain QA tasks.&lt;SEP&gt;The text reports that RAG models achieve new state-of-the-art performance on multiple open-domain question answering tasks, outperforming previous models.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open-domain Question Answering">
  <data key="d0">Open-domain Question Answering</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Answering questions using broad knowledge sources like Wikipedia, requiring retrieval and reasoning.&lt;SEP&gt;Open-domain QA involves answering questions using broad, unstructured knowledge sources like Wikipedia, requiring retrieval and reasoning.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generation and Classification Test Scores">
  <data key="d0">Generation and Classification Test Scores</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics evaluating model performance on tasks like Jeopardy, MS-MARCO, FEVER, indicating accuracy and effectiveness.&lt;SEP&gt;Metrics evaluating the performance of models like RAG on tasks such as Jeopardy, MS-MARCO, FEVER, indicating their accuracy and effectiveness.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="MS-MARCO">
  <data key="d0">MS-MARCO</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset and benchmark for evaluating question answering and information retrieval models.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="FVR3 (FEVER 3)">
  <data key="d0">FVR3 (FEVER 3)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A variant or dataset related to FEVER used for evaluating fact verification models.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="FVR2 (FEVER 2)">
  <data key="d0">FVR2 (FEVER 2)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Another variant or dataset related to FEVER for model evaluation.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="B-1 (BLEU-1)">
  <data key="d0">B-1 (BLEU-1)</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric measuring the overlap of unigrams between generated and reference texts, used for evaluating answer quality.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="QB-1 (Question BERT-1)">
  <data key="d0">QB-1 (Question BERT-1)</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric based on BERT for evaluating question relevance or quality.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="R-L (Rouge-L)">
  <data key="d0">R-L (Rouge-L)</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric measuring the longest common subsequence between generated and reference texts, used for evaluating text generation.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG-Tok.">
  <data key="d0">RAG-Tok.</data>
  <data key="d1">Methods</data>
  <data key="d2">A variant of RAG that uses token-level retrieval and generation techniques.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG-Seq.">
  <data key="d0">RAG-Seq.</data>
  <data key="d1">Methods</data>
  <data key="d2">A variant of RAG that uses sequence-level retrieval and generation techniques.</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG models">
  <data key="d0">RAG models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Retrieval-Augmented Generation (RAG) models are advanced language models that combine retrieval mechanisms with generative capabilities, designed to produce factually accurate and diverse responses.&lt;SEP&gt;Retrieval-Augmented Generation (RAG) models combine parametric memory with non-parametric retrieval to generate more factual and contextually relevant responses in NLP tasks.&lt;SEP&gt;Retrieval-Augmented Generation models combine parametric memory with non-parametric retrieval to produce more factual, contextually relevant responses in NLP tasks.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933&lt;SEP&gt;chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document Posterior">
  <data key="d0">Document Posterior</data>
  <data key="d1">Variables</data>
  <data key="d2">The posterior probability distribution over retrieved documents during generation, indicating which documents influence the output.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Parametric Knowledge">
  <data key="d0">Parametric Knowledge</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Knowledge stored within the model parameters, enabling the model to complete titles or facts without external retrieval.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Non-parametric Memory">
  <data key="d0">Non-parametric Memory</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An external memory component that stores information outside the model's parameters, allowing updates by replacing or editing stored data, such as document indices.&lt;SEP&gt;External retrieval component that guides generation by providing specific documents or evidence.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad&lt;SEP&gt;chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document 1">
  <data key="d0">Document 1</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A source document containing information about Hemingway's works, used for retrieval in fact verification and generation tasks.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document 2">
  <data key="d0">Document 2</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Another source document with details about Hemingway's novels, supporting the generation of accurate responses.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document 3">
  <data key="d0">Document 3</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Additional source document providing supplementary information relevant to the task.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document 4">
  <data key="d0">Document 4</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Further document used for retrieval to enhance factual accuracy.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document 5">
  <data key="d0">Document 5</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Additional supporting document for fact verification and question generation.</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Purgatorio">
  <data key="d0">Purgatorio</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Purgatorio is the second cantica of Dante Alighieri's Divine Comedy, depicting the soul's purification process in the afterlife.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Paradiso">
  <data key="d0">Paradiso</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Paradiso is the third cantica of Dante's Divine Comedy, representing the ascent to heaven and divine enlightenment.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Thorne">
  <data key="d0">Thorne</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Thorne's model involves classifying claims as true or false using a trained language model, such as RoBERTa, based on evidence sentences.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Vlachos">
  <data key="d0">Vlachos</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Vlachos' approach complements Thorne's by providing methods for evidence-based claim classification.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RoBERTa">
  <data key="d0">RoBERTa</data>
  <data key="d1">Tools</data>
  <data key="d2">RoBERTa is a transformer-based language model used for natural language understanding tasks, including claim classification.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG (Retrieval-Augmented Generation)">
  <data key="d0">RAG (Retrieval-Augmented Generation)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A model architecture that enhances language models by retrieving relevant documents to improve knowledge and performance.&lt;SEP&gt;RAG combines retrieval of relevant documents with generative models to improve factual accuracy and evidence retrieval in tasks like question answering.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd&lt;SEP&gt;chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Gold Evidence Sentence">
  <data key="d0">Gold Evidence Sentence</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A gold evidence sentence is the annotated, authoritative sentence used as the ground truth for verifying claim accuracy.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Top k documents">
  <data key="d0">Top k documents</data>
  <data key="d1">Variables</data>
  <data key="d2">The top k documents refer to the highest-ranked retrieved documents in a retrieval system, used to evaluate retrieval performance.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document Title Overlap">
  <data key="d0">Document Title Overlap</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Overlap analysis compares the titles of retrieved documents with gold evidence to assess retrieval accuracy.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generation Diversity">
  <data key="d0">Generation Diversity</data>
  <data key="d1">Results</data>
  <data key="d2">Generation diversity measures how varied the generated texts are, with higher diversity indicating less repetitive, more factual outputs.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval Ablations">
  <data key="d0">Retrieval Ablations</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Ablation studies assess the impact of different retrieval mechanisms, such as freezing retrievers or replacing them with simpler methods, on model performance.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="BM25">
  <data key="d0">BM25</data>
  <data key="d1">Tools</data>
  <data key="d2">A ranking function used in information retrieval to estimate the relevance of documents based on term frequency and document length.&lt;SEP&gt;BM25 is a traditional information retrieval algorithm based on word overlap used as a baseline for document retrieval.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Index Hot-Swapping">
  <data key="d0">Index Hot-Swapping</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Index hot-swapping involves replacing or updating the non-parametric memory index used by RAG to incorporate new knowledge without retraining the entire model.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="World Leaders">
  <data key="d0">World Leaders</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A list of 82 world leaders with changed positions between 2016 and 2018 used to evaluate retrieval and updating of world knowledge.&lt;SEP&gt;Individuals holding leadership positions globally, whose data is analyzed using indices to assess accuracy and facilitate knowledge updates.&lt;SEP&gt;Individuals in global leadership positions whose data is analyzed using indices to assess accuracy and update knowledge.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd&lt;SEP&gt;chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Template 'Who is {position}?'">
  <data key="d0">Template 'Who is {position}?'</data>
  <data key="d1">Tools</data>
  <data key="d2">A templated question format used to query the index for specific information about world leaders.</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="2016 Index">
  <data key="d0">2016 Index</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A numerical representation used to analyze and compare world leaders' data from 2016, utilized for matching and updating knowledge.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="2018 Index">
  <data key="d0">2018 Index</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A numerical representation used to analyze and compare world leaders' data from 2018, used for matching and updating knowledge.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Indices">
  <data key="d0">Indices</data>
  <data key="d1">Variables</data>
  <data key="d2">Numerical metrics used to measure and compare data related to world leaders, with mismatched indices affecting accuracy.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Accuracy">
  <data key="d0">Accuracy</data>
  <data key="d1">Results</data>
  <data key="d2">Accuracy measures the correctness of the model's predictions, typically evaluated against ground truth data, but is distinguished from confidence metrics like perplexity.&lt;SEP&gt;Accuracy measures the proportion of correct outputs produced by models, such as correct pragma generation or performance slowdown predictions, serving as a key metric for evaluating model effectiveness.&lt;SEP&gt;Accuracy measures the proportion of correct predictions made by a model, such as correctly generating pragmas or predicting performance slowdown, serving as a metric for model success.&lt;SEP&gt;Measurement of how correctly the models predict the presence and structure of OpenMP pragmas, with 97% and 94% for PolyCoder+HPC and PolyCoder respectively.&lt;SEP&gt;The measure of correctness in matching world leaders' data across different indices, with low accuracy indicating challenges in data matching.&lt;SEP&gt;The measure of how accurately the model predicts tokens during validation, used alongside perplexity to evaluate performance.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-7d9c04128411fd2962a424d26641c6ad&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Non-Parametric Memory">
  <data key="d0">Non-Parametric Memory</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">External memory component that stores information outside the model parameters, allowing updates by replacing or editing stored data.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieving More Documents">
  <data key="d0">Retrieving More Documents</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique where models fetch additional relevant documents during processing to improve performance, with performance depending on the number of documents retrieved.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Performance Metrics (e.g., NQ, Rouge-L, Bleu-1)">
  <data key="d0">Performance Metrics (e.g., NQ, Rouge-L, Bleu-1)</data>
  <data key="d1">Results</data>
  <data key="d2">Quantitative measures used to evaluate the effectiveness of retrieval strategies and model outputs on tasks like question answering and text generation.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Test Time Adjustment">
  <data key="d0">Test Time Adjustment</data>
  <data key="d1">Methodology</data>
  <data key="d2">Dynamically changing the number of retrieved documents at test time to optimize performance and computational efficiency.&lt;SEP&gt;The process of dynamically changing the number of retrieved documents during testing to optimize model performance and runtime.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Figure 3">
  <data key="d0">Figure 3</data>
  <data key="d1">Tools</data>
  <data key="d2">A visual figure illustrating the effects of retrieving different numbers of documents on various performance metrics like NQ, Rouge-L, Bleu-1.&lt;SEP&gt;A visual representation illustrating the impact of retrieved documents on model performance metrics such as NQ, Rouge-L, and Bleu-1.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Related Work">
  <data key="d0">Related Work</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Previous research exploring retrieval in NLP tasks, general-purpose architectures, learned retrieval methods, and memory-based models to contextualize current approaches.&lt;SEP&gt;Previous research exploring retrieval in NLP tasks, general-purpose architectures, learned retrieval, and memory-based models, providing context for current approaches.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Single-Task Retrieval">
  <data key="d0">Single-Task Retrieval</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Research demonstrating how retrieval improves performance across various NLP tasks such as question answering, fact checking, and translation.&lt;SEP&gt;Research demonstrating that incorporating retrieval improves performance across multiple NLP tasks, including question answering, fact checking, translation, and dialogue.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="General-Purpose Architectures for NLP">
  <data key="d0">General-Purpose Architectures for NLP</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models like GPT-2, BART, and T5 that achieve strong performance without retrieval, serving as baselines or complements to retrieval-augmented methods.&lt;SEP&gt;Models like GPT-2, BART, and T5 that achieve strong performance without retrieval, serving as baselines or complements to retrieval-augmented models.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Learned Retrieval">
  <data key="d0">Learned Retrieval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approaches involving training models to learn optimal document retrieval strategies, often using neural language models, reinforcement learning, or latent variable techniques.&lt;SEP&gt;Techniques involving training models to learn optimal document retrieval strategies, often using neural language models, reinforcement learning, or latent variable approaches.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Memory-based Architectures">
  <data key="d0">Memory-based Architectures</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models that treat document indices as external memory, enabling attention over stored text or embeddings to improve factual accuracy and interpretability.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieve-and-Edit Approaches">
  <data key="d0">Retrieve-and-Edit Approaches</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods where retrieved content is edited or aggregated to produce final outputs, applied in machine translation and semantic parsing.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Discussion">
  <data key="d0">Discussion</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A broad analysis of the implications, challenges, and future directions of combining retrieval with generative models in NLP.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="2016 index">
  <data key="d0">2016 index</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A numerical index used to analyze and compare data related to 2016 world leaders, utilized for matching and updating knowledge.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="2018 index">
  <data key="d0">2018 index</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A numerical index used to analyze and compare data related to 2018 world leaders, utilized for matching and updating knowledge.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Mismatch">
  <data key="d0">Mismatch</data>
  <data key="d1">Variables</data>
  <data key="d2">Situations where the indices for different years do not align, leading to low accuracy in data matching (e.g., 12% and 4%).</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieving more documents">
  <data key="d0">Retrieving more documents</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique where models fetch additional relevant documents during inference to improve performance, with the number of documents affecting results.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Memory">
  <data key="d0">Memory</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large external storage of information that models can attend to, enabling dynamic updates and retrieval of raw text or embeddings.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Human-Readable Memory">
  <data key="d0">Human-Readable Memory</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A feature of the memory system that stores raw text, making it interpretable and writable by humans, enabling updates by editing the document index.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Human-Writable Memory">
  <data key="d0">Human-Writable Memory</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A memory system that can be directly edited by humans, allowing dynamic updates to stored information.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval Strategies">
  <data key="d0">Retrieval Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for selecting relevant documents or information during model inference, affecting performance and efficiency.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Document Index">
  <data key="d0">Document Index</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The external collection of documents used for retrieval, serving as a knowledge base that can be updated or edited.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval-augmented Generation (RAG)">
  <data key="d0">Retrieval-augmented Generation (RAG)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A hybrid model architecture that combines retrieval of relevant documents with generative language modeling to improve factual accuracy and knowledge incorporation.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Performance Peaks">
  <data key="d0">Performance Peaks</data>
  <data key="d1">Results</data>
  <data key="d2">Observations that for RAG-Sequence, performance improves monotonically with more documents, while RAG-Token peaks at 10 documents.</data>
  <data key="d3">chunk-7d9c04128411fd2962a424d26641c6ad</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Semantic Parsing">
  <data key="d0">Semantic Parsing</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Semantic Parsing is a computational approach that converts natural language into formal representations, enabling machines to understand and process human language more effectively.&lt;SEP&gt;Semantic Parsing is a computational approach that involves converting natural language into formal representations, enabling machines to understand and process human language more effectively.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval">
  <data key="d0">Retrieval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Retrieval involves fetching relevant information or evidence documents from large corpora to support or improve language understanding models.&lt;SEP&gt;Retrieval refers to the process of fetching relevant information or evidence documents from a large corpus, often used to support or enhance language understanding models.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Latent Retrieval">
  <data key="d0">Latent Retrieval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Latent retrieval involves learning hidden or implicit representations to improve the relevance and efficiency of information retrieval within models.&lt;SEP&gt;Latent retrieval refers to learning implicit or hidden representations to enhance the relevance and efficiency of information retrieval within models.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open-domain QA">
  <data key="d0">Open-domain QA</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Open-domain Question Answering aims to develop systems capable of answering questions across diverse topics using large external knowledge sources like Wikipedia.&lt;SEP&gt;Open-domain Question Answering involves developing systems capable of answering questions across a wide range of topics using large knowledge sources like Wikipedia.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="State of the Art Results">
  <data key="d0">State of the Art Results</data>
  <data key="d1">Results</data>
  <data key="d2">Achieving the highest performance in open-domain question answering tasks, demonstrating the effectiveness of RAG models.&lt;SEP&gt;Achieving top performance on open-domain QA benchmarks, demonstrating the effectiveness of RAG models.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Factual Knowledge">
  <data key="d0">Factual Knowledge</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Factual knowledge refers to accurate, real-world information stored within or retrieved by models, crucial for reducing hallucinations and increasing trustworthiness.&lt;SEP&gt;Factual knowledge represents accurate, real-world information stored in external sources or learned representations, crucial for reducing hallucinations and increasing response reliability.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Retraining">
  <data key="d0">Model Retraining</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Retraining involves updating models from scratch or fine-tuning, potentially integrating parametric and non-parametric components for improved knowledge integration.&lt;SEP&gt;Retraining involves updating or training models from scratch, potentially combining parametric and non-parametric components for improved performance.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Societal Benefits">
  <data key="d0">Societal Benefits</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Grounding models in factual knowledge can improve societal outcomes by providing accurate information, aiding decision-making, and supporting education.&lt;SEP&gt;Using models grounded in factual data to improve societal outcomes, such as better medical information retrieval or more effective workplace tools.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Bias and Misinformation">
  <data key="d0">Bias and Misinformation</data>
  <data key="d1">Limitations</data>
  <data key="d2">Bias and misinformation refer to the risks of models generating false, misleading, or biased content due to limitations in external data sources or training data.&lt;SEP&gt;Potential downsides include the perpetuation of biases present in external sources like Wikipedia and the risk of generating misleading or false content.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Automated Spam and Misleading Content">
  <data key="d0">Automated Spam and Misleading Content</data>
  <data key="d1">Limitations</data>
  <data key="d2">Advanced language models can be exploited to produce spam, fake news, or impersonate individuals, raising ethical concerns.&lt;SEP&gt;Advanced language models may be exploited to generate spam, fake news, impersonations, or misleading content, raising ethical concerns.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge Source Bias">
  <data key="d0">Knowledge Source Bias</data>
  <data key="d1">Limitations</data>
  <data key="d2">Biases and inaccuracies inherent in external sources like Wikipedia can influence model outputs, leading to potential misinformation or unfair biases.&lt;SEP&gt;Wikipedia and other external knowledge bases may contain inaccuracies or biases, which can influence model outputs.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge Base">
  <data key="d0">Knowledge Base</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Knowledge bases such as Wikidata contain structured, domain-specific information that can be queried and retrieved to enhance language model outputs."|&lt;SEP&gt;Wikipedia functions as a comprehensive external knowledge base used to supply factual content for retrieval and grounding in NLP models.</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc&lt;SEP&gt;chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bias in External Data">
  <data key="d0">Bias in External Data</data>
  <data key="d1">Limitations</data>
  <data key="d2">External data sources like Wikipedia may contain biases, inaccuracies, or outdated information, impacting model fairness and reliability.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Efficiency">
  <data key="d0">Model Efficiency</data>
  <data key="d1">Tools</data>
  <data key="d2">Tools include retrieval systems and indexing techniques that enable models to efficiently fetch relevant evidence during generation.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Training Objectives">
  <data key="d0">Training Objectives</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Denoising objectives like those used in BART or other self-supervised learning methods can be employed to pre-train models for better integration of retrieval and generation.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Research Directions">
  <data key="d0">Research Directions</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Future research includes jointly pre-training parametric and non-parametric components, exploring new training objectives, and improving the interaction between retrieval and generation modules.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Societal Impact">
  <data key="d0">Societal Impact</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Societal impact involves understanding how code generation models influence broader societal factors, such as safety, ethics, and public trust.&lt;SEP&gt;Using factually grounded models can enhance information accuracy, reduce hallucinations, and support societal needs such as healthcare, education, and misinformation mitigation.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb&lt;SEP&gt;chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ethical Concerns">
  <data key="d0">Ethical Concerns</data>
  <data key="d1">Limitations</data>
  <data key="d2">Potential misuse of language models for generating misleading content, impersonation, or automation of malicious activities poses ethical challenges.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Open-source Collaboration">
  <data key="d0">Open-source Collaboration</data>
  <data key="d1">Tools</data>
  <data key="d2">HuggingFace and other platforms support open-sourcing code and models, fostering community development and transparency in NLP research.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Funding Sources">
  <data key="d0">Funding Sources</data>
  <data key="d1">Limitations</data>
  <data key="d2">Funding from organizations like NSF and Facebook supports research but may influence research directions or priorities.</data>
  <data key="d3">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Association for Computational Linguistics">
  <data key="d0">Association for Computational Linguistics</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A professional organization dedicated to advancing the scientific study of language and computational linguistics.&lt;SEP&gt;A professional organization supporting research in computational linguistics and NLP.&lt;SEP&gt;A professional organization supporting research in computational linguistics.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Eunsol Choi">
  <data key="d0">Eunsol Choi</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in entity supervision and sparse memory access in NLP.&lt;SEP&gt;A researcher involved in question answering research, co-author of studies on long document comprehension and entity supervision.&lt;SEP&gt;A researcher involved in question answering research, co-author of studies on long document comprehension.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Daniel Hewlett">
  <data key="d0">Daniel Hewlett</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP research, particularly in question answering and long document comprehension.&lt;SEP&gt;A researcher contributing to question answering and NLP research.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jakob Uszkoreit">
  <data key="d0">Jakob Uszkoreit</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in NLP research, co-author of question answering studies, and entity modeling.&lt;SEP&gt;A researcher involved in NLP research, co-author of question answering studies.&lt;SEP&gt;Jakob Uszkoreit is a researcher contributing to neural network models for NLP.&lt;SEP&gt;Jakob Uszkoreit is a researcher known for neural network architectures in NLP.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Illia Polosukhin">
  <data key="d0">Illia Polosukhin</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP and question answering research.&lt;SEP&gt;A researcher contributing to NLP, especially in question answering and transformer models.&lt;SEP&gt;Illia Polosukhin is a researcher contributing to natural language processing studies.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Alexandre Lacoste">
  <data key="d0">Alexandre Lacoste</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in NLP research and publications related to question answering and language understanding.&lt;SEP&gt;A researcher involved in NLP research and publications.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Proceedings of the 10th Annual Meeting of the Association for Computational Linguistics">
  <data key="d0">Proceedings of the 10th Annual Meeting of the Association for Computational Linguistics</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference proceeding documenting research papers on computational linguistics.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Long Papers">
  <data key="d0">Long Papers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A category of papers in ACL conferences focusing on detailed research studies.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Vancouver, Canada">
  <data key="d0">Vancouver, Canada</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Location where the ACL conference took place in 2017.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="July 2017">
  <data key="d0">July 2017</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Date when the ACL conference was held.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Christopher Clark">
  <data key="d0">Christopher Clark</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in NLP research, author of multi-paragraph reading comprehension studies.&lt;SEP&gt;A researcher involved in NLP, author of multi-paragraph reading comprehension studies.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Matt Gardner">
  <data key="d0">Matt Gardner</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP and reading comprehension research.&lt;SEP&gt;A researcher contributing to NLP research, especially in reading comprehension.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="arXiv:1710.10723">
  <data key="d0">arXiv:1710.10723</data>
  <data key="d1">Tools</data>
  <data key="d2">An arXiv preprint identifier for a publication on multi-paragraph reading comprehension.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="October 2017">
  <data key="d0">October 2017</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Date when the arXiv preprint was published.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jacob Devlin">
  <data key="d0">Jacob Devlin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher involved in NLP, co-author of BERT paper.&lt;SEP&gt;A researcher involved in NLP, co-author of BERT, a foundational language understanding model.&lt;SEP&gt;Jacob Devlin is a researcher known for contributions to natural language understanding and BERT.&lt;SEP&gt;Jacob Devlin is a researcher known for work in natural language understanding.&lt;SEP&gt;Researcher contributing to large-scale language model development.&lt;SEP&gt;Researcher contributing to large-scale language models and their training methodologies.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ming-Wei Chang">
  <data key="d0">Ming-Wei Chang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher contributing to NLP and neural conversation systems.&lt;SEP&gt;A researcher contributing to NLP and pre-training models like BERT.&lt;SEP&gt;A researcher contributing to NLP, co-author of BERT paper.&lt;SEP&gt;A researcher involved in neural conversation models and language understanding.&lt;SEP&gt;Ming-Wei Chang is a researcher contributing to language models and retrieval frameworks.&lt;SEP&gt;Ming-Wei Chang is a researcher involved in natural language processing and retrieval methods.&lt;SEP&gt;Ming-Wei Chang is a researcher working on language models, retrieval, and structured prediction frameworks.&lt;SEP&gt;Ming-Wei Chang is a researcher working on question answering and retrieval techniques.&lt;SEP&gt;Ming-Wei Chang is a researcher working on retrieval techniques and question answering.&lt;SEP&gt;Ming-Wei Chang is working on retrieval techniques and question answering.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-b5a1ae2fdbff2671d10e6572fa6fc442&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kenton Lee">
  <data key="d0">Kenton Lee</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher involved in NLP, co-author of BERT paper.&lt;SEP&gt;A researcher involved in NLP, contributing to transformer-based models.&lt;SEP&gt;Kenton Lee is a researcher contributing to language models and retrieval techniques.&lt;SEP&gt;Kenton Lee is a researcher involved in latent retrieval and question answering.&lt;SEP&gt;Kenton Lee is a researcher involved in latent retrieval methods for open domain question answering.&lt;SEP&gt;Kenton Lee is a researcher working on retrieval models and language understanding in NLP.&lt;SEP&gt;Kenton Lee is involved in research on latent retrieval for question answering.&lt;SEP&gt;Kenton Lee is involved in research on latent retrieval methods for question answering.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-b5a1ae2fdbff2671d10e6572fa6fc442&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kristina Toutanova">
  <data key="d0">Kristina Toutanova</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP, co-author of BERT paper.&lt;SEP&gt;A researcher involved in NLP, contributing to language models and understanding.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics">
  <data key="d0">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference proceeding documenting NLP research including BERT.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Minneapolis, Minnesota">
  <data key="d0">Minneapolis, Minnesota</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Location of the 2019 NAACL conference.&lt;SEP&gt;Location of the AAAI 2018 conference.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="June 2019">
  <data key="d0">June 2019</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Date of the BERT paper publication event.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Emily Dinan">
  <data key="d0">Emily Dinan</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in NLP, focusing on knowledge-powered conversational agents.&lt;SEP&gt;A researcher involved in conversational agents and knowledge-powered NLP systems.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Stephen Roller">
  <data key="d0">Stephen Roller</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP research on conversational agents.&lt;SEP&gt;A researcher working on NLP, particularly in conversational agents and dialogue systems.&lt;SEP&gt;Stephen Roller is a researcher focusing on dialogue systems and evaluation methods.&lt;SEP&gt;Stephen Roller is a researcher focusing on dialogue systems and evaluation.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kurt Shuster">
  <data key="d0">Kurt Shuster</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP, especially in dialogue systems and conversational AI.&lt;SEP&gt;A researcher involved in NLP and conversational systems.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Angela Fan">
  <data key="d0">Angela Fan</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in NLP, long-form question answering, and model augmentation.&lt;SEP&gt;A researcher involved in NLP, story generation, and knowledge augmentation.&lt;SEP&gt;A researcher involved in NLP, story generation, and knowledge integration.&lt;SEP&gt;A researcher involved in NLP, story generation, and question answering methodologies.&lt;SEP&gt;A researcher working on neural story generation and NLP models.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Michael Auli">
  <data key="d0">Michael Auli</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP language models.&lt;SEP&gt;A researcher contributing to NLP, particularly in language modeling.&lt;SEP&gt;A researcher involved in NLP, language modeling, and neural network architectures.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jason Weston">
  <data key="d0">Jason Weston</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP, especially in neural conversation and dialogue systems.&lt;SEP&gt;A researcher involved in NLP research, especially conversational systems.&lt;SEP&gt;Jason Weston is a researcher involved in NLP and conversational AI.&lt;SEP&gt;Jason Weston is a researcher involved in NLP and dialogue systems.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Melbourne, Australia">
  <data key="d0">Melbourne, Australia</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Location of ACL 2018 conference.&lt;SEP&gt;Location of the ACL 2018 conference.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="July 2018">
  <data key="d0">July 2018</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Date when the ACL 2018 conference took place.&lt;SEP&gt;Date when the ACL 2018 story generation study was published.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Ethan Perez">
  <data key="d0">Ethan Perez</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in NLP, language understanding, and model augmentation.&lt;SEP&gt;A researcher working on NLP models and story generation.&lt;SEP&gt;Ethan Perez works on evidence finding and convincing Q&amp;A models in NLP.&lt;SEP&gt;Ethan Perez works on evidence retrieval, convincing question-answering models, and improving model robustness in NLP.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="David Grangier">
  <data key="d0">David Grangier</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP, language modeling, and question answering.&lt;SEP&gt;A researcher involved in NLP research, especially in language modeling.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Florence, Italy">
  <data key="d0">Florence, Italy</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Location of the ACL 2019 conference.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="July 2019">
  <data key="d0">July 2019</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Date of the long-form QA study publication.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Claire Gardent">
  <data key="d0">Claire Gardent</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP, especially in language understanding.&lt;SEP&gt;A researcher contributing to NLP, language understanding, and question answering.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Chloe Braud">
  <data key="d0">Chloe Braud</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in NLP, story generation, and language modeling.&lt;SEP&gt;A researcher working on NLP models and question answering.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Antoine Bordes">
  <data key="d0">Antoine Bordes</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP, transformer models, and question answering.&lt;SEP&gt;A researcher involved in NLP research, model development.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Augmenting transformers with KNN-based composite memory">
  <data key="d0">Augmenting transformers with KNN-based composite memory</data>
  <data key="d1">Methodology</data>
  <data key="d2">A methodology to enhance transformer models in NLP using KNN-based memory augmentation.&lt;SEP&gt;A technique to enhance transformer models in NLP using KNN-based memory augmentation.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Thibault Févry">
  <data key="d0">Thibault Févry</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher working on entity supervision and sparse memory in NLP.&lt;SEP&gt;A researcher working on entity supervision, sparse memory, and NLP memory systems.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Livio Baldini Soares">
  <data key="d0">Livio Baldini Soares</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP and entity modeling.&lt;SEP&gt;A researcher contributing to NLP, entity modeling, and memory access techniques.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Nicholas FitzGerald">
  <data key="d0">Nicholas FitzGerald</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in NLP research on entities and memory.&lt;SEP&gt;A researcher involved in NLP, entity supervision, and memory access research.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Tom Kwiatkowski">
  <data key="d0">Tom Kwiatkowski</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher working on entity-based models and NLP memory systems.&lt;SEP&gt;Tom Kwiatkowski is a researcher working on question answering benchmarks and NLP evaluation datasets.&lt;SEP&gt;Tom Kwiatkowski is a researcher working on question answering benchmarks and datasets for NLP evaluation.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Entities as experts: Sparse memory access with entity supervision">
  <data key="d0">Entities as experts: Sparse memory access with entity supervision</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique for sparse memory access in NLP using entity supervision.&lt;SEP&gt;A technique for sparse memory access in NLP utilizing entity supervision.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Marjan Ghazvininejad">
  <data key="d0">Marjan Ghazvininejad</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in neural conversation models grounded in knowledge and memory.&lt;SEP&gt;A researcher involved in neural conversation models grounded in knowledge.&lt;SEP&gt;Marjan Ghazvininejad is involved in NLP research, especially in language generation.&lt;SEP&gt;Marjan Ghazvininejad is involved in NLP research, particularly in language generation.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Chris Brockett">
  <data key="d0">Chris Brockett</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to neural conversation modeling and grounded NLP.&lt;SEP&gt;A researcher working on neural conversation modeling.&lt;SEP&gt;Chris Brockett is a researcher working on conversational AI and neural dialogue models.&lt;SEP&gt;Chris Brockett is a researcher working on conversational AI.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Bill Dolan">
  <data key="d0">Bill Dolan</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in NLP, especially in conversational AI.&lt;SEP&gt;A researcher working on NLP, neural conversation, and grounded models.&lt;SEP&gt;Bill Dolan is a researcher specializing in NLP and conversational models.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jianfeng Gao">
  <data key="d0">Jianfeng Gao</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to grounded neural conversation models in NLP.&lt;SEP&gt;A researcher working on grounded neural models in NLP.&lt;SEP&gt;Jianfeng Gao is a researcher focusing on NLP and dialog systems.&lt;SEP&gt;Jianfeng Gao is a researcher focusing on NLP and dialogue systems.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wen Yih">
  <data key="d0">Wen Yih</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP research.&lt;SEP&gt;A researcher involved in NLP, knowledge-grounded models, and conversation systems.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Michel Galley">
  <data key="d0">Michel Galley</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to neural conversation models grounded in knowledge.&lt;SEP&gt;A researcher involved in NLP and neural conversation models.&lt;SEP&gt;Michel Galley is a researcher involved in NLP, especially dialogue systems and evaluation.&lt;SEP&gt;Michel Galley is involved in NLP research, especially dialogue systems.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="When will AI exceed human performance? evidence from AI experts">
  <data key="d0">When will AI exceed human performance? evidence from AI experts</data>
  <data key="d1">Research Question</data>
  <data key="d2">A research question exploring predictions and evidence about AI surpassing human performance.&lt;SEP&gt;A research question exploring the timeline and evidence for AI surpassing human performance.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Katja Grace">
  <data key="d0">Katja Grace</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in AI expertise and performance prediction studies.&lt;SEP&gt;A researcher involved in AI performance prediction and expert surveys.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="John Salvatier">
  <data key="d0">John Salvatier</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to AI performance and expertise research.&lt;SEP&gt;A researcher contributing to AI performance, safety, and expertise studies.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Allan Dafoe">
  <data key="d0">Allan Dafoe</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in AI safety and performance studies.&lt;SEP&gt;A researcher involved in AI safety, performance, and expertise prediction.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Baobao Zhang">
  <data key="d0">Baobao Zhang</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher working on AI, expertise, and performance prediction.&lt;SEP&gt;A researcher working on AI, safety, and expertise prediction.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Owain Evans">
  <data key="d0">Owain Evans</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to AI performance and safety research.&lt;SEP&gt;A researcher contributing to AI performance, safety, and expertise research.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="arXiv:1705.08807">
  <data key="d0">arXiv:1705.08807</data>
  <data key="d1">Tools</data>
  <data key="d2">A preprint identifier discussing AI exceeding human performance.&lt;SEP&gt;Identifier for a preprint discussing AI exceeding human performance.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Search engine guided neural machine translation">
  <data key="d0">Search engine guided neural machine translation</data>
  <data key="d1">Methodology</data>
  <data key="d2">A methodology that uses search engines to guide neural machine translation for improved results.&lt;SEP&gt;A neural machine translation approach utilizing search engines to improve translation quality.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jiatao Gu">
  <data key="d0">Jiatao Gu</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in NLP and search engine-guided translation.&lt;SEP&gt;A researcher involved in NLP, neural machine translation, and search engine guidance.&lt;SEP&gt;Jiatao Gu is a researcher involved in developing search engine guided neural machine translation methods, focusing on integrating search techniques into neural translation models.&lt;SEP&gt;Jiatao Gu is a researcher involved in developing search engine guided neural machine translation methods.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Yong Wang">
  <data key="d0">Yong Wang</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher contributing to NLP and search engine-guided translation.&lt;SEP&gt;Yong Wang is a researcher contributing to neural machine translation and AI research.&lt;SEP&gt;Yong Wang is a researcher contributing to neural machine translation research.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kyunghyun Cho">
  <data key="d0">Kyunghyun Cho</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in neural translation, transformer models, and NLP.&lt;SEP&gt;A researcher working on neural translation and NLP models.&lt;SEP&gt;Kyunghyun Cho is a researcher known for work in neural network models and machine translation.&lt;SEP&gt;Kyunghyun Cho is a researcher known for work on neural network architectures and their applications in machine translation.&lt;SEP&gt;Kyunghyun Cho is involved in NLP research including language modeling, passage re-ranking, and neural network techniques.&lt;SEP&gt;Kyunghyun Cho is involved in NLP research including passage re-ranking and language modeling.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb&lt;SEP&gt;chunk-b5a1ae2fdbff2671d10e6572fa6fc442&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Victor O.K. Li">
  <data key="d0">Victor O.K. Li</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">A researcher involved in NLP and machine translation.&lt;SEP&gt;A researcher working on NLP, machine translation, and search-guided models.&lt;SEP&gt;Victor O.K. Li is a researcher involved in artificial intelligence and machine translation.&lt;SEP&gt;Victor O.K. Li is a researcher involved in artificial intelligence, machine translation, and related methodologies.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442&lt;SEP&gt;chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Proceedings of the 32nd AAAI Conference on Artificial Intelligence">
  <data key="d0">Proceedings of the 32nd AAAI Conference on Artificial Intelligence</data>
  <data key="d1">Study Design</data>
  <data key="d2">Conference proceedings documenting AI research including search engine-guided translation.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="AAAI 2018">
  <data key="d0">AAAI 2018</data>
  <data key="d1">Study Design</data>
  <data key="d2">A major AI conference where research on search engine-guided translation was presented.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="2018">
  <data key="d0">2018</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Year when the search engine-guided translation research was published.</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Search Engine Guided Neural Machine Translation">
  <data key="d0">Search Engine Guided Neural Machine Translation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model that combines search engine techniques with neural machine translation to improve translation accuracy and robustness.&lt;SEP&gt;A model that integrates search engine techniques to improve neural machine translation performance.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="AAAI Conference on Artificial Intelligence 2018">
  <data key="d0">AAAI Conference on Artificial Intelligence 2018</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An academic conference where research papers on artificial intelligence, including neural machine translation, are presented.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kelvin Guu">
  <data key="d0">Kelvin Guu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Kelvin Guu is a researcher working on language models, sentence generation, and retrieval-augmented pretraining methods.&lt;SEP&gt;Kelvin Guu is a researcher working on language models, sentence generation, and retrieval-augmented techniques.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Tatsunori B. Hashimoto">
  <data key="d0">Tatsunori B. Hashimoto</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Tatsunori B. Hashimoto is a researcher involved in structured output prediction and retrieval-based frameworks.&lt;SEP&gt;Tatsunori B. Hashimoto is a researcher specializing in structured output prediction and retrieval frameworks in NLP.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Yonatan Oren">
  <data key="d0">Yonatan Oren</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Yonatan Oren is a researcher contributing to language model pre-training and retrieval methods.&lt;SEP&gt;Yonatan Oren is a researcher involved in language model pretraining, retrieval methods, and structured prediction frameworks.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Percy Liang">
  <data key="d0">Percy Liang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Percy Liang is a researcher focused on natural language understanding, structured prediction, and retrieval-based models.&lt;SEP&gt;Percy Liang is a researcher known for work in natural language processing and structured prediction.&lt;SEP&gt;Percy Liang is a researcher focusing on language models and prompt optimization.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="REALM: Retrieval-augmented Language Model Pre-training">
  <data key="d0">REALM: Retrieval-augmented Language Model Pre-training</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">REALM is a language model framework that incorporates retrieval mechanisms to enhance pretraining and downstream NLP tasks.&lt;SEP&gt;REALM is a language model pre-training framework that incorporates retrieval mechanisms to enhance language understanding and generation.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieve-and-Edit Framework">
  <data key="d0">Retrieve-and-Edit Framework</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A framework for predicting structured outputs by retrieving relevant information and editing it accordingly.&lt;SEP&gt;A framework for structured output prediction that combines retrieval of relevant information with editing to produce outputs.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Nabil Hossain">
  <data key="d0">Nabil Hossain</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Nabil Hossain is a researcher working on text generation techniques, specifically retrieve-edit-rerank strategies for improving output quality.&lt;SEP&gt;Nabil Hossain is a researcher working on text generation, especially retrieve-edit-rerank methods.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Simple and Effective Retrieve-Edit-Rerank Text Generation">
  <data key="d0">Simple and Effective Retrieve-Edit-Rerank Text Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A methodology that combines retrieval, editing, and reranking to improve text generation quality.&lt;SEP&gt;A methodology that integrates retrieval, editing, and reranking processes to generate high-quality text outputs efficiently.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jeff Johnson">
  <data key="d0">Jeff Johnson</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Jeff Johnson is a researcher focusing on large-scale similarity search, especially utilizing GPU acceleration for efficient retrieval.&lt;SEP&gt;Jeff Johnson is involved in similarity search techniques at large scale, often using GPUs.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Zora Tung">
  <data key="d0">Zora Tung</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Zora Tung is a researcher contributing to language modeling, retrieval techniques, and NLP systems.&lt;SEP&gt;Zora Tung is a researcher working on language modeling and retrieval methods.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Panupong Pasupat">
  <data key="d0">Panupong Pasupat</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Panupong Pasupat is involved in NLP tasks related to retrieval, structured prediction, and language understanding.&lt;SEP&gt;Panupong Pasupat is involved in language understanding and retrieval-based NLP tasks.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Dense Passage Retrieval for Open-Domain Question Answering">
  <data key="d0">Dense Passage Retrieval for Open-Domain Question Answering</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A retrieval technique that uses dense vector representations to fetch relevant passages for question answering tasks.&lt;SEP&gt;Dense Passage Retrieval (DPR) is a retrieval technique that uses dense vector representations to find relevant passages for open-domain question answering.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Urvashi Khandelwal">
  <data key="d0">Urvashi Khandelwal</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Urvashi Khandelwal is a researcher exploring generalization in language models through memorization and nearest neighbor approaches.&lt;SEP&gt;Urvashi Khandelwal is a researcher exploring how language models memorize and generalize, utilizing nearest neighbor methods.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Omer Levy">
  <data key="d0">Omer Levy</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Omer Levy is a researcher known for work in language modeling and NLP techniques.&lt;SEP&gt;Omer Levy is a researcher known for work on language modeling, retrieval, and efficient NLP algorithms.&lt;SEP&gt;Omer Levy is a researcher working on language modeling and NLP systems.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Dan Jurafsky">
  <data key="d0">Dan Jurafsky</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dan Jurafsky is a prominent NLP researcher focusing on language understanding, models, and applications.&lt;SEP&gt;Dan Jurafsky is a prominent researcher in computational linguistics and NLP.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Luke Zettlemoyer">
  <data key="d0">Luke Zettlemoyer</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An author analyzing in-context learning mechanisms and demonstration impacts.&lt;SEP&gt;Author working on language model training and evaluation.&lt;SEP&gt;Luke Zettlemoyer is a researcher focusing on language understanding and retrieval models.&lt;SEP&gt;Luke Zettlemoyer is a researcher known for work on NLP models and pre-training.&lt;SEP&gt;Luke Zettlemoyer is a researcher specializing in language modeling, retrieval, and structured prediction techniques.&lt;SEP&gt;Luke Zettlemoyer works on language models' ability to learn to use external tools and improve task performance.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-b5a1ae2fdbff2671d10e6572fa6fc442&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mike Lewis">
  <data key="d0">Mike Lewis</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An author studying in-context learning and demonstration effectiveness in language models.&lt;SEP&gt;Author involved in language model research.&lt;SEP&gt;Mike Lewis is a researcher known for developing BART, a denoising sequence-to-sequence pre-training model.&lt;SEP&gt;Mike Lewis is a researcher known for developing BART, a sequence-to-sequence pre-training model.&lt;SEP&gt;Mike Lewis is involved in language model research, retrieval-based NLP, and generalization strategies.&lt;SEP&gt;Mike Lewis is involved in language modeling, retrieval, and generalization in NLP.&lt;SEP&gt;Mike Lewis researches in NLP, focusing on continual learning and prompt-based training methods.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-b5a1ae2fdbff2671d10e6572fa6fc442&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Generalization through Memorization">
  <data key="d0">Generalization through Memorization</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A concept that discusses how language models can improve their performance by memorizing and retrieving relevant information to generalize better.&lt;SEP&gt;A concept that explores how language models can improve their generalization capabilities by memorizing and retrieving relevant information.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Diederik P. Kingma">
  <data key="d0">Diederik P. Kingma</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Diederik P. Kingma is a researcher known for developing optimization algorithms like Adam for training neural networks.&lt;SEP&gt;Diederik P. Kingma is a researcher known for developing the Adam optimizer, a stochastic optimization algorithm widely used in training neural networks.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jimmy Ba">
  <data key="d0">Jimmy Ba</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Jimmy Ba is a researcher co-developer of the Adam optimizer used in stochastic training of models.&lt;SEP&gt;Jimmy Ba is a researcher co-developer of the Adam optimizer, contributing to effective training of deep learning models.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Adam Optimization Method">
  <data key="d0">Adam Optimization Method</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Adam is an optimization algorithm that combines momentum and adaptive learning rates, widely used for training neural networks efficiently.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Natural Questions Dataset">
  <data key="d0">Natural Questions Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A large-scale dataset for question answering tasks, used as a benchmark for evaluating NLP models.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="32nd AAAI Conference on Artificial Intelligence 2018">
  <data key="d0">32nd AAAI Conference on Artificial Intelligence 2018</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An academic conference where research on AI, including neural machine translation, was presented.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Matthijs Douze">
  <data key="d0">Matthijs Douze</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Matthijs Douze is a researcher specializing in similarity search, indexing, and scalable retrieval systems.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Hervé Jégou">
  <data key="d0">Hervé Jégou</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Hervé Jégou is involved in developing efficient similarity search algorithms and large-scale retrieval systems.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Adam: A Method for Stochastic Optimization">
  <data key="d0">Adam: A Method for Stochastic Optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Adam is an adaptive optimization algorithm that combines momentum and adaptive learning rates, enabling efficient training of deep neural networks.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Natural Questions">
  <data key="d0">Natural Questions</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Natural Questions is a large-scale dataset designed for benchmarking question answering systems, containing real user queries and answers.</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Danielle Epstein">
  <data key="d0">Danielle Epstein</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Danielle Epstein is an author involved in research related to question answering benchmarks.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Matthew Kelcey">
  <data key="d0">Matthew Kelcey</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Matthew Kelcey is a researcher working on question answering research.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kristina N. Toutanova">
  <data key="d0">Kristina N. Toutanova</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Kristina N. Toutanova is a researcher contributing to natural language processing and question answering.&lt;SEP&gt;Kristina N. Toutanova is a researcher focusing on NLP and retrieval models.&lt;SEP&gt;Kristina N. Toutanova is a researcher focusing on NLP models, retrieval, and question answering systems.&lt;SEP&gt;Kristina N. Toutanova is involved in NLP models and retrieval systems.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Llion Jones">
  <data key="d0">Llion Jones</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Llion Jones is a researcher contributing to neural network models for NLP.&lt;SEP&gt;Llion Jones is a researcher working on NLP models and systems.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Andrew Dai">
  <data key="d0">Andrew Dai</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Andrew Dai is a researcher involved in NLP model development and question answering research.&lt;SEP&gt;Andrew Dai is a researcher working on NLP model development.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Slav Petrov">
  <data key="d0">Slav Petrov</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Slav Petrov is a researcher involved in language modeling and NLP research.&lt;SEP&gt;Slav Petrov is a researcher known for contributions to language modeling.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Natural Questions: a Benchmark for Question Answering Research">
  <data key="d0">Natural Questions: a Benchmark for Question Answering Research</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark dataset for evaluating question answering systems, published in 2019.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Transactions of the Association of Computational Linguistics">
  <data key="d0">Transactions of the Association of Computational Linguistics</data>
  <data key="d1">Discipline</data>
  <data key="d2">An academic journal publishing research in computational linguistics.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Guillaume Lample">
  <data key="d0">Guillaume Lample</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Guillaume Lample is a researcher working on neural network architectures and NLP models.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Alexandre Sablayrolles">
  <data key="d0">Alexandre Sablayrolles</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Alexandre Sablayrolles is a researcher focusing on large memory layers with product keys in neural networks.&lt;SEP&gt;Alexandre Sablayrolles is involved in research on neural network memory layers.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Marc’ Aurelio Ranzato">
  <data key="d0">Marc’ Aurelio Ranzato</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Marc’ Aurelio Ranzato is a researcher contributing to neural information processing and deep learning.&lt;SEP&gt;Marc’ Aurelio Ranzato is a researcher contributing to neural information processing.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Ludovic Denoyer">
  <data key="d0">Ludovic Denoyer</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ludovic Denoyer is a researcher involved in neural network models and NLP.&lt;SEP&gt;Ludovic Denoyer is a researcher working on neural network models.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Herve Jegou">
  <data key="d0">Herve Jegou</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Herve Jegou is a researcher involved in neural network research and applications.&lt;SEP&gt;Herve Jegou is a researcher working on neural network models and advances in neural information processing.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Advances in Neural Information Processing Systems 32">
  <data key="d0">Advances in Neural Information Processing Systems 32</data>
  <data key="d1">Study Design</data>
  <data key="d2">A collection of research papers and proceedings published in 2019, covering advancements in neural information processing.&lt;SEP&gt;A conference proceeding presenting advancements in neural information processing from 2019.&lt;SEP&gt;A conference proceeding presenting advances in neural information processing from 2019.&lt;SEP&gt;A proceedings volume published in 2019, containing multiple research papers on neural information processing, machine learning, and AI advancements.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics">
  <data key="d0">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</data>
  <data key="d1">Study Design</data>
  <data key="d2">Conference proceedings documenting NLP research presented in 2019.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Yinhan Liu">
  <data key="d0">Yinhan Liu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Yinhan Liu is a researcher involved in NLP pre-training and language models.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Naman Goyal">
  <data key="d0">Naman Goyal</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Naman Goyal is a researcher working on NLP models and training techniques.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Abdelrahman Mohamed">
  <data key="d0">Abdelrahman Mohamed</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Abdelrahman Mohamed is a researcher contributing to NLP model development.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Veselin Stoyanov">
  <data key="d0">Veselin Stoyanov</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Veselin Stoyanov is involved in NLP research, focusing on language understanding.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension">
  <data key="d0">BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A pre-training model for NLP tasks, introduced in 2019.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jiwei Li">
  <data key="d0">Jiwei Li</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Jiwei Li is a researcher working on neural conversation models and diversity objectives.&lt;SEP&gt;Jiwei Li is a researcher working on neural conversation models and promoting diversity in dialogue generation.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="A diversity-promoting objective function for neural conversation models">
  <data key="d0">A diversity-promoting objective function for neural conversation models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A research paper proposing an objective function to improve neural conversation diversity.&lt;SEP&gt;A research paper proposing an objective to promote diversity in neural dialogue models.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Margaret Li">
  <data key="d0">Margaret Li</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Margaret Li is a researcher working on dialogue evaluation and NLP metrics.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons">
  <data key="d0">Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A methodology for evaluating dialogue quality using optimized questions and multi-turn comparisons.&lt;SEP&gt;A methodology for evaluating dialogue quality using optimized questions.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Hairong Liu">
  <data key="d0">Hairong Liu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Hairong Liu is a researcher working on neural machine translation and embedding techniques.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Mingbo Ma">
  <data key="d0">Mingbo Ma</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Mingbo Ma is involved in NLP research, especially in translation and robust neural machine translation.&lt;SEP&gt;Mingbo Ma is involved in NLP research, particularly in translation.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Liang Huang">
  <data key="d0">Liang Huang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Liang Huang is a researcher working on NLP models and algorithms.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Hao Xiong">
  <data key="d0">Hao Xiong</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Hao Xiong is a researcher involved in NLP and translation systems.&lt;SEP&gt;Hao Xiong is a researcher involved in neural machine translation and NLP.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Zhongjun He">
  <data key="d0">Zhongjun He</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Zhongjun He is a researcher working on neural NLP models.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Robust neural machine translation with joint textual and phonetic embedding">
  <data key="d0">Robust neural machine translation with joint textual and phonetic embedding</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A research study on improving neural machine translation using joint embeddings.&lt;SEP&gt;A study on improving neural machine translation by combining textual and phonetic embeddings.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Peter J. Liu">
  <data key="d0">Peter J. Liu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Peter J. Liu is a researcher involved in sequence generation and NLP modeling.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Mohammad Saleh">
  <data key="d0">Mohammad Saleh</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Mohammad Saleh is a researcher working on NLP models and sequence generation.&lt;SEP&gt;Mohammad Saleh is a researcher working on sequence modeling and NLP.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Etienne Pot">
  <data key="d0">Etienne Pot</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Etienne Pot is involved in NLP research, especially in sequence modeling.&lt;SEP&gt;Etienne Pot is involved in NLP research, especially in sequence-to-sequence models.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Ben Goodrich">
  <data key="d0">Ben Goodrich</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ben Goodrich is a researcher working on NLP and machine learning.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Ryan Sepassi">
  <data key="d0">Ryan Sepassi</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ryan Sepassi is involved in NLP research, particularly in sequence generation.&lt;SEP&gt;Ryan Sepassi is involved in NLP research, particularly in sequence modeling.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Lukasz Kaiser">
  <data key="d0">Lukasz Kaiser</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.&lt;SEP&gt;Lukasz Kaiser is a researcher known for neural network architectures such as the Transformer.&lt;SEP&gt;Lukasz Kaiser is a researcher known for work on neural network architectures.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Noam Shazeer">
  <data key="d0">Noam Shazeer</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Noam Shazeer is a researcher contributing to studies on transfer learning and language models in machine learning.&lt;SEP&gt;Noam Shazeer is a researcher involved in NLP and deep learning.&lt;SEP&gt;Noam Shazeer is a researcher involved in NLP, deep learning, and neural network architectures.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Generating Wikipedia by summarizing long sequences">
  <data key="d0">Generating Wikipedia by summarizing long sequences</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A research paper on automatic Wikipedia content generation by summarization.&lt;SEP&gt;A research paper on automatic summarization for Wikipedia article generation.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Yury A. Malkov">
  <data key="d0">Yury A. Malkov</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Yury A. Malkov is a researcher working on algorithms for approximate nearest neighbor search.&lt;SEP&gt;Yury A. Malkov is a researcher working on approximate nearest neighbor search algorithms.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="D. A. Yashunin">
  <data key="d0">D. A. Yashunin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">D. A. Yashunin is a researcher involved in efficient graph-based search algorithms.&lt;SEP&gt;D. A. Yashunin is a researcher involved in efficient search algorithms and graph-based methods.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Efﬁcient and robust approximate nearest neighbor search using hierarchical navigable small world graphs">
  <data key="d0">Efﬁcient and robust approximate nearest neighbor search using hierarchical navigable small world graphs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A study on efficient algorithms for approximate nearest neighbor search using small world graphs.&lt;SEP&gt;A study on hierarchical small world graph algorithms for approximate nearest neighbor search.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="IEEE Transactions on Pattern Analysis and Machine Intelligence">
  <data key="d0">IEEE Transactions on Pattern Analysis and Machine Intelligence</data>
  <data key="d1">Discipline</data>
  <data key="d2">A scientific journal publishing research on pattern analysis and machine intelligence.&lt;SEP&gt;A scientific journal publishing research on pattern analysis, machine intelligence, and related algorithms.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Gary Marcus">
  <data key="d0">Gary Marcus</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Gary Marcus is a researcher discussing future steps towards robust artificial intelligence.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="The next decade in AI: four steps towards robust artificial intelligence">
  <data key="d0">The next decade in AI: four steps towards robust artificial intelligence</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A preprint discussing future directions for AI development.&lt;SEP&gt;A research paper outlining future directions for AI development.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Luca Massarelli">
  <data key="d0">Luca Massarelli</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Luca Massarelli is a researcher working on decoding strategies and text generation.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Fabrizio Silvestri">
  <data key="d0">Fabrizio Silvestri</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Fabrizio Silvestri is a researcher involved in NLP and information retrieval.&lt;SEP&gt;Fabrizio Silvestri is a researcher working on information retrieval and NLP.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Sebastian Riedel">
  <data key="d0">Sebastian Riedel</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Sebastian Riedel is a researcher working on NLP models and knowledge integration.&lt;SEP&gt;Sebastian Riedel is a researcher working on knowledge representation and NLP.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="arXiv preprint arXiv:1911.03587">
  <data key="d0">arXiv preprint arXiv:1911.03587</data>
  <data key="d1">Study Design</data>
  <data key="d2">A preprint discussing how decoding strategies influence text verifiability.&lt;SEP&gt;A preprint discussing how decoding strategies influence the verifiability of generated text.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Paulius Micikevicius">
  <data key="d0">Paulius Micikevicius</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Paulius Micikevicius is a researcher working on mixed precision training for neural networks.&lt;SEP&gt;Paulius Micikevicius is a researcher working on mixed precision training techniques.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Sharan Narang">
  <data key="d0">Sharan Narang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in pathway-based model scaling techniques.&lt;SEP&gt;Researcher involved in scalable language model research using pathway architectures.&lt;SEP&gt;Sharan Narang is a researcher contributing to the development of transfer learning techniques in NLP.&lt;SEP&gt;Sharan Narang is a researcher working on optimization techniques for deep learning.&lt;SEP&gt;Sharan Narang is involved in deep learning and training optimization.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jonah Alben">
  <data key="d0">Jonah Alben</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Jonah Alben is a researcher working on neural network training and hardware acceleration.&lt;SEP&gt;Jonah Alben is a researcher working on neural network training methods.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Gregory Diamos">
  <data key="d0">Gregory Diamos</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Gregory Diamos is a researcher working on neural network hardware and training optimization.&lt;SEP&gt;Gregory Diamos is involved in hardware-aware neural network training.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Erich Elsen">
  <data key="d0">Erich Elsen</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Erich Elsen is a researcher focused on neural network training and hardware.&lt;SEP&gt;Erich Elsen is a researcher working on neural network optimization.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="David Garcia">
  <data key="d0">David Garcia</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">David Garcia is involved in deep learning research.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Boris Ginsburg">
  <data key="d0">Boris Ginsburg</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Boris Ginsburg is a researcher working on neural network hardware acceleration.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Michael Houston">
  <data key="d0">Michael Houston</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Michael Houston is a researcher working on neural network training and hardware.&lt;SEP&gt;Michael Houston is involved in neural network training and hardware.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Oleksii Kuchaiev">
  <data key="d0">Oleksii Kuchaiev</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Oleksii Kuchaiev is a researcher involved in neural network architecture research.&lt;SEP&gt;Oleksii Kuchaiev is a researcher working on neural network architectures.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Ganesh Venkatesh">
  <data key="d0">Ganesh Venkatesh</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ganesh Venkatesh is a researcher working on neural network optimization.&lt;SEP&gt;Ganesh Venkatesh is an author contributing to research on mixed precision training in deep learning.&lt;SEP&gt;Ganesh Venkatesh is an author contributing to research on mixed precision training in machine learning.&lt;SEP&gt;Ganesh Venkatesh is involved in neural network research and optimization.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Hao Wu">
  <data key="d0">Hao Wu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Hao Wu is a researcher involved in neural network training and deep learning.&lt;SEP&gt;Hao Wu is a researcher working on deep learning and training methods.&lt;SEP&gt;Hao Wu is an author associated with research on mixed precision training in deep learning.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb&lt;SEP&gt;chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Towards exploiting background knowledge for building conversation systems">
  <data key="d0">Towards exploiting background knowledge for building conversation systems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A research paper exploring how background knowledge can enhance conversational AI systems.&lt;SEP&gt;A research paper exploring the use of background knowledge to improve conversational AI.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Transactions of the the Association of Computational Linguistics">
  <data key="d0">Transactions of the the Association of Computational Linguistics</data>
  <data key="d1">Discipline</data>
  <data key="d2">An academic journal publishing research in computational linguistics and NLP.</data>
  <data key="d3">chunk-33d74fdf1c7d92bf60e54b62b86377dd</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Kuchaiev">
  <data key="d0">Kuchaiev</data>
  <data key="d1">Researcher</data>
  <data key="d2">Kuchaiev is an author involved in research on mixed precision training, contributing to machine learning methodologies.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Mixed precision training">
  <data key="d0">Mixed precision training</data>
  <data key="d1">Methodology</data>
  <data key="d2">Mixed precision training is a machine learning technique that employs lower-precision calculations to accelerate training and reduce computational resources, often used in neural network training.&lt;SEP&gt;Mixed precision training is a technique in machine learning that uses lower-precision calculations to improve training efficiency and speed.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Nikita Moghe">
  <data key="d0">Nikita Moghe</data>
  <data key="d1">Researcher</data>
  <data key="d2">Nikita Moghe is involved in research on exploiting background knowledge for building conversation systems.&lt;SEP&gt;Nikita Moghe is involved in research on leveraging background knowledge to improve natural language processing (NLP) conversation systems.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Siddhartha Arora">
  <data key="d0">Siddhartha Arora</data>
  <data key="d1">Researcher</data>
  <data key="d2">Siddhartha Arora contributed to research on background knowledge in conversational AI.&lt;SEP&gt;Siddhartha Arora contributed to research on background knowledge utilization in NLP systems.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Suman Banerjee">
  <data key="d0">Suman Banerjee</data>
  <data key="d1">Researcher</data>
  <data key="d2">Suman Banerjee is associated with research on background knowledge integration for building better conversation systems.&lt;SEP&gt;Suman Banerjee is associated with research on enhancing conversation systems.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Mitesh M. Khapra">
  <data key="d0">Mitesh M. Khapra</data>
  <data key="d1">Researcher</data>
  <data key="d2">Mitesh M. Khapra is involved in NLP research, focusing on evaluation metrics, background knowledge, and system improvement.&lt;SEP&gt;Mitesh M. Khapra is involved in multiple studies on natural language processing and evaluation metrics.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Background knowledge">
  <data key="d0">Background knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Background knowledge refers to prior information used to enhance the performance of NLP systems, especially in conversation and question generation tasks.&lt;SEP&gt;Background knowledge refers to prior information used to improve the performance of conversation systems.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Evaluation metric for question generation">
  <data key="d0">Evaluation metric for question generation</data>
  <data key="d1">Methodology</data>
  <data key="d2">A metric designed to assess the quality of question generation systems in NLP tasks.&lt;SEP&gt;A specific metric designed to assess the quality and effectiveness of question generation systems in NLP.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="NLP evaluation">
  <data key="d0">NLP evaluation</data>
  <data key="d1">Study Design</data>
  <data key="d2">The process of assessing NLP systems using metrics and experimental setups to measure their performance.&lt;SEP&gt;The process of assessing NLP systems using specific metrics to measure performance.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Tri Nguyen">
  <data key="d0">Tri Nguyen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tri Nguyen contributed to creating MS MARCO, a dataset for machine reading comprehension.&lt;SEP&gt;Tri Nguyen contributed to creating MS MARCO, a large-scale dataset for machine reading comprehension and evaluation.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="MS MARCO">
  <data key="d0">MS MARCO</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">MS MARCO is a comprehensive dataset created for training and evaluating machine reading comprehension models, consisting of human-generated passages and questions.&lt;SEP&gt;MS MARCO is a large dataset created for training and evaluating machine reading comprehension models.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Human generated dataset">
  <data key="d0">Human generated dataset</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">MS MARCO is a dataset built from human annotations to serve as a benchmark for NLP systems.&lt;SEP&gt;MS MARCO is a dataset generated by human annotators to facilitate machine comprehension research.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Xia Song">
  <data key="d0">Xia Song</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xia Song is involved in work on passage re-ranking using BERT models.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="BERT">
  <data key="d0">BERT</data>
  <data key="d1">Tools</data>
  <data key="d2">A deep learning model pre-trained on large corpora for various NLP tasks, utilizing bidirectional transformer architecture.&lt;SEP&gt;BERT is a transformer-based language model used for passage re-ranking and other NLP tasks.&lt;SEP&gt;BERT is a transformer-based language model used for various NLP tasks, including passage re-ranking, question answering, and more.&lt;SEP&gt;A pre-trained transformer model that achieves state-of-the-art results on various NLP tasks, foundational for modern language understanding.&lt;SEP&gt;A transformer-based language model pre-trained on large corpora, widely used for natural language understanding tasks.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71&lt;SEP&gt;chunk-d82fbac5a45159b990b5c96afdf81c21&lt;SEP&gt;chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Passage re-ranking">
  <data key="d0">Passage re-ranking</data>
  <data key="d1">Methodology</data>
  <data key="d2">Passage re-ranking involves reordering retrieved passages to improve information retrieval effectiveness using models like BERT.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Rodrigo Nogueira">
  <data key="d0">Rodrigo Nogueira</data>
  <data key="d1">Researcher</data>
  <data key="d2">Rodrigo Nogueira contributed to research on passage re-ranking techniques with BERT, improving retrieval accuracy.&lt;SEP&gt;Rodrigo Nogueira contributed to research on passage re-ranking with BERT.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="fairseq">
  <data key="d0">fairseq</data>
  <data key="d1">Tools</data>
  <data key="d2">fairseq is an extensible toolkit for sequence modeling, supporting various NLP tasks including translation and language modeling.&lt;SEP&gt;fairseq is an open-source sequence modeling toolkit supporting tasks like translation, language modeling, and re-ranking, used in research for flexible experimentation.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Sequence modeling">
  <data key="d0">Sequence modeling</data>
  <data key="d1">Methodology</data>
  <data key="d2">Sequence modeling encompasses methods for processing sequential data in NLP, such as language models, translation systems, and re-ranking models.&lt;SEP&gt;Sequence modeling encompasses techniques for processing sequential data in NLP, such as language modeling and translation.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Convince Q&amp;A models">
  <data key="d0">Convince Q&amp;A models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Convince Q&amp;A models are designed to generate convincing, accurate answers in question-answering tasks, often evaluated for reliability and persuasiveness.&lt;SEP&gt;Convince Q&amp;A models are systems designed to generate convincing answers in question-answering tasks.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Yusuf Wu">
  <data key="d0">Yusuf Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuxiang Wu is involved in research on language models as knowledge bases.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Language models as knowledge bases">
  <data key="d0">Language models as knowledge bases</data>
  <data key="d1">Theoretical Concept</data>
  <data key="d2">This concept explores the potential of language models to serve as repositories of factual knowledge.&lt;SEP&gt;This concept explores the potential of large language models to serve as implicit knowledge repositories, capable of storing and retrieving factual information.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge base">
  <data key="d0">Knowledge base</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Knowledge bases are structured repositories of factual information, with research investigating whether language models can function as such.&lt;SEP&gt;Knowledge bases store structured factual information, and language models are being investigated as an alternative.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Fabio Petroni">
  <data key="d0">Fabio Petroni</data>
  <data key="d1">Researcher</data>
  <data key="d2">Fabio Petroni researches how context influences language models’ factual predictions.&lt;SEP&gt;Fabio Petroni researches how context influences the factual accuracy of language models' predictions.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Context in language models">
  <data key="d0">Context in language models</data>
  <data key="d1">Variables</data>
  <data key="d2">Context refers to surrounding text or information that affects the factual predictions of language models.&lt;SEP&gt;Context refers to surrounding textual information that affects the factual predictions and knowledge retrieval capabilities of language models.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Yuxiang Wu">
  <data key="d0">Yuxiang Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuxiang Wu is involved in research on language models and their factual capabilities.&lt;SEP&gt;Yuxiang Wu researches the role of context in language models' factual predictions and knowledge retrieval.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Alexander Miller">
  <data key="d0">Alexander Miller</data>
  <data key="d1">Researcher</data>
  <data key="d2">Alexander Miller contributes to research on language models and knowledge bases.&lt;SEP&gt;Alexander Miller is involved in research on language models, knowledge bases, and their applications in NLP.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Automated Knowledge Base Construction">
  <data key="d0">Automated Knowledge Base Construction</data>
  <data key="d1">Study Design</data>
  <data key="d2">This involves building knowledge bases automatically using language models and other NLP techniques.&lt;SEP&gt;This involves using NLP models and techniques to automatically build or enhance knowledge bases from unstructured data.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Radford et al. ">
  <data key="d0">Radford et al. </data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Radford et al. are authors of foundational papers on language understanding and generative pre-training.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generative Pre-Training">
  <data key="d0">Generative Pre-Training</data>
  <data key="d1">Methodology</data>
  <data key="d2">A training approach where language models are pre-trained on large corpora to improve language understanding and generation.&lt;SEP&gt;Generative Pre-Training refers to pre-training language models on large corpora using unsupervised learning to improve their understanding and generation capabilities.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Language understanding">
  <data key="d0">Language understanding</data>
  <data key="d1">Core Concept</data>
  <data key="d2">The ability of models to comprehend and process natural language effectively.&lt;SEP&gt;The ability of models to comprehend, interpret, and generate human language effectively, foundational to NLP.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Unsupervised learning">
  <data key="d0">Unsupervised learning</data>
  <data key="d1">Methodology</data>
  <data key="d2">Training models without labeled data, as used in pre-training language models.&lt;SEP&gt;Training models without labeled data, enabling large-scale pre-training of language models.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Language models as multitask learners">
  <data key="d0">Language models as multitask learners</data>
  <data key="d1">Theoretical Model</data>
  <data key="d2">Language models that are capable of performing multiple NLP tasks after training.&lt;SEP&gt;Language models trained with pre-training can perform multiple NLP tasks with minimal task-specific data, demonstrating versatility.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Raffel et al.&quot;|">
  <data key="d0">Raffel et al."|</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Raffel et al. contributed significantly to research on advanced language models, pre-training techniques, and their applications.&lt;SEP&gt;Raffel et al. contributed to research on advanced language models and their capabilities.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Question generation systems">
  <data key="d0">Question generation systems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Question generation systems are NLP systems designed to automatically generate questions, evaluated using specialized metrics.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Radford et al.">
  <data key="d0">Radford et al.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Radford et al. are authors of foundational papers on language understanding, unsupervised pre-training, and generative models.</data>
  <data key="d3">chunk-4abd23114af78f5d3ff5bf7b1056dbdb</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Unsupervised Multitask Learners">
  <data key="d0">Unsupervised Multitask Learners</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A paradigm where language models are trained without explicit labels, enabling them to perform multiple language tasks simultaneously by learning from large unlabeled datasets.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Transfer Learning">
  <data key="d0">Transfer Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A broader concept where knowledge gained in one task or domain is applied to improve learning in another, closely related to prompt transfer.&lt;SEP&gt;A machine learning technique where knowledge gained from training on one task is transferred to improve performance on a different but related task, often used to enhance language model capabilities.&lt;SEP&gt;The process of applying knowledge gained from one domain or task to improve performance in another, often facilitated by prompt tuning or fine-tuning.&lt;SEP&gt;A technique where pre-trained language models are adapted to specific HPC tasks with limited additional data to improve performance.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-6f045498b0e63780c3aef4b9daf795b6&lt;SEP&gt;chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Text-to-Text Transformer">
  <data key="d0">Text-to-Text Transformer</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A neural network architecture that converts various NLP tasks into a text-to-text format, facilitating unified training and transfer learning across multiple language tasks.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Parameters">
  <data key="d0">Model Parameters</data>
  <data key="d1">Variables</data>
  <data key="d2">The adjustable components within a neural network that store learned knowledge; their size influences the model's capacity to encode information.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Knowledge Packing">
  <data key="d0">Knowledge Packing</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates the extent to which language models can encode and utilize vast amounts of information within their parameters to perform various NLP tasks effectively.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Relevance Framework">
  <data key="d0">Relevance Framework</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A probabilistic approach to information retrieval that models the relevance of documents to queries, exemplified by models like BM25.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Memory Networks">
  <data key="d0">Memory Networks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Neural network architectures designed to incorporate explicit memory components, enabling models to reason over and utilize stored information for tasks like question answering.&lt;SEP&gt;Neural networks that incorporate explicit memory components to enhance reasoning abilities.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Fact Extraction and Verification Dataset (FEVER)">
  <data key="d0">Fact Extraction and Verification Dataset (FEVER)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A large-scale dataset created to evaluate systems' ability to extract factual information and verify claims, supporting research in fact-checking and knowledge retrieval.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Catastrophic Forgetting">
  <data key="d0">Catastrophic Forgetting</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A challenge in neural networks where learning new information causes the model to forget previously acquired knowledge, impacting continual learning and model stability.&lt;SEP&gt;A phenomenon where a model forgets previously learned information when trained on new data, limiting continual learning.&lt;SEP&gt;Catastrophic forgetting describes the tendency of models to lose previously acquired knowledge when fine-tuned on new tasks or data, posing a challenge for continual learning.&lt;SEP&gt;Catastrophic forgetting refers to the challenge where models forget previous knowledge when adapting to new tasks, limiting adaptability.&lt;SEP&gt;A phenomenon where a model loses previously learned information during fine-tuning, which can negatively impact downstream task performance.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-19e79205b492f438828e7baefec8588e&lt;SEP&gt;chunk-ce8332c6d0b3d23f38189ff80650d4bc&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Elastic Weight Consolidation (EWC)">
  <data key="d0">Elastic Weight Consolidation (EWC)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to mitigate catastrophic forgetting by selectively constraining important weights during training on new tasks, preserving prior knowledge.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Attention Mechanism">
  <data key="d0">Attention Mechanism</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A neural network component that allows models to focus on relevant parts of the input sequence, significantly improving performance in tasks like translation and summarization.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Multi-Task Benchmark (GLUE)">
  <data key="d0">Multi-Task Benchmark (GLUE)</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A collection of diverse NLP tasks used to evaluate and compare the performance of language understanding models across multiple tasks.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="SuperGLUE">
  <data key="d0">SuperGLUE</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">An advanced benchmark built upon GLUE, designed to test and push the limits of general-purpose language understanding systems.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Diverse Beam Search">
  <data key="d0">Diverse Beam Search</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">A decoding strategy that generates multiple diverse candidate outputs in sequence-to-sequence models, improving the quality and variety of generated descriptions or translations.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Neural Network Architectures">
  <data key="d0">Neural Network Architectures</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The field of deep learning within artificial intelligence focused on designing and training neural models for complex pattern recognition and data processing.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Natural Language Understanding">
  <data key="d0">Natural Language Understanding</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A subfield of AI and NLP that focuses on enabling machines to comprehend, interpret, and generate human language meaningfully.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Model Biases">
  <data key="d0">Model Biases</data>
  <data key="d1">Results</data>
  <data key="d2">Refers to systematic errors or unfair tendencies in language models that can lead to skewed or incorrect outputs, often mitigated through techniques like elastic weight consolidation.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Social Impacts of Language Models">
  <data key="d0">Social Impacts of Language Models</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Explores how deploying large language models affects society, including issues related to misinformation, bias, and accessibility.</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Alché-Buc, E. Fox, and R. Garnett">
  <data key="d0">Alché-Buc, E. Fox, and R. Garnett</data>
  <data key="d1">Research Team</data>
  <data key="d2">Editors of the publication 'Advances in Neural Information Processing Systems 32', contributing to the dissemination of research in neural information processing.&lt;SEP&gt;Editors of the publication 'Advances in Neural Information Processing Systems 32', responsible for compiling and editing the collection of research papers in neural information processing.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, Jing Jiang">
  <data key="d0">Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, Jing Jiang</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers contributing to multiple studies on question answering and evidence aggregation in artificial intelligence.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="R3: Reinforced ranker-reader for open-domain question answering">
  <data key="d0">R3: Reinforced ranker-reader for open-domain question answering</data>
  <data key="d1">Methodology</data>
  <data key="d2">A method involving reinforcement learning to improve question answering systems by ranking and reading relevant evidence.&lt;SEP&gt;A reinforcement learning-based approach designed to improve answer retrieval and ranking in open-domain question answering systems.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Evidence aggregation for answer re-ranking in open-domain question answering">
  <data key="d0">Evidence aggregation for answer re-ranking in open-domain question answering</data>
  <data key="d1">Methodology</data>
  <data key="d2">Techniques for combining multiple pieces of evidence to improve answer accuracy in open-domain QA systems.&lt;SEP&gt;Techniques involving combining multiple evidence sources to enhance answer accuracy in open-domain QA systems.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Memory networks">
  <data key="d0">Memory networks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A neural network architecture designed to store and retrieve information over multiple steps, enhancing reasoning capabilities.&lt;SEP&gt;A neural network architecture that stores and retrieves information to facilitate reasoning and question answering.&lt;SEP&gt;Memory networks incorporate external memory components to improve reasoning and learning in neural models.&lt;SEP&gt;Memory networks incorporate external memory modules to improve reasoning and algorithm learning in neural models."|&lt;SEP&gt;Neural networks with explicit memory components to enhance reasoning and question-answering capabilities.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446&lt;SEP&gt;chunk-a17c97bd5849d0ccac2f6a28eab01a8e&lt;SEP&gt;chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Retrieve and refine: Improved sequence generation models for dialogue">
  <data key="d0">Retrieve and refine: Improved sequence generation models for dialogue</data>
  <data key="d1">Methodology</data>
  <data key="d2">An approach to enhance dialogue systems by retrieving relevant information and refining responses.&lt;SEP&gt;Models that retrieve relevant information and refine responses to improve conversational AI performance.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Huggingface’s transformers">
  <data key="d0">Huggingface’s transformers</data>
  <data key="d1">Tools</data>
  <data key="d2">A library of state-of-the-art NLP models used for various language understanding and generation tasks.&lt;SEP&gt;A library providing state-of-the-art NLP models for various natural language processing tasks.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Addressing semantic drift in question generation for semi-supervised question answering">
  <data key="d0">Addressing semantic drift in question generation for semi-supervised question answering</data>
  <data key="d1">Research Study</data>
  <data key="d2">A study exploring methods to reduce semantic drift in generated questions to improve semi-supervised question answering performance.&lt;SEP&gt;A study focusing on reducing semantic drift in generated questions to improve semi-supervised question answering performance.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Reasoning over semantic-level graph for fact checking">
  <data key="d0">Reasoning over semantic-level graph for fact checking</data>
  <data key="d1">Methodology</data>
  <data key="d2">A reasoning approach that employs semantic graphs to verify the factual accuracy of information.&lt;SEP&gt;A reasoning approach utilizing semantic graphs to verify factual information.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Shuohang Wang">
  <data key="d0">Shuohang Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher involved in developing question answering models and evidence aggregation techniques in AI.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Mo Yu">
  <data key="d0">Mo Yu</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher contributing to studies on open-domain question answering and reinforcement learning methods.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Xiaoxiao Guo">
  <data key="d0">Xiaoxiao Guo</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher working on evidence aggregation and question answering systems in NLP.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Zhiguo Wang">
  <data key="d0">Zhiguo Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher focusing on question answering and NLP model development.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Tim Klinger">
  <data key="d0">Tim Klinger</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher involved in AI research related to question answering and evidence retrieval.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Shiyu Chang">
  <data key="d0">Shiyu Chang</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher contributing to evidence aggregation and NLP model improvements in question answering.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Gerry Tesauro">
  <data key="d0">Gerry Tesauro</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher working on reinforcement learning and AI systems for question answering.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Bowen Zhou">
  <data key="d0">Bowen Zhou</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher involved in developing AI models for open-domain QA.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Jing Jiang">
  <data key="d0">Jing Jiang</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher focusing on evidence aggregation and question answering techniques.</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="DPR">
  <data key="d0">DPR</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-20aafa58f3d7697ab6ba5015b31cda9b&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d2">DPR provides the non-parametric memory by retrieving relevant documents that inform the generator in RAG models.&lt;SEP&gt;DPR provides the non-parametric memory component by retrieving relevant documents for RAG models.&lt;SEP&gt;DPR provides the retrieval component for RAG models, using supervised signals to initialize effective retrieval in open-domain QA.&lt;SEP&gt;DPR provides the retrieval component for RAG, trained with supervised signals from datasets like Natural Questions and TriviaQA.&lt;SEP&gt;DPR serves as the retrieval component within the RAG framework, providing relevant documents for the generator to use.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG">
  <data key="d0">RAG</data>
  <data key="d3">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-20aafa58f3d7697ab6ba5015b31cda9b&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d2">DPR provides the non-parametric memory by retrieving relevant documents that inform the generator in RAG models.&lt;SEP&gt;DPR provides the non-parametric memory component by retrieving relevant documents for RAG models.&lt;SEP&gt;DPR provides the retrieval component for RAG models, using supervised signals to initialize effective retrieval in open-domain QA.&lt;SEP&gt;DPR provides the retrieval component for RAG, trained with supervised signals from datasets like Natural Questions and TriviaQA.&lt;SEP&gt;DPR serves as the retrieval component within the RAG framework, providing relevant documents for the generator to use.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG-Sequence Model">
  <data key="d0">RAG-Sequence Model</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d2">Uses the same retrieved document for entire sequence generation, marginalizing over the top K documents.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Top-K Documents">
  <data key="d0">Top-K Documents</data>
  <data key="d3">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d2">Uses the same retrieved document for entire sequence generation, marginalizing over the top K documents.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Decoding Strategies">
  <data key="d0">Decoding Strategies</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d2">Different decoding approaches are used to approximate the maximum likelihood of output sequences, balancing accuracy and efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="RAG-Token and RAG-Sequence">
  <data key="d0">RAG-Token and RAG-Sequence</data>
  <data key="d3">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d2">Different decoding approaches are used to approximate the maximum likelihood of output sequences, balancing accuracy and efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Fact Verification">
  <data key="d0">Fact Verification</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d2">RAG-Token achieves competitive accuracy on FEVER, demonstrating its effectiveness in fact verification tasks without extensive domain-specific engineering.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generation Process">
  <data key="d0">Generation Process</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d2">The document posterior influences which document the model relies on during generation, affecting the factual accuracy and relevance of outputs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Title Completion">
  <data key="d0">Title Completion</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d2">Parametric knowledge stored in BART's parameters allows it to complete titles without external documents, indicating internalized information.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Generation Guidance">
  <data key="d0">Generation Guidance</data>
  <data key="d3">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d2">External retrieval guides generation by providing relevant documents, improving factual accuracy and specificity.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Claim Classification">
  <data key="d0">Claim Classification</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d2">RoBERTa is employed to classify claims as true or false based on evidence sentences.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Evidence Retrieval and Generation">
  <data key="d0">Evidence Retrieval and Generation</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d2">RAG integrates document retrieval with generative models to improve factual accuracy in tasks like question answering.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Claim Verification">
  <data key="d0">Claim Verification</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d2">Gold evidence sentences serve as the ground truth for verifying the correctness of claims.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Study Dataset">
  <data key="d0">Study Dataset</data>
  <data key="d3">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d2">FEVER provides a benchmark dataset for fact extraction and verification, used to evaluate model performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Coarse-to-fine question answering for long documents">
  <data key="d0">Coarse-to-fine question answering for long documents</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Eunsol Choi authored the study on question answering for long documents.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Simple and Effective Multi-Paragraph Reading Comprehension">
  <data key="d0">Simple and Effective Multi-Paragraph Reading Comprehension</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Christopher Clark authored the paper on multi-paragraph reading comprehension.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding">
  <data key="d0">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Jacob Devlin authored or co-authored the BERT paper, a foundational NLP model.&lt;SEP&gt;Jacob Devlin authored the BERT paper, a foundational NLP model.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wizard of Wikipedia: Knowledge-powered conversational agents">
  <data key="d0">Wizard of Wikipedia: Knowledge-powered conversational agents</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Emily Dinan contributed to research on knowledge-powered conversational agents.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Matthew Dunn">
  <data key="d0">Matthew Dunn</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Matthew Dunn authored or contributed to the SearchQA dataset study.&lt;SEP&gt;Matthew Dunn authored or contributed to the dataset study.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="SearchQA: A New Q&amp;A Dataset Augmented with Context from a Search Engine">
  <data key="d0">SearchQA: A New Q&amp;A Dataset Augmented with Context from a Search Engine</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Matthew Dunn authored or contributed to the SearchQA dataset study.&lt;SEP&gt;Matthew Dunn authored or contributed to the dataset study.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Hierarchical neural story generation">
  <data key="d0">Hierarchical neural story generation</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Angela Fan authored the work on hierarchical story generation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="ELI5: Long form question answering">
  <data key="d0">ELI5: Long form question answering</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Angela Fan contributed to research on long-form question answering.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="A knowledge-grounded neural conversation model">
  <data key="d0">A knowledge-grounded neural conversation model</data>
  <data key="d3">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d2">Marjan Ghazvininejad contributed to neural conversation models grounded in knowledge.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="REALM">
  <data key="d0">REALM</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d2">Kelvin Guu contributed to the development of the retrieval-augmented language model framework, integrating retrieval into pretraining.&lt;SEP&gt;Kelvin Guu contributed to the development of the retrieval-augmented language model framework.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Tatsunori Hashimoto">
  <data key="d0">Tatsunori Hashimoto</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d2">Hashimoto contributed to structured output prediction frameworks involving retrieve-and-edit techniques.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Similarity Search with GPUs">
  <data key="d0">Similarity Search with GPUs</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d2">Johnson worked on scalable similarity search methods utilizing GPU acceleration for efficient retrieval systems.&lt;SEP&gt;Johnson worked on scalable similarity search methods utilizing GPU acceleration.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Retrieval Models">
  <data key="d0">Retrieval Models</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d2">Kenton Lee contributed to retrieval models and language understanding in NLP systems.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Structured Prediction">
  <data key="d0">Structured Prediction</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d2">Pasupat is involved in structured prediction tasks that utilize retrieval and language understanding.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Dense Passage Retrieval">
  <data key="d0">Dense Passage Retrieval</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d2">Levy contributed to the development of dense retrieval methods for NLP, especially for question answering.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Language Understanding">
  <data key="d0">Language Understanding</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d2">Jurafsky's work encompasses language understanding, models, and applications in NLP.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Language Modeling and Retrieval">
  <data key="d0">Language Modeling and Retrieval</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d2">Zettlemoyer contributed to language modeling, retrieval, and structured prediction frameworks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Language Models and Retrieval">
  <data key="d0">Language Models and Retrieval</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d2">Lewis worked on integrating retrieval into language models and improving generalization in NLP.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Adam Optimization">
  <data key="d0">Adam Optimization</data>
  <data key="d3">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d2">Kingma developed the Adam optimizer, a widely used method for training neural networks efficiently.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Elastic Weight Consolidation">
  <data key="d0">Elastic Weight Consolidation</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d2">EWC is used to mitigate biases and prevent catastrophic forgetting, thereby improving model fairness and stability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Natural Language Generation">
  <data key="d0">Natural Language Generation</data>
  <data key="d3">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d2">Diverse beam search improves the quality of generated language by promoting output variety in sequence models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Research Team">
  <data key="d0">Research Team</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d2">The publication is edited by the research team, disseminating advancements in neural information processing.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Theoretical Model">
  <data key="d0">Theoretical Model</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d2">Memory networks are used as a model architecture to enhance reasoning and information retrieval in NLP tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Research Study">
  <data key="d0">Research Study</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d2">This study aims to reduce semantic drift in question generation to improve semi-supervised QA.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Question answering">
  <data key="d0">Question answering</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d2">Zhiguo Wang contributes to developing NLP models for question answering systems.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Wei Zhang">
  <data key="d0">Wei Zhang</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d2">Wei Zhang develops AI models for open-domain question answering systems.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Evidence aggregation">
  <data key="d0">Evidence aggregation</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d2">Shiyu Chang's research involves improving evidence aggregation techniques to enhance answer accuracy.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Reinforcement learning">
  <data key="d0">Reinforcement learning</data>
  <data key="d3">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d2">Gerry Tesauro's work focuses on reinforcement learning approaches for AI systems.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</node>
<node id="Benchmark ParEval">
  <data key="d0">Benchmark ParEval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A benchmark created to evaluate the effectiveness of language models in generating parallel code, consisting of prompts representing 420 coding tasks related to scientific and parallel computing.&lt;SEP&gt;A comprehensive benchmark developed to evaluate the ability of language models to generate correct and efficient parallel code across 420 diverse scientific and parallel computing tasks.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Metrics for Code Evaluation">
  <data key="d0">Metrics for Code Evaluation</data>
  <data key="d1">Tools</data>
  <data key="d2">Novel metrics introduced to assess the performance of generated code, including correctness and efficiency, across various computational problem types and parallel programming models.&lt;SEP&gt;Novel metrics introduced to quantitatively assess the performance of generated code, including correctness, efficiency, and problem-specific success measures, across different computational problem types and parallel models.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="State-of-the-art Language Models">
  <data key="d0">State-of-the-art Language Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Advanced language models, both open- and closed-source, used to generate code and evaluated in this study for their ability to produce parallel code.&lt;SEP&gt;Leading language models, both open-source and closed-source, evaluated for their capacity to generate parallel code, including models like StarCoder and others.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Programming Models">
  <data key="d0">Parallel Programming Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Different computational frameworks such as MPI, OpenMP, CUDA, and others that define how parallel code is structured and executed.&lt;SEP&gt;Frameworks such as MPI, OpenMP, CUDA, and others that define how parallel algorithms are structured, implemented, and executed in code.&lt;SEP&gt;Models like MPI, OpenMP, CUDA, HIP, and Kokkos define how parallelism is structured in code, affecting the ease with which LLMs can generate correct implementations.&lt;SEP&gt;Frameworks enabling concurrent computation in HPC, targeted by the generated kernels.&lt;SEP&gt;Models like OpenMP are used as prompts to evaluate Copilot's code suggestions across different languages.&lt;SEP&gt;Parallel programming models are frameworks that enable concurrent computation in languages like C++, Fortran, Python, and Julia, used in HPC.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3&lt;SEP&gt;chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-04aecdc2586d2c7966e70e02cac846b0&lt;SEP&gt;chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Scientific and Parallel Computing Tasks">
  <data key="d0">Scientific and Parallel Computing Tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A diverse set of 420 coding tasks related to scientific and parallel computing, used to evaluate language models.&lt;SEP&gt;A set of 420 coding tasks representing various scientific and parallel computing problems used to assess model performance.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Reproducible Methodology">
  <data key="d0">Reproducible Methodology</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A systematic approach to evaluate language models' capabilities in parallel code generation, including benchmark design, novel metrics, and analysis procedures.&lt;SEP&gt;A systematic, transparent approach to evaluate language models' capabilities, including benchmark design, metrics, and analysis procedures to ensure reproducibility.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Performance">
  <data key="d0">Code Performance</data>
  <data key="d1">Results</data>
  <data key="d2">Evaluation of the efficiency and execution quality of generated parallel code, including metrics like runtime and scalability.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Complexity of Tasks">
  <data key="d0">Complexity of Tasks</data>
  <data key="d1">Variables</data>
  <data key="d2">The degree of difficulty of the coding tasks, ranging from simple to highly complex scientific and parallel computing problems.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Model Capabilities">
  <data key="d0">Model Capabilities</data>
  <data key="d1">Variables</data>
  <data key="d2">Model capabilities refer to the technical abilities of models like Codex, which influence their potential for misalignment, bias, and safety risks.&lt;SEP&gt;The ability of language models to generate accurate, efficient, and complex parallel code, measured through evaluation.&lt;SEP&gt;The extent of what Codex can do, including code generation, vulnerability detection, and potential for malicious use, with limitations noted.&lt;SEP&gt;While capable of code generation, Codex's effectiveness in offensive cybersecurity is limited, but its potential to suggest insecure code or dependencies raises concerns.</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00&lt;SEP&gt;chunk-eec372249525c58f53cd0e9c24744ffb&lt;SEP&gt;chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="benchmarks">
  <data key="d0">benchmarks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Benchmarks are standardized sets of problems and tests designed to evaluate the capabilities of LLMs in generating parallel code, covering various models, algorithms, and problem types.&lt;SEP&gt;Standardized computational tasks used to evaluate the performance of different implementations or systems.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c&lt;SEP&gt;chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="metrics">
  <data key="d0">metrics</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Metrics are quantitative measures used to assess the correctness, performance, and scalability of generated parallel code, including novel metrics like speedup n@k and efficiency n@k.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="shared-memory programming models">
  <data key="d0">shared-memory programming models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Shared-memory programming models are approaches where multiple processors access a common memory space, such as OpenMP, used in evaluating parallel code generation.&lt;SEP&gt;Shared-memory programming models are approaches where multiple processors access a common memory space, such as OpenMP, used in evaluating parallel code.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="distributed-memory programming models">
  <data key="d0">distributed-memory programming models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Distributed-memory programming models involve multiple processors with separate memory, like MPI, and are key in benchmarking parallel code.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="computational problem types">
  <data key="d0">computational problem types</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Different types of computational problems (e.g., sparse, unstructured) are used to evaluate LLM performance in generating suitable parallel code.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="state-of-the-art LLMs">
  <data key="d0">state-of-the-art LLMs</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">State-of-the-art large language models (e.g., GPT-3.5) are advanced models evaluated for their ability to generate correct, performant, and scalable parallel code.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="research questions">
  <data key="d0">research questions</data>
  <data key="d1">Research Questions</data>
  <data key="d2">The study investigates how well current LLMs generate parallel code, which models and problem types are most challenging, and how scalable and translatable the generated code is.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="code translation">
  <data key="d0">code translation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Code translation involves converting code from one parallel execution model to another, which can improve correctness and performance.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model translation">
  <data key="d0">model translation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Model translation refers to converting code between different parallel execution models, such as from serial to MPI or OpenMP.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model improvement areas">
  <data key="d0">model improvement areas</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Identified areas where LLMs can improve their capabilities in parallel code generation and translation, guiding future development.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="evaluation metrics">
  <data key="d0">evaluation metrics</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics designed to score the quality of AI-generated code outputs, including correctness, efficiency, and relevance, used to benchmark performance.&lt;SEP&gt;Variables such as correctness, speedup, efficiency, and scalability are used to evaluate LLM outputs.&lt;SEP&gt;Quantitative measures such as pass@k and BLEU score used to assess the performance and correctness of generated code.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-f37ccebb4e61f6d64cd2096830d27b04&lt;SEP&gt;chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="parallel algorithms">
  <data key="d0">parallel algorithms</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Different parallel algorithms are used in benchmarks to test LLMs' ability to generate diverse types of parallel code.</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Token in a sequence">
  <data key="d0">Token in a sequence</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A basic unit of text data processed in language models, representing individual elements within a sequence, such as words or subword units.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Transformer-based models">
  <data key="d0">Transformer-based models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Deep learning models that utilize attention mechanisms to process sequential data, highly effective for modeling text data in NLP tasks.&lt;SEP&gt;Deep learning models utilizing attention mechanisms to process sequential data, highly effective for modeling text data in NLP tasks.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Large Language Models for Code">
  <data key="d0">Large Language Models for Code</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Language models trained on large corpora of code and natural language, designed to generate, understand, and manipulate code across various programming languages.&lt;SEP&gt;Language models trained on large corpora of code and natural language, used for code generation, understanding, and related tasks.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Pre-training corpus">
  <data key="d0">Pre-training corpus</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Large datasets like The Stack and The Pile used to initially train code LLMs, covering diverse programming languages and applications.&lt;SEP&gt;Large datasets of text or code used to initially train language models, such as The Stack or The Pile, covering diverse programming languages and application types.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Token selection strategy">
  <data key="d0">Token selection strategy</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques used during text generation to select the next token, including nucleus sampling and model temperature adjustments, to improve output quality.&lt;SEP&gt;Techniques used during text generation to select the next token, including nucleus sampling and temperature adjustments, to enhance output quality.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Nucleus Sampling">
  <data key="d0">Nucleus Sampling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A sampling technique used to generate diverse outputs by truncating the CDF at a cutoff value, here 0.93.&lt;SEP&gt;A token sampling method that chooses the next token from the top probability mass p, ensuring more representative and diverse outputs.&lt;SEP&gt;A token sampling technique that selects the next token from a probability distribution up to a certain cumulative probability p, promoting more representative sampling.&lt;SEP&gt;Nucleus, or top-p, sampling chooses from the smallest set of tokens whose cumulative probability exceeds p, aiming for more meaningful sampling.&lt;SEP&gt;Nucleus, or top-p, sampling chooses tokens based on a cumulative probability threshold p, aiming for more meaningful cut-offs in the distribution.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Model Temperature">
  <data key="d0">Model Temperature</data>
  <data key="d1">Variables</data>
  <data key="d2">A parameter that scales the logits before softmax, controlling the randomness and creativity of generated outputs; lower values produce more conservative results, higher values more diverse outputs.&lt;SEP&gt;A scaling parameter applied to model logits before softmax to control randomness in generated outputs; lower values produce more conservative outputs, higher values more diverse.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Generation Tasks">
  <data key="d0">Code Generation Tasks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Benchmark tasks designed to evaluate the ability of language models to generate correct code snippets, including datasets like HumanEval, MBPP, DS-1000, GSM8K, and CoderEval.&lt;SEP&gt;Benchmark tasks designed to evaluate the ability of language models to generate correct code snippets, such as HumanEval, MBPP, DS-1000, GSM8K, and CoderEval.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Benchmarking LLMs for Code">
  <data key="d0">Benchmarking LLMs for Code</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Evaluation frameworks and datasets used to assess the performance of language models on code-related tasks across multiple programming languages and complexity levels.&lt;SEP&gt;Frameworks and datasets used to evaluate and compare the performance of language models on code-related tasks across multiple benchmarks and programming languages.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Evaluation datasets">
  <data key="d0">Evaluation datasets</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Standardized problem sets such as HumanEval, MBPP, DS-1000, GSM8K, and CoderEval, used to assess code generation accuracy and quality.&lt;SEP&gt;Standardized sets of programming problems, such as HumanEval, MBPP, DS-1000, used to measure the effectiveness of code-generating language models.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="MultiPL-E">
  <data key="d0">MultiPL-E</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark extending code evaluation to 18 programming languages, assessing multilingual capabilities of LLMs.&lt;SEP&gt;A benchmarking framework for evaluating neural code generation across multiple programming languages and tasks.&lt;SEP&gt;A scalable and polyglot benchmark for evaluating neural code generation models across multiple programming languages.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Applying LLMs to Parallel and HPC Code">
  <data key="d0">Applying LLMs to Parallel and HPC Code</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The application of language models to generate, analyze, and optimize parallel and high-performance computing (HPC) code, including developing specialized models and tokenizers.&lt;SEP&gt;The application of language models to generate, analyze, or optimize parallel and high-performance computing code, including creating specialized models and tokenizers.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HPC tokenizer">
  <data key="d0">HPC tokenizer</data>
  <data key="d1">Tools</data>
  <data key="d2">Specialized tokenizer like TOKOMPILER designed for HPC code to improve model training and code understanding in high-performance computing contexts.&lt;SEP&gt;Specialized tokenizers like TOKOMPILER designed for HPC code to improve model understanding and processing of HPC-specific syntax and structures.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Multilingual benchmarks">
  <data key="d0">Multilingual benchmarks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Extensions like MultiPL-E that evaluate LLM performance across 18 programming languages, testing multilingual code generation capabilities.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel code">
  <data key="d0">Parallel code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code written to execute computations across multiple processors or cores, often requiring specialized handling and generation by models.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenMP pragmas">
  <data key="d0">OpenMP pragmas</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Annotations in code that specify parallel execution directives, which models like HPCCoder aim to label or generate.&lt;SEP&gt;OpenMP pragmas are compiler directives used to specify parallel regions and directives in code, critical for parallel programming.&lt;SEP&gt;OpenMP pragmas are compiler directives used to specify parallel regions and directives in code, essential for shared-memory parallel programming.&lt;SEP&gt;OpenMP pragmas are directives in source code that enable parallel programming, and labeling them is a key task for performance optimization.&lt;SEP&gt;OpenMP pragmas are directives in source code used to specify parallel regions, important for performance optimization in HPC.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2&lt;SEP&gt;chunk-3e334e5860963a6ca1939b6719cae953&lt;SEP&gt;chunk-c27a9a886dd19125bb1adb49ea7038f7&lt;SEP&gt;chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Performance prediction">
  <data key="d0">Performance prediction</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Estimations of code efficiency and runtime performance in HPC environments, targeted by models trained on HPC code.</data>
  <data key="d3">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Nichols et al.">
  <data key="d0">Nichols et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Nichols et al. is a research team that introduces the HPCCoder model, evaluates its ability to generate HPC code, and compares various large language models (LLMs) on parallel code generation tasks.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HPCCoder">
  <data key="d0">HPCCoder</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model fine-tuned on HPC code designed to generate HPC code, label OpenMP pragmas, and predict performance.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="TOKOMPILER">
  <data key="d0">TOKOMPILER</data>
  <data key="d1">Tools</data>
  <data key="d2">An HPC-specific tokenizer for LLMs used to train COMPCODER.&lt;SEP&gt;An HPC-specific tokenizer for LLMs used to train the COMPCODER model on C, C++, and Fortran code.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="COMPCODER">
  <data key="d0">COMPCODER</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model trained on C, C++, and Fortran code using TOKOMPILER, aimed at HPC code generation.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Munley et al.">
  <data key="d0">Munley et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Evaluate LLMs' ability to generate compiler verification tests for parallel OpenACC code.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Chen et al.">
  <data key="d0">Chen et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Use LLMs to identify data races in parallel code and propose the DRB-ML data set.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="DRB-ML">
  <data key="d0">DRB-ML</data>
  <data key="d1">Study Design</data>
  <data key="d2">A dataset integrated into the LM4HPC framework for data race detection in parallel code.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Godoy et al.">
  <data key="d0">Godoy et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Evaluate LLMs' capabilities in generating HPC kernels, using limited problems and standard evaluation practices.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Valero-Lara et al.">
  <data key="d0">Valero-Lara et al.</data>
  <data key="d1">Research Team</data>
  <data key="d2">Evaluate LLMs' capabilities in generating HPC kernels, with limited problem sets and evaluation practices.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Prompt">
  <data key="d0">Prompt</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A carefully designed input or instruction used to elicit specific responses from language models, serving as the basis for prompt tuning.&lt;SEP&gt;A sequence of tokens or instructions designed to elicit specific responses from an LLM, guiding the model's output.&lt;SEP&gt;A sequence of tokens or instructions designed to guide the LLM's output, effectively framing the task or question for the model.&lt;SEP&gt;An individual text input given to an LLM to generate code, which is then compiled, executed, and scored.&lt;SEP&gt;Prompts are carefully crafted instructions provided to language models to generate code across multiple execution models, including serial, OpenMP, MPI, Kokkos, CUDA, and HIP.&lt;SEP&gt;Input instructions crafted to guide LLMs towards domain-specific outputs without internal modifications.&lt;SEP&gt;Input descriptions provided to the model, such as function headers and comments, used to generate code.&lt;SEP&gt;The input description provided to the model, such as function headers and comments, used to generate code.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-d3bbf812d2ef1f847454ee16a672e8f9&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Problem">
  <data key="d0">Problem</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A set of tasks or prompts testing the LLM's ability to generate code for the same computational work using different execution models.&lt;SEP&gt;A set of tasks or prompts testing the ability of an LLM to generate code for the same computational work, possibly with different execution models.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Problem Type">
  <data key="d0">Problem Type</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A category of problems testing similar computational tasks, such as sorting, graph algorithms, or linear algebra, used within the benchmark.&lt;SEP&gt;A category of problems testing similar computational work, such as sorting or graph algorithms, used within the benchmark.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sort">
  <data key="d0">Sort</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type requiring the LLM to generate code that sorts an array or sub-array of values, either in-place or out-of-place.&lt;SEP&gt;A problem type requiring the generation of code to sort arrays or sub-arrays, either in-place or out-of-place.&lt;SEP&gt;Sorting problems involve arranging data in order, with parallel implementations available, yet still challenging for LLMs in some models.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Scan">
  <data key="d0">Scan</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type involving prefix sum operations over arrays, requiring code generation for scan algorithms.&lt;SEP&gt;A problem type involving scan operations, such as prefix sums, over an array of values.&lt;SEP&gt;Scan operations are prefix sum computations that are fundamental in parallel algorithms, with varying difficulty for LLMs.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Dense Linear Algebra">
  <data key="d0">Dense Linear Algebra</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type involving dense linear algebra functions from BLAS libraries, such as matrix multiplication.&lt;SEP&gt;A problem type involving dense linear algebra functions from BLAS libraries.&lt;SEP&gt;Dense linear algebra problems involve dense matrices and are more straightforward for LLMs to parallelize and solve correctly.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sparse Linear Algebra">
  <data key="d0">Sparse Linear Algebra</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type involving sparse linear algebra functions from BLAS libraries, such as sparse matrix-vector multiplication.&lt;SEP&gt;A problem type involving sparse linear algebra functions from BLAS libraries.&lt;SEP&gt;Problems involving sparse matrices, noted as the most difficult for LLMs to parallelize effectively.&lt;SEP&gt;Sparse linear algebra problems involve sparse matrices, which are more difficult for LLMs to parallelize effectively, resulting in lower pass@1 scores.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Search">
  <data key="d0">Search</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type focused on searching for an element or property within an array.&lt;SEP&gt;A problem type involving generating code to find elements or properties within arrays.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Reduce">
  <data key="d0">Reduce</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type involving reduction operations like summing or finding maximum over array elements.&lt;SEP&gt;A problem type involving reduction operations over an array, such as summing elements.&lt;SEP&gt;Reduction operations aggregate data, and are relatively simple for LLMs to generate in parallel contexts.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Histogram">
  <data key="d0">Histogram</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type involving binning data values based on properties for data analysis.&lt;SEP&gt;A problem type that bins values based on data properties.&lt;SEP&gt;Histogram problems involve data distribution analysis, which can be parallelized but presents challenges for LLM code correctness.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Stencil">
  <data key="d0">Stencil</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type involving one iteration of 1D or 2D stencil computations, such as Jacobi relaxation.&lt;SEP&gt;A problem type involving stencil computations, such as Jacobi relaxation, over grid data.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Graph">
  <data key="d0">Graph</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type involving graph algorithms like connected components or shortest path calculations.&lt;SEP&gt;A problem type involving graph algorithms, such as component counting.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Geometry">
  <data key="d0">Geometry</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type involving computation of geometric properties, such as convex hulls.&lt;SEP&gt;A problem type involving geometric computations, such as convex hull or geometric property calculations.&lt;SEP&gt;Geometry pertains to the mathematical study of shapes, sizes, and properties of space, including the computation of geometric properties like convex hulls.&lt;SEP&gt;Geometry problems involve spatial computations, often complex to parallelize, making them more difficult for LLMs.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Fourier Transform">
  <data key="d0">Fourier Transform</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type involving computation of Fourier transforms and inverse transforms.&lt;SEP&gt;A problem type involving computation of standard and inverse Fourier transforms.&lt;SEP&gt;Fourier Transform is a mathematical technique to decompose functions into their frequency components, with standard and inverse forms used in signal processing.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Transform">
  <data key="d0">Transform</data>
  <data key="d1">Problem Type</data>
  <data key="d2">A problem type involving mapping a constant function to each element of an array.&lt;SEP&gt;Transform maps a constant function to each element of an array, facilitating data processing and analysis in various computational tasks.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="component counting">
  <data key="d0">component counting</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Component counting involves quantifying elements within a structure or dataset, fundamental for understanding and analyzing data.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Convex Hull">
  <data key="d0">Convex Hull</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The convex hull is the smallest convex shape that encompasses all points in a dataset, used in computational geometry.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Problems">
  <data key="d0">Problems</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Problems are structured tasks designed to evaluate core functionalities of a problem type, with variations to assess understanding and prevent copying from training data.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Problem Variations">
  <data key="d0">Problem Variations</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Variations of problems are small changes in problem parameters or structure to test the robustness of model understanding.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="C++&quot;, ">
  <data key="d0">C++", </data>
  <data key="d1">Tools</data>
  <data key="d2">C++ is a programming language used in prompts for serial, OpenMP, MPI, and MPI+OpenMP models, utilizing STL data structures for code examples.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CUDA&quot;, ">
  <data key="d0">CUDA", </data>
  <data key="d1">Tools</data>
  <data key="d2">CUDA is a parallel computing platform and API model for NVIDIA GPUs, used in prompts to generate GPU-accelerated code.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HIP&quot;, ">
  <data key="d0">HIP", </data>
  <data key="d1">Tools</data>
  <data key="d2">HIP is a GPU programming platform for AMD GPUs, included among the models tested for code generation.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Kokkos">
  <data key="d0">Kokkos</data>
  <data key="d1">Tools</data>
  <data key="d2">A performance portability library enabling manycore performance through polymorphic memory access patterns, facilitating high-performance computing.&lt;SEP&gt;A performance portability library for writing parallel code across different hardware architectures."&gt;&lt;SEP&gt;A performance portability library supporting parallel programming across diverse hardware architectures, including CPUs and GPUs.&lt;SEP&gt;Kokkos is a performance portability library providing data structures like Kokkos::View, used in prompts for parallel code in Kokkos models.&lt;SEP&gt;Kokkos is a performance portability library providing data structures like Kokkos::View, used in prompts for parallel code in portability libraries.&lt;SEP&gt;Kokkos is a performance portability programming model that enables writing code that can run efficiently across different hardware architectures, such as CUDA and HIP.&lt;SEP&gt;Kokkos is a performance-portable programming library designed to write code that can run efficiently across diverse hardware architectures, supporting multiple execution models.&lt;SEP&gt;Kokkos is a programming model aimed at performance portability across different hardware architectures, such as CUDA and HIP.&lt;SEP&gt;Kokkos is a programming model and library for writing performance-portable parallel code across diverse hardware architectures, supporting multiple execution and memory spaces.&lt;SEP&gt;A programming model tested for its sensitivity and correctness in code suggestion experiments.&lt;SEP&gt;Kokkos is a high-level abstraction for performance portability in HPC, but it performs poorly over several kernels, possibly due to limited community adoption and complexity.&lt;SEP&gt;Kokkos is a high-level programming abstraction for performance portability in HPC, but it performs poorly over several kernels, possibly due to community size and complexity.&lt;SEP&gt;Kokkos is a programming model tested for its sensitivity and correctness in code suggestion experiments.</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Component Counting">
  <data key="d0">Component Counting</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Component counting involves quantifying elements within a structure or dataset, fundamental for understanding and analyzing data.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Prompts">
  <data key="d0">Prompts</data>
  <data key="d1">Tools</data>
  <data key="d2">Prompts are carefully crafted instructions provided to language models to generate code across multiple execution models, including serial, OpenMP, MPI, Kokkos, CUDA, and HIP.</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="C++">
  <data key="d0">C++</data>
  <data key="d1">methodology</data>
  <data key="d2">A programming language used in the experiments to evaluate model sensitivity and correctness in code generation tasks.&lt;SEP&gt;C++ is a programming language used in prompts for serial, OpenMP, MPI, and MPI+OpenMP models, utilizing STL data structures for code examples.&lt;SEP&gt;C++ is a programming language used in the experimental setup to evaluate model sensitivity and correctness metrics in code generation tasks.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CUDA">
  <data key="d0">CUDA</data>
  <data key="d1">Tools</data>
  <data key="d2">A parallel computing platform and API model for NVIDIA GPUs, supporting high-performance GPU programming.&lt;SEP&gt;A parallel computing platform and API model for NVIDIA GPUs."&gt;&lt;SEP&gt;CUDA is a parallel computing platform and API by NVIDIA that enables offloading computation to GPUs, managing kernels, memory transfers, and execution.&lt;SEP&gt;CUDA is a parallel computing platform and API created by NVIDIA that enables GPU-accelerated computing, managing memory allocation, data transfer, and kernel execution.&lt;SEP&gt;CUDA is a parallel computing platform and API developed by NVIDIA for GPU programming, used as a benchmark for LLM performance in generating code for GPU-based models.&lt;SEP&gt;CUDA is a parallel computing platform and API developed by NVIDIA, enabling GPU acceleration for high-performance computing tasks.&lt;SEP&gt;CUDA is a parallel computing platform and API model created by NVIDIA, enabling developers to use GPU acceleration for compute-intensive tasks.&lt;SEP&gt;CUDA is a parallel computing platform and API model created by NVIDIA, used for GPU programming and high-performance computing.&lt;SEP&gt;CUDA is a parallel computing platform and API model created by NVIDIA, used for GPU programming, and compared with HIP in performance for LLM code generation.&lt;SEP&gt;CUDA is a parallel computing platform and API model for NVIDIA GPUs, used in prompts to generate GPU-accelerated code.&lt;SEP&gt;CUDA is a parallel computing platform and API model created by NVIDIA that allows for direct access to GPU resources for offloading computation tasks.&lt;SEP&gt;CUDA is a parallel computing platform and API model created by NVIDIA that allows for using GPUs for general purpose processing, including managing memory and kernel execution.&lt;SEP&gt;A parallel computing platform evaluated for its effectiveness in code suggestion correctness across different kernels.&lt;SEP&gt;CUDA is a parallel computing platform evaluated for its effectiveness in code suggestion correctness across kernels.&lt;SEP&gt;CUDA is a parallel programming model primarily used for GPU programming; its effectiveness depends on specific language features like 'kernel' or '__global__', and its performance can decrease if these are not used.&lt;SEP&gt;CUDA is a parallel programming model that, despite its popularity, shows decreased quality in some contexts, especially when specific keywords like 'kernel' or '__global__' are not used.</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HIP">
  <data key="d0">HIP</data>
  <data key="d1">Tools</data>
  <data key="d2">A programming model assessed for its sensitivity and correctness in code generation tasks.&lt;SEP&gt;HIP is a GPU programming API developed by AMD, similar to CUDA, and analyzed for its efficiency and similarity to CUDA in LLM performance.&lt;SEP&gt;HIP is a GPU programming platform for AMD GPUs, included among the models tested for code generation.&lt;SEP&gt;HIP is an AMD GPU programming API similar to CUDA, used to compare performance and efficiency with CUDA in the context of LLM code generation.&lt;SEP&gt;HIP is a programming model assessed for its sensitivity and correctness in code generation tasks.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-dfe74b691919432b3bb0f4652ee2468c&lt;SEP&gt;chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="MBPP results">
  <data key="d0">MBPP results</data>
  <data key="d1">Results</data>
  <data key="d2">MBPP results are outcomes derived from a specific benchmark dataset, used to assess model performance.&lt;SEP&gt;MBPP results are performance metrics obtained from the MBPP benchmark dataset, used to assess the effectiveness of language models in code generation tasks.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Prompt in Listing 1">
  <data key="d0">Prompt in Listing 1</data>
  <data key="d1">Tools</data>
  <data key="d2">A prompt format used to evaluate LLMs' ability to generate code for parallel code evaluation.&lt;SEP&gt;A specific prompt format designed to evaluate LLMs' ability to generate code from natural language descriptions in a standardized manner.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Section 7">
  <data key="d0">Section 7</data>
  <data key="d1">Study Design</data>
  <data key="d2">Section in the document describing the evaluation metrics and methodology for assessing code generation.&lt;SEP&gt;Section in the document that describes the evaluation methodology, including metrics and procedures for assessing model performance.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenMP, MPI, MPI+OpenMP, Kokkos, CUDA, HIP">
  <data key="d0">OpenMP, MPI, MPI+OpenMP, Kokkos, CUDA, HIP</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Execution models used in the evaluation of code performance and translation capabilities.&lt;SEP&gt;Parallel execution models used as the basis for evaluating code translation and performance in the experiments.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Serial results">
  <data key="d0">Serial results</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Baseline results obtained from serial execution of code, used for comparison with parallel implementations.&lt;SEP&gt;Results obtained from serial execution models used as baseline comparisons.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Experiment 2">
  <data key="d0">Experiment 2</data>
  <data key="d1">Study Design</data>
  <data key="d2">A specific experiment designed to assess the ability of LLMs to translate code between different execution models.&lt;SEP&gt;An experiment studying the ability of LLMs to translate code between different execution models.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Listing 2">
  <data key="d0">Listing 2</data>
  <data key="d1">Tools</data>
  <data key="d2">A prompt format used to instruct models to translate code from one execution model to another.&lt;SEP&gt;A prompt used to instruct models to perform code translation tasks from one execution model to another.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Pairs: serial→OpenMP, serial→MPI, CUDA→Kokkos">
  <data key="d0">Pairs: serial→OpenMP, serial→MPI, CUDA→Kokkos</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specific translation tasks evaluated for their effectiveness in the experiment.&lt;SEP&gt;Specific translation tasks evaluated to analyze the models' translation capabilities between these pairs.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Metrics">
  <data key="d0">Metrics</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Quantitative measures used to assess the accuracy and quality of code translation and generation.&lt;SEP&gt;Quantitative measures used to evaluate the accuracy, quality, and effectiveness of code generated or translated by the models.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Models: CodeLlama (CL-7B, CL-13B, CL-34B), StarCoderBase">
  <data key="d0">Models: CodeLlama (CL-7B, CL-13B, CL-34B), StarCoderBase</data>
  <data key="d1">Tools</data>
  <data key="d2">State-of-the-art language models fine-tuned for code generation, translation, and infilling tasks, with various sizes and training data.&lt;SEP&gt;State-of-the-art open-source and fine-tuned language models used for code translation and generation tasks.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Table 2">
  <data key="d0">Table 2</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A summary table presenting properties, capabilities, and configurations of the models used in the evaluation.&lt;SEP&gt;Summary and properties of the models used in the evaluation.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CodeLlama (CL-7B, CL-13B, CL-34B)">
  <data key="d0">CodeLlama (CL-7B, CL-13B, CL-34B)</data>
  <data key="d1">Tools</data>
  <data key="d2">A series of open-source models based on Llama 2, optimized for code tasks, supporting different sizes and features like infilling and long context.</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="StarCoderBase">
  <data key="d0">StarCoderBase</data>
  <data key="d1">Tools</data>
  <data key="d2">A 15.5 billion parameter model trained on extensive code and natural language data, supporting multiple programming languages and infilling capabilities.&lt;SEP&gt;An LLM evaluated for code translation and generation, showing performance variations across tasks.&lt;SEP&gt;An LLM evaluated for code translation and generation, with observed performance variations across different parallel programming models.&lt;SEP&gt;An open-source language model based on SantaCoder architecture supporting code infilling and custom tokens, with a context length of 8K tokens, used for code generation and comparison in research.&lt;SEP&gt;An open-source language model supporting code infilling and custom tokens, based on SantaCoder architecture, with an 8K token context length, designed for code generation tasks.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7&lt;SEP&gt;chunk-8044b7aee8628a78f321eae0291f7292&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="The Stack">
  <data key="d0">The Stack</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large-scale dataset comprising 1 trillion tokens, including code from over 80 programming languages, natural language in git commits, and Jupyter notebooks, used for training language models.&lt;SEP&gt;A large-scale dataset containing 1 trillion tokens, including code from over 80 programming languages, natural language in git commits, and Jupyter notebooks, used for training and evaluating language models.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Phind-CodeLlama-V2">
  <data key="d0">Phind-CodeLlama-V2</data>
  <data key="d1">Tools</data>
  <data key="d2">A fine-tuned CodeLlama-34B model trained on over 1.5 billion code tokens, evaluated on the BigCode leaderboard with a pass@1 score of 71.95, used for code generation and benchmarking.&lt;SEP&gt;A fine-tuned CodeLlama-34B model trained on over 1.5 billion code tokens, evaluated on the BigCode leaderboard with a pass@1 score of 71.95, used for code generation and comparison.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="GPT-3.5 and GPT-4">
  <data key="d0">GPT-3.5 and GPT-4</data>
  <data key="d1">Tools</data>
  <data key="d2">Closed-source large language models from OpenAI, instruction-tuned and aligned to human preferences, accessed via API for inference rather than direct code generation.&lt;SEP&gt;Closed-source large language models from OpenAI, instruction-tuned and aligned to human preferences, accessed via API for inference, used for code generation and evaluation.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="speedup n@k">
  <data key="d0">speedup n@k</data>
  <data key="d1">Results</data>
  <data key="d2">A performance metric measuring the expected speedup of generated code relative to a sequential baseline, based on execution time across multiple processes or threads.&lt;SEP&gt;A performance metric measuring the expected speedup of generated code relative to a sequential baseline, based on execution times across multiple processes or threads.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="efficiency n@k">
  <data key="d0">efficiency n@k</data>
  <data key="d1">Results</data>
  <data key="d2">A metric assessing resource utilization and runtime efficiency of parallel or HPC code generated by models.&lt;SEP&gt;A metric assessing the efficiency of parallel or HPC code generated by models, considering runtime and resource utilization.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Generation Evaluation">
  <data key="d0">Code Generation Evaluation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">How well do different language models perform in generating correct and efficient code across various prompts and languages?</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Benchmarking">
  <data key="d0">Benchmarking</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A comparative evaluation framework using standardized metrics like pass@k, speedup n@k, and efficiency n@k across multiple models and prompts.&lt;SEP&gt;Comparative evaluation of multiple language models using standardized metrics like pass@k and speedup n@k across a set of code prompts.&lt;SEP&gt;The process of evaluating AI-generated code against benchmarks to assess quality, performance, and applicability.&lt;SEP&gt;The evaluation of models on datasets like HumanEval and APPS benchmarks measures their coding competence.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-aba26da203f4fd14ca664e347342978e&lt;SEP&gt;chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Comparisons">
  <data key="d0">Model Comparisons</data>
  <data key="d1">Results</data>
  <data key="d2">Analyses comparing different models' correctness and efficiency metrics to determine relative performance.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Research Methodology">
  <data key="d0">Research Methodology</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The approach of systematically evaluating models using standardized metrics and datasets to assess their code generation abilities.</data>
  <data key="d3">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sequential Baseline">
  <data key="d0">Sequential Baseline</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A reference performance measure representing the performance of a simple, step-by-step process used for comparison with more advanced models.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Speedup">
  <data key="d0">Speedup</data>
  <data key="d1">Results</data>
  <data key="d2">A measure of performance improvement, indicating how much faster the optimized code runs compared to the baseline.&lt;SEP&gt;A metric that quantifies how much faster a model's performance is compared to a baseline, indicating efficiency gains in parallel processing.&lt;SEP&gt;A variable representing the ratio of time taken by sequential execution to the time taken by parallel execution, indicating performance gain.&lt;SEP&gt;PolyCoder+HPC-generated code achieves speedups greater than 1, indicating effective parallelization and performance improvement.&lt;SEP&gt;PolyCoder+HPC-generated code achieves speedups greater than 1, showing that it produces faster-than-sequential, efficient parallel code.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-aebb652b359c14534612e14559754bbc&lt;SEP&gt;chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Relative Speedup">
  <data key="d0">Relative Speedup</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ratio of execution times between different processes or models, used to compare performance improvements.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Equation (2)">
  <data key="d0">Equation (2)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A mathematical formula defining the expected best speedup relative to a sequential baseline for a specific prompt.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Equation (3)">
  <data key="d0">Equation (3)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A formula calculating the average speedup across multiple prompts, reflecting overall model performance.&lt;SEP&gt;An equation used to define efficiency𝑛@𝑘, which has been modified in Equation (5&lt;SEP&gt;An equation used to define the efficiency𝑛@𝑘 metric, modified from Equation (3</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd&lt;SEP&gt;chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Equation (4)">
  <data key="d0">Equation (4)</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A formula estimating the maximum speedup over all resource counts, providing an upper bound on performance.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="speedup𝑛@𝑘">
  <data key="d0">speedup𝑛@𝑘</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric measuring the average speedup of generated code compared to sequential baselines, considering a fixed number of resources 𝑛 and attempts 𝑘.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="speedupmax@𝑘">
  <data key="d0">speedupmax@𝑘</data>
  <data key="d1">Variables</data>
  <data key="d2">A variant of the speedup metric estimating the maximum speedup over all resource counts, indicating peak performance potential.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="efficiency𝑛@𝑘">
  <data key="d0">efficiency𝑛@𝑘</data>
  <data key="d1">Variables</data>
  <data key="d2">A metric assessing the performance efficiency (speedup per resource) of generated code when given 𝑘 attempts, range between 0 and 1.&lt;SEP&gt;A metric that quantifies the expected best performance efficiency of generated code when given 𝑘 attempts, indicating how effectively the code makes use of parallel resources, with values ranging from 0 to 1.0.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd&lt;SEP&gt;chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="parallel code">
  <data key="d0">parallel code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code designed to execute multiple operations simultaneously, leveraging parallel resources to improve performance.&lt;SEP&gt;Parallel code refers to programming code designed to execute tasks concurrently across multiple processors or cores, crucial for high-performance computing.&lt;SEP&gt;The code generated or translated by LLMs for parallel execution models, used to evaluate model performance.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="resources">
  <data key="d0">resources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Computational resources such as processes or threads used to execute parallel code.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="hardware cores">
  <data key="d0">hardware cores</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Physical processing units in hardware over which parallel execution can be distributed.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="performance of a sequential baseline">
  <data key="d0">performance of a sequential baseline</data>
  <data key="d1">Results</data>
  <data key="d2">The measured performance of a simple, step-by-step process used as a reference point for evaluating speedup.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="execution time">
  <data key="d0">execution time</data>
  <data key="d1">Variables</data>
  <data key="d2">The duration required for a process or code to complete, used to compute speedup and performance metrics.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="prompt">
  <data key="d0">prompt</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An input or initial data provided to the model or system to generate output or code.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="𝑇∗𝑝">
  <data key="d0">𝑇∗𝑝</data>
  <data key="d1">Variables</data>
  <data key="d2">The expected best runtime or performance metric for a prompt p, used as a reference in speedup calculations.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="𝑇𝑝">
  <data key="d0">𝑇𝑝</data>
  <data key="d1">Variables</data>
  <data key="d2">The runtime or performance of a prompt p on a specific process or resource configuration.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="𝑘">
  <data key="d0">𝑘</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of attempts or samples used to generate or evaluate code for a prompt.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="𝑛">
  <data key="d0">𝑛</data>
  <data key="d1">Variables</data>
  <data key="d2">Number of processes or threads used in parallel execution.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="𝑁">
  <data key="d0">𝑁</data>
  <data key="d1">Variables</data>
  <data key="d2">Total number of generated samples or runs for a prompt, used in probability calculations.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="𝑗">
  <data key="d0">𝑗</data>
  <data key="d1">Variables</data>
  <data key="d2">Index of a specific sample or run among generated samples, ordered from slowest to fastest.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="probability">
  <data key="d0">probability</data>
  <data key="d1">Variables</data>
  <data key="d2">The likelihood that a specific sample is the j-th slowest or fastest, used in expected value calculations.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="𝑁𝑘">
  <data key="d0">𝑁𝑘</data>
  <data key="d1">Variables</data>
  <data key="d2">Total number of samples considering the number of attempts 𝑘, used in speedup calculations.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="set of resource counts">
  <data key="d0">set of resource counts</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The collection of different numbers of processes or threads over which experiments are conducted, e.g., 1, 2, 4, 8, etc.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="procs">
  <data key="d0">procs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Set of resource counts (e.g., 1, 2, 4, 8, ...) used to evaluate maximum speedup across different hardware configurations.</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="performance of the generated code">
  <data key="d0">performance of the generated code</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The overall efficiency and effectiveness of code produced by language models, evaluated through specific metrics such as speedup and resource utilization to understand how well the generated code performs in various computational contexts.&lt;SEP&gt;The performance of code generated by models, measured by specific metrics such as efficiency𝑛@𝑘, which evaluates how well the code utilizes parallel resources and scales with processes or threads.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="efficiencymax@𝑘">
  <data key="d0">efficiencymax@𝑘</data>
  <data key="d1">Variables</data>
  <data key="d2">A related metric to efficiency𝑛@𝑘, representing the maximum achievable efficiency at 𝑘 attempts, used to evaluate optimal performance of generated code.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Equation (5)">
  <data key="d0">Equation (5)</data>
  <data key="d1">Theoretical Framework</data>
  <data key="d2">An equation that formalizes the calculation of efficiency𝑛@𝑘, incorporating the division by 𝑛, used to measure code performance.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Resources">
  <data key="d0">Parallel Resources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Resources such as processes or threads that are utilized by generated code, with metrics assessing how well the code leverages these resources for performance.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Benchmarks (HumanEval, MBPP, DS-1000)">
  <data key="d0">Benchmarks (HumanEval, MBPP, DS-1000)</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Standard benchmark datasets used to evaluate the performance of generated Python code, specifically measuring speedup1@𝑘 to compare efficiency against human-created baselines.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="LLMs (Large Language Models)">
  <data key="d0">LLMs (Large Language Models)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Advanced AI models trained on large datasets to analyze and generate human-like language, applicable across biomedical and Earth science domains.&lt;SEP&gt;Language models used to generate code outputs for evaluation, including models like GPT-3.5 and GPT-4, with specific inference setups described.&lt;SEP&gt;Large Language Models are advanced AI models capable of understanding and generating human-like text, which can be augmented with external and implicit knowledge to improve domain-specific performance."|&lt;SEP&gt;Large Language Models are advanced AI models designed to understand and generate human language, capable of handling diverse tasks but challenged by dynamic knowledge updates.&lt;SEP&gt;Large-scale language models trained on extensive text corpora, capable of few-shot and zero-shot learning, used for various NLP tasks.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-8bf110218e64d416737ff57117ec74cc&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b&lt;SEP&gt;chunk-f3c94db4d83b03209953445c36e8cb0d&lt;SEP&gt;chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HuggingFace library">
  <data key="d0">HuggingFace library</data>
  <data key="d1">Tools</data>
  <data key="d2">A software library used with PyTorch to load and run inference on open-source language models for code generation.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="NVIDIA A100 80GB GPU">
  <data key="d0">NVIDIA A100 80GB GPU</data>
  <data key="d1">Tools</data>
  <data key="d2">Hardware used to run inference for code generation, providing high-performance computing resources.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenAI API">
  <data key="d0">OpenAI API</data>
  <data key="d1">Tools</data>
  <data key="d2">API used to generate outputs from GPT-3.5 and GPT-4 models, with specified sampling and temperature configurations.&lt;SEP&gt;Provides programmatic access to OpenAI's models for various AI applications.&lt;SEP&gt;The OpenAI API provides access to OpenAI's language models for various natural language processing tasks.&lt;SEP&gt;OpenAI API provides access to Codex models for code generation, enabling integration of AI-generated code into various software applications.&lt;SEP&gt;OpenAI API provides access to Codex models for programmatic code generation, enabling integration into various software workflows.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-d1ed35f0489d99675c43fbbee04d61fd&lt;SEP&gt;chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Nucleus sampling">
  <data key="d0">Nucleus sampling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A sampling technique used during code generation, with a probability p=0.95 to produce diverse outputs within a controlled distribution.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Test harness (ParEval)">
  <data key="d0">Test harness (ParEval)</data>
  <data key="d1">Tools</data>
  <data key="d2">A set of scripts and infrastructure used to compile, run, and evaluate generated code against test drivers, recording correctness and execution metrics.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="GCC (version 9.4.0)">
  <data key="d0">GCC (version 9.4.0)</data>
  <data key="d1">Tools</data>
  <data key="d2">Compiler used to compile generated C++ code, with specific flags for optimization and standards compliance.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Kokkos (version 4.1.0)">
  <data key="d0">Kokkos (version 4.1.0)</data>
  <data key="d1">Tools</data>
  <data key="d2">A performance portability library for parallel programming in C++, used to compile Kokkos-based code with specific execution spaces.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="MPI (OpenMPI version 4.1.1)">
  <data key="d0">MPI (OpenMPI version 4.1.1)</data>
  <data key="d1">Tools</data>
  <data key="d2">Message Passing Interface library used for parallel code, particularly in distributed memory systems.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CUDA (nvcc, version 12.1.1)">
  <data key="d0">CUDA (nvcc, version 12.1.1)</data>
  <data key="d1">Tools</data>
  <data key="d2">NVIDIA's parallel computing platform compiler used to compile CUDA code for GPUs.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HIP (hipcc, ROCm version 5.7.0)">
  <data key="d0">HIP (hipcc, ROCm version 5.7.0)</data>
  <data key="d1">Tools</data>
  <data key="d2">Compiler for HIP, used to compile code for AMD GPUs in the evaluation pipeline.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Performance evaluation process">
  <data key="d0">Performance evaluation process</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of assessing generated code by compiling, executing, and comparing outputs against baselines, using specific hardware and software configurations.</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="output">
  <data key="d0">output</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The output refers to the result generated by a program or code, including correctness, runtime, and performance metrics, which are used to evaluate the quality of code in computational tasks.&lt;SEP&gt;The output refers to the result produced by the code, including correctness, runtime, and performance metrics, used to evaluate the effectiveness of generated code.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="the prompt">
  <data key="d0">the prompt</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The prompt is the initial input or instruction provided to a language model or system to generate a response or output.&lt;SEP&gt;The prompt is the initial instruction or input provided to the language model to generate code or responses, guiding the output.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="generated code">
  <data key="d0">generated code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Generated code is the computer program output created by the language model, which is assessed for correctness, efficiency, and adherence to requirements.&lt;SEP&gt;Generated code is the computer programming output produced by a language model or algorithm, used to perform specific tasks and evaluated for correctness and performance.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="test harness">
  <data key="d0">test harness</data>
  <data key="d1">Tools</data>
  <data key="d2">The test harness is a framework that executes the generated code to verify correctness, measure runtime, and compare with baseline implementations.&lt;SEP&gt;The test harness is a testing framework that runs the generated code to verify correctness, measure runtime, and compare against baseline implementations.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="parallel programming model">
  <data key="d0">parallel programming model</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A parallel programming model is a conceptual framework that guides the development of parallel algorithms and code, such as OpenMP, MPI, or CUDA, to enable concurrent execution.&lt;SEP&gt;A parallel programming model provides the conceptual framework and guidelines for developing parallel code, such as OpenMP, MPI, or CUDA, enabling concurrent execution across hardware.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenMP, MPI, CUDA, Kokkos">
  <data key="d0">OpenMP, MPI, CUDA, Kokkos</data>
  <data key="d1">Tools</data>
  <data key="d2">These are specific frameworks and tools used for parallel programming, allowing developers to implement and run parallel algorithms on various hardware architectures.&lt;SEP&gt;These are specific tools and frameworks used for parallel programming, enabling the development and execution of parallel code on various hardware architectures.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="code correctness">
  <data key="d0">code correctness</data>
  <data key="d1">Results</data>
  <data key="d2">Code correctness indicates whether the generated code produces the correct output within specified constraints, such as time limits, and without errors.&lt;SEP&gt;Code correctness refers to whether the generated code produces the intended output without errors and within specified constraints, such as time limits.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="pass@1 score">
  <data key="d0">pass@1 score</data>
  <data key="d1">Results</data>
  <data key="d2">A metric indicating the accuracy of LLMs in generating correct code on the first attempt, used to compare performance across models and problem types.&lt;SEP&gt;A performance metric indicating the percentage of correct code generated by LLMs on the first attempt, used to compare effectiveness across models and problem types.&lt;SEP&gt;The pass@1 score measures the percentage of generated outputs where the top candidate is correct, used to evaluate the effectiveness of code generation models.&lt;SEP&gt;The pass@1 score measures the percentage of times the top generated code output is correct, used here to compare different language models' effectiveness in code generation.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model size (e.g., GPT-3.5, GPT-4, CodeLlama-34B)">
  <data key="d0">model size (e.g., GPT-3.5, GPT-4, CodeLlama-34B)</data>
  <data key="d1">Variables</data>
  <data key="d2">Model size influences the confidence, diversity, and sometimes correctness of generated outputs; larger models tend to produce more confident results but may also generate repetitive outputs.&lt;SEP&gt;Model size influences the confidence, diversity, and sometimes the correctness of generated outputs; larger models tend to produce more confident but sometimes less varied outputs.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="runtime">
  <data key="d0">runtime</data>
  <data key="d1">Variables</data>
  <data key="d2">Runtime measures the duration taken by generated code to execute, impacting overall performance and usability.</data>
  <data key="d3">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="accuracy">
  <data key="d0">accuracy</data>
  <data key="d1">Results</data>
  <data key="d2">Accuracy refers to whether the generated code produces correct outputs for given inputs, a key metric in evaluating code quality.&lt;SEP&gt;Results indicate that kernel complexity impacts the correctness and success rate of generated code, with simpler kernels achieving higher accuracy.&lt;SEP&gt;Results show that increasing kernel complexity decreases the likelihood of correct code generation by AI models, highlighting the challenge of complex kernel synthesis.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="correctness">
  <data key="d0">correctness</data>
  <data key="d1">Results</data>
  <data key="d2">Correctness assesses whether the generated code functions as intended without errors, producing expected results.&lt;SEP&gt;Correctness measures how accurately the generated parallel code implements the intended functionality.&lt;SEP&gt;The degree to which the generated code accurately implements the intended parallel algorithms and models.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="execution environment">
  <data key="d0">execution environment</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The execution environment includes hardware and software setups, such as CPUs, GPUs, and operating systems, which influence code performance.&lt;SEP&gt;The hardware or software environment in which parallel code is executed, impacting model performance and code correctness.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a&lt;SEP&gt;chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="closed-source models">
  <data key="d0">closed-source models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Proprietary AI models like GPT-3.5 and GPT-4, with restricted access, evaluated for code generation performance.&lt;SEP&gt;Proprietary AI models like GPT-3.5 and GPT-4, with restricted access, evaluated for their code generation performance.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="parallel execution models">
  <data key="d0">parallel execution models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Different paradigms for executing code in parallel, including serial, OpenMP, CUDA/HIP, MPI/MPI+OpenMP, and Kokkos, used to analyze model effectiveness.&lt;SEP&gt;Different programming paradigms for executing code in parallel, including serial, OpenMP, CUDA/HIP, MPI/MPI+OpenMP, and Kokkos, analyzed for their compatibility with LLM-generated code.&lt;SEP&gt;Specific models like serial, OpenMP, CUDA/HIP, MPI/MPI+OpenMP, and Kokkos used to evaluate the ease or difficulty for LLMs to generate correct code.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model ordering">
  <data key="d0">model ordering</data>
  <data key="d1">Results</data>
  <data key="d2">Ranking of models based on pass@k scores, with Phind-V2 leading among open-source models and GPT-4 showing strong performance on certain tasks.&lt;SEP&gt;The relative ranking of models based on pass@k scores, with Phind-V2 leading among open-source models and GPT-4 performing well on certain tasks.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="performance plateau">
  <data key="d0">performance plateau</data>
  <data key="d1">Results</data>
  <data key="d2">Observation that model scores tend to plateau at higher attempts, indicating a limit to improvements with additional tries.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="code complexity">
  <data key="d0">code complexity</data>
  <data key="d1">Variables</data>
  <data key="d2">The level of verbosity and niche-specific features in parallel programming models like Kokkos, affecting model performance.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="cost of generation">
  <data key="d0">cost of generation</data>
  <data key="d1">Variables</data>
  <data key="d2">Financial or computational cost associated with generating multiple samples in models like GPT-3.5 and GPT-4, influencing which k-values are practical.</data>
  <data key="d3">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="model limitations">
  <data key="d0">model limitations</data>
  <data key="d1">Limitations</data>
  <data key="d2">Current shortcomings of language models in code generation, highlighting areas for improvement.&lt;SEP&gt;Current shortcomings of models in accurately generating correct, efficient, and reliable code, indicating areas for future improvement.&lt;SEP&gt;Factors such as training data scarcity, code verbosity, and niche paradigms that restrict some models' ability to generate correct code effectively.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83&lt;SEP&gt;chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="LLMs">
  <data key="d0">LLMs</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Large Language Models (LLMs) are advanced AI models designed to generate code and solve computational problems, with varying performance across different programming models and problem types.&lt;SEP&gt;Large Language Models (LLMs) are advanced AI models designed to generate code, solve computational problems, and are evaluated based on their accuracy and ability to handle various programming models and problem types.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="MPI">
  <data key="d0">MPI</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A message-passing interface standard used for parallel programming across distributed-memory systems, enabling communication between processes.&lt;SEP&gt;A message-passing interface used for parallel programming across distributed systems."&gt;&lt;SEP&gt;MPI (Message Passing Interface) is a parallel programming model for distributed memory systems, known for its complexity and difficulty for LLMs to generate correct code, especially as it differs significantly from serial code.&lt;SEP&gt;MPI (Message Passing Interface) is a parallel programming model used for distributed memory systems, noted here for its complexity and difficulty for LLMs to generate correct code.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized and portable message-passing system designed to function on parallel computing architectures, facilitating communication among processes.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized protocol for communication among processes in parallel computing, used as a target model for code translation and performance evaluation.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized and portable message-passing system designed to function on parallel computing architectures.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized message-passing system used for communication between processes in parallel computing.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized and portable message-passing system designed to function on parallel computing architectures, enabling processes to communicate and coordinate for high-performance computing tasks.&lt;SEP&gt;MPI (Message Passing Interface) is a standardized message-passing system enabling processes in parallel computing environments to communicate and coordinate, facilitating high-performance computation across distributed systems.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-71ff485ed5de2f1a53b77145285b1a49&lt;SEP&gt;chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Structured, Dense Problems">
  <data key="d0">Structured, Dense Problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Types of computational problems characterized by data parallelism and density, which LLMs tend to solve more effectively.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Unstructured, Sparse Problems">
  <data key="d0">Unstructured, Sparse Problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Types of problems with less regular data, which are more challenging for LLMs to parallelize and solve correctly.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Transform Problems">
  <data key="d0">Transform Problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A class of problems that are data parallel and are generally easiest for LLMs to generate solutions for.&lt;SEP&gt;Transform problems are data-parallel, structured problems that are generally easier for LLMs to generate correct solutions for, reflected in higher pass@1 scores.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="FFT, Geometry, Sort, Scan, Histogram, Reduce">
  <data key="d0">FFT, Geometry, Sort, Scan, Histogram, Reduce</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Various computational problem types, with FFT and geometry being more difficult, and sort and scan surprisingly more manageable for parallelization by LLMs.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Performance Trends">
  <data key="d0">Performance Trends</data>
  <data key="d1">Results</data>
  <data key="d2">Larger LLMs like GPT-4 generally perform better, especially on structured and dense problems, compared to smaller models.&lt;SEP&gt;Observation that LLMs perform best on transform problems and worse on sparse linear algebra, with performance varying across different parallel execution models.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Dual Execution Models">
  <data key="d0">Dual Execution Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models like MPI+OpenMP that combine multiple parallel programming paradigms, which pose additional challenges for LLM code generation.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="MPI+OpenMP">
  <data key="d0">MPI+OpenMP</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A combined parallel programming model that integrates MPI and OpenMP, presenting additional challenges for LLMs due to its complexity and hybrid nature.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="FFT">
  <data key="d0">FFT</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Fast Fourier Transform (FFT) problems involve signal processing computations that are challenging for LLMs to parallelize, especially in sparse contexts.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Graph Problems">
  <data key="d0">Graph Problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Graph-related problems, such as traversals and algorithms, are complex and pose difficulties for LLMs, especially in less structured models.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Difficulty of Parallelization">
  <data key="d0">Difficulty of Parallelization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The inherent complexity of parallelizing certain problem types, such as sparse linear algebra and geometry, impacts LLM performance.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Execution Models">
  <data key="d0">Parallel Execution Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models like CUDA, HIP, MPI, OpenMP, and MPI+OpenMP define different paradigms of parallelism, influencing how easily LLMs can generate correct code for each.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Similarity of CUDA and HIP">
  <data key="d0">Similarity of CUDA and HIP</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">CUDA and HIP are similar in structure, leading to comparable LLM performance in generating code for these models.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Complexity of MPI and MPI+OpenMP">
  <data key="d0">Complexity of MPI and MPI+OpenMP</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">MPI and MPI+OpenMP are more complex, making it harder for LLMs to produce correct code, especially when the code significantly differs from serial implementations.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Trend in Code Difficulty">
  <data key="d0">Trend in Code Difficulty</data>
  <data key="d1">Results</data>
  <data key="d2">The more a parallel programming model's code diverges from serial code, the more difficult it is for LLMs to generate correct code, especially for models like MPI and MPI+OpenMP.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Problem Type Difficulty">
  <data key="d0">Problem Type Difficulty</data>
  <data key="d1">Results</data>
  <data key="d2">Structured, dense problems are easier for LLMs, while unstructured, sparse, and geometry problems are more challenging.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Model Size and Performance">
  <data key="d0">Model Size and Performance</data>
  <data key="d1">Results</data>
  <data key="d2">Larger models such as GPT-4 outperform smaller models across most problem types, especially on structured problems.</data>
  <data key="d3">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Methodologies">
  <data key="d0">Methodologies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methodologies encompass systematic procedures, techniques, and processes employed to conduct research or perform tasks effectively.&lt;SEP&gt;Systematic procedures and processes employed to conduct research, experiments, or analysis effectively.&lt;SEP&gt;Systematic procedures or techniques employed to conduct research, collect data, or analyze information in the study.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Taxonomies">
  <data key="d0">Taxonomies</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">Classification systems organizing entities or concepts into hierarchical categories for analysis and understanding.&lt;SEP&gt;Classifications or hierarchical structures used to organize concepts, variables, or entities within the research.&lt;SEP&gt;Taxonomies are classification systems that organize concepts, entities, or phenomena into hierarchical categories for better understanding and analysis.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Analytical Techniques">
  <data key="d0">Analytical Techniques</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Analytical Techniques are methods used to analyze data, such as statistical tests, computational algorithms, or qualitative analysis methods.&lt;SEP&gt;Methods or procedures applied to analyze data, identify patterns, or interpret results, such as statistical tests or computational algorithms.&lt;SEP&gt;Methods such as statistical tests, computational algorithms, or qualitative analysis used to analyze data and derive results.&lt;SEP&gt;Techniques include measuring test loss, evaluating pass@k with different sampling temperatures and sample sizes, and selecting the best sample based on log-probability heuristics.</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Disciplines">
  <data key="d0">Disciplines</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Academic or professional fields like psychology, biology, engineering that provide context, theories, and frameworks for research.&lt;SEP&gt;Academic or scientific fields related to the study, such as computer science, statistics, or engineering.&lt;SEP&gt;Disciplines refer to academic or professional fields of study, such as psychology, biology, or engineering, that provide context and frameworks for research.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Spatiotemporal Information">
  <data key="d0">Spatiotemporal Information</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Data describing the spatial and temporal aspects of the objects or phenomena under study.&lt;SEP&gt;Data related to the spatial and temporal aspects of phenomena, including location, time, or environmental context.&lt;SEP&gt;Spatiotemporal Information encompasses data related to the spatial and temporal aspects of phenomena, such as location and time of events.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Study Populations/Dataset">
  <data key="d0">Study Populations/Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Groups of entities or collections of data used as the basis for research analysis, representing the studied population or data set.&lt;SEP&gt;Study Populations or Datasets are groups of entities or data collections used as the basis for research analysis.&lt;SEP&gt;The group of subjects or the collection of data used for analysis in the research.</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Data">
  <data key="d0">Data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The data refers to the source, destination, and amount of information involved in the optimization process, critical for managing data flow during parallel computation.&lt;SEP&gt;The dataset consists of numerical values representing various metrics related to research parameters, such as percentages and scores, used for analysis.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Figures">
  <data key="d0">Figures</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Visual representations like graphs and charts illustrating data distributions, performance metrics, and experimental results.</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Speedup@k">
  <data key="d0">Speedup@k</data>
  <data key="d1">Results</data>
  <data key="d2">A measure of how much faster a parallel algorithm performs compared to a baseline, evaluated at different process counts or thread numbers.</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Efficiency@k">
  <data key="d0">Efficiency@k</data>
  <data key="d1">Results</data>
  <data key="d2">A metric assessing the resource utilization efficiency of parallel computations at various process or thread counts.</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Efficiency">
  <data key="d0">Efficiency</data>
  <data key="d1">Variables</data>
  <data key="d2">A measure of how effectively computational resources are utilized during parallel processing, calculated as speedup divided by number of processes or threads.&lt;SEP&gt;The goal of parameter-efficient updates is to reduce computational costs while maintaining performance.</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011&lt;SEP&gt;chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Threads">
  <data key="d0">Threads</data>
  <data key="d1">Variables</data>
  <data key="d2">Units of execution within a process, used to measure and optimize parallel performance across different hardware configurations.</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Processes">
  <data key="d0">Processes</data>
  <data key="d1">Variables</data>
  <data key="d2">Independent units of execution in distributed computing environments, such as MPI ranks, used to analyze scalability.</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Kernel Threads">
  <data key="d0">Kernel Threads</data>
  <data key="d1">Variables</data>
  <data key="d2">Threads executed on GPU kernels, relevant for measuring parallelism and performance in GPU computing.</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Across Thread Counts">
  <data key="d0">Across Thread Counts</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The section discusses the performance metrics and efficiency of various large language models (LLMs) in parallel code generation and translation across different execution models, highlighting the challenges of efficiency and scalability in parallel programming.&lt;SEP&gt;This section discusses performance metrics, efficiency, and scalability of various large language models (LLMs) in parallel code generation and translation across different execution models, highlighting challenges related to efficiency and resource utilization.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CL-7B">
  <data key="d0">CL-7B</data>
  <data key="d1">Models</data>
  <data key="d2">A specific LLM evaluated for its performance in parallel code tasks, with particular metrics such as pass@1 scores and efficiency.&lt;SEP&gt;A specific large language model evaluated for performance in parallel code tasks, including metrics like pass@1 and efficiency across different execution models.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CL-13B">
  <data key="d0">CL-13B</data>
  <data key="d1">Models</data>
  <data key="d2">A large language model assessed for its performance metrics, including pass@1 scores and efficiency in parallel code generation and translation tasks.&lt;SEP&gt;A specific LLM evaluated similarly, with performance metrics across different parallel programming models.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CL-34B">
  <data key="d0">CL-34B</data>
  <data key="d1">Models</data>
  <data key="d2">A large language model evaluated for parallel code efficiency, translation capabilities, and performance metrics.&lt;SEP&gt;An LLM model assessed for parallel code efficiency and translation capabilities.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Figure 7">
  <data key="d0">Figure 7</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">A figure illustrating efficiency@1 for MPI, OpenMP, and Kokkos prompts across different models and thread counts, showing performance trends and comparative efficiency.&lt;SEP&gt;A figure illustrating efficiency@1 for MPI, OpenMP, and Kokkos prompts across different models and thread counts, showing performance trends.&lt;SEP&gt;Figure 7 illustrates the performance comparison of different models in code compilation success rates and shows correlation between build and correctness rates across samples.&lt;SEP&gt;Figure 7 presents a comparison of model performances in code compilation, showing the percentage of samples that compile correctly and illustrating the correlation between build and correctness rates.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Figure 6">
  <data key="d0">Figure 6</data>
  <data key="d1">Results</data>
  <data key="d2">A figure comparing pass@1 scores and speedups for different models, highlighting GPT-4's superior speedup but lower efficiency in parallel code execution.&lt;SEP&gt;A figure showing pass@1 scores and speedup for different models, highlighting GPT-4's high speedup and low efficiency.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Figure 8">
  <data key="d0">Figure 8</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">A figure depicting expected maximum speedup and efficiency across resource counts, illustrating trends in parallel code performance.&lt;SEP&gt;A figure depicting the expected maximum speedup and efficiency across resource counts, illustrating scalability and resource utilization trends in parallel code performance.&lt;SEP&gt;Figure 8 shows example outputs from PolyCoder and PolyCoder+HPC generating OpenMP code to compute a sum in parallel, demonstrating their ability to produce correct parallel code with or without pragmas.&lt;SEP&gt;Figure 8 shows example outputs from PolyCoder and PolyCoder+HPC generating OpenMP code to compute a sum in parallel, illustrating differences in their ability to include parallel pragmas.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Experiment 2: Parallel Code Translation">
  <data key="d0">Experiment 2: Parallel Code Translation</data>
  <data key="d1">Study Design</data>
  <data key="d2">An experiment evaluating the ability of LLMs to translate code between different execution models and their performance/scalability.&lt;SEP&gt;An experimental setup to evaluate the ability of various LLMs to translate code between different execution models and assess their performance and scalability.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="pass@1 scores">
  <data key="d0">pass@1 scores</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Performance metrics used to evaluate the accuracy of code generation and translation by LLMs.&lt;SEP&gt;Performance metrics used to evaluate the correctness and accuracy of code generated or translated by LLMs.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="serial to OpenMP, serial to MPI, CUDA to Kokkos">
  <data key="d0">serial to OpenMP, serial to MPI, CUDA to Kokkos</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Different translation tasks evaluated to measure LLMs' ability to translate code between execution models.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="serial to OpenMP">
  <data key="d0">serial to OpenMP</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A translation task where serial code is converted into OpenMP parallel code, used to evaluate LLMs' translation capabilities.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="serial to MPI">
  <data key="d0">serial to MPI</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A translation task involving converting serial code into MPI parallel code, assessing LLM performance in code translation.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CUDA to Kokkos">
  <data key="d0">CUDA to Kokkos</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A translation task to convert CUDA code into Kokkos, testing LLMs' ability to translate between specific parallel execution models.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="efficiency">
  <data key="d0">efficiency</data>
  <data key="d1">Variables</data>
  <data key="d2">A measure of how effectively parallel code utilizes resources, with values such as 0.13 for GPT-4 indicating low efficiency despite high speedup.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="speedup">
  <data key="d0">speedup</data>
  <data key="d1">Results</data>
  <data key="d2">Quantitative measure of performance improvement, often expressed as a multiple of original runtime, achieved by optimizations.&lt;SEP&gt;The ratio indicating how much faster parallel code runs compared to sequential baseline, with GPT-4 achieving a speedup of 20.28.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7&lt;SEP&gt;chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="scalability">
  <data key="d0">scalability</data>
  <data key="d1">Study Design</data>
  <data key="d2">Scalability assesses how well a system or algorithm performs as the size of the problem or resources increases, important for scheduling and load balancing.&lt;SEP&gt;Scalability assesses how well the generated code performs as the problem size or computational resources increase.&lt;SEP&gt;The ability of the generated code to maintain efficiency as problem size or computational resources increase.&lt;SEP&gt;The capacity of models to maintain performance as resource counts increase, analyzed through maximum speedup and efficiency metrics.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-a1b2a0e4b767a0658ae2b70b61e208a7&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="parallel programming models">
  <data key="d0">parallel programming models</data>
  <data key="d1">Disciplines</data>
  <data key="d2">MPI, OpenMP, Kokkos, CUDA—these are the frameworks and models evaluated for code translation and performance assessment.</data>
  <data key="d3">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="speedup n@1">
  <data key="d0">speedup n@1</data>
  <data key="d1">Results</data>
  <data key="d2">speedup n@1 measures the efficiency and scalability of generated parallel code, indicating how well code performs as problem size or resources increase.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CodeLlama-7B">
  <data key="d0">CodeLlama-7B</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A smaller LLM model tested for its ability to translate serial code into parallel code, and how providing correct implementations affects its performance.&lt;SEP&gt;Investigates how different LLMs perform in generating parallel code, particularly the impact of providing correct implementations during translation.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Serial Code">
  <data key="d0">Serial Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Serial code refers to a sequence of programming instructions executed in order, forming the basis for translating and generating code in various parallel programming models.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="efficiency@1">
  <data key="d0">efficiency@1</data>
  <data key="d1">Results</data>
  <data key="d2">efficiency@1 measures the relative performance or speedup of generated code, indicating how effectively the code runs in parallel.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="speedup@1">
  <data key="d0">speedup@1</data>
  <data key="d1">Results</data>
  <data key="d2">speedup@1 quantifies the scalability and performance gains of parallel code, comparing execution times or resource utilization.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CodeLlama-13B">
  <data key="d0">CodeLlama-13B</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A larger LLM model evaluated for its effectiveness in translating and generating parallel code, especially in complex scenarios.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="performance modeling">
  <data key="d0">performance modeling</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Performance modeling involves predicting and analyzing the runtime and scalability of parallel code to optimize efficiency.&lt;SEP&gt;Using LLMs to predict code performance can lead to more efficient scientific computing, optimization, and resource utilization.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e&lt;SEP&gt;chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="correct implementation">
  <data key="d0">correct implementation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Correct implementation involves accurately translating serial code into parallel code that maintains functional correctness and performance.</data>
  <data key="d3">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="National Energy Research Scientific Computing Center">
  <data key="d0">National Energy Research Scientific Computing Center</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A U.S. Department of Energy Office of Science User Facility providing high-performance computing resources for scientific research activities.&lt;SEP&gt;A U.S. Department of Energy Office of Science User Facility providing high-performance computing resources for scientific research.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="NERSC">
  <data key="d0">NERSC</data>
  <data key="d1">Tools</data>
  <data key="d2">A high-performance computing facility used for scientific computations and resource allocation.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="DDR-ERCAP0025593">
  <data key="d0">DDR-ERCAP0025593</data>
  <data key="d1">Variables</data>
  <data key="d2">A specific award identifier associated with resource funding for computational activities.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Big Code Models Leaderboard">
  <data key="d0">Big Code Models Leaderboard</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A benchmarking platform to evaluate and compare large-scale code models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="HIP Documentation">
  <data key="d0">HIP Documentation</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Documentation resource detailing the HIP programming environment and tools.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Zero-Shot Replication Framework">
  <data key="d0">Zero-Shot Replication Framework</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A framework enabling replication of experiments without prior training, facilitating zero-shot learning approaches.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang">
  <data key="d0">Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Researchers investigating transformer-based approaches for source code summarization.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Transformer-based Approach">
  <data key="d0">Transformer-based Approach</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model leveraging transformer architecture to generate summaries of source code.&lt;SEP&gt;A model leveraging transformer architecture to improve source code summarization.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Source Code Summarization">
  <data key="d0">Source Code Summarization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Automated techniques to produce brief descriptions of code functionalities, aiding understanding and documentation.&lt;SEP&gt;Automated techniques to produce concise descriptions of code functionalities, aiding in understanding and documentation.&lt;SEP&gt;The task of generating concise descriptions of source code functionalities, often using machine learning models.&lt;SEP&gt;The task of generating summaries for source code to facilitate understanding.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Toufique Ahmed and Prem Devanbu">
  <data key="d0">Toufique Ahmed and Prem Devanbu</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Researchers exploring learning techniques for code summarization from limited datasets.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Learning from Small and Local Datasets">
  <data key="d0">Learning from Small and Local Datasets</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique focusing on training models with limited, localized data to improve code summarization performance.&lt;SEP&gt;Approaches that focus on training models with limited, localized data to improve code summarization performance.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="SantaCoder">
  <data key="d0">SantaCoder</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A neural code generation model designed to produce code snippets without relying on extensive datasets.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jacob Austin, Augustus Odena, Maxwell I. Nye, et al.">
  <data key="d0">Jacob Austin, Augustus Odena, Maxwell I. Nye, et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Researchers studying program synthesis using large language models to generate or complete code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Program Synthesis with Large Language Models">
  <data key="d0">Program Synthesis with Large Language Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of automatically generating code that fulfills specified functionalities using advanced language models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Tom B. Brown et al.">
  <data key="d0">Tom B. Brown et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Researchers testing the capabilities of large language models as few-shot learners across various tasks.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Language Models as Few-Shot Learners">
  <data key="d0">Language Models as Few-Shot Learners</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A concept that large language models can perform tasks with minimal task-specific training data.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Data Race Detection Using Large Language Models">
  <data key="d0">Data Race Detection Using Large Language Models</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring how large language models can be applied to detect data races in concurrent programming environments.&lt;SEP&gt;Research exploring how large language models can be applied to detect data races in concurrent programming environments.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="LM4HPC">
  <data key="d0">LM4HPC</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">A methodology applying language models to high-performance computing tasks, including detecting data races and optimizing code.&lt;SEP&gt;An application of language models aimed at high-performance computing, including tasks like data race detection and code optimization.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Mark Chen and et al.">
  <data key="d0">Mark Chen and et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Researchers evaluating the performance of large language models trained on source code datasets.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Evaluating Large Language Models Trained on Code">
  <data key="d0">Evaluating Large Language Models Trained on Code</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">A comprehensive evaluation of large language models' performance on code generation tasks, utilizing metrics like pass@k and filtering strategies.&lt;SEP&gt;A research paper focused on assessing the performance of large language models trained specifically on code.&lt;SEP&gt;A research study focused on assessing the capabilities and performance of large language models trained specifically on code data.&lt;SEP&gt;A systematic assessment of the capabilities and limitations of language models in code-related tasks.&lt;SEP&gt;A systematic evaluation of the performance and capabilities of large language models trained specifically on source code datasets.&lt;SEP&gt;A study assessing the performance of various large language models on code-related tasks, with evaluations including pass@k metrics.&lt;SEP&gt;Research assessing the performance and capabilities of large language models trained specifically on code datasets.&lt;SEP&gt;The study investigates the challenges of benchmarking and evaluating large language models specifically trained on programming code.&lt;SEP&gt;The study investigates the difficulties and benchmarks associated with assessing large language models trained specifically on programming code.&lt;SEP&gt;The text explores the correctness of various code completions for counting vowels and multiplying numbers, assessing their accuracy and logic.&lt;SEP&gt;This is the main topic of the document, focusing on assessing large language models trained specifically on code, their capabilities, limitations, and implications.&lt;SEP&gt;This text examines the correctness and logic of multiple code implementations aimed at counting vowels and multiplying numbers, assessing their accuracy and reasoning.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c&lt;SEP&gt;chunk-b15d5bb768f451028654d71370cc6879&lt;SEP&gt;chunk-b089b4639ea075693b83629858196628&lt;SEP&gt;chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b&lt;SEP&gt;chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="arXiv">
  <data key="d0">arXiv</data>
  <data key="d1">&lt;Tools</data>
  <data key="d2">A preprint repository hosting research papers on AI, code models, and related topics.&lt;SEP&gt;Repository for preprints on AI, machine learning, and code models.&lt;SEP&gt;Repository hosting preprints of scientific papers on AI and related topics.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Neural Code Generation">
  <data key="d0">Neural Code Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Using neural network models to generate or synthesize source code from input data or specifications.&lt;SEP&gt;Using neural network-based models to synthesize or generate source code from input data or prompts.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="High-Performance Computing">
  <data key="d0">High-Performance Computing</data>
  <data key="d1">&lt;Disciplines</data>
  <data key="d2">A field dedicated to large-scale computation for scientific and engineering applications.&lt;SEP&gt;A field focused on developing and utilizing supercomputers and parallel processing techniques for scientific and engineering problems.&lt;SEP&gt;A scientific discipline focused on developing and utilizing supercomputers and parallel processing techniques for complex computational tasks.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Data Race Detection">
  <data key="d0">Data Race Detection</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Detecting issues in concurrent programs where multiple processes access shared data simultaneously, leading to potential bugs.&lt;SEP&gt;Identifying concurrent programming issues where multiple processes access shared data simultaneously, leading to unpredictable results.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Summarization from a Small Dataset">
  <data key="d0">Code Summarization from a Small Dataset</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approaches focusing on training models effectively with limited data for source code summarization.&lt;SEP&gt;Approaches that focus on training models with limited data to effectively summarize source code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Wasi Uddin Ahmad">
  <data key="d0">Wasi Uddin Ahmad</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher investigating transformer-based approaches for source code summarization.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Saikat Chakraborty">
  <data key="d0">Saikat Chakraborty</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher investigating transformer-based approaches for source code summarization.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Baishakhi Ray">
  <data key="d0">Baishakhi Ray</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher investigating transformer-based approaches for source code summarization.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Kai-Wei Chang">
  <data key="d0">Kai-Wei Chang</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher investigating transformer-based approaches for source code summarization.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Toufique Ahmed">
  <data key="d0">Toufique Ahmed</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher exploring learning techniques for code summarization from small datasets.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Prem Devanbu">
  <data key="d0">Prem Devanbu</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher exploring learning techniques for code summarization from small datasets.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jacob Austin">
  <data key="d0">Jacob Austin</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher studying program synthesis using large language models to generate or complete code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Augustus Odena">
  <data key="d0">Augustus Odena</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher studying program synthesis using large language models to generate or complete code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Maxwell I. Nye">
  <data key="d0">Maxwell I. Nye</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher studying program synthesis using large language models to generate or complete code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Maarten Bosma">
  <data key="d0">Maarten Bosma</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in scaling language models with pathway techniques.&lt;SEP&gt;Researcher studying program synthesis using large language models to generate or complete code.&lt;SEP&gt;Researcher working on scaling models with pathway architectures.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Henryk Michalewski">
  <data key="d0">Henryk Michalewski</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher studying program synthesis using large language models to generate or complete code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="David Dohan">
  <data key="d0">David Dohan</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher studying program synthesis using large language models to generate or complete code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Ellen Jiang">
  <data key="d0">Ellen Jiang</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher studying program synthesis using large language models to generate or complete code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Carrie J. Cai">
  <data key="d0">Carrie J. Cai</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher studying program synthesis using large language models to generate or complete code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Michael Terry">
  <data key="d0">Michael Terry</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher studying program synthesis using large language models to generate or complete code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Quoc V. Le">
  <data key="d0">Quoc V. Le</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher studying program synthesis using large language models to generate or complete code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Charles Sutton">
  <data key="d0">Charles Sutton</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher studying program synthesis using large language models to generate or complete code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Tom B. Brown">
  <data key="d0">Tom B. Brown</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher evaluating the capabilities of large language models as few-shot learners across various tasks.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CoRR">
  <data key="d0">CoRR</data>
  <data key="d1">&lt;Tools</data>
  <data key="d2">An open-access preprint repository hosting research papers on AI, machine learning, and related fields.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="abs/2005.14165">
  <data key="d0">abs/2005.14165</data>
  <data key="d1">&lt;Evidence Types</data>
  <data key="d2">A specific identifier for the paper "Language Models are Few-Shot Learners" indicating its arXiv preprint version.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="abs/2108.07732">
  <data key="d0">abs/2108.07732</data>
  <data key="d1">&lt;Evidence Types</data>
  <data key="d2">A specific identifier for the paper "Program Synthesis with Large Language Models" indicating its arXiv preprint version.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Le Chen">
  <data key="d0">Le Chen</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher investigating data race detection using large language models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Xianzhong Ding">
  <data key="d0">Xianzhong Ding</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher investigating data race detection using large language models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Murali Emani">
  <data key="d0">Murali Emani</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher investigating data race detection using large language models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Tristan Vanderbruggen">
  <data key="d0">Tristan Vanderbruggen</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher investigating data race detection using large language models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Pei Hung Lin">
  <data key="d0">Pei Hung Lin</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher investigating data race detection using large language models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Chunhua Liao">
  <data key="d0">Chunhua Liao</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher investigating data race detection using large language models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Bronis de Supinski">
  <data key="d0">Bronis de Supinski</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Researcher investigating data race detection using large language models.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Mark Chen">
  <data key="d0">Mark Chen</data>
  <data key="d1">Researchers</data>
  <data key="d2">One of the primary authors involved in the study, contributing to the investigation and analysis of Codex and related models.&lt;SEP&gt;Researcher evaluating large language models trained on code datasets.&lt;SEP&gt;Researcher evaluating large language models trained on code, contributing to AI and machine learning evaluation methodologies.&lt;SEP&gt;Researcher evaluating large language models trained on code, contributing to AI model assessment methodologies.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad&lt;SEP&gt;chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="et al.">
  <data key="d0">et al.</data>
  <data key="d1">&lt;Research Questions/Hypotheses</data>
  <data key="d2">Indicates multiple authors contributing to the research evaluating large language models on code.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, Wojciech Zaremba">
  <data key="d0">Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, Wojciech Zaremba</data>
  <data key="d1">Research Team</data>
  <data key="d2">A group of researchers involved in the development and evaluation of large language models, particularly trained on code, and their performance assessment.&lt;SEP&gt;A group of researchers involved in the study of large language models and AI evaluation.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:arXiv:2107.03374">
  <data key="d0">arXiv:arXiv:2107.03374</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">Preprint publication on arXiv presenting initial findings of the evaluation study.&lt;SEP&gt;Preprint publication on arXiv providing preliminary research findings.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman">
  <data key="d0">Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman</data>
  <data key="d1">Research Team</data>
  <data key="d2">A group of researchers focusing on training verifiers for solving math word problems.&lt;SEP&gt;Researchers working on training models to verify solutions to math word problems.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Training Verifiers to Solve Math Word Problems">
  <data key="d0">Training Verifiers to Solve Math Word Problems</data>
  <data key="d1">Study</data>
  <data key="d2">Research on developing and training models to verify solutions to math problems.&lt;SEP&gt;Research on developing models capable of verifying and solving math word problems effectively.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Xueying Du, Mingwei Liu, Kaixin Wang, Hanlin Wang, Junwei Liu, Yixuan Chen, Jiayi Feng, Chaofeng Sha, Xin Peng, Yiling Lou">
  <data key="d0">Xueying Du, Mingwei Liu, Kaixin Wang, Hanlin Wang, Junwei Liu, Yixuan Chen, Jiayi Feng, Chaofeng Sha, Xin Peng, Yiling Lou</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers creating benchmarks to evaluate language models' performance in class-level code generation.&lt;SEP&gt;Researchers working on benchmarking and evaluating language models on code generation tasks.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation">
  <data key="d0">ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation</data>
  <data key="d1">Study</data>
  <data key="d2">A benchmark designed to evaluate language models' performance on class-level code generation.&lt;SEP&gt;Development of a benchmark for assessing language models' ability to generate class-level code.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2308.01861">
  <data key="d0">arXiv:2308.01861</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">Preprint publication describing the benchmark and evaluation results.&lt;SEP&gt;Preprint publication on arXiv detailing the benchmark and evaluation results.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, Connor Leahy">
  <data key="d0">Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, Connor Leahy</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers involved in compiling large diverse datasets for language modeling.&lt;SEP&gt;Researchers involved in creating a large diverse text dataset for language modeling.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="The Pile: An 800GB Dataset of Diverse Text for Language Modeling">
  <data key="d0">The Pile: An 800GB Dataset of Diverse Text for Language Modeling</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large dataset compiled for training and evaluating language models.&lt;SEP&gt;A large, diverse textual dataset used for training and evaluating language models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2101.00027">
  <data key="d0">arXiv:2101.00027</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">Preprint publication describing the dataset and its composition.&lt;SEP&gt;Preprint publication describing the dataset.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig">
  <data key="d0">Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers developing program-aided language models to improve performance and capabilities.&lt;SEP&gt;Researchers working on program-aided language models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="PAL: Program-aided Language Models">
  <data key="d0">PAL: Program-aided Language Models</data>
  <data key="d1">Methodology</data>
  <data key="d2">A framework integrating program-like structures into language models to improve reasoning and problem-solving capabilities.&lt;SEP&gt;A methodology that integrates program-like structures and external tools into language models to enhance reasoning and problem-solving.&lt;SEP&gt;An approach integrating programming and code understanding into language models to enhance their performance.&lt;SEP&gt;An approach that incorporates programming and code understanding into language models to enhance their capabilities.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2211.10435">
  <data key="d0">arXiv:2211.10435</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">Preprint publication on arXiv presenting the PAL methodology.&lt;SEP&gt;Preprint publication presenting the PAL methodology and experimental results.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Spandan Garg, Roshanak Zilouchian Moghaddam, Colin B. Clement, Neel Sundaresan, Chen Wu">
  <data key="d0">Spandan Garg, Roshanak Zilouchian Moghaddam, Colin B. Clement, Neel Sundaresan, Chen Wu</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers developing deep learning approaches to improve software performance.&lt;SEP&gt;Researchers focusing on deep learning approaches to improve software performance.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="DeepDev-PERF: a deep learning-based approach for improving software performance">
  <data key="d0">DeepDev-PERF: a deep learning-based approach for improving software performance</data>
  <data key="d1">Study</data>
  <data key="d2">Research applying deep learning techniques to optimize software performance metrics.&lt;SEP&gt;Research on applying deep learning techniques to optimize software performance.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering">
  <data key="d0">Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference proceedings where research on software engineering methodologies like Deepdev-perf are published.&lt;SEP&gt;Conference proceedings documenting the DeepDev-PERF approach.&lt;SEP&gt;Conference publication documenting the approach.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0&lt;SEP&gt;chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="William Godoy, Pedro Valero-Lara, Keita Teranishi, Prasanna Balaprakash, Jeffrey Vetter">
  <data key="d0">William Godoy, Pedro Valero-Lara, Keita Teranishi, Prasanna Balaprakash, Jeffrey Vetter</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers evaluating OpenAI Codex for high-performance computing kernel generation.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Evaluation of OpenAI Codex for HPC Parallel Programming Models Kernel Generation">
  <data key="d0">Evaluation of OpenAI Codex for HPC Parallel Programming Models Kernel Generation</data>
  <data key="d1">Study</data>
  <data key="d2">Assessment of Codex's effectiveness in generating HPC kernels for parallel programming.&lt;SEP&gt;Assessment of Codex's effectiveness in generating HPC kernels.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Proceedings of the 52nd International Conference on Parallel Processing Workshops">
  <data key="d0">Proceedings of the 52nd International Conference on Parallel Processing Workshops</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">Conference proceedings presenting the evaluation results.&lt;SEP&gt;Conference proceedings with evaluation results.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jian Gu, Pasquale Salza, Harald C. Gall">
  <data key="d0">Jian Gu, Pasquale Salza, Harald C. Gall</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers working on assembling foundation models for automatic code summarization.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Assemble Foundation Models for Automatic Code Summarization">
  <data key="d0">Assemble Foundation Models for Automatic Code Summarization</data>
  <data key="d1">Study</data>
  <data key="d2">Research on creating models capable of automatically summarizing source code.&lt;SEP&gt;Research on creating models that can generate summaries of source code.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)">
  <data key="d0">2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">Conference publication describing the model assembly process.&lt;SEP&gt;Conference publication detailing the methodology and results of code summarization models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sakib Haque, Zachary Eberhart, Aakash Bansal, Collin McMillan">
  <data key="d0">Sakib Haque, Zachary Eberhart, Aakash Bansal, Collin McMillan</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers developing semantic similarity metrics for evaluating source code summaries.&lt;SEP&gt;Researchers developing semantic similarity metrics to evaluate source code summaries.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Semantic Similarity Metrics for Evaluating Source Code Summarization">
  <data key="d0">Semantic Similarity Metrics for Evaluating Source Code Summarization</data>
  <data key="d1">Study</data>
  <data key="d2">Research on metrics to assess the quality of code summaries.&lt;SEP&gt;Research on metrics used to assess the quality and accuracy of source code summaries.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="2022 IEEE/ACM 30th International Conference on Program Comprehension">
  <data key="d0">2022 IEEE/ACM 30th International Conference on Program Comprehension</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">Conference publication presenting the evaluation metrics and results.&lt;SEP&gt;Conference publication with evaluation results.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi">
  <data key="d0">Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers exploring issues related to neural text degeneration and language model output quality.&lt;SEP&gt;Researchers exploring issues related to neural text degeneration.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="The Curious Case of Neural Text Degeneration">
  <data key="d0">The Curious Case of Neural Text Degeneration</data>
  <data key="d1">Study</data>
  <data key="d2">Research investigating why neural language models produce degenerate or poor-quality text.&lt;SEP&gt;Research on problems and phenomena related to language model text generation quality.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="International Conference on Learning Representations">
  <data key="d0">International Conference on Learning Representations</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference where research on learning representations, including code and speech, is presented and evaluated.&lt;SEP&gt;Conference publication presenting the findings on neural text degeneration.&lt;SEP&gt;Conference publication presenting the study.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb&lt;SEP&gt;chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Weizhu Chen">
  <data key="d0">Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Weizhu Chen</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers developing LoRA, a low-rank adaptation method for large language models.&lt;SEP&gt;Researchers developing LoRA, a low-rank adaptation technique for large language models.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="LoRA: Low-Rank Adaptation of Large Language Models">
  <data key="d0">LoRA: Low-Rank Adaptation of Large Language Models</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique to efficiently adapt and fine-tune large language models using low-rank matrices.&lt;SEP&gt;A technique to efficiently adapt large language models using low-rank matrices.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2106.09685">
  <data key="d0">arXiv:2106.09685</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">Preprint publication on arXiv detailing LoRA.&lt;SEP&gt;Preprint publication on arXiv detailing the LoRA methodology.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Tal Kadosh, Niranjan Hasabnis, Vy A. Vo, Nadav Schneider, Neva Krien, Abdul Wasay, Nesreen Ahmed, Ted Willke, Guy Tamir, Yuval Pinter, Timothy Mattson, Gal Oren">
  <data key="d0">Tal Kadosh, Niranjan Hasabnis, Vy A. Vo, Nadav Schneider, Neva Krien, Abdul Wasay, Nesreen Ahmed, Ted Willke, Guy Tamir, Yuval Pinter, Timothy Mattson, Gal Oren</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers transforming LLMs for high-performance computing code.&lt;SEP&gt;Researchers working on transforming language models for high-performance computing (HPC) code generation.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Scope is all you need: Transforming LLMs for HPC Code">
  <data key="d0">Scope is all you need: Transforming LLMs for HPC Code</data>
  <data key="d1">Study</data>
  <data key="d2">Research on adapting language models specifically for HPC code generation.&lt;SEP&gt;Research on adapting large language models specifically for HPC code and applications.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:2308.09440">
  <data key="d0">arXiv:2308.09440</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">Preprint publication on arXiv detailing the transformation techniques.&lt;SEP&gt;Preprint publication on arXiv.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Md Abul Kalam Azad, Nafees Iqbal, Foyzul Hassan, Probir Roy">
  <data key="d0">Md Abul Kalam Azad, Nafees Iqbal, Foyzul Hassan, Probir Roy</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers conducting empirical studies on bugs affecting high-performance computing (HPC) systems.&lt;SEP&gt;Researchers studying high-performance computing (HPC) performance bugs.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="An Empirical Study of High Performance Computing (HPC) Performance Bugs">
  <data key="d0">An Empirical Study of High Performance Computing (HPC) Performance Bugs</data>
  <data key="d1">Study</data>
  <data key="d2">Empirical analysis of bugs impacting HPC system performance and stability.&lt;SEP&gt;Empirical research analyzing bugs affecting HPC system performance.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="2023 IEEE/ACM 20th International Conference on Mining Software Repositories">
  <data key="d0">2023 IEEE/ACM 20th International Conference on Mining Software Repositories</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">Conference publication presenting the empirical study results.&lt;SEP&gt;Conference publication presenting the empirical study.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Anant Kharkar, Roshanak Zilouchian Moghaddam, Matthew Jin, Xiaoyu Liu, Xin Shi, Colin B. Clement, Neel Sundaresan">
  <data key="d0">Anant Kharkar, Roshanak Zilouchian Moghaddam, Matthew Jin, Xiaoyu Liu, Xin Shi, Colin B. Clement, Neel Sundaresan</data>
  <data key="d1">Research Team</data>
  <data key="d2">Researchers working on reducing false positives in analytic bug detectors.&lt;SEP&gt;Researchers working on reducing false positives in static and dynamic bug detection tools.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Learning to Reduce False Positives in Analytic Bug Detectors">
  <data key="d0">Learning to Reduce False Positives in Analytic Bug Detectors</data>
  <data key="d1">Study</data>
  <data key="d2">Research on improving bug detection accuracy by reducing false positives in analytic tools.&lt;SEP&gt;Research on methods to improve bug detection accuracy.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="2022 IEEE/ACM 44th International Conference on Software Engineering">
  <data key="d0">2022 IEEE/ACM 44th International Conference on Software Engineering</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">Conference publication with research findings on bug detection improvements.&lt;SEP&gt;Conference publication with research findings.</data>
  <data key="d3">chunk-71987847f5d7f5bd36428e254673c5cb</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Anant Kharkar">
  <data key="d0">Anant Kharkar</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Anant Kharkar is an author involved in research on reducing false positives in analytic bug detectors.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Roshanak Zilouchian Moghaddam">
  <data key="d0">Roshanak Zilouchian Moghaddam</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Roshanak Zilouchian Moghaddam is an author contributing to research on bug detection and software engineering.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Matthew Jin">
  <data key="d0">Matthew Jin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Matthew Jin is an author associated with research on software analytics and bug detection methodologies.&lt;SEP&gt;Matthew Jin is an author associated with research on software analytics.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Xiaoyu Liu">
  <data key="d0">Xiaoyu Liu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Xiaoyu Liu is an author involved in software engineering research, particularly in bug detection.&lt;SEP&gt;Xiaoyu Liu is an author involved in software engineering research.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Xin Shi">
  <data key="d0">Xin Shi</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Xin Shi is an author contributing to studies on bug detection methodologies.&lt;SEP&gt;Xin Shi is an author working on analytic bug detectors and reducing false positives.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Colin B. Clement">
  <data key="d0">Colin B. Clement</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Colin B. Clement is an author contributing to machine learning applications in software engineering.&lt;SEP&gt;Colin B. Clement is an author working on software analytics and machine learning applications.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Neel Sundaresan">
  <data key="d0">Neel Sundaresan</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Neel Sundaresan is an author involved in research on software analytics and bug detection.&lt;SEP&gt;Neel Sundaresan is an author involved in research on software engineering and analytics.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Denis Kocetkov">
  <data key="d0">Denis Kocetkov</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Denis Kocetkov is an author contributing to research on large-scale source code datasets.&lt;SEP&gt;Denis Kocetkov is an author working on large-scale source code datasets and licensing issues.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Raymond Li">
  <data key="d0">Raymond Li</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Raymond Li is an author contributing to data science and large code repositories.&lt;SEP&gt;Raymond Li is an author involved in data science and source code analysis.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Loubna Ben Allal">
  <data key="d0">Loubna Ben Allal</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Loubna Ben Allal is an author involved in licensing and analysis of large source code datasets.&lt;SEP&gt;Loubna Ben Allal is an author working on source code datasets and licensing.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jia Li">
  <data key="d0">Jia Li</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in language model fine-tuning and efficiency.&lt;SEP&gt;Jia Li is an author associated with source code and data analysis.&lt;SEP&gt;Jia Li is an author working on source code datasets and analysis.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Chenghao Mou">
  <data key="d0">Chenghao Mou</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Chenghao Mou is an author involved in software engineering and data analysis.&lt;SEP&gt;Chenghao Mou is an author involved in source code analysis and dataset creation.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Carlos Muñoz Ferrandis">
  <data key="d0">Carlos Muñoz Ferrandis</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Carlos Muñoz Ferrandis is an author contributing to source code research.&lt;SEP&gt;Carlos Muñoz Ferrandis is an author working on source code datasets and licensing issues.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Margaret Mitchell">
  <data key="d0">Margaret Mitchell</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Margaret Mitchell is an author working on AI ethics and data analysis.&lt;SEP&gt;Margaret Mitchell is an author working on AI ethics and responsible AI research.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Sean Hughes">
  <data key="d0">Sean Hughes</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Sean Hughes is an author contributing to AI and software engineering research.&lt;SEP&gt;Sean Hughes is an author involved in AI and software engineering research.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Dzmitry Bahdanau">
  <data key="d0">Dzmitry Bahdanau</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dzmitry Bahdanau is an author working on neural network architectures and machine learning.&lt;SEP&gt;Dzmitry Bahdanau is an author working on neural networks and machine learning.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Leandro von Werra">
  <data key="d0">Leandro von Werra</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Leandro von Werra is an author involved in AI research and software analysis.&lt;SEP&gt;Leandro von Werra is an author involved in AI research and software engineering.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Harm de Vries">
  <data key="d0">Harm de Vries</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Harm de Vries is an author contributing to AI and software engineering research.&lt;SEP&gt;Harm de Vries is an author contributing to AI research and model development.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="StarCoder">
  <data key="d0">StarCoder</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">StarCoder is a large language model designed for source code generation, inspired by the Star Wars theme, aiming to generate code effectively.&lt;SEP&gt;StarCoder is a large language model designed for source code generation, inspired by the Star Wars universe.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="VerilogEval">
  <data key="d0">VerilogEval</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">VerilogEval is a benchmark dataset for evaluating large language models' performance on Verilog hardware description language code generation tasks.&lt;SEP&gt;VerilogEval is a benchmark dataset used to evaluate the performance of language models on Verilog code generation tasks.&lt;SEP&gt;VerilogEval is a benchmark for evaluating large language models' performance in Verilog hardware description language code generation.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="LLM4VV">
  <data key="d0">LLM4VV</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">LLM4VV is a framework for developing large language model-driven test suites for compiler validation.&lt;SEP&gt;LLM4VV is a framework or benchmark for testing large language models' ability to validate compilers and generate code.&lt;SEP&gt;LLM4VV is a framework or dataset for testing large language models' capabilities in compiler validation.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Modeling Parallel Programs">
  <data key="d0">Modeling Parallel Programs</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A conceptual framework or approach for representing, analyzing, and automating parallel programs in HPC, leveraging language models to assist developers and predict performance.&lt;SEP&gt;A framework or approach for representing and analyzing parallel programs, particularly in the context of HPC, using language models to automate tasks and predict performance.&lt;SEP&gt;A methodology for representing and analyzing parallel programs using large language models to understand concurrency and performance.&lt;SEP&gt;A methodology for representing parallel programs using large language models to analyze and simulate their behavior.&lt;SEP&gt;A methodology or framework for representing and analyzing parallel programs using large language models.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718&lt;SEP&gt;chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenAI Python API library">
  <data key="d0">OpenAI Python API library</data>
  <data key="d1">Tools</data>
  <data key="d2">A Python library for interfacing with OpenAI's models, enabling integration into software applications.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="OpenMP4 2013">
  <data key="d0">OpenMP4 2013</data>
  <data key="d1">Tools</data>
  <data key="d2">OpenMP 4.0 is an API for parallel programming in shared memory environments, facilitating multi-threaded application development.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Phind-CodeLlama-34B-v2">
  <data key="d0">Phind-CodeLlama-34B-v2</data>
  <data key="d1">Tools</data>
  <data key="d2">A large language model specialized for code understanding and generation, available on Hugging Face platform.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="NVIDIA CUDA 10.2.89">
  <data key="d0">NVIDIA CUDA 10.2.89</data>
  <data key="d1">Tools</data>
  <data key="d2">CUDA version 10.2.89 is a toolkit for GPU-accelerated computing, enabling high-performance parallel processing.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Source Code Datasets">
  <data key="d0">Source Code Datasets</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Large datasets of source code, such as permissively licensed repositories, used for training and evaluating AI models.&lt;SEP&gt;Large datasets of source code, such as the permissively licensed code corpus, used for training and evaluating AI models.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Permissively Licensed Source Code">
  <data key="d0">Permissively Licensed Source Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large corpus of source code with permissive licenses, used for AI training and research.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Data Science Code Benchmark DS-1000">
  <data key="d0">Data Science Code Benchmark DS-1000</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark dataset for evaluating data science code generation models.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Program Models">
  <data key="d0">Parallel Program Models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Models and frameworks for representing and analyzing parallel programs using large language models.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Compiler Validation Test Suite">
  <data key="d0">Compiler Validation Test Suite</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A test suite developed using LLMs to validate compiler correctness and behavior.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Performance Deep Learning">
  <data key="d0">Performance Deep Learning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Performance Deep Learning involves applying deep learning techniques to improve performance across various tasks, emphasizing model training, data processing, and optimization.&lt;SEP&gt;Performance Deep Learning refers to the application of deep learning techniques to enhance and optimize performance in various domains, often involving complex data processing and model training.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="arXiv:1912.01703 [cs.LG]">
  <data key="d0">arXiv:1912.01703 [cs.LG]</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint paper presenting research on performance deep learning methodologies and applications.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Phind">
  <data key="d0">Phind</data>
  <data key="d1">Tools</data>
  <data key="d2">Phind-CodeLlama-34B-v2 is a language model designed for code generation and understanding, available on Hugging Face.&lt;SEP&gt;Phind-CodeLlama-34B-v2 is a large language model designed for code understanding and generation, hosted on Hugging Face for use in AI and software development tasks.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Cedric Richter and Heike Wehrheim">
  <data key="d0">Cedric Richter and Heike Wehrheim</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigate whether learning from developer mistakes can enhance bug localization and repair processes in software engineering.&lt;SEP&gt;Investigate whether learning from developer mistakes can improve bug localization and repair techniques.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Learning to localize and repair real bugs from real bug fixes">
  <data key="d0">Learning to localize and repair real bugs from real bug fixes</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A research study focused on analyzing real-world bug fixes to improve bug localization and automated repair techniques.&lt;SEP&gt;A study exploring methods to identify and fix real software bugs based on actual bug fix data.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Baptiste Rozière, Jonas Gehring, et al.">
  <data key="d0">Baptiste Rozière, Jonas Gehring, et al.</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Development of Code Llama, an open foundation model for code understanding and generation, based on large-scale training.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Code Llama: Open Foundation Models for Code">
  <data key="d0">Code Llama: Open Foundation Models for Code</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model architecture designed for code-related tasks, leveraging foundation model techniques for improved performance.&lt;SEP&gt;A set of models and architectures designed for code comprehension and generation, leveraging foundation model techniques for improved accuracy and versatility.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="M. Snir">
  <data key="d0">M. Snir</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Authoritative reference on MPI (Message Passing Interface), detailing its core functionalities for parallel and distributed computing.&lt;SEP&gt;Provides comprehensive reference material on MPI (Message Passing Interface), a core technology for parallel computing.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Xiangru Tang, Bill Qian, Rick Gao, et al.">
  <data key="d0">Xiangru Tang, Bill Qian, Rick Gao, et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Assess the effectiveness of BioCoder as a benchmark for bioinformatics code generation using contextual pragmatic knowledge.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge">
  <data key="d0">BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark dataset and framework for evaluating bioinformatics code generation models.&lt;SEP&gt;A benchmarking framework and dataset for assessing bioinformatics code generation models' performance in practical scenarios.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Hugo Touvron et al.">
  <data key="d0">Hugo Touvron et al.</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Development of Llama 2, an open foundation and fine-tuned chat model for various NLP tasks.&lt;SEP&gt;Development of Llama 2, an open foundation and fine-tuned language model for NLP tasks, emphasizing accessibility and adaptability.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Llama 2: Open Foundation and Fine-Tuned Chat Models">
  <data key="d0">Llama 2: Open Foundation and Fine-Tuned Chat Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A large language model architecture designed for versatile natural language processing, emphasizing open access and fine-tuning.&lt;SEP&gt;A large-scale transformer-based language model architecture designed for versatile NLP applications, supporting open access and customization.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Christian R. Trott, Damien Lebrun-Grandié, et al.">
  <data key="d0">Christian R. Trott, Damien Lebrun-Grandié, et al.</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Extension of programming models via Kokkos 3 to support exascale computing, focusing on parallel and distributed systems.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Kokkos 3: Programming Model Extensions for the Exascale Era">
  <data key="d0">Kokkos 3: Programming Model Extensions for the Exascale Era</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A set of programming model extensions aimed at enabling scalable high-performance computing on exascale systems.&lt;SEP&gt;A set of programming model extensions designed to enable scalable and efficient exascale computing through advanced parallel programming abstractions.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Pedro Valero-Lara, Alexis Huante, Mustafa Al Lail, et al.">
  <data key="d0">Pedro Valero-Lara, Alexis Huante, Mustafa Al Lail, et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Compare the performance of Llama-2 and GPT-3 in generating HPC kernels to evaluate their suitability for high-performance computing tasks.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation">
  <data key="d0">Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A comparative study evaluating two large language models' effectiveness in generating HPC kernels to inform their suitability for scientific computing.&lt;SEP&gt;A study examining the capabilities of two large language models in generating high-performance computing kernels.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Hao Yu, Bo Shen, Dezhi Ran, et al.">
  <data key="d0">Hao Yu, Bo Shen, Dezhi Ran, et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Assess the pragmatic performance of code generation models across different tasks and benchmarks.&lt;SEP&gt;Evaluate the pragmatic and real-world performance of code generation models across multiple benchmarks, including CoderEval.&lt;SEP&gt;Evaluate the pragmatic code generation performance of various large language models using the CoderEval benchmark.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models">
  <data key="d0">CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark framework designed to assess the pragmatic code generation abilities of different pre-trained language models.&lt;SEP&gt;A benchmark framework designed to evaluate the pragmatic and practical code generation capabilities of multiple pre-trained language models across diverse tasks.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Attention Is All You Need">
  <data key="d0">Attention Is All You Need</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A foundational Transformer model architecture that introduced the attention mechanism as the core component for sequence modeling.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Transformers: State-of-the-Art Natural Language Processing">
  <data key="d0">Transformers: State-of-the-Art Natural Language Processing</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A comprehensive overview of Transformer models and their impact on NLP, highlighting their architecture and applications.&lt;SEP&gt;A comprehensive overview of Transformer models, their architecture, and their revolutionary impact on NLP and sequence modeling.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Frank F. Xu, Uri Alon, Graham Neubig, and Vincent J. Hellendoorn">
  <data key="d0">Frank F. Xu, Uri Alon, Graham Neubig, and Vincent J. Hellendoorn</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Systematically evaluate the performance of large language models of code to identify strengths and limitations.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="A Systematic Evaluation of Large Language Models of Code">
  <data key="d0">A Systematic Evaluation of Large Language Models of Code</data>
  <data key="d1">Results</data>
  <data key="d2">Provides detailed insights into the performance, accuracy, and practical limitations of current large language models for code synthesis and understanding.&lt;SEP&gt;Provides insights into the capabilities, accuracy, and limitations of current large language models for code generation.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Performance Deep Learning Library">
  <data key="d0">Performance Deep Learning Library</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A software library facilitating deep learning research and application development, referenced in multiple research works.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Library. arXiv:1912.01703 [cs.LG]">
  <data key="d0">Library. arXiv:1912.01703 [cs.LG]</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint publication presenting research findings and methodologies related to performance deep learning applications.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Xiangru Tang, Bill Qian, Rick Gao, Jiakang Chen, Xinyun Chen, Mark Gerstein">
  <data key="d0">Xiangru Tang, Bill Qian, Rick Gao, Jiakang Chen, Xinyun Chen, Mark Gerstein</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Evaluate the effectiveness of BioCoder as a benchmark for bioinformatics code generation utilizing contextual pragmatic knowledge.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Christian R. Trott, Damien Lebrun-Grandié, Daniel Arndt, Jan Ciesko, Vinh Dang, Nathan Ellingwood, Rahulkumar Gayatri, Evan Harvey, Daisy S. Hollman, Dan Ibanez, Nevin Liber, Jonathan Madsen, Jeff Miles, David Poliakoff, Amy Powell, Sivasankaran Rajamanickam, Mikael Simberg, Dan Sunderland, Bruno Turcksin, Jeremiah Wilke">
  <data key="d0">Christian R. Trott, Damien Lebrun-Grandié, Daniel Arndt, Jan Ciesko, Vinh Dang, Nathan Ellingwood, Rahulkumar Gayatri, Evan Harvey, Daisy S. Hollman, Dan Ibanez, Nevin Liber, Jonathan Madsen, Jeff Miles, David Poliakoff, Amy Powell, Sivasankaran Rajamanickam, Mikael Simberg, Dan Sunderland, Bruno Turcksin, Jeremiah Wilke</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Extension of programming models via Kokkos 3 to support exascale computing, focusing on high-performance parallel and distributed system programming.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Pedro Valero-Lara, Alexis Huante, Mustafa Al Lail, William F. Godoy, Keita Teranishi, Prasanna Balaprakash, Jeffrey S. Vetter">
  <data key="d0">Pedro Valero-Lara, Alexis Huante, Mustafa Al Lail, William F. Godoy, Keita Teranishi, Prasanna Balaprakash, Jeffrey S. Vetter</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Compare the performance and capabilities of Llama-2 and GPT-3 large language models in generating HPC (High-Performance Computing) kernels for efficiency and accuracy.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Hao Yu, Bo Shen, Dezhi Ran, Jiaxin Zhang, Qi Zhang, Yuchi Ma, Guangtai Liang, Ying Li, Tao Xie, Qianxiang Wang">
  <data key="d0">Hao Yu, Bo Shen, Dezhi Ran, Jiaxin Zhang, Qi Zhang, Yuchi Ma, Guangtai Liang, Ying Li, Tao Xie, Qianxiang Wang</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Assess the pragmatic code generation performance of various large language models using the CoderEval benchmark, focusing on real-world applicability.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="H. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, I. Polosukhin">
  <data key="d0">H. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, I. Polosukhin</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Introduction of the Transformer architecture emphasizing attention mechanisms as the core component for sequence modeling in NLP.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Frank F. Xu, Uri Alon, Graham Neubig, Vincent J. Hellendoorn">
  <data key="d0">Frank F. Xu, Uri Alon, Graham Neubig, Vincent J. Hellendoorn</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Conduct a systematic evaluation of large language models of code to determine their strengths, limitations, and suitability for various programming tasks.</data>
  <data key="d3">chunk-764fdbb8cfee52f0f6d62be5589676f9</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Tasks">
  <data key="d0">Tasks</data>
  <data key="d3">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d2">Different tasks' complexity influences the evaluation of model performance and capability."|&gt;"difficulty, assessment</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Benchmarks">
  <data key="d0">Benchmarks</data>
  <data key="d3">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d2">Benchmarks are designed to evaluate the performance of LLMs in generating parallel code, covering various computational problem types and execution models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Kadosh et al.">
  <data key="d0">Kadosh et al.</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d2">Kadosh et al. introduce TOKOMPILER, an HPC-specific tokenizer, and use it to train COMPCODER.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Content">
  <data key="d0">Content</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d2">ParEval is a benchmark designed to evaluate LLMs' ability to generate parallel code across various problem types and execution models, using standardized prompts and evaluation techniques.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="content_keywords">
  <data key="d0">content_keywords</data>
  <data key="d3">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d2">ParEval is a benchmark designed to evaluate LLMs' ability to generate parallel code across various problem types and execution models, using standardized prompts and evaluation techniques.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Component counting">
  <data key="d0">Component counting</data>
  <data key="d3">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d2">Component counting is used within geometric analysis to quantify elements like points or shapes, essential for geometric computations."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Study Design">
  <data key="d0">Study Design</data>
  <data key="d3">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d2">The experiment aims to evaluate how well models can translate code between specified pairs of execution models.&lt;SEP&gt;The experiment evaluates the ability of LLMs to translate code between specified pairs of execution models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Resources">
  <data key="d0">Resources</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d2">Parallel code relies on computational resources such as processes or threads to execute operations simultaneously."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Hardware cores">
  <data key="d0">Hardware cores</data>
  <data key="d3">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d2">Resources include hardware cores, which are physical units that support parallel execution."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="benchmarks (HumanEval, MBPP, DS-1000)">
  <data key="d0">benchmarks (HumanEval, MBPP, DS-1000)</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d2">The benchmarks are used to measure speedup1@𝑘, which helps compare the efficiency of generated code against human baselines, providing insights into code quality and performance.&lt;SEP&gt;These benchmarks are used to measure speedup1@𝑘, comparing generated code performance to human baselines."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="performance evaluation process">
  <data key="d0">performance evaluation process</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d2">The ParEval test harness compiles, runs, and evaluates generated code, recording correctness and execution times to assess performance."|&lt;|"evaluation methodology, correctness verification&lt;SEP&gt;The test harness automates compilation, execution, and correctness verification of generated code, recording performance metrics."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="GCC, OpenMP, Kokkos, MPI, CUDA, HIP">
  <data key="d0">GCC, OpenMP, Kokkos, MPI, CUDA, HIP</data>
  <data key="d3">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d2">Various compiler and parallelization tools are used within the test harness to compile and run generated code across different hardware and software configurations."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Process Counts">
  <data key="d0">Process Counts</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">Efficiency is analyzed across different process and thread counts to assess scalability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="GPU Performance">
  <data key="d0">GPU Performance</data>
  <data key="d3">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d2">Kernel threads are a key factor in measuring GPU parallel performance and efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Benchmarking Platform">
  <data key="d0">Benchmarking Platform</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d2">Serves as a platform to benchmark and compare large code models."|&gt;"benchmarking, model evaluation</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Documentation Resource">
  <data key="d0">Documentation Resource</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d2">Provides technical documentation for HIP programming environment."|&gt;"software documentation, tools</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Wasi Uddin Ahmad et al.">
  <data key="d0">Wasi Uddin Ahmad et al.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d2">Investigate transformer-based models for source code summarization."|&gt;"research, code summarization</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Jacob Austin et al.">
  <data key="d0">Jacob Austin et al.</data>
  <data key="d3">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d2">Study program synthesis using large language models."|&gt;"research, program synthesis</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="DS-1000 Benchmark">
  <data key="d0">DS-1000 Benchmark</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d2">DS-1000 is a benchmark dataset for data science code generation, designed to evaluate the performance of models in generating reliable data science code.&lt;SEP&gt;DS-1000 is designed as a reliable benchmark for data science code generation, used to evaluate model performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Yuhang Lai et al.">
  <data key="d0">Yuhang Lai et al.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d2">DS-1000 is a benchmark dataset for data science code generation, designed to evaluate the performance of models in generating reliable data science code.&lt;SEP&gt;DS-1000 is designed as a reliable benchmark for data science code generation, used to evaluate model performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Raymond Li et al.">
  <data key="d0">Raymond Li et al.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d2">They contribute to research involving large source code datasets and their licensing, analysis, and applications in AI.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Source Code Research">
  <data key="d0">Source Code Research</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d2">They contribute to research involving large source code datasets and their licensing, analysis, and applications in AI.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Mingjie Liu et al.">
  <data key="d0">Mingjie Liu et al.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d2">VerilogEval is used to evaluate large language models' performance in Verilog hardware description language code generation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Christian Munley et al.">
  <data key="d0">Christian Munley et al.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d2">They develop or utilize LLM4VV as a test suite for validating compiler outputs and behaviors using large language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Daniel Nichols et al.">
  <data key="d0">Daniel Nichols et al.</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d2">They focus on modeling parallel programs using large language models to analyze concurrency and performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Source Code Generation">
  <data key="d0">Source Code Generation</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d2">StarCoder is a large language model used specifically for source code generation tasks, inspired by sci-fi themes."|&gt;"model, source code generation</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Validation Framework">
  <data key="d0">Validation Framework</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d2">LLM4VV serves as a framework for validating compiler correctness and behavior using large language models."|&gt;"validation, compiler</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Analysis Method">
  <data key="d0">Analysis Method</data>
  <data key="d3">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d2">A methodology for representing and analyzing parallel programs with large language models to understand concurrency."|&gt;"methodology, parallel programs</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</node>
<node id="Parallel Pattern Language Code Generation">
  <data key="d0">Parallel Pattern Language Code Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A high-level approach for generating optimized parallel code using a pattern-based language, aimed at addressing heterogeneity and optimizing HPC applications.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Adrian Schmitz">
  <data key="d0">Adrian Schmitz</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author affiliated with IT Center, RWTH Aachen University, involved in developing the PPL code generator for high-performance computing.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Julian Miller">
  <data key="d0">Julian Miller</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author affiliated with IT Center, RWTH Aachen University, contributing to the development and evaluation of the PPL code generator.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Semih Burak">
  <data key="d0">Semih Burak</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author affiliated with IT Center, RWTH Aachen University, involved in the project on parallel pattern code generation.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Matthias S. Müller">
  <data key="d0">Matthias S. Müller</data>
  <data key="d1">Researchers</data>
  <data key="d2">Author affiliated with IT Center, RWTH Aachen University, working on the PPL project for scientific software optimization.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory and power constraints">
  <data key="d0">Memory and power constraints</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Fundamental limitations in high-performance computing that restrict scaling and performance, motivating hardware specialization and complex software optimization.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Heterogeneity in HPC systems">
  <data key="d0">Heterogeneity in HPC systems</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Presence of diverse hardware components like CPUs, GPUs, and NUMA architectures that complicate software development and optimization.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Non-Uniform Memory Architecture (NUMA)">
  <data key="d0">Non-Uniform Memory Architecture (NUMA)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A memory design where memory access time varies depending on the memory location relative to the processor, affecting performance and software design.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Accelerator offloading">
  <data key="d0">Accelerator offloading</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of transferring computation to specialized hardware accelerators like GPUs to improve performance and energy efficiency.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rodinia benchmark suite">
  <data key="d0">Rodinia benchmark suite</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A collection of HPC benchmarks used to evaluate the performance of the code generator and optimization techniques.&lt;SEP&gt;A comprehensive set of benchmark kernels used to evaluate performance, scalability, and correctness of parallel computing implementations.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global optimizations">
  <data key="d0">Global optimizations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Compiler techniques applied across entire applications to improve performance, such as workload assignment and code restructuring.&lt;SEP&gt;Global optimizations analyze entire programs to improve performance, concurrency, and resource utilization across heterogeneous systems.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel patterns">
  <data key="d0">Parallel patterns</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">High-level abstractions representing common parallel computation structures, used to define and optimize parallelism.&lt;SEP&gt;Parallel patterns are programming constructs that enable concurrent execution, crucial for optimizing large-scale applications.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Static global optimizations">
  <data key="d0">Static global optimizations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Optimization processes performed at compile time to enhance code performance and portability across architectures.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Assignment between tasklets and architecture">
  <data key="d0">Assignment between tasklets and architecture</data>
  <data key="d1">Variables</data>
  <data key="d2">Mapping of computational tasks (tasklets) to specific hardware resources during compile time, enabling optimized code generation.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Source code generator">
  <data key="d0">Source code generator</data>
  <data key="d1">Tools</data>
  <data key="d2">A component that automatically produces optimized source code for shared memory, distributed memory, and GPU offloading based on the parallel pattern descriptions and mappings.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Speedups in Rodinia benchmarks">
  <data key="d0">Speedups in Rodinia benchmarks</data>
  <data key="d1">Results</data>
  <data key="d2">Performance improvements achieved by the prototype, demonstrating the effectiveness of the code generator in optimizing HPC applications.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Limitations of the tool">
  <data key="d0">Limitations of the tool</data>
  <data key="d1">Limitations</data>
  <data key="d2">Challenges include analyzing dynamic algorithms and overheads during compile-time optimization, which restrict certain applications.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Heterogeneous cluster architecture">
  <data key="d0">Heterogeneous cluster architecture</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The hardware configuration comprising CPUs, GPUs, and other accelerators used for testing and optimizing code generation.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Compile-time mapping">
  <data key="d0">Compile-time mapping</data>
  <data key="d1">Variables</data>
  <data key="d2">The process of assigning tasklets to specific hardware resources during compilation to optimize execution.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance speedups">
  <data key="d0">Performance speedups</data>
  <data key="d1">Results</data>
  <data key="d2">Quantitative improvements in execution time achieved through the code generator's optimizations.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="HPC systems">
  <data key="d0">HPC systems</data>
  <data key="d1">Disciplines</data>
  <data key="d2">High-Performance Computing systems that involve complex hardware and software architectures requiring optimization.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Code optimization techniques">
  <data key="d0">Code optimization techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Strategies such as global optimization, workload assignment, and code restructuring to improve performance.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="High-level IR (Intermediate Representation)">
  <data key="d0">High-level IR (Intermediate Representation)</data>
  <data key="d1">Tools</data>
  <data key="d2">An abstract representation used by the compiler to analyze and optimize parallel patterns before code generation.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Evaluation setup">
  <data key="d0">Evaluation setup</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Experimental configuration involving Rodinia benchmarks, baseline OpenMP versions, and heterogeneous clusters to assess performance.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Overheads during compile time">
  <data key="d0">Overheads during compile time</data>
  <data key="d1">Limitations</data>
  <data key="d2">Additional time and resource costs associated with static analysis and optimization processes.</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Single CPU Node">
  <data key="d0">Single CPU Node</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A computational configuration involving a single CPU node used as a baseline for performance comparison and evaluation.&lt;SEP&gt;A computational setup involving a single CPU node used as a baseline for performance comparison."&gt;</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Distributed Setup with CPUs and GPUs">
  <data key="d0">Distributed Setup with CPUs and GPUs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A parallel computing configuration utilizing multiple CPUs and GPUs to evaluate scalability and performance."&gt;</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="LULESH">
  <data key="d0">LULESH</data>
  <data key="d1">Tools</data>
  <data key="d2">LULESH (Livermore Unstructured Lagrangian Explicit Shock Hydrodynamics) is a proxy application used as a benchmark for evaluating scalability and performance of HPC systems and codes.&lt;SEP&gt;LULESH is a mini-application simulating wave propagation, used to evaluate parallelization and optimization strategies in large applications.&lt;SEP&gt;LULESH is a mini-application simulating wave propagation, used to evaluate parallelization and optimization strategies.&lt;SEP&gt;LULESH is a proxy application used as a benchmark to assess scalability and performance of computational codes."&gt;</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Linear Programming (LP) Based Global Optimization">
  <data key="d0">Linear Programming (LP) Based Global Optimization</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A mathematical approach to optimize global solutions in computational problems, currently under assessment for issues."&gt;</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Code Generator">
  <data key="d0">Code Generator</data>
  <data key="d1">Tools</data>
  <data key="d2">A software component developed to produce code automatically, here for the PPLprototype toolchain."&gt;&lt;SEP&gt;A software component that produces code implementing synchronization, data transfer strategies, and workload assignment to optimize performance in heterogeneous systems.&lt;SEP&gt;A software component that produces code to implement synchronization, data movement, and workload assignment strategies, impacting overall system performance.&lt;SEP&gt;Component that produces optimized code for CPU and GPU targets, balancing performance and portability, with ongoing enhancements for specific kernels.&lt;SEP&gt;Component that produces optimized code for CPUs and GPUs, balancing performance with portability, and supporting specific kernels.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc&lt;SEP&gt;chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPLprototype Toolchain">
  <data key="d0">PPLprototype Toolchain</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A set of tools and processes designed to facilitate parallel programming and code optimization."&gt;</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Inlining">
  <data key="d0">Inlining</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A compiler optimization technique that replaces function calls with the function code itself to reduce overhead and improve performance.&lt;SEP&gt;A compiler optimization technique where function calls are replaced with the function code itself to improve performance."&gt;&lt;SEP&gt;Inlining replaces function calls with their actual code body, enabling better optimization and parallelization by flattening nested structures.&lt;SEP&gt;Inlining replaces function calls with their body to flatten hierarchical code structures, facilitating further optimization and parallelization.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Loop Unrolling">
  <data key="d0">Loop Unrolling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A code optimization technique that expands loops to reduce iteration overhead and increase parallelism."&gt;&lt;SEP&gt;Loop unrolling expands loop iterations into repeated code blocks to reduce overhead and improve execution efficiency in GPU kernels.&lt;SEP&gt;Loop unrolling is a technique that expands loop iterations into repeated code blocks to reduce overhead and improve performance in parallel code.&lt;SEP&gt;Loop unrolling is an optimization technique where loops are expanded by replicating the loop body multiple times to reduce iteration overhead, applicable when no break or continue statements are present.&lt;SEP&gt;Loop unrolling is an optimization technique where loops are expanded by replicating the loop body multiple times, reducing iteration overhead, applicable when no break or continue statements are present.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rodinia Benchmark Suite">
  <data key="d0">Rodinia Benchmark Suite</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A collection of benchmark kernels used to evaluate performance and scalability of parallel applications."&gt;&lt;SEP&gt;The Rodinia benchmark suite is a collection of parallel computing benchmarks used to evaluate the performance of parallel programming tools and frameworks.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPL">
  <data key="d0">PPL</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A parallel programming approach that separates semantics from hardware specifics, supporting broad application and hardware types."&gt;</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Polyhedral Compilers">
  <data key="d0">Polyhedral Compilers</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Tools that optimize nested loop structures in high-performance computing."&gt;</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Korali">
  <data key="d0">Korali</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A Bayesian uncertainty quantification framework for stochastic simulations, supporting probabilistic modeling and analysis.&lt;SEP&gt;A Bayesian uncertainty quantification framework for stochastic simulations."&gt;&lt;SEP&gt;A high-performance computing framework designed for stochastic optimization and Bayesian uncertainty quantification, enabling scalable experiments.&lt;SEP&gt;A high-performance computing framework for stochastic optimization and Bayesian uncertainty quantification.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Halide">
  <data key="d0">Halide</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A domain-specific language and compiler framework for image processing and computational photography, optimizing image pipelines.&lt;SEP&gt;A domain-specific language and compiler framework for image processing pipelines, supporting automatic scheduling for performance optimization.&lt;SEP&gt;A domain-specific language for image processing and computational photography."&gt;&lt;SEP&gt;A domain-specific language for image processing pipelines that supports automatic scheduling for performance.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Graph Algorithms">
  <data key="d0">Graph Algorithms</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Algorithms used to process and analyze graph data structures, often optimized for GPUs."&gt;</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="LLVM">
  <data key="d0">LLVM</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A compiler framework that enables building custom compilers, performing program analysis, and code optimization across languages and architectures.&lt;SEP&gt;A compiler infrastructure for building, optimizing, and analyzing code across multiple languages and architectures.&lt;SEP&gt;A compiler infrastructure project that provides modular compiler and toolchain technologies."&gt;&lt;SEP&gt;An open-source compiler infrastructure providing modular compiler components and toolchains for code generation and optimization.&lt;SEP&gt;LLVM (Low Level Virtual Machine) is a compiler infrastructure used to build optimized compilers and language tools, supporting multiple languages including Julia.&lt;SEP&gt;LLVM (Low Level Virtual Machine) is a compiler infrastructure used to develop optimized compilers and language tools, supporting multiple languages including Julia.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="gcc">
  <data key="d0">gcc</data>
  <data key="d1">Tools</data>
  <data key="d2">GNU Compiler Collection, a compiler system supporting various programming languages."&gt;&lt;SEP&gt;The GNU Compiler Collection supporting multiple programming languages, used for compiling and optimizing code across platforms.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="C2Rust">
  <data key="d0">C2Rust</data>
  <data key="d1">Tools</data>
  <data key="d2">A toolchain for translating C code to Rust, facilitating safer and more efficient code transformation.&lt;SEP&gt;A toolchain for translating existing C codebases into Rust, enabling safer and more maintainable code transformations.&lt;SEP&gt;A transpiler that converts C99 code into Rust for safer and modern software development."&gt;&lt;SEP&gt;A transpiler tool that converts C99 code into Rust, facilitating porting and modernization of legacy codebases.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenSBLI">
  <data key="d0">OpenSBLI</data>
  <data key="d1">Tools</data>
  <data key="d2">A code generator for fluid dynamics simulations on unstructured grids targeting heterogeneous architectures."&gt;&lt;SEP&gt;A code generator for fluid dynamics simulations on unstructured grids, targeting heterogeneous architectures for high-performance computing.&lt;SEP&gt;An automated code-generation framework for simulating compressible fluid dynamics on heterogeneous computing architectures.&lt;SEP&gt;An automated code-generation framework for simulating compressible fluid dynamics on structured grids, targeting heterogeneous computing architectures.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kempf et al.">
  <data key="d0">Kempf et al.</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research work providing a code generator for the discontinuous Galerkin method to enable vectorization."&gt;&lt;SEP&gt;Research work that provides a code generator for the discontinuous Galerkin method, enabling vectorization and performance optimization.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Lift">
  <data key="d0">Lift</data>
  <data key="d1">Tools</data>
  <data key="d2">A framework utilizing OpenCL to generate GPU code based on parallel patterns."&gt;&lt;SEP&gt;A framework utilizing parallel patterns specified in OpenCL to generate optimized GPU code for various applications.&lt;SEP&gt;A functional data-parallel intermediate representation aimed at high-performance GPU code generation.&lt;SEP&gt;A functional data-parallel intermediate representation designed to generate optimized GPU code from high-level descriptions.&lt;SEP&gt;Lift is a functional data-parallel intermediate representation designed to facilitate high-performance GPU code generation.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="YASK">
  <data key="d0">YASK</data>
  <data key="d1">Tools</data>
  <data key="d2">A DSL for generating optimized stencil kernels for high-performance computing."&gt;&lt;SEP&gt;A domain-specific language and code generator for optimized stencil kernels in high-performance computing environments.&lt;SEP&gt;YASK is a framework designed for generating and optimizing stencil computations in high-performance computing environments.&lt;SEP&gt;YASK is a framework designed to generate and optimize stencil computations for high-performance computing.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Li et al.">
  <data key="d0">Li et al.</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research focusing on code generation for optimized stencil kernels."&gt;&lt;SEP&gt;Research focusing on code generation for stencil kernels, emphasizing optimization for performance.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Skeleton Libraries">
  <data key="d0">Skeleton Libraries</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">Reusable libraries that provide parallel patterns and instructions for high-level parallel programming."&gt;</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Müsli">
  <data key="d0">Müsli</data>
  <data key="d1">Tools</data>
  <data key="d2">A skeleton library for parallel programming, facilitating reusable parallel instructions."&gt;&lt;SEP&gt;A skeleton library for parallel programming, providing reusable parallel instructions and patterns to simplify development.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Thrust">
  <data key="d0">Thrust</data>
  <data key="d1">Tools</data>
  <data key="d2">A parallel algorithms library for CUDA and C++, enabling high-level implementation of parallel operations like reductions, scans, and sorts.&lt;SEP&gt;A parallel algorithms library for CUDA and C++, enabling high-level parallel operations."&gt;&lt;SEP&gt;A parallel algorithms library tested for its impact on code suggestion accuracy.&lt;SEP&gt;Thrust is a C++ template library for CUDA that simplifies GPU programming by providing a high-level interface for parallel algorithms.&lt;SEP&gt;Thrust is a high-level CUDA library for parallel algorithms; it shows performance issues over complex kernels, reflecting limitations in community size and usage.&lt;SEP&gt;Thrust is a high-level parallel programming library for CUDA, with performance issues observed over complex kernels, reflecting community and usage limitations.&lt;SEP&gt;Thrust is a parallel algorithms library tested for its impact on code suggestion accuracy.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482&lt;SEP&gt;chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intel Thread Building Blocks">
  <data key="d0">Intel Thread Building Blocks</data>
  <data key="d1">Tools</data>
  <data key="d2">A C++ library for task-based parallelism and concurrent programming."&gt;&lt;SEP&gt;A C++ template library for task-based parallelism and concurrency, facilitating scalable multi-core application development.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Microsoft Parallel Pattern Library">
  <data key="d0">Microsoft Parallel Pattern Library</data>
  <data key="d1">Tools</data>
  <data key="d2">A library implementing parallel patterns for efficient multi-core and many-core programming in Windows environments.&lt;SEP&gt;A library that implements parallel patterns for efficient multi-core programming."&gt;</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Raja">
  <data key="d0">Raja</data>
  <data key="d1">Tools</data>
  <data key="d2">A library for portable parallel programming targeting many-core architectures."&gt;&lt;SEP&gt;A performance portability library similar to Kokkos, supporting parallel execution on various hardware platforms.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="SDFGs (Stateful DataFlow Graphs)">
  <data key="d0">SDFGs (Stateful DataFlow Graphs)</data>
  <data key="d1">Tools</data>
  <data key="d2">A detailed dependency analysis framework that enables aliasing elimination and dependency chain extraction during compile time, facilitating static scheduling.&lt;SEP&gt;A detailed dependency analysis framework that facilitates aliasing elimination and dependency chain extraction for static scheduling.&lt;SEP&gt;A rule-based optimization framework for applying transformations and optimizations to computational hotspots."&gt;&lt;SEP&gt;A rule-based optimization framework that models computations as dataflow graphs, enabling automated and semi-automated optimizations.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="DaCe">
  <data key="d0">DaCe</data>
  <data key="d1">Tools</data>
  <data key="d2">A software tool for data-centric parallel programming and optimization using SDFGs."&gt;&lt;SEP&gt;A software tool that implements SDFGs for data-centric parallel programming, providing optimization and code generation capabilities.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Distributed setup with CPUs and GPUs">
  <data key="d0">Distributed setup with CPUs and GPUs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A parallel computing environment utilizing multiple CPUs and GPUs to assess scalability, performance, and resource utilization.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Linear Programming (LP) based global optimization">
  <data key="d0">Linear Programming (LP) based global optimization</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A mathematical approach for optimizing solutions across the entire problem space, currently under evaluation for effectiveness and issues.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Code generator">
  <data key="d0">Code generator</data>
  <data key="d1">Tools</data>
  <data key="d2">A code generator translates high-level source code into optimized machine code, enabling performance improvements and portability.&lt;SEP&gt;A software component developed to produce optimized source code automatically, specifically for the PPLprototype toolchain to facilitate parallel code generation.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04&lt;SEP&gt;chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPLprototype toolchain">
  <data key="d0">PPLprototype toolchain</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A set of integrated tools and processes aimed at parallel programming, code optimization, and supporting various hardware architectures.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Loop unrolling">
  <data key="d0">Loop unrolling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An optimization technique that expands loops to decrease iteration overhead and increase instruction-level parallelism.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Abstract Pattern Tree (APT)">
  <data key="d0">Abstract Pattern Tree (APT)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A data structure used to represent and optimize code patterns for parallelization and code generation within the PPL framework.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Evaluation against Rodinia kernels">
  <data key="d0">Evaluation against Rodinia kernels</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A performance assessment comparing the PPL tool/concept's results with existing OpenMP implementations on benchmark kernels.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Issues of PPL prototype">
  <data key="d0">Issues of PPL prototype</data>
  <data key="d1">Limitations</data>
  <data key="d2">Current problems identified in the prototype, including potential solutions aimed at preparing a release version.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Polyhedral compilers">
  <data key="d0">Polyhedral compilers</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Compiler frameworks that optimize nested loop structures and data access patterns in high-performance computing, often used for loop nest optimization.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Graph algorithms">
  <data key="d0">Graph algorithms</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Algorithms designed to process, analyze, and manipulate graph data structures, often optimized for GPU execution.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Skeleton libraries">
  <data key="d0">Skeleton libraries</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">Reusable libraries that encapsulate parallel patterns and instructions to facilitate high-level parallel programming.</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Distributed Memory">
  <data key="d0">Distributed Memory</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Distributed memory architecture involves separate local memories per node, requiring explicit data movement and synchronization across nodes for parallel computation.&lt;SEP&gt;Distributed memory refers to a system architecture where each node has its own local memory, requiring explicit data movement and synchronization across nodes.&lt;SEP&gt;Distributed memory refers to a system architecture where memory is partitioned across multiple nodes or processors, requiring explicit data movement and management for parallel computation.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="SDFGs">
  <data key="d0">SDFGs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">SDFGs (Stateful DataFlow Graphs) are a model for representing computations with optimized data movement and execution strategies in high-performance computing.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="DaCe Tool">
  <data key="d0">DaCe Tool</data>
  <data key="d1">Tools</data>
  <data key="d2">The DaCe tool is a software platform that utilizes SDFGs to perform rule-based optimizations on computational hotspots in high-performance applications.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Optimization Strategy">
  <data key="d0">Optimization Strategy</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A rule-based optimization strategy involves applying predefined rules to improve computational performance, particularly in hotspots.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="HPC Expert">
  <data key="d0">HPC Expert</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">An HPC expert defines optimization rules and strategies tailored to specific hardware and application requirements.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Application Wide Optimizations">
  <data key="d0">Application Wide Optimizations</data>
  <data key="d1">Methodsology</data>
  <data key="d2">Application wide optimizations involve global modifications to improve overall application performance, as opposed to local optimizations.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Local Optimizations">
  <data key="d0">Local Optimizations</data>
  <data key="d1">Methodsology</data>
  <data key="d2">Local optimizations target specific parts or hotspots within an application to enhance performance.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPL Tool">
  <data key="d0">PPL Tool</data>
  <data key="d1">Tools</data>
  <data key="d2">The PPL (Parallel Pattern Language) tool is a prototype that verifies pattern-based approaches for parallel programming, enabling automatic global optimizations.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Pattern Language (PPL)">
  <data key="d0">Parallel Pattern Language (PPL)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">PPL is a pattern-based approach for representing and optimizing parallel algorithms across diverse hardware.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pattern-Based Approach">
  <data key="d0">Pattern-Based Approach</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A pattern-based approach involves using predefined computational patterns to model, analyze, and optimize parallel algorithms.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Source-to-Source Compiler">
  <data key="d0">Source-to-Source Compiler</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A source-to-source compiler transforms high-level parallel pattern descriptions into optimized code through multiple stages, including parsing, generation, and code output.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="APT Generation">
  <data key="d0">APT Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">APT (Abstract Pattern Tree) generation involves creating a hierarchical representation of the algorithm based on the parsed input.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="AMT Generation">
  <data key="d0">AMT Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Abstract Mapping Tree (AMT) generation produces a structure that incorporates synchronization and data transfer details based on optimization results.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Patterns">
  <data key="d0">Parallel Patterns</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Abstracted parallelism structures that reduce boilerplate code, improve programmability, and support automatic optimization.&lt;SEP&gt;Parallel patterns are constructs that define how computations are executed in parallel, influencing task partitioning and optimization.&lt;SEP&gt;Parallel patterns are high-level abstractions representing common parallel computation structures, facilitating pattern-based optimization.&lt;SEP&gt;Parallel patterns describe common structures in parallel programming, such as nested patterns, that guide how computations are organized and executed.&lt;SEP&gt;Parallel patterns refer to structured approaches for executing computations concurrently across multiple threads or GPU cores, such as reduction patterns and work-sharing strategies.&lt;SEP&gt;Reusable abstractions of parallelism that reduce boilerplate code, improve maintainability, and facilitate automatic optimization across hardware platforms.&lt;SEP&gt;Structured approaches for executing computations concurrently, such as reduction patterns and work-sharing strategies, to exploit data parallelism on GPUs.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-0223d4c2805a1c339a5639baaa802cfc&lt;SEP&gt;chunk-5f6ee49c82aaaf22c167cac791d43a0f&lt;SEP&gt;chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Dependency Analysis">
  <data key="d0">Data Dependency Analysis</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Data dependency analysis examines the relationships between data elements to determine safe parallel execution and optimize task scheduling.&lt;SEP&gt;Techniques to analyze and identify dependencies among data variables, enabling static identification of dynamic workloads and aliasing elimination.&lt;SEP&gt;Techniques to analyze and understand dependencies among data variables, enabling better handling of dynamic workloads and aliasing during compile time.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc&lt;SEP&gt;chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hardware Language (HWL)">
  <data key="d0">Hardware Language (HWL)</data>
  <data key="d1">Tools</data>
  <data key="d2">HWL is a JSON-based description of target hardware architecture used to guide optimization and mapping.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pure Functions">
  <data key="d0">Pure Functions</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Pure functions are functions without side effects, simplifying dependency analysis and enabling static array size derivation.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="List of Parallel Patterns">
  <data key="d0">List of Parallel Patterns</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A collection of predefined patterns such as multiply and subtract, used to model computations in the PPL approach.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Array Size">
  <data key="d0">Array Size</data>
  <data key="d1">Variables</data>
  <data key="d2">Static array size definitions are used in the DSL to facilitate analysis and optimization of parallel patterns.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Function-Inlining/Loop-Unrolling">
  <data key="d0">Function-Inlining/Loop-Unrolling</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">These code transformations are applied to optimize performance by reducing function call overhead and increasing instruction-level parallelism.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Application Environments">
  <data key="d0">Application Environments</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The approach aims to verify the applicability of pattern-based optimization in real-world high-performance computing environments.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global View on Application">
  <data key="d0">Global View on Application</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A global view involves analyzing entire applications to identify opportunities for optimization across multiple components.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hierarchical Representation">
  <data key="d0">Hierarchical Representation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The hierarchical APT provides a structured view of algorithms, enabling systematic optimization.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Explicit Hardware Mapping">
  <data key="d0">Explicit Hardware Mapping</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Explicit hardware mapping assigns computational tasks to specific hardware units to optimize resource utilization.&lt;SEP&gt;Explicit hardware mapping assigns computational tasks to specific hardware units, optimizing resource utilization.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Reordering">
  <data key="d0">Reordering</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Reordering rearranges computational steps to improve data locality and parallel efficiency.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Synchronization">
  <data key="d0">Synchronization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Synchronization ensures correct execution order and data integrity during GPU offloading, often through barriers, atomic operations, or events.&lt;SEP&gt;Synchronization in CUDA involves mechanisms like cudaMemcpy and shared memory synchronization to ensure correct ordering of GPU operations, especially data transfers and kernel executions.&lt;SEP&gt;Synchronization in GPU offloading ensures correct execution order and data consistency, often via barriers or atomic operations.&lt;SEP&gt;Synchronization mechanisms are incorporated into the AMT to ensure correct data dependencies during parallel execution.&lt;SEP&gt;Synchronization mechanisms like barriers coordinate task execution across threads, ensuring data consistency and correct sequencing.&lt;SEP&gt;Synchronization mechanisms like cudaMemcpy and shared memory barriers ensure correct ordering of GPU operations, preventing race conditions and data corruption.&lt;SEP&gt;Synchronization mechanisms, such as barriers, are employed to coordinate task execution and ensure data consistency across threads.&lt;SEP&gt;Synchronization nodes manage dependencies and coordination between tasklets and devices to ensure correct execution order.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1&lt;SEP&gt;chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Transfers">
  <data key="d0">Data Transfers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data transfers refer to moving data between different parts of the hardware or memory hierarchies, critical for performance.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance Optimization">
  <data key="d0">Performance Optimization</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Improving computational performance through techniques like static overhead reduction, compiler optimizations, and parallel pattern abstraction to enhance productivity and efficiency.&lt;SEP&gt;The overall goal of the described methodologies is to improve computational performance in high-performance computing applications.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc&lt;SEP&gt;chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rule-Based Optimization">
  <data key="d0">Rule-Based Optimization</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Rule-based optimization involves applying predefined rules to improve performance, particularly in hotspots.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global Optimization">
  <data key="d0">Global Optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Global optimization involves applying techniques like loop fusion and data flow optimizations across the entire application to improve performance and efficiency.&lt;SEP&gt;Global optimization refers to techniques that consider the entire application or system to improve overall performance.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1&lt;SEP&gt;chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Local Optimization">
  <data key="d0">Local Optimization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Local optimization focuses on specific hotspots or components within an application for targeted performance improvements.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Automatic Global Optimization">
  <data key="d0">Automatic Global Optimization</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The work aims to enable automatic global optimizations, reducing manual intervention by experts.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Local Optimization Focus">
  <data key="d0">Local Optimization Focus</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The work emphasizes local optimizations, such as local hotspots, within the broader optimization framework.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Application of Pattern-Based Approach">
  <data key="d0">Application of Pattern-Based Approach</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The pattern-based approach is applied to verify its effectiveness in real-world HPC environments.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hierarchical Representation of Algorithms">
  <data key="d0">Hierarchical Representation of Algorithms</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The hierarchical APT captures the structure of algorithms for systematic optimization.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Optimization of Data Movement">
  <data key="d0">Optimization of Data Movement</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Optimizing data movement is essential for performance in distributed memory systems and is addressed through data transfer management.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Reordering and Synchronization">
  <data key="d0">Reordering and Synchronization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Reordering computational steps and incorporating synchronization mechanisms improve data locality and correctness.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance in High-Performance Computing">
  <data key="d0">Performance in High-Performance Computing</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The ultimate goal is to enhance performance and scalability of HPC applications through systematic optimization.</data>
  <data key="d3">chunk-3487322ee335c5f4b3b40717a7de46d1</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="TheHWL">
  <data key="d0">TheHWL</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The Hardware Layer (TheHWL) allows defining execution units, such as cores, and supports arbitrary division of devices into these units, enabling flexible parallelism.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="APG Generation">
  <data key="d0">APG Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">APG (Abstract Program Graph) generation creates a high-level hierarchical representation of parallel code, categorizing nodes into expressions and statements for analysis and optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Nodes">
  <data key="d0">Nodes</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Nodes in the APG represent computations (expressions) and control flow (statements), including function calls and pattern calls, which are essential for analyzing data dependencies and parallelism.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Dependencies">
  <data key="d0">Data Dependencies</data>
  <data key="d1">Variables</data>
  <data key="d2">Data dependencies link expressions within the APG, enabling static analysis of data flow and dependencies across program components.&lt;SEP&gt;Data dependencies refer to the relationships between tasks where output from one task serves as input for another, which must be known beforehand to avoid data races.&lt;SEP&gt;Data dependencies specify relationships between tasks where output from one task is required as input for another, critical for avoiding data races and ensuring correct execution order.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Synchronization Efficiency">
  <data key="d0">Synchronization Efficiency</data>
  <data key="d1">Variables</data>
  <data key="d2">Synchronization efficiency measures the effectiveness of minimizing dependency-based synchronization to maximize parallel execution.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Inter-processor Dataflow Efficiency">
  <data key="d0">Inter-processor Dataflow Efficiency</data>
  <data key="d1">Variables</data>
  <data key="d2">This efficiency assesses the optimization of data transfer and execution costs between multiple processing units, aiming to reduce overall runtime.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intra-processor Dataflow Efficiency">
  <data key="d0">Intra-processor Dataflow Efficiency</data>
  <data key="d1">Variables</data>
  <data key="d2">Intra-processor dataflow efficiency maximizes data reuse within the same execution unit, reducing cache misses and improving performance.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Gurobi Solver">
  <data key="d0">Gurobi Solver</data>
  <data key="d1">Tools</data>
  <data key="d2">Gurobi is a proprietary optimization solver used to solve Mixed Integer Linear Programming (MILP) problems generated during global optimization to optimize task mapping and scheduling.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="AMT (Abstract Mapping Tree)">
  <data key="d0">AMT (Abstract Mapping Tree)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The AMT extends the APT by including optimization and mapping data, representing heterogeneous, distributed, and concurrent task execution, including tasklet assignments, synchronization, and data transfers.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tasklets">
  <data key="d0">Tasklets</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Tasklets are lightweight units of work, often lambda functions, scheduled for concurrent execution within the thread pool, enabling flexible parallelism.&lt;SEP&gt;Tasklets are lightweight, independent units of work (often lambda functions) that can be scheduled and executed in parallel within the thread pool.&lt;SEP&gt;Tasklets are partitioned units of parallel computation derived from patterns, assigned to hardware units, and optimized for performance and resource utilization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Transfer">
  <data key="d0">Data Transfer</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data transfer nodes represent synchronization and data movement between devices or within device memory, derived iteratively from dataflow analysis.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="GPU Memory Management">
  <data key="d0">GPU Memory Management</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Special nodes in the AMT represent offloaded parallel patterns and memory management on GPUs, facilitating heterogeneous execution.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Task Mapping">
  <data key="d0">Task Mapping</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Task mapping involves assigning computational units (tasklets) to hardware resources, optimizing for performance and resource utilization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hardware Language">
  <data key="d0">Hardware Language</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The hardware language defines the hardware resources, such as cores and memory groups, used for task assignment and optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dataflow">
  <data key="d0">Dataflow</data>
  <data key="d1">Variables</data>
  <data key="d2">Dataflow describes the movement and dependencies of data between computations, devices, and memory, critical for optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Patterns">
  <data key="d0">Patterns</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Parallel patterns are abstract models that define how computations are structured and executed in parallel, enabling optimization strategies.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Static Analysis">
  <data key="d0">Static Analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Static analysis examines data dependencies and control flow in the code without executing it, enabling optimization and correctness checking.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Partitioning">
  <data key="d0">Partitioning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Partitioning divides the computation into smaller tasklets or patterns, facilitating parallel execution and resource management.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Optimization Pipeline">
  <data key="d0">Optimization Pipeline</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The optimization pipeline involves steps like synchronization minimization, data transfer reduction, and task fusion to improve performance.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Mapping">
  <data key="d0">Mapping</data>
  <data key="d1">Variables</data>
  <data key="d2">Mapping refers to assigning tasklets to hardware resources, such as cores or GPUs, to optimize execution.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Cost Models">
  <data key="d0">Cost Models</data>
  <data key="d1">Variables</data>
  <data key="d2">Cost models estimate execution time, network transfer time, and resource utilization to guide optimization decisions.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MILP (Mixed Integer Linear Programming)">
  <data key="d0">MILP (Mixed Integer Linear Programming)</data>
  <data key="d1">Tools</data>
  <data key="d2">MILP formulations are used to optimize task scheduling and mapping during global optimization, solved by solvers like Gurobi.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Optimization Objectives">
  <data key="d0">Optimization Objectives</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The objectives include minimizing synchronization, data transfer, execution time, and resource usage to enhance overall performance.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Execution Cost">
  <data key="d0">Execution Cost</data>
  <data key="d1">Variables</data>
  <data key="d2">Execution cost estimates the time required to perform tasks, guiding optimization strategies.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Network Cost">
  <data key="d0">Network Cost</data>
  <data key="d1">Variables</data>
  <data key="d2">Network cost estimates the data transfer time between devices, influencing data movement optimization.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallelism">
  <data key="d0">Parallelism</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Parallelism enables concurrent execution of tasks within dynamic control flow structures like loops and branches, facilitating faster computations.&lt;SEP&gt;Parallelism refers to executing multiple computations simultaneously, enabled by task partitioning, patterns, and hardware capabilities.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Heterogeneous Systems">
  <data key="d0">Heterogeneous Systems</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Heterogeneous systems involve combining different types of computing resources, such as CPUs and GPUs, for optimized performance.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Shared Memory">
  <data key="d0">Shared Memory</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Shared memory systems allow multiple processing units to access common memory spaces, enabling pattern-independent read/write operations.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory Offloading">
  <data key="d0">Memory Offloading</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Memory offloading involves transferring data and computations to accelerators like GPUs to improve performance.</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="synchronization">
  <data key="d0">synchronization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Synchronization is a process that ensures data consistency and correct execution order among computational units, especially in heterogeneous systems involving CPUs and GPUs.&lt;SEP&gt;Synchronization is a process that ensures data consistency and proper execution order among computational units, particularly in heterogeneous systems involving CPUs and GPUs.&lt;SEP&gt;Synchronization overhead in parallel code, which can be minimized to improve performance.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b&lt;SEP&gt;chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="data flow">
  <data key="d0">data flow</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data flow refers to the movement and transfer of data between different execution units and memory locations during computation.&lt;SEP&gt;Data flow refers to the movement, transfer, and management of data between execution units and memory during computational processes.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="device local dependencies">
  <data key="d0">device local dependencies</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dependencies that can be resolved within a single device through synchronization, assuming shared memory systems, enabling pattern-independent read and write accesses.&lt;SEP&gt;Dependencies within a single device that can be resolved through synchronization, assuming shared memory systems, enabling pattern-independent read and write accesses.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="remote write accesses">
  <data key="d0">remote write accesses</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Accesses where data is written to a remote device without the need for synchronization, as they do not risk data races, with invalidation of copies to maintain data consistency.&lt;SEP&gt;Accesses where data is written to remote device memory without requiring synchronization, since they do not cause write-after-write data races, provided unified memory or RMA operations are used.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="remote read accesses">
  <data key="d0">remote read accesses</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Accesses requiring synchronization and data transfer between devices, often involving creating data copies on closer devices to reduce network traffic, at the expense of increased memory footprint.&lt;SEP&gt;Accesses that require synchronization and data transfer between devices, involving creating copies of data on closer devices to reduce network traffic, at the cost of increased memory footprint.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="GPU memory">
  <data key="d0">GPU memory</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">GPUs have limited memory capacity, holding only data necessary for subsequent computations to optimize resource utilization and performance.&lt;SEP&gt;GPUs have limited memory capacity, holding only data required for upcoming computations to optimize performance and resource utilization.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="source-to-source compiler">
  <data key="d0">source-to-source compiler</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A compiler that translates high-level code into optimized code for heterogeneous systems, supporting features like shared memory, offloading, and synchronization.&lt;SEP&gt;A compiler translating high-level code into optimized code for heterogeneous systems, supporting features like shared memory, offloading, and synchronization mechanisms.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="shared memory">
  <data key="d0">shared memory</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Shared memory is a fast, accessible memory space shared among multiple processing units, enabling quick data exchange and synchronization within a device or system.&lt;SEP&gt;Shared memory is a memory space accessible by multiple processing units, enabling fast data exchange and synchronization within a device or system.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="CUDA, MPI, PThreads">
  <data key="d0">CUDA, MPI, PThreads</data>
  <data key="d1">Tools</data>
  <data key="d2">Programming models and tools used to implement parallelism, data movement, and synchronization across CPU and GPU architectures.&lt;SEP&gt;Programming tools and models used to implement parallelism, data transfer, and synchronization across CPU and GPU architectures.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="thread pool">
  <data key="d0">thread pool</data>
  <data key="d1">Tools</data>
  <data key="d2">A collection of threads managed to execute tasks with explicit synchronization, supporting workload assignment and parallel execution.&lt;SEP&gt;A collection of threads managed to execute tasks with explicit synchronization, supporting workload distribution and parallel execution.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="hierarchical synchronization">
  <data key="d0">hierarchical synchronization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Synchronization structured across different hardware levels: intra-device, intra-node, and inter-device, to coordinate data access and execution order.&lt;SEP&gt;Synchronization structured across hardware levels: intra-device, intra-node, and inter-device, to coordinate data access and execution order.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="invalidation">
  <data key="d0">invalidation</data>
  <data key="d1">Methods</data>
  <data key="d2">A technique to maintain data consistency by marking copies of data as invalid after updates, prompting data transfer or refresh when needed.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="data transfers">
  <data key="d0">data transfers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The movement of data between CPU and GPU or across devices, essential for maintaining data coherence and enabling computation.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="performance bottlenecks">
  <data key="d0">performance bottlenecks</data>
  <data key="d1">Results</data>
  <data key="d2">Identified issues in the code generation process that limit system efficiency, such as inefficient data movement or synchronization overheads.&lt;SEP&gt;Identified issues in the code generation process that limit system efficiency, such as inefficient data movement, synchronization overheads, or memory constraints.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="optimization">
  <data key="d0">optimization</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Strategies aimed at improving system performance by reducing bottlenecks, enhancing data locality, and streamlining synchronization.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="heterogeneous system">
  <data key="d0">heterogeneous system</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A computing environment combining different processing units like CPUs and GPUs to leverage their respective strengths for parallel computation.&lt;SEP&gt;A computing environment combining different types of processing units like CPUs and GPUs to leverage their respective strengths.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="parallel pattern">
  <data key="d0">parallel pattern</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A template or method defining how computations are parallelized and scheduled, supported by the code generator to optimize execution.&lt;SEP&gt;A template or method defining how computations are parallelized, supported by the code generator to optimize execution.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dynamic load balancing">
  <data key="d0">dynamic load balancing</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigates the potential to distribute workloads dynamically during runtime to improve efficiency and adapt to varying computational demands.&lt;SEP&gt;The potential for distributing workloads dynamically during runtime to improve efficiency and adapt to varying computational demands.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="execution units">
  <data key="d0">execution units</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Hardware components such as CPU cores or GPU streams where tasks are executed.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="pinning of workload">
  <data key="d0">pinning of workload</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Assigning specific tasks to specific hardware units (cores or devices) to optimize performance and resource utilization.&lt;SEP&gt;Assigning specific tasks to specific hardware units to optimize performance and resource utilization.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="data movement across devices">
  <data key="d0">data movement across devices</data>
  <data key="d1">Variables</data>
  <data key="d2">The transfer of data between different processing units, crucial for synchronization and computation in heterogeneous systems.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="support for shared, distributed memory, and offloading models">
  <data key="d0">support for shared, distributed memory, and offloading models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Features supported by the code generator to enable flexible parallel programming across various hardware architectures.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="implementation">
  <data key="d0">implementation</data>
  <data key="d1">Results</data>
  <data key="d2">The developed code supports multiple features like workload pinning, data movement, and synchronization, aligning with the system's optimization goals.&lt;SEP&gt;The developed system supports multiple features like workload pinning, data movement, and synchronization, aiming to optimize performance and resource use.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="optimization strategies">
  <data key="d0">optimization strategies</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Approaches aimed at improving system performance by reducing bottlenecks, enhancing data locality, and streamlining synchronization processes.</data>
  <data key="d3">chunk-b943bff32a36cd0ce9ab43893da92b5b</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Shared Memory Parallelism">
  <data key="d0">Shared Memory Parallelism</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Shared memory parallelism refers to the programming approach that utilizes multiple cores or threads within a shared memory environment to execute tasks concurrently.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="POSIX Threads">
  <data key="d0">POSIX Threads</data>
  <data key="d1">Tools</data>
  <data key="d2">POSIX threads are a standardized API for creating and managing threads in a shared memory environment, enabling parallel execution of tasks.&lt;SEP&gt;POSIX threads are an API for managing multiple threads within a shared memory environment, enabling parallel execution and synchronization of tasks.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="HWL">
  <data key="d0">HWL</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Hardware Layer (HWL) defines the number of cores and resources available for parallel processing, serving as the basis for thread assignment and task distribution.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Thread Pinning">
  <data key="d0">Thread Pinning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Thread pinning involves binding specific threads to particular CPU cores to optimize performance and reduce context switching, often implemented via pthread_setaffinity_np.&lt;SEP&gt;Thread pinning involves binding threads to specific CPU cores using functions like pthread_setaffinity_np to optimize performance and reduce context switching.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hyper-threading">
  <data key="d0">Hyper-threading</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Hyper-threading is a CPU feature that allows a single physical core to appear as multiple logical cores, but it is currently disregarded in this context.&lt;SEP&gt;Hyper-threading is a CPU technology that allows a single physical core to appear as multiple logical cores, but it is currently disregarded in this context.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Lambda Functions">
  <data key="d0">Lambda Functions</data>
  <data key="d1">Tools</data>
  <data key="d2">Lambda functions are anonymous functions used to store deferred execution tasks, enabling flexible and modular parallel task management.&lt;SEP&gt;Lambda functions are anonymous, deferred executable units used to store tasks with known data dependencies, facilitating modular parallel execution.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="pthread_setaffinity_np">
  <data key="d0">pthread_setaffinity_np</data>
  <data key="d1">Tools</data>
  <data key="d2">A POSIX function used to bind threads to specific CPU cores by setting CPU affinity, optimizing thread placement for performance.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MPI (Message Passing Interface)">
  <data key="d0">MPI (Message Passing Interface)</data>
  <data key="d1">Tools</data>
  <data key="d2">A standardized API for message passing in parallel computing environments, currently at version 3.1.&lt;SEP&gt;A standardized API for message passing in parallel computing, currently at version 3.1, enabling communication across distributed systems.&lt;SEP&gt;MPI is a standardized and portable message-passing system designed for parallel programming across distributed memory systems, supporting explicit data transfer and synchronization.&lt;SEP&gt;MPI is a standardized message-passing library enabling explicit data transfer, synchronization, and collective operations across distributed memory systems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MPI Reduction">
  <data key="d0">MPI Reduction</data>
  <data key="d1">Methodologies</data>
  <data key="d2">MPI reduction is a collective communication operation that combines data from multiple processes or nodes into a single result, used here for distributed memory reduction patterns.&lt;SEP&gt;MPI reduction is a collective operation that combines data from multiple processes or nodes into a single result, used in distributed memory reduction patterns.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MPI Communication">
  <data key="d0">MPI Communication</data>
  <data key="d1">Tools</data>
  <data key="d2">MPI communication functions facilitate data transfer between nodes in distributed systems, supporting explicit synchronization and collective operations like reductions.&lt;SEP&gt;MPI communication functions facilitate explicit data transfer between nodes in a distributed system, enabling synchronization and data sharing.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MPI Synchronization">
  <data key="d0">MPI Synchronization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">MPI provides blocking communication calls that inherently synchronize processes, ensuring data consistency before proceeding.&lt;SEP&gt;MPI provides blocking communication calls that synchronize processes, ensuring all data is transferred and ready before computation continues.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Accelerator Offloading">
  <data key="d0">Accelerator Offloading</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Accelerator offloading involves transferring computation to specialized hardware such as GPUs to improve performance, often utilizing CUDA or similar frameworks.&lt;SEP&gt;Accelerator offloading transfers computation tasks to specialized hardware such as GPUs to accelerate processing and reduce load on CPUs.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Thread Pool">
  <data key="d0">Thread Pool</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A thread pool is a collection of pre-created threads that execute scheduled tasks, simplifying parallel management across multiple processing units or GPUs.&lt;SEP&gt;A thread pool is a collection of pre-instantiated, reusable threads that execute queued tasks, simplifying parallel task management across multiple GPUs or cores.&lt;SEP&gt;A thread pool is a collection of worker threads that efficiently manage and execute multiple tasks concurrently, often used in GPU offloading and parallel pattern execution.&lt;SEP&gt;A thread pool is a collection of worker threads used to manage and execute multiple tasks concurrently, facilitating efficient resource utilization in GPU offloading scenarios.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory Locality">
  <data key="d0">Memory Locality</data>
  <data key="d1">Variables</data>
  <data key="d2">Memory locality involves optimizing data placement and movement to minimize latency and maximize throughput during GPU offloading and kernel execution.&lt;SEP&gt;Memory locality refers to optimizing data placement and movement to reduce latency and improve throughput during GPU offloading and kernel execution.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kernel">
  <data key="d0">Kernel</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A kernel is a function executed on the GPU, performing computations on data transferred from host memory, often optimized for parallel execution.&lt;SEP&gt;A kernel is a function executed on the GPU, performing computations on data transferred from host memory.&lt;SEP&gt;Specific computational kernels like AXPY, GEMV, GEMM, SpMV, Jacobi, CG used in experiments to assess code generation accuracy.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Movement">
  <data key="d0">Data Movement</data>
  <data key="d1">Variables</data>
  <data key="d2">Data movement involves transferring data between CPU and GPU memory spaces, managed via CUDA functions like cudaMemcpy, critical for maintaining data locality and performance.&lt;SEP&gt;Data movement involves transferring data between host and device memory, managed explicitly via MPI or CUDA calls to optimize performance.&lt;SEP&gt;Data movement refers to transferring data between CPU and GPU memory, managed via CUDA functions like cudaMemcpy, crucial for correct and efficient parallel processing.&lt;SEP&gt;Data movement refers to transferring data between host and device (GPU) memory, managed explicitly via CUDA or MPI calls to enhance performance.</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d&lt;SEP&gt;chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="GPU">
  <data key="d0">GPU</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Graphics Processing Units (GPUs) are hardware accelerators designed for massively parallel processing, used here to offload computations and manage data for high-performance applications.&lt;SEP&gt;Graphics Processing Units (GPUs) are hardware accelerators designed for parallel processing, used here to offload computations and manage data for high-performance tasks.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="CUDA Calls">
  <data key="d0">CUDA Calls</data>
  <data key="d1">Tools</data>
  <data key="d2">CUDA API functions such as cudaMalloc, cudaFree, and cudaMemcpy are used for memory management and data transfer between host and device, essential for GPU programming.&lt;SEP&gt;CUDA calls are specific API functions such as cudaMalloc, cudaFree, and cudaMemcpy used to allocate, free, and transfer data on the GPU, facilitating data movement and memory management in GPU programming.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="CUDA Streams">
  <data key="d0">CUDA Streams</data>
  <data key="d1">Tools</data>
  <data key="d2">CUDA streams are sequences of operations that execute asynchronously on the GPU, allowing concurrent execution of data transfers and kernel executions to improve performance.&lt;SEP&gt;CUDA streams are sequences of operations that execute asynchronously on the GPU, allowing concurrent execution of kernels and data transfers to optimize performance.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Execution Range">
  <data key="d0">Execution Range</data>
  <data key="d1">Variables</data>
  <data key="d2">The execution range defines the number of iterations assigned per thread in GPU kernels, influencing workload distribution and performance optimization.&lt;SEP&gt;The execution range specifies the number of iterations assigned to each thread during kernel execution, influencing workload distribution and efficiency.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Indexing Formula">
  <data key="d0">Indexing Formula</data>
  <data key="d1">Variables</data>
  <data key="d2">INDEX = t * r + i + n, where t is thread id, r is execution range, i is local iteration, and n is remainder, used to map array elements to threads during parallel execution.&lt;SEP&gt;INDEX = t * r + i + n, where t is thread id, r is execution range, i is local iteration, and n is remainder, used to map data elements to threads in parallel execution.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intra-block and Inter-block Reduction">
  <data key="d0">Intra-block and Inter-block Reduction</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for combining partial results within a GPU block or across multiple blocks, often involving atomic operations or shared memory for synchronization.&lt;SEP&gt;These are techniques for combining partial results within a GPU block or across multiple blocks, often involving atomic operations for consistency.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MILP Specification">
  <data key="d0">MILP Specification</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The Mixed-Integer Linear Programming (MILP) specification defines the semantic constraints and rules that parallel code optimization must adhere to, ensuring correctness.&lt;SEP&gt;The formal specification of Mixed-Integer Linear Programming (MILP) defines the semantic constraints and rules that parallel code must adhere to for correctness.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Shared Memory Synchronization">
  <data key="d0">Shared Memory Synchronization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Shared memory synchronization involves coordinating access to shared resources within GPU threads to prevent race conditions and ensure data consistency.&lt;SEP&gt;Synchronization within shared memory ensures correct data access among threads, preventing race conditions during parallel execution.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pattern Implementation">
  <data key="d0">Pattern Implementation</data>
  <data key="d1">Methods</data>
  <data key="d2">Defining how many iterations are assigned per thread, managing workload distribution for parallel execution.&lt;SEP&gt;Pattern implementation involves explicitly defining how many iterations of a task are assigned per thread, managing workload distribution for parallel execution.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rearrangement of Patterns">
  <data key="d0">Rearrangement of Patterns</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Rearranging patterns like nested parallelism or combining multiple patterns requires code transformations such as inlining and flattening to adhere to semantic constraints.&lt;SEP&gt;Transformations like nested parallelism, inlining, and code flattening to enable complex pattern nesting while preserving semantic correctness.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Management">
  <data key="d0">Data Management</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Data management encompasses allocation, transfer, and synchronization of data on GPU, handled through wrapping CUDA functions and dedicated threads to enable concurrent CPU-GPU computations.&lt;SEP&gt;Handling allocation, transfer, and synchronization of data on GPU, including wrapping CUDA functions and managing concurrent CPU-GPU computations.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Synchronization of CUDA Calls">
  <data key="d0">Synchronization of CUDA Calls</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Ensuring correct execution order of CUDA operations through mechanisms like cudaMemcpy and stream synchronization to maintain data integrity.&lt;SEP&gt;Synchronization ensures correct execution order of CUDA calls, primarily through cudaMemcpy and stream synchronization, to maintain data integrity across GPU operations.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Optimization Process">
  <data key="d0">Optimization Process</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process involving recognizing parallelism, applying inlining, unrolling, flattening code hierarchies, and respecting MILP semantics to generate efficient parallel code.&lt;SEP&gt;The optimization process involves recognizing parallelism, inlining functions, unrolling loops, and flattening code hierarchies to generate efficient parallel code respecting MILP semantics.</data>
  <data key="d3">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Function Arguments">
  <data key="d0">Function Arguments</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Function arguments are the inputs passed to functions, including nested patterns, which influence control flow and data dependencies in programming.&lt;SEP&gt;Function arguments refer to the inputs passed to functions, including nested patterns, which influence control flow and data dependencies in programming.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Write-After-Write and Write-After-Read Dependencies">
  <data key="d0">Write-After-Write and Write-After-Read Dependencies</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">These are data hazards in concurrent programming where write operations overlap or follow read operations, affecting program correctness and optimization.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Local Array">
  <data key="d0">Local Array</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A local array is a data structure used within functions to store temporary data during computation, especially in parallel processing contexts.&lt;SEP&gt;A local array is a temporary data structure used within functions to store intermediate results, especially in parallel computation contexts.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Jump Label">
  <data key="d0">Jump Label</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A jump label is a marker used in control flow to facilitate function returns and manage execution flow, including deallocating local data.&lt;SEP&gt;A jump label is a marker used to manage control flow, particularly for function returns and deallocating local data during code transformation.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="ReturnNode">
  <data key="d0">ReturnNode</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A ReturnNode represents a return statement in a control flow graph, indicating the end of a function or a return point.&lt;SEP&gt;A ReturnNode represents a return statement in the control flow graph, indicating the end of a function or a return point.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hashing of Variables">
  <data key="d0">Hashing of Variables</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Hashing variables involves converting variable references into hashed identifiers to manage variable replacements and references during code transformation.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Deep Copy">
  <data key="d0">Deep Copy</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Deep copy creates an entirely new copy of a data structure or node, including all nested objects, to prevent side effects during transformations.&lt;SEP&gt;Deep copying creates an entire new copy of a data structure or node, including nested objects, to prevent side effects during code modifications such as inlining or loop unrolling.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Function Call Replacer">
  <data key="d0">Function Call Replacer</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The call.replacer variable encapsulates the return values of a function, used to replace inlined function calls within expressions during code generation.&lt;SEP&gt;The call.replacer variable encapsulates the return values of a function, used to replace inlined function calls within expressions during code transformation.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Algorithm 1: Simplified APT Function Inlining">
  <data key="d0">Algorithm 1: Simplified APT Function Inlining</data>
  <data key="d1">Methodologies</data>
  <data key="d2">This algorithm describes the process of inlining functions by copying nodes, managing jump labels, replacing variables, and handling return nodes, to optimize code execution.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenMP Version of Rodinia Benchmark Suite">
  <data key="d0">OpenMP Version of Rodinia Benchmark Suite</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The Rodinia benchmark suite is a collection of parallel computing benchmarks used to evaluate performance of parallel programming tools and frameworks.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="System Environment">
  <data key="d0">System Environment</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">All measurements were performed on CLAIX18 systems at RWTH Aachen University, equipped with Xeon Platinum 8160 CPUs and 192 GB RAM, indicating the hardware context for performance evaluation.&lt;SEP&gt;The evaluation was performed on CLAIX18 systems at RWTH Aachen University, equipped with Xeon Platinum 8160 CPUs and 192 GB RAM, providing hardware context for performance measurement.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Nested Parallel Patterns">
  <data key="d0">Nested Parallel Patterns</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Nested parallel patterns refer to the structure where parallel patterns are embedded within each other, affecting execution flow and synchronization.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Write-After-Write Dependencies">
  <data key="d0">Write-After-Write Dependencies</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Write-after-write dependencies are data hazards where a write operation occurs after another write to the same location, impacting concurrency and correctness.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Write-After-Read Dependencies">
  <data key="d0">Write-After-Read Dependencies</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Write-after-read dependencies are data hazards where a write occurs after a read, potentially causing data inconsistency in parallel execution.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hashing Variables">
  <data key="d0">Hashing Variables</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Hashing variables involves converting variable references into hashed identifiers to facilitate variable replacement and manage references during code transformations.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Function Inlining Algorithm">
  <data key="d0">Function Inlining Algorithm</data>
  <data key="d1">Methodologies</data>
  <data key="d2">This algorithm describes the process of replacing function calls with copies of function code, managing control flow with jump labels, replacing variables, and handling return nodes to optimize execution.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Evaluation Study">
  <data key="d0">Evaluation Study</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Evaluation assesses the effectiveness of the code generator and optimization toolchain by comparing generated code against benchmarks, measuring runtime and performance metrics.</data>
  <data key="d3">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Environment">
  <data key="d0">Environment</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The environment refers to the computational setup and hardware infrastructure used for performing measurements, including systems, processors, memory, network fabric, operating system, and GPU resources.&lt;SEP&gt;The environment refers to the specific hardware and software setup used for performing measurements, including systems, processors, memory, network fabric, operating system, and GPU resources.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="CLAIX18 systems">
  <data key="d0">CLAIX18 systems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The CLAIX18 systems are high-performance computing systems equipped with Xeon CPUs, NVIDIA GPUs, high-speed network fabric, and running Rocky 8.9 OS, used for conducting performance measurements.&lt;SEP&gt;The CLAIX18 systems are the specific high-performance computing systems used for measurements, equipped with Xeon CPUs, NVIDIA GPUs, high-speed network fabric, and running Rocky 8.9 OS.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="RWTH Aachen University">
  <data key="d0">RWTH Aachen University</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The university provides the research environment and infrastructure for conducting the experiments and measurements described.&lt;SEP&gt;The university provides the research infrastructure and environment for executing the experiments and measurements described in the study.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Xeon Platinum 8160">
  <data key="d0">Xeon Platinum 8160</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A CPU model used in the systems, featuring 24 cores at 2.1 GHz, used for parallel computation and performance testing.&lt;SEP&gt;A CPU model used in the systems, featuring 24 cores at 2.1 GHz, utilized for parallel processing tasks and performance benchmarking.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="NVIDIA V100 GPUs">
  <data key="d0">NVIDIA V100 GPUs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Graphics processing units used for GPU-accelerated computations in the systems.&lt;SEP&gt;Graphics processing units used to accelerate GPU-based kernels, enabling high-performance computations in the experiments.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rocky 8.9">
  <data key="d0">Rocky 8.9</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The Linux-based operating system running on the systems, providing the platform for code execution and environment management.&lt;SEP&gt;The operating system running on the systems, providing the environment for code execution and resource management.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intel Omni-Path 100G">
  <data key="d0">Intel Omni-Path 100G</data>
  <data key="d1">Tools</data>
  <data key="d2">High-speed network fabric connecting nodes within the system, facilitating fast data transfer necessary for parallel and distributed computations.&lt;SEP&gt;High-speed network fabric used to connect nodes within the system, enabling fast data transfer for parallel processing.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intel OneAPI C/C++ Compiler 2022.1.0">
  <data key="d0">Intel OneAPI C/C++ Compiler 2022.1.0</data>
  <data key="d1">Tools</data>
  <data key="d2">Compiler used for code compilation, optimization, and performance enhancement in the experiments.&lt;SEP&gt;Compiler used to compile code with high optimization levels, supporting performance tuning and code generation for the experiments.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="IntelMPI 2021.6.0">
  <data key="d0">IntelMPI 2021.6.0</data>
  <data key="d1">Tools</data>
  <data key="d2">MPI implementation used for message passing in distributed and parallel processing, especially for MPI-based kernels.&lt;SEP&gt;Message Passing Interface implementation used for parallel communication, especially in MPI-based kernels.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="CUDA 11.8">
  <data key="d0">CUDA 11.8</data>
  <data key="d1">Tools</data>
  <data key="d2">GPU programming toolkit used for compiling and running GPU-accelerated code, enabling development of GPU kernels and performance optimization.&lt;SEP&gt;GPU programming toolkit used to compile and run GPU-accelerated code on NVIDIA V100 GPUs.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Measurement methodology">
  <data key="d0">Measurement methodology</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The approach involves performing measurements without artificial synchronization, adding timing manually, and averaging over multiple repetitions to ensure accuracy.&lt;SEP&gt;The systematic approach involves manual timing, multiple repetitions (e.g., 40 runs), and avoiding artificial synchronization points to ensure accurate and reproducible performance measurements.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global optimization">
  <data key="d0">Global optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Optimization process designed to prevent artificial dependencies during measurements, ensuring the correctness of timing and performance data, by avoiding synchronization points and dependencies that could bias results.&lt;SEP&gt;Optimization process that avoids artificial dependencies to prevent measurement bias, ensuring the correctness of performance data.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Gurobi">
  <data key="d0">Gurobi</data>
  <data key="d1">Tools</data>
  <data key="d2">An optimization solver used for scheduling and MILP optimization, which introduces stochasticity due to random seed usage, mitigated by multiple seed runs to reduce instability in results.&lt;SEP&gt;Optimization solver used for scheduling and MILP optimization, with known instabilities due to its random seed usage, mitigated by multiple seeds.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Generator Results">
  <data key="d0">Generator Results</data>
  <data key="d1">Results</data>
  <data key="d2">The outcomes of evaluating different code versions across multiple kernels, showing performance metrics such as speedups and slowdowns compared to baseline and handwritten implementations.&lt;SEP&gt;The performance outcomes of different code versions (naive, handwritten, generated) across multiple kernels, including metrics like speedup, slowdown, and stability, used to evaluate code effectiveness.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rodinia benchmarks">
  <data key="d0">Rodinia benchmarks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A set of benchmark applications based on the Berkeley dwarfs, designed to evaluate the applicability, coverage, and performance of generated and optimized code on HPC workloads.&lt;SEP&gt;A suite of HPC benchmarks used to evaluate the applicability and coverage of the generated and optimized code, based on the Berkeley dwarfs.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance measurements">
  <data key="d0">Performance measurements</data>
  <data key="d1">Results</data>
  <data key="d2">Quantitative data such as runtime in seconds over multiple runs, used to compare different code versions and hardware configurations.&lt;SEP&gt;Quantitative runtime data collected over multiple runs, used to compare different code implementations and hardware configurations, providing metrics like execution time and speedup.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel kernels">
  <data key="d0">Parallel kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specific computational tasks (e.g., batch classification, Jacobi solver, Monte Carlo estimation, convolution, neural network) used to evaluate code performance in different processing environments.&lt;SEP&gt;Specific computational tasks such as batch classification, Jacobi solver, Monte Carlo estimation, convolution, and neural network inference, used to evaluate performance across CPU and GPU environments.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Speedups and slowdowns">
  <data key="d0">Speedups and slowdowns</data>
  <data key="d1">Results</data>
  <data key="d2">Performance metrics indicating how much faster or slower a particular code version runs relative to baseline or other implementations.&lt;SEP&gt;Performance metrics indicating relative improvements or regressions in runtime compared to baseline or other implementations, highlighting the effectiveness of optimizations.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Distributed kernels">
  <data key="d0">Distributed kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Kernels executed across multiple nodes or with GPU acceleration, often exhibiting performance impacts due to implementation details such as local reduction patterns and communication overhead.&lt;SEP&gt;Kernels executed across multiple nodes or with GPU acceleration, often showing performance impacts due to implementation details like local reduction patterns.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Application of generated code">
  <data key="d0">Application of generated code</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The generated code aims to improve computational performance, scalability, and efficiency of HPC applications, with implications for high-performance computing workflows and optimization strategies.&lt;SEP&gt;The generated code aims to improve performance, efficiency, and scalability of HPC applications, with implications for optimizing complex computational workflows.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance variability">
  <data key="d0">Performance variability</data>
  <data key="d1">Limitations</data>
  <data key="d2">Observed in some kernels (Monte Carlo, neural network) due to optimization instabilities or implementation challenges, indicating areas for further refinement.&lt;SEP&gt;Observed in some kernels (e.g., Monte Carlo, neural network) where optimization instabilities or implementation challenges cause inconsistent performance, indicating areas for further refinement.</data>
  <data key="d3">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPLin">
  <data key="d0">PPLin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A framework or approach designed to optimize and adapt code for parallel processing, including modifications, tuning, and performance measurement.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rodinia">
  <data key="d0">Rodinia</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark suite consisting of various computational workloads used to evaluate parallel computing performance.&lt;SEP&gt;A benchmark suite used for performance evaluation and characterization of heterogeneous computing workloads.&lt;SEP&gt;A benchmark suite used to evaluate and characterize the performance of heterogeneous computing architectures across various workloads.&lt;SEP&gt;Rodinia is a benchmark suite of parallel applications used to evaluate optimization techniques and parallel programming models.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-5cd0b27c19a2314eb0b2f819a6edfa2e&lt;SEP&gt;chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPLport">
  <data key="d0">PPLport</data>
  <data key="d1">Tools</data>
  <data key="d2">A porting tool or version of PPL designed to adapt benchmarks to different hardware configurations and sizes.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kmeans">
  <data key="d0">Kmeans</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A specific benchmark in Rodinia used for clustering analysis, optimized for better parallelism.&lt;SEP&gt;Kmeans is a clustering algorithm used in data analysis, subject to optimization for parallel execution.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="nnbenchmarks">
  <data key="d0">nnbenchmarks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Neural network benchmarks in Rodinia, optimized for improved performance.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dynamic control-flow">
  <data key="d0">Dynamic control-flow</data>
  <data key="d1">Limitations</data>
  <data key="d2">A challenge in optimization where code with nested or dynamic control structures cannot be effectively optimized by certain tools or algorithms.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory overhead">
  <data key="d0">Memory overhead</data>
  <data key="d1">Limitations</data>
  <data key="d2">A constraint where excessive memory requirements per thread hinder efficient execution and optimization.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Static workload">
  <data key="d0">Static workload</data>
  <data key="d1">Limitations</data>
  <data key="d2">A challenge where workloads with unpredictable or uneven distribution cause load imbalance and reduce efficiency.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Speedup of lavaMD">
  <data key="d0">Speedup of lavaMD</data>
  <data key="d1">Results</data>
  <data key="d2">A performance improvement of over two times achieved by the PPL-generated code, partly due to compiler optimizations.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hotspot3D">
  <data key="d0">Hotspot3D</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark in Rodinia with limited thread utilization, used to evaluate parallelization efficiency.&lt;SEP&gt;Hotspot3D is a benchmark application modeling heat distribution in 3D, used to evaluate parallel optimization techniques.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Backprop">
  <data key="d0">Backprop</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A neural network training benchmark in Rodinia, optimized to reduce synchronization and improve runtime.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance optimization">
  <data key="d0">Performance optimization</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The process of enhancing code to reduce runtime and improve efficiency, demonstrated by speedups in various benchmarks.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="port for the PPLin">
  <data key="d0">port for the PPLin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A component or version of the PPL framework used to adapt and optimize code for parallel execution, including features like configuration and measurement capabilities.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="previous work">
  <data key="d0">previous work</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Refers to earlier research or implementations related to PPLin, serving as a basis for current adaptations.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="errors detected by the compiler">
  <data key="d0">errors detected by the compiler</data>
  <data key="d1">Results</data>
  <data key="d2">Issues identified during code compilation indicating bugs or issues that need fixing.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="timing measurements">
  <data key="d0">timing measurements</data>
  <data key="d1">Tools</data>
  <data key="d2">Performance metrics collected to evaluate the runtime or efficiency of benchmarks.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="data set/configuration">
  <data key="d0">data set/configuration</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The specific data and configuration parameters used in benchmarks, such as size and complexity, defined by the scripts.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Rodinia codes">
  <data key="d0">Rodinia codes</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The source code implementations within the Rodinia benchmark suite, used for testing and optimization.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="seeds">
  <data key="d0">seeds</data>
  <data key="d1">Variables</data>
  <data key="d2">Random seed values used to initialize stochastic processes in benchmarks, ensuring reproducibility.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="deviation between different seeds">
  <data key="d0">deviation between different seeds</data>
  <data key="d1">Results</data>
  <data key="d2">The observed variation in benchmark results across different random seed initializations, indicating stability or variability.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="measurement">
  <data key="d0">measurement</data>
  <data key="d1">Results</data>
  <data key="d2">The process of recording runtime and performance data during benchmarking.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="optimized by the PPL">
  <data key="d0">optimized by the PPL</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Refers to the benchmarks that have been improved using the PPL framework, including kernel tuning and code rewriting.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="support status">
  <data key="d0">support status</data>
  <data key="d1">Limitations</data>
  <data key="d2">Indicates whether certain benchmarks are supported or not supported by the PPL framework, affecting their inclusion in performance analysis.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="not supported">
  <data key="d0">not supported</data>
  <data key="d1">Limitations</data>
  <data key="d2">Benchmarks that are either not ported to PPL or have significant kernel alterations preventing optimization.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="backprop">
  <data key="d0">backprop</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A neural network training benchmark in Rodinia, affected by limitations such as kernel splitting and dynamic control flow.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="heartwall">
  <data key="d0">heartwall</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark in Rodinia, noted for being well optimized, with minimal performance change after PPL optimization.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="hotspot3d">
  <data key="d0">hotspot3d</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A benchmark involving 3D hotspot computation, with limited thread utilization and specific parallelization constraints.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="lavaMD">
  <data key="d0">lavaMD</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A molecular dynamics simulation benchmark that experienced significant speedup due to compiler optimizations and parallelization.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="performance improvement">
  <data key="d0">performance improvement</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The overall benefit of optimization techniques, demonstrated through speedups and reduced runtime in benchmarks.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="static overhead">
  <data key="d0">static overhead</data>
  <data key="d1">Variables</data>
  <data key="d2">The fixed computational or synchronization overhead that can be reduced through optimization.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="optimization from the Intel OneAPI compiler">
  <data key="d0">optimization from the Intel OneAPI compiler</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Compiler-based enhancements that improve code performance, as seen in lavaMD.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="parallelism">
  <data key="d0">parallelism</data>
  <data key="d1">Variables</data>
  <data key="d2">Parallelism involves executing multiple computations simultaneously to enhance efficiency, especially within dynamic control flow structures like loops and branches.&lt;SEP&gt;The degree to which tasks can be executed simultaneously, critical for performance gains in benchmarks.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dataset sizes">
  <data key="d0">dataset sizes</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The size of data used in benchmarks, influencing the ability to utilize hardware resources effectively.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="multi-node parallelism">
  <data key="d0">multi-node parallelism</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Using multiple computing nodes to run benchmarks in parallel, increasing computational capacity.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="kernel splitting">
  <data key="d0">kernel splitting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Dividing kernels into smaller parts or separate applications to optimize performance, used in hotspot.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dynamic control-flow">
  <data key="d0">dynamic control-flow</data>
  <data key="d1">Limitations</data>
  <data key="d2">A challenge in optimization where code with nested or data-dependent control structures cannot be efficiently optimized.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="large search space">
  <data key="d0">large search space</data>
  <data key="d1">Limitations</data>
  <data key="d2">Refers to the extensive set of possible scheduling or optimization configurations, making automated optimization difficult.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="search space">
  <data key="d0">search space</data>
  <data key="d1">Variables</data>
  <data key="d2">The range of possible configurations or schedules in optimization tasks, impacting the feasibility of finding optimal solutions.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="task scheduling">
  <data key="d0">task scheduling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of assigning computational tasks to hardware resources, crucial for performance and load balancing.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="triangular matrix">
  <data key="d0">triangular matrix</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A matrix structure created during LU decomposition, which influences workload and optimization challenges.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="load imbalances">
  <data key="d0">load imbalances</data>
  <data key="d1">Limitations</data>
  <data key="d2">Unequal distribution of work across processing units, leading to inefficiencies.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="static assignment">
  <data key="d0">static assignment</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Assigning tasks to hardware resources based on static analysis, which can cause load imbalance in dynamic workloads.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="small runtime applications">
  <data key="d0">small runtime applications</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Benchmarks with short execution times, which benefit from reduced overhead and synchronization.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dataset size">
  <data key="d0">dataset size</data>
  <data key="d1">Variables</data>
  <data key="d2">The size of input data, affecting the ability of the PPL to decide on resource utilization.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="node">
  <data key="d0">node</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A computational unit in multi-node parallelism, used by benchmarks like particle and backprop.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="GPU utilization">
  <data key="d0">GPU utilization</data>
  <data key="d1">Variables</data>
  <data key="d2">The extent to which GPU resources are used during benchmark execution, influencing speedup potential.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="computation kernels">
  <data key="d0">computation kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Core computational routines within benchmarks, targeted for optimization.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="element-wise iteration">
  <data key="d0">element-wise iteration</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A rewriting technique replacing tiled kernels with straightforward element-wise loops to avoid branches.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="corner cases">
  <data key="d0">corner cases</data>
  <data key="d1">Variables</data>
  <data key="d2">Specific data or boundary conditions in stencil computations, handled separately to optimize performance.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="parallel execution of edge cases and main stencil">
  <data key="d0">parallel execution of edge cases and main stencil</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An approach to improve parallelism by executing boundary and main computations concurrently, leading to speedup.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="runtime reduction">
  <data key="d0">runtime reduction</data>
  <data key="d1">Results</data>
  <data key="d2">Decreased execution time achieved through various optimization strategies.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="performance gains">
  <data key="d0">performance gains</data>
  <data key="d1">Results</data>
  <data key="d2">Overall improvements in speed, efficiency, or resource utilization demonstrated in benchmarks.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="optimization limitations">
  <data key="d0">optimization limitations</data>
  <data key="d1">Limitations</data>
  <data key="d2">Factors such as unsupported kernels, dynamic control flow, or large search spaces that restrict optimization effectiveness.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="multi-threading">
  <data key="d0">multi-threading</data>
  <data key="d1">Variables</data>
  <data key="d2">The use of multiple threads to execute code concurrently, essential for parallel speedups.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="parallelization constraints">
  <data key="d0">parallelization constraints</data>
  <data key="d1">Limitations</data>
  <data key="d2">Restrictions on how code can be parallelized, affecting achievable speedups.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="kernel alterations">
  <data key="d0">kernel alterations</data>
  <data key="d1">Limitations</data>
  <data key="d2">Significant changes to kernel code, such as splitting or rewriting, which can impact optimization strategies.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dataset size influence">
  <data key="d0">dataset size influence</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Smaller datasets allow for more effective optimization and resource utilization, leading to better speedups.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="static analysis">
  <data key="d0">static analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to analyze code without executing it, used to determine workload distribution and optimization potential.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="extraction of corner cases">
  <data key="d0">extraction of corner cases</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Process of isolating boundary or special cases in stencil computations to optimize kernels.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="elimination of synchronization">
  <data key="d0">elimination of synchronization</data>
  <data key="d1">Results</data>
  <data key="d2">Reduction in synchronization points in code, leading to faster execution.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="speedup visualization">
  <data key="d0">speedup visualization</data>
  <data key="d1">Results</data>
  <data key="d2">A graphical depiction of performance improvements across benchmarks, highlighting the effectiveness of optimizations.&lt;SEP&gt;Graphical representation of performance improvements, such as in Figure 1.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="speedup factors">
  <data key="d0">speedup factors</data>
  <data key="d1">Results</data>
  <data key="d2">Numerical values indicating how many times faster the optimized code runs compared to baseline.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="performance variability">
  <data key="d0">performance variability</data>
  <data key="d1">Results</data>
  <data key="d2">Differences observed in benchmark results across different runs or configurations, indicating stability or inconsistency.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="benchmark suite">
  <data key="d0">benchmark suite</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A collection of standardized benchmarks, such as Rodinia, used for evaluating optimization techniques.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="parallel baseline">
  <data key="d0">parallel baseline</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The original, unoptimized implementation of benchmarks used as a reference for measuring speedup.</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Backprop, nn, srad, lavaMD Benchmarks">
  <data key="d0">Backprop, nn, srad, lavaMD Benchmarks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Benchmark applications used to evaluate the effectiveness of the proposed performance optimization approach, each with specific characteristics and potential for speedups.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PPL (Parallel Pattern Language)">
  <data key="d0">PPL (Parallel Pattern Language)</data>
  <data key="d1">Methodology</data>
  <data key="d2">A framework that abstracts parallelism into reusable patterns, enabling automatic, global optimization across heterogeneous architectures from a single source code base.&lt;SEP&gt;A framework that enables static code analysis and global optimization for heterogeneous architectures, supporting single-source code, abstracted parallelism, and potential for compiler-driven speedups.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Static Code">
  <data key="d0">Static Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Source code that remains unchanged during execution, which the PPL approach aims to optimize automatically for various architectures.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Compiler Optimizations">
  <data key="d0">Compiler Optimizations</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Techniques applied by compilers to improve code speed and efficiency, including aggressive optimization strategies enabled by the PPL framework.&lt;SEP&gt;Techniques applied during compilation to enhance code performance, including aggressive optimizations enabled by the PPL framework.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="C/C++, Fortran">
  <data key="d0">C/C++, Fortran</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Programming languages that are commonly used in scientific applications, which the proposed approach aims to support for easier porting and reusability.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Annotations (e.g., OpenMP)">
  <data key="d0">Annotations (e.g., OpenMP)</data>
  <data key="d1">Tools</data>
  <data key="d2">Directive-based annotations that identify parallel regions in source code, facilitating porting and parallelization.&lt;SEP&gt;Directive-based annotations to identify parallel patterns in source code, facilitating porting and parallelization.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kernels (batch, jacobi, monte)">
  <data key="d0">Kernels (batch, jacobi, monte)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specific computational kernels evaluated for performance, some of which do not yet achieve speedups due to pending optimizations like kernel fusion or reduction implementations.&lt;SEP&gt;Specific computational kernels whose performance impacts the overall effectiveness of the optimization approach; some kernels do not yet achieve speedups.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kernel Fusion, Reduction Implementations">
  <data key="d0">Kernel Fusion, Reduction Implementations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Optimization techniques aimed at improving kernel performance, including combining operations and efficient reduction strategies.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dynamic Behavior">
  <data key="d0">Dynamic Behavior</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Application behaviors that change during runtime, such as workload variability, which challenge static optimization approaches.&lt;SEP&gt;Application characteristics that change during runtime, such as workload variability, which challenge static optimization approaches.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Legion, StarPU">
  <data key="d0">Legion, StarPU</data>
  <data key="d1">Tools</data>
  <data key="d2">Runtime systems that support dynamic task scheduling and load balancing, enabling execution of patterns with unknown sizes and migration of tasklets during runtime, also supporting GPU execution.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tasklet Scheduling">
  <data key="d0">Tasklet Scheduling</data>
  <data key="d1">Methodology</data>
  <data key="d2">Approach to managing execution units in parallel applications, with scalability issues in complex benchmarks due to exponential search space.&lt;SEP&gt;Approaches for managing execution units in parallel applications, with scalability challenges for complex benchmarks due to exponential search spaces.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory Model">
  <data key="d0">Memory Model</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Design of data storage and movement strategies within code generators to minimize local copies and improve performance.&lt;SEP&gt;Design of data storage and movement strategies within code generators to minimize local memory copies and improve performance.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Static Overhead">
  <data key="d0">Static Overhead</data>
  <data key="d1">&lt;|Core Concepts</data>
  <data key="d2">Static overhead involves fixed computational costs that can be reduced through optimization techniques to improve overall performance.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Backprop, nn, srad, lavaMD">
  <data key="d0">Backprop, nn, srad, lavaMD</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">Benchmark applications used to evaluate the effectiveness of performance optimization strategies, with specific focus on their speedups and overhead reductions.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Single Source">
  <data key="d0">Single Source</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">A codebase that remains unchanged across different hardware architectures, facilitating portability and maintainability in scientific applications.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Heterogeneous Architectures">
  <data key="d0">Heterogeneous Architectures</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">Computing systems composed of diverse processing units (CPUs, GPUs, accelerators) targeted by the PPL approach for optimization.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Code Porting">
  <data key="d0">Code Porting</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">The process of adapting existing codebases, often in C/C++ or Fortran, to new architectures or frameworks, which the PPL aims to simplify.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kernel Fusion">
  <data key="d0">Kernel Fusion</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">Optimization technique that combines multiple kernels to reduce overhead and improve performance.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Reduction Implementation">
  <data key="d0">Reduction Implementation</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">Strategies for efficient reduction operations in kernels, addressing shared memory, distributed memory, and offloading challenges.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Alias Elimination">
  <data key="d0">Alias Elimination</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">Techniques to remove redundant or conflicting data references during compile time, improving optimization and reducing runtime overhead.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dependency Chain">
  <data key="d0">Dependency Chain</data>
  <data key="d1">&lt;|Variables</data>
  <data key="d2">Sequences of data dependencies that can be analyzed to identify runtime arguments and control flow variables, aiding static analysis.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Runtime-Dependent Applications">
  <data key="d0">Runtime-Dependent Applications</data>
  <data key="d1">&lt;|Objects of Study</data>
  <data key="d2">Applications whose behavior depends on runtime data, requiring dynamic analysis or adaptation for efficient execution.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Legion">
  <data key="d0">Legion</data>
  <data key="d1">&lt;|Tools</data>
  <data key="d2">A runtime system supporting execution of patterns/tasklets with unknown sizes, enabling dynamic load balancing and GPU offloading.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="StarPU">
  <data key="d0">StarPU</data>
  <data key="d1">&lt;|Tools</data>
  <data key="d2">A runtime system that supports dynamic task migration across distributed memory and offloading to GPUs, addressing load imbalance and dynamic workloads.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Exponential Search Space">
  <data key="d0">Exponential Search Space</data>
  <data key="d1">&lt;|Variables</data>
  <data key="d2">The vast number of possible scheduling configurations in complex benchmarks, which hampers scalability and optimization.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pruning Strategies (n-best)">
  <data key="d0">Pruning Strategies (n-best)</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">Techniques used within beam search to limit candidate solutions, controlling compile time and improving stability.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Variable Names">
  <data key="d0">Variable Names</data>
  <data key="d1">&lt;|Variables</data>
  <data key="d2">Names influenced by random seeds affecting the duration and stability of solving processes in benchmarks.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="LP-Solvers">
  <data key="d0">LP-Solvers</data>
  <data key="d1">&lt;|Tools</data>
  <data key="d2">Linear programming solvers used for optimization, which can be replaced with custom methods like beam search for better predictability.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Custom Implementation of Beam Search">
  <data key="d0">Custom Implementation of Beam Search</data>
  <data key="d1">&lt;|Methodologies</data>
  <data key="d2">A tailored search approach to improve predictability and stability in scheduling, reducing the impact of random seed variability.</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="source">
  <data key="d0">source</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The source refers to the origin or starting point of data within the optimization process, crucial for understanding data flow and management in parallel computing applications.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="destination">
  <data key="d0">destination</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The destination indicates where data is directed during optimization, affecting data transfer and resource allocation.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="amount of data">
  <data key="d0">amount of data</data>
  <data key="d1">Variables</data>
  <data key="d2">The amount of data pertains to the volume of data involved in the optimization, influencing computational load and performance.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dynamic control flow structures">
  <data key="d0">dynamic control flow structures</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dynamic control flow structures, such as loops and branches, determine the execution path of programs and are key to optimizing parallel execution.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="unrolling large loops">
  <data key="d0">unrolling large loops</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Unrolling large loops is a technique to transform iterative processes into sequential steps to facilitate parallel execution and reduce overhead.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="streamcluster">
  <data key="d0">streamcluster</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Streamcluster is a benchmark application used to evaluate parallel processing and optimization techniques.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="cfd">
  <data key="d0">cfd</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">CFD (Computational Fluid Dynamics) is a domain-specific application involving complex simulations of fluid flows, relevant for parallel optimization.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="memory model">
  <data key="d0">memory model</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The memory model defines how data is stored, accessed, and managed during program execution, impacting efficiency and optimization strategies.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="local memory copies">
  <data key="d0">local memory copies</data>
  <data key="d1">Variables</data>
  <data key="d2">Local memory copies involve duplicating data within local memory to optimize access, but can introduce overhead and complexity.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="particle">
  <data key="d0">particle</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Particles are fundamental units in simulations, such as in physics or fluid dynamics, whose data management affects performance.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="myocyte">
  <data key="d0">myocyte</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Myocytes are muscle cells involved in biological simulations, relevant in modeling and data management.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="global optimization step">
  <data key="d0">global optimization step</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A global optimization step aims to improve overall program performance by eliminating redundant or unnecessary local copies of data.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="local copy">
  <data key="d0">local copy</data>
  <data key="d1">Variables</data>
  <data key="d2">A local copy is a duplicate of data stored locally to reduce access latency, but may increase memory overhead.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="access by reference">
  <data key="d0">access by reference</data>
  <data key="d1">Variables</data>
  <data key="d2">Access by reference involves directly using data locations without copying, to optimize memory use and performance.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="physical simulation">
  <data key="d0">physical simulation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Physical simulation models real-world phenomena, such as wave propagation, requiring efficient computation and parallel processing.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="weak scaling">
  <data key="d0">weak scaling</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Weak scaling assesses how the application performs as the problem size and resources increase proportionally, maintaining efficiency.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="iterative solvers">
  <data key="d0">iterative solvers</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Iterative solvers are algorithms used to approximate solutions for complex physics equations in simulations, often involving multiple iterations over time steps.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="propagation logic">
  <data key="d0">propagation logic</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Propagation logic refers to the algorithms governing wave or particle movement within simulations, critical for accurate modeling.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="parallel patterns">
  <data key="d0">parallel patterns</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Parallel patterns are programming constructs that facilitate concurrent execution, essential for optimizing large-scale applications.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dynamic behavior">
  <data key="d0">dynamic behavior</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dynamic behavior describes how applications change execution flow during runtime, influencing optimization strategies.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="global optimization approach">
  <data key="d0">global optimization approach</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A global optimization approach analyzes entire programs to identify and improve performance bottlenecks across parallel structures.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="parallel programs">
  <data key="d0">parallel programs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Parallel programs are software that execute multiple computations simultaneously, requiring specialized analysis and optimization.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="analysis and view">
  <data key="d0">analysis and view</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Analysis and view techniques are used to understand program behavior and identify optimization opportunities in parallel code.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="intermediate representation">
  <data key="d0">intermediate representation</data>
  <data key="d1">Tools</data>
  <data key="d2">Intermediate representation is a form of code used internally by compilers and tools to facilitate optimization and analysis.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="high-level source code">
  <data key="d0">high-level source code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">High-level source code is the human-readable programming language code that serves as input for compilers and tools.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="code generator">
  <data key="d0">code generator</data>
  <data key="d1">Tools</data>
  <data key="d2">A code generator translates high-level source code into optimized machine code, enabling performance improvements.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="global optimizations">
  <data key="d0">global optimizations</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Global optimizations analyze entire programs to improve performance, concurrency, and resource utilization.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="heterogeneous architectures">
  <data key="d0">heterogeneous architectures</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Heterogeneous architectures are computing systems composed of diverse processing units such as CPUs, GPUs, and other accelerators, requiring specialized programming models for performance optimization.&lt;SEP&gt;Heterogeneous architectures combine different types of processing units, such as CPUs and GPUs, to enhance computational efficiency.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="performance portability">
  <data key="d0">performance portability</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Performance portability ensures that code performs efficiently across various hardware platforms without modification.&lt;SEP&gt;Performance portability refers to the capability of software or applications to run efficiently across different hardware architectures without significant modification, enabling flexibility and scalability in high-performance computing.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="speedups">
  <data key="d0">speedups</data>
  <data key="d1">Results</data>
  <data key="d2">Speedups refer to the improvement in execution time achieved through optimization techniques, with up to 12.43x reported.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="concurrency">
  <data key="d0">concurrency</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Concurrency involves executing multiple program parts simultaneously, increasing efficiency and resource utilization.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="kmeans">
  <data key="d0">kmeans</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Kmeans is a clustering algorithm used in data analysis, subject to optimization for parallel execution.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="hotspot3D">
  <data key="d0">hotspot3D</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Hotspot3D is a benchmark application modeling heat distribution in 3D, used to evaluate parallel optimization.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="reduction implementation">
  <data key="d0">reduction implementation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Reduction implementation involves aggregating data across processes, crucial for efficient parallel reduction operations.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="local copies">
  <data key="d0">local copies</data>
  <data key="d1">Variables</data>
  <data key="d2">Local copies are duplicated data segments to reduce access latency but can increase memory overhead.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="pruning strategies">
  <data key="d0">pruning strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Pruning strategies are techniques to reduce the search space in scheduling algorithms, improving efficiency.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="scheduling algorithms">
  <data key="d0">scheduling algorithms</data>
  <data key="d1">Tools</data>
  <data key="d2">Scheduling algorithms manage task execution order and resource allocation, impacting overall performance.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="C/C++">
  <data key="d0">C/C++</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">C and C++ are programming languages supported in future work to facilitate application porting and testing.&lt;SEP&gt;C and C++ are programming languages that will be supported to facilitate application porting and testing.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="dynamic load balancers">
  <data key="d0">dynamic load balancers</data>
  <data key="d1">Tools</data>
  <data key="d2">Dynamic load balancers distribute work during runtime, adapting to changing application demands for better performance.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dynamic control flow structures">
  <data key="d0">Dynamic control flow structures</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dynamic control flow structures, including loops and branches, determine execution paths in programs and are key targets for optimization to enable parallel execution.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Unrolling large loops">
  <data key="d0">Unrolling large loops</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Unrolling large loops is a technique to transform iterative processes into sequential steps, reducing overhead and enabling better parallelization.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Streamcluster">
  <data key="d0">Streamcluster</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Streamcluster is a benchmark application used to evaluate parallelization and optimization techniques in high-performance computing.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="CFD">
  <data key="d0">CFD</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">CFD (Computational Fluid Dynamics) is a domain-specific simulation modeling fluid flows, relevant for optimization in scientific computing.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory model">
  <data key="d0">Memory model</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The memory model defines how data is stored and accessed during program execution, impacting efficiency and optimization strategies.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Local memory copies">
  <data key="d0">Local memory copies</data>
  <data key="d1">Variables</data>
  <data key="d2">Local memory copies are duplicated data segments to optimize access latency but may introduce overhead and complexity.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Particle">
  <data key="d0">Particle</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Particles are fundamental units in physical simulations, affecting data management and computational performance.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Myocyte">
  <data key="d0">Myocyte</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Myocytes are biological muscle cells involved in biological simulations, relevant for data handling and modeling.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global optimization step">
  <data key="d0">Global optimization step</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A global optimization step aims to eliminate redundant local copies of data to improve overall performance and reduce memory overhead.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Local copy">
  <data key="d0">Local copy</data>
  <data key="d1">Variables</data>
  <data key="d2">A local copy is a duplicate of data stored locally to reduce access latency, but can lead to increased memory usage and overhead.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Access by reference">
  <data key="d0">Access by reference</data>
  <data key="d1">Variables</data>
  <data key="d2">Access by reference involves directly referencing data locations without copying, optimizing memory use and performance.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Physical simulation">
  <data key="d0">Physical simulation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Physical simulation models real-world phenomena like wave propagation, requiring efficient computation and parallel execution.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Weak scaling">
  <data key="d0">Weak scaling</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Weak scaling assesses how the application performs as problem size and resources increase proportionally, maintaining efficiency.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Iterative solvers">
  <data key="d0">Iterative solvers</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Iterative solvers are algorithms that approximate solutions for physics-based equations through multiple iterations, used in simulations like LULESH.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Propagation logic">
  <data key="d0">Propagation logic</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Propagation logic refers to the algorithms governing the movement of waves or particles in simulations, essential for accurate modeling.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dynamic behavior">
  <data key="d0">Dynamic behavior</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dynamic behavior describes how applications change execution flow during runtime, influencing optimization approaches.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Global optimization approach">
  <data key="d0">Global optimization approach</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A global optimization approach analyzes entire programs to identify and improve performance bottlenecks across parallel structures.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel programs">
  <data key="d0">Parallel programs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Parallel programs are software systems that execute multiple tasks simultaneously, requiring analysis and optimization for efficiency.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Analysis and view">
  <data key="d0">Analysis and view</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Analysis and view techniques help understand program behavior and identify optimization opportunities in parallel applications.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intermediate representation">
  <data key="d0">Intermediate representation</data>
  <data key="d1">Tools</data>
  <data key="d2">Intermediate representation is an internal code form used by compilers and tools to facilitate analysis and optimization.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="High-level source code">
  <data key="d0">High-level source code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">High-level source code is the human-readable programming language code that serves as input for compilers and optimization tools.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Heterogeneous architectures">
  <data key="d0">Heterogeneous architectures</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Heterogeneous architectures combine different processing units like CPUs and GPUs to improve computational efficiency.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance portability">
  <data key="d0">Performance portability</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Performance portability ensures that optimized code performs efficiently across various hardware platforms without requiring modifications.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Speedups">
  <data key="d0">Speedups</data>
  <data key="d1">Results</data>
  <data key="d2">Speedups refer to the reduction in execution time achieved through optimization, with up to 12.43x improvements reported.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Concurrency">
  <data key="d0">Concurrency</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Concurrency involves executing multiple parts of a program simultaneously, increasing efficiency and resource utilization.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Reduction implementation">
  <data key="d0">Reduction implementation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Reduction implementation involves aggregating data across processes efficiently, critical for parallel reduction operations.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Local copies">
  <data key="d0">Local copies</data>
  <data key="d1">Variables</data>
  <data key="d2">Local copies are duplicated data segments created to reduce access latency but can increase memory overhead and complexity.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Scalability">
  <data key="d0">Scalability</data>
  <data key="d1">Variables</data>
  <data key="d2">Scalability evaluates how well a system or algorithm performs as problem size or resources increase, important for scheduling and load balancing.&lt;SEP&gt;Scalability refers to the system's capacity to handle increasing volumes of knowledge data and complex retrieval tasks without performance degradation."|&lt;SEP&gt;This concept pertains to the challenge of efficiently scaling domain-specific training and fine-tuning processes across multiple or large, complex domains.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20&lt;SEP&gt;chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pruning strategies">
  <data key="d0">Pruning strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Pruning strategies are techniques to reduce search space in scheduling algorithms, improving efficiency and scalability.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Scheduling algorithms">
  <data key="d0">Scheduling algorithms</data>
  <data key="d1">Tools</data>
  <data key="d2">Scheduling algorithms determine the order and allocation of tasks for execution, impacting overall performance and scalability.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dynamic load balancers">
  <data key="d0">Dynamic load balancers</data>
  <data key="d1">Tools</data>
  <data key="d2">Dynamic load balancers distribute computational workload during runtime, adapting to changing application demands for improved performance.</data>
  <data key="d3">chunk-e578b0d9bfe757587fab19ecc63b4d20</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance Portability on Heterogeneous Architectures">
  <data key="d0">Performance Portability on Heterogeneous Architectures</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Performance portability refers to the ability of software to maintain efficient performance across diverse hardware architectures, especially heterogeneous systems, enabling flexible and scalable high-performance computing solutions.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Proceedings of the 40">
  <data key="d0">Proceedings of the 40</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A scholarly conference proceeding documenting research on performance portability and related high-performance computing topics, published in 2025.&lt;SEP&gt;A scholarly publication documenting research related to performance portability, presented at ACM Digital Library, including conference details and publication date.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Schmitz et al.">
  <data key="d0">Schmitz et al.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of the research paper discussing performance portability on heterogeneous architectures.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="ACM Digital Library">
  <data key="d0">ACM Digital Library</data>
  <data key="d1">Tools</data>
  <data key="d2">Digital repository hosting the research publication, facilitating access and dissemination of scholarly articles.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tal Ben-Nun et al.">
  <data key="d0">Tal Ben-Nun et al.</data>
  <data key="d1">Researcher</data>
  <data key="d2">A group of researchers who authored the technical report on Data Centric Parallel Programming, contributing methodologies for parallel computing.&lt;SEP&gt;Authors of the technical report on Data Centric Parallel Programming, contributing to methodologies for high-performance computing.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Data Centric Parallel Programming">
  <data key="d0">Data Centric Parallel Programming</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A programming paradigm emphasizing data movement and locality to optimize performance on parallel and heterogeneous systems.&lt;SEP&gt;A programming paradigm focusing on data movement and locality to optimize performance on parallel architectures.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Ernesto G Birgin, João Eduardo Ferreira, and Débora Pretti Ronconi">
  <data key="d0">Ernesto G Birgin, João Eduardo Ferreira, and Débora Pretti Ronconi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of a study on beam search method for permutation flowshop scheduling, addressing optimization problems in manufacturing.&lt;SEP&gt;Authors who developed a filtered beam search method aimed at solving permutation flowshop scheduling problems with minimal penalties and waiting times.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Filtered Beam Search Method">
  <data key="d0">Filtered Beam Search Method</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An optimization algorithm designed to efficiently explore solution spaces for complex scheduling problems, reducing penalties and wait times.&lt;SEP&gt;An optimization technique designed to efficiently solve permutation flowshop scheduling problems by reducing search space and penalties.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Pradip Bose">
  <data key="d0">Pradip Bose</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of work on Power Wall, discussing limitations in power consumption for high-performance computing systems.&lt;SEP&gt;Author of work on the Power Wall, analyzing the power consumption limits impacting high-performance computing systems.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Power Wall">
  <data key="d0">Power Wall</data>
  <data key="d1">Limitations</data>
  <data key="d2">A fundamental constraint in high-performance computing where power and thermal limits restrict further performance improvements.&lt;SEP&gt;A phenomenon where increasing performance in computing systems is constrained by power consumption and thermal limits.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Shuai Che et al.">
  <data key="d0">Shuai Che et al.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of the benchmark suite Rodinia, aimed at evaluating heterogeneous computing systems.&lt;SEP&gt;Authors who created Rodinia, a benchmark suite for evaluating heterogeneous computing systems.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Philipp Ciechanowicz, Michael Poldner, and Herbert Kuchen">
  <data key="d0">Philipp Ciechanowicz, Michael Poldner, and Herbert Kuchen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors providing an overview of the Münster Skeleton Library muesli, a software tool for skeleton-based parallel programming.&lt;SEP&gt;Authors who provided an overview of the Münster Skeleton Library muesli, a software framework for structured parallel programming using skeletons.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Münster Skeleton Library muesli">
  <data key="d0">Münster Skeleton Library muesli</data>
  <data key="d1">Tools</data>
  <data key="d2">A comprehensive software library facilitating structured management of parallel computations through skeletons.&lt;SEP&gt;A software library supporting structured parallel programming through the use of skeletons, facilitating modular and efficient code development.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Murray Cole">
  <data key="d0">Murray Cole</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of "Algorithmic Skeletons," a foundational text on managing parallel computations through high-level abstractions.&lt;SEP&gt;Author of "Algorithmic Skeletons," a foundational work on structured parallel computation management.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Algorithmic Skeletons">
  <data key="d0">Algorithmic Skeletons</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A conceptual framework for designing and managing parallel algorithms using high-level skeletons to improve modularity and performance.&lt;SEP&gt;A conceptual framework for structuring parallel algorithms using high-level skeletons to improve code clarity, modularity, and performance.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Massimiliano Fatica">
  <data key="d0">Massimiliano Fatica</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author discussing CUDA toolkit and libraries, essential tools for GPU programming and performance optimization.&lt;SEP&gt;Author discussing CUDA toolkit and libraries, tools for GPU programming and performance optimization.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="CUDA Toolkit and Libraries">
  <data key="d0">CUDA Toolkit and Libraries</data>
  <data key="d1">Tools</data>
  <data key="d2">A collection of software libraries and tools for developing high-performance GPU-accelerated applications, supporting parallel computing.&lt;SEP&gt;A suite of software tools and libraries for developing high-performance GPU-accelerated applications.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Free Software Foundation">
  <data key="d0">Free Software Foundation</data>
  <data key="d1">Organization</data>
  <data key="d2">An organization that maintains and documents GCC, a widely used compiler supporting multiple languages and optimization techniques.&lt;SEP&gt;Maintains and documents GCC, a compiler system supporting various programming languages and optimization features.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="GCC 13.2 Manual">
  <data key="d0">GCC 13.2 Manual</data>
  <data key="d1">Tools</data>
  <data key="d2">Official documentation for GCC compiler version 13.2, providing guidance on compiler features and usage.&lt;SEP&gt;Official documentation providing guidance on the features, options, and usage of GCC version 13.2 for compiler optimizations.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Prometeus GmbH">
  <data key="d0">Prometeus GmbH</data>
  <data key="d1">Organization</data>
  <data key="d2">Maintains the Top500 List, ranking supercomputers worldwide based on performance metrics.&lt;SEP&gt;Maintains the Top500 List, ranking the most powerful supercomputers worldwide based on performance metrics.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Top500 List">
  <data key="d0">Top500 List</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A biannual ranking of the top supercomputers globally, used as a benchmark for high-performance computing advancements.&lt;SEP&gt;A ranking of the most powerful supercomputers, updated biannually to reflect advancements in high-performance computing.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Maxime Gonthier, Loris Marchal, and Samuel Thibault">
  <data key="d0">Maxime Gonthier, Loris Marchal, and Samuel Thibault</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of work on locality-aware scheduling for runtime systems, aiming to improve task scheduling efficiency.&lt;SEP&gt;Authors who researched locality-aware scheduling techniques to improve runtime system efficiency for parallel tasks.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Locality-Aware Scheduling">
  <data key="d0">Locality-Aware Scheduling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A scheduling approach that considers data locality to optimize task execution on modern architectures.&lt;SEP&gt;A scheduling approach that optimizes task placement based on data locality to reduce communication overhead and improve performance.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tobias Grosser, Armin Groesslinger, and Christian Lengauer">
  <data key="d0">Tobias Grosser, Armin Groesslinger, and Christian Lengauer</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of work on Polly, a tool for polyhedral optimizations on low-level intermediate representations.&lt;SEP&gt;Authors who developed Polly, a tool for performing polyhedral optimizations on low-level intermediate representations in compilers.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Polly">
  <data key="d0">Polly</data>
  <data key="d1">Tools</data>
  <data key="d2">A compiler optimization framework for performing polyhedral transformations to enhance code performance.&lt;SEP&gt;A compiler optimization framework that applies polyhedral transformations to generate efficient code for loop nests and affine computations.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Gurobi Optimization, LLC">
  <data key="d0">Gurobi Optimization, LLC</data>
  <data key="d1">Organization</data>
  <data key="d2">Provider of Gurobi, a leading optimization solver used for solving linear, integer, and quadratic programming problems.&lt;SEP&gt;Provider of the Gurobi Optimizer, a software suite for solving complex mathematical optimization problems.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Gurobi Optimizer Reference Manual">
  <data key="d0">Gurobi Optimizer Reference Manual</data>
  <data key="d1">Tools</data>
  <data key="d2">Official documentation detailing Gurobi's features, usage, and API for solving complex optimization problems.&lt;SEP&gt;Official documentation detailing features and usage of the Gurobi optimization software.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Jeff R. Hammond, Sayan Ghosh, and Barbara M. Chapman">
  <data key="d0">Jeff R. Hammond, Sayan Ghosh, and Barbara M. Chapman</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of work on implementing OpenSHMEM using MPI-3 one-sided communication, contributing to parallel programming models.&lt;SEP&gt;Authors who worked on implementing OpenSHMEM using MPI-3 one-sided communication, advancing parallel programming models.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenSHMEM Using MPI-3 One-Sided Communication">
  <data key="d0">OpenSHMEM Using MPI-3 One-Sided Communication</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A parallel programming technique that implements shared memory semantics over MPI-3, improving communication efficiency in distributed systems.&lt;SEP&gt;A technique for implementing shared memory programming models on distributed systems to improve communication efficiency.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Mark Harris et al.">
  <data key="d0">Mark Harris et al.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of work on optimizing parallel reduction in CUDA, enhancing GPU-based parallel algorithms.&lt;SEP&gt;Authors who optimized parallel reduction algorithms in CUDA to improve GPU performance.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Reduction in CUDA">
  <data key="d0">Parallel Reduction in CUDA</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">A method for efficiently aggregating data across GPU threads, essential for many parallel algorithms.&lt;SEP&gt;A technique for efficiently aggregating data in parallel on GPUs, critical for many high-performance computations.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Torsten Hoefler, Christian Siebert, and Andrew Lumsdaine">
  <data key="d0">Torsten Hoefler, Christian Siebert, and Andrew Lumsdaine</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of work on scalable communication protocols for dynamic sparse data exchange, addressing communication challenges in distributed systems.&lt;SEP&gt;Authors who developed scalable communication protocols for dynamic sparse data exchange in distributed systems.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Scalable Communication Protocols">
  <data key="d0">Scalable Communication Protocols</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Protocols designed to efficiently handle data exchange in large, dynamic, and sparse data environments across distributed architectures.&lt;SEP&gt;Protocols designed to efficiently handle data exchange in large-scale, dynamic sparse data environments.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Intel Corporation">
  <data key="d0">Intel Corporation</data>
  <data key="d1">Organization</data>
  <data key="d2">A major technology company that develops the oneAPI Threading Building Blocks (TBB), a C++ library for parallel programming.&lt;SEP&gt;Developer of oneAPI Threading Building Blocks (TBB), a C++ library for parallel programming.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="oneAPI Threading Building Blocks">
  <data key="d0">oneAPI Threading Building Blocks</data>
  <data key="d1">Tools</data>
  <data key="d2">A C++ template library for task-based parallelism, facilitating high-level parallel programming across architectures.&lt;SEP&gt;A high-level C++ library facilitating task-based parallelism, enabling portable and efficient parallel code across hardware architectures.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="I Karlin, J Keasler, and J R Neely">
  <data key="d0">I Karlin, J Keasler, and J R Neely</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of updates on LULESH 2.0, a hydrodynamics mini-application for benchmarking and testing high-performance computing systems.&lt;SEP&gt;Authors who provided updates and enhancements to LULESH 2.0, a hydrodynamics mini-application used for benchmarking supercomputers.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="LULESH 2.0">
  <data key="d0">LULESH 2.0</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A computational hydrodynamics simulation used for evaluating supercomputers and parallel systems.&lt;SEP&gt;A mini-application simulating hydrodynamics, used as a benchmark for evaluating supercomputing performance and scalability.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dominic Kempf, René Heß, Steffen Müthing, and Peter Bastian">
  <data key="d0">Dominic Kempf, René Heß, Steffen Müthing, and Peter Bastian</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of work on automatic code generation for high-performance discontinuous Galerkin methods on modern architectures.&lt;SEP&gt;Authors who developed automatic code generation techniques for high-performance discontinuous Galerkin methods tailored to modern architectures.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Automatic Code Generation for Discontinuous Galerkin Methods">
  <data key="d0">Automatic Code Generation for Discontinuous Galerkin Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique for generating optimized code automatically to improve performance of numerical methods on modern hardware.&lt;SEP&gt;A technique to automatically produce optimized code for complex numerical methods, improving performance on modern hardware.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Chris Lattner and Vikram Adve">
  <data key="d0">Chris Lattner and Vikram Adve</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of LLVM, a compiler infrastructure supporting program analysis, transformation, and optimization.&lt;SEP&gt;Authors of the LLVM framework, a compiler infrastructure supporting program analysis and transformation.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Lawrence Livermore National Laboratory">
  <data key="d0">Lawrence Livermore National Laboratory</data>
  <data key="d1">Organization</data>
  <data key="d2">A research institution that developed RAJA, a performance portability layer for high-performance computing.&lt;SEP&gt;Developer of RAJA, a performance portability layer for portable performance across hardware architectures.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="RAJA">
  <data key="d0">RAJA</data>
  <data key="d1">Tools</data>
  <data key="d2">A performance portability library designed to enable developers to write code that can run efficiently across various hardware architectures, including CPUs and GPUs.&lt;SEP&gt;A performance portability library that enables developers to write portable high-performance code across different hardware architectures.&lt;SEP&gt;A software abstraction layer that facilitates writing portable performance code across diverse hardware architectures.&lt;SEP&gt;A software library that provides abstractions for performance-portable kernel development in high-performance computing.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca&lt;SEP&gt;chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Mingzhen Li, Yi Liu, Hailong Yang, et al.">
  <data key="d0">Mingzhen Li, Yi Liu, Hailong Yang, et al.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of work on automatic code generation and optimization of large-scale stencil computations on many-core processors.&lt;SEP&gt;Authors who researched automatic code generation and optimization techniques for large-scale stencil computations on many-core processors.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Automatic Code Generation and Optimization of Large-Scale Stencil Computation">
  <data key="d0">Automatic Code Generation and Optimization of Large-Scale Stencil Computation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique for enhancing performance and efficiency of stencil-based numerical algorithms on modern many-core architectures.&lt;SEP&gt;A technique to generate optimized, scalable code for stencil computations on modern many-core architectures, enhancing performance and efficiency.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="PMAM ’24">
  <data key="d0">PMAM ’24</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A specific conference event held in March 2024 in Edinburgh, focused on high-performance computing, networking, storage, and analysis.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="SLAC National Accelerator Lab.">
  <data key="d0">SLAC National Accelerator Lab.</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A research laboratory in Menlo Park, CA, producing technical reports and supporting high-performance computing research.</data>
  <data key="d3">chunk-5cd0b27c19a2314eb0b2f819a6edfa2e</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="github.com/LLNL">
  <data key="d0">github.com/LLNL</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A web-based platform hosting research projects, code repositories, and related scientific activities.&lt;SEP&gt;A web-based platform hosting research projects, code repositories, and scientific activities related to high-performance computing and scientific research.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Mingzhen Li, Yi Liu, Hailong Yang, Yongmin Hu, Qingxiao Sun, Bangduo Chen, Xin You, Xiaoyan Liu, Zhongzhi Luan, Depei Qian">
  <data key="d0">Mingzhen Li, Yi Liu, Hailong Yang, Yongmin Hu, Qingxiao Sun, Bangduo Chen, Xin You, Xiaoyan Liu, Zhongzhi Luan, Depei Qian</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a study on automatic code generation and optimization for large-scale stencil computations on many-core processors.&lt;SEP&gt;Authors of a study on automatic code generation and optimization techniques for large-scale stencil computations on many-core processors.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2021">
  <data key="d0">2021</data>
  <data key="d1">Study Design</data>
  <data key="d2">A research study conducted in 2021 focusing on automatic code generation and optimization techniques for high-performance computing.&lt;SEP&gt;A research study conducted in 2021 focusing on automating code generation and optimizing performance for scientific computations on high-performance hardware.&lt;SEP&gt;Development and application of PPIR for hierarchical parallelism in exascale computing systems.&lt;SEP&gt;Development and application of PPIR for hierarchical parallelism in exascale computing.&lt;SEP&gt;Development and application of Polygeist for code transformation in high-performance computing.&lt;SEP&gt;Development and application of Polygeist for transforming C code into polyhedral representations to optimize performance.&lt;SEP&gt;Research on applying automated code generation techniques to fluid dynamics simulations on structured grids using OpenSBLI.&lt;SEP&gt;Research on applying automated code generation to fluid dynamics simulations on structured grids.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Proceedings of the 50th International Conference on Parallel Processing">
  <data key="d0">Proceedings of the 50th International Conference on Parallel Processing</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">Conference proceedings documenting research presentations related to parallel processing and high-performance computing.&lt;SEP&gt;Conference proceedings documenting research presentations related to parallel processing, code optimization, and high-performance computing.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Large-scale stencil computation">
  <data key="d0">Large-scale stencil computation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A computational pattern used in scientific simulations, optimized for execution on many-core processors.&lt;SEP&gt;A computational pattern used in scientific simulations, optimized for many-core processors in the study.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Many-core processors">
  <data key="d0">Many-core processors</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Hardware architecture characterized by numerous processing cores designed for parallel computation.&lt;SEP&gt;Hardware architectures with numerous processing cores designed for parallel scientific computations.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance Variability in Mixed-Integer Programming">
  <data key="d0">Performance Variability in Mixed-Integer Programming</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">Investigates the factors influencing performance variability in mixed-integer programming algorithms.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Andrea Lodi, Andrea Tramontani">
  <data key="d0">Andrea Lodi, Andrea Tramontani</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors exploring performance variability issues in mixed-integer programming algorithms.&lt;SEP&gt;Authors exploring the performance variability in mixed-integer programming problems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="202x (unspecified)">
  <data key="d0">202x (unspecified)</data>
  <data key="d1">Study Design</data>
  <data key="d2">A theoretical and empirical analysis of mixed-integer programming performance variability.&lt;SEP&gt;A theoretical and empirical investigation into factors affecting performance variability in mixed-integer programming.&lt;SEP&gt;Research and documentation on MPI standards and their implementation.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="INFORMS">
  <data key="d0">INFORMS</data>
  <data key="d1">Discipline</data>
  <data key="d2">A professional organization for operations research and management sciences, hosting conferences and publications.&lt;SEP&gt;A professional organization for operations research, hosting conferences, journals, and research on optimization and decision sciences.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance Variability">
  <data key="d0">Performance Variability</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The fluctuations in computational performance observed when solving mixed-integer programming problems, influenced by problem structure and solver heuristics.&lt;SEP&gt;The fluctuations in computational performance observed when solving mixed-integer programming problems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Compressible fluid dynamics">
  <data key="d0">Compressible fluid dynamics</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A branch of fluid mechanics dealing with flows where density changes are significant, simulated with OpenSBLI.&lt;SEP&gt;A branch of fluid mechanics focusing on flows where density changes are significant, simulated using OpenSBLI.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Structured grids">
  <data key="d0">Structured grids</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A computational grid arrangement used in simulations of fluid flows.&lt;SEP&gt;A type of computational grid used in numerical simulations of fluid flows, facilitating structured data management.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2020">
  <data key="d0">2020</data>
  <data key="d1">Study Design</data>
  <data key="d2">Development and evaluation of Korali for high-performance stochastic optimization.&lt;SEP&gt;Development, implementation, and testing of Korali for Bayesian uncertainty quantification in scientific models.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Bayesian Uncertainty Quantification">
  <data key="d0">Bayesian Uncertainty Quantification</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A statistical approach to quantify and propagate uncertainty in computational models using Bayesian inference.&lt;SEP&gt;A statistical approach to quantify uncertainty in computational models using Bayesian methods.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Memory Wall">
  <data key="d0">Memory Wall</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The bottleneck in computing where processor speeds outpace memory bandwidth, limiting overall performance in high-performance systems.&lt;SEP&gt;The limitation in computing performance caused by the disparity between processor speed and memory bandwidth.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sally A. McKee, Robert W. Wisniewski">
  <data key="d0">Sally A. McKee, Robert W. Wisniewski</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors analyzing the Memory Wall phenomenon and its impact on high-performance computing systems.&lt;SEP&gt;Authors discussing the Memory Wall phenomenon.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2011">
  <data key="d0">2011</data>
  <data key="d1">Study Design</data>
  <data key="d2">A comprehensive analysis of the Memory Wall issue in high-performance computing.&lt;SEP&gt;A comprehensive review and analysis of the Memory Wall issue, including potential mitigation strategies.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Improving compiler scalability">
  <data key="d0">Improving compiler scalability</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques aimed at optimizing large programs efficiently by enhancing compiler performance.&lt;SEP&gt;Techniques and approaches aimed at enhancing compiler performance to handle large-scale programs efficiently.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sanyam Mehta, Pen-Chung Yew">
  <data key="d0">Sanyam Mehta, Pen-Chung Yew</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors proposing methods for optimizing compiler scalability to support large and complex software systems.&lt;SEP&gt;Authors proposing methods to optimize compiler scalability for large codebases.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2015">
  <data key="d0">2015</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research focused on compiler optimization techniques that improve scalability and reduce compilation time for large codebases.&lt;SEP&gt;Research on compiler optimization techniques for scalability and efficiency.&lt;SEP&gt;Research on compiler techniques for throughput optimization of GPU-based graph algorithms.&lt;SEP&gt;Research on compiler techniques for throughput optimization of graph algorithms on GPUs, focusing on performance enhancement.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Efficiency of Algorithmic Structures">
  <data key="d0">Efficiency of Algorithmic Structures</data>
  <data key="d1">Results</data>
  <data key="d2">Analyses demonstrating how different algorithmic structures impact performance and efficiency in high-performance computing.&lt;SEP&gt;Analysis of the performance of various algorithmic structures in high-performance computing.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Julian Miller, Lukas Trümper, Christian Terboven, Matthias S. Müller">
  <data key="d0">Julian Miller, Lukas Trümper, Christian Terboven, Matthias S. Müller</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of studies on algorithmic efficiency and theoretical models for parallel algorithms.&lt;SEP&gt;Authors of studies on the efficiency and theoretical modeling of parallel algorithms.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2019, 2021">
  <data key="d0">2019, 2021</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research papers presenting theoretical models and efficiency analyses of parallel algorithms.&lt;SEP&gt;Research papers presenting theoretical models for the global optimization of parallel algorithms and their efficiency analysis.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Polygeist">
  <data key="d0">Polygeist</data>
  <data key="d1">Tools</data>
  <data key="d2">A system designed to raise C code to Polyhedral MLIR, enabling advanced optimization and code generation for high-performance computing.&lt;SEP&gt;A system for raising C code to Polyhedral MLIR, facilitating high-performance code generation.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="C to Polyhedral MLIR">
  <data key="d0">C to Polyhedral MLIR</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A compiler intermediate representation that enables advanced optimization of C code.&lt;SEP&gt;A compiler intermediate representation that facilitates polyhedral optimizations for high-performance code.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Ravi Teja Mullapudi, Andrew Adams, Dillon Sharlet, Jonathan Ragan-Kelley, Kayvon Fatahalian">
  <data key="d0">Ravi Teja Mullapudi, Andrew Adams, Dillon Sharlet, Jonathan Ragan-Kelley, Kayvon Fatahalian</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors working on automatic scheduling of image processing pipelines using Halide, focusing on performance and efficiency.&lt;SEP&gt;Authors working on automatic scheduling of image processing pipelines using Halide.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2016">
  <data key="d0">2016</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research on compiler optimizations and techniques for efficient GPU-based graph processing.&lt;SEP&gt;Research on compiler techniques for optimizing graph algorithms for GPU architectures.&lt;SEP&gt;Research on compiler techniques for throughput optimization on GPU architectures.&lt;SEP&gt;Research on compiler techniques tailored for GPU architectures.&lt;SEP&gt;Research on optimizing image processing pipelines through automatic scheduling techniques.&lt;SEP&gt;Research on techniques for automatic scheduling of Halide image processing pipelines to optimize performance.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Sreepathi Pai, Keshav Pingali">
  <data key="d0">Sreepathi Pai, Keshav Pingali</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors developing compiler techniques for throughput optimization of graph algorithms on GPU architectures.&lt;SEP&gt;Authors developing compilers for optimizing graph algorithms on GPUs.&lt;SEP&gt;Authors of a compiler targeting throughput optimization for GPU-accelerated graph algorithms.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenCL">
  <data key="d0">OpenCL</data>
  <data key="d1">Tools</data>
  <data key="d2">An open standard for parallel programming of heterogeneous systems, supporting cross-platform development and execution.&lt;SEP&gt;An open standard for parallel programming of heterogeneous systems, supporting cross-platform development.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="n.d.&quot; (unspecified date)">
  <data key="d0">n.d." (unspecified date)</data>
  <data key="d1">Study Design</data>
  <data key="d2">Documentation and analysis of MPI standards, implementations, and their impact on parallel applications.&lt;SEP&gt;Documentation and standardization of OpenCL's API and features.&lt;SEP&gt;Documentation, standardization, and analysis of OpenCL's features and their applications in heterogeneous computing.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenMP 5.1">
  <data key="d0">OpenMP 5.1</data>
  <data key="d1">Tools</data>
  <data key="d2">A specification for parallel programming API supporting shared-memory multiprocessing.&lt;SEP&gt;A specification for shared-memory parallel programming, enabling developers to write portable parallel code for multicore systems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="n.d.">
  <data key="d0">n.d.</data>
  <data key="d1">Study Design</data>
  <data key="d2">Official specifications and standards documentation for OpenMP 5.1.&lt;SEP&gt;Official standards documentation and implementations of OpenMP 5.1, supporting high-level parallel programming.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Filtered Beam Search">
  <data key="d0">Filtered Beam Search</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A scheduling algorithm optimizing search processes by filtering candidate beams to improve efficiency.&lt;SEP&gt;A search and scheduling technique that filters candidate options to improve efficiency in search and scheduling problems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Peng Si Ow, Thomas E Morton">
  <data key="d0">Peng Si Ow, Thomas E Morton</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors proposing filtered beam search algorithms for scheduling and search optimization.&lt;SEP&gt;Authors proposing filtered beam search techniques for scheduling.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="1988">
  <data key="d0">1988</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research on scheduling algorithms in production and manufacturing.&lt;SEP&gt;Research on scheduling algorithms, including beam search techniques, in production and manufacturing contexts.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="A compiler for throughput optimization of graph algorithms on GPUs">
  <data key="d0">A compiler for throughput optimization of graph algorithms on GPUs</data>
  <data key="d1">Tools</data>
  <data key="d2">A compiler designed to improve the throughput of graph algorithms running on GPU hardware.&lt;SEP&gt;A specialized compiler aimed at improving the throughput and performance of graph algorithms executing on GPU hardware.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Pattern Intermediate Representation (PPIR)">
  <data key="d0">Parallel Pattern Intermediate Representation (PPIR)</data>
  <data key="d1">Tools</data>
  <data key="d2">An intermediate representation designed to facilitate parallel pattern optimization in high-performance computing.&lt;SEP&gt;An intermediate representation designed to facilitate the expression and optimization of parallel patterns in high-performance computing.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hierarchical Parallelism">
  <data key="d0">Hierarchical Parallelism</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A paradigm for organizing parallel computation at multiple levels to achieve scalability in exascale systems.&lt;SEP&gt;A paradigm for organizing parallel computation at multiple levels to scale efficiently to exascale systems.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Michel Steuwer, Toomas Remmelg, Christophe Dubach">
  <data key="d0">Michel Steuwer, Toomas Remmelg, Christophe Dubach</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of work on functional data-parallel IR for GPU code generation.&lt;SEP&gt;Authors of work on functional data-parallel IRs, including Lift, for high-performance GPU code generation.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="2023">
  <data key="d0">2023</data>
  <data key="d1">Study Design</data>
  <data key="d2">Development, documentation, and application of C2Rust for code migration and safety in systems programming.&lt;SEP&gt;Documentation and development of C2Rust for code migration and safety.</data>
  <data key="d3">chunk-2823358e9d763974915b4e0c1e7dc3ca</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="IEEE">
  <data key="d0">IEEE</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">IEEE is a professional organization involved in the dissemination of research and standards related to electrical and electronic engineering, including high-performance computing.&lt;SEP&gt;IEEE is a professional organization that publishes standards, research, and technical documents related to electrical engineering, computer science, and high-performance computing.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="30–40">
  <data key="d0">30–40</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Likely indicates page numbers or section range in a publication, providing contextual location for referenced materials.&lt;SEP&gt;The reference '30–40' likely indicates a page range or section within a publication, providing contextual location for the cited material.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Michel Steuwer">
  <data key="d0">Michel Steuwer</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Michel Steuwer is an author who contributed to research on data-parallel intermediate representations for GPU code generation.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Toomas Remmelg">
  <data key="d0">Toomas Remmelg</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Toomas Remmelg is an author involved in high-performance code generation research.&lt;SEP&gt;Toomas Remmelg is an author involved in the development of high-performance GPU code generation techniques.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Christophe Dubach">
  <data key="d0">Christophe Dubach</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Christophe Dubach is an author contributing to research on functional data-parallel IR for GPU code generation.&lt;SEP&gt;Christophe Dubach is an author contributing to the research on functional data-parallel IR for GPU code.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="IEEE/ACM International Symposium on Code Generation and Optimization (CGO)">
  <data key="d0">IEEE/ACM International Symposium on Code Generation and Optimization (CGO)</data>
  <data key="d1">Study Design</data>
  <data key="d2">The CGO symposium is a conference where research related to code generation and optimization, including Lift, is presented.&lt;SEP&gt;The CGO symposium is a conference where research related to code generation, optimization, and GPU programming, including Lift, is presented.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="C2Rust Development Team">
  <data key="d0">C2Rust Development Team</data>
  <data key="d1">Research Team</data>
  <data key="d2">The C2Rust Development Team develops tools and documentation for converting C code to Rust, including the C2Rust Manual.&lt;SEP&gt;The C2Rust Development Team is responsible for developing and maintaining the C2Rust tool and manual for Rust language interoperability.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="C2Rust Manual">
  <data key="d0">C2Rust Manual</data>
  <data key="d1">Tools</data>
  <data key="d2">The C2Rust Manual provides documentation and guidelines for using the C2Rust tool for C to Rust code conversion.&lt;SEP&gt;The C2Rust Manual provides documentation and guidelines for using the C2Rust tool to convert C code to Rust.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Christian R. Trott">
  <data key="d0">Christian R. Trott</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Author of a paper on Kokkos, focusing on high-performance computing frameworks.&lt;SEP&gt;Christian R. Trott and colleagues authored research on programming model extensions for exascale computing, specifically Kokkos 3.&lt;SEP&gt;Christian R. Trott and colleagues contributed to research on programming model extensions for exascale computing.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450&lt;SEP&gt;chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Kokkos 3">
  <data key="d0">Kokkos 3</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Kokkos 3 is a programming model extension aimed at enabling scalable and portable performance for exascale computing architectures.&lt;SEP&gt;Kokkos 3 is a programming model extension aimed at enabling scalable, portable performance for exascale architectures.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="IEEE Transactions on Parallel and Distributed Systems">
  <data key="d0">IEEE Transactions on Parallel and Distributed Systems</data>
  <data key="d1">Study Design</data>
  <data key="d2">A peer-reviewed journal where research on parallel programming models, including Kokkos 3, is published.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Lukas Trümper">
  <data key="d0">Lukas Trümper</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Lukas Trümper and colleagues developed methods for automatic mapping of parallel algorithms on heterogeneous architectures.&lt;SEP&gt;Lukas Trümper and colleagues researched automatic mapping of parallel pattern-based algorithms onto heterogeneous architectures.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Automatic Mapping of Parallel Pattern-Based Algorithms">
  <data key="d0">Automatic Mapping of Parallel Pattern-Based Algorithms</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique for automatically assigning parallel algorithms to suitable hardware architectures for performance optimization.&lt;SEP&gt;A technique to automatically assign parallel algorithms to suitable hardware architectures to optimize performance.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Architecture of Computing Systems">
  <data key="d0">Architecture of Computing Systems</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference proceedings where research on computing system architectures and algorithm mapping is presented.&lt;SEP&gt;A conference proceedings where research on computing system architectures and algorithm mapping is published.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Tyler Whitney">
  <data key="d0">Tyler Whitney</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Tyler Whitney and colleagues authored resources on the Parallel Patterns Library (PPL) for parallel programming in C++.&lt;SEP&gt;Tyler Whitney and colleagues authored resources related to the Parallel Patterns Library (PPL) for parallel programming in C++.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Patterns Library (PPL)">
  <data key="d0">Parallel Patterns Library (PPL)</data>
  <data key="d1">Tools</data>
  <data key="d2">A C++ library providing parallel algorithms and patterns to facilitate concurrent programming.&lt;SEP&gt;A C++ library that provides parallel algorithms and patterns for concurrent programming.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Samuel Williams">
  <data key="d0">Samuel Williams</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Samuel Williams and colleagues developed the Roofline performance model for analyzing multicore architectures.&lt;SEP&gt;Samuel Williams, Andrew Waterman, and David Patterson developed the Roofline performance model for multicore architectures.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Roofline">
  <data key="d0">Roofline</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Roofline is a visual performance model that helps understand the computational limits and efficiencies of multicore architectures.&lt;SEP&gt;The Roofline model is a visual performance analysis tool that illustrates the maximum achievable performance of multicore architectures based on operational intensity.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Charles Yount">
  <data key="d0">Charles Yount</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Charles Yount and colleagues developed YASK, a framework for high-performance stencil code generation and tuning.&lt;SEP&gt;Charles Yount and team created YASK, a framework for HPC stencil code-generation and tuning.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Performance evaluation">
  <data key="d0">Performance evaluation</data>
  <data key="d3">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d2">The benchmark suite is used to evaluate the effectiveness of the code generator in optimizing HPC applications.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Benchmark Suite">
  <data key="d0">Benchmark Suite</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">LULESH is used as a benchmark application to evaluate scalability and performance of computational setups."|&lt;SEP&gt;LULESH is used as a representative benchmark application to evaluate the performance and scalability of the proposed prototype and setups."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Programming Model">
  <data key="d0">Parallel Programming Model</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">OpenMP is a core concept used as a baseline in the evaluation setup."|&lt;SEP&gt;OpenMP serves as the baseline parallel programming model against which the new tools and approaches are evaluated."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Current Issues">
  <data key="d0">Current Issues</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">The evaluation assesses issues related to the LP-based global optimization approach."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="LP-based Global Optimization">
  <data key="d0">LP-based Global Optimization</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">The evaluation assesses issues related to the LP-based global optimization approach."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="APT">
  <data key="d0">APT</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">Inlining is applied to the Abstract Pattern Tree in the tool to optimize code."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenMP Implementation">
  <data key="d0">OpenMP Implementation</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">The PPL toolchain is compared against existing OpenMP implementations of Rodinia kernels."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Issues and Solutions">
  <data key="d0">Issues and Solutions</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">An analysis of current issues in the PPL prototype includes potential solutions for a future release."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel Algorithms">
  <data key="d0">Parallel Algorithms</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">Recurring structures like OpenMP, MPI, and CUDA are used in parallel algorithms."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Application Range">
  <data key="d0">Application Range</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">The PPL aims to support a broad range of applications and hardware by separating semantics from hardware specifics."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Complete Node Coverage">
  <data key="d0">Complete Node Coverage</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">Kokkos supports performance portability across entire nodes, similar to PPL's broader scope."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="LP-based global optimization">
  <data key="d0">LP-based global optimization</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">The current approach under assessment for issues and potential improvements."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Parallel algorithms">
  <data key="d0">Parallel algorithms</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">Recurring structures like OpenMP, MPI, and CUDA are fundamental to parallel algorithm design and implementation."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Application range">
  <data key="d0">Application range</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">The PPL aims to support a broad spectrum of applications across hardware architectures by abstracting parallel semantics."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Complete node coverage">
  <data key="d0">Complete node coverage</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">Kokkos supports performance portability across entire nodes, similar to PPL's goal of supporting cluster-wide applications."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Optimization strategy">
  <data key="d0">Optimization strategy</data>
  <data key="d3">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d2">SDFGs utilize rule-based transformations for optimization, which can complement or be integrated with PPL's flexible optimization approach."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="APG Nodes">
  <data key="d0">APG Nodes</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d2">Data dependencies link expressions within the APG, allowing static analysis of data flow across program components.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="AMT">
  <data key="d0">AMT</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d2">The AMT extends the APG by including optimization and mapping data, representing heterogeneous and distributed task execution.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="APG">
  <data key="d0">APG</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d2">The AMT extends the APG by including optimization and mapping data, representing heterogeneous and distributed task execution.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="MILP">
  <data key="d0">MILP</data>
  <data key="d3">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d2">MILP formulations are used to optimize task scheduling and mapping during global optimization, solved by solvers like Gurobi.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="GPU Offloading">
  <data key="d0">GPU Offloading</data>
  <data key="d3">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d2">Synchronization mechanisms coordinate GPU kernel execution and data consistency between host and device, ensuring correct order.&lt;SEP&gt;Synchronization mechanisms ensure correct order of GPU kernel execution and data consistency across host and device.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Hotspot">
  <data key="d0">Hotspot</data>
  <data key="d3">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d2">Hotspot's static code structure allowed for almost complete elimination of synchronization, leading to runtime reduction.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Dynamic Task Scheduling">
  <data key="d0">Dynamic Task Scheduling</data>
  <data key="d3">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d2">These tools support execution of dynamic workloads, load balancing, and GPU offloading, addressing limitations of static approaches in handling runtime variability.&lt;SEP&gt;These tools support execution of dynamic workloads, load balancing, and GPU offloading, addressing limitations of static approaches.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="Charles Yount and colleagues' YASK framework is focused on optimizing stencil code for HPC applications.">
  <data key="d0">Charles Yount and colleagues' YASK framework is focused on optimizing stencil code for HPC applications.</data>
  <data key="d3">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d2">optimization, stencil computations</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</node>
<node id="OpenAI Codex">
  <data key="d0">OpenAI Codex</data>
  <data key="d1">Tools</data>
  <data key="d2">An AI tool designed for code generation and programming assistance, impacting education and programming practices.&lt;SEP&gt;An AI-powered code generation tool that assists with programming tasks and impacts education practices.&lt;SEP&gt;OpenAI Codex is a GPT-3 descendant designed for code generation, leveraging large language models trained on extensive source code datasets.&lt;SEP&gt;OpenAI Codex is an AI model used for code generation supporting multiple programming languages and models, facilitating AI-assisted high-performance computing (HPC) kernel development.&lt;SEP&gt;OpenAI Codex is an AI model used for code generation, supporting multiple programming languages and models, facilitating AI-assisted high-performance computing (HPC) kernel development.&lt;SEP&gt;OpenAI Codex is an advanced AI model based on GPT-3 designed specifically for code generation, trained on extensive source code datasets to assist in scientific and HPC kernel development.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HPC (High-Performance Computing)">
  <data key="d0">HPC (High-Performance Computing)</data>
  <data key="d1">Disciplines</data>
  <data key="d2">HPC involves the use of supercomputers and parallel processing techniques to solve complex computational problems efficiently.&lt;SEP&gt;HPC involves the use of supercomputers and parallel processing techniques to solve complex computational problems.&lt;SEP&gt;The field focused on computational tasks requiring high-performance systems, relevant here as the domain for the code generation models.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42&lt;SEP&gt;chunk-8184ca90cae86b58652f2117d440bd17&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Kernel Generation">
  <data key="d0">Kernel Generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Kernel generation refers to creating optimized computational kernels for numerical operations like AXPY, GEMV, GEMM, SpMV, JacobiStencil, and CG, often using AI-assisted tools.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="AI-assisted generative capabilities">
  <data key="d0">AI-assisted generative capabilities</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Refers to the use of artificial intelligence, particularly large language models like GPT-3 and GPT-4, to automatically generate code for numerical kernels in various programming models.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Programming Models">
  <data key="d0">Programming Models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Programming models such as C++, Fortran, Python, and Julia, supported by different parallel and hardware offloading frameworks like OpenMP, OpenACC, CUDA, HIP, Kokkos, SyCL, and others, used for HPC kernel implementation.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Proficiency Metric">
  <data key="d0">Proficiency Metric</data>
  <data key="d1">Results</data>
  <data key="d2">A metric proposed to quantify the quality and relevance of code suggestions generated by AI tools, based on the initial suggestions provided for each prompt.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Language-supported Programming Models">
  <data key="d0">Language-supported Programming Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Various programming paradigms and frameworks supported by the AI models, including C++, Fortran, Python, and Julia, each with specific hardware acceleration or parallelism capabilities.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GitHub Copilot">
  <data key="d0">GitHub Copilot</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">An AI-powered code assistant integrated with Visual Studio Code, leveraging OpenAI Codex to generate code snippets and implementations for HPC kernels.&lt;SEP&gt;An AI-powered code completion and assistance tool designed to aid software developers.&lt;SEP&gt;An AI-powered code completion tool aimed at assisting programmers.&lt;SEP&gt;An AI-powered code generation tool evaluated for its accuracy and proficiency in generating code snippets based on different prompts.&lt;SEP&gt;GitHub Copilot is an AI code generation tool evaluated for its accuracy and proficiency in generating code snippets based on different prompts.&lt;SEP&gt;GitHub Copilot is an AI-powered code completion tool based on OpenAI Codex, used to generate relevant code snippets and kernels for HPC applications.&lt;SEP&gt;GitHub Copilot is an AI-powered code completion tool built on OpenAI Codex, used to generate code snippets and scientific kernels for high-performance computing applications.&lt;SEP&gt;GitHub Copilot is an AI-powered code completion tool that assists programmers by suggesting code snippets, with security assessments analyzing its contributions.&lt;SEP&gt;GitHub Copilot is a product powered by a production version of Codex, used for assisting programmers by suggesting code snippets.&lt;SEP&gt;GitHub Copilot is an AI-powered coding assistant that utilizes Codex models to help developers generate code snippets and functions within their development environment.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Numerical Kernels">
  <data key="d0">Numerical Kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Core computational routines such as AXPY, GEMV, GEMM, SpMV, JacobiStencil, and CG, which are fundamental in scientific computing and HPC applications.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Language Support">
  <data key="d0">Language Support</data>
  <data key="d1">Variables</data>
  <data key="d2">The set of programming languages (C++, Fortran, Python, Julia) and their associated frameworks used for kernel implementation and AI code generation.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Implementation Quality">
  <data key="d0">Implementation Quality</data>
  <data key="d1">Results</data>
  <data key="d2">The effectiveness and accuracy of AI-generated code, measured via the proficiency metric and experimental outcomes.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Experimental Results">
  <data key="d0">Experimental Results</data>
  <data key="d1">Results</data>
  <data key="d2">Data and findings demonstrating the performance, accuracy, and limitations of AI-generated HPC kernels across different programming models.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HPC Community">
  <data key="d0">HPC Community</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The scientific and engineering community involved in high-performance computing research and development.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code Prompts">
  <data key="d0">Code Prompts</data>
  <data key="d1">Variables</data>
  <data key="d2">Input prompts provided to AI models such as simple kernel + programming model + optional hints, used to generate code implementations.</data>
  <data key="d3">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="potential of this new technology">
  <data key="d0">potential of this new technology</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Potential encompasses the capabilities, prospects, and future applications of the emerging technology, highlighting its significance and possible impact.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPT-3">
  <data key="d0">GPT-3</data>
  <data key="d1">Tools</data>
  <data key="d2">A language model used as a benchmark for bias and harm comparison with Codex in comment and text generation.&lt;SEP&gt;A large language model developed by OpenAI, analyzed for its capabilities, limitations, and societal impacts in Floridi and Chiriatti's work.&lt;SEP&gt;A large language model developed by OpenAI, with attributes including its capabilities, limitations, and societal impacts.&lt;SEP&gt;An advanced language model with capabilities, limitations, and societal implications, central to AI research.&lt;SEP&gt;An advanced language model with significant capabilities, limitations, and societal implications, central to AI research.&lt;SEP&gt;GPT-3 is a large language model developed by OpenAI that demonstrates strong performance in NLP tasks and serves as the foundation for Codex and related AI code-generation tools.&lt;SEP&gt;GPT-3 is a state-of-the-art language model developed by OpenAI, known for its advanced natural language processing capabilities and influence on subsequent models.&lt;SEP&gt;A large language model used as a comparison benchmark to assess bias and harmful content in generated text.&lt;SEP&gt;GPT-3 is a large language model developed by OpenAI, capable of understanding and generating human-like text, but not explicitly trained for code generation tasks.&lt;SEP&gt;GPT-3 is a large language model developed by OpenAI, known for natural language understanding and generation capabilities.&lt;SEP&gt;GPT-3 is a large language model that was evaluated for code generation capabilities and found to solve 0% of problems in the HumanEval set, serving as a baseline comparison.&lt;SEP&gt;GPT-3 is a large language model that was not explicitly trained for code generation but demonstrates capabilities in various modalities, including language understanding and generation.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a&lt;SEP&gt;chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-38bf816094395541632173a71659ec3b&lt;SEP&gt;chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b&lt;SEP&gt;chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="scien-tific kernels for HPC">
  <data key="d0">scien-tific kernels for HPC</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Scientific kernels for high-performance computing are optimized computational routines used in scientific simulations, which are generated and tested using AI tools like Codex.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="prompt input pattern methodology">
  <data key="d0">prompt input pattern methodology</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A structured approach to interact with AI code generators, involving specific input patterns to improve the quality and relevance of generated kernels.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="assessment of GPT-3 capabilities">
  <data key="d0">assessment of GPT-3 capabilities</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study investigates how well GPT-3, via Codex, can generate, optimize, and test mathematical kernels for HPC, assessing correctness, trade-offs, and value.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="prompt trade-off options">
  <data key="d0">prompt trade-off options</data>
  <data key="d1">Variables</data>
  <data key="d2">Different prompt configurations and keyword inputs that influence the quality, correctness, and efficiency of generated HPC kernels.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="current status of prompt engineering">
  <data key="d0">current status of prompt engineering</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">An inquiry into the effectiveness and maturity of prompt engineering practices when applying AI models like Codex to generate scientific kernels.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="related efforts in computer science">
  <data key="d0">related efforts in computer science</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Overview of recent research efforts highlighting focus areas such as code generation, prompt-based learning, and AI applications in scientific computing.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="accuracy of AI-generated code">
  <data key="d0">accuracy of AI-generated code</data>
  <data key="d1">Results</data>
  <data key="d2">Results from the evaluation indicating the correctness, trade-offs, and overall value of code generated by GPT-3/ Codex for HPC kernels.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="future directions">
  <data key="d0">future directions</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Proposed future research paths, including improving prompt techniques, expanding datasets, and enhancing AI integration in scientific computing workflows.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="reproducibility of the study">
  <data key="d0">reproducibility of the study</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Appendix A provides detailed artifact descriptions to enable reproduction and validation of the research findings.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Potential of this new technology">
  <data key="d0">Potential of this new technology</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The potential of this new technology encompasses its capabilities, future applications, and impact on scientific computing and HPC, highlighting its promise and areas for growth.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Prompt input pattern methodology">
  <data key="d0">Prompt input pattern methodology</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A structured approach to designing prompts for interacting with AI code generators, aimed at improving the relevance, correctness, and efficiency of generated HPC kernels.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Assessment of GPT-3 capabilities">
  <data key="d0">Assessment of GPT-3 capabilities</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study investigates how effectively GPT-3 and Codex can generate, optimize, and test scientific kernels for HPC, focusing on correctness, trade-offs, and overall utility.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Prompt trade-off options">
  <data key="d0">Prompt trade-off options</data>
  <data key="d1">Variables</data>
  <data key="d2">Different prompt configurations and keyword inputs that influence the quality, correctness, and efficiency of the generated HPC kernels.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Current status of prompt engineering">
  <data key="d0">Current status of prompt engineering</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">An investigation into the maturity, effectiveness, and challenges of prompt engineering techniques when applying GPT-3/Codex to scientific kernel generation.</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Copilot">
  <data key="d0">Copilot</data>
  <data key="d1">Methodology</data>
  <data key="d2">An AI-powered code suggestion tool trained on public repositories, used to generate programming code snippets and assist in software development.&lt;SEP&gt;Copilot is an AI-powered code suggestion tool trained on public repositories, used to generate programming code snippets and assist in software development.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Genetic Programming">
  <data key="d0">Genetic Programming</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A field studying evolution-inspired algorithms, emphasizing properties like code reuse, automatic architecture determination, and broad applicability.&lt;SEP&gt;An automatic problem-solving approach that evolves computer programs using genetic algorithms, often used for optimization and invention tasks.&lt;SEP&gt;An evolutionary algorithm-based approach to automatically generate programs or solutions for complex problems.&lt;SEP&gt;An evolutionary algorithm-based methodology that evolves computer programs to solve specific problems, used here as a comparison to Copilot in code generation.&lt;SEP&gt;Genetic programming is an evolutionary algorithm technique that evolves computer programs to solve specific problems, often used as a benchmark for code synthesis performance.&lt;SEP&gt;Genetic programming is an evolutionary algorithm-based methodology that evolves computer programs to solve problems, used as a benchmark for code generation performance.&lt;SEP&gt;Genetic programming is an evolutionary algorithm-based methodology that evolves computer programs to solve specific problems, used here as a comparison to Copilot in code generation.&lt;SEP&gt;Genetic programming is a field of study that explores evolution-inspired algorithms, long discussing properties like code reuse, automatic architecture determination, and applicability.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-603d0ab6656c1e8cc11a81310ec387dd&lt;SEP&gt;chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="PSB2 Program Synthesis Benchmarks">
  <data key="d0">PSB2 Program Synthesis Benchmarks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A set of benchmark problems used to evaluate program synthesis and code generation tools, including Copilot and genetic programming approaches.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HumanEval Dataset">
  <data key="d0">HumanEval Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset of programming problems used to assess the correctness, validity, and efficiency of code generated by AI tools like Copilot.&lt;SEP&gt;The HumanEval dataset contains programming problems with reference solutions and unit tests, used to evaluate code generation models.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3&lt;SEP&gt;chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Quality">
  <data key="d0">Code Quality</data>
  <data key="d1">Variables</data>
  <data key="d2">A measure of the correctness, readability, efficiency, and security of generated code, used to evaluate AI-generated programming outputs.&lt;SEP&gt;Code quality indicates the effectiveness and correctness of generated code, affected by prompt phrasing, community support, and language features.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Security Vulnerabilities">
  <data key="d0">Security Vulnerabilities</data>
  <data key="d1">Results</data>
  <data key="d2">High vulnerability rates were found in code contributions generated by Copilot, indicating security concerns.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Educational Effectiveness">
  <data key="d0">Educational Effectiveness</data>
  <data key="d1">Results</data>
  <data key="d2">Studies show that Codex and Copilot can generate programming exercises and explanations, but require oversight to ensure output quality.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Programming Languages">
  <data key="d0">Programming Languages</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">C++, Fortran, Python, Julia are the languages evaluated for AI code suggestion capabilities and their correlation with suggestion quality.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Prompt Queries">
  <data key="d0">Prompt Queries</data>
  <data key="d1">Tools</data>
  <data key="d2">Structured prompts used to elicit code suggestions from Copilot, based on kernels and programming models.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Suggestion Quality">
  <data key="d0">Suggestion Quality</data>
  <data key="d1">Variables</data>
  <data key="d2">The level of correctness, efficiency, and security of code suggestions generated by Copilot, assessed through metrics and experiments.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Security-Aware Tooling">
  <data key="d0">Security-Aware Tooling</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Tools and practices that should be paired with Copilot to mitigate security vulnerabilities in generated code.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HPC Kernels">
  <data key="d0">HPC Kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">High-Performance Computing kernels, which are not yet explored for Copilot's application, representing a gap in current research.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Research Gap">
  <data key="d0">Research Gap</data>
  <data key="d1">Limitations</data>
  <data key="d2">Lack of studies on applying Copilot to HPC kernels, indicating an area for future exploration.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Evaluation Method">
  <data key="d0">Evaluation Method</data>
  <data key="d1">Study Design</data>
  <data key="d2">Methodology involving prompt-based code generation and correctness metrics to assess Copilot's performance across multiple languages.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Multilingual Testing">
  <data key="d0">Multilingual Testing</data>
  <data key="d1">Study Design</data>
  <data key="d2">Assessment of Copilot's code suggestion capabilities across different programming languages like C++, Python, Fortran, and Julia.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Training Dataset Diversity">
  <data key="d0">Training Dataset Diversity</data>
  <data key="d1">Variables</data>
  <data key="d2">The diversity and volume of training data for each language, affecting the quality and relevance of suggestions.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code Suggestion Sensitivity">
  <data key="d0">Code Suggestion Sensitivity</data>
  <data key="d1">Variables</data>
  <data key="d2">Sensitivity of Copilot's suggestions to specific prompt keywords and prompt structure, varying across languages.</data>
  <data key="d3">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Fortran">
  <data key="d0">Fortran</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A programming language evaluated for its sensitivity to keywords like subroutine in code suggestion experiments.&lt;SEP&gt;Fortran is a language significant in HPC and scientific computing, with Copilot providing good results due to its domain-specific nature and legacy, especially with mature solutions like OpenMP and OpenACC.&lt;SEP&gt;Fortran is a programming language evaluated for its sensitivity to specific keywords like subroutine in code suggestion experiments.&lt;SEP&gt;Fortran is a scientific language with legacy importance in HPC; Copilot can generate good code due to its domain-specific nature, especially when using 'optimized' prompts and 'subroutine' keyword.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Python">
  <data key="d0">Python</data>
  <data key="d1">Variables</data>
  <data key="d2">A dominant programming language used in education and industry, noted for its high readability and increasing use facilitated by tools like Codex.&lt;SEP&gt;A programming language tested for sensitivity to the 'def' keyword in code generation tasks.&lt;SEP&gt;Python is a high-level programming language widely used in scientific computing, data analysis, and machine learning due to its simplicity and extensive libraries.&lt;SEP&gt;Python is a high-level, versatile programming language widely used in scientific computing, data analysis, and machine learning due to its simplicity and rich ecosystem.&lt;SEP&gt;Python is a programming language tested for its sensitivity to the 'def' keyword in code generation tasks.&lt;SEP&gt;Python is a widely-used, general-purpose language with a significant role in AI, research, and education; code quality improves with the 'def' keyword, and it supports libraries like numpy, cuPy, pyCUDA, and Numba.&lt;SEP&gt;Python is a widely-used, general-purpose language with an important role in AI, research, and education, with code generation quality improving when using specific keywords like 'def', and supporting libraries like numpy, cuPy, pyCUDA, and Numba.&lt;SEP&gt;A widely used programming language, especially in educational contexts, with increasing use due to tools like Codex.&lt;SEP&gt;Programming language used as a primary target for Codex's code generation capabilities.</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482&lt;SEP&gt;chunk-706ca7a8d3fc8406a24b8328b849606b&lt;SEP&gt;chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Julia">
  <data key="d0">Julia</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A programming language examined for low sensitivity to the 'function' postfix in code suggestion prompts.&lt;SEP&gt;Julia is a high-performance programming language designed for numerical and scientific computing, influenced by Fortran and C++, supporting high-level syntax and efficient execution.&lt;SEP&gt;Julia is a high-performance, dynamic programming language designed for numerical and scientific computing, with syntax influenced by Fortran and C++.&lt;SEP&gt;Julia is a programming language examined for its low sensitivity to the 'function' postfix when prompting code suggestions.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="model sensitivity">
  <data key="d0">model sensitivity</data>
  <data key="d1">Core Concept</data>
  <data key="d2">Model sensitivity refers to how programming language models respond to different prompts, keywords, and postfixes, affecting the correctness and proficiency of generated code.&lt;SEP&gt;Refers to how programming language models respond to different prompts, keywords, and postfixes, influencing the correctness and proficiency of generated code.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="correctness metric">
  <data key="d0">correctness metric</data>
  <data key="d1">Methodology</data>
  <data key="d2">A proposed method to evaluate the correctness of code suggestions based on levels from non-knowledge to expert, used to assess model performance.&lt;SEP&gt;A proposed metric to evaluate the correctness of code suggestions based on levels from non-knowledge to expert, used to assess model performance.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="OpenACC">
  <data key="d0">OpenACC</data>
  <data key="d1">Tools</data>
  <data key="d2">A programming model evaluated for its influence on code correctness and sensitivity in code generation tasks.&lt;SEP&gt;OpenACC is a programming model evaluated for its influence on code correctness and sensitivity in code generation tasks.&lt;SEP&gt;OpenACC is a programming standard and API designed to simplify parallel programming of heterogeneous systems, enabling easier offloading of computations to accelerators.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="SyCL">
  <data key="d0">SyCL</data>
  <data key="d1">Tools</data>
  <data key="d2">A programming model evaluated for its performance in generating correct code suggestions.&lt;SEP&gt;SyCL is a high-level programming model for heterogeneous computing, performing poorly over multiple kernels, indicating limited adoption or effectiveness in this context.&lt;SEP&gt;SyCL is a high-level programming model for heterogeneous systems; it performs poorly over several kernels, indicating limited adoption or community support.&lt;SEP&gt;SyCL is a programming model evaluated for its performance in generating correct code suggestions.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="prompts">
  <data key="d0">prompts</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Prompts structured as &lt;kernel&gt; &lt;programming model&gt; (function) are used to evaluate the model's ability to generate correct code across different kernels and models.&lt;SEP&gt;Structured prompts combining kernel and programming model are used to evaluate AI model's ability to generate correct code across different kernels and models.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="correctness levels">
  <data key="d0">correctness levels</data>
  <data key="d1">Results</data>
  <data key="d2">Levels from non-knowledge to expert are used to categorize the accuracy and proficiency of code suggestions generated by models like Copilot.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Prompt pattern">
  <data key="d0">Prompt pattern</data>
  <data key="d1">Research Question/Hypothesis</data>
  <data key="d2">Structured input prompts combining kernel and programming model used to evaluate code suggestion quality.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Evaluation results">
  <data key="d0">Evaluation results</data>
  <data key="d1">Results</data>
  <data key="d2">Data on the correctness and proficiency levels of code generated by Copilot for various kernels and prompts.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code correctness">
  <data key="d0">Code correctness</data>
  <data key="d1">Variables</data>
  <data key="d2">A measure of how accurately the generated code matches expected functionality, used to evaluate model performance.&lt;SEP&gt;The accuracy of generated code solutions, which diminishes as prompt complexity or length increases.&lt;SEP&gt;Correctness refers to the accuracy and functional correctness of generated HPC code, an important aspect of model evaluation.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0&lt;SEP&gt;chunk-d25502af8737c59d857916af40cc4020&lt;SEP&gt;chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Proficiency">
  <data key="d0">Proficiency</data>
  <data key="d1">Variables</data>
  <data key="d2">The level of correctness of code suggestions, categorized from non-knowledge to expert.</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Numpy">
  <data key="d0">Numpy</data>
  <data key="d1">Tools</data>
  <data key="d2">Numpy is a standard Python library for scientific computing, used as a target for AI-generated code, with acceptable implementations generated by Copilot.&lt;SEP&gt;Numpy is a standard Python library for scientific computing, used as a target for AI-generated code, with acceptable implementations produced by Copilot.</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="CuPy">
  <data key="d0">CuPy</data>
  <data key="d1">Tools</data>
  <data key="d2">CuPy is a GPU-accelerated Python library compatible with NumPy, enabling high-performance array computations on NVIDIA GPUs.&lt;SEP&gt;CuPy is a GPU-accelerated library compatible with NumPy that allows for high-performance array computations on NVIDIA GPUs.&lt;SEP&gt;CuPy is a GPU-accelerated library compatible with numpy, providing correct raw CUDA kernel source code, and is popular in community for lightweight GPU code.&lt;SEP&gt;CuPy is a GPU-accelerated library compatible with numpy, providing correct raw CUDA kernel source code, popular for lightweight GPU code layers.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="pyCUDA">
  <data key="d0">pyCUDA</data>
  <data key="d1">Tools</data>
  <data key="d2">pyCUDA allows direct CUDA kernel programming within Python, with correct kernel source code generated and documented for GPU instances.&lt;SEP&gt;pyCUDA enables direct CUDA kernel programming in Python, with correct kernel source code generated, supporting GPU instances.&lt;SEP&gt;pyCUDA is a Python wrapper for CUDA, allowing direct access to GPU programming and kernel execution from Python scripts.&lt;SEP&gt;pyCUDA is a Python wrapper for CUDA, enabling direct GPU kernel programming and execution from Python scripts.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Numba">
  <data key="d0">Numba</data>
  <data key="d1">Tools</data>
  <data key="d2">An LLVM-based JIT compiler for Python aimed at accelerating numerical code.&lt;SEP&gt;An LLVM-based Python JIT compiler that accelerates numerical code for high-performance computing.&lt;SEP&gt;Numba is a JIT compiler for Python supporting CPU and GPU code; however, it performs less well on GPU kernels and recently deprecated AMD GPU support.&lt;SEP&gt;Numba is a JIT compiler for Python that accelerates numerical functions by translating Python code into optimized machine code, supporting CPU and GPU acceleration.&lt;SEP&gt;Numba is a JIT compiler for Python that accelerates numerical functions by translating Python code into optimized machine code, supporting both CPU and GPU execution.&lt;SEP&gt;Numba is a JIT compiler for Python, supporting CPU and GPU code, but falls behind in quality for some GPU kernels, and recently deprecated AMD GPU support.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-07477bd37f9598e434f96bc52e2aea53&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Scientific Computing">
  <data key="d0">Scientific Computing</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Scientific computing involves numerical methods and algorithms implemented in programming languages like Fortran and Python for research applications.</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Community Size">
  <data key="d0">Community Size</data>
  <data key="d1">Variables</data>
  <data key="d2">Community size refers to the number of users or developers supporting a particular programming model or library, influencing its performance and adoption.</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Legacy Code">
  <data key="d0">Legacy Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Legacy code refers to older, established codebases in scientific computing, often written in Fortran, that influence current code generation and model choice.</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Prompt Optimization">
  <data key="d0">Prompt Optimization</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Prompt optimization involves adjusting input prompts to improve code generation quality in AI systems like Copilot.&lt;SEP&gt;Techniques and algorithms used to refine prompts during training, including gradient-based methods and initialization strategies.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6&lt;SEP&gt;chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Syntax Habits">
  <data key="d0">Syntax Habits</data>
  <data key="d1">Variables</data>
  <data key="d2">Syntax habits refer to community-specific language features and keywords used in programming, impacting AI code generation accuracy.</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Benchmark Repositories">
  <data key="d0">Benchmark Repositories</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Benchmark repositories like HecBench provide datasets for evaluating kernel performance and AI code generation.</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GEMM">
  <data key="d0">GEMM</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">GEMM (General Matrix to Matrix Multiplication) is a fundamental operation in linear algebra and high-performance computing, involving the multiplication of matrices, often optimized for various hardware architectures.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="SpMV">
  <data key="d0">SpMV</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">SpMV (Sparse Matrix-Vector multiplication) is a computational kernel used in scientific computing to efficiently multiply sparse matrices by vectors, crucial for large-scale simulations.&lt;SEP&gt;SpMV (Sparse Matrix-Vector multiplication) is a key operation in scientific computing involving multiplying a sparse matrix by a vector, important for large-scale simulations.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Jacobi">
  <data key="d0">Jacobi</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Jacobi is an iterative method for solving linear systems, used in numerical analysis to approximate solutions efficiently.&lt;SEP&gt;Jacobi method is an iterative algorithm for solving systems of linear equations, used in numerical analysis and computational mathematics.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="CG">
  <data key="d0">CG</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Conjugate Gradient (CG) is an iterative algorithm for solving large, sparse, symmetric positive-definite linear systems, commonly used in scientific and engineering computations.&lt;SEP&gt;Conjugate Gradient (CG) is an iterative method for solving large, sparse systems of linear equations, especially symmetric positive-definite matrices.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="numpy">
  <data key="d0">numpy</data>
  <data key="d1">Tools</data>
  <data key="d2">NumPy is a Python library providing support for large multi-dimensional arrays, matrices, and a collection of mathematical functions for numerical computations.&lt;SEP&gt;NumPy is a fundamental Python library providing support for large multi-dimensional arrays and matrices, along with a collection of mathematical functions for numerical computations.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="&lt;kernel&gt;">
  <data key="d0">&lt;kernel&gt;</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The &lt;kernel&gt; pattern indicates a code or function definition used in GPU programming, often involving parallel computation kernels.&lt;SEP&gt;The &lt;kernel&gt; pattern indicates a code snippet or function designed for GPU execution, typically involving parallel computation kernels.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="def">
  <data key="d0">def</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The 'def' keyword signifies function definitions in Python and similar languages, used here to denote code blocks or kernels.&lt;SEP&gt;The 'def' keyword signifies the definition of a function in Python and similar languages, used here to denote code blocks or kernels.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="CUDA.jl">
  <data key="d0">CUDA.jl</data>
  <data key="d1">Tools</data>
  <data key="d2">CUDA.jl is a Julia package enabling GPU computing with NVIDIA CUDA, allowing Julia code to run efficiently on GPUs.&lt;SEP&gt;CUDA.jl is a Julia package that enables GPU computing with NVIDIA CUDA, allowing Julia code to execute efficiently on GPUs.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="AMDGPU.jl">
  <data key="d0">AMDGPU.jl</data>
  <data key="d1">Tools</data>
  <data key="d2">AMDGPU.jl is a Julia package for programming AMD GPUs, supporting GPU kernels on AMD hardware.&lt;SEP&gt;AMDGPU.jl is a Julia package that supports programming AMD GPUs, expanding GPU acceleration capabilities beyond NVIDIA hardware.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="KernelAbstractions.jl">
  <data key="d0">KernelAbstractions.jl</data>
  <data key="d1">Tools</data>
  <data key="d2">KernelAbstractions.jl is a Julia package providing a high-level interface for writing portable GPU kernels across different hardware vendors.&lt;SEP&gt;KernelAbstractions.jl provides a high-level interface for writing portable GPU kernels across different hardware vendors, facilitating code reuse and flexibility.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="public repositories">
  <data key="d0">public repositories</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Public code repositories are sources of existing code snippets and implementations that influence the availability and quality of code samples in languages like Python, Julia, and C++.&lt;SEP&gt;Public code repositories serve as sources of existing code snippets and implementations that influence the availability and quality of code in languages like Python, Julia, and C++.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="prompt keywords">
  <data key="d0">prompt keywords</data>
  <data key="d1">Variables</data>
  <data key="d2">Keywords used in prompts can influence AI code generation proficiency; targeted, specific keywords tend to improve output quality.&lt;SEP&gt;Keywords used in prompts can influence the proficiency of code generation by AI models, with specific, targeted keywords improving output quality.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="V GEMM">
  <data key="d0">V GEMM</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">V GEMM refers to a variant of General Matrix to Matrix Multiplication optimized for specific hardware or algorithmic approaches, often used in high-performance computing contexts.</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code Complexity">
  <data key="d0">Code Complexity</data>
  <data key="d1">Variables</data>
  <data key="d2">Attributes of source code, including size, structure, and dependencies, impacting the difficulty of modeling and automation.&lt;SEP&gt;Code complexity refers to the intricacy of programming code, impacting the difficulty of obtaining acceptable results as complexity increases.&lt;SEP&gt;Code complexity refers to the level of intricacy in programming tasks, affecting the difficulty of achieving acceptable results as complexity increases.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0&lt;SEP&gt;chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Multistep or Multikernel Codes">
  <data key="d0">Multistep or Multikernel Codes</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">These are advanced programming codes involving multiple steps or kernels, such as CG, which are challenging to generate with high quality.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Keywords">
  <data key="d0">Keywords</data>
  <data key="d1">Variables</data>
  <data key="d2">Keywords are specific words used to improve answer proficiency; selecting accurate and sensitive keywords is essential for effective programming language/model or community-specific results.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Popularity or Accessibility of Programming Languages">
  <data key="d0">Popularity or Accessibility of Programming Languages</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The popularity or accessibility of programming languages or public codes influences their results, though less popular languages can also be effective due to targeted nature.&lt;SEP&gt;The prominence or ease of access to certain programming languages or public codes influences their results, though less popular languages can also provide good results due to their targeted nature.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="OpenAI Codex via Copilot">
  <data key="d0">OpenAI Codex via Copilot</data>
  <data key="d1">Tools</data>
  <data key="d2">An AI-powered code generation tool evaluated in the study for its ability to produce HPC numerical kernels targeting parallel programming models.&lt;SEP&gt;OpenAI Codex via Copilot is an AI tool used to generate HPC numerical kernels, evaluated for its current capacity in the study.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HPC Numerical Kernels">
  <data key="d0">HPC Numerical Kernels</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">HPC numerical kernels are specialized computational routines used in high-performance computing, targeted for parallel programming models.&lt;SEP&gt;Specialized computational routines used in high-performance computing, designed to work with parallel programming frameworks in languages like C++, Fortran, Python, and Julia.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Taxonomy">
  <data key="d0">Taxonomy</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">A classification system used to evaluate the accuracy and trustworthiness of AI-generated HPC code; the study emphasizes the need for a comprehensive taxonomy.&lt;SEP&gt;A taxonomy is a classification system; the study highlights the need for a comprehensive taxonomy akin to natural language to evaluate AI-generated results.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Accuracy and Trustworthiness">
  <data key="d0">Accuracy and Trustworthiness</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics or criteria used to evaluate the correctness and reliability of AI-generated HPC code, emphasizing the need for standardized evaluation.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Human-in-the-loop">
  <data key="d0">Human-in-the-loop</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A proposed approach where human oversight is integrated into AI code generation to refine suggestions and improve outcomes.&lt;SEP&gt;The study questions whether human oversight can refine AI suggestions and improve HPC software modernization.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Metadata-rich Suggestions">
  <data key="d0">Metadata-rich Suggestions</data>
  <data key="d1">Variables</data>
  <data key="d2">AI suggestions enhanced with detailed metadata to support human decision-making and improve code quality.&lt;SEP&gt;Suggestions containing detailed metadata to assist human decision-making in AI-assisted HPC code generation.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="HPC Software Modernization Initiatives">
  <data key="d0">HPC Software Modernization Initiatives</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Large-scale projects like DARPA’s High Productivity Computing Systems and DOE’s Exascale Computing Project aim to modernize HPC software, potentially integrating AI tools.&lt;SEP&gt;Large-scale projects like DARPA’s High Productivity Computing Systems and DOE’s Exascale Computing Project that aim to modernize HPC software, potentially integrating AI tools.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Ecosystem Features Automation">
  <data key="d0">Ecosystem Features Automation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Automating features like building systems, validation, verification, and pipelines could significantly impact HPC community workflows.&lt;SEP&gt;Automating processes such as building, packaging, validation, verification, and deployment pipelines to impact HPC development workflows.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Educational Aspects of HPC">
  <data key="d0">Educational Aspects of HPC</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Revolutionary AI capabilities could redefine how HPC is taught and learned, emphasizing automation and human-AI collaboration.&lt;SEP&gt;Using AI and automation to redefine and enhance education and training in high-performance computing.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Acceptable Results">
  <data key="d0">Acceptable Results</data>
  <data key="d1">Results</data>
  <data key="d2">Acceptable results are the desired outcomes in programming, which become harder to attain as code complexity increases.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Generating High-Quality Codes">
  <data key="d0">Generating High-Quality Codes</data>
  <data key="d1">Methods</data>
  <data key="d2">The process of creating accurate and effective multistep or multikernel codes, which is difficult especially at higher complexities.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Initial Study">
  <data key="d0">Initial Study</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An initial evaluation conducted to assess the current capacity of AI tools like Codex for HPC kernel generation, serving as a basis for further research.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Limitations of AI Tools">
  <data key="d0">Limitations of AI Tools</data>
  <data key="d1">Limitations</data>
  <data key="d2">Current shortcomings and challenges of AI tools like Codex, impacting their effectiveness in HPC code generation.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Standardized Methodology">
  <data key="d0">Standardized Methodology</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A widely accepted framework or approach for evaluating AI-generated code across different studies, ensuring consistency and comparability.</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Information Processing Systems">
  <data key="d0">Information Processing Systems</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A collection of scientific papers and proceedings related to neural information processing, machine learning, and high-performance computing, including editors and publication details.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="H. Larochelle">
  <data key="d0">H. Larochelle</data>
  <data key="d1">Researchers/Editors</data>
  <data key="d2">An editor associated with the proceedings of neural information processing and machine learning.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="M. Ranzato">
  <data key="d0">M. Ranzato</data>
  <data key="d1">Researchers/Editors</data>
  <data key="d2">A researcher/editor contributing to neural information processing studies.&lt;SEP&gt;A researcher/editor contributing to neural processing and machine learning publications.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="R. Hadsell">
  <data key="d0">R. Hadsell</data>
  <data key="d1">Researchers/Editors</data>
  <data key="d2">A researcher/editor involved in neural information processing research.&lt;SEP&gt;A researcher/editor involved in neural information processing studies.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="M.F. Balcan">
  <data key="d0">M.F. Balcan</data>
  <data key="d1">Researchers/Editors</data>
  <data key="d2">A researcher/editor involved in machine learning and data analysis.&lt;SEP&gt;A researcher/editor involved in neural information processing and machine learning publications.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="H. Lin">
  <data key="d0">H. Lin</data>
  <data key="d1">Researchers/Editors</data>
  <data key="d2">A researcher/editor contributing to neural information processing research.&lt;SEP&gt;A researcher/editor contributing to neural information systems research.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Curran Associates, Inc.">
  <data key="d0">Curran Associates, Inc.</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A publisher responsible for disseminating proceedings and scientific papers in neural and machine learning research.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="NeurIPS Conference">
  <data key="d0">NeurIPS Conference</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A major conference where research papers on neural information processing, machine learning, and high-performance computing are presented.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Daniel Sunderland">
  <data key="d0">Daniel Sunderland</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Author involved in research on high-performance computing and programming languages.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Jerry Tworek">
  <data key="d0">Jerry Tworek</data>
  <data key="d1">Researchers</data>
  <data key="d2">One of the primary authors involved in the study, contributing to the investigation and analysis of Codex and related models.&lt;SEP&gt;Researcher involved in the evaluation of language models and AI systems.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Heewoo Jun">
  <data key="d0">Heewoo Jun</data>
  <data key="d1">Researchers</data>
  <data key="d2">One of the primary authors involved in the study, contributing to the investigation and analysis of Codex and related models.&lt;SEP&gt;Researcher contributing to large language model evaluation.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Qiming Yuan">
  <data key="d0">Qiming Yuan</data>
  <data key="d1">Researchers</data>
  <data key="d2">One of the primary authors involved in the study, contributing to the investigation and analysis of Codex and related models.&lt;SEP&gt;Researcher in large language models and AI evaluation.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Henrique Ponde de Oliveira Pinto">
  <data key="d0">Henrique Ponde de Oliveira Pinto</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Researcher involved in AI model evaluation and high-performance computing.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Jared Kaplan">
  <data key="d0">Jared Kaplan</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.&lt;SEP&gt;Researcher contributing to AI model evaluation research.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Harri Edwards">
  <data key="d0">Harri Edwards</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.&lt;SEP&gt;Researcher involved in language model evaluation studies.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Yuri Burda">
  <data key="d0">Yuri Burda</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.&lt;SEP&gt;Researcher contributing to AI evaluation and high-performance computing research.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Nicholas Joseph">
  <data key="d0">Nicholas Joseph</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.&lt;SEP&gt;Researcher involved in large language model evaluation.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Greg Brockman">
  <data key="d0">Greg Brockman</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.&lt;SEP&gt;Researcher contributing to AI model evaluation and development.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Omid Khalili">
  <data key="d0">Omid Khalili</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Researcher contributing to AI model evaluation.&lt;SEP&gt;Researcher involved in AI evaluation methodologies.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Sadaf Alam">
  <data key="d0">Sadaf Alam</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Researcher contributing to AI research and evaluation.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Roy Campbell">
  <data key="d0">Roy Campbell</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Researcher involved in high-performance computing and AI systems.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Laura Carrington">
  <data key="d0">Laura Carrington</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Researcher contributing to AI and high-performance computing research.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Tzu-Yi Chen">
  <data key="d0">Tzu-Yi Chen</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Researcher involved in computational research and AI evaluation.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Jeremy Meredith">
  <data key="d0">Jeremy Meredith</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Researcher involved in high-performance computing and AI systems.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Mustafa Tikir">
  <data key="d0">Mustafa Tikir</data>
  <data key="d1">Researchers/Authors</data>
  <data key="d2">Researcher contributing to AI research and high-performance computing.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="DARPA’s HPCS Program">
  <data key="d0">DARPA’s HPCS Program</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A high-performance computing research initiative focused on developing models, tools, languages, and architectures for exascale computing.&lt;SEP&gt;A high-performance computing research program focused on developing models, tools, and languages for exascale computing.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="International Exascale Software Project">
  <data key="d0">International Exascale Software Project</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A roadmap project aimed at guiding the development of software for exascale supercomputers.&lt;SEP&gt;A roadmap project guiding the development of software for exascale supercomputers and high-performance computing environments.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Li Fei-Fei">
  <data key="d0">Li Fei-Fei</data>
  <data key="d1">Researchers/Objects of Study</data>
  <data key="d2">A prominent researcher known for work on one-shot learning of object categories in computer vision.&lt;SEP&gt;A researcher known for work on one-shot learning of object categories in computer vision.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="R. Fergus">
  <data key="d0">R. Fergus</data>
  <data key="d1">Researchers/Objects of Study</data>
  <data key="d2">A researcher involved in pattern analysis and machine learning for object recognition.&lt;SEP&gt;A researcher involved in pattern recognition and machine learning for object classification.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="P. Perona">
  <data key="d0">P. Perona</data>
  <data key="d1">Researchers/Objects of Study</data>
  <data key="d2">A researcher contributing to computer vision and machine learning for object categorization.&lt;SEP&gt;A researcher contributing to computer vision and machine learning research.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Object Categories">
  <data key="d0">Object Categories</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Classes of visual objects used in recognition tasks, studied via one-shot learning methods.&lt;SEP&gt;Object categories refer to classes of objects in visual recognition, studied through one-shot learning methods.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="One-shot Learning">
  <data key="d0">One-shot Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A machine learning technique allowing recognition of new object categories from a single example, important in computer vision.&lt;SEP&gt;A technique allowing the recognition of new object categories from a single example, used in computer vision.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Michael Fink">
  <data key="d0">Michael Fink</data>
  <data key="d1">Researchers/Objects of Study</data>
  <data key="d2">Researcher working on object classification from a single example utilizing class relevance metrics.&lt;SEP&gt;Researcher working on object classification from minimal examples using relevance metrics.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="James Finnie-Ansley">
  <data key="d0">James Finnie-Ansley</data>
  <data key="d1">Researchers/Objects of Study</data>
  <data key="d2">Researcher exploring implications of OpenAI Codex on introductory programming education.</data>
  <data key="d3">chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Luciano Floridi">
  <data key="d0">Luciano Floridi</data>
  <data key="d1">Researchers/Objects of Study</data>
  <data key="d2">A philosopher and AI researcher analyzing GPT-3's nature, scope, limits, and societal consequences.&lt;SEP&gt;A philosopher and researcher analyzing GPT-3's nature, scope, limitations, and societal impacts.&lt;SEP&gt;A philosopher and researcher discussing the nature, scope, limits, and consequences of GPT-3.&lt;SEP&gt;A philosopher and researcher specializing in the philosophy of information, ethics of AI, and digital technology impacts.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Massimo Chiriatti">
  <data key="d0">Massimo Chiriatti</data>
  <data key="d1">Researchers/Objects of Study</data>
  <data key="d2">A researcher collaborating on analyzing GPT-3's capabilities, limits, and societal impacts.&lt;SEP&gt;A researcher collaborating with Floridi on analyzing GPT-3.&lt;SEP&gt;A researcher collaborating with Floridi, focusing on the analysis of GPT-3's nature, scope, limits, and societal consequences.&lt;SEP&gt;Researcher collaborating on analysis of GPT-3's implications and limits.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="William F. Godoy">
  <data key="d0">William F. Godoy</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher evaluating high-level programming models' performance and portability on exascale computing nodes, including Julia, Python/Numba, and Kokkos.&lt;SEP&gt;A researcher evaluating performance and portability of programming models on exascale computing nodes.&lt;SEP&gt;No description provided in the excerpt.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252&lt;SEP&gt;chunk-7d708fb91b624e6e44a1f601647c9fac</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Association for Computing Machinery">
  <data key="d0">Association for Computing Machinery</data>
  <data key="d1">Discipline/Organization</data>
  <data key="d2">A professional organization focusing on computing, computer science, and information technology research and dissemination.&lt;SEP&gt;An organization that publishes research proceedings and conferences related to computing and computer science.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="New York, NY, USA">
  <data key="d0">New York, NY, USA</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">A geographic location serving as the conference location for the ACE ’22 event.&lt;SEP&gt;Location serving as the venue for the ACM conference, indicating geographic and temporal context.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="ACE ’22">
  <data key="d0">ACE ’22</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference event organized by ACM focusing on computing research.&lt;SEP&gt;A specific academic conference organized by ACM, serving as a platform for presenting research findings.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Pedro Valero-Lara">
  <data key="d0">Pedro Valero-Lara</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher collaborating with Godoy on performance evaluation of programming models for exascale computing.&lt;SEP&gt;A researcher involved in performance evaluation of high-level programming models.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Julia, Python/Numba, Kokkos">
  <data key="d0">Julia, Python/Numba, Kokkos</data>
  <data key="d1">Tools</data>
  <data key="d2">High-level programming frameworks evaluated for performance and portability in exascale environments.&lt;SEP&gt;High-level programming models evaluated for performance and portability on exascale systems.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Thomas Helmuth">
  <data key="d0">Thomas Helmuth</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher developing the PSB2 benchmark suite for program synthesis evaluation.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Peter Kelly">
  <data key="d0">Peter Kelly</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher collaborating on the development and evaluation of the PSB2 benchmark suite.&lt;SEP&gt;A researcher collaborating on the development of the PSB2 benchmark suite.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="PSB2: The Second Program Synthesis Benchmark Suite">
  <data key="d0">PSB2: The Second Program Synthesis Benchmark Suite</data>
  <data key="d1">Tools</data>
  <data key="d2">A benchmark suite designed to evaluate program synthesis techniques and algorithms.&lt;SEP&gt;A benchmark suite designed to evaluate program synthesis techniques.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Julia Hirschberg">
  <data key="d0">Julia Hirschberg</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher contributing to advances in natural language processing.&lt;SEP&gt;A researcher specializing in natural language processing and computational linguistics.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Christopher D. Manning">
  <data key="d0">Christopher D. Manning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A prominent researcher in NLP, known for work on language understanding and processing.&lt;SEP&gt;A researcher collaborating with Hirschberg on NLP advancements.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Advances in natural language processing">
  <data key="d0">Advances in natural language processing</data>
  <data key="d1">Research Area</data>
  <data key="d2">A field focused on improving algorithms and models for understanding, generating, and translating human language.&lt;SEP&gt;A field focusing on improving computational understanding and generation of human language.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Saki Imai">
  <data key="d0">Saki Imai</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher conducting empirical studies on the effectiveness of GitHub Copilot as a substitute for human pair-programming.&lt;SEP&gt;A researcher studying the effectiveness of GitHub Copilot as a substitute for human pair-programming.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Zheming Jin">
  <data key="d0">Zheming Jin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher working on the Rodinia benchmarks implemented in SYCL for heterogeneous computing.&lt;SEP&gt;A researcher working on the implementation and analysis of the Rodinia benchmarks using SYCL for heterogeneous computing environments.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Hecbench">
  <data key="d0">Hecbench</data>
  <data key="d1">Tools</data>
  <data key="d2">A benchmarking suite for high-performance computing, available on GitHub, used for evaluating HPC hardware and software performance.&lt;SEP&gt;A benchmarking suite for high-performance computing, available on GitHub.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Srinath Kailasa">
  <data key="d0">Srinath Kailasa</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher developing PyExaFMM, a high-performance software framework using Python and Numba.&lt;SEP&gt;A researcher focused on designing high-performance software frameworks using Python and Numba, such as PyExaFMM.&lt;SEP&gt;A researcher working on high-performance software frameworks, exemplified by PyExaFMM, emphasizing Python and Numba.&lt;SEP&gt;A researcher working on high-performance software with Python and Numba.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="PyExaFMM">
  <data key="d0">PyExaFMM</data>
  <data key="d1">Tools</data>
  <data key="d2">A high-performance software framework developed with Python and Numba for exascale and HPC applications.&lt;SEP&gt;A software exercise designed to demonstrate high-performance computing techniques in Python.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Andreas Klöckner">
  <data key="d0">Andreas Klöckner</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher and developer contributing to GPU computing tools like pycuda and pyopencl.&lt;SEP&gt;A researcher and developer contributing to GPU computing tools, including pycuda and pyopencl.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="pycuda">
  <data key="d0">pycuda</data>
  <data key="d1">Tools</data>
  <data key="d2">A Python library for GPU programming and runtime code generation.&lt;SEP&gt;A Python library for GPU runtime code generation and GPU programming.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="pyopencl">
  <data key="d0">pyopencl</data>
  <data key="d1">Tools</data>
  <data key="d2">A Python library enabling OpenCL-based GPU computing.&lt;SEP&gt;A Python library for OpenCL-based GPU computing.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Tobias Knopp">
  <data key="d0">Tobias Knopp</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher supporting multi-threading and high-performance computing support in Julia.&lt;SEP&gt;A researcher supporting multi-threading support in Julia for high-performance computing.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Douglas Kothe">
  <data key="d0">Douglas Kothe</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher discussing exascale computing in the United States.&lt;SEP&gt;A researcher discussing the state, challenges, and prospects of exascale computing in the United States.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Siu Kwan Lam">
  <data key="d0">Siu Kwan Lam</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher working on Numba, a JIT compiler for Python aimed at accelerating numerical and scientific computing.&lt;SEP&gt;A researcher working on Numba, a JIT compiler for Python targeting high-performance computing.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Dongdong Lu">
  <data key="d0">Dongdong Lu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher analyzing the popularity and trends of programming languages within open-source software communities.&lt;SEP&gt;A researcher analyzing the popularity of programming languages in open-source communities.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Yongxiang Sheng">
  <data key="d0">Yongxiang Sheng</data>
  <data key="d1">Variables</data>
  <data key="d2">A researcher involved in programming languages and software community analysis.&lt;SEP&gt;A researcher studying the usage patterns and popularity metrics of programming languages across communities.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Yunsup Lee">
  <data key="d0">Yunsup Lee</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher working on GPU acceleration frameworks and high-performance software development.&lt;SEP&gt;A researcher working on GPU computing and high-performance software frameworks.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Bryan Catanzaro">
  <data key="d0">Bryan Catanzaro</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher contributing to GPU acceleration and deep learning frameworks.&lt;SEP&gt;A researcher contributing to GPU-accelerated deep learning frameworks and related high-performance tools.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Paul Ivanov">
  <data key="d0">Paul Ivanov</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher involved in GPU programming tools and frameworks.&lt;SEP&gt;A researcher working on GPU programming frameworks, including pycuda and other tools.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Ahmed Fasih">
  <data key="d0">Ahmed Fasih</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher involved in GPU computing, parallel algorithms, and high-performance software.&lt;SEP&gt;A researcher working on GPU computing and parallel programming.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Zhemin Jin">
  <data key="d0">Zhemin Jin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher developing Hecbench, a benchmark suite for HPC performance evaluation.&lt;SEP&gt;A researcher involved in developing Hecbench, a benchmark suite for HPC performance evaluation.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="arXiv:2303.08394">
  <data key="d0">arXiv:2303.08394</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">An arXiv preprint presenting research on PyExaFMM for high-performance computing.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="arXiv:2303.06195">
  <data key="d0">arXiv:2303.06195</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">An arXiv preprint evaluating performance of programming models Julia, Python/Numba, Kokkos on exascale nodes.&lt;SEP&gt;An arXiv preprint evaluating performance of programming models on exascale nodes.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="arXiv:3511861.3511863">
  <data key="d0">arXiv:3511861.3511863</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A DOI link to a conference proceeding discussing ACM ACE ’22.&lt;SEP&gt;A DOI-linked conference proceeding on ACM ACE ’22 discussing research in computing.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="https://doi.org/10.1145/3449639.3459285">
  <data key="d0">https://doi.org/10.1145/3449639.3459285</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A DOI link to a publication on the PSB2 benchmark suite for program synthesis.&lt;SEP&gt;A DOI link to a publication on the PSB2 benchmark suite.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="https://doi.org/10.1126/science.aaa8685">
  <data key="d0">https://doi.org/10.1126/science.aaa8685</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A DOI link to a Science article on advances in NLP.&lt;SEP&gt;A DOI link to a Science article on advances in natural language processing.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="https://doi.org/10.1145/3510454.3522684">
  <data key="d0">https://doi.org/10.1145/3510454.3522684</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A DOI link to a conference paper evaluating GitHub Copilot's code suggestions.&lt;SEP&gt;A DOI link to a conference paper on GitHub Copilot empirical evaluation.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="https://github.com/zjin-lcf/HeCBench">
  <data key="d0">https://github.com/zjin-lcf/HeCBench</data>
  <data key="d1">Tools</data>
  <data key="d2">A GitHub repository hosting Hecbench, a high-performance HPC benchmarking suite.&lt;SEP&gt;A GitHub repository hosting Hecbench, a high-performance benchmark suite.&lt;SEP&gt;The GitHub repository hosting Hecbench, a high-performance benchmarking suite.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="https://developer.nvidia.com/cuda">
  <data key="d0">https://developer.nvidia.com/cuda</data>
  <data key="d1">Tools</data>
  <data key="d2">Official NVIDIA CUDA Toolkit documentation, version 11.7.0, for GPU programming.&lt;SEP&gt;Official documentation for NVIDIA's CUDA Toolkit, version 11.7.0.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="UAL Event, Australia">
  <data key="d0">UAL Event, Australia</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset or event related to a university or academic event held in Australia, possibly involving research or academic presentations.</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Cupy">
  <data key="d0">Cupy</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Cupy is a numpy-compatible library designed for GPU calculations, facilitating high-performance numerical computations.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="NVIDIA CUDA Toolkit">
  <data key="d0">NVIDIA CUDA Toolkit</data>
  <data key="d1">Tools</data>
  <data key="d2">The CUDA Toolkit provides a suite of software tools and libraries for GPU programming and development, supporting high-performance computing tasks.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="JuliaGPU/AMDGPU.jl">
  <data key="d0">JuliaGPU/AMDGPU.jl</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">JuliaGPU/AMDGPU.jl is a Julia package enabling high-performance GPU programming on AMD hardware for scientific and computational applications.&lt;SEP&gt;JuliaGPU/AMDGPU.jl is a Julia package for GPU programming, enabling high-performance computations on AMD GPUs.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Program Synthesis">
  <data key="d0">Program Synthesis</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Program synthesis involves automatically generating code from specifications or descriptions, often evaluated for performance and accuracy.&lt;SEP&gt;The process of automatically generating programs from specifications, often using models like probabilistic context-free grammars or neural networks.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Generation Tools">
  <data key="d0">Code Generation Tools</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Automated systems like Codex designed to generate, assist with, or automate programming tasks, potentially broadening access and shifting skill requirements.&lt;SEP&gt;Code generation tools powered by LLMs aim to improve developer productivity, code quality, and automation in software development.&lt;SEP&gt;Tools like Codex facilitate faster and better code creation, impacting software development efficiency, worker productivity, and lowering barriers to entry in programming.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b&lt;SEP&gt;chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Security of GitHub Copilot">
  <data key="d0">Security of GitHub Copilot</data>
  <data key="d1">Results</data>
  <data key="d2">Studies assess the security implications of AI code contributions, identifying potential vulnerabilities and security risks.&lt;SEP&gt;Studies have analyzed the security risks associated with AI-generated code contributions, identifying vulnerabilities and potential exploits.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Python Programming Language">
  <data key="d0">Python Programming Language</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Python is a widely-used high-level programming language known for its readability and extensive libraries.&lt;SEP&gt;Python is a widely-used high-level programming language known for its simplicity and extensive ecosystem of libraries and frameworks.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="C++ Programming Language">
  <data key="d0">C++ Programming Language</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">C++ is a high-performance programming language used for system/software development, emphasizing efficiency and control over hardware resources.&lt;SEP&gt;C++ is a high-performance programming language used for system/software development, emphasizing efficiency and control.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="NumPy">
  <data key="d0">NumPy</data>
  <data key="d1">Tools</data>
  <data key="d2">NumPy is a fundamental Python library for numerical computing, providing efficient array structures and mathematical functions for scientific computations.&lt;SEP&gt;NumPy is a fundamental Python library for numerical computing, providing efficient array structures and mathematical functions.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Security and Privacy in AI Code Contributions">
  <data key="d0">Security and Privacy in AI Code Contributions</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Research investigates how AI-generated code impacts security and privacy considerations in software systems.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="NVIDIA">
  <data key="d0">NVIDIA</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">NVIDIA is a technology company specializing in graphics processing units (GPUs) and related software tools such as CUDA, enabling high-performance computing and GPU acceleration.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="CUDA Toolkit Documentation">
  <data key="d0">CUDA Toolkit Documentation</data>
  <data key="d1">Tools</data>
  <data key="d2">The CUDA Toolkit Documentation provides comprehensive guides and references for developing GPU-accelerated applications using NVIDIA's CUDA platform.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="OpenACC Architecture Review Board">
  <data key="d0">OpenACC Architecture Review Board</data>
  <data key="d1">Organizations</data>
  <data key="d2">The OpenACC Architecture Review Board develops and maintains the OpenACC standard, facilitating portable parallel programming for heterogeneous systems.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="OpenMP Architecture Review Board">
  <data key="d0">OpenMP Architecture Review Board</data>
  <data key="d1">Organizations</data>
  <data key="d2">The OpenMP Architecture Review Board oversees the development and standardization of the OpenMP API for shared-memory parallel programming.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Hammond Pearce">
  <data key="d0">Hammond Pearce</data>
  <data key="d1">Researchers</data>
  <data key="d2">Hammond Pearce is a researcher who conducted security assessments of GitHub Copilot’s code contributions, analyzing potential vulnerabilities.</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="T. Peterka, M. Strout, and J. Wilke">
  <data key="d0">T. Peterka, M. Strout, and J. Wilke</data>
  <data key="d1">authors</data>
  <data key="d2">Researchers who authored a report on extreme heterogeneity in computational science, focusing on productive approaches in this challenging environment.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Extreme Heterogeneity 2018">
  <data key="d0">Extreme Heterogeneity 2018</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A report discussing the challenges and productive strategies in computational science amidst extreme heterogeneity, serving as a foundational document for the field.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="DOE ASCR Workshop on Extreme Heterogeneity">
  <data key="d0">DOE ASCR Workshop on Extreme Heterogeneity</data>
  <data key="d1">Study Design</data>
  <data key="d2">A workshop organized by the DOE Office of Science to explore and address issues related to extreme heterogeneity in computational science.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="USDOE Office of Science (SC)">
  <data key="d0">USDOE Office of Science (SC)</data>
  <data key="d1">Discipline</data>
  <data key="d2">The U.S. Department of Energy's Office of Science, overseeing research and workshops related to scientific computing and heterogeneity.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="https://doi.org/10.2172/1473756">
  <data key="d0">https://doi.org/10.2172/1473756</data>
  <data key="d1">Tools</data>
  <data key="d2">Digital Object Identifier (DOI) link to the technical report, providing access to the full document.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Yaqing Wang, Quanming Yao, James T. Kwok, and Lionel M. Ni">
  <data key="d0">Yaqing Wang, Quanming Yao, James T. Kwok, and Lionel M. Ni</data>
  <data key="d1">authors</data>
  <data key="d2">Researchers who conducted a survey on few-shot learning, exploring generalization from limited examples.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Generalizing from a Few Examples">
  <data key="d0">Generalizing from a Few Examples</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">A survey exploring methods and challenges in enabling machine learning models to generalize from only a few training examples, i.e., few-shot learning.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="ACM Comput. Surv.">
  <data key="d0">ACM Comput. Surv.</data>
  <data key="d1">Study Design</data>
  <data key="d2">A comprehensive survey article published in the ACM Computing Surveys journal, reviewing techniques in few-shot learning.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="https://doi.org/10.1145/3386252">
  <data key="d0">https://doi.org/10.1145/3386252</data>
  <data key="d1">Tools</data>
  <data key="d2">DOI link to the survey article for detailed methodology and findings.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Michel Wermelinger">
  <data key="d0">Michel Wermelinger</data>
  <data key="d1">author</data>
  <data key="d2">Researcher who investigated the use of GitHub Copilot to solve programming problems.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Using GitHub Copilot to Solve Simple Programming Problems">
  <data key="d0">Using GitHub Copilot to Solve Simple Programming Problems</data>
  <data key="d1">Methodology</data>
  <data key="d2">A study examining how effectively GitHub Copilot can assist in solving basic programming tasks, demonstrating practical application of AI tools.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="ACM Technical Symposium on Computer Science Education V. 1">
  <data key="d0">ACM Technical Symposium on Computer Science Education V. 1</data>
  <data key="d1">Study Design</data>
  <data key="d2">Conference proceedings where the research was published, indicating peer-reviewed dissemination of findings.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="https://doi.org/10.1145/3545945.3569830">
  <data key="d0">https://doi.org/10.1145/3545945.3569830</data>
  <data key="d1">Tools</data>
  <data key="d2">DOI link to the conference paper detailing experimental setup and results.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Burak Yetistiren, Isik Ozsoy, and Eray Tuzun">
  <data key="d0">Burak Yetistiren, Isik Ozsoy, and Eray Tuzun</data>
  <data key="d1">authors</data>
  <data key="d2">Researchers who assessed the quality of GitHub Copilot's code generation capabilities.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Assessing the Quality of GitHub Copilot’s Code Generation">
  <data key="d0">Assessing the Quality of GitHub Copilot’s Code Generation</data>
  <data key="d1">Study Design</data>
  <data key="d2">A research study analyzing the performance and reliability of GitHub Copilot in generating code, focusing on quality metrics.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="PROMISE 2022">
  <data key="d0">PROMISE 2022</data>
  <data key="d1">Study Design</data>
  <data key="d2">The 18th International Conference on Predictive Models and Data Analytics in Software Engineering, where the study was presented.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="https://doi.org/10.1145/3558489.3559072">
  <data key="d0">https://doi.org/10.1145/3558489.3559072</data>
  <data key="d1">Tools</data>
  <data key="d2">DOI link to the conference proceedings and detailed methodology.</data>
  <data key="d3">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="scientific kernels for HPC">
  <data key="d0">scientific kernels for HPC</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d2">The generated kernels are evaluated using defined metrics to determine their correctness, efficiency, and suitability for HPC applications.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="background">
  <data key="d0">background</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d2">The background section discusses recent research efforts and highlights the focus on code generation and AI-assisted scientific computing.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="applications/implications">
  <data key="d0">applications/implications</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d2">Future directions include improving prompt techniques, dataset expansion, and integration of AI in HPC workflows, impacting scientific computing practices.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Scientific kernels for HPC">
  <data key="d0">Scientific kernels for HPC</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d2">The generated scientific kernels are evaluated using defined metrics to determine correctness, efficiency, and suitability for HPC applications."|"&lt;performance assessment</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Background">
  <data key="d0">Background</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d2">The background discusses recent research efforts in AI code generation, prompt-based learning, and the application of large language models in scientific computing."|"&lt;literature review, context</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Related efforts in computer science">
  <data key="d0">Related efforts in computer science</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d2">The background discusses recent research efforts in AI code generation, prompt-based learning, and the application of large language models in scientific computing."|"&lt;literature review, context</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Future directions">
  <data key="d0">Future directions</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d2">Future research aims to improve prompt techniques, expand datasets, and better integrate AI into HPC workflows, influencing future scientific computing practices."|"&lt;research development, innovation</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Reproducibility of the study">
  <data key="d0">Reproducibility of the study</data>
  <data key="d3">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d2">The detailed artifact descriptions in Appendix A ensure the study can be reproduced and validated, supporting transparency and further research."|"&lt;validation, transparency</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="code suggestions">
  <data key="d0">code suggestions</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d2">Structured prompts combining kernel and programming model influence the quality and correctness of generated code.&lt;SEP&gt;Structured prompts combining kernel and programming model influence the quality of code generated by AI models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="evaluation results">
  <data key="d0">evaluation results</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d2">The evaluation results summarize the accuracy and proficiency of Copilot's code suggestions across kernels and prompts.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Content-level keywords">
  <data key="d0">Content-level keywords</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d2">Main themes include programming languages, model sensitivity, code correctness, and evaluation metrics.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="main concepts">
  <data key="d0">main concepts</data>
  <data key="d3">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d2">Main themes include programming languages, model sensitivity, code correctness, and evaluation metrics.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Language">
  <data key="d0">Language</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">CUDA's effectiveness depends on specific keywords like 'kernel' or '__global__', and improper prompt language can decrease code quality.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Kernel Performance">
  <data key="d0">Kernel Performance</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">Kokkos performs poorly over several kernels, likely due to its smaller user community and abstraction complexity.&lt;SEP&gt;Kokkos performs poorly over several kernels, potentially due to the smaller user community and complexity of high-level abstractions.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Code Availability">
  <data key="d0">Code Availability</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">Copilot can generate correct Fortran code, especially with 'optimized' prompts and 'subroutine' keyword, due to Fortran's legacy and domain-specific nature.&lt;SEP&gt;Copilot can generate good Fortran code due to its domain-specific nature and legacy code base, especially when using an 'optimized' prompt and 'subroutine' keyword.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Kernel Syntax">
  <data key="d0">Kernel Syntax</data>
  <data key="d3">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d2">The effectiveness of CUDA code generation depends on using community-specific keywords like 'kernel' or '__global__', and improper prompts can decrease quality.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="kernel complexity">
  <data key="d0">kernel complexity</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d2">Higher kernel complexity reduces the likelihood of correct code generation by AI models, indicating a relationship between problem difficulty and output accuracy."|&gt;"complexity, correctness&lt;SEP&gt;Higher kernel complexity reduces the success rate of correct code generation by AI models, indicating a direct relationship between complexity and accuracy."|&gt;"complexity, correctness</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="code availability">
  <data key="d0">code availability</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d2">The abundance of publicly available code influences the success rate of AI code generation models across different languages."|&gt;"code access, model performance&lt;SEP&gt;The abundance of publicly available code influences the success rate of code generation models across languages."|&gt;"code access, model performance</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="code quality">
  <data key="d0">code quality</data>
  <data key="d3">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d2">Use of specific, targeted keywords in prompts improves the proficiency and correctness of AI-generated code."|&gt;"prompt design, output quality</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Generating High-Quality Multistep or Multikernel Codes">
  <data key="d0">Generating High-Quality Multistep or Multikernel Codes</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d2">As code complexity increases, generating high-quality multistep or multikernel codes becomes more difficult, highlighting a challenge in HPC code generation.&lt;SEP&gt;As code complexity increases, the difficulty of generating high-quality multistep or multikernel codes also increases, indicating a challenge in AI code generation capabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Improving Answer Proficiency">
  <data key="d0">Improving Answer Proficiency</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d2">Proper selection of keywords enhances the quality and relevance of AI-generated answers, emphasizing the importance of keyword sensitivity and specificity.&lt;SEP&gt;Using keywords enhances the proficiency of answers in programming tasks, emphasizing the importance of correct keyword selection.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="AI Tools">
  <data key="d0">AI Tools</data>
  <data key="d3">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d2">Current limitations of AI tools like Codex impact their practical use in HPC software development, necessitating further research and improvement.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Rodinia Benchmarks in SYCL">
  <data key="d0">Rodinia Benchmarks in SYCL</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d2">Jin works on implementing and analyzing benchmarks for heterogeneous computing using SYCL.&lt;SEP&gt;Jin's work involves implementing and analyzing the Rodinia benchmarks using SYCL for heterogeneous computing.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="pycuda and pyopencl">
  <data key="d0">pycuda and pyopencl</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d2">He developed and documented these libraries for GPU runtime code generation.&lt;SEP&gt;Klöckner developed and documented pycuda and pyopencl for GPU runtime code generation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Exascale Computing in the United States">
  <data key="d0">Exascale Computing in the United States</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d2">Discusses the current state and future prospects of exascale supercomputing in the US.&lt;SEP&gt;Kothe discusses the state and prospects of exascale computing efforts in the US.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPU Computing">
  <data key="d0">GPU Computing</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d2">Focuses on GPU acceleration frameworks and high-performance software.&lt;SEP&gt;Lee's research focuses on GPU acceleration and high-performance software frameworks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPU Acceleration">
  <data key="d0">GPU Acceleration</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d2">Catanzaro contributes to GPU-accelerated deep learning frameworks and tools.&lt;SEP&gt;Contributes to GPU-accelerated deep learning frameworks and tools.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPU Programming Tools">
  <data key="d0">GPU Programming Tools</data>
  <data key="d3">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d2">Ivanov works on GPU programming frameworks and tools like pycuda.&lt;SEP&gt;Works on GPU programming frameworks like pycuda.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="CUDA Toolkit">
  <data key="d0">CUDA Toolkit</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d2">Thrust is a library within the CUDA ecosystem, providing high-level parallel algorithms for GPU programming.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Multi-core CPUs">
  <data key="d0">Multi-core CPUs</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d2">OpenMP enables shared-memory parallelism on multi-core CPUs, improving computational efficiency.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Security">
  <data key="d0">Security</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d2">Studies assess the security implications of code contributions generated by GitHub Copilot, identifying potential vulnerabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="GPU Programming">
  <data key="d0">GPU Programming</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d2">JuliaGPU/AMDGPU.jl enables high-performance GPU programming on AMD hardware, facilitating scientific and computational tasks.&lt;SEP&gt;JuliaGPU/AMDGPU.jl provides tools for high-performance GPU programming on AMD hardware, enabling advanced computational tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Baleegh Ahmad">
  <data key="d0">Baleegh Ahmad</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d2">Baleegh Ahmad contributed to security evaluations of AI-generated code, focusing on vulnerabilities.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Benjamin Tan">
  <data key="d0">Benjamin Tan</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d2">Benjamin Tan's work involves assessing security implications of AI code contributions.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Brendan Dolan-Gavitt">
  <data key="d0">Brendan Dolan-Gavitt</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d2">Brendan Dolan-Gavitt's research includes analyzing security risks associated with AI-generated code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Ramesh Karri">
  <data key="d0">Ramesh Karri</data>
  <data key="d3">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d2">Ramesh Karri contributed to understanding security vulnerabilities in AI code contributions.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</node>
<node id="Domain Specialization">
  <data key="d0">Domain Specialization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Domain specialization involves techniques for customizing large language models (LLMs) to specific application domains, addressing challenges posed by data heterogeneity, domain knowledge complexity, unique objectives, and diverse constraints, with the goal of making LLMs more effective and disruptive in targeted fields.&lt;SEP&gt;Domain specialization refers to techniques designed to tailor large language models to specific application domains, addressing heterogeneity, knowledge complexity, and constraints to enhance their effectiveness and disruptiveness.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Specification Techniques">
  <data key="d0">Domain Specification Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods and approaches designed to tailor LLMs to specific domains, including techniques for increasing accessibility, integrating domain knowledge, and managing constraints to improve performance and applicability.&lt;SEP&gt;Techniques aimed at customizing LLMs for particular domains, including methods for enhancing accessibility, knowledge integration, and constraint handling.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Heterogeneity of Domain Data">
  <data key="d0">Heterogeneity of Domain Data</data>
  <data key="d1">Variables</data>
  <data key="d2">Refers to the diversity and variability of data within specific domains that challenge the direct application of general-purpose LLMs.&lt;SEP&gt;The diverse and variable nature of data within specific domains that complicates direct application of general LLMs and necessitates domain-specific adaptation techniques.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sophistication of Domain Knowledge">
  <data key="d0">Sophistication of Domain Knowledge</data>
  <data key="d1">Variables</data>
  <data key="d2">The complexity and depth of domain-specific knowledge that require specialized adaptation of LLMs for effective understanding and reasoning.&lt;SEP&gt;The complexity, depth, and specialized nature of knowledge within particular domains, requiring advanced methods for knowledge encoding and integration into LLMs.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Uniqueness of Domain Objectives">
  <data key="d0">Uniqueness of Domain Objectives</data>
  <data key="d1">Variables</data>
  <data key="d2">Distinct goals and constraints within different application domains that influence how LLMs should be tailored and utilized.&lt;SEP&gt;Distinct goals, tasks, and performance criteria that vary across domains, influencing how LLMs should be tailored to meet specific application needs.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Diversity of Constraints">
  <data key="d0">Diversity of Constraints</data>
  <data key="d1">Variables</data>
  <data key="d2">Various social norms, cultural standards, religious beliefs, and ethical considerations that impose specific limitations and requirements on LLM applications in different domains.&lt;SEP&gt;Various social norms, cultural standards, religious beliefs, and ethical considerations that impose specific limitations and requirements on domain-specific LLM applications.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Systematic Taxonomy">
  <data key="d0">Systematic Taxonomy</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A structured classification framework that categorizes LLM domain-specialization techniques based on their accessibility and functional attributes.&lt;SEP&gt;A structured classification framework that categorizes domain-specific LLM techniques based on their accessibility, methodological approaches, and functional attributes, aiding systematic understanding and research.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Application Domains">
  <data key="d0">Application Domains</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Application domains are specific fields or industries where domain-specialized LLMs are applied, such as healthcare, finance, or legal sectors.&lt;SEP&gt;Critical fields where specialized LLMs can have significant impact, including practical, social, and technological areas.&lt;SEP&gt;Key fields and sectors where specialized LLMs can be deployed to address specific challenges, improve efficiency, and enable new capabilities, such as healthcare, finance, and legal domains.&lt;SEP&gt;Specific fields or sectors, such as medicine or law, that can benefit from specialized LLMs to improve practical outcomes and efficiency.&lt;SEP&gt;Specific sectors such as medical, legal, and financial, where domain-specific LLMs are employed to improve task performance and reliability.&lt;SEP&gt;Various fields such as natural sciences, social sciences, and formal sciences where domain-specific LLMs can be applied for tasks like knowledge extraction, reasoning, and decision support.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c&lt;SEP&gt;chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-130e4012ca037ccaf70ac4ffd0928777&lt;SEP&gt;chunk-4068ec6ee794d8ae5ed33ac825ff37d4&lt;SEP&gt;chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Open Challenges">
  <data key="d0">Open Challenges</data>
  <data key="d1">Limitations</data>
  <data key="d2">Challenges include stability and universality of adapters, resource demands, and risks of overfitting or insufficient representation power.&lt;SEP&gt;Current unresolved issues in domain specialization of LLMs, including data scarcity, knowledge encoding difficulties, ethical concerns, and the need for better evaluation metrics.&lt;SEP&gt;Current unresolved issues in domain specialization, including knowledge updating, proprietary data integration, and social norm adaptation.&lt;SEP&gt;Key challenges include stability and universality of adapters, resource demands, and overfitting risks across tasks and domains.&lt;SEP&gt;Open challenges involve resource-intensive training, effective knowledge integration, avoiding catastrophic forgetting, and standardizing evaluation across domains.&lt;SEP&gt;Open challenges refer to the current limitations and issues faced in utilizing prompt tuning techniques for large language models, including interpretability, access restrictions, and domain adaptation.&lt;SEP&gt;Unresolved issues and difficulties in implementing and advancing domain-specific LLMs, such as data accessibility, knowledge encoding, and ethical considerations.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556&lt;SEP&gt;chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-130e4012ca037ccaf70ac4ffd0928777&lt;SEP&gt;chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Future Trends">
  <data key="d0">Future Trends</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Emerging directions and anticipated developments in domain-specific LLM research, including improved adaptation techniques, better handling of constraints, and broader application scopes.&lt;SEP&gt;Emerging directions and anticipated developments in the research and application of domain specialization for large language models.&lt;SEP&gt;Predicted directions for research, focusing on improving continuous learning, knowledge updating, and domain adaptation in LLMs.</data>
  <data key="d3">chunk-1c77a184d805ecadcb8dd5b0d1057e7c&lt;SEP&gt;chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Natural Language Processing">
  <data key="d0">Natural Language Processing</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Natural Language Processing (NLP) is a field of artificial intelligence focused on enabling computers to understand, interpret, and generate human language.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Transformer-based neural network architecture">
  <data key="d0">Transformer-based neural network architecture</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">An architecture leveraging self-attention mechanisms that significantly improved the performance of pre-trained language models, leading to the development of models like GPT-3.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pre-trained Language Models (PLMs)">
  <data key="d0">Pre-trained Language Models (PLMs)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Models trained on large corpus data using unsupervised learning to learn universal language representations, which can be fine-tuned for specific tasks.&lt;SEP&gt;PLMs are a subset of LLMs that are pre-trained on large corpora to learn linguistic patterns, serving as foundational models for various NLP applications.&lt;SEP&gt;PLMs are a subset of LLMs that are pre-trained on large text datasets to learn linguistic patterns, structures, and semantics, forming the foundation for downstream NLP tasks.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4&lt;SEP&gt;chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scaling law">
  <data key="d0">Scaling law</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A principle indicating that increasing model size and training data can lead to continuous improvements in model capacity and performance.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain specialization of LLMs">
  <data key="d0">Domain specialization of LLMs</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of customizing general-purpose LLMs with domain-specific data, knowledge, objectives, and constraints to better serve specialized tasks and fields.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge cut-off">
  <data key="d0">Knowledge cut-off</data>
  <data key="d1">Variables</data>
  <data key="d2">The point beyond which LLMs lack updated information due to limitations in training data, affecting their ability to incorporate the latest knowledge or discoveries.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Challenges in domain specialization">
  <data key="d0">Challenges in domain specialization</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Identifying key obstacles such as keeping models updated, integrating proprietary knowledge, and adapting to social norms for effective domain-specific LLM deployment.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Open challenges">
  <data key="d0">Open challenges</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Current unresolved issues in maintaining, updating, and customizing LLMs for specific domains, impacting their practical utility.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Future trends">
  <data key="d0">Future trends</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring methods to improve continuous learning, knowledge updating, and domain adaptation for LLMs to enhance their applicability and reliability.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Specialization Techniques">
  <data key="d0">Domain Specialization Techniques</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Domain specialization techniques are methods designed to adapt general-purpose LLMs to specific fields, enhancing performance on domain-specific tasks.&lt;SEP&gt;Techniques aimed at adapting or customizing LLMs for specific domains or tasks, including model fine-tuning, prompt engineering, and architectural modifications.&lt;SEP&gt;Techniques designed to customize and adapt Large Language Models (LLMs) for specific domains by leveraging domain-specific data, knowledge, and constraints to improve performance and relevance.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4&lt;SEP&gt;chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Accessibility to LLMs">
  <data key="d0">Accessibility to LLMs</data>
  <data key="d1">Variables</data>
  <data key="d2">The degree to which LLMs are available and usable for various applications, influencing the scope and effectiveness of domain specialization.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Framework for Subcategories">
  <data key="d0">Framework for Subcategories</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An organized structure summarizing the relationships and differences among various subcategories within domain specialization of LLMs.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Practical Significance">
  <data key="d0">Practical Significance</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The real-world importance and benefits of applying domain-specific LLMs to solve problems and enhance performance in targeted areas.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Current Research Status">
  <data key="d0">Current Research Status</data>
  <data key="d1">Results</data>
  <data key="d2">The present state of research on domain specialization of LLMs, including advancements, limitations, and ongoing efforts.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Update">
  <data key="d0">Knowledge Update</data>
  <data key="d1">Variables</data>
  <data key="d2">Knowledge updates based on explicit instructions perform well on natural language understanding tasks but are limited to simpler instructions and can cause forgetting when adapting to diverse tasks.&lt;SEP&gt;The process and mechanisms by which LLMs incorporate the latest information, discoveries, and regulations to maintain relevance.&lt;SEP&gt;The process of modifying a model's internal parameters or knowledge base to incorporate new information or correct errors.&lt;SEP&gt;Updating internal model parameters with new domain-specific text to enhance relevance and accuracy.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25&lt;SEP&gt;chunk-ce8332c6d0b3d23f38189ff80650d4bc&lt;SEP&gt;chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scaling up Model and Data">
  <data key="d0">Scaling up Model and Data</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Strategies involving increasing model size and training data to improve LLM capacity and performance, following the scaling law.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Self-Attention">
  <data key="d0">Self-Attention</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural network mechanism that allows models to weigh different parts of the input data, central to Transformer architectures.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Transformer-based neural networks">
  <data key="d0">Transformer-based neural networks</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A neural network architecture leveraging self-attention mechanisms, foundational to modern LLMs like GPT-3 and LLaMA.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Cut-off">
  <data key="d0">Knowledge Cut-off</data>
  <data key="d1">Variables</data>
  <data key="d2">The point beyond which LLMs lack updated information, impacting their ability to incorporate recent discoveries or events.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Proprietary Knowledge Resources">
  <data key="d0">Proprietary Knowledge Resources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Exclusive data sources, knowledge bases, or assets owned by organizations, critical for domain-specific LLM training and performance.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Social Norms, Cultural Conformity, Religious Beliefs, Legal Requirements, Ethical Practice">
  <data key="d0">Social Norms, Cultural Conformity, Religious Beliefs, Legal Requirements, Ethical Practice</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters influencing how LLMs must adapt to different social, cultural, religious, legal, and ethical contexts across regions and communities.</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Discoveries">
  <data key="d0">Discoveries</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Discoveries refer to new findings or insights that advance understanding in specialized domains, often leading to updates in regulations, practices, or knowledge bases.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Regulations">
  <data key="d0">Regulations</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Regulations are formal rules or directives established by authorities to govern practices within specific fields, often evolving based on new discoveries.&lt;SEP&gt;Regulations are rules or directives established by authorities to govern practices within specific fields, influencing how discoveries and best practices are implemented.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Best Practices">
  <data key="d0">Best Practices</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Best practices are established methods or techniques that are widely accepted as the most effective and efficient approaches within a domain, often evolving with new discoveries.&lt;SEP&gt;Best practices are established, validated methods or techniques considered optimal within a domain, often updated as new discoveries and regulations emerge.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Extraction">
  <data key="d0">Knowledge Extraction</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Knowledge extraction involves methods to retrieve relevant information from data sources, crucial for keeping LLMs updated and accurate.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Re-Training">
  <data key="d0">Re-Training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Re-Training is the process of updating a model with new data to improve performance, relevance, and accuracy, especially important for dynamic fields.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Continuous Learning">
  <data key="d0">Continuous Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Continuous learning enables models to adapt over time by incorporating new information, reducing obsolescence in rapidly evolving domains.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-Specific Knowledge">
  <data key="d0">Domain-Specific Knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Domain-specific knowledge encompasses specialized terminology, concepts, and relationships unique to particular fields, often underrepresented in general models.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hallucination">
  <data key="d0">Hallucination</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Hallucination refers to the tendency of LLMs to generate plausible but incorrect or inconsistent outputs, especially when lacking domain-specific guidance.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task-Specific Demonstrations">
  <data key="d0">Task-Specific Demonstrations</data>
  <data key="d1">Tools</data>
  <data key="d2">Task-specific demonstrations are examples provided to guide LLMs to produce more relevant and accurate responses in particular tasks.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Downstream Task Learning">
  <data key="d0">Downstream Task Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Downstream task learning involves adapting models to specific tasks using high-quality, task-relevant data, often requiring fine-tuning and hyperparameter optimization.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hyperparameters">
  <data key="d0">Hyperparameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Hyperparameters are adjustable settings in machine learning models that influence training behavior and performance, such as learning rate and training duration.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Computational Power">
  <data key="d0">Computational Power</data>
  <data key="d1">Tools</data>
  <data key="d2">Computational power refers to the hardware resources, such as GPUs or TPUs, required to train and fine-tune large models, often representing a significant resource constraint.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Complexity">
  <data key="d0">Model Complexity</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Model complexity pertains to the architectural intricacy of LLMs, characterized by billions of parameters, impacting training, fine-tuning, and resource requirements.&lt;SEP&gt;The level of intricacy in a model's architecture and operations, which can affect both performance and explainability.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Taxonomy of Techniques">
  <data key="d0">Taxonomy of Techniques</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The taxonomy categorizes domain specialization methods based on their accessibility levels (black-box, grey-box, white-box) and organizational structure.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Evaluation Methods">
  <data key="d0">Evaluation Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Evaluation methods assess the effectiveness of domain-specific techniques and models, including performance metrics, benchmarks, and qualitative analyses.&lt;SEP&gt;Probes and prompts designed to detect bias, such as def gender(x): and def race(x):, used to assess bias levels in model outputs.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906&lt;SEP&gt;chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Research Trends">
  <data key="d0">Research Trends</data>
  <data key="d1">Results</data>
  <data key="d2">Current research trends include developing systematic taxonomies, expanding application domains, and addressing challenges like resource demands and knowledge integration.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Discovered Knowledge">
  <data key="d0">Discovered Knowledge</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Discovered knowledge refers to new findings, insights, or information in specialized domains that can influence regulations, practices, and the development of best practices.</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Taxonomy of Domain Specialization Techniques">
  <data key="d0">Taxonomy of Domain Specialization Techniques</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A systematic classification of methods based on accessibility levels (black-box, grey-box, white-box</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Transformer Architecture">
  <data key="d0">Transformer Architecture</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Transformer architecture is a neural network design that employs attention mechanisms, forming the basis of many modern LLMs and enabling efficient processing of sequential data.&lt;SEP&gt;Transformer architecture is a neural network design that underpins many modern LLMs and PLMs, enabling efficient processing of sequential data through attention mechanisms.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scaling of Models">
  <data key="d0">Scaling of Models</data>
  <data key="d1">Variables</data>
  <data key="d2">Increasing model size or data size to enhance the capacity and performance of LLMs for various NLP tasks.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt-based Learning">
  <data key="d0">Prompt-based Learning</data>
  <data key="d1">Tools</data>
  <data key="d2">A methodology where specific prompts are designed to steer LLM outputs for particular tasks, reducing the need for extensive model retraining.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Evaluation of Domain Adaptation">
  <data key="d0">Evaluation of Domain Adaptation</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Systematic assessments and investigations that measure the effectiveness and challenges of domain adaptation techniques for LLMs.&lt;SEP&gt;Systematic surveys and investigations assessing the effectiveness of techniques to adapt PLMs and LLMs to specific domains such as medical, legal, or financial sectors.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Open Challenges in Domain Specialization">
  <data key="d0">Open Challenges in Domain Specialization</data>
  <data key="d1">Limitations</data>
  <data key="d2">Current bottlenecks include the inaccessibility of internal architecture of LLMs, high computational costs for updating knowledge, and the risk of inaccuracies when applying generic models to specialized fields.&lt;SEP&gt;Current issues include inaccessibility of internal architecture, high computational costs for knowledge updates, and risks of inaccuracies when applying generic models to specialized fields.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Future Trends in LLM Research">
  <data key="d0">Future Trends in LLM Research</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring efficient adaptation strategies, improving reasoning capabilities, and developing comprehensive taxonomies for domain-specific LLMs to make them more effective and accessible.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Scaling">
  <data key="d0">Model Scaling</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Increasing the size of models (parameters, data) to enhance their capacity and performance on downstream NLP tasks.&lt;SEP&gt;Model performance appears to scale smoothly with size in a sigmoid pattern as a function of parameters.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Domain Adaptation Techniques">
  <data key="d0">Domain Adaptation Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods used to adapt general LLMs to specific domains, including fine-tuning, prompt engineering, and architectural modifications.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Future Directions in LLM Research">
  <data key="d0">Future Directions in LLM Research</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring efficient adaptation strategies, improving reasoning and interpretability, and developing comprehensive taxonomies for domain-specific LLMs.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Technical Taxonomy of Domain Specialization">
  <data key="d0">Technical Taxonomy of Domain Specialization</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">A classification framework for existing techniques and approaches used to specialize LLMs for various domains, aiding systematic understanding and development.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Update Challenges">
  <data key="d0">Knowledge Update Challenges</data>
  <data key="d1">Limitations</data>
  <data key="d2">Difficulties associated with updating the knowledge embedded within LLMs due to their architecture and computational costs.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Risks of Generic LLMs">
  <data key="d0">Risks of Generic LLMs</data>
  <data key="d1">Limitations</data>
  <data key="d2">Potential inaccuracies, lack of originality, and ethical concerns when deploying non-specialized models in sensitive or precise fields.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Technical Taxonomy of Domain Specialization Techniques">
  <data key="d0">Technical Taxonomy of Domain Specialization Techniques</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">A structured classification of methods used to adapt and specialize LLMs for different application areas.</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ms">
  <data key="d0">Ms</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ms (likely referring to sequence models) are used for sequence-to-sequence tasks like machine translation and summarization, with T5 as a notable example.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="T5">
  <data key="d0">T5</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">T5 is a transformer-based model designed for various NLP tasks, exemplifying sequence-to-sequence architecture.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Decoder-only Language Models">
  <data key="d0">Decoder-only Language Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Decoder-only language models, such as GPT, are autoregressive models that generate the next token based on previous tokens, suitable for text generation.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="GPT">
  <data key="d0">GPT</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">GPT is an autoregressive language model that predicts subsequent words in a sequence, used for text generation.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Autoregressive Language Models">
  <data key="d0">Autoregressive Language Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Autoregressive models generate each token based on preceding tokens, fundamental for sequential text generation.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sequence of Tokens">
  <data key="d0">Sequence of Tokens</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A sequence of tokens is a series of discrete units (words or subwords) used as input/output in language models.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Vector Representation">
  <data key="d0">Vector Representation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Vector representations encode sequences of tokens into numerical form for model processing.&lt;SEP&gt;Vector representations encode token sequences into numerical vectors for computational processing by models.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Contextually Relevant Content">
  <data key="d0">Contextually Relevant Content</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Content generated by language models that is relevant to the input context, ensuring coherence.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Specialization of LLMs">
  <data key="d0">Domain Specialization of LLMs</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Tailoring large language models to perform optimally within specific fields or domains.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="External Augmentation">
  <data key="d0">External Augmentation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A domain specialization approach where external resources or tools are used to incorporate domain knowledge into LLMs without modifying internal parameters.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Crafting">
  <data key="d0">Prompt Crafting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique involving designing prompts to elicit domain-specific knowledge from LLMs, especially under limited model access.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Black Box">
  <data key="d0">Black Box</data>
  <data key="d1">Discipline</data>
  <data key="d2">Refers to scenarios where only the model's output can be accessed via API, with no internal details available.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Grey Box">
  <data key="d0">Grey Box</data>
  <data key="d1">Discipline</data>
  <data key="d2">Refers to scenarios where some internal information (like token probabilities) is accessible, enabling more refined prompt design.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="White Box">
  <data key="d0">White Box</data>
  <data key="d1">Discipline</data>
  <data key="d2">Refers to full access to the model's architecture and parameters, allowing comprehensive fine-tuning.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="External Knowledge">
  <data key="d0">External Knowledge</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">External Knowledge encompasses explicit or implicit information sources outside the model's parameters, used to improve domain-specific task performance without extensive retraining."|&lt;SEP&gt;Knowledge sourced outside the LLM, used to augment domain-specific performance via retrieval or other methods.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25&lt;SEP&gt;chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge-updated Domain Specialization">
  <data key="d0">Knowledge-updated Domain Specialization</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Updating LLM internal knowledge with domain-specific text to improve relevance and accuracy.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task-dependent">
  <data key="d0">Task-dependent</data>
  <data key="d1">Variables</data>
  <data key="d2">Variables that depend on specific tasks, influencing how models are fine-tuned or prompted.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instance-dependent">
  <data key="d0">Instance-dependent</data>
  <data key="d1">Variables</data>
  <data key="d2">Variables that depend on specific instances within a task, affecting prompt design or model adaptation.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Framework">
  <data key="d0">Framework</data>
  <data key="d1">Tools</data>
  <data key="d2">Structured approaches combining techniques like external augmentation, prompt crafting, and fine-tuning for domain adaptation.&lt;SEP&gt;Structured approaches combining various techniques for domain adaptation of LLMs.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sequence-to-Sequence Tasks">
  <data key="d0">Sequence-to-Sequence Tasks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Sequence-to-sequence tasks involve transforming an input sequence into a corresponding output sequence, common in machine translation and summarization, exemplified by models like T5.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Machine Translation">
  <data key="d0">Machine Translation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Machine translation is the process of automatically converting text from one language to another, a key application of sequence-to-sequence models.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Summarization">
  <data key="d0">Summarization</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Summarization involves condensing lengthy texts into shorter versions while preserving meaning, often achieved using sequence models like T5.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Token">
  <data key="d0">Token</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A token is a basic unit of text (word or subword) processed by language models, serving as the input/output unit.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Token Sequence">
  <data key="d0">Token Sequence</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A sequence of tokens is the ordered list of tokens input to or generated by a language model.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Autoregressive Modeling">
  <data key="d0">Autoregressive Modeling</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Autoregressive modeling predicts the next token based on previous tokens, fundamental for sequential text generation.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Contextual Relevance">
  <data key="d0">Contextual Relevance</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Refers to the generation of content that is relevant to the preceding context in text models.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Knowledge Augmentation">
  <data key="d0">Domain Knowledge Augmentation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Involves integrating external domain-specific knowledge into language models to improve performance in specialized fields.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="External Resources">
  <data key="d0">External Resources</data>
  <data key="d1">Tools</data>
  <data key="d2">External resources such as databases or knowledge bases used to augment language models without altering internal parameters.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot Learning">
  <data key="d0">Zero-shot Learning</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Training or testing models on new tasks without explicit prior examples, relying on prompt design or inherent knowledge.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Few-shot Learning">
  <data key="d0">Few-shot Learning</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Training or adapting models with a small number of examples to perform specific tasks.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapter-based Fine-tuning">
  <data key="d0">Adapter-based Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A domain adaptation approach that adds small trainable modules (adapters) into the model architecture to improve task-specific performance with minimal parameter updates.&lt;SEP&gt;A domain adaptation approach that inserts small trainable modules (adapters) into the existing model architecture to improve task-specific performance with minimal parameter updates.&lt;SEP&gt;A fine-tuning approach that inserts small trainable modules (adapters) into the model to adapt it to specific tasks or domains.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neural Adapter">
  <data key="d0">Neural Adapter</data>
  <data key="d1">Tools</data>
  <data key="d2">A type of adapter used in fine-tuning that employs neural network modules for domain adaptation.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Low-rank Adapter">
  <data key="d0">Low-rank Adapter</data>
  <data key="d1">Tools</data>
  <data key="d2">A lightweight adapter that constrains updates to low-rank matrices, enabling efficient domain adaptation.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instruction-based Fine-tuning">
  <data key="d0">Instruction-based Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique of updating LLMs using explicit task instructions and prompts across diverse datasets, improving zero-shot and few-shot performance.&lt;SEP&gt;Fine-tuning models based on specific instructions to improve task performance and controllability.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b&lt;SEP&gt;chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Black Box Assumption">
  <data key="d0">Black Box Assumption</data>
  <data key="d1">Discipline</data>
  <data key="d2">Scenario where only model outputs are accessible via API, with no internal details available.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Grey Box Assumption">
  <data key="d0">Grey Box Assumption</data>
  <data key="d1">Discipline</data>
  <data key="d2">Scenario where limited internal information (like token probabilities) is accessible, enabling prompt refinement.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="White Box Assumption">
  <data key="d0">White Box Assumption</data>
  <data key="d1">Discipline</data>
  <data key="d2">Scenario with full access to model architecture, parameters, and training data, allowing comprehensive fine-tuning.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Training Strategy">
  <data key="d0">Training Strategy</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approach for domain adaptation, including from-scratch training, fine-tuning, or mixed strategies.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pre-training Intervention">
  <data key="d0">Pre-training Intervention</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Modifying the pre-training process to incorporate domain-specific knowledge during initial training.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fine-tuning Intervention">
  <data key="d0">Fine-tuning Intervention</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Adjusting model parameters during fine-tuning to better fit domain-specific data.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Inference-time Intervention">
  <data key="d0">Inference-time Intervention</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Modifying model behavior during inference to generate domain-specific outputs without changing parameters.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Evaluation and Feedback">
  <data key="d0">Evaluation and Feedback</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Mechanisms for assessing model performance, including fixed benchmarks, dynamic evaluation, and user feedback.</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameters to Incorporate">
  <data key="d0">Parameters to Incorporate</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Parameters to incorporate refer to the process of integrating domain-specific knowledge directly into large language models (LLMs) to enhance their performance and specialization.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Approaches in Different Categories">
  <data key="d0">Approaches in Different Categories</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Relations between various approaches (external knowledge augmentation, prompt engineering, fine-tuning) are categorized and compared based on their operational levels and effects.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Specialization Levels">
  <data key="d0">Specialization Levels</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Different levels of approach specialization include black box, grey box, and white box, each operating at different depths of model intervention and knowledge integration.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="External Knowledge Augmentation">
  <data key="d0">External Knowledge Augmentation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">External Knowledge Augmentation involves enriching LLMs with domain-specific information retrieved from external sources, either as explicit structured data or implicit embedded knowledge, to improve accuracy and depth.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neural Adapters">
  <data key="d0">Neural Adapters</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Neural adapters are additional modules inserted into the model architecture to adapt the model to specific domains without full retraining, balancing performance and complexity.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Framework for Domain Specialization">
  <data key="d0">Framework for Domain Specialization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A common framework consisting of four stages—Definition, Augmentation, Optimization, and Evaluation—guides the process of domain-specific model adaptation.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Definition">
  <data key="d0">Definition</data>
  <data key="d1">Study Design</data>
  <data key="d2">The first stage where the domain, objectives, and constraints are clearly defined to guide subsequent augmentation and optimization steps.&lt;SEP&gt;The initial stage where the domain, objectives, and constraints are clearly defined to set the scope for subsequent augmentation and optimization steps.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Augmentation">
  <data key="d0">Augmentation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Stage involving the incorporation of domain-specific knowledge into the model or its inputs/outputs, such as through fine-tuning, prompt crafting, or external tools.&lt;SEP&gt;Stage involving the incorporation of domain-specific knowledge or tools into the model or its inputs, such as through fine-tuning, prompt crafting, or external resource integration.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="External Knowledge Sources">
  <data key="d0">External Knowledge Sources</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">External Knowledge Sources include documents, knowledge graphs, or neural networks containing domain knowledge used to augment LLMs.&lt;SEP&gt;External knowledge sources include documents, knowledge graphs, or neural networks that contain domain-specific information used to augment models.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Knowledge">
  <data key="d0">Domain Knowledge</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Domain knowledge encompasses concepts, principles, facts, and patterns specific to a field, which can be explicit (structured, easily expressed) or implicit (latent, embedded).&lt;SEP&gt;Domain knowledge encompasses facts, principles, and patterns specific to a field, which can be explicit (structured and easily expressed) or implicit (latent and embedded within data or models).&lt;SEP&gt;The accumulated and organized information, concepts, and relationships within a specific domain used to inform model understanding and reasoning.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Explicit Knowledge">
  <data key="d0">Explicit Knowledge</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Explicit Knowledge refers to clearly articulated, external information sources used to guide language models in domain-specific tasks, enabling the model to prioritize relevant data over memorized knowledge."|&lt;SEP&gt;Explicit Knowledge refers to external, clearly articulated information sources used to guide language models in domain-specific tasks, ensuring model predictions are anchored in relevant data."|&lt;SEP&gt;Explicit knowledge is clearly defined, structured information directly accessible and usable by LLMs, such as databases or structured documents.&lt;SEP&gt;Explicit knowledge is structured, clearly defined information that can be directly retrieved and utilized by models, such as databases, structured documents, or formalized data sources.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Implicit Knowledge">
  <data key="d0">Implicit Knowledge</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Implicit domain knowledge is latent, embedded information within data or models, represented as vectorized embeddings learned during pre-training, capturing intricate data patterns."|&lt;SEP&gt;Implicit knowledge is embedded within data or models in a latent form, not directly expressed, often requiring retrieval or inference techniques.&lt;SEP&gt;Implicit knowledge is latent, embedded within data or models in a non-obvious way, requiring inference or retrieval techniques to access effectively.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd&lt;SEP&gt;chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Complementary Nature">
  <data key="d0">Complementary Nature</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The approaches (external knowledge, prompt engineering, fine-tuning) can be combined or used independently to optimize domain-specific performance.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Relations between approaches in different categories">
  <data key="d0">Relations between approaches in different categories</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Relations describe how different approaches (external knowledge, prompt engineering, fine-tuning) are interconnected or compared within the framework of domain-specific model adaptation.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Different levels of specialization">
  <data key="d0">Different levels of specialization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Levels such as black box, grey box, and white box describe the depth and manner in which approaches modify or augment the model, impacting the degree of internal change and external intervention.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Augmenting with external knowledge">
  <data key="d0">Augmenting with external knowledge</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">This approach involves enriching models with external domain-specific information, which can be explicit or implicit, to improve performance and accuracy in specific fields.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt engineering">
  <data key="d0">Prompt engineering</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A methodology involving designing and refining input prompts to guide the model's responses towards domain-specific outputs without altering internal parameters.&lt;SEP&gt;The process of designing and optimizing prompts to improve the quality and accuracy of LLM outputs across different tasks.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3&lt;SEP&gt;chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neural adapters">
  <data key="d0">Neural adapters</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Modules inserted into the model architecture to facilitate domain adaptation without full retraining, offering a balance between performance and complexity.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Common Framework">
  <data key="d0">Common Framework</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A structured process comprising four stages—Definition, Augmentation, Optimization, and Evaluation—that guides systematic domain adaptation of large language models.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Complementary nature">
  <data key="d0">Complementary nature</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The approaches (external knowledge, prompt engineering, fine-tuning) can be combined or used independently to optimize domain-specific model performance.</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neural Retriever">
  <data key="d0">Neural Retriever</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A neural retriever is a technique that vectorizes queries and knowledge sources to search for relevant information based on similarity metrics like cosine similarity, facilitating retrieval of task-relevant external data."|</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Attention Mechanisms">
  <data key="d0">Attention Mechanisms</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Attention mechanisms enable models to retrieve task-related information from implicit knowledge by calculating attention scores between query vectors and knowledge entries, improving information access during inference."|</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Retrieval Process">
  <data key="d0">Knowledge Retrieval Process</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The process involves decomposing retrieval into detailed reasoning steps, verifying relevance, and integrating retrieved information into model inputs to enhance transparency and explainability."|</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Tool">
  <data key="d0">Domain Tool</data>
  <data key="d1">Tools</data>
  <data key="d2">Domain tools are specialized software, libraries, or frameworks tailored for specific fields (e.g., genomics APIs, theorem provers) to handle domain-specific tasks and data effectively."|</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Seamless Integration">
  <data key="d0">Seamless Integration</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A key challenge is developing methods for smoothly incorporating external knowledge into LLMs, allowing models to accept or reject retrieved information based on relevance and completeness."|</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scalability and Adaptability">
  <data key="d0">Scalability and Adaptability</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Designing systems that can efficiently scale to large knowledge bases and adapt to evolving information remains a significant challenge for external knowledge augmentation."|</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Augmentation">
  <data key="d0">Knowledge Augmentation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Knowledge augmentation involves enhancing language models with external (explicit) or embedded (implicit) knowledge to improve accuracy, relevance, and domain-specific performance."|</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Relevance Verification">
  <data key="d0">Relevance Verification</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Verifying whether retrieved external information is relevant and accurate, often using reasoning steps or validation mechanisms, to ensure reliable model outputs."|</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Explainability">
  <data key="d0">Explainability</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Explainability refers to the ability of models to provide understandable reasoning for their outputs, often enhanced by transparent retrieval and integration processes."|</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adaptability">
  <data key="d0">Adaptability</data>
  <data key="d1">Variables</data>
  <data key="d2">Adaptability indicates the ability of knowledge augmentation systems to incorporate new or changing information efficiently."|</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Retrieval Transparency">
  <data key="d0">Retrieval Transparency</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Retrieval transparency involves making the process of information retrieval understandable and traceable to users, aiding trust and explainability."|</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Tools">
  <data key="d0">Domain Tools</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specialized tools and functionalities designed for specific domains that can be invoked by LLMs to perform domain-specific tasks.&lt;SEP&gt;Tools and functionalities specialized for particular domains that can be called upon by LLMs to perform complex or domain-specific tasks.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Collaboration Approach">
  <data key="d0">Collaboration Approach</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A proposed integrated method combining LLMs and domain-specific tools to overcome limitations of each, enhancing task performance and user engagement.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multi-stage Pipeline">
  <data key="d0">Multi-stage Pipeline</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A procedural framework where LLMs generate commands, execute them via domain tools, and process outputs to accomplish complex tasks.&lt;SEP&gt;A procedural framework where LLMs generate commands, execute them via domain tools, and process outputs to solve complex problems.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Executable Commands">
  <data key="d0">Executable Commands</data>
  <data key="d1">Tools</data>
  <data key="d2">Commands generated by LLMs that invoke domain-specific tools or scripts, such as code snippets or API calls, to perform specific tasks.&lt;SEP&gt;Commands generated by LLMs to invoke domain tools, such as scripts or API calls, necessary for task execution.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Python Script">
  <data key="d0">Python Script</data>
  <data key="d1">Tools</data>
  <data key="d2">A code snippet written in Python used by LLMs to solve arithmetic problems or perform calculations as part of domain tool invocation.&lt;SEP&gt;A programming code example used by LLMs to solve arithmetic problems, demonstrating how executable code can be used in domain tool calls.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Arithmetic Question">
  <data key="d0">Arithmetic Question</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A specific problem used to illustrate how LLMs can generate executable code to solve domain-specific questions.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task Decomposition">
  <data key="d0">Task Decomposition</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of breaking down complex tasks into smaller, manageable subtasks that can be addressed by calling multiple domain tools or scripts.&lt;SEP&gt;The process of breaking down complex tasks into smaller, manageable subtasks that can be addressed by calling multiple domain tools.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="API Calling Scripts">
  <data key="d0">API Calling Scripts</data>
  <data key="d1">Tools</data>
  <data key="d2">Scripts generated by LLMs to interact with domain-specific APIs for tasks like search, database queries, or automation.&lt;SEP&gt;Scripts or code generated by LLMs to interact with domain-specific APIs for functionalities like search, database queries, or automation tasks.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot and Few-shot Prompting">
  <data key="d0">Zero-shot and Few-shot Prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques used to elicit executable commands or code from LLMs with minimal or no task-specific examples.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task Planners">
  <data key="d0">Task Planners</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Frameworks or systems that decompose complex tasks into subtasks and coordinate multiple tools or models to accomplish them.&lt;SEP&gt;Functions or models that decompose complex tasks into subtasks and coordinate the calling of multiple domain tools for efficient problem-solving.&lt;SEP&gt;Models or functions that decompose complex tasks into subtasks and coordinate multiple tool calls for efficient problem-solving.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74&lt;SEP&gt;chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Collaborative Integration Approach">
  <data key="d0">Collaborative Integration Approach</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A strategy that combines LLMs with domain-specific tools to overcome individual limitations, enhancing performance and usability in complex tasks.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Arithmetic Problem">
  <data key="d0">Arithmetic Problem</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A specific problem involving counts of heads and feet to demonstrate how LLMs generate executable code for domain tasks.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Bases">
  <data key="d0">Knowledge Bases</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Structured repositories of domain-specific information that can be accessed or utilized by LLMs and tools to improve accuracy and relevance.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Result Accuracy">
  <data key="d0">Result Accuracy</data>
  <data key="d1">Variables</data>
  <data key="d2">The measure of correctness or precision of the outputs produced by LLMs and domain tools in solving tasks.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tool APIs">
  <data key="d0">Tool APIs</data>
  <data key="d1">Tools</data>
  <data key="d2">Application Programming Interfaces that enable LLMs to call domain-specific functionalities programmatically for precise task execution.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Result Validation">
  <data key="d0">Result Validation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Procedures or checks performed to verify the correctness and reliability of outputs generated by LLMs and tools.</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-Shot or Few-Shot Prompting Techniques">
  <data key="d0">Zero-Shot or Few-Shot Prompting Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques that involve prompting large language models with minimal examples or instructions to perform tasks without extensive retraining.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="API Selectors">
  <data key="d0">API Selectors</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Components or roles within task planning systems responsible for selecting appropriate domain tools or models to execute subtasks.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Controllers">
  <data key="d0">Controllers</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Elements that manage and orchestrate multiple domain tools or models during complex task execution.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="DSP (Draft, Sketch, and Prove Framework)">
  <data key="d0">DSP (Draft, Sketch, and Prove Framework)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A framework for automated theorem proving involving drafting informal proofs, generating formal sketches, and applying off-the-shelf provers to verify conjectures.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="TaskMatrix.AI">
  <data key="d0">TaskMatrix.AI</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A system that uses LLMs to generate high-level solutions, match subtasks to domain models, and complete tasks automatically.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="HuggingGPT">
  <data key="d0">HuggingGPT</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An approach leveraging LLMs as controllers to manage existing domain models for solving complex tasks.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Qin et al.'s Framework">
  <data key="d0">Qin et al.'s Framework</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A general framework for decomposing complex tasks, dynamically adjusting execution plans, and utilizing appropriate tools for subtasks.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LLMs Embodied to Domain Tools">
  <data key="d0">LLMs Embodied to Domain Tools</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The integration of large language models into domain-specific interactive environments, such as robots, to serve as decision-making modules or agents.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ProgPrompt">
  <data key="d0">ProgPrompt</data>
  <data key="d1">Tools</data>
  <data key="d2">A system that employs LLMs to assist robots in completing tasks by generating situated actions based on perception and action specifications.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Murali et al.'s System">
  <data key="d0">Murali et al.'s System</data>
  <data key="d1">Tools</data>
  <data key="d2">An application where LLMs identify speakers in multiparty conversations involving social robots, serving as core components for human-robot interaction.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mind’s Eye">
  <data key="d0">Mind’s Eye</data>
  <data key="d1">Tools</data>
  <data key="d2">A system that uses LLMs to interact with physics engines, providing grounded rationale for physics-related tasks.&lt;SEP&gt;Mind’s Eye is a grounded language model approach that uses simulation for reasoning and grounded language understanding.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="CAMEL">
  <data key="d0">CAMEL</data>
  <data key="d1">Tools</data>
  <data key="d2">A framework for multiple AI agents to communicate and collaborate by chatting, assigning roles to solve tasks collectively.&lt;SEP&gt;CAMEL refers to Communicative Agents for 'Mind' Exploration of Large Scale Language Model Society, a framework or approach for studying language models and their societal roles.&lt;SEP&gt;CAMEL stands for Communicative Agents for 'Mind' Exploration of Large Scale Language Model Society, a framework or approach for studying language models and their societal roles.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Game-Based Sandbox Environment with 25 LLMs">
  <data key="d0">Game-Based Sandbox Environment with 25 LLMs</data>
  <data key="d1">Tools</data>
  <data key="d2">A simulation environment where multiple LLMs act as generative agents to create realistic human behavior for interactive applications.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Open Challenges in Domain Tool Augmentation">
  <data key="d0">Open Challenges in Domain Tool Augmentation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Key issues include automating integration of domain tools and developing AGI models that do not depend on external tools or domain-specific knowledge.</data>
  <data key="d3">chunk-13de013c89659019025ef3c655d8a436</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Discrete Prompt">
  <data key="d0">Discrete Prompt</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique used to adapt large language models (LLMs) to unseen domains by providing instructions or examples without updating model parameters, enabling zero-shot or few-shot task performance.&lt;SEP&gt;A technique used to enable large language models (LLMs) to perform tasks in unseen domains by providing task instructions or examples without modifying the model's internal parameters, supporting zero-shot and few-shot learning scenarios.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot Discrete Prompts">
  <data key="d0">Zero-shot Discrete Prompts</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompting approach where only task description is provided, with no supportive examples, used to evaluate LLMs' reasoning without prior task-specific examples.&lt;SEP&gt;A prompting approach where only task descriptions are provided to LLMs without supporting examples, used to evaluate the model's ability to generalize to new tasks without prior exposure.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Few-shot Discrete Prompts">
  <data key="d0">Few-shot Discrete Prompts</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompting approach where a few annotated examples are included along with task description to improve LLM performance on domain-specific tasks.&lt;SEP&gt;A prompting strategy that supplies a small number of annotated examples along with task instructions to improve LLM performance on specific tasks with limited data.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LLM">
  <data key="d0">LLM</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Large Language Models are AI models trained on vast text data to perform natural language understanding and generation tasks.&lt;SEP&gt;Large Language Models are advanced AI models trained on extensive text corpora to understand and generate human-like language across diverse tasks.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task description">
  <data key="d0">Task description</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A natural language description of the task that guides the LLM in generating the desired output.&lt;SEP&gt;A natural language statement that defines the specific task the LLM is expected to perform, such as classification, reasoning, or extraction.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Test query">
  <data key="d0">Test query</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A specific input or question provided to the LLM to evaluate its performance, reasoning, or response accuracy.&lt;SEP&gt;A specific input or question provided to the LLM to evaluate its response or reasoning capabilities.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Reasoning sentences">
  <data key="d0">Reasoning sentences</data>
  <data key="d1">Results</data>
  <data key="d2">Generated intermediate logical steps that demonstrate the LLM's thought process during multi-step reasoning tasks, often used to improve interpretability and accuracy.&lt;SEP&gt;Generated intermediate logical steps that demonstrate the model's thought process during multi-step reasoning tasks.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instruction alignment pre-training">
  <data key="d0">Instruction alignment pre-training</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A pre-training approach that improves LLMs' zero-shot performance by aligning instructions with model capabilities, enhancing task generalization.&lt;SEP&gt;A pre-training framework that aligns model training objectives with human instructions, enhancing zero-shot generalization and task adaptability in LLMs.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain adaptation ability">
  <data key="d0">Domain adaptation ability</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The capability of LLMs to adapt their performance to new, unseen domains through specific prompting strategies and training techniques.&lt;SEP&gt;The capacity of LLMs to adjust their performance to new, unseen domains through specific prompting strategies.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Arithmetic, symbolic reasoning, logical reasoning tasks">
  <data key="d0">Arithmetic, symbolic reasoning, logical reasoning tasks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Types of evaluation tasks used to measure LLMs' reasoning and problem-solving abilities, particularly in zero-shot and few-shot settings.&lt;SEP&gt;Types of tasks used to evaluate the reasoning and problem-solving capabilities of LLMs, especially in zero-shot and few-shot settings.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multi-step reasoning">
  <data key="d0">Multi-step reasoning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A cognitive process involving sequential logical steps to arrive at a conclusion, which can be elicited in LLMs through specific prompting techniques like Chain-of-Thoughts.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chain-of-Thoughts (CoT)">
  <data key="d0">Chain-of-Thoughts (CoT)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A prompting technique that encourages LLMs to generate a series of intermediate reasoning steps before providing a final answer, improving performance on complex reasoning tasks.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot-CoT">
  <data key="d0">Zero-shot-CoT</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A variant of Chain-of-Thought prompting that does not rely on illustrative examples but prompts the model to think step-by-step using specific instructions like 'Let's think step by step.'</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model parameters">
  <data key="d0">Model parameters</data>
  <data key="d1">Variables</data>
  <data key="d2">The internal weights and configurations of an LLM that determine its behavior and output, which are fixed during inference in zero-shot/few-shot settings.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task performance">
  <data key="d0">Task performance</data>
  <data key="d1">Results</data>
  <data key="d2">The success rate or accuracy of an LLM in completing specific tasks under different prompting strategies, reflecting the model's reasoning and generalization capabilities.</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="APGAR Scores">
  <data key="d0">APGAR Scores</data>
  <data key="d1">Results</data>
  <data key="d2">APGAR scores are a clinical measure used to assess the health of newborns, with low scores indicating potential health issues.</data>
  <data key="d3">chunk-03fe9b9ee91cb6d7d1e6d86d23f22ae9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hypothesis">
  <data key="d0">Hypothesis</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The hypothesis states that she had low APGAR scores, suggesting an inquiry into neonatal health outcomes.</data>
  <data key="d3">chunk-03fe9b9ee91cb6d7d1e6d86d23f22ae9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Low APGAR Scores">
  <data key="d0">Low APGAR Scores</data>
  <data key="d1">Variables</data>
  <data key="d2">Low APGAR scores are specific numeric or categorical outcomes indicating possible neonatal health concerns.</data>
  <data key="d3">chunk-03fe9b9ee91cb6d7d1e6d86d23f22ae9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neonatal Health">
  <data key="d0">Neonatal Health</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Neonatal health refers to the health status of newborn infants, often assessed through various clinical measures including APGAR scores.</data>
  <data key="d3">chunk-03fe9b9ee91cb6d7d1e6d86d23f22ae9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Clinical Assessment">
  <data key="d0">Clinical Assessment</data>
  <data key="d1">Tools</data>
  <data key="d2">Clinical assessment involves methods and tools used to evaluate newborn health, such as the APGAR scoring system.</data>
  <data key="d3">chunk-03fe9b9ee91cb6d7d1e6d86d23f22ae9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="prompt tuning">
  <data key="d0">prompt tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Prompt tuning is a technique for adapting pre-trained language models (PLMs) and large language models (LLMs) by optimizing continuous prompts to improve task performance, domain adaptation, and efficiency.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="task-dependent prompt tuning">
  <data key="d0">task-dependent prompt tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A category of prompt tuning that involves optimizing a shared prompt for all instances within a specific task, capturing extensive dataset information.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="prompt content enhancement">
  <data key="d0">prompt content enhancement</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Enhancements in prompt tuning focusing on task-specific initialization and transfer of prior knowledge to improve optimization and performance.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="prompt initialization">
  <data key="d0">prompt initialization</data>
  <data key="d1">Variables</data>
  <data key="d2">The process of setting initial embedding values for prompts, which influences the convergence and effectiveness of prompt tuning.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="special token '[MASK]'">
  <data key="d0">special token '[MASK]'</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A token used in prompt tuning to facilitate masked language modeling, serving as a basis for initializing prompts in certain methods like WARP.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="virtual type words">
  <data key="d0">virtual type words</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Learnable prompts designed as virtual words representing types or answers, initialized based on dataset label words to guide prompt tuning.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="prompt transferability">
  <data key="d0">prompt transferability</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The concept that prompts trained on source domains or tasks can be transferred to enhance performance on unseen target domains or tasks.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="self-supervised learning">
  <data key="d0">self-supervised learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A learning paradigm used to pre-train prompts on unlabeled data, enabling better initialization and transfer in prompt tuning.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="prompt transfer">
  <data key="d0">prompt transfer</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using transferred prompts across tasks or domains to improve learning efficiency and model performance.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Tuning">
  <data key="d0">Prompt Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique for adapting large language models (LLMs) and pre-trained language models (PLMs) by optimizing continuous prompts to improve task performance, domain adaptation, and parameter efficiency.&lt;SEP&gt;A technique to adapt large language models by optimizing prompts rather than fine-tuning entire models, involving prompt construction, enhancement, and transfer.&lt;SEP&gt;A technique to adapt large language models by optimizing prompts rather than updating all model parameters, involving prompt construction, enhancement, and transfer.&lt;SEP&gt;Prompt tuning involves adjusting prompts to steer LLM outputs for specific tasks, with variants including soft and discrete prompts, aiming to improve efficiency and task-specific performance.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-6f045498b0e63780c3aef4b9daf795b6&lt;SEP&gt;chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task-dependent Prompt Tuning">
  <data key="d0">Task-dependent Prompt Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A category of prompt tuning that involves creating a shared prompt optimized across all instances within a specific task, capturing extensive dataset information for better task performance.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Content">
  <data key="d0">Prompt Content</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The embedded values of continuous prompts that can be enhanced through task-specific initialization and knowledge transfer to improve optimization and effectiveness.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Initialization">
  <data key="d0">Prompt Initialization</data>
  <data key="d1">Variables</data>
  <data key="d2">The process of setting initial embedding values for prompts, which significantly influences convergence speed and final performance in prompt tuning.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Special Token '[MASK]'">
  <data key="d0">Special Token '[MASK]'</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A token used in masked language modeling and prompt tuning to facilitate predictions and serve as a basis for prompt initialization, such as in WARP.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Virtual Type Words">
  <data key="d0">Virtual Type Words</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Learnable virtual words representing types or labels, initialized based on dataset label words to guide prompt learning.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Transferability">
  <data key="d0">Prompt Transferability</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The concept that prompts trained on one domain or task can be transferred to improve performance in other domains or tasks, emphasizing adaptability and reusability.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Self-supervised Learning">
  <data key="d0">Self-supervised Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A learning paradigm used to pre-train prompts on unlabeled data, enabling better initialization and transfer, and enhancing prompt tuning effectiveness.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Transfer">
  <data key="d0">Prompt Transfer</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Applying trained prompts across different tasks or domains to leverage learned representations, thereby improving efficiency and performance in new contexts.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Fine-tuning">
  <data key="d0">Prompt Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of adapting prompts to specific tasks or domains by further training, often following initial pretraining or transfer.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Initialization Strategies">
  <data key="d0">Prompt Initialization Strategies</data>
  <data key="d1">Variables</data>
  <data key="d2">Different approaches to setting initial prompt embeddings, such as random, dataset-based, or learned initializations, affecting training convergence.</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Adaptation">
  <data key="d0">Domain Adaptation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Adjusting prompts and models trained on one domain to perform well in another, often via transfer learning and specialized initialization.&lt;SEP&gt;Techniques that modify models to perform effectively within specific fields or tasks, enhancing their practical utility.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Self-Supervised Learning">
  <data key="d0">Self-Supervised Learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A training approach where models learn representations by predicting parts of data without labeled examples, used to pre-train language models.&lt;SEP&gt;A training paradigm where models learn to understand data structures by predicting parts of the data without labeled supervision, used for pre-training language models.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Transferability of Prompts">
  <data key="d0">Transferability of Prompts</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The ability of prompts trained or initialized in one context to be effectively used in different tasks or models, enabling cross-task and cross-model generalization.&lt;SEP&gt;The concept that prompts trained or initialized in one context or task can be effectively applied to other tasks or models, enhancing adaptability.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lifelong Learning">
  <data key="d0">Lifelong Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A learning framework where models continually learn new tasks over time while retaining previous knowledge, often employing techniques like soft prompts to mitigate catastrophic forgetting.&lt;SEP&gt;A learning paradigm where models continuously acquire knowledge over time, retaining previous knowledge while learning new tasks, often employing soft prompts.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Template">
  <data key="d0">Template</data>
  <data key="d1">Tools</data>
  <data key="d2">Predefined formats or patterns used to reformulate NLP tasks into forms suitable for prompt-based models, such as masked word prediction.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Soft Prompt">
  <data key="d0">Soft Prompt</data>
  <data key="d1">Tools</data>
  <data key="d2">Trainable prompt embeddings that can be inserted into input sequences to condition models without modifying their internal parameters.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prefix-tuning">
  <data key="d0">Prefix-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A prompt tuning approach where prompts are prepended to input sequences, leveraging autoregressive models' properties to influence subsequent words."|&gt;8&lt;SEP&gt;A prompt tuning method where prompts are prepended to input sequences, leveraging autoregressive properties for efficient task adaptation.&lt;SEP&gt;Prefix-tuning prepends trainable prefix tokens to the input to adapt large language models to specific tasks.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556&lt;SEP&gt;chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="KnowPrompt">
  <data key="d0">KnowPrompt</data>
  <data key="d1">Methods/Models</data>
  <data key="d2">A prompt design that appends templates with masked tokens and virtual type words to facilitate relation extraction by aligning embeddings with target relations.&lt;SEP&gt;A prompt design that appends templates with masked tokens and virtual type words to facilitate relation extraction by aligning embeddings with target relations."|&gt;9&lt;SEP&gt;A prompt-discovery method that identifies domain-related prompt tokens, enhancing domain-specific interpretability and performance.&lt;SEP&gt;A prompt-tuning approach that discovers prompt tokens near domain-related terms, aiming to enhance domain-specific performance.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="KiPT">
  <data key="d0">KiPT</data>
  <data key="d1">Methods/Models</data>
  <data key="d2">A knowledge extractor that identifies trigger words for event detection and reformulates sequence tagging into generative tasks, utilizing semantic similarity to event concepts."|&gt;8&lt;SEP&gt;A knowledge extractor that identifies trigger words for event detection and reformulates sequence tagging into generative tasks, utilizing semantic similarity.&lt;SEP&gt;KiPT stands for Knowledge-injected Prompt Tuning, a methodology for improving event detection in language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instance-dependent Prompt Tuning">
  <data key="d0">Instance-dependent Prompt Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A prompt tuning approach that generates prompts conditioned on individual instances, incorporating contextual and task-specific information for fine-grained objectives.&lt;SEP&gt;A prompt tuning approach that generates prompts conditioned on individual instances, incorporating contextual and task-specific information for more precise adaptation."|&gt;9</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="IDPG">
  <data key="d0">IDPG</data>
  <data key="d1">Tools</data>
  <data key="d2">A prompt generator employing a perceptron to produce adaptive soft prompts based on sentence embeddings, enabling instance-aware prompt creation.&lt;SEP&gt;A prompt generator employing a perceptron to produce adaptive soft prompts based on sentence embeddings, enabling instance-aware prompt creation."|&gt;8</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Attention Network">
  <data key="d0">Attention Network</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural network component used to aggregate multiple prompts based on relevance, enhancing prompt effectiveness for specific inputs."|&gt;7&lt;SEP&gt;A neural network component used to aggregate multiple prompts based on sentence-wise attention, enhancing prompt relevance for target tasks.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Content Enhancement">
  <data key="d0">Prompt Content Enhancement</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Strategies to improve prompts by adding external knowledge, adjusting position and length, or dynamically defining prompt parameters for better task performance.&lt;SEP&gt;Strategies to improve prompts by adding external knowledge, adjusting position and length, or dynamically defining prompt parameters for better task performance."|&gt;9</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="OntoPrompt">
  <data key="d0">OntoPrompt</data>
  <data key="d1">Tools</data>
  <data key="d2">A method that enriches prompts with external ontology knowledge and external context, tuning prompts with instance-related information to improve prediction accuracy."|&gt;8&lt;SEP&gt;A method that enriches prompts with external ontology knowledge and tunes prompts with instance-related information to improve prediction accuracy.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dynamic Prompting">
  <data key="d0">Dynamic Prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A framework to learn and adjust instance-dependent prompts dynamically by defining position, length, and content for each input, improving adaptability."|&gt;8&lt;SEP&gt;A framework to learn instance-dependent prompts by dynamically adjusting position, length, and content for each input, enhancing flexibility and effectiveness.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Open Challenges in Prompt Tuning">
  <data key="d0">Open Challenges in Prompt Tuning</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The ongoing issues with prompt reliance, computational complexity, and domain adaptation, requiring more robust and adaptable prompt methods for large language models."|&gt;7&lt;SEP&gt;The ongoing issues with prompt reliance, computational complexity, and the need for more robust, domain-adaptive prompt methods for large language models.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pre-training">
  <data key="d0">Pre-training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of training a model on large unlabeled corpora to learn general representations before fine-tuning for specific tasks.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Templates">
  <data key="d0">Templates</data>
  <data key="d1">Tools</data>
  <data key="d2">Predefined patterns or structures used to reformulate NLP tasks into prompt-compatible formats, such as masked language modeling or relation extraction templates.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Continuous Prompts">
  <data key="d0">Continuous Prompts</data>
  <data key="d1">Tools</data>
  <data key="d2">Trainable prompt embeddings that can be prepended, appended, or inserted into input sequences without additional language phrases, used to guide model outputs.</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="WARP">
  <data key="d0">WARP</data>
  <data key="d1">Tools</data>
  <data key="d2">A prompt method employing all three intersections with a “[MASK]” token for classification tasks, enhancing flexibility in prompt design.&lt;SEP&gt;A study analyzing the non-interpretable nature of soft prompts by examining their proximity to domain-related terms in language model vocabularies.&lt;SEP&gt;A study that explores the non-interpretable nature of soft prompts by analyzing their proximity to domain-related terms in language model vocabularies.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Soft Prompts">
  <data key="d0">Soft Prompts</data>
  <data key="d1">Tools</data>
  <data key="d2">Trainable prompt embeddings that can be inserted into input sequences, allowing models to adapt to specific tasks without full fine-tuning."|&gt;8</data>
  <data key="d3">chunk-d3bbf812d2ef1f847454ee16a672e8f9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Continuous Prompt Tuning">
  <data key="d0">Continuous Prompt Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A method that leverages the broad language understanding capacity of LLMs to adapt to specific tasks across domains by tuning prompts continuously, aiming to improve efficiency and effectiveness.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Discreet Prompt Methods">
  <data key="d0">Discreet Prompt Methods</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Approaches that depend on specific, manually designed prompts, which are sensitive to wording and template variations, impacting performance and generalizability.&lt;SEP&gt;Approaches that rely on manually designed prompts, sensitive to wording, affecting model performance and transferability.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt-tuning">
  <data key="d0">Prompt-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique that involves adjusting prompts to guide model outputs, with variants like soft and discrete prompt tuning.&lt;SEP&gt;A technique that involves adjusting prompts to steer LLMs towards desired outputs, with variants like soft and discrete prompt tuning.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="OPTIMA">
  <data key="d0">OPTIMA</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A domain adaptation approach that tunes prompts to regularize decision boundaries and improve transferability across similar data distributions via adversarial learning.&lt;SEP&gt;A domain adaptation method that tunes prompts to regularize decision boundaries via adversarial learning, enhancing transferability across similar data distributions.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Limited Access to LLMs">
  <data key="d0">Limited Access to LLMs</data>
  <data key="d1">Limitations</data>
  <data key="d2">A significant challenge where models with immense size or only API access hinder gradient-based prompt optimization, necessitating alternative approaches.&lt;SEP&gt;A significant challenge where models with immense size or only API access hinder gradient-based prompt optimization, necessitating alternative methods.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Black-box Tuning (BBT)">
  <data key="d0">Black-box Tuning (BBT)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A gradient-free approach that searches for optimal prompts without requiring access to model gradients, using covariance matrix adaptation evolution strategy (CMA-ES).</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Covariance Matrix Adaptation Evolution Strategy (CMA-ES)">
  <data key="d0">Covariance Matrix Adaptation Evolution Strategy (CMA-ES)</data>
  <data key="d1">Tools</data>
  <data key="d2">An optimization algorithm employed in black-box tuning to find optimal prompts in non-convex, gradient-inaccessible scenarios.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Clip-Tuning">
  <data key="d0">Clip-Tuning</data>
  <data key="d1">Tools</data>
  <data key="d2">A method that employs deterministic clipping of model instances to optimize prompts, applicable when direct gradient access is unavailable.&lt;SEP&gt;A method that uses deterministic clipping of model instances to optimize prompts, applicable when direct gradient access is unavailable.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Derivative-Free Prompt Search">
  <data key="d0">Derivative-Free Prompt Search</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approaches that optimize prompts without relying on gradients, suitable for black-box models with restricted access, showing preliminary success.&lt;SEP&gt;Approaches that optimize prompts without relying on gradients, suitable for models with restricted access, showing preliminary success.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Fine-tuning for Domain Specialization">
  <data key="d0">Model Fine-tuning for Domain Specialization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Techniques to adapt large language models to specific domains or tasks by modifying or adding parameters, enhancing performance in targeted areas.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Task-oriented Fine-tuning">
  <data key="d0">Task-oriented Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A methodology involving updating LLMs' parameters on specific high-quality datasets to improve performance on targeted tasks, balancing knowledge retention and adaptation.&lt;SEP&gt;A strategy that involves directly updating the model's parameters to better align with specific tasks, often requiring extensive modifications and computational resources.&lt;SEP&gt;A strategy that involves updating the model's parameters directly to better align with specific tasks, often requiring extensive modifications and computational resources.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-specific Knowledge">
  <data key="d0">Domain-specific Knowledge</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Knowledge tailored to particular fields or areas that can be incorporated into LLMs through fine-tuning to improve domain relevance and accuracy.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapters">
  <data key="d0">Adapters</data>
  <data key="d1">Tools</data>
  <data key="d2">Adapters are modules inserted into pre-trained language models (PLMs) to enable domain adaptation and specialization without retraining the entire model.&lt;SEP&gt;Modular components inserted into pre-trained models that facilitate efficient domain-specific fine-tuning without altering the entire model.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5&lt;SEP&gt;chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter-efficient Fine-tuning">
  <data key="d0">Parameter-efficient Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques that enable domain adaptation or task specialization with minimal additional parameters, such as adapters.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Decision Boundary Regularization">
  <data key="d0">Decision Boundary Regularization</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A concept in adversarial learning frameworks like OPTIMA that aims to make the model's decision boundary smoother around data regions, improving domain transferability.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adversarial Learning">
  <data key="d0">Adversarial Learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A training paradigm where models learn to be robust against data perturbations, used in domain adaptation and regularization techniques like OPTIMA.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Gradient-based Optimization">
  <data key="d0">Gradient-based Optimization</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Methods that rely on gradients for optimizing prompts or model parameters, often restricted in black-box scenarios.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Derivative-free Optimization">
  <data key="d0">Derivative-free Optimization</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Methods that optimize prompts without gradient information, suitable for models with limited access.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Search Space">
  <data key="d0">Search Space</data>
  <data key="d1">Variables</data>
  <data key="d2">The set of all possible prompts or parameters that can be optimized during tuning processes.</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="parameters">
  <data key="d0">parameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters refer to the adjustable elements within language models and adapters that are fine-tuned during training to optimize performance.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="adapters">
  <data key="d0">adapters</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Adapters are trainable modules inserted between layers of pre-trained language models, designed to enable efficient domain adaptation by keeping original model parameters frozen while learning domain-specific information.&lt;SEP&gt;Modules inserted into pre-trained language models to enable efficient fine-tuning and domain adaptation by learning domain-specific parameters while keeping the original model frozen.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="parameter-efficient fine-tuning">
  <data key="d0">parameter-efficient fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Parameter-efficient fine-tuning refers to strategies that optimize model performance with minimal additional parameters, often involving adapters, to adapt large language models to specific tasks or domains.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="unsupervised domain adaptation">
  <data key="d0">unsupervised domain adaptation</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Unsupervised domain adaptation is a training approach that adapts models to new domains without labeled data, often using techniques like adapters to learn domain-invariant representations.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="domain-invariant representations">
  <data key="d0">domain-invariant representations</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Features or representations learned by models that are effective across multiple domains, facilitating transfer and generalization.&lt;SEP&gt;Representations learned by models that are effective across multiple domains, enabling better generalization without domain-specific tuning.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="AdapterFusion">
  <data key="d0">AdapterFusion</data>
  <data key="d1">Methodologies</data>
  <data key="d2">AdapterFusion combines multiple adapters trained on different tasks using a fusion layer to improve performance.&lt;SEP&gt;AdapterFusion is a framework that combines multiple adapters, typically via weighted averaging, to enhance domain adaptation and transfer learning capabilities.&lt;SEP&gt;AdapterFusion is a technique for non-destructive task composition in transfer learning, allowing models to adapt to multiple tasks efficiently.&lt;SEP&gt;AdapterFusion is a transfer learning technique that combines multiple adapters for non-destructive task adaptation in transformers.&lt;SEP&gt;AdapterFusion trains multiple adapters on different tasks and combines their embeddings through a fusion layer to improve multi-task performance.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-bc782afdd6c18f4e206e464038047556&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LLaMA-adapter">
  <data key="d0">LLaMA-adapter</data>
  <data key="d1">Tools</data>
  <data key="d2">An adapter architecture tailored for LLaMA models, enabling efficient domain adaptation with self-instruct demonstrations."|&lt;"tool&lt;SEP&gt;LLaMA-adapter is a specific adapter architecture designed for efficient adaptation on large language models like LLaMA, incorporating self-instruct demonstrations and zero-init attention mechanisms.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="neural adapters">
  <data key="d0">neural adapters</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Neural adapters are a class of adapter modules with neural network architectures, used to facilitate domain adaptation in large language models.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="low-rank adapters">
  <data key="d0">low-rank adapters</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Low-rank adapters are a type of adapter that employs low-rank matrix approximations to reduce parameters and improve efficiency in model adaptation.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="invertible adapters">
  <data key="d0">invertible adapters</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Invertible adapters are a type of neural adapter that can be inverted, inspired by autoencoders, allowing for reversible transformations within the adaptation process.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="hypercomplex multiplication layers">
  <data key="d0">hypercomplex multiplication layers</data>
  <data key="d1">Tools</data>
  <data key="d2">Hypercomplex multiplication layers are parameterized layers used in certain adapters like Compacters to improve parameter efficiency by learning sums of Kronecker products.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="SparseAdapter">
  <data key="d0">SparseAdapter</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An approach that introduces sparse, low-rank adapters into neural networks to reduce the number of trainable parameters while maintaining performance.&lt;SEP&gt;SparseAdapter is a technique that prunes parameters at initialization to reduce the number of training parameters in neural adapters, enhancing efficiency.&lt;SEP&gt;SparseAdapter is a technique that reduces training parameters by pruning adapters at initialization, applicable across neural adapters.&lt;SEP&gt;SparseAdapter is a technique that reduces training parameters by pruning adapters at initialization, making it applicable to neural adapters broadly.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71&lt;SEP&gt;chunk-bc782afdd6c18f4e206e464038047556&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="multi-head attention">
  <data key="d0">multi-head attention</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Multi-head attention is a core component of transformer architectures, and adapters are often inserted after these layers to facilitate domain adaptation.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="transformer">
  <data key="d0">transformer</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Transformers are a neural network architecture that forms the backbone of large language models, with adapters inserted within their layers for efficient fine-tuning.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="simple parameters">
  <data key="d0">simple parameters</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A minimal set of parameters used to describe or configure models, emphasizing simplicity and efficiency.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="original language models">
  <data key="d0">original language models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Language models designed to process and generate human language, serving as the foundational models for various NLP tasks.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="sequential training">
  <data key="d0">sequential training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A training approach where models are trained on data in sequence, allowing models to adapt incrementally to specific domains or tasks.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="parameter sharing">
  <data key="d0">parameter sharing</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The practice of using the same parameters across different parts of a model or across models to promote efficiency and reduce redundancy.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="frozen parameters">
  <data key="d0">frozen parameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters within a model that are kept unchanged during training or fine-tuning to preserve learned representations and reduce training complexity.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="task performance metric 𝜙">
  <data key="d0">task performance metric 𝜙</data>
  <data key="d1">Variables</data>
  <data key="d2">A quantitative measure used to evaluate the performance of a model on a specific task, such as accuracy or F1 score.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="domain-specific task performance 𝜙𝐷">
  <data key="d0">domain-specific task performance 𝜙𝐷</data>
  <data key="d1">Variables</data>
  <data key="d2">Performance metric evaluated on data within a specific domain, indicating how well the model adapts to domain-specific tasks.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="cross-lingual learning">
  <data key="d0">cross-lingual learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A paradigm where models are trained to perform across multiple languages, enabling transfer of knowledge between languages.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="multi-task learning">
  <data key="d0">multi-task learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A learning approach where models are trained on multiple tasks simultaneously to improve generalization and transfer learning.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="unsupervised learning">
  <data key="d0">unsupervised learning</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A training paradigm where models learn from unlabeled data, often used in domain adaptation and language modeling.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="domain adaptation">
  <data key="d0">domain adaptation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Techniques used to adapt models trained on one domain to perform well on a different, possibly unseen, domain.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="two-step training strategy">
  <data key="d0">two-step training strategy</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process involving an initial phase of domain-fusion training followed by task-specific fine-tuning to improve domain adaptation.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="domain-fusion training">
  <data key="d0">domain-fusion training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An initial training phase where models learn to combine multiple domain data, often using MLM loss on a mixed corpus.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="task fine-tuning">
  <data key="d0">task fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A subsequent training phase where models are fine-tuned on specific task data within a domain to improve task performance.</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="UDApter">
  <data key="d0">UDApter</data>
  <data key="d1">Tools</data>
  <data key="d2">A framework for unsupervised domain adaptation using adapters, involving separate domain and task adapter modules."|&lt;"tool&lt;SEP&gt;UDApter is an adapter-based method for efficient domain adaptation in language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79&lt;SEP&gt;chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="domain adapter">
  <data key="d0">domain adapter</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A module within UDApter that learns domain-invariant representations to facilitate domain adaptation."|&lt;"object</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="task adapter">
  <data key="d0">task adapter</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A module within UDApter that is trained on task-specific data, often frozen during domain adaptation to preserve task performance."|&lt;"object</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="AdapterSoup">
  <data key="d0">AdapterSoup</data>
  <data key="d1">Tools</data>
  <data key="d2">An approach that improves adaptation efficiency by averaging weights of domain adapters during testing."|&lt;"tool</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="self-instruct demonstrations">
  <data key="d0">self-instruct demonstrations</data>
  <data key="d1">Tools</data>
  <data key="d2">Data or instructions used to guide models in training or adaptation processes, especially in large language models."|&lt;"tool</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="zero-init attention mechanism">
  <data key="d0">zero-init attention mechanism</data>
  <data key="d1">Tools</data>
  <data key="d2">An attention mechanism initialized with zeros to facilitate stable training and adaptation in large language models."|&lt;"tool</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LLaMA">
  <data key="d0">LLaMA</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large language model architecture designed for efficient adaptation and instruction-following tasks."|&lt;"object</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="multi-modal reasoning">
  <data key="d0">multi-modal reasoning</data>
  <data key="d1">Variables</data>
  <data key="d2">The ability of models to process and reason across multiple modalities such as text, images, and audio."|&lt;"variable</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="parameter efficiency">
  <data key="d0">parameter efficiency</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Design goal of creating models or modules that achieve high performance with minimal parameters, often through techniques like adapters or low-rank layers."|&lt;"concept</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="adaptive modules">
  <data key="d0">adaptive modules</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Modules like adapters, hypercomplex layers, and invertible adapters designed to adapt models to various tasks or domains."|&lt;"object</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="training parameters">
  <data key="d0">training parameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters that are adjusted during training to optimize model performance."|&lt;"variable</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="model pruning">
  <data key="d0">model pruning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques to reduce the number of parameters in a model by removing less important weights, improving efficiency."|&lt;"method</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="parameterized hypercomplex multiplication layers">
  <data key="d0">parameterized hypercomplex multiplication layers</data>
  <data key="d1">Tools</data>
  <data key="d2">Layers that learn sums of Kronecker products to improve parameter efficiency in adapters like Compacters."|&lt;"tool</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="autoencoder">
  <data key="d0">autoencoder</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A neural network architecture used as inspiration for invertible adapters, capable of learning compressed representations."|&lt;"object</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="transformer architecture">
  <data key="d0">transformer architecture</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The neural network architecture underlying models like GPT, BERT, and LLaMA, featuring attention mechanisms and layers where adapters are inserted."|&lt;"object</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kronecker Products">
  <data key="d0">Kronecker Products</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Kronecker products are mathematical operations used to construct parameter-efficient layers by representing complex matrices as sums of Kronecker products.&lt;SEP&gt;Kronecker products are mathematical operations used to efficiently learn sums of products, facilitating parameter efficiency in neural network layers.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="K-adapters">
  <data key="d0">K-adapters</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">K-adapters are adapters trained on different knowledge domains that are injected into language models via concatenation, enabling multi-domain knowledge integration.&lt;SEP&gt;K-adapters are methods that train multiple adapters on various knowledge domains and inject the learned knowledge into language models via concatenation.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ladder Side-tuning">
  <data key="d0">Ladder Side-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Ladder side-tuning adds small modules connected via shortcuts to language models, aiming to reduce memory usage during training while maintaining performance.&lt;SEP&gt;Ladder side-tuning adds small modules connected via shortcuts to the language model, reducing memory requirements during training.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Low-rank Adaptation (LoRA)">
  <data key="d0">Low-rank Adaptation (LoRA)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">LoRA introduces learnable low-rank matrices into language models, reducing the number of trained parameters while preserving inference speed.&lt;SEP&gt;LoRA is a low-rank adaptation technique that introduces learnable SVD blocks into language models, significantly reducing parameters and inference latency.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="DyLora">
  <data key="d0">DyLora</data>
  <data key="d1">Methodologies</data>
  <data key="d2">DyLora addresses fixed block size and rank search issues in LoRA using dynamic search methods to optimize low-rank modules.&lt;SEP&gt;DyLora enhances LoRA by dynamically searching for optimal ranks and block sizes, addressing fixed block size and rank limitations.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kronecker Adapter (KronA)">
  <data key="d0">Kronecker Adapter (KronA)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">KronA replaces SVD modules with Kronecker product modules of smaller matrices to enhance representation power in low-rank adapters.&lt;SEP&gt;KronA replaces the SVD modules in low-rank adapters with Kronecker product modules of smaller matrices to improve representation power.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="UniPELT">
  <data key="d0">UniPELT</data>
  <data key="d1">Methodologies</data>
  <data key="d2">UniPELT activates different adapter combinations via a gating mechanism to adapt to current data or task setups.&lt;SEP&gt;UniPELT activates different combinations of adapters via a gating mechanism, allowing flexible adaptation to current data or task setups.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Serial Adapter, LoRA, Prefix-tuning, Bitfit">
  <data key="d0">Serial Adapter, LoRA, Prefix-tuning, Bitfit</data>
  <data key="d1">Tools</data>
  <data key="d2">These are various adapter architectures used in modular fine-tuning of language models.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="AdaMix">
  <data key="d0">AdaMix</data>
  <data key="d1">Methodologies</data>
  <data key="d2">AdaMix stacks multiple adapters and employs stochastic routing to select among them, reducing computational costs.&lt;SEP&gt;AdaMix stacks multiple adapters of the same type and uses stochastic routing to reduce computational costs.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Polytropon">
  <data key="d0">Polytropon</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Polytropon jointly learns an inventory of adapters and a routing function for multi-task learning, enabling shared adaptation across tasks.&lt;SEP&gt;Polytropon jointly learns an inventory of adapters and a routing function to enable multi-task sharing across different tasks.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="AdapterHub">
  <data key="d0">AdapterHub</data>
  <data key="d1">Tools</data>
  <data key="d2">AdapterHub is a comprehensive library that integrates mainstream adapters for language models, supporting various architectures.&lt;SEP&gt;AdapterHub is a library that provides a collection of pre-trained adapters for various language models, supporting easy fine-tuning.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LLM-adapters">
  <data key="d0">LLM-adapters</data>
  <data key="d1">Tools</data>
  <data key="d2">LLM-adapters framework includes open-access large language models and multiple adapter types, supporting extensibility and domain-specific fine-tuning.&lt;SEP&gt;LLM-adapters framework supports large language models like LLaMA, GPT-J, and OPT, integrating multiple adapter types for domain-specific tuning.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fully-Connected Layer">
  <data key="d0">Fully-Connected Layer</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A fully-connected layer is a neural network component where each input neuron is connected to every output neuron, serving as a fundamental building block in deep learning models.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter Efficiency">
  <data key="d0">Parameter Efficiency</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Parameter efficiency refers to designing neural network components to achieve high performance with fewer parameters, reducing computational and memory costs.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Network Pruning">
  <data key="d0">Network Pruning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Network pruning involves removing unnecessary weights or neurons from neural networks at initialization or during training to reduce complexity and resource usage.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Serial Adapter">
  <data key="d0">Serial Adapter</data>
  <data key="d1">Tools</data>
  <data key="d2">Serial adapters are a type of adapter architecture that processes data sequentially, used in modular fine-tuning.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LoRA">
  <data key="d0">LoRA</data>
  <data key="d1">Tools</data>
  <data key="d2">LoRA is an adapter method that introduces low-rank matrices into models for parameter-efficient fine-tuning.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bitfit">
  <data key="d0">Bitfit</data>
  <data key="d1">Tools</data>
  <data key="d2">Bitfit fine-tunes only bias terms in language models, enabling lightweight adaptation.</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Backpropagation">
  <data key="d0">Backpropagation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Backpropagation is a fundamental algorithm used to train neural networks by propagating errors backward through the network to update weights.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stability and Universality">
  <data key="d0">Stability and Universality</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Theories or models concerning the consistent performance of adapters across different architectures, hyperparameters, and tasks, highlighting challenges in generalization.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Computational Resources">
  <data key="d0">Computational Resources</data>
  <data key="d1">Variables</data>
  <data key="d2">High-performance hardware requirements for fine-tuning large models limit accessibility for smaller organizations and individual researchers.&lt;SEP&gt;Resources such as memory and processing power required for training and deploying adapters and LLMs, influencing scalability and efficiency.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b&lt;SEP&gt;chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Training Memory">
  <data key="d0">Training Memory</data>
  <data key="d1">Variables</data>
  <data key="d2">Memory consumption during model training, which can be optimized through architectural innovations or fine-tuning strategies to reduce costs.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Reinforcement Learning from Human Feedback (RLHF)">
  <data key="d0">Reinforcement Learning from Human Feedback (RLHF)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to align LLM outputs with human preferences by iterative feedback, ranking, reward modeling, and policy updates.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot Performance">
  <data key="d0">Zero-shot Performance</data>
  <data key="d1">Results</data>
  <data key="d2">The ability of LLMs to perform tasks without explicit training on them, improved significantly through instruction tuning and RLHF.</data>
  <data key="d3">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Reward Model">
  <data key="d0">Reward Model</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A reward model assigns scores to content based on rankings, capturing evaluator preferences, and is used to guide the optimization of language models.&lt;SEP&gt;A reward model assigns scores to content based on rankings, capturing evaluator preferences, and is used to optimize model behavior.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Policy">
  <data key="d0">Model Policy</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The model policy is the strategy or set of rules used to update and guide the behavior of the language model, often optimized via reinforcement learning.&lt;SEP&gt;The model policy is updated using reinforcement learning techniques to maximize expected reward, fine-tuning the model to better align with human preferences.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Reinforcement Learning">
  <data key="d0">Reinforcement Learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A machine learning paradigm where models learn to make decisions by receiving rewards or penalties, used here to fine-tune language models.&lt;SEP&gt;Reinforcement learning techniques are used to update the model policy by maximizing reward signals, enabling models to learn from feedback.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Content Generation Process">
  <data key="d0">Content Generation Process</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The process involves generating content, ranking it, applying reward modeling, and optimizing policies iteratively to improve model outputs.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Human Feedback">
  <data key="d0">Human Feedback</data>
  <data key="d1">Variables</data>
  <data key="d2">Feedback provided by humans used as a variable to improve model outputs through reinforcement learning.&lt;SEP&gt;Human feedback is used as a variable to guide the reinforcement learning process, helping the model align with human preferences.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="High-Confidence Rationale-Augmented Answers">
  <data key="d0">High-Confidence Rationale-Augmented Answers</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Huang et al. proposed a method using a pre-trained LLM to generate high-confidence, rationale-augmented answers for unlabeled questions, improving reasoning without ground truth labels.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Continual Learning via Rehearsal">
  <data key="d0">Continual Learning via Rehearsal</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A method where models are trained on new data while rehearsing previous data to prevent forgetting.&lt;SEP&gt;Scialom et al. introduced an approach to expand LLM knowledge and abilities without forgetting previous skills by fine-tuning across tasks and using rehearsal techniques to mitigate catastrophic forgetting.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Partial Knowledge Update">
  <data key="d0">Partial Knowledge Update</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Partial knowledge update involves editing or updating specific parts of an LLM's parameters to incorporate new knowledge without retraining the entire model.&lt;SEP&gt;Updating only specific parts of an LLM's parameters to incorporate new knowledge efficiently, avoiding full retraining.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter-Efficient Knowledge Update">
  <data key="d0">Parameter-Efficient Knowledge Update</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques such as knowledge editing, gradient masking, and knowledge distillation aim to update LLMs efficiently by modifying only a small subset of parameters.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Editing">
  <data key="d0">Knowledge Editing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Knowledge editing locates and updates specific parameters or internal mechanisms in an LLM to replace outdated information or add domain-specific knowledge, often using hyper-networks or neuron activation analysis.&lt;SEP&gt;Techniques to locate and modify specific factual knowledge within an LLM's parameters or internal mechanisms.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Gradient Masking">
  <data key="d0">Gradient Masking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to selectively mask gradients during training to update only relevant parts of the model, aiding efficient fine-tuning.&lt;SEP&gt;Gradient Masking is a technique used to selectively prevent certain model parameters from updating during training, often to preserve pre-trained knowledge or improve efficiency.&lt;SEP&gt;Gradient Masking is a technique used to selectively prevent certain parameters from updating during training, often to preserve pre-trained knowledge or reduce overfitting.&lt;SEP&gt;Gradient masking involves selectively modifying gradients during back-propagation to update only relevant parts of the model, reducing computational costs and mitigating issues like catastrophic forgetting.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc&lt;SEP&gt;chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Content Generation">
  <data key="d0">Content Generation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The process of producing text outputs from language models, which can be evaluated and optimized.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ranking">
  <data key="d0">Ranking</data>
  <data key="d1">Methods/Methodologies</data>
  <data key="d2">A process of ordering generated content based on certain criteria, often guided by a reward model.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Expected Reward">
  <data key="d0">Expected Reward</data>
  <data key="d1">Variables</data>
  <data key="d2">The anticipated reward signal used to optimize the model policy during training.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Explicit Instruction-based Knowledge Update">
  <data key="d0">Explicit Instruction-based Knowledge Update</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A method where models are updated based on clear, human-provided instructions, effective for simple tasks but limited in scope.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Divergence from Evaluation Sets">
  <data key="d0">Divergence from Evaluation Sets</data>
  <data key="d1">Limitations</data>
  <data key="d2">A challenge where models perform well on training instructions but poorly on tasks diverging from the training data.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="General Reasoning">
  <data key="d0">General Reasoning</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The ability of models to perform broad, complex reasoning tasks, often enhanced by specific knowledge update techniques.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="High-confidence Rationale-augmented Answers">
  <data key="d0">High-confidence Rationale-augmented Answers</data>
  <data key="d1">Tools</data>
  <data key="d2">Generated by pre-trained LLMs to improve reasoning by providing explanations or justifications without ground-truth labels.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scialom et al.'s Method">
  <data key="d0">Scialom et al.'s Method</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique to expand LLMs' knowledge and abilities across tasks without forgetting previous skills, using continual learning and rehearsal.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter Linkage">
  <data key="d0">Parameter Linkage</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameters of the model that are linked to specific knowledge or functions, targeted during partial updates.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hyper-network">
  <data key="d0">Hyper-network</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural network trained to update LLM parameters with minimal fine-tuning, avoiding performance degradation.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neuron Activation Analysis">
  <data key="d0">Neuron Activation Analysis</data>
  <data key="d1">Tools</data>
  <data key="d2">Methods to identify influential neurons responsible for specific predictions, used for factual knowledge updates.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Retrieval-based Methods">
  <data key="d0">Retrieval-based Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques that store and reason over explicit knowledge edits to update LLMs without retraining.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Factual Prediction">
  <data key="d0">Factual Prediction</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The process where models predict factual information, which can be updated through editing or training.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Localizing Internal Mechanisms">
  <data key="d0">Localizing Internal Mechanisms</data>
  <data key="d1">Tools</data>
  <data key="d2">Methods to understand and modify specific internal components of LLMs for knowledge editing.</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Update Process">
  <data key="d0">Model Update Process</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The Model Update Process involves determining which parts of a machine learning model will be modified or masked during training to improve efficiency and task relevance.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameters Masking Criteria">
  <data key="d0">Parameters Masking Criteria</data>
  <data key="d1">Variables</data>
  <data key="d2">Criteria such as relevance, importance, or contribution to loss are used to decide which model parameters to mask during the update process.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fine-tuning Large Language Models (LLMs)">
  <data key="d0">Fine-tuning Large Language Models (LLMs)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Fine-tuning LLMs involves updating model weights with domain-specific data, often requiring substantial computational resources and strategies like regularization and parameter selection.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Regularization Techniques">
  <data key="d0">Regularization Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Regularization techniques help prevent overfitting during the fine-tuning of language models by constraining the learning process.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Child-Tuning">
  <data key="d0">Child-Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Child-Tuning is a method that uses downstream task data to identify and freeze non-task-related parameters in a sub-network, optimizing the fine-tuning process for specific tasks.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dynamic Parameter Selection">
  <data key="d0">Dynamic Parameter Selection</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique that adaptively selects promising sub-networks based on gradient information to improve domain-specific fine-tuning of LLMs.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-Specific Knowledge Distillation">
  <data key="d0">Domain-Specific Knowledge Distillation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">This approach distills specialized knowledge from large models into smaller networks, enhancing domain-specific performance and resource utilization.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="BERT-like Encoders">
  <data key="d0">BERT-like Encoders</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">BERT-like encoders are transformer-based models used in knowledge distillation to retain performance while reducing model size for tasks like click-through-rate prediction.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Cross-Architecture Distillation">
  <data key="d0">Cross-Architecture Distillation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process where knowledge is transferred across different model architectures to improve efficiency and performance in specific tasks.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fine-tuning Challenges">
  <data key="d0">Fine-tuning Challenges</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Key questions include how to ensure compliance with regulations, reduce computational costs, and adapt models to rapidly changing domains.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Regulatory Compliance">
  <data key="d0">Regulatory Compliance</data>
  <data key="d1">Limitations</data>
  <data key="d2">Ensuring that fine-tuned LLMs adhere to data protection laws and industry standards poses ongoing challenges.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Applications of Domain-Specific LLMs">
  <data key="d0">Applications of Domain-Specific LLMs</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Domain-specific LLMs are applied in social sciences, natural sciences, and formal sciences for tasks like information extraction, text generation, data prediction, conversational agents, and code analysis.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Information Extraction">
  <data key="d0">Information Extraction</data>
  <data key="d1">Results</data>
  <data key="d2">LLMs can identify entities, relationships, and events within domain-specific texts, such as genes in biomedical literature or legal clauses in contracts.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Text Generation and Summarization">
  <data key="d0">Text Generation and Summarization</data>
  <data key="d1">Results</data>
  <data key="d2">LLMs generate high-quality, domain-specific content and create summaries of complex texts.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Data-Driven Predictions">
  <data key="d0">Data-Driven Predictions</data>
  <data key="d1">Results</data>
  <data key="d2">LLMs analyze domain data to forecast trends and provide recommendations, such as predicting financial markets or medical treatments.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Conversational Agents and Expert Systems">
  <data key="d0">Conversational Agents and Expert Systems</data>
  <data key="d1">Results</data>
  <data key="d2">LLMs are integrated into chatbots and virtual assistants to provide domain-specific guidance in fields like healthcare, law, and education.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Automated Code Generation">
  <data key="d0">Automated Code Generation</data>
  <data key="d1">Results</data>
  <data key="d2">In software engineering, LLMs generate, analyze, and improve code based on natural language descriptions.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Biomedicine">
  <data key="d0">Biomedicine</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Biomedicine involves the application of language models to biological research, disease understanding, drug discovery, and clinical healthcare support.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Protein Structure Prediction">
  <data key="d0">Protein Structure Prediction</data>
  <data key="d1">Results</data>
  <data key="d2">LLMs assist in predicting protein structures and interactions, critical for cellular biology and drug development.</data>
  <data key="d3">chunk-bf6a553300b045fc9b2a5d7c34c274bc</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Useful in the field of biology">
  <data key="d0">Useful in the field of biology</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The application of large language models (LLMs) spans from fundamental biomedical research to clinical healthcare support, involving analysis, prediction, and assistance in biological functions, disease mechanisms, drug discovery, protein structure prediction, medical record processing, and medical image analysis.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fundamental biomedical research">
  <data key="d0">Fundamental biomedical research</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research activities focused on basic biological processes, often involving data analysis and hypothesis testing to understand fundamental life sciences.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Clinical healthcare support">
  <data key="d0">Clinical healthcare support</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Use of LLMs for medical record analysis, diagnosis, personalized treatment, and medical image analysis to improve healthcare outcomes.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Genomic and Proteomic Data">
  <data key="d0">Genomic and Proteomic Data</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Biological datasets containing genetic and protein information used to train and inform LLMs for biological analysis.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Protein Structures and Interactions">
  <data key="d0">Protein Structures and Interactions</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Biological entities critical for understanding cellular functions, targeted in prediction tasks by LLMs.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Medical Records">
  <data key="d0">Medical Records</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Data comprising patient health information used by LLMs for natural language processing to support diagnosis and treatment.&lt;SEP&gt;Data comprising patient health information used by LLMs for natural language processing, pattern recognition, and diagnosis.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Medical Image Analysis">
  <data key="d0">Medical Image Analysis</data>
  <data key="d1">Tools</data>
  <data key="d2">Application of LLMs in multi-modality learning to identify features in X-rays or MRI scans for medical diagnostics.&lt;SEP&gt;Use of LLMs in multi-modality learning to identify features in X-rays, MRI scans, and other imaging modalities for diagnostic purposes.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Earth Science">
  <data key="d0">Earth Science</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Interdisciplinary field examining interactions between physical and human systems across spatial and temporal scales, involving climate change, land use, disasters, and urbanization.&lt;SEP&gt;Interdisciplinary study of physical and human systems across spatial and temporal scales, involving climate change, land use, natural disasters, and urbanization.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Earth Observation">
  <data key="d0">Earth Observation</data>
  <data key="d1">Tools</data>
  <data key="d2">Methods and datasets involving satellite and remote sensing technologies used to monitor environmental phenomena.&lt;SEP&gt;Remote sensing technologies and datasets, such as satellite imagery, used for environmental monitoring and research.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Spatial Analysis">
  <data key="d0">Spatial Analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for analyzing geographic and environmental data to understand spatial phenomena in Earth science.&lt;SEP&gt;Techniques for analyzing geographic data to understand spatial phenomena in Earth science.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Climate Change">
  <data key="d0">Climate Change</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Environmental and atmospheric phenomena related to global warming and climate variability.&lt;SEP&gt;Environmental and atmospheric phenomena related to global warming, climate variability, and their impacts.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Geographic Information Science">
  <data key="d0">Geographic Information Science</data>
  <data key="d1">Tools</data>
  <data key="d2">Technologies and methods for managing and analyzing spatial data in Earth science research.&lt;SEP&gt;Technologies for managing, analyzing, and visualizing spatial data in Earth science research.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Large Language Models (e.g., ChatGPT)">
  <data key="d0">Large Language Models (e.g., ChatGPT)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">AI models capable of answering questions, generating code, providing knowledge, and assisting in various scientific domains, including Earth science, biology, finance, and law.&lt;SEP&gt;AI models capable of answering questions, processing datasets, generating code, and assisting with knowledge in Earth science, finance, law, HCI, and software engineering.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Question-Answer Systems">
  <data key="d0">Question-Answer Systems</data>
  <data key="d1">Tools</data>
  <data key="d2">Applications of LLMs in Earth science to provide knowledge, data processing, and code generation.&lt;SEP&gt;Applications of LLMs to provide knowledge, recommend datasets, generate code snippets, and support environmental and scientific inquiries.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Climate Scenario Generation">
  <data key="d0">Climate Scenario Generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Use of LLMs to develop and simulate climate change scenarios for research and policy planning.&lt;SEP&gt;Use of LLMs to develop and simulate climate change scenarios for research, policy, and planning purposes.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Finance and Law">
  <data key="d0">Finance and Law</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Fields requiring specialized understanding of complex terminologies, trends, regulations, and legal language, with LLMs adapted via fine-tuning for domain-specific tasks.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Financial Terminologies, Economic Trends, Regulatory Norms">
  <data key="d0">Financial Terminologies, Economic Trends, Regulatory Norms</data>
  <data key="d1">Variables</data>
  <data key="d2">Key concepts and data that LLMs must understand to generate accurate financial analyses and reports.&lt;SEP&gt;Key elements that LLMs must comprehend to generate accurate financial content and analyses.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Legal Language, Laws, Court Rulings">
  <data key="d0">Legal Language, Laws, Court Rulings</data>
  <data key="d1">Variables</data>
  <data key="d2">Complex legal concepts and documents that require precise understanding for legal document generation and analysis.&lt;SEP&gt;Complex legal concepts that LLMs need to understand for legal document generation and analysis.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ethical Guardrails">
  <data key="d0">Ethical Guardrails</data>
  <data key="d1">Limitations</data>
  <data key="d2">Constraints implemented to ensure responsible, safe, and ethical deployment of LLMs in high-stakes domains like finance and law.&lt;SEP&gt;Constraints to ensure responsible and accurate use of LLMs in sensitive domains like finance and law.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Human-Computer Interaction (HCI)">
  <data key="d0">Human-Computer Interaction (HCI)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Field focused on designing and improving the interfaces and interactions between humans and computers, with LLMs aiding in understanding user inputs and improving usability.&lt;SEP&gt;Field focused on designing effective interfaces and interactions between humans and computers, with LLMs improving natural language understanding and usability.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Software Engineering">
  <data key="d0">Software Engineering</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Discipline involving software development, code management, bug detection, and documentation, with LLMs assisting in code generation and review tasks.&lt;SEP&gt;Discipline involving the development, maintenance, and documentation of software, where LLMs assist in code generation, bug detection, and review.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Code Generation, Bug Detection, Documentation">
  <data key="d0">Code Generation, Bug Detection, Documentation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Tasks in software engineering that benefit from LLMs trained on large codebases and related data.&lt;SEP&gt;Tasks in software engineering that benefit from trained LLMs on large codebases, issue trackers, and documentation.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Biomedical Research">
  <data key="d0">Biomedical Research</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Fundamental biological research activities aimed at understanding biological functions, disease mechanisms, and drug discovery, often involving data analysis and hypothesis testing.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Clinical Healthcare Support">
  <data key="d0">Clinical Healthcare Support</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Application of LLMs in analyzing medical records, assisting diagnosis, providing personalized treatments, and supporting medical image analysis to improve healthcare outcomes.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Finance">
  <data key="d0">Finance</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Field involving the study of markets, economic trends, financial data, and risk assessments, requiring specialized models and datasets.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Law">
  <data key="d0">Law</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Legal field focusing on understanding laws, legal language, court rulings, and regulations, with models fine-tuned for legal language processing.</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Balancing General and Domain Knowledge">
  <data key="d0">Balancing General and Domain Knowledge</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This concept involves managing the trade-off between a language model's general knowledge and its domain-specific expertise to ensure appropriate responses across contexts.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Explainability and Trust">
  <data key="d0">Explainability and Trust</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This concept addresses the importance of transparency in model decision-making processes to build user trust, especially in high-stakes domains.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapting to Domain Evolution">
  <data key="d0">Adapting to Domain Evolution</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This concept involves updating and refining models to stay relevant amid ongoing changes and new terminologies within specific domains.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Black-box, Grey-box, and White-box Methods">
  <data key="d0">Black-box, Grey-box, and White-box Methods</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">These are different approaches for model interpretability and fine-tuning, ranging from opaque (black-box) to fully transparent (white-box), used to optimize domain specialization techniques.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hybrid Approaches">
  <data key="d0">Hybrid Approaches</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Combining multiple domain adaptation methods, such as black-box, grey-box, and white-box techniques, to balance resource use and performance in domain modeling.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Meta-Learning or AutoML Techniques">
  <data key="d0">Meta-Learning or AutoML Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Automated strategies for selecting optimal domain adaptation methods, data, and model layers, reducing resource requirements and improving effectiveness.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Incorporating More Explicit World Knowledge">
  <data key="d0">Incorporating More Explicit World Knowledge</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Utilizing structured knowledge sources like knowledge graphs and ontologies to enhance model understanding and reasoning within specific domains.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Human-in-the-loop Learning">
  <data key="d0">Human-in-the-loop Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An interactive training process where human feedback guides model updates, ensuring relevance and correctness in domain-specific contexts.&lt;SEP&gt;Continuous interaction with human experts to guide, correct, and update models based on real-world feedback, improving adaptability and accuracy.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Active Learning">
  <data key="d0">Active Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process where models actively query users or sources for information on uncertain or unfamiliar concepts, improving learning efficiency.&lt;SEP&gt;A technique where models query for additional information or clarification on unfamiliar or low-confidence domain concepts, enhancing learning efficiency.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Future Techniques">
  <data key="d0">Future Techniques</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring innovative methods such as hybrid approaches, meta-learning, structured knowledge integration, human-in-the-loop, and active learning to advance domain specialization in LLMs.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Challenges of Domain Specialization">
  <data key="d0">Challenges of Domain Specialization</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Analyses the current difficulties in scaling, adapting, and maintaining effective domain-specific large language models, including resource constraints and evolving knowledge.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Implications for Future Research">
  <data key="d0">Implications for Future Research</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Guides the development of more adaptable, explainable, and resource-efficient domain-specific LLMs through emerging techniques and methodologies.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Explainability">
  <data key="d0">Model Explainability</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The degree to which a model's decision-making process can be understood and interpreted by humans, essential for building trust in high-stakes applications.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Trade-off between Explainability and Complexity">
  <data key="d0">Trade-off between Explainability and Complexity</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">This theory describes the inherent tension between making models more transparent and maintaining high performance, often requiring balancing these aspects.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Evolution">
  <data key="d0">Domain Evolution</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ongoing process of change in domain-specific knowledge, terminology, and trends over time, necessitating continuous model adaptation.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Adaptation">
  <data key="d0">Model Adaptation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques and processes used to update models in response to domain evolution, ensuring continued relevance and accuracy.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scaling Domain-Specific Models">
  <data key="d0">Scaling Domain-Specific Models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Strategies and techniques aimed at efficiently expanding model coverage across multiple or large domains, including resource management and data acquisition.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Black-box Methods">
  <data key="d0">Black-box Methods</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Approaches where the internal workings of models are opaque, often used in initial or complex modeling, with limited interpretability.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Grey-box Methods">
  <data key="d0">Grey-box Methods</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Hybrid approaches that combine elements of black-box and white-box methods, allowing partial interpretability and refinement.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="White-box Methods">
  <data key="d0">White-box Methods</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Approaches where the internal mechanisms of models are fully transparent and interpretable, facilitating understanding and trust.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hybrid Approach">
  <data key="d0">Hybrid Approach</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Combining multiple modeling techniques, such as black-box, grey-box, and white-box, to optimize performance, interpretability, and resource use.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Meta-Learning">
  <data key="d0">Meta-Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Automated learning strategies that enable models to learn how to learn, optimizing domain adaptation and fine-tuning processes.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="AutoML">
  <data key="d0">AutoML</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Automated Machine Learning methods that streamline the selection of models, hyperparameters, and training strategies for domain-specific tasks.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Graphs">
  <data key="d0">Knowledge Graphs</data>
  <data key="d1">Tools</data>
  <data key="d2">Structured representations of domain knowledge capturing entities and their relationships, used to enhance model understanding and reasoning.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Graphs in LLMs">
  <data key="d0">Knowledge Graphs in LLMs</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Integration of knowledge graphs into language models to improve domain understanding, reasoning, and accuracy.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Resource Constraints">
  <data key="d0">Resource Constraints</data>
  <data key="d1">Limitations</data>
  <data key="d2">Limitations related to computational resources, data availability, and expertise required for scaling domain-specific models effectively.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Relevance">
  <data key="d0">Model Relevance</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The degree to which a model remains accurate and useful within an evolving domain context.</data>
  <data key="d3">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Medical Ontology">
  <data key="d0">Medical Ontology</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A structured framework that defines and categorizes medical concepts, relationships, and terminology to facilitate understanding, interoperability, and data sharing in healthcare.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-Specific Techniques">
  <data key="d0">Domain-Specific Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques tailored for applying large language models (LLMs) to specific knowledge domains, addressing challenges like limited expertise and model complexity.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Elicitation">
  <data key="d0">Knowledge Elicitation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Processes and methods used to extract, gather, and formalize domain-specific knowledge to improve LLM performance in specialized fields.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Black-Box Methods">
  <data key="d0">Black-Box Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approaches that utilize LLMs without exposing or modifying their internal mechanisms, often relying on prompt engineering and inference.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Grey-Box Methods">
  <data key="d0">Grey-Box Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Hybrid approaches that combine some interpretability or partial understanding of LLM internals with external knowledge integration.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="White-Box Methods">
  <data key="d0">White-Box Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques that involve transparent access to LLM internals, enabling direct modification, fine-tuning, or detailed analysis.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Challenges and Limitations">
  <data key="d0">Challenges and Limitations</data>
  <data key="d1">Limitations</data>
  <data key="d2">Current obstacles in domain-specific LLM application, including knowledge gaps, model complexity, and interpretability issues.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Specialization in Large Language Models">
  <data key="d0">Domain Specialization in Large Language Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of tailoring LLMs to perform effectively within specific fields by incorporating domain knowledge and addressing unique challenges.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Future Research Directions">
  <data key="d0">Future Research Directions</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring new techniques, improving knowledge integration, and overcoming current limitations to enhance domain-specific LLM capabilities.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Interdisciplinary Collaboration">
  <data key="d0">Interdisciplinary Collaboration</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Collaborative efforts among domain experts, data scientists, and AI researchers to develop more effective and specialized LLMs for diverse fields.</data>
  <data key="d3">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multi-Head Adapter Routing">
  <data key="d0">Multi-Head Adapter Routing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique for data-efficient fine-tuning of models, involving multiple adapter heads to improve learning efficiency.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Data-Efficient Fine-Tuning">
  <data key="d0">Data-Efficient Fine-Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A process aimed at optimizing model performance with minimal data, often utilizing specialized techniques such as adapter routing.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2211.03831">
  <data key="d0">arXiv preprint arXiv:2211.03831</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A specific research paper detailing the Multi-Head Adapter Routing methodology.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2303.04226">
  <data key="d0">arXiv preprint arXiv:2303.04226</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A comprehensive survey paper covering the history and development of AI-generated content (AIGC), from GANs to ChatGPT.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yihan Cao">
  <data key="d0">Yihan Cao</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher conducting a comprehensive survey of AI-generated content (AIGC), covering history and technological evolution.&lt;SEP&gt;Researcher involved in the survey of AI-generated content, contributing to understanding generative AI evolution.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Siyu Li">
  <data key="d0">Siyu Li</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in analyzing AI-generated content and generative models from GANs to ChatGPT.&lt;SEP&gt;Researcher involved in the survey of AI-generated content, contributing to the overview of generative AI technologies.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yixin Liu">
  <data key="d0">Yixin Liu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to the survey on generative AI history and development.&lt;SEP&gt;Researcher involved in the survey of AI-generated content, focusing on AI history and generative models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhiling Yan">
  <data key="d0">Zhiling Yan</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher focusing on the progression of generative AI technologies, including GANs and ChatGPT.&lt;SEP&gt;Researcher involved in the survey of AI-generated content, analyzing technological progression from GANs to ChatGPT.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yutong Dai">
  <data key="d0">Yutong Dai</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to the comprehensive survey of generative AI models and their history.&lt;SEP&gt;Researcher involved in the survey of generative AI, emphasizing historical context and technological advances.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Philip S Yu">
  <data key="d0">Philip S Yu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing insights into AI-generated content and its applications.&lt;SEP&gt;Researcher providing insights into the applications and impact of AI-generated content.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lichao Sun">
  <data key="d0">Lichao Sun</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to the survey of generative AI evolution and applications.&lt;SEP&gt;Researcher involved in the survey, emphasizing the evolution of generative AI systems.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LEGAL-BERT">
  <data key="d0">LEGAL-BERT</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A domain-specific BERT model trained on legal texts to improve NLP tasks within legal contexts, such as document classification and relation extraction.&lt;SEP&gt;A specialized BERT model trained on legal texts to improve NLP tasks in the legal domain.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shuohuan Wang">
  <data key="d0">Shuohuan Wang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in developing or applying LEGAL-BERT for legal NLP tasks.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yu Sun">
  <data key="d0">Yu Sun</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in legal NLP model development and fine-tuning.&lt;SEP&gt;Researcher working on fine-tuning and deploying legal domain language models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hao Tian">
  <data key="d0">Hao Tian</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to the development of domain-specific language models like LEGAL-BERT.&lt;SEP&gt;Researcher contributing to the development of legal NLP models like LEGAL-BERT.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hua Wu">
  <data key="d0">Hua Wu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in legal NLP research and model adaptation.&lt;SEP&gt;Researcher working on NLP applications in legal domain, including model adaptation and evaluation.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Haifeng Wang">
  <data key="d0">Haifeng Wang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in legal NLP model research and fine-tuning.&lt;SEP&gt;Researcher involved in legal NLP research and model optimization.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Recall and learn">
  <data key="d0">Recall and learn</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A research approach focused on fine-tuning deep pretrained language models with minimal forgetting, aiming to improve continual learning and adaptation.&lt;SEP&gt;A study examining methods for fine-tuning deep pretrained language models with less forgetting, aiming to improve learning efficiency.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="William W. Cohen">
  <data key="d0">William W. Cohen</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in NLP research focusing on improving model training and fine-tuning techniques.&lt;SEP&gt;Researcher involved in NLP research on improving model robustness and continual learning.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Program of Thoughts Prompting">
  <data key="d0">Program of Thoughts Prompting</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A prompting technique that disentangles computation from reasoning, enabling numerical reasoning and complex problem solving in language models.&lt;SEP&gt;An approach to numerical reasoning that disentangles computation from reasoning by prompting language models with structured thought processes.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xiang Chen">
  <data key="d0">Xiang Chen</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher contributing to language model research and ontology integration.&lt;SEP&gt;Researcher developing the Program of Thoughts prompting method for reasoning tasks.&lt;SEP&gt;Researcher developing the Program of Thoughts prompting technique for reasoning tasks.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ningyu Zhang">
  <data key="d0">Ningyu Zhang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in knowledge integration and prompt-tuning for NLP tasks.&lt;SEP&gt;Researcher involved in knowledge-aware prompt-tuning and relation extraction research.&lt;SEP&gt;Researcher working on knowledge-aware prompt-tuning for relation extraction.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xin Xie">
  <data key="d0">Xin Xie</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to NLP techniques that incorporate knowledge for improved relation extraction.&lt;SEP&gt;Researcher contributing to knowledge-aware prompt-tuning and relation extraction techniques.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shumin Deng">
  <data key="d0">Shumin Deng</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher exploring ontology integration in language models.&lt;SEP&gt;Researcher involved in enhancing relation extraction through optimized prompt-tuning.&lt;SEP&gt;Researcher working on optimizing prompt-tuning with knowledge integration.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yunzhi Yao">
  <data key="d0">Yunzhi Yao</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in knowledge-aware NLP models and relation extraction.&lt;SEP&gt;Researcher working on knowledge integration in NLP models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chuanqi Tan">
  <data key="d0">Chuanqi Tan</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in relation extraction and prompt-tuning methodologies.&lt;SEP&gt;Researcher working on relation extraction and prompt-tuning methodologies.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fei Huang">
  <data key="d0">Fei Huang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to knowledge-aware NLP models.&lt;SEP&gt;Researcher involved in knowledge-aware relation extraction models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Luo Si">
  <data key="d0">Luo Si</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in relation extraction and knowledge integration research.&lt;SEP&gt;Researcher working on relation extraction and knowledge integration in NLP.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Huajun Chen">
  <data key="d0">Huajun Chen</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher focusing on language model fine-tuning approaches.&lt;SEP&gt;Researcher involved in knowledge-aware NLP and relation extraction research.&lt;SEP&gt;Researcher working on knowledge-aware NLP models and relation extraction.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Binding Language Models in Symbolic Languages">
  <data key="d0">Binding Language Models in Symbolic Languages</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A framework for integrating language models with symbolic reasoning systems within formal languages to enhance interpretability and reasoning capabilities.&lt;SEP&gt;A theoretical framework for integrating language models with symbolic reasoning systems in formal languages.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tao Yu">
  <data key="d0">Tao Yu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher exploring the binding of language models in symbolic languages for improved reasoning and formalization.&lt;SEP&gt;Researcher exploring the binding of language models within symbolic languages for enhanced reasoning.&lt;SEP&gt;Researcher working on the theoretical aspects of binding language models in symbolic languages.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Noah A. Smith">
  <data key="d0">Noah A. Smith</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in formal reasoning, language model integration, and symbolic reasoning frameworks.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dragomir Radev">
  <data key="d0">Dragomir Radev</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to the development of symbolic and language model integration techniques.&lt;SEP&gt;Researcher working on combining language models with symbolic reasoning for better interpretability.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Aakanksha Chowdhery">
  <data key="d0">Aakanksha Chowdhery</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher developing the pathways framework for large-scale language model scaling.&lt;SEP&gt;Researcher developing the pathways framework for scaling language models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Gaurav Mishra">
  <data key="d0">Gaurav Mishra</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher focusing on model efficiency and scaling techniques.&lt;SEP&gt;Researcher working on model scaling and efficiency.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Deep reinforcement learning from human preferences">
  <data key="d0">Deep reinforcement learning from human preferences</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An experimental approach where reinforcement learning algorithms are trained based on human feedback to align AI behavior with human values.&lt;SEP&gt;An experimental framework where reinforcement learning algorithms are trained using human feedback to align AI behaviors with human values.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Paul F Christiano">
  <data key="d0">Paul F Christiano</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher pioneering reinforcement learning from human preferences for AI alignment.&lt;SEP&gt;Researcher pioneering reinforcement learning guided by human preferences.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jan Leike">
  <data key="d0">Jan Leike</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.&lt;SEP&gt;Researcher involved in human-in-the-loop reinforcement learning research.&lt;SEP&gt;Researcher working on human-in-the-loop reinforcement learning approaches.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Tom Brown">
  <data key="d0">Tom Brown</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to reinforcement learning and AI alignment.&lt;SEP&gt;Researcher involved in reinforcement learning research and AI safety.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Miljan Martic">
  <data key="d0">Miljan Martic</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher exploring reinforcement learning algorithms based on human preferences.&lt;SEP&gt;Researcher working on reinforcement learning methodologies.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shane Legg">
  <data key="d0">Shane Legg</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in AI safety and reinforcement learning.&lt;SEP&gt;Researcher working on AI safety and reinforcement learning from human feedback.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dario Amodei">
  <data key="d0">Dario Amodei</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on AI safety, alignment, and model tuning.&lt;SEP&gt;An author specializing in AI safety, alignment, and model fine-tuning techniques.&lt;SEP&gt;Researcher focusing on AI alignment and reinforcement learning from human feedback.&lt;SEP&gt;Researcher focusing on AI alignment and reinforcement learning guided by human preferences.&lt;SEP&gt;Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-d8b0b9da667ca7eef007d5dabeba89a9&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b&lt;SEP&gt;chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Knowledge Graphs for Healthcare">
  <data key="d0">Knowledge Graphs for Healthcare</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A collection of resources, applications, and research efforts utilizing knowledge graphs to improve healthcare data management and analysis.&lt;SEP&gt;A collection of resources, applications, and research efforts utilizing knowledge graphs to improve healthcare data management, integration, and decision-making.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hejie Cui">
  <data key="d0">Hejie Cui</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher exploring resources and applications of knowledge graphs in healthcare.&lt;SEP&gt;Researcher exploring the resources and applications of knowledge graphs in healthcare.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Li Dong">
  <data key="d0">Li Dong</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher analyzing factual knowledge encoding in transformers.&lt;SEP&gt;Researcher involved in analyzing factual knowledge encoding in transformers.&lt;SEP&gt;Researcher involved in healthcare knowledge graph development.&lt;SEP&gt;Researcher working on knowledge graph construction and applications in healthcare.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yaru Hao">
  <data key="d0">Yaru Hao</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in healthcare knowledge graph development.&lt;SEP&gt;Researcher working on healthcare data integration using knowledge graphs.&lt;SEP&gt;Researcher working on knowledge editing in pretrained models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhifang Sui">
  <data key="d0">Zhifang Sui</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to healthcare knowledge graph resources and applications.&lt;SEP&gt;Researcher contributing to knowledge graph applications in medical data.&lt;SEP&gt;Researcher contributing to knowledge neuron research.&lt;SEP&gt;Researcher involved in knowledge neuron research.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Baobao Chang">
  <data key="d0">Baobao Chang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in healthcare knowledge resource development.&lt;SEP&gt;Researcher working on healthcare knowledge resources and graph-based data integration.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Furu Wei">
  <data key="d0">Furu Wei</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in healthcare data and knowledge graph research.&lt;SEP&gt;Researcher working on knowledge graph applications for healthcare.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Neurons in Pretrained Transformers">
  <data key="d0">Knowledge Neurons in Pretrained Transformers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Research on specific neurons within transformer models that encode factual knowledge, relevant for understanding and editing model knowledge.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Damai Dai">
  <data key="d0">Damai Dai</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher studying how knowledge is stored in transformer neurons and how to manipulate it.&lt;SEP&gt;Researcher studying knowledge neurons in transformers to understand model knowledge representation.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Promptagator">
  <data key="d0">Promptagator</data>
  <data key="d1">Tools</data>
  <data key="d2">A few-shot dense retrieval system that uses prompts and minimal examples to retrieve relevant information efficiently.&lt;SEP&gt;A tool/system designed for few-shot dense retrieval using prompt-based techniques, enabling effective information retrieval with minimal examples.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Few-shot Dense Retrieval">
  <data key="d0">Few-shot Dense Retrieval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A retrieval approach that leverages few examples to improve information retrieval performance in NLP tasks.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ishita Dasgupta">
  <data key="d0">Ishita Dasgupta</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher working on embodied reasoning with language models, integrating language understanding with physical or simulated environments.&lt;SEP&gt;Researcher working on embodied reasoning, integrating language models with physical or simulated environments.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Christine Kaeser-Chen">
  <data key="d0">Christine Kaeser-Chen</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in embodied reasoning and language model collaboration.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kenneth Marino">
  <data key="d0">Kenneth Marino</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher exploring embodied reasoning and language model collaboration.&lt;SEP&gt;Researcher exploring embodied reasoning with language models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Arun Ahuja">
  <data key="d0">Arun Ahuja</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher developing frameworks for embodied reasoning.&lt;SEP&gt;Researcher working on embodied reasoning frameworks.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sheila Babayan">
  <data key="d0">Sheila Babayan</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to embodied reasoning research.&lt;SEP&gt;Researcher involved in embodied reasoning research.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Felix Hill">
  <data key="d0">Felix Hill</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to embodied reasoning and language models.&lt;SEP&gt;Researcher working on embodied reasoning and language models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rob Fergus">
  <data key="d0">Rob Fergus</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in embodied reasoning and language model collaboration.&lt;SEP&gt;Researcher working on embodied reasoning and language models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lucas Caccia">
  <data key="d0">Lucas Caccia</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in developing and applying multi-head adapter routing techniques for data-efficient fine-tuning of neural models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Edoardo Ponti">
  <data key="d0">Edoardo Ponti</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to methods in data-efficient model fine-tuning and adapter routing.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lucas Liu">
  <data key="d0">Lucas Liu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher working on efficient fine-tuning methods for large language models.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Matheus Pereira">
  <data key="d0">Matheus Pereira</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher involved in neural network optimization and adapter-based fine-tuning.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Nicolas Le Roux">
  <data key="d0">Nicolas Le Roux</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher contributing to model adaptation and data-efficient training strategies.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alessandro Sordoni">
  <data key="d0">Alessandro Sordoni</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researcher working on neural model fine-tuning and adapter techniques.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge neurons in pretrained transformers">
  <data key="d0">Knowledge neurons in pretrained transformers</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Research on specific neurons within transformer models that encode factual knowledge, enabling understanding and editing of model knowledge.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Few-shot dense retrieval">
  <data key="d0">Few-shot dense retrieval</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A retrieval method that leverages few examples and prompt-based techniques to improve retrieval accuracy in NLP tasks.</data>
  <data key="d3">chunk-d8b0b9da667ca7eef007d5dabeba89a9</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Gupta, Christine Kaeser-Chen, Kenneth Marino, Arun Ahuja, Sheila Babayan, Felix Hill, and Rob Fergus">
  <data key="d0">Gupta, Christine Kaeser-Chen, Kenneth Marino, Arun Ahuja, Sheila Babayan, Felix Hill, and Rob Fergus</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">A group of researchers involved in studying language models and embodied reasoning, publishing their findings in academic workshops and conferences.&lt;SEP&gt;A group of researchers involved in studying language models, embodied reasoning, and machine learning, publishing multiple papers and participating in workshops and conferences.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Collaborating with language models for embodied reasoning">
  <data key="d0">Collaborating with language models for embodied reasoning</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A scholarly article discussing methods and findings related to collaborating with language models for embodied reasoning, presented at the Second Workshop on Language and Reinforcement Learning.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Nicola De Cao, Wilker Aziz, and Ivan Titov">
  <data key="d0">Nicola De Cao, Wilker Aziz, and Ivan Titov</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers focusing on editing factual knowledge in language models, contributing to NLP conference proceedings.&lt;SEP&gt;Researchers specializing in natural language processing, particularly in editing and improving factual knowledge in language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Editing Factual Knowledge in Language Models">
  <data key="d0">Editing Factual Knowledge in Language Models</data>
  <data key="d1">Research Paper</data>
  <data key="d2">A study on methods for editing and updating factual information stored within language models, presented at EMNLP 2021.&lt;SEP&gt;A study on methods to modify and improve factual information stored within language models, presented at EMNLP 2021.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric P. Xing, and Zhiting Hu">
  <data key="d0">Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric P. Xing, and Zhiting Hu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers working on optimizing text prompts for language models using reinforcement learning, presented at EMNLP.&lt;SEP&gt;Researchers working on prompt optimization using reinforcement learning, focusing on discrete text prompts.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="RLPrompt">
  <data key="d0">RLPrompt</data>
  <data key="d1">Methodology</data>
  <data key="d2">A reinforcement learning approach to optimize discrete text prompts for language models, aiming to improve prompt effectiveness.&lt;SEP&gt;A reinforcement learning-based approach to optimize discrete text prompts for language models, aimed at improving prompt efficacy.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova">
  <data key="d0">Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers who developed BERT, a pre-training model based on deep bidirectional transformers for language understanding.&lt;SEP&gt;Researchers who developed BERT, a pre-training model for deep bidirectional transformers in language understanding.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bert">
  <data key="d0">Bert</data>
  <data key="d1">Model</data>
  <data key="d2">BERT is a deep learning model pre-trained for language understanding tasks, utilizing bidirectional transformers to capture context.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al.">
  <data key="d0">Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers studying parameter-efficient methods for pre-trained language models, including delta tuning.&lt;SEP&gt;Researchers studying parameter-efficient tuning methods for pre-trained language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Delta tuning">
  <data key="d0">Delta tuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A comprehensive approach for tuning pre-trained language models efficiently by adjusting a minimal set of parameters to adapt to new tasks.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, and Denny Zhou">
  <data key="d0">Andrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, and Denny Zhou</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers working on compositional semantic parsing with large language models, presented at learning representations conference.&lt;SEP&gt;Researchers working on semantic parsing, compositional understanding, and large language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Compositional Semantic Parsing with Large Language Models">
  <data key="d0">Compositional Semantic Parsing with Large Language Models</data>
  <data key="d1">Research Area</data>
  <data key="d2">A methodology for parsing complex semantic structures using large language models, enabling better understanding of compositional language.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt Gardner">
  <data key="d0">Dheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt Gardner</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers exploring prompt-based techniques for decomposing complex questions in NLP, presented at EMNLP 2022.&lt;SEP&gt;Researchers focusing on question decomposition and prompt-based methods for NLP, especially in complex question answering.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Successive Prompting">
  <data key="d0">Successive Prompting</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompting strategy that decomposes complex questions into simpler sub-questions to improve NLP model performance.&lt;SEP&gt;A prompting strategy that decomposes complex questions into simpler sub-questions to improve model reasoning.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ali Edalati, Marzieh Tahaei, Ivan Kobyzev, Vahid Partovi Nia, James J Clark, and Mehdi Rezagholizadeh">
  <data key="d0">Ali Edalati, Marzieh Tahaei, Ivan Kobyzev, Vahid Partovi Nia, James J Clark, and Mehdi Rezagholizadeh</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers developing parameter-efficient tuning methods, including Kronecker adapters, for NLP models.&lt;SEP&gt;Researchers developing parameter-efficient tuning methods, including Kronecker adapters, for language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="KronA">
  <data key="d0">KronA</data>
  <data key="d1">Methodology</data>
  <data key="d2">A parameter-efficient tuning technique that uses Kronecker product-based adapters to fine-tune models with fewer parameters.&lt;SEP&gt;A parameter-efficient tuning technique using Kronecker adapters to adapt language models to new tasks with minimal parameter updates.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick Pérez, and Raoul de Charette">
  <data key="d0">Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick Pérez, and Raoul de Charette</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers working on prompt-driven zero-shot domain adaptation for language models, presented as P{\O}DA.&lt;SEP&gt;Researchers working on zero-shot domain adaptation using prompt-driven methods, notably P{\O}DA.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="P{\O}DA">
  <data key="d0">P{\O}DA</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompt-based approach enabling language models to adapt to new domains without additional training, focusing on zero-shot transfer.&lt;SEP&gt;A prompt-driven zero-shot domain adaptation framework allowing models to adapt to new domains without additional training data.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yang Feng, Shiyue Zhang, Andi Zhang, Dong Wang, and Andrew Abel">
  <data key="d0">Yang Feng, Shiyue Zhang, Andi Zhang, Dong Wang, and Andrew Abel</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers exploring memory-augmented neural machine translation to improve translation quality and context handling.&lt;SEP&gt;Researchers investigating memory-augmented neural machine translation models to improve translation performance.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Memory-augmented Neural Machine Translation">
  <data key="d0">Memory-augmented Neural Machine Translation</data>
  <data key="d1">Methodology</data>
  <data key="d2">An NMT approach that incorporates external memory components to enhance translation accuracy and context handling.&lt;SEP&gt;An NMT approach that incorporates external memory components to enhance translation performance, especially on complex or low-resource tasks.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig">
  <data key="d0">Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers developing program-aided language models (PAL) to improve reasoning, coding, and complex task performance.&lt;SEP&gt;Researchers exploring program-aided language models (PAL) to enhance reasoning and task performance.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chunjiang Ge, Rui Huang, Mixue Xie, Zihang Lai, Shiji Song, Shuang Li, and Gao Huang">
  <data key="d0">Chunjiang Ge, Rui Huang, Mixue Xie, Zihang Lai, Shiji Song, Shuang Li, and Gao Huang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers focusing on domain adaptation techniques in NLP using prompt learning methods.&lt;SEP&gt;Researchers focusing on domain adaptation using prompt learning techniques in NLP.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Adaptation via Prompt Learning">
  <data key="d0">Domain Adaptation via Prompt Learning</data>
  <data key="d1">Methodology</data>
  <data key="d2">Techniques that adapt language models to specific domains through prompt tuning without retraining the entire model.&lt;SEP&gt;Techniques that adapt language models to specific target domains through prompt tuning, without retraining the entire model.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Edouard Grave, Armand Joulin, and Nicolas Usunier">
  <data key="d0">Edouard Grave, Armand Joulin, and Nicolas Usunier</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers who enhanced neural language models by incorporating a continuous cache to improve context retention and prediction accuracy.&lt;SEP&gt;Researchers who enhanced neural language models with continuous cache mechanisms to improve context retention and prediction.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Improving neural language models with a continuous cache">
  <data key="d0">Improving neural language models with a continuous cache</data>
  <data key="d1">Methodology</data>
  <data key="d2">A method that adds a continuous cache to neural language models to improve their ability to generate contextually relevant predictions.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuxian Gu, Xu Han, Zhiyuan Liu, and Minlie Huang">
  <data key="d0">Yuxian Gu, Xu Han, Zhiyuan Liu, and Minlie Huang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers developing pre-trained prompt tuning (PPT) for few-shot learning in NLP.&lt;SEP&gt;Researchers developing pre-trained prompt tuning (PPT) for few-shot learning, aiming to improve low-resource NLP tasks.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pre-trained Prompt Tuning for Few-shot Learning (PPT)">
  <data key="d0">Pre-trained Prompt Tuning for Few-shot Learning (PPT)</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompt-based fine-tuning approach designed to improve few-shot performance of language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xu Guo, Boyang Li, and Han Yu">
  <data key="d0">Xu Guo, Boyang Li, and Han Yu</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers studying domain adaptation and generalization of pretrained language models, including methods to improve sample efficiency.&lt;SEP&gt;Researchers studying domain adaptation and generalization techniques to improve the robustness and transferability of pretrained language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Adaptation and Generalization of Pretrained Language Models">
  <data key="d0">Domain Adaptation and Generalization of Pretrained Language Models</data>
  <data key="d1">Study Area</data>
  <data key="d2">Research focused on making pre-trained models more adaptable and robust across different domains and tasks.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May">
  <data key="d0">Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers working on adversarial reprogramming at the word level to improve NLP model robustness.&lt;SEP&gt;Researchers working on adversarial reprogramming at the word level to test and improve model robustness against malicious inputs.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="WARP: Word-level Adversarial ReProgramming">
  <data key="d0">WARP: Word-level Adversarial ReProgramming</data>
  <data key="d1">Methodology</data>
  <data key="d2">An adversarial reprogramming technique that manipulates word inputs at the token level to evaluate and improve NLP model robustness.&lt;SEP&gt;An adversarial reprogramming technique that manipulates word inputs to test and improve model robustness.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hangfeng He, Hongming Zhang, and Dan Roth">
  <data key="d0">Hangfeng He, Hongming Zhang, and Dan Roth</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers proposing retrieval-based inference methods to improve faithfulness and factual correctness in large language models.&lt;SEP&gt;Researchers rethinking large language model inference by integrating retrieval mechanisms to improve faithfulness and accuracy.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rethinking with Retrieval: Faithful Large Language Model Inference">
  <data key="d0">Rethinking with Retrieval: Faithful Large Language Model Inference</data>
  <data key="d1">Methodology</data>
  <data key="d2">An approach that incorporates retrieval-based methods into LLM inference to enhance faithfulness and factual correctness.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig">
  <data key="d0">Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers exploring parameter-efficient transfer learning approaches, aiming to unify various methods for efficient adaptation.&lt;SEP&gt;Researchers exploring parameter-efficient transfer learning techniques for language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Towards a unified view of parameter-efficient transfer learning">
  <data key="d0">Towards a unified view of parameter-efficient transfer learning</data>
  <data key="d1">Study Area</data>
  <data key="d2">Research aiming to unify various transfer learning approaches to improve efficiency and adaptability of language models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shwai He, Liang Ding, Daize Dong, Miao Zhang, and Dacheng Tao">
  <data key="d0">Shwai He, Liang Ding, Daize Dong, Miao Zhang, and Dacheng Tao</data>
  <data key="d1">Researchers</data>
  <data key="d2">Researchers working on sparse adapters to improve parameter efficiency during model fine-tuning and domain adaptation.&lt;SEP&gt;Researchers working on sparse adapters to improve parameter efficiency in model fine-tuning.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sparseadapter">
  <data key="d0">Sparseadapter</data>
  <data key="d1">Methodology</data>
  <data key="d2">An approach that introduces sparse adapters to neural networks, reducing parameters needed for adaptation while maintaining performance.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Second Workshop on Language and Reinforcement Learning">
  <data key="d0">Second Workshop on Language and Reinforcement Learning</data>
  <data key="d1">Event</data>
  <data key="d2">An academic workshop focused on language models, reinforcement learning, and embodied reasoning, where the paper on collaborating with language models was presented.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Delta Tuning">
  <data key="d0">Delta Tuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A comprehensive study of parameter-efficient tuning techniques, including delta tuning, for adapting pre-trained models to downstream tasks.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Compositional Semantic Parsing">
  <data key="d0">Compositional Semantic Parsing</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique for parsing complex semantic structures by leveraging large language models to understand compositional language.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Continuous Cache">
  <data key="d0">Continuous Cache</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique that adds a continuous cache to neural language models, enabling better modeling of recent context and improving prediction quality.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pre-trained Prompt Tuning (PPT)">
  <data key="d0">Pre-trained Prompt Tuning (PPT)</data>
  <data key="d1">Methodology</data>
  <data key="d2">A prompt-based fine-tuning strategy designed for few-shot learning scenarios, enhancing model adaptability with minimal data.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Adaptation and Generalization">
  <data key="d0">Domain Adaptation and Generalization</data>
  <data key="d1">Study Area</data>
  <data key="d2">Research focused on making language models more adaptable across domains and improving their generalization capabilities.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Retrieval-based Inference">
  <data key="d0">Retrieval-based Inference</data>
  <data key="d1">Methodology</data>
  <data key="d2">An approach that incorporates retrieval mechanisms into inference processes of language models to enhance factual accuracy and faithfulness.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Unified Transfer Learning">
  <data key="d0">Unified Transfer Learning</data>
  <data key="d1">Study Area</data>
  <data key="d2">Research aiming to develop a unified framework for transfer learning approaches to improve efficiency and flexibility in NLP models.</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ma">
  <data key="d0">Ma</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ma is an author involved in studies related to transfer learning and parameter efficiency in machine learning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Taylor Berg-Kirkpatrick">
  <data key="d0">Taylor Berg-Kirkpatrick</data>
  <data key="d1">Researcher</data>
  <data key="d2">Taylor Berg-Kirkpatrick is an author contributing to a unified view of parameter-efficient transfer learning methodologies.&lt;SEP&gt;Taylor Berg-Kirkpatrick is an author contributing to the development of a unified view of parameter-efficient transfer learning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Graham Neubig">
  <data key="d0">Graham Neubig</data>
  <data key="d1">Researcher</data>
  <data key="d2">Graham Neubig is an author working on transfer learning methodologies in machine learning.&lt;SEP&gt;Graham Neubig is an author working on transfer learning techniques and models in machine learning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shwai He">
  <data key="d0">Shwai He</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shwai He is an author who proposed Sparseadapter, a method to improve parameter efficiency of adapters in models.&lt;SEP&gt;Shwai He is an author who proposed Sparseadapter, an approach to improve parameter efficiency of adapters in models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Liang Ding">
  <data key="d0">Liang Ding</data>
  <data key="d1">Researcher</data>
  <data key="d2">Liang Ding is an author involved in research on efficient adapter models for NLP.&lt;SEP&gt;Liang Ding is an author involved in research on parameter-efficient models in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Daize Dong">
  <data key="d0">Daize Dong</data>
  <data key="d1">Researcher</data>
  <data key="d2">Daize Dong is an author contributing to studies on model efficiency in NLP.&lt;SEP&gt;Daize Dong is an author working on sparse adapter techniques for model efficiency.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Miao Zhang">
  <data key="d0">Miao Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Miao Zhang is an author contributing to parameter-efficient neural network architectures.&lt;SEP&gt;Miao Zhang is an author working on sparse adapters for improved parameter efficiency.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dacheng Tao">
  <data key="d0">Dacheng Tao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dacheng Tao is an author involved in machine learning research, including model efficiency.&lt;SEP&gt;Dacheng Tao is an author involved in machine learning research, including transfer learning and model efficiency.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dan Hendrycks">
  <data key="d0">Dan Hendrycks</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dan Hendrycks is an author who introduced Gaussian Error Linear Units (GELUs) as an activation function to improve neural network performance.&lt;SEP&gt;Dan Hendrycks is an author who introduced Gaussian Error Linear Units (GELUs) as an activation function.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kevin Gimpel">
  <data key="d0">Kevin Gimpel</data>
  <data key="d1">Researcher</data>
  <data key="d2">Kevin Gimpel co-authored work on GELUs in neural networks.&lt;SEP&gt;Kevin Gimpel is an author who co-developed GELUs for neural network activation functions.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Evan Hernandez">
  <data key="d0">Evan Hernandez</data>
  <data key="d1">Researcher</data>
  <data key="d2">Evan Hernandez is an author researching knowledge representations in language models.&lt;SEP&gt;Evan Hernandez is an author researching methods to measure and manipulate knowledge representations in language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Belinda Z Li">
  <data key="d0">Belinda Z Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Belinda Z Li is an author involved in studies on language models and knowledge manipulation.&lt;SEP&gt;Belinda Z Li is an author working on understanding and controlling knowledge in language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jacob Andreas">
  <data key="d0">Jacob Andreas</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jacob Andreas is an author studying techniques for measuring and manipulating knowledge representations in NLP models.&lt;SEP&gt;Jacob Andreas is an author working on measuring and manipulating knowledge in language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neil Houlsby">
  <data key="d0">Neil Houlsby</data>
  <data key="d1">Researcher</data>
  <data key="d2">Neil Houlsby is an author who contributed to parameter-efficient transfer learning approaches for NLP.&lt;SEP&gt;Neil Houlsby is an author who contributed to the development of parameter-efficient transfer learning for NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andrei Giurgiu">
  <data key="d0">Andrei Giurgiu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Andrei Giurgiu is an author involved in transfer learning research for NLP.&lt;SEP&gt;Andrei Giurgiu is an author involved in transfer learning research in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stanislaw Jastrzebski">
  <data key="d0">Stanislaw Jastrzebski</data>
  <data key="d1">Researcher</data>
  <data key="d2">Stanislaw Jastrzebski is an author contributing to parameter-efficient transfer learning studies.&lt;SEP&gt;Stanislaw Jastrzebski is an author working on parameter-efficient transfer learning methods.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bruna Morrone">
  <data key="d0">Bruna Morrone</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bruna Morrone is an author involved in transfer learning techniques for NLP.&lt;SEP&gt;Bruna Morrone is an author working on transfer learning techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Quentin De Laroussilhe">
  <data key="d0">Quentin De Laroussilhe</data>
  <data key="d1">Researcher</data>
  <data key="d2">Quentin De Laroussilhe is an author involved in NLP transfer learning research.&lt;SEP&gt;Quentin De Laroussilhe is an author researching transfer learning and model fine-tuning in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andrea Gesmundo">
  <data key="d0">Andrea Gesmundo</data>
  <data key="d1">Researcher</data>
  <data key="d2">Andrea Gesmundo is an author contributing to transfer learning in NLP.&lt;SEP&gt;Andrea Gesmundo is an author working on transfer learning methodologies for NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mona Attariyan">
  <data key="d0">Mona Attariyan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Mona Attariyan is an author involved in transfer learning research in NLP.&lt;SEP&gt;Mona Attariyan is an author working on NLP transfer learning methodologies.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sylvain Gelly">
  <data key="d0">Sylvain Gelly</data>
  <data key="d1">Researcher</data>
  <data key="d2">Sylvain Gelly is an author involved in transfer learning research.&lt;SEP&gt;Sylvain Gelly is an author working on transfer learning and model adaptation techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jeremy Howard">
  <data key="d0">Jeremy Howard</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jeremy Howard is an author known for universal language model fine-tuning for text classification.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sebastian Ruder">
  <data key="d0">Sebastian Ruder</data>
  <data key="d1">Researcher</data>
  <data key="d2">Sebastian Ruder is an author working on NLP transfer learning and language models.&lt;SEP&gt;Sebastian Ruder is an author working on language models and NLP techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Cheng-Yu Hsieh">
  <data key="d0">Cheng-Yu Hsieh</data>
  <data key="d1">Researcher</data>
  <data key="d2">Cheng-Yu Hsieh is an author researching methods to outperform larger language models with less data and smaller models.&lt;SEP&gt;Cheng-Yu Hsieh is an author researching methods to outperform larger language models with less data.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yasuhisa Fujii">
  <data key="d0">Yasuhisa Fujii</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yasuhisa Fujii is an author involved in NLP research, including data efficiency and model training.&lt;SEP&gt;Yasuhisa Fujii is an author involved in NLP research, including data efficiency.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alexander Ratner">
  <data key="d0">Alexander Ratner</data>
  <data key="d1">Researcher</data>
  <data key="d2">Alexander Ratner is an author working on NLP methodologies and model training techniques.&lt;SEP&gt;Alexander Ratner is an author working on NLP methodologies.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tomas Pfister">
  <data key="d0">Tomas Pfister</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tomas Pfister is an author contributing to NLP model efficiency and training methods.&lt;SEP&gt;Tomas Pfister is an author contributing to NLP model efficiency.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Edward J Hu">
  <data key="d0">Edward J Hu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Edward J Hu is an author involved in developing low-rank adaptation methods for large language models.&lt;SEP&gt;Edward J Hu is an author who developed Low-Rank Adaptation (LoRA) techniques for large language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yelong Shen">
  <data key="d0">Yelong Shen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yelong Shen is an author working on adaptation methods for large language models.&lt;SEP&gt;Yelong Shen is an author working on language model adaptation techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Phillip Wallis">
  <data key="d0">Phillip Wallis</data>
  <data key="d1">Researcher</data>
  <data key="d2">Phillip Wallis is an author contributing to NLP transfer learning research.&lt;SEP&gt;Phillip Wallis is an author involved in NLP transfer learning and model adaptation.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zeyuan Allen-Zhu">
  <data key="d0">Zeyuan Allen-Zhu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zeyuan Allen-Zhu is an author involved in large language model adaptation studies.&lt;SEP&gt;Zeyuan Allen-Zhu is an author working on low-rank adaptation and parameter-efficient fine-tuning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuanzhi Li">
  <data key="d0">Yuanzhi Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuanzhi Li is an author researching knowledge incorporation and efficient training in language models.&lt;SEP&gt;Yuanzhi Li is an author working on knowledge incorporation in language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shean Wang">
  <data key="d0">Shean Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shean Wang is an author researching NLP model training.&lt;SEP&gt;Shean Wang is an author working on NLP model training and adaptation.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lu Wang">
  <data key="d0">Lu Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lu Wang is an author involved in NLP model efficiency and training.&lt;SEP&gt;Lu Wang is an author involved in NLP research, especially in model training and fine-tuning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Weizhu Chen">
  <data key="d0">Weizhu Chen</data>
  <data key="d1">Researcher</data>
  <data key="d2">Weizhu Chen is an author contributing to language model adaptation techniques.&lt;SEP&gt;Weizhu Chen is an author working on parameter-efficient fine-tuning and adaptation of language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shengding Hu">
  <data key="d0">Shengding Hu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shengding Hu is an author researching knowledge prompt-tuning and incorporation in NLP.&lt;SEP&gt;Shengding Hu is an author working on knowledge prompt-tuning in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ning Ding">
  <data key="d0">Ning Ding</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ning Ding is an author involved in prompt-tuning and knowledge integration in language models.&lt;SEP&gt;Ning Ding is an author working on prompt-tuning and knowledge integration for NLP models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Huadong Wang">
  <data key="d0">Huadong Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Huadong Wang is an author involved in NLP model training and efficiency.&lt;SEP&gt;Huadong Wang is an author researching NLP model training.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhiyuan Liu">
  <data key="d0">Zhiyuan Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zhiyuan Liu is an author working on knowledge-enhanced NLP models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jingang Wang">
  <data key="d0">Jingang Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jingang Wang is an author involved in NLP research.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Juanzi Li">
  <data key="d0">Juanzi Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Juanzi Li is an author working on knowledge integration in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wei Wu">
  <data key="d0">Wei Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Wei Wu is an author contributing to NLP model training and efficiency.&lt;SEP&gt;Wei Wu is an author contributing to NLP model training and knowledge incorporation.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Maosong Sun">
  <data key="d0">Maosong Sun</data>
  <data key="d1">Researcher</data>
  <data key="d2">Maosong Sun is an author involved in NLP and knowledge-based models.&lt;SEP&gt;Maosong Sun is an author involved in NLP, knowledge-based models, and transfer learning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhiqiang Hu">
  <data key="d0">Zhiqiang Hu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zhiqiang Hu is an author working on parameter-efficient fine-tuning of large language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yihuai Lan">
  <data key="d0">Yihuai Lan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yihuai Lan is an author researching NLP adaptation and fine-tuning methods.&lt;SEP&gt;Yihuai Lan is an author researching NLP adaptation methods.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lei Wang">
  <data key="d0">Lei Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lei Wang is an author involved in NLP model fine-tuning and adaptation.&lt;SEP&gt;Lei Wang is an author involved in NLP model fine-tuning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wanyu Xu">
  <data key="d0">Wanyu Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Wanyu Xu is an author working on large language model adaptation techniques.&lt;SEP&gt;Wanyu Xu is an author working on large language model adaptation.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ee-Peng Lim">
  <data key="d0">Ee-Peng Lim</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ee-Peng Lim is an author involved in NLP research, especially in model fine-tuning.&lt;SEP&gt;Ee-Peng Lim is an author involved in NLP research.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Roy Ka-Wei Lee">
  <data key="d0">Roy Ka-Wei Lee</data>
  <data key="d1">Researcher</data>
  <data key="d2">Roy Ka-Wei Lee is an author working on NLP model adaptation and fine-tuning.&lt;SEP&gt;Roy Ka-Wei Lee is an author working on NLP model adaptation.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lidong Bing">
  <data key="d0">Lidong Bing</data>
  <data key="d1">Researcher</data>
  <data key="d2">Lidong Bing is an author contributing to NLP model adaptation and efficiency.&lt;SEP&gt;Lidong Bing is an author contributing to NLP model fine-tuning.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Soujanya Poria">
  <data key="d0">Soujanya Poria</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in research on domain adaptation, focusing on improving model performance and efficiency.&lt;SEP&gt;Author contributing to domain adaptation research, focusing on efficient model training.&lt;SEP&gt;Soujanya Poria is an author involved in NLP research, including hallucination detection.&lt;SEP&gt;Soujanya Poria is an author involved in NLP research.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiaxin Huang">
  <data key="d0">Jiaxin Huang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiaxin Huang is an author working on self-improvement and self-enhancement of large language models.&lt;SEP&gt;Jiaxin Huang is an author working on self-improvement of large language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shixiang Shane Gu">
  <data key="d0">Shixiang Shane Gu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shixiang Shane Gu is an author involved in NLP model self-improvement.&lt;SEP&gt;Shixiang Shane Gu is an author researching NLP model self-improvement techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Le Hou">
  <data key="d0">Le Hou</data>
  <data key="d1">Researcher</data>
  <data key="d2">Le Hou is an author involved in NLP model enhancement and self-improvement.&lt;SEP&gt;Le Hou is an author researching NLP model enhancement.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuexin Wu">
  <data key="d0">Yuexin Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuexin Wu is an author working on NLP models and their self-improvement.&lt;SEP&gt;Yuexin Wu is an author working on NLP models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hongkun Yu">
  <data key="d0">Hongkun Yu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hongkun Yu is an author working on NLP model development.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiawei Han">
  <data key="d0">Jiawei Han</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in data analysis and language model research, contributing to understanding model performance.&lt;SEP&gt;Author involved in data analysis and language model research.&lt;SEP&gt;Jiawei Han is an author contributing to knowledge and data mining in NLP.&lt;SEP&gt;Jiawei Han is an author specializing in knowledge discovery and data mining in NLP.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ziwei Ji">
  <data key="d0">Ziwei Ji</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ziwei Ji is an author researching hallucination issues in natural language generation.&lt;SEP&gt;Ziwei Ji is an author researching hallucinations and issues in natural language generation.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Nayeon Lee">
  <data key="d0">Nayeon Lee</data>
  <data key="d1">Researcher</data>
  <data key="d2">Nayeon Lee is an author involved in NLP hallucination studies.&lt;SEP&gt;Nayeon Lee is an author working on hallucination detection and mitigation in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rita Frieske">
  <data key="d0">Rita Frieske</data>
  <data key="d1">Researcher</data>
  <data key="d2">Rita Frieske is an author researching hallucination phenomena in language models.&lt;SEP&gt;Rita Frieske is an author working on hallucination in language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tiezheng Yu">
  <data key="d0">Tiezheng Yu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tiezheng Yu is an author involved in natural language generation and hallucination studies.&lt;SEP&gt;Tiezheng Yu is an author researching natural language generation issues.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dan Su">
  <data key="d0">Dan Su</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dan Su is an author involved in NLP hallucination research.&lt;SEP&gt;Dan Su is an author working on hallucination issues in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yan Xu">
  <data key="d0">Yan Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yan Xu is an author researching hallucination problems in language models.&lt;SEP&gt;Yan Xu is an author working on language model hallucination issues.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Etsuko Ishii">
  <data key="d0">Etsuko Ishii</data>
  <data key="d1">Researcher</data>
  <data key="d2">Etsuko Ishii is an author involved in NLP hallucination research.&lt;SEP&gt;Etsuko Ishii is an author researching NLP hallucinations.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ye Jin Bang">
  <data key="d0">Ye Jin Bang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ye Jin Bang is an author working on hallucination in NLP.&lt;SEP&gt;Ye Jin Bang is an author working on hallucination issues in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andrea Madotto">
  <data key="d0">Andrea Madotto</data>
  <data key="d1">Researcher</data>
  <data key="d2">Andrea Madotto is an author involved in NLP hallucination studies.&lt;SEP&gt;Andrea Madotto is an author researching hallucination phenomena in language models.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pascale Fung">
  <data key="d0">Pascale Fung</data>
  <data key="d1">Researcher</data>
  <data key="d2">Pascale Fung is an author researching hallucinations in language models.&lt;SEP&gt;Pascale Fung is an author working on hallucination detection and mitigation in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chen Jia">
  <data key="d0">Chen Jia</data>
  <data key="d1">Researcher</data>
  <data key="d2">Chen Jia is an author working on prompt-based distribution alignment for domain generalization in NLP.&lt;SEP&gt;Chen Jia is an author working on prompt-based distribution alignment in NLP.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yue Zhang">
  <data key="d0">Yue Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yue Zhang is an author involved in NLP domain generalization.&lt;SEP&gt;Yue Zhang is an author involved in domain generalization and prompt-based NLP techniques.</data>
  <data key="d3">chunk-3f464ce07046c0201c72becc8d51da3e</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt-based Distribution Alignment">
  <data key="d0">Prompt-based Distribution Alignment</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A technique designed to align data distributions across different domains to improve the robustness of models in domain generalization tasks within text classification.&lt;SEP&gt;A technique for aligning distributions in domain generalization tasks within text classification, aiming to improve model robustness across different domains.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Generalization">
  <data key="d0">Domain Generalization</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A machine learning challenge aiming to develop models that perform well on unseen domains by leveraging training data from multiple source domains.&lt;SEP&gt;A machine learning challenge focused on training models that perform well across unseen domains by leveraging diverse source domain data.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Text Classification">
  <data key="d0">Text Classification</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A task in natural language processing that involves categorizing text into predefined labels or classes.&lt;SEP&gt;An NLP task that involves categorizing text into predefined labels or classes, often used in various applications like spam detection, sentiment analysis, and topic labeling.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Conference on Empirical Methods in Natural Language Processing">
  <data key="d0">Conference on Empirical Methods in Natural Language Processing</data>
  <data key="d1">Study Design</data>
  <data key="d2">An academic conference where research papers related to empirical NLP methods are presented, including the discussed work.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ACM">
  <data key="d0">ACM</data>
  <data key="d1">Organization</data>
  <data key="d2">The Association for Computing Machinery, a professional organization that publishes and disseminates research in computing.&lt;SEP&gt;The Association for Computing Machinery, a professional organization that publishes research and organizes conferences in computing.&lt;SEP&gt;The Association for Computing Machinery, to which the manuscript has been submitted, indicating peer review and dissemination.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Theoretical Models">
  <data key="d0">Theoretical Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models explaining how large language models learn, generalize, and can be guided or improved through techniques like distribution alignment.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Regularized Optimization">
  <data key="d0">Regularized Optimization</data>
  <data key="d1">Methodology</data>
  <data key="d2">A training approach that incorporates regularization terms to improve model robustness and prevent overfitting, used in fine-tuning large language models.&lt;SEP&gt;An optimization approach that incorporates regularization terms during training to improve model robustness and prevent overfitting, used in fine-tuning large language models.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Learning">
  <data key="d0">Prompt Learning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique for designing prompts to guide language models toward desired behaviors or outputs, including instance-aware prompt learning for better task adaptation.&lt;SEP&gt;A technique for guiding language models by designing prompts to elicit desired outputs, including instance-aware prompt learning.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Biomedical Information Access">
  <data key="d0">Biomedical Information Access</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Access to biomedical knowledge using domain-specific tools integrated with large language models, exemplified by GeneGPT, aiming to improve retrieval and understanding of biomedical data.&lt;SEP&gt;Access to specialized biomedical knowledge using domain tools integrated with large language models, exemplified by GeneGPT.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scaling Laws for Neural Language Models">
  <data key="d0">Scaling Laws for Neural Language Models</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Empirical laws describing how the performance of neural language models scales with model size, data, and compute.&lt;SEP&gt;Empirical laws that describe how the performance of neural language models scales with model size, data, and compute resources, guiding model development.&lt;SEP&gt;Investigate the relationship between model size, training data, and performance in neural language models to inform scaling strategies.&lt;SEP&gt;Investigating how the size of neural language models affects their performance and capabilities.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Adapter Layers">
  <data key="d0">Adapter Layers</data>
  <data key="d1">Tools</data>
  <data key="d2">Low-rank hypercomplex adapter layers designed to make neural networks more efficient and adaptable, as in the Compacter model.&lt;SEP&gt;Low-rank hypercomplex adapter layers, such as those used in the Compacter model, designed to make large models more parameter-efficient and adaptable.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Internet-Augmented Dialogue Generation">
  <data key="d0">Internet-Augmented Dialogue Generation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Dialogue systems enhanced with internet access to retrieve and incorporate external information during conversation.&lt;SEP&gt;Dialogue systems enhanced with internet access to retrieve external information during interactions, improving relevance and accuracy.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Clinical Language Models">
  <data key="d0">Clinical Language Models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Language models specialized for clinical or medical NLP tasks, with ongoing debates about their necessity and utility in healthcare applications.&lt;SEP&gt;Language models specialized in clinical or medical text, with ongoing debates about their necessity and effectiveness.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Financial Sentiment Analysis">
  <data key="d0">Financial Sentiment Analysis</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Analysis of financial news and social media to gauge market sentiment, exemplified by the Sentiment Spin project using GPT-3.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Parameter-Efficient Prompt Tuning">
  <data key="d0">Parameter-Efficient Prompt Tuning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A technique to adapt large language models efficiently by tuning a small number of parameters, reducing resource requirements while maintaining performance.&lt;SEP&gt;A technique to optimize large language models by tuning a small set of parameters, achieving efficient adaptation with minimal resource use.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Giant Frozen Language Models">
  <data key="d0">Giant Frozen Language Models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Large-scale, pre-trained language models that are frozen during downstream tasks, serving as foundational models for various applications.&lt;SEP&gt;Large-scale, pre-trained language models that are kept frozen during downstream tasks, serving as foundational models for various applications.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Retrieval-augmented Generation">
  <data key="d0">Retrieval-augmented Generation</data>
  <data key="d1">Methodology</data>
  <data key="d2">An approach combining external knowledge retrieval with generative models to improve performance on knowledge-intensive NLP tasks.&lt;SEP&gt;An approach combining external knowledge retrieval with generative models to perform knowledge-intensive NLP tasks more effectively.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Controllable Working Memory">
  <data key="d0">Controllable Working Memory</data>
  <data key="d1">Variables</data>
  <data key="d2">A component of large language models that manages the amount of information retained during processing, enabling better control over reasoning and memory.&lt;SEP&gt;A feature of large language models that allows managing and controlling the amount of information retained during processing.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Communicative Agents">
  <data key="d0">Communicative Agents</data>
  <data key="d1">Tools</data>
  <data key="d2">Agents designed for communication and interaction within the large-scale language model ecosystem, facilitating information exchange and exploration.&lt;SEP&gt;Agents designed for interaction and exploration within large-scale language model society, facilitating communication and information exchange.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing">
  <data key="d0">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</data>
  <data key="d1">Study Design</data>
  <data key="d2">An academic conference where research related to empirical NLP methods, including the discussed work, is presented and published.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sentiment Spin">
  <data key="d0">Sentiment Spin</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A project that uses GPT-3 to analyze and manipulate financial sentiment, demonstrating NLP's application in financial market analysis.</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Guohao Li">
  <data key="d0">Guohao Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Guohao Li is an author involved in the study of large-scale language models and their societal implications.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hasan Abed Al Kader Hammoud">
  <data key="d0">Hasan Abed Al Kader Hammoud</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hani Itani is a researcher contributing to research on communicative agents and language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hani Itani">
  <data key="d0">Hani Itani</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hani Itani is a researcher contributing to research on communicative agents and language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dmitrii Khizbullin">
  <data key="d0">Dmitrii Khizbullin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Dmitrii Khizbullin is involved in the development of models related to language understanding and society.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bernard Ghanem">
  <data key="d0">Bernard Ghanem</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bernard Ghanem is a researcher focused on large-scale language models and their societal impacts.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2303.17760">
  <data key="d0">arXiv:2303.17760</data>
  <data key="d1">Study Design</data>
  <data key="d2">A preprint publication presenting research findings on large language models and their societal implications.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Haochen Li">
  <data key="d0">Haochen Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Haochen Li is a researcher who contributed to the development of KiPT for event detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tong Mo">
  <data key="d0">Tong Mo</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tong Mo is a researcher involved in computational linguistics and event detection methodologies.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hongcheng Fan">
  <data key="d0">Hongcheng Fan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hongcheng Fan is a researcher working on prompt tuning and event detection techniques.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jingkun Wang">
  <data key="d0">Jingkun Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jingkun Wang is a researcher contributing to event detection research.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiaxi Wang">
  <data key="d0">Jiaxi Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiaxi Wang is a researcher involved in computational linguistics and event detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fuhao Zhang">
  <data key="d0">Fuhao Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Fuhao Zhang is a researcher working on language models and event detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Weiping Li">
  <data key="d0">Weiping Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Weiping Li is a researcher contributing to prompt tuning and event detection methodologies.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="International Conference on Computational Linguistics">
  <data key="d0">International Conference on Computational Linguistics</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference where research on language models and event detection was presented.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jinyang Li">
  <data key="d0">Jinyang Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jinyang Li is a researcher exploring language models as database interfaces and text-to-SQL tasks.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Binyuan Hui">
  <data key="d0">Binyuan Hui</data>
  <data key="d1">Researcher</data>
  <data key="d2">Binyuan Hui is involved in research on large-scale database grounded language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ge Qu">
  <data key="d0">Ge Qu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ge Qu is a researcher contributing to database interface research using language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Binhua Li">
  <data key="d0">Binhua Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Binhua Li is a researcher working on language models for database applications.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiaxi Yang">
  <data key="d0">Jiaxi Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiaxi Yang is involved in research on language models and database interaction.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bowen Li">
  <data key="d0">Bowen Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bowen Li is a researcher working on text-to-SQL and database grounding.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bailin Wang">
  <data key="d0">Bailin Wang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bailin Wang is a researcher exploring language models for database tasks.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bowen Qin">
  <data key="d0">Bowen Qin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Bowen Qin is involved in research on language models and database interfaces.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rongyu Cao">
  <data key="d0">Rongyu Cao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Rongyu Cao is a researcher working on language models as database interfaces.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruiying Geng">
  <data key="d0">Ruiying Geng</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ruiying Geng is a researcher exploring language models for database grounding.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Can LLM Already Serve as A Database Interface?">
  <data key="d0">Can LLM Already Serve as A Database Interface?</data>
  <data key="d1">Research Question</data>
  <data key="d2">Investigates whether large language models can effectively serve as database interfaces and handle text-to-SQL tasks.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2305.03111">
  <data key="d0">arXiv:2305.03111</data>
  <data key="d1">Study Design</data>
  <data key="d2">A preprint exploring large language models as database interfaces.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xiang Lisa Li">
  <data key="d0">Xiang Lisa Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xiang Lisa Li is a researcher studying prompt tuning and language model optimization.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prefix-Tuning">
  <data key="d0">Prefix-Tuning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Prefix-Tuning is a technique for optimizing continuous prompts to improve language generation.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Proceedings of the 59th Annual Meeting of the ACL">
  <data key="d0">Proceedings of the 59th Annual Meeting of the ACL</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference proceeding presenting research on prompt tuning and language model optimization.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="abs/2101.00190">
  <data key="d0">abs/2101.00190</data>
  <data key="d1">Study Design</data>
  <data key="d2">Preprint paper detailing prefix-tuning methodology for language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jacky Liang">
  <data key="d0">Jacky Liang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jacky Liang is involved in research on language model programs for embodied control.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wenlong Huang">
  <data key="d0">Wenlong Huang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Wenlong Huang is a researcher working on language models and robotics.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fei Xia">
  <data key="d0">Fei Xia</data>
  <data key="d1">Researcher</data>
  <data key="d2">Fei Xia is a researcher exploring language models for control and robotics.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Peng Xu">
  <data key="d0">Peng Xu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Peng Xu is involved in research on language models and embodied control.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Karol Hausman">
  <data key="d0">Karol Hausman</data>
  <data key="d1">Researcher</data>
  <data key="d2">Karol Hausman is a researcher working on language models applied to embodied tasks.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pete Florence">
  <data key="d0">Pete Florence</data>
  <data key="d1">Researcher</data>
  <data key="d2">Pete Florence is a researcher contributing to language and robotics integration.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andy Zeng">
  <data key="d0">Andy Zeng</data>
  <data key="d1">Researcher</data>
  <data key="d2">Andy Zeng is involved in research on language models for embodied control.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Code as Policies">
  <data key="d0">Code as Policies</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Code as Policies refers to using language model programs to control embodied agents.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Workshop on Language and Robotics at CoRL 2022">
  <data key="d0">Workshop on Language and Robotics at CoRL 2022</data>
  <data key="d1">Study Design</data>
  <data key="d2">A workshop presentation on language models applied to robotics and embodied control.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yaobo Liang">
  <data key="d0">Yaobo Liang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yaobo Liang is a researcher working on task completion connecting foundation models with APIs.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chenfei Wu">
  <data key="d0">Chenfei Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Chenfei Wu is involved in research on task completion and foundation models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="TaskMatrix AI">
  <data key="d0">TaskMatrix AI</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">TaskMatrix AI is a framework for completing tasks by connecting foundation models with numerous APIs.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2303.16434">
  <data key="d0">arXiv:2303.16434</data>
  <data key="d1">Study Design</data>
  <data key="d2">Preprint detailing TaskMatrix AI's approach to task completion.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hongzhan Lin">
  <data key="d0">Hongzhan Lin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hongzhan Lin is a researcher exploring prompt learning for rumor detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pengyao Yi">
  <data key="d0">Pengyao Yi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Pengyao Yi is a researcher working on propagation structure and prompt learning for rumor detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jing Ma">
  <data key="d0">Jing Ma</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jing Ma is involved in research on rumor detection using language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Haiyun Jiang">
  <data key="d0">Haiyun Jiang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Haiyun Jiang is a researcher working on propagation-based rumor detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ziyang Luo">
  <data key="d0">Ziyang Luo</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ziyang Luo is involved in research on rumor detection and propagation structures.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shuming Shi">
  <data key="d0">Shuming Shi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Shuming Shi is a researcher contributing to rumor detection methodologies.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruifang Liu">
  <data key="d0">Ruifang Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Ruifang Liu is a researcher exploring propagation structure in rumor detection.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Relational Memory-Augmented Language Models">
  <data key="d0">Relational Memory-Augmented Language Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Relational Memory-Augmented Language Models enhance language models with relational memory to improve reasoning and knowledge retrieval.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Transactions of the ACL 10 (2022), 555–572">
  <data key="d0">Transactions of the ACL 10 (2022), 555–572</data>
  <data key="d1">Study Design</data>
  <data key="d2">A publication presenting the development and evaluation of relational memory-augmented language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2210.05359">
  <data key="d0">arXiv:2210.05359</data>
  <data key="d1">Study Design</data>
  <data key="d2">Preprint detailing grounded language model reasoning through simulation.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xiangyang Liu">
  <data key="d0">Xiangyang Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xiangyang Liu is a researcher working on prompt tuning and language model efficiency.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tianxiang Sun">
  <data key="d0">Tianxiang Sun</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tianxiang Sun is involved in research on prompt tuning strategies.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xuanjing Huang">
  <data key="d0">Xuanjing Huang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xuanjing Huang is a researcher working on language model optimization.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xipeng Qiu">
  <data key="d0">Xipeng Qiu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Xipeng Qiu is a researcher exploring prompt tuning and language model performance.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Late Prompt Tuning">
  <data key="d0">Late Prompt Tuning</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Late Prompt Tuning is a technique where prompts are applied late in the model to improve performance.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Findings of the ACL EMNLP 2022">
  <data key="d0">Findings of the ACL EMNLP 2022</data>
  <data key="d1">Study Design</data>
  <data key="d2">Conference proceedings presenting research on prompt tuning strategies.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yiheng Liu">
  <data key="d0">Yiheng Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yiheng Liu is a researcher summarizing GPT-4 and ChatGPT research.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tianle Han">
  <data key="d0">Tianle Han</data>
  <data key="d1">Researcher</data>
  <data key="d2">Tianle Han is involved in research on large language model summaries.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Siyuan Ma">
  <data key="d0">Siyuan Ma</data>
  <data key="d1">Researcher</data>
  <data key="d2">Siyuan Ma is a researcher working on language model analysis.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiayue Zhang">
  <data key="d0">Jiayue Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiayue Zhang is a researcher contributing to GPT-4 and ChatGPT research summaries.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuanyuan Yang">
  <data key="d0">Yuanyuan Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuanyuan Yang is involved in research on large language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiaming Tian">
  <data key="d0">Jiaming Tian</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jiaming Tian is a researcher working on GPT-4 research analysis.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hao He">
  <data key="d0">Hao He</data>
  <data key="d1">Researcher</data>
  <data key="d2">Hao He is a researcher contributing to GPT-4 research summaries.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Antong Li">
  <data key="d0">Antong Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Antong Li is involved in research on large language model summaries.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mengshen He">
  <data key="d0">Mengshen He</data>
  <data key="d1">Researcher</data>
  <data key="d2">Mengshen He is a researcher working on GPT-4 and ChatGPT research.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhengliang Liu">
  <data key="d0">Zhengliang Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Zhengliang Liu is a researcher contributing to large language model research.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2304.01852">
  <data key="d0">arXiv:2304.01852</data>
  <data key="d1">Study Design</data>
  <data key="d2">Preprint summarizing ChatGPT/GPT-4 research and future perspectives.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Can ChatGPT Forecast Stock Price Movements?">
  <data key="d0">Can ChatGPT Forecast Stock Price Movements?</data>
  <data key="d1">Research Question</data>
  <data key="d2">Investigates whether ChatGPT can predict stock market movements and return predictability.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2304.07619">
  <data key="d0">arXiv:2304.07619</data>
  <data key="d1">Study Design</data>
  <data key="d2">Preprint analyzing ChatGPT's ability to forecast stock prices.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuehua Tang">
  <data key="d0">Yuehua Tang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yuehua Tang is a researcher studying stock prediction using large language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yueling Mao">
  <data key="d0">Yueling Mao</data>
  <data key="d1">Researcher</data>
  <data key="d2">Yueling Mao is involved in research on financial forecasting with language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2302.03194">
  <data key="d0">arXiv:2302.03194</data>
  <data key="d1">Study Design</data>
  <data key="d2">Preprint on domain adaptation using adapters for language models.</data>
  <data key="d3">chunk-213967d818970d7799e7d9779765ed79</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Designing Chemical Reaction Arrays">
  <data key="d0">Designing Chemical Reaction Arrays</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A methodology involving the use of phactor and ChatGPT to design chemical reaction arrays, focusing on systematic experimentation and automation.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="phactor">
  <data key="d0">phactor</data>
  <data key="d1">Tools</data>
  <data key="d2">A software platform used for designing, managing, and automating chemical reaction arrays, enabling high-throughput experimentation.&lt;SEP&gt;A software tool used for designing and managing chemical reaction arrays, facilitating automation and high-throughput experimentation.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ChatGPT">
  <data key="d0">ChatGPT</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An AI language model employed to assist in the design and optimization of chemical reaction arrays, providing computational support.&lt;SEP&gt;An AI language model utilized to assist in designing chemical reaction arrays, providing computational support and automation.&lt;SEP&gt;An advanced AI language model developed by OpenAI, used for generating human-like text and facilitating research applications.&lt;SEP&gt;ChatGPT is an advanced conversational AI model developed by OpenAI, serving as a foundational component for GingGPT.&lt;SEP&gt;ChatGPT is an advanced conversational AI model developed by OpenAI, used as a foundational component in GingGPT.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-0fedeaf17a30ea46b3aacf96752c0053&lt;SEP&gt;chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bhavitvya Malik">
  <data key="d0">Bhavitvya Malik</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in research on domain adaptation techniques, specifically using adapters for efficient transfer learning.&lt;SEP&gt;Author involved in research on domain adaptation using adapters, contributing to efficient model training techniques.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Abhinav Ramesh Kashyap">
  <data key="d0">Abhinav Ramesh Kashyap</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author contributing to the development of efficient domain adaptation methods with adapters in machine learning.&lt;SEP&gt;Author contributing to research on domain adaptation, focusing on model efficiency.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Min-Yen Kan">
  <data key="d0">Min-Yen Kan</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on language model tuning and domain adaptation frameworks to improve efficiency.&lt;SEP&gt;Author involved in research on domain adaptation and language model tuning.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="UDApter–Efficient Domain Adaptation Using Adapters">
  <data key="d0">UDApter–Efficient Domain Adaptation Using Adapters</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A framework or methodology for domain adaptation that utilizes adapters to improve efficiency in machine learning models.&lt;SEP&gt;A theoretical framework or methodology that utilizes adapters to enable efficient domain adaptation in neural networks, reducing training costs and data requirements.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuning Mao">
  <data key="d0">Yuning Mao</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author who developed Unipelt, a unified framework for parameter-efficient language model tuning, aiming to streamline and improve tuning processes.&lt;SEP&gt;Author involved in developing Unipelt, a unified framework for parameter-efficient language model tuning.&lt;SEP&gt;Yuning Mao researches continual learning methods for language models, focusing on progressive prompts.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lambert Mathias">
  <data key="d0">Lambert Mathias</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author contributing to research on language model tuning and efficiency, focusing on unified frameworks.&lt;SEP&gt;Author contributing to research on language model tuning and efficiency.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rui Hou">
  <data key="d0">Rui Hou</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in studies related to language model optimization and parameter efficiency.&lt;SEP&gt;Author involved in studies on language model optimization and efficiency.&lt;SEP&gt;Rui Hou studies continual learning approaches in NLP, including progressive prompts for language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Amjad Almahairi">
  <data key="d0">Amjad Almahairi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Amjad Almahairi explores continual learning techniques for language models.&lt;SEP&gt;An author exploring unified frameworks for language model tuning to enhance efficiency and performance.&lt;SEP&gt;Author working on language model frameworks, focusing on unified tuning approaches.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hao Ma">
  <data key="d0">Hao Ma</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on methods to improve the efficiency of language model tuning processes.&lt;SEP&gt;Author contributing to language model research, especially in parameter efficiency.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wen-tau Yih">
  <data key="d0">Wen-tau Yih</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on large language models and their applications, including parameter-efficient tuning.&lt;SEP&gt;Author working on language models and their applications.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Madian Khabsa">
  <data key="d0">Madian Khabsa</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author studying how language models reveal perception and psychophysical knowledge.&lt;SEP&gt;Author involved in research on language model frameworks and efficiency.&lt;SEP&gt;Madian Khabsa investigates continual learning and prompt strategies in language modeling.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Unipelt: A unified framework for parameter-efficient language model tuning">
  <data key="d0">Unipelt: A unified framework for parameter-efficient language model tuning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A comprehensive framework designed to enable efficient tuning of language models across multiple tasks by unifying parameter management and optimization strategies.&lt;SEP&gt;A framework designed to optimize language model tuning by making it more parameter-efficient and unified across tasks.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Raja Marjieh">
  <data key="d0">Raja Marjieh</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author investigating how language models can reveal perceptual and psychophysical insights from their representations.&lt;SEP&gt;Author investigating how language models reveal perception and psychophysical knowledge.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ilia Sucholutsky">
  <data key="d0">Ilia Sucholutsky</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author exploring psychophysical knowledge distillation from large language models to understand perception.&lt;SEP&gt;Author exploring psychophysical insights derived from large language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pol van Rijn">
  <data key="d0">Pol van Rijn</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author studying perceptual insights and how language models encode perception-related information.&lt;SEP&gt;Author studying perception and language model relationships.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Nori Jacoby">
  <data key="d0">Nori Jacoby</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author analyzing psychophysical knowledge and perception signals in language models.&lt;SEP&gt;Author researching perceptual knowledge in language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Thomas L Griffiths">
  <data key="d0">Thomas L Griffiths</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author examining perception and cognition through language model analysis.&lt;SEP&gt;Author analyzing perception and language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="What Language Reveals about Perception: Distilling Psychophysical Knowledge from Large Language Models">
  <data key="d0">What Language Reveals about Perception: Distilling Psychophysical Knowledge from Large Language Models</data>
  <data key="d1">Study Design</data>
  <data key="d2">A research effort aimed at extracting and understanding perceptual and psychophysical information from large language models to gain insights into perception processes.&lt;SEP&gt;A research study aimed at extracting perceptual and psychophysical insights from large language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kevin Meng">
  <data key="d0">Kevin Meng</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on methods to locate, edit, and understand factual associations within GPT models to improve factual accuracy and controllability.&lt;SEP&gt;Author working on locating, editing, and understanding factual associations in GPT models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="David Bau">
  <data key="d0">David Bau</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in research on memory editing and factual knowledge manipulation in transformer models.&lt;SEP&gt;Author involved in research on model editing and memory manipulation in transformers.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alex Andonian">
  <data key="d0">Alex Andonian</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author contributing to techniques for editing and supporting factual knowledge in language models.&lt;SEP&gt;Author contributing to factual association and memory editing in language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yonatan Belinkov">
  <data key="d0">Yonatan Belinkov</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author focusing on factual correctness, model editing, and knowledge verification in neural language models.&lt;SEP&gt;Author focusing on factual accuracy and model editing techniques.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2210.07229: Mass-editing memory in a transformer">
  <data key="d0">arXiv:2210.07229: Mass-editing memory in a transformer</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A methodology for editing the memory and factual knowledge stored within transformer-based language models to correct or update information efficiently.&lt;SEP&gt;A technique for editing and updating the memory of transformer-based language models to correct or modify knowledge.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jacob Menick">
  <data key="d0">Jacob Menick</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on methods to support answers with verified quotes and improve factual consistency in language models.&lt;SEP&gt;Author working on supporting answers with verified quotes and improving factual accuracy in language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Maja Trebacz">
  <data key="d0">Maja Trebacz</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in research on verifying and supporting model outputs with credible quotations.&lt;SEP&gt;Author involved in research on model support and verification with quotes.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Vladimir Mikulik">
  <data key="d0">Vladimir Mikulik</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author exploring techniques for verifying facts and supporting answers in language models.&lt;SEP&gt;Author exploring methods for verifying and supporting model outputs.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="John Aslanides">
  <data key="d0">John Aslanides</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on methods to support answers with verified quotes and factual accuracy.&lt;SEP&gt;Author contributing to answer verification in language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Francis Song">
  <data key="d0">Francis Song</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in improving answer support and factual verification in language models.&lt;SEP&gt;Author working on enhancing model answer support mechanisms.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Martin Chadwick">
  <data key="d0">Martin Chadwick</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author contributing to the development of techniques that support verified and trustworthy answers in language models.&lt;SEP&gt;Author involved in improving language model answer reliability.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mia Glaese">
  <data key="d0">Mia Glaese</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on support mechanisms for factual correctness in language models.&lt;SEP&gt;Author focusing on answer support and verification.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Susannah Young">
  <data key="d0">Susannah Young</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in research on answer verification and factual support.&lt;SEP&gt;Author contributing to answer verification processes.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lucy Campbell-Gillingham">
  <data key="d0">Lucy Campbell-Gillingham</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author focusing on supporting answers with verified quotes and factual accuracy.&lt;SEP&gt;Author working on answer validation in language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Geoffrey Irving">
  <data key="d0">Geoffrey Irving</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher involved in large language model research and fine-tuning.&lt;SEP&gt;An author working on AI safety and reinforcement learning, supporting the development of aligned and safe AI models.&lt;SEP&gt;An author working on AI safety, reinforcement learning, and model training methodologies.&lt;SEP&gt;An author working on validation and verification techniques for language model outputs.&lt;SEP&gt;Author involved in developing verified answer mechanisms.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pointer Sentinel Mixture Models">
  <data key="d0">Pointer Sentinel Mixture Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A model architecture designed to improve language modeling by integrating pointer mechanisms and mixture models for better context handling.&lt;SEP&gt;A neural network architecture that combines pointer mechanisms with mixture models to improve language modeling by better handling context and memory.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stephen Merity">
  <data key="d0">Stephen Merity</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author who proposed pointer sentinel mixture models to enhance language modeling performance.&lt;SEP&gt;Author who proposed pointer sentinel mixture models for enhanced language modeling.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Caiming Xiong">
  <data key="d0">Caiming Xiong</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in research on advanced language modeling architectures and techniques.&lt;SEP&gt;Author involved in research on advanced language modeling techniques.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="James Bradbury">
  <data key="d0">James Bradbury</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on improving language model architectures, including mixture models.&lt;SEP&gt;Author working on language model architectures and improvements.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Richard Socher">
  <data key="d0">Richard Socher</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author contributing to innovative language modeling techniques and architectures.&lt;SEP&gt;Author contributing to language model research and modeling techniques.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Augmented Language Models: A Survey">
  <data key="d0">Augmented Language Models: A Survey</data>
  <data key="d1">Study Design</data>
  <data key="d2">A comprehensive survey of recent advancements, architectures, and methodologies in augmented language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Grégoire Mialon">
  <data key="d0">Grégoire Mialon</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author conducting surveys on augmented language models and their capabilities.&lt;SEP&gt;Author conducting surveys on language model augmentation and capabilities.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Roberto Dessì">
  <data key="d0">Roberto Dessì</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author exploring architectures and methods for augmenting language models.&lt;SEP&gt;Author exploring augmented language model architectures.&lt;SEP&gt;Roberto Dessì researches in NLP, focusing on tool use and language model self-teaching capabilities.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Maria Lomeli">
  <data key="d0">Maria Lomeli</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in survey research on language model augmentation.&lt;SEP&gt;Author involved in survey research on language models.&lt;SEP&gt;Maria Lomeli explores tool use in language models and their self-supervised learning processes.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Christoforos Nalmpantis">
  <data key="d0">Christoforos Nalmpantis</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author contributing to the survey of augmented language models.&lt;SEP&gt;Author contributing to the survey of augmented language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ram Pasunuru">
  <data key="d0">Ram Pasunuru</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author studying enhancements and augmentation techniques in language models.&lt;SEP&gt;Author working on language model enhancements and survey studies.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Roberta Raileanu">
  <data key="d0">Roberta Raileanu</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in research on augmented language models and their applications.&lt;SEP&gt;Author involved in research on language model augmentation.&lt;SEP&gt;Roberta Raileanu studies language models' ability to utilize tools and perform tasks via self-instruction.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Baptiste Rozière">
  <data key="d0">Baptiste Rozière</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author exploring architectures and methods for augmenting language models.&lt;SEP&gt;Author contributing to the survey of augmented language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Timo Schick">
  <data key="d0">Timo Schick</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on advanced language model architectures, including augmentation approaches.&lt;SEP&gt;Author exploring advanced language model architectures.&lt;SEP&gt;Timo Schick develops Toolformer, a methodology that enables language models to teach themselves to use external tools.&lt;SEP&gt;Timo Schick develops Toolformer, enabling language models to teach themselves to use external tools.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jane Dwivedi-Yu">
  <data key="d0">Jane Dwivedi-Yu</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in survey research on augmented language models.&lt;SEP&gt;Author involved in language model survey research.&lt;SEP&gt;Jane Dwivedi-Yu works on prompt-based learning and tool integration in language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d&lt;SEP&gt;chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Asli Celikyilmaz">
  <data key="d0">Asli Celikyilmaz</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author focusing on capabilities and augmentation techniques in language models.&lt;SEP&gt;Author working on language model capabilities and surveys.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2302.07842: Augmented language models: a survey">
  <data key="d0">arXiv:2302.07842: Augmented language models: a survey</data>
  <data key="d1">Study Design</data>
  <data key="d2">A comprehensive survey summarizing recent advancements, architectures, and applications of augmented language models, including models with enhanced capabilities and integrations.&lt;SEP&gt;A survey paper reviewing recent developments, architectures, and applications of augmented language models to understand their evolution and capabilities.&lt;SEP&gt;A survey summarizing recent developments, architectures, and applications of augmented language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Recent advances in natural language processing via large pre-trained language models: A survey">
  <data key="d0">Recent advances in natural language processing via large pre-trained language models: A survey</data>
  <data key="d1">Study Design</data>
  <data key="d2">A comprehensive review of progress in NLP driven by large pre-trained language models, including techniques, architectures, and applications.&lt;SEP&gt;A comprehensive review of progress in NLP driven by large pre-trained models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Eneko Agirre">
  <data key="d0">Eneko Agirre</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author contributing to NLP survey research and language model advancements.&lt;SEP&gt;Author involved in NLP survey and language model research.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ilana Heinz">
  <data key="d0">Ilana Heinz</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in summarizing recent NLP advances and large language model research.&lt;SEP&gt;Author contributing to natural language processing advancements.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dan Roth">
  <data key="d0">Dan Roth</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on NLP and large language models, including survey and review studies.&lt;SEP&gt;Author working on NLP and language model development.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?">
  <data key="d0">Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?</data>
  <data key="d1">Study Design</data>
  <data key="d2">A research study analyzing how demonstrations influence in-context learning and model performance, aiming to understand the mechanisms behind effective in-context learning.&lt;SEP&gt;Research exploring how in-context demonstrations influence learning and performance in language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sewon Min">
  <data key="d0">Sewon Min</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author investigating the role of demonstrations and in-context learning in language models.&lt;SEP&gt;Author investigating in-context learning and demonstration effectiveness.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xinxi Lyu">
  <data key="d0">Xinxi Lyu</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author exploring the mechanisms that make in-context learning effective.&lt;SEP&gt;Author analyzing the role of demonstrations in language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ari Holtzman">
  <data key="d0">Ari Holtzman</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author focusing on in-context learning, demonstrations, and how models learn from examples.&lt;SEP&gt;Author focusing on in-context learning mechanisms.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mikel Artetxe">
  <data key="d0">Mikel Artetxe</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author analyzing in-context learning and demonstration techniques.&lt;SEP&gt;Author studying language model training and in-context learning.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hannaneh Hajishirzi">
  <data key="d0">Hannaneh Hajishirzi</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author exploring factors affecting in-context learning performance.&lt;SEP&gt;Author exploring demonstration effects in language models.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2202.12837: Rethinking the Role of Demonstrations">
  <data key="d0">arXiv:2202.12837: Rethinking the Role of Demonstrations</data>
  <data key="d1">Study Design</data>
  <data key="d2">A research paper analyzing the importance and effects of demonstrations in in-context learning.&lt;SEP&gt;A research paper examining the importance of demonstrations in in-context learning, proposing insights into what makes in-context learning effective.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Eric Mitchell">
  <data key="d0">Eric Mitchell</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on scalable and fast model editing techniques for large language models.&lt;SEP&gt;Author working on fast and scalable model editing techniques.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Charles Lin">
  <data key="d0">Charles Lin</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author involved in research on model editing at scale, aiming to efficiently modify model knowledge.&lt;SEP&gt;Author involved in model editing at scale.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Antoine Bosselut">
  <data key="d0">Antoine Bosselut</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author exploring methods for large-scale model editing and knowledge updating.&lt;SEP&gt;Author exploring scalable model modification methods.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chelsea Finn">
  <data key="d0">Chelsea Finn</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author working on model adaptation, editing, and continual learning.&lt;SEP&gt;Author focusing on model adaptation and editing.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2110.11309: Fast model editing at scale">
  <data key="d0">arXiv:2110.11309: Fast model editing at scale</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique designed to enable efficient editing of large language models' knowledge and behaviors.&lt;SEP&gt;A technique for efficiently editing large language models' knowledge base, enabling quick updates and corrections.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2022.15817: Memory-based model editing at scale">
  <data key="d0">arXiv:2022.15817: Memory-based model editing at scale</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A method for editing models' memory to support updates and corrections at scale.&lt;SEP&gt;A methodology for editing and updating the internal memory of models to support ongoing learning and correction at scale.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Philip Moons">
  <data key="d0">Philip Moons</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author exploring the application of ChatGPT and AI language models in healthcare, specifically for cardiovascular nurses and allied health professionals.&lt;SEP&gt;Author exploring AI language models' value for healthcare professionals, particularly cardiovascular nurses.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Liesbet Van Bulck">
  <data key="d0">Liesbet Van Bulck</data>
  <data key="d1">Researcher</data>
  <data key="d2">An author studying the potential value and applications of AI language models like ChatGPT in healthcare settings.&lt;SEP&gt;Author studying applications of AI language models in healthcare contexts.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ChatGPT: Can artificial intelligence language models be of value for cardiovascular nurses and allied health professionals">
  <data key="d0">ChatGPT: Can artificial intelligence language models be of value for cardiovascular nurses and allied health professionals</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">A study assessing how ChatGPT can be valuable tools for healthcare professionals in cardiovascular care and allied health.&lt;SEP&gt;A study assessing the utility of ChatGPT for healthcare professionals in cardiovascular care.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chemical Reaction Arrays">
  <data key="d0">Chemical Reaction Arrays</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Arrays of chemical reactions designed systematically to optimize and explore chemical processes, utilizing tools like phactor and ChatGPT for automation and design.</data>
  <data key="d3">chunk-09444836044cdc7760bd666a5b6e6c6d</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Reiichiro Nakano">
  <data key="d0">Reiichiro Nakano</data>
  <data key="d1">Researcher</data>
  <data key="d2">Reiichiro Nakano is a researcher involved in human factors and AI research, contributing to publications on language models and human feedback mechanisms.&lt;SEP&gt;Reiichiro Nakano is a researcher involved in studies related to human-computer interaction and AI, contributing to publications on language models and feedback mechanisms.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jacob Hilton">
  <data key="d0">Jacob Hilton</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jacob Hilton is a researcher contributing to studies on AI and human factors, particularly in question-answering systems.&lt;SEP&gt;Jacob Hilton is a researcher working on AI, human-computer interaction, and question-answering systems, contributing to related publications.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Suchir Balaji">
  <data key="d0">Suchir Balaji</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.&lt;SEP&gt;Suchir Balaji is involved in research on AI systems and human feedback mechanisms in language models.&lt;SEP&gt;Suchir Balaji researches AI systems, focusing on human feedback, instruction tuning, and language model training methodologies.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jeff Wu">
  <data key="d0">Jeff Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Jeff Wu is a researcher working on language model training and feedback processes.&lt;SEP&gt;Jeff Wu is involved in AI research, particularly in training language models with human feedback and improving model instruction-following capabilities.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Long Ouyang">
  <data key="d0">Long Ouyang</data>
  <data key="d1">Researcher</data>
  <data key="d2">Long Ouyang is a researcher specializing in training language models with human feedback, contributing to advancements in instruction-following models.&lt;SEP&gt;Long Ouyang specializes in training large language models to follow instructions using human feedback, significantly advancing instruction alignment.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Christina Kim">
  <data key="d0">Christina Kim</data>
  <data key="d1">Researcher</data>
  <data key="d2">Christina Kim contributes to AI research related to human factors, feedback, and language model evaluation.&lt;SEP&gt;Christina Kim is a researcher involved in AI and human-computer interaction research.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Christopher Hesse">
  <data key="d0">Christopher Hesse</data>
  <data key="d1">Researchers</data>
  <data key="d2">Christopher Hesse is a researcher contributing to AI research publications.&lt;SEP&gt;Christopher Hesse is involved in AI research focusing on language models, feedback mechanisms, and system development.&lt;SEP&gt;Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Shantanu Jain">
  <data key="d0">Shantanu Jain</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.&lt;SEP&gt;Shantanu Jain is involved in AI research, particularly in language models and human feedback.&lt;SEP&gt;Shantanu Jain researches human-AI interaction, feedback, and language model training methodologies.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Vineet Kosaraju">
  <data key="d0">Vineet Kosaraju</data>
  <data key="d1">Researcher</data>
  <data key="d2">Vineet Kosaraju is a researcher working on AI systems and human-AI interaction.&lt;SEP&gt;Vineet Kosaraju works on human-AI interaction, feedback, and language model alignment in AI research.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="William Saunders">
  <data key="d0">William Saunders</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.&lt;SEP&gt;William Saunders contributes to AI research, focusing on language models, human feedback, and system evaluation.&lt;SEP&gt;William Saunders is a researcher contributing to AI and human feedback studies.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ChatGPT plugins">
  <data key="d0">ChatGPT plugins</data>
  <data key="d1">Tools</data>
  <data key="d2">ChatGPT plugins are software extensions developed by OpenAI to enhance the functionality of ChatGPT, enabling integration with external tools and services.&lt;SEP&gt;ChatGPT plugins are software extensions provided by OpenAI to enhance ChatGPT's functionality through external tool integration.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Generative Agents: Interactive Simulacra of Human Behavior">
  <data key="d0">Generative Agents: Interactive Simulacra of Human Behavior</data>
  <data key="d1">Research Topic</data>
  <data key="d2">This research develops AI agents that simulate human behavior for interactive applications, emphasizing human-like interactions.&lt;SEP&gt;This research explores the creation of generative agents that simulate human behavior for interactive applications.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instruction tuning with GPT-4">
  <data key="d0">Instruction tuning with GPT-4</data>
  <data key="d1">Methodology</data>
  <data key="d2">Instruction tuning involves fine-tuning GPT-4 on specific instructions to enhance its task performance and alignment.&lt;SEP&gt;Instruction tuning involves refining large language models like GPT-4 through specific training on task instructions to improve performance.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adapterhub">
  <data key="d0">Adapterhub</data>
  <data key="d1">Tools</data>
  <data key="d2">Adapterhub is a framework for adapting transformer models to various tasks through modular components, facilitating transfer learning.&lt;SEP&gt;Adapterhub is a framework that facilitates the adaptation of transformer models to various tasks via modular adapters, enabling efficient transfer learning.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mad-x">
  <data key="d0">Mad-x</data>
  <data key="d1">Methodology</data>
  <data key="d2">Mad-x is an adapter-based framework designed for multi-task cross-lingual transfer learning in NLP.&lt;SEP&gt;Mad-x is an adapter-based framework designed for multi-task, cross-lingual transfer learning in NLP, enabling multi-language model adaptation.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Decomposed In-Context Learning of Text-to-SQL with Self-Correction (DIN-SQL)">
  <data key="d0">Decomposed In-Context Learning of Text-to-SQL with Self-Correction (DIN-SQL)</data>
  <data key="d1">Methodology</data>
  <data key="d2">DIN-SQL is a method for in-context learning in text-to-SQL tasks that incorporates self-correction mechanisms to improve accuracy.&lt;SEP&gt;DIN-SQL is a technique for in-context learning of text-to-SQL conversion that incorporates self-correction to improve accuracy.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Gradient-free, Edit-based Instruction Search (GrIPS)">
  <data key="d0">Gradient-free, Edit-based Instruction Search (GrIPS)</data>
  <data key="d1">Methodology</data>
  <data key="d2">GrIPS is a prompt optimization technique that searches for effective instructions in large language models using gradient-free, edit-based methods.&lt;SEP&gt;GrIPS is a technique for instruction search in large language models that uses gradient-free, edit-based approaches to optimize prompts.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hierarchical Domain-specific Language Models and Attention">
  <data key="d0">Hierarchical Domain-specific Language Models and Attention</data>
  <data key="d1">Methodology</data>
  <data key="d2">This approach involves hierarchical domain-specific language models combined with attention mechanisms to improve decision classification in legal NLP tasks.&lt;SEP&gt;This approach uses hierarchical, domain-specific language models combined with attention mechanisms to improve decision classification in legal NLP tasks.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="LFPT5">
  <data key="d0">LFPT5</data>
  <data key="d1">Methodology</data>
  <data key="d2">LFPT5 is a framework for lifelong, few-shot language learning based on prompt tuning of the T5 model, enabling continual learning across tasks.&lt;SEP&gt;LFPT5 is a unified framework for lifelong few-shot language learning based on prompt tuning of the T5 model.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tool Learning with Foundation Models">
  <data key="d0">Tool Learning with Foundation Models</data>
  <data key="d1">Research Question/Hypothesis</data>
  <data key="d2">This research investigates how foundation models can be used for tool learning, aiming to enhance AI capabilities in task execution.&lt;SEP&gt;This research investigates how foundation models can learn to use external tools to enhance task performance and adaptability.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pre-trained models for natural language processing">
  <data key="d0">Pre-trained models for natural language processing</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Pre-trained language models are foundational architectures trained on large corpora, enabling transfer learning and broad NLP applications.&lt;SEP&gt;This survey reviews the development and application of pre-trained language models in NLP, highlighting their impact on the field.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Improving language understanding by generative pre-training">
  <data key="d0">Improving language understanding by generative pre-training</data>
  <data key="d1">Results</data>
  <data key="d2">Generative pre-training significantly improves language understanding and downstream NLP task performance in AI models.&lt;SEP&gt;This study demonstrates that generative pre-training significantly enhances language understanding capabilities in AI models.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Exploring the limits of transfer learning with a unified text-to-text transformer">
  <data key="d0">Exploring the limits of transfer learning with a unified text-to-text transformer</data>
  <data key="d1">Results</data>
  <data key="d2">This research explores how transfer learning can be optimized using a unified text-to-text transformer architecture.&lt;SEP&gt;This study demonstrates how transfer learning can be maximized using a unified text-to-text transformer architecture.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey">
  <data key="d0">Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This survey emphasizes the importance of domain specialization in large language models to achieve disruptive impact in AI applications.&lt;SEP&gt;This survey emphasizes the importance of domain-specific training and specialization to unlock the disruptive potential of large language models in various fields.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="WebGPT: Browser-assisted question-answering with human feedback">
  <data key="d0">WebGPT: Browser-assisted question-answering with human feedback</data>
  <data key="d1">Study Design</data>
  <data key="d2">This study explores how human feedback improves browser-assisted question-answering systems, contributing to AI system development.</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Colin Raffel">
  <data key="d0">Colin Raffel</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Colin Raffel is a researcher involved in exploring the limits of transfer learning with a unified text-to-text transformer, contributing to foundational understanding in machine learning.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adam Roberts">
  <data key="d0">Adam Roberts</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Adam Roberts (also listed above) focuses on knowledge capacity of language models and their parameterization.&lt;SEP&gt;Adam Roberts is a researcher focused on understanding the capacity of language models and their knowledge storage capabilities.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Katherine Lee">
  <data key="d0">Katherine Lee</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Katherine Lee is involved in research on transfer learning and language modeling in machine learning.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Michael Matena">
  <data key="d0">Michael Matena</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Michael Matena works on language models and transfer learning in machine learning research.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yanqi Zhou">
  <data key="d0">Yanqi Zhou</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Yanqi Zhou is involved in research related to natural language processing and transfer learning.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wei Li">
  <data key="d0">Wei Li</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Wei Li contributes to studies on language models and transfer learning in machine learning.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Peter J Liu">
  <data key="d0">Peter J Liu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Peter J Liu is a researcher exploring transfer learning and language model limits in machine learning.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ori Ram">
  <data key="d0">Ori Ram</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ori Ram researches in-context retrieval-augmented language models, focusing on enhancing language understanding and retrieval capabilities.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yoav Levine">
  <data key="d0">Yoav Levine</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Yoav Levine contributes to development of retrieval-augmented language models, improving contextual understanding.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Itay Dalmedigos">
  <data key="d0">Itay Dalmedigos</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Itay Dalmedigos works on retrieval-augmented language models, enhancing model performance and knowledge integration.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dor Muhlgay">
  <data key="d0">Dor Muhlgay</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dor Muhlgay is involved in research on retrieval techniques for language models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Amnon Shashua">
  <data key="d0">Amnon Shashua</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Amnon Shashua researches in artificial intelligence, focusing on retrieval-augmented models and their applications.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kevin Leyton-Brown">
  <data key="d0">Kevin Leyton-Brown</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Kevin Leyton-Brown studies in AI and machine learning, particularly in retrieval and contextual models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yoav Shoham">
  <data key="d0">Yoav Shoham</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Yoav Shoham explores language models and retrieval-augmented techniques within AI research.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Arya Rao">
  <data key="d0">Arya Rao</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Arya Rao evaluates ChatGPT as an adjunct for radiologic decision-making, examining AI applications in healthcare.&lt;SEP&gt;Arya Rao evaluates ChatGPT as an adjunct in radiologic decision-making, examining AI applications in healthcare.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="John Kim">
  <data key="d0">John Kim</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">John Kim participates in research assessing language models like ChatGPT in medical decision support.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Meghana Kamineni">
  <data key="d0">Meghana Kamineni</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Meghana Kamineni investigates AI tools, including ChatGPT, in clinical decision processes.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Michael Pang">
  <data key="d0">Michael Pang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Michael Pang explores AI applications in healthcare, focusing on radiology and decision-making.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Winston Lie">
  <data key="d0">Winston Lie</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Winston Lie studies AI's role in medical imaging and diagnostics, evaluating ChatGPT's utility.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Marc D Succi">
  <data key="d0">Marc D Succi</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Marc D Succi researches AI integration in radiology, assessing ChatGPT as an adjunct tool.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Anastasia Razdaibiedina">
  <data key="d0">Anastasia Razdaibiedina</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Anastasia Razdaibiedina works on continual learning in language models, developing progressive prompt techniques.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sylvestre-Alvise Rebuffi">
  <data key="d0">Sylvestre-Alvise Rebuffi</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Sylvestre-Alvise Rebuffi studies learning across multiple visual domains with residual adapters, contributing to multi-domain learning methodologies.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hakan Bilen">
  <data key="d0">Hakan Bilen</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Hakan Bilen works on visual domain learning and residual adapter techniques in neural networks.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andrea Vedaldi">
  <data key="d0">Andrea Vedaldi</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Andrea Vedaldi researches in neural networks and multi-domain learning, including residual adaptation methods.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Joshua Robinson">
  <data key="d0">Joshua Robinson</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Joshua Robinson develops methods leveraging large language models for multiple-choice question answering, enhancing NLP applications.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Christopher Michael Rytting">
  <data key="d0">Christopher Michael Rytting</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Christopher Rytting works on question answering systems using large language models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="David Wingate">
  <data key="d0">David Wingate</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">David Wingate researches in NLP, focusing on question answering and language model applications.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jerret Ross">
  <data key="d0">Jerret Ross</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Jerret Ross studies large-scale chemical language representations, capturing molecular structure and properties for AI applications.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Brian Belgodere">
  <data key="d0">Brian Belgodere</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Brian Belgodere works on chemical language models and molecular property prediction.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Vijil Chenthamarakshan">
  <data key="d0">Vijil Chenthamarakshan</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Vijil Chenthamarakshan researches chemical language representations and molecular modeling.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Inkit Padhi">
  <data key="d0">Inkit Padhi</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Inkit Padhi focuses on chemical language modeling and molecular structure understanding.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Youssef Mroueh">
  <data key="d0">Youssef Mroueh</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Youssef Mroueh explores molecular property prediction using language representations.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Payel Das">
  <data key="d0">Payel Das</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Payel Das investigates chemical language models for molecular analysis.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Malik Sallam">
  <data key="d0">Malik Sallam</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Malik Sallam systematically reviews the use of ChatGPT in healthcare education, research, and practice, analyzing future perspectives and limitations.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Albert Webson">
  <data key="d0">Albert Webson</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Albert Webson works on prompt-based training and model generalization in NLP.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stephen Bach">
  <data key="d0">Stephen Bach</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Stephen Bach contributes to multitask training and zero-shot task generalization in language models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Lintang Sutawika">
  <data key="d0">Lintang Sutawika</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Lintang Sutawika researches prompt engineering and multitask learning in NLP.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zaid Alyafeai">
  <data key="d0">Zaid Alyafeai</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Zaid Alyafeai explores prompt-based training techniques for language models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Antoine Chaffin">
  <data key="d0">Antoine Chaffin</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Antoine Chaffin works on prompt engineering and generalization in NLP models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Arnaud Stiegler">
  <data key="d0">Arnaud Stiegler</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Arnaud Stiegler studies prompt-based learning and model adaptation techniques.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Urmish Thakker">
  <data key="d0">Urmish Thakker</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Urmish Thakker researches in prompt tuning and zero-shot learning in NLP.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shanya Sharma Sharma">
  <data key="d0">Shanya Sharma Sharma</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Shanya Sharma Sharma focuses on prompt strategies and model generalization in NLP.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Eliza Szczechla">
  <data key="d0">Eliza Szczechla</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Eliza Szczechla studies prompt engineering and multitask training methods.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Taewoon Kim">
  <data key="d0">Taewoon Kim</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Taewoon Kim explores prompt-based approaches for task generalization in language models.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Gunjan Chhablani">
  <data key="d0">Gunjan Chhablani</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Gunjan Chhablani researches in NLP prompt techniques and model adaptability.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Nihal Nayak">
  <data key="d0">Nihal Nayak</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Nihal Nayak works on prompt engineering and zero-shot learning in NLP.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Debajyoti Datta">
  <data key="d0">Debajyoti Datta</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Debajyoti Datta studies prompt-based training and model generalization strategies.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jonathan Chang">
  <data key="d0">Jonathan Chang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Jonathan Chang contributes to multitask prompt training and zero-shot task performance.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mike Tian-Jian Jiang">
  <data key="d0">Mike Tian-Jian Jiang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Mike Tian-Jian Jiang researches prompt strategies and task generalization.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Han Wang">
  <data key="d0">Han Wang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Han Wang works on prompt engineering and language model adaptation.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Matteo Manica">
  <data key="d0">Matteo Manica</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Matteo Manica explores prompt-based training and zero-shot learning in NLP.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sheng Shen">
  <data key="d0">Sheng Shen</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Sheng Shen studies multitask prompt training and model generalization.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zheng Xin Yong">
  <data key="d0">Zheng Xin Yong</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Zheng Xin Yong researches in prompt techniques and zero-shot task performance.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Harshit Pandey">
  <data key="d0">Harshit Pandey</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Harshit Pandey focuses on prompt engineering and model adaptability.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Rachel Bawden">
  <data key="d0">Rachel Bawden</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Rachel Bawden works on prompt strategies and zero-shot generalization in NLP.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Thomas Wang">
  <data key="d0">Thomas Wang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Thomas Wang researches in prompt-based multitask training and task generalization.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Trishala Neeraj">
  <data key="d0">Trishala Neeraj</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Trishala Neeraj explores prompt tuning and zero-shot learning approaches.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jos Rozen">
  <data key="d0">Jos Rozen</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Jos Rozen studies prompt engineering and language model performance across tasks.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Abheesht Sharma">
  <data key="d0">Abheesht Sharma</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Abheesht Sharma works on prompt strategies for model generalization.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Andrea Santilli">
  <data key="d0">Andrea Santilli</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Andrea Santilli researches prompt-based training and zero-shot capabilities.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Thibault Fevry">
  <data key="d0">Thibault Fevry</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Thibault Fevry explores prompt techniques and multitask learning.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jason Alan Fries">
  <data key="d0">Jason Alan Fries</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Jason Fries studies prompt engineering for task generalization.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ryan Teehan">
  <data key="d0">Ryan Teehan</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ryan Teehan focuses on prompt-based zero-shot learning.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stella Biderman">
  <data key="d0">Stella Biderman</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Stella Biderman works on prompt engineering and transfer learning in NLP.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Leo Gao">
  <data key="d0">Leo Gao</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Leo Gao explores prompt-based training for zero-shot task performance.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alexander M Rush">
  <data key="d0">Alexander M Rush</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Alexander M Rush researches in prompt techniques and zero-shot generalization.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Nicola Cancedda">
  <data key="d0">Nicola Cancedda</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Nicola Cancedda researches in NLP, focusing on tool learning and model self-improvement.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Thomas Scialom">
  <data key="d0">Thomas Scialom</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Thomas Scialom studies fine-tuning and continual learning in language models, emphasizing adaptability and knowledge retention.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tuhin Chakrabarty">
  <data key="d0">Tuhin Chakrabarty</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Tuhin Chakrabarty works on continual learning and prompt-based techniques in NLP.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Smaranda Muresan">
  <data key="d0">Smaranda Muresan</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Smaranda Muresan researches in NLP, focusing on continual learning and language model adaptation.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shohreh Shaghaghian">
  <data key="d0">Shohreh Shaghaghian</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Shohreh Shaghaghian studies legal NLP, customizing contextualized language models for legal document review.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Luna Yue Feng">
  <data key="d0">Luna Yue Feng</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Luna Yue Feng works on legal NLP and contextualized language models tailored for legal texts.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Borna Jafarpour">
  <data key="d0">Borna Jafarpour</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Borna Jafarpour researches in legal NLP, focusing on customizing models for legal document analysis.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Nicolai Pogrebnyakov">
  <data key="d0">Nicolai Pogrebnyakov</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Nicolai Pogrebnyakov explores NLP for legal applications, customizing language models for legal review.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yongliang Shen">
  <data key="d0">Yongliang Shen</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Yongliang Shen researches in AI, focusing on HuggingGPT, integrating ChatGPT with HuggingFace tools for AI task solving.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kaitao Song">
  <data key="d0">Kaitao Song</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Kaitao Song works on AI task solving using HuggingGPT and related frameworks.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xu Tan">
  <data key="d0">Xu Tan</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Xu Tan contributes to AI and NLP, focusing on multi-model integration like HuggingGPT.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dongsheng Li">
  <data key="d0">Dongsheng Li</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Dongsheng Li researches AI systems, including HuggingGPT for solving complex tasks.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Weiming Lu">
  <data key="d0">Weiming Lu</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Weiming Lu studies AI frameworks such as HuggingGPT for multi-model task execution.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yueting Zhuang">
  <data key="d0">Yueting Zhuang</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Yueting Zhuang works on AI task frameworks like HuggingGPT, integrating models for comprehensive solutions.</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="GingGPT">
  <data key="d0">GingGPT</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">GingGPT is a language model designed for solving AI tasks, leveraging ChatGPT and its related models within the HuggingFace ecosystem.&lt;SEP&gt;GingGPT is a language model designed to solve AI tasks by leveraging ChatGPT and related models within the HuggingFace platform.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="HuggingFace">
  <data key="d0">HuggingFace</data>
  <data key="d1">Tools</data>
  <data key="d2">HuggingFace is a platform providing access to numerous machine learning models and tools, including ChatGPT, facilitating deployment and integration.&lt;SEP&gt;HuggingFace is a platform providing access to various machine learning models and tools, including ChatGPT and related models.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv:2303.17580">
  <data key="d0">arXiv:2303.17580</data>
  <data key="d1">Study Design</data>
  <data key="d2">A preprint manuscript detailing the development and application of GingGPT for AI tasks.&lt;SEP&gt;A preprint manuscript that describes the development, methodology, and applications of GingGPT for AI task solving.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hanul Shin, Jung Kwon Lee, Jaehong Kim, Jiwon Kim">
  <data key="d0">Hanul Shin, Jung Kwon Lee, Jaehong Kim, Jiwon Kim</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of a study on continual learning with deep generative replay, contributing to neural information processing and continual learning methodologies.&lt;SEP&gt;Authors of a study on continual learning with deep generative replay, contributing to understanding neural information processing.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kumar Shridhar, Alessandro Stolfo, Mrinmaya Sachan">
  <data key="d0">Kumar Shridhar, Alessandro Stolfo, Mrinmaya Sachan</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of a study on distilling reasoning capabilities of large language models into smaller models via semantic decompositions.&lt;SEP&gt;Authors of research on distilling multi-step reasoning capabilities of large language models into smaller models via semantic decompositions, advancing model compression techniques.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Devendra Singh, Siva Reddy, Will Hamilton, Chris Dyer, Dani Yogatama">
  <data key="d0">Devendra Singh, Siva Reddy, Will Hamilton, Chris Dyer, Dani Yogatama</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of research on end-to-end training of multi-document reader and retriever for open-domain question answering.&lt;SEP&gt;Authors of work on end-to-end training of multi-document reader and retriever systems for open-domain question answering, enhancing NLP retrieval methods.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, Animesh Garg">
  <data key="d0">Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, Animesh Garg</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of ProgPrompt, a system for generating situated robot task plans using large language models, bridging NLP and robotics.&lt;SEP&gt;Authors of work on ProgPrompt, generating situated robot task plans using large language models.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yusheng Su, Xiaozhi Wang, Yujia Qin, Chi-Min Chan, Yankai Lin, Huadong Wang, Kaiyue Wen, Zhiyuan Liu, Peng Li, Juanzi Li">
  <data key="d0">Yusheng Su, Xiaozhi Wang, Yujia Qin, Chi-Min Chan, Yankai Lin, Huadong Wang, Kaiyue Wen, Zhiyuan Liu, Peng Li, Juanzi Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors exploring the transferability of prompt tuning for natural language processing, impacting model adaptation and transfer learning methodologies.&lt;SEP&gt;Authors investigating transferability of prompt tuning for natural language processing.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, Xipeng Qiu">
  <data key="d0">Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, Xipeng Qiu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors exploring black-box tuning for language-model-as-a-service.&lt;SEP&gt;Authors investigating black-box tuning approaches for language-model-as-a-service (MLaaS), relevant for model deployment and API-based NLP solutions.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yi-Lin Sung, Jaemin Cho, Mohit Bansal">
  <data key="d0">Yi-Lin Sung, Jaemin Cho, Mohit Bansal</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors proposing Ladder Side-Tuning (LST), a parameter and memory-efficient transfer learning methodology for large models.&lt;SEP&gt;Authors proposing Ladder Side-Tuning (LST), an efficient transfer learning technique.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dídac Surís, Sachit Menon, Carl Vondrick">
  <data key="d0">Dídac Surís, Sachit Menon, Carl Vondrick</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors presenting ViperGPT, a method for visual inference via Python execution for reasoning tasks.&lt;SEP&gt;Authors presenting ViperGPT, a system for visual inference via Python execution, enabling reasoning in multimodal AI systems.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al.">
  <data key="d0">Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of Llama, an open and efficient foundation language model.&lt;SEP&gt;Developers of Llama, an open, efficient foundation language model designed for broad NLP applications.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mojtaba Valipour, Mehdi Rezagholizadeh, Ivan Kobyzev, Ali Ghodsi">
  <data key="d0">Mojtaba Valipour, Mehdi Rezagholizadeh, Ivan Kobyzev, Ali Ghodsi</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of DyLoRA, a parameter-efficient tuning method for pre-trained models.&lt;SEP&gt;Authors of DyLoRA, a parameter-efficient tuning method utilizing dynamic search-free low-rank adaptation for large pre-trained models.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Josef Valvoda, Ryan Cotterell, Simone Teufel">
  <data key="d0">Josef Valvoda, Ryan Cotterell, Simone Teufel</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors analyzing the role of negative precedent in legal outcome prediction, integrating NLP with legal decision modeling.&lt;SEP&gt;Authors studying the role of negative precedent in legal outcome prediction.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin">
  <data key="d0">Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors of 'Attention is All You Need', the foundational paper that introduced the transformer architecture for NLP.&lt;SEP&gt;Authors of the seminal 'Attention is All You Need' paper, foundational for transformer models.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tu Vu, Brian Lester, Noah Constant, Rami Al-Rfou, Daniel Matthew Cer">
  <data key="d0">Tu Vu, Brian Lester, Noah Constant, Rami Al-Rfou, Daniel Matthew Cer</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors proposing SPoT, a method for better frozen model adaptation through soft prompt transfer, improving NLP model efficiency.&lt;SEP&gt;Authors proposing SPoT, improving frozen model adaptation through soft prompt transfer.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Danilo Vucetic, Mohammadreza Tayaranian, Maryam Ziaeefard, James J Clark, Brett H Meyer, Warren J Gross">
  <data key="d0">Danilo Vucetic, Mohammadreza Tayaranian, Maryam Ziaeefard, James J Clark, Brett H Meyer, Warren J Gross</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors focusing on efficient fine-tuning of compressed language models using learners, enhancing model deployment and resource efficiency.&lt;SEP&gt;Authors on efficient fine-tuning of compressed language models with learners.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhongwei Wan, Yichun Yin, Wei Zhang, Jiaxin Shi, Lifeng Shang, Guangyong Chen, Xin Jiang, Qun Liu">
  <data key="d0">Zhongwei Wan, Yichun Yin, Wei Zhang, Jiaxin Shi, Lifeng Shang, Guangyong Chen, Xin Jiang, Qun Liu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors introducing G-MAP, a general memory-augmented pre-trained language model for domain-specific tasks.&lt;SEP&gt;Authors of G-MAP, a general memory-augmented pre-trained language model tailored for domain-specific NLP tasks.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang, Dian Yu, Shuming Shi, Zhaopeng Tu">
  <data key="d0">Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang, Dian Yu, Shuming Shi, Zhaopeng Tu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors working on document-level machine translation with large language models, advancing translation quality and context handling.&lt;SEP&gt;Authors working on document-level machine translation with large language models.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruijie Wang, Zheng Li, Dachun Sun, Shengzhong Liu, Jinning Li, Bing Yin, Tarek Abdelzaher">
  <data key="d0">Ruijie Wang, Zheng Li, Dachun Sun, Shengzhong Liu, Jinning Li, Bing Yin, Tarek Abdelzaher</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors focusing on learning to sample and aggregate for reasoning over temporal knowledge graphs, integrating ML with graph reasoning.&lt;SEP&gt;Authors focusing on learning to sample and aggregate for reasoning over temporal knowledge graphs.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruize Wang, Duyu Tang, Nan Duan, Zhongyu">
  <data key="d0">Ruize Wang, Duyu Tang, Nan Duan, Zhongyu</data>
  <data key="d1">Researcher</data>
  <data key="d2">Authors involved in research on methods for reasoning and inference in temporal knowledge graphs.&lt;SEP&gt;Authors involved in research on reasoning and inference techniques for temporal knowledge graphs, enhancing reasoning accuracy.</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="language models">
  <data key="d0">language models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Language models are computational systems designed to understand, generate, and manipulate human language, often used in natural language processing tasks.&lt;SEP&gt;Language models are computational systems designed to understand, generate, and process human language, used extensively in natural language processing tasks.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2304.02210">
  <data key="d0">arXiv preprint arXiv:2304.02210</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint publication on arXiv documenting research related to language models and their applications.&lt;SEP&gt;A preprint publication on arXiv reporting research related to language models and their applications.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruijie Wang, Zheng Li, Dachun Sun, Shengzhong Liu, Jinning Li, Bing Yin, and Tarek Abdelzaher">
  <data key="d0">Ruijie Wang, Zheng Li, Dachun Sun, Shengzhong Liu, Jinning Li, Bing Yin, and Tarek Abdelzaher</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">A group of researchers involved in studies on knowledge sampling, reasoning, and language model techniques.&lt;SEP&gt;A team of researchers conducting studies on reasoning, sampling, and aggregation in knowledge graphs and language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Learning to sample and aggregate: Few-shot reasoning over temporal knowledge graphs">
  <data key="d0">Learning to sample and aggregate: Few-shot reasoning over temporal knowledge graphs</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A theoretical framework or approach for performing reasoning tasks over temporal knowledge graphs with few-shot learning techniques.&lt;SEP&gt;A theoretical framework or model for performing reasoning over temporal knowledge graphs using few-shot learning techniques.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Guihong Cao, Daxin Jiang, Ming Zhou, et al.">
  <data key="d0">Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Guihong Cao, Daxin Jiang, Ming Zhou, et al.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">A group of researchers working on knowledge infusion, adapter-based models, and pre-trained language model enhancements.&lt;SEP&gt;A team of researchers contributing to studies on knowledge infusion into pre-trained models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="K-adapter: Infusing knowledge into pre-trained models with adapters">
  <data key="d0">K-adapter: Infusing knowledge into pre-trained models with adapters</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A method for integrating external knowledge into large language models using adapter modules to improve performance.&lt;SEP&gt;A methodology or approach for integrating external knowledge into language models using adapter modules.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2002.01808">
  <data key="d0">arXiv preprint arXiv:2002.01808</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint paper describing the K-adapter technique for knowledge infusion.&lt;SEP&gt;A preprint paper detailing the K-adapter technique for knowledge infusion in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou">
  <data key="d0">Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Researchers developing ensemble techniques, reasoning strategies, and rationale-based improvements for language models.&lt;SEP&gt;Researchers involved in developing ensemble techniques and reasoning methods for language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi">
  <data key="d0">Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Researchers studying self-instruction, alignment, and reasoning improvements in language models.&lt;SEP&gt;Researchers working on instruction tuning, self-instruction, and alignment techniques to improve language model capabilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Self-Instruct: Aligning Language Model with Self Generated Instructions">
  <data key="d0">Self-Instruct: Aligning Language Model with Self Generated Instructions</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A methodology for aligning language models by self-generated instruction data to improve task performance and safety.&lt;SEP&gt;A methodology for aligning language models through self-generated instructions to enhance performance and safety.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2211.00635">
  <data key="d0">arXiv preprint arXiv:2211.00635</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint describing the Self-Instruct technique for model alignment.&lt;SEP&gt;A preprint detailing techniques to preserve in-context learning abilities during model fine-tuning.&lt;SEP&gt;A preprint detailing techniques to preserve in-context learning during fine-tuning.&lt;SEP&gt;A preprint paper presenting self-instruction techniques for language model alignment.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yaqing Wang, Subhabrata Mukherjee, Xiaodong Liu, Jing Gao, Ahmed Hassan Awadallah, and Jianfeng Gao">
  <data key="d0">Yaqing Wang, Subhabrata Mukherjee, Xiaodong Liu, Jing Gao, Ahmed Hassan Awadallah, and Jianfeng Gao</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Researchers exploring parameter-efficient tuning, adapter methods, and model alignment for large language models.&lt;SEP&gt;Researchers working on parameter-efficient tuning and adaptation of large language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Adamix: Mixture-of-adapter for parameter-efficient tuning of large language models">
  <data key="d0">Adamix: Mixture-of-adapter for parameter-efficient tuning of large language models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A tuning approach combining multiple adapters to efficiently adapt large language models for diverse tasks.&lt;SEP&gt;A tuning approach combining multiple adapters to efficiently adapt large language models for various tasks.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2205.12410">
  <data key="d0">arXiv preprint arXiv:2205.12410</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint describing the Adamix method for efficient fine-tuning of large models.&lt;SEP&gt;A preprint describing the Adamix method for efficient fine-tuning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yihan Wang, Si Si, Daliang Li, Michal Lukasik, Felix Yu, Cho-Jui Hsieh, Inderjit S Dhillon, and Sanjiv Kumar">
  <data key="d0">Yihan Wang, Si Si, Daliang Li, Michal Lukasik, Felix Yu, Cho-Jui Hsieh, Inderjit S Dhillon, and Sanjiv Kumar</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Researchers exploring in-context learning and fine-tuning in large language models.&lt;SEP&gt;Researchers focused on preserving in-context learning abilities during fine-tuning of large language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Preserving In-Context Learning ability in Large Language Model Fine-tuning">
  <data key="d0">Preserving In-Context Learning ability in Large Language Model Fine-tuning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A framework or methodology aimed at maintaining the in-context learning capabilities of language models during the fine-tuning process.&lt;SEP&gt;A methodology or framework aimed at maintaining the in-context learning capabilities of language models during fine-tuning processes.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang">
  <data key="d0">Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Researchers developing interactive planning techniques with large language models for multi-task agents.&lt;SEP&gt;Researchers working on interactive planning and multi-task agents using large language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents">
  <data key="d0">Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A methodology for interactive planning and decision-making in multi-task agents utilizing large language models.&lt;SEP&gt;A methodology for open-world multi-task agent planning using large language models to facilitate description, explanation, and decision-making.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2302.01560">
  <data key="d0">arXiv preprint arXiv:2302.01560</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint paper describing interactive planning techniques for open-world multi-task agents.&lt;SEP&gt;A preprint paper presenting the interactive planning framework for multi-task agents.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le">
  <data key="d0">Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Researchers investigating emergent reasoning abilities, zero-shot learning, and chain-of-thought prompting in large language models.&lt;SEP&gt;Researchers studying zero-shot learning, emergent abilities, and chain-of-thought prompting in large language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Finetuned Language Models are Zero-Shot Learners">
  <data key="d0">Finetuned Language Models are Zero-Shot Learners</data>
  <data key="d1">Results</data>
  <data key="d2">Research demonstrating that fine-tuned language models can perform zero-shot learning tasks effectively.&lt;SEP&gt;Research demonstrating that fine-tuned large language models can perform zero-shot tasks effectively.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Emergent abilities of large language models">
  <data key="d0">Emergent abilities of large language models</data>
  <data key="d1">Results</data>
  <data key="d2">Findings that large language models develop unexpected capabilities as they scale.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chain-of-Thought Prompting Elicits Reasoning in Large Language Models">
  <data key="d0">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A prompting technique that encourages models to generate intermediate reasoning steps to improve complex problem-solving.&lt;SEP&gt;A prompting technique that guides models to generate intermediate reasoning steps to improve complex reasoning.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="arXiv preprint arXiv:2206.07682">
  <data key="d0">arXiv preprint arXiv:2206.07682</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A preprint describing the chain-of-thought prompting methodology.&lt;SEP&gt;A preprint presenting chain-of-thought prompting methodology.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stephen Wolfram">
  <data key="d0">Stephen Wolfram</data>
  <data key="d1">Researcher</data>
  <data key="d2">A scientist discussing enhancements and capabilities of ChatGPT with Wolfram's computational powers.&lt;SEP&gt;A scientist discussing enhancements to ChatGPT, including integration of Wolfram's computational superpowers.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ChatGPT Gets Its “Wolfram Superpowers”!">
  <data key="d0">ChatGPT Gets Its “Wolfram Superpowers”!</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">An article explaining how Wolfram's integration enhances ChatGPT's computational and reasoning powers.&lt;SEP&gt;An article explaining how integrating Wolfram's technology enhances ChatGPT's computational abilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann">
  <data key="d0">Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Researchers developing large language models for finance and other specialized domains.&lt;SEP&gt;Researchers working on domain-specific large language models, including finance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bloomberggpt: A large language model for finance">
  <data key="d0">Bloomberggpt: A large language model for finance</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A specialized language model designed for financial applications.&lt;SEP&gt;A specialized large language model tailored for financial data processing and analysis.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhuofeng Wu, Sinong Wang, Jiatao Gu, Rui Hou, Yuxiao Dong, V. G. Vinod Vydiswaran, and Hao Ma">
  <data key="d0">Zhuofeng Wu, Sinong Wang, Jiatao Gu, Rui Hou, Yuxiao Dong, V. G. Vinod Vydiswaran, and Hao Ma</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Researchers proposing instance-dependent prompt generation methods to improve model performance.&lt;SEP&gt;Researchers proposing instance-dependent prompt generation methods.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="IDPG: An Instance-Dependent Prompt Generation Method">
  <data key="d0">IDPG: An Instance-Dependent Prompt Generation Method</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A novel prompt generation approach that adapts prompts based on specific instances to enhance model responses.&lt;SEP&gt;A novel prompt generation technique that adapts to specific instances to improve language model performance.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Runxin Xu, Fuli Luo, Zhiyuan Zhang, Chuanqi Tan, Baobao Chang, Songfang Huang, and Fei Huang">
  <data key="d0">Runxin Xu, Fuli Luo, Zhiyuan Zhang, Chuanqi Tan, Baobao Chang, Songfang Huang, and Fei Huang</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Researchers focusing on effective fine-tuning strategies for large language models to improve generalization.&lt;SEP&gt;Researchers focusing on effective fine-tuning strategies for large language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Raise a child in large language model: Towards effective and generalizable fine-tuning">
  <data key="d0">Raise a child in large language model: Towards effective and generalizable fine-tuning</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A research paper on fine-tuning methods aimed at improving generalization and effectiveness.&lt;SEP&gt;A research paper on fine-tuning techniques aimed at improving model adaptability and robustness.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jingfeng Yang, Haoming Jiang, Qingyu Yin, Danqing Zhang, Bing Yin, and Diyi Yang">
  <data key="d0">Jingfeng Yang, Haoming Jiang, Qingyu Yin, Danqing Zhang, Bing Yin, and Diyi Yang</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Researchers working on semantic parsing, few-shot learning, and zero-shot models.&lt;SEP&gt;Researchers working on semantic parsing, few-shot learning, and zero-shot reasoning in language models.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="SEQZERO: Few-shot Compositional Semantic Parsing with Sequential Prompts and Zero-shot Models">
  <data key="d0">SEQZERO: Few-shot Compositional Semantic Parsing with Sequential Prompts and Zero-shot Models</data>
  <data key="d1">Results</data>
  <data key="d2">A study demonstrating advanced semantic parsing capabilities using sequential prompts and zero-shot learning approaches.&lt;SEP&gt;A study demonstrating advanced semantic parsing techniques using sequential prompts and zero-shot capabilities.</data>
  <data key="d3">chunk-130f4b29fc5e5322f823d6edfc5ef3c3</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Preprint arXiv:2109.05687">
  <data key="d0">Preprint arXiv:2109.05687</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A preprint identifier indicating a research paper hosted on arXiv from 2021, serving as a primary source for research data.&lt;SEP&gt;A research paper hosted on arXiv from 2021, serving as a primary source for research data.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jingfeng Yang">
  <data key="d0">Jingfeng Yang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in multiple studies on semantic parsing and language models, contributing to methodological advancements.&lt;SEP&gt;A researcher involved in surveys on large language models like ChatGPT.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Haoming Jiang">
  <data key="d0">Haoming Jiang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher collaborating on semantic parsing and language model research, focusing on few-shot learning.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Qingyu Yin">
  <data key="d0">Qingyu Yin</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to semantic parsing methodologies and model evaluation.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Danqing Zhang">
  <data key="d0">Danqing Zhang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in semantic parsing and natural language processing research.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Bing Yin">
  <data key="d0">Bing Yin</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on semantic parsing and language understanding models.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Diyi Yang">
  <data key="d0">Diyi Yang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher focusing on language models and their applications in computational linguistics.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hongye Jin">
  <data key="d0">Hongye Jin</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to language model research and survey studies.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ruixiang Tang">
  <data key="d0">Ruixiang Tang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on language model applications and evaluation frameworks.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xiaotian Han">
  <data key="d0">Xiaotian Han</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in language model research and experimental studies.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Qizhang Feng">
  <data key="d0">Qizhang Feng</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to language model research and model assessment.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xia Hu">
  <data key="d0">Xia Hu</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher focusing on language models and their practical deployment.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Kai-Cheng Yang">
  <data key="d0">Kai-Cheng Yang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher studying credibility assessment in news outlets using language models.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Filippo Menczer">
  <data key="d0">Filippo Menczer</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher exploring the capabilities of large language models in rating news credibility.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xianjun Yang">
  <data key="d0">Xianjun Yang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on prompt tuning frameworks for language models.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wei Cheng">
  <data key="d0">Wei Cheng</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher developing unified frameworks for prompt optimization.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xujiang Zhao">
  <data key="d0">Xujiang Zhao</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in dynamic prompting and language model tuning.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Linda Petzold">
  <data key="d0">Linda Petzold</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to adaptive optimization in language generation.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Haifeng Chen">
  <data key="d0">Haifeng Chen</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on ontology-enhanced prompt tuning for few-shot learning.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hui Chen">
  <data key="d0">Hui Chen</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in prompt-tuning methodologies.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Feiyu Xiong">
  <data key="d0">Feiyu Xiong</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on language model enhancement techniques.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Elad Ben Zaken">
  <data key="d0">Elad Ben Zaken</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher developing parameter-efficient fine-tuning methods for transformers.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shauli Ravfogel">
  <data key="d0">Shauli Ravfogel</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on efficient language model fine-tuning techniques.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yoav Goldberg">
  <data key="d0">Yoav Goldberg</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher exploring simple and effective fine-tuning strategies for language models.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yi Tay">
  <data key="d0">Yi Tay</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on advanced model architectures and parameterization.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shuai Zhang">
  <data key="d0">Shuai Zhang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in model parameterization and optimization.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alvin Chan">
  <data key="d0">Alvin Chan</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher focusing on model efficiency and fine-tuning methods.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jie Fu">
  <data key="d0">Jie Fu</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher exploring hypercomplex algebra in deep learning.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chaoning Zhang">
  <data key="d0">Chaoning Zhang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher conducting surveys on generative AI and ChatGPT evolution.&lt;SEP&gt;A researcher conducting surveys on generative AI and large language models.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chenshuang Zhang">
  <data key="d0">Chenshuang Zhang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher analyzing generative AI technologies.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sheng Zheng">
  <data key="d0">Sheng Zheng</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on AI model survey and analysis.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yu Qiao">
  <data key="d0">Yu Qiao</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in AI model evaluation and survey studies.&lt;SEP&gt;A researcher working on language model fine-tuning and adaptation.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chenghao Li">
  <data key="d0">Chenghao Li</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher studying generative AI frameworks.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Mengchun Zhang">
  <data key="d0">Mengchun Zhang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to AI model surveys.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sumit Kumar Dam">
  <data key="d0">Sumit Kumar Dam</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on AI model analysis.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chu Myaet Thwal">
  <data key="d0">Chu Myaet Thwal</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in AI and language model research.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ye Lin Tun">
  <data key="d0">Ye Lin Tun</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher exploring AI model architectures.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Le Luang Huy">
  <data key="d0">Le Luang Huy</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher focusing on AI model survey and evaluation.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhi Jin">
  <data key="d0">Zhi Jin</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to language model fine-tuning research.&lt;SEP&gt;A researcher working on language model optimization.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zhongjin Zhang">
  <data key="d0">Zhongjin Zhang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on model optimization techniques.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Yuqi Zhu">
  <data key="d0">Yuqi Zhu</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher exploring AI model parameterization.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Renrui Zhang">
  <data key="d0">Renrui Zhang</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher developing efficient fine-tuning methods like Llama-adapter.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jiaming Han">
  <data key="d0">Jiaming Han</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on domain adaptation and model tuning.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Aojun Zhou">
  <data key="d0">Aojun Zhou</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher exploring domain adaptation techniques.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Xiangfei Hu">
  <data key="d0">Xiangfei Hu</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher focusing on domain adaptation in language models.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Shilin Yan">
  <data key="d0">Shilin Yan</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in language model fine-tuning.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Pan Lu">
  <data key="d0">Pan Lu</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher working on model adaptation strategies.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hongsheng Li">
  <data key="d0">Hongsheng Li</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher contributing to model adaptation and fine-tuning.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Peng Gao">
  <data key="d0">Peng Gao</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher exploring model efficiency and adaptation.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Daniel M Ziegler">
  <data key="d0">Daniel M Ziegler</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher investigating fine-tuning from human preferences.&lt;SEP&gt;An author involved in research on language models and human preferences, contributing to AI methodology development.&lt;SEP&gt;An author who contributed to research on AI fine-tuning, particularly involving human preferences, impacting methodology development.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Nisan Stiennon">
  <data key="d0">Nisan Stiennon</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher focusing on alignment and fine-tuning of language models.&lt;SEP&gt;An author contributing to AI research, specifically in language model fine-tuning from human preferences.&lt;SEP&gt;An author involved in research on refining language models through human feedback, influencing AI training techniques.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Jeffrey Wu">
  <data key="d0">Jeffrey Wu</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher involved in large language model training and fine-tuning.&lt;SEP&gt;An author contributing to methods for improving language models with human preferences, advancing AI fine-tuning approaches.&lt;SEP&gt;An author involved in AI research, focusing on language model training and optimization.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Tom B Brown">
  <data key="d0">Tom B Brown</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher leading research on GPT models and fine-tuning techniques.&lt;SEP&gt;An author known for work on large language models and their training methodologies.&lt;SEP&gt;An author known for work on large language models, including GPT, and their training methodologies involving human preferences.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Alec Radford">
  <data key="d0">Alec Radford</data>
  <data key="d1">Researchers</data>
  <data key="d2">A pioneer in developing GPT models, contributing to AI methodology for large-scale language model training.&lt;SEP&gt;A researcher pioneering GPT architecture and development.&lt;SEP&gt;An author recognized for pioneering work in developing AI language models like GPT.&lt;SEP&gt;Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b&lt;SEP&gt;chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Paul Christiano">
  <data key="d0">Paul Christiano</data>
  <data key="d1">Researchers</data>
  <data key="d2">A researcher focused on AI alignment and preferences in model training.&lt;SEP&gt;An author focusing on AI alignment, preferences, and safety research.&lt;SEP&gt;An author specializing in AI alignment, preferences, and safety, contributing to theories on model behavior and safety protocols.</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c&lt;SEP&gt;chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="ChatGPT and environmental research">
  <data key="d0">ChatGPT and environmental research</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">This refers to the application of ChatGPT, an AI language model, within the context of environmental research, exploring its potential uses, benefits, and implications.</data>
  <data key="d3">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Environmental Science &amp; Technology">
  <data key="d0">Environmental Science &amp; Technology</data>
  <data key="d1">Discipline</data>
  <data key="d2">A peer-reviewed journal publishing research on environmental science, technology, and related interdisciplinary studies.&lt;SEP&gt;A scientific journal publishing research related to environmental science and technology.</data>
  <data key="d3">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Fine-tuning language models from human preferences">
  <data key="d0">Fine-tuning language models from human preferences</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A foundational approach in AI where language models are adjusted based on human feedback to improve performance and alignment.&lt;SEP&gt;A methodology where language models are adjusted based on human feedback to improve alignment with human values and specific task performance.</data>
  <data key="d3">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Environmental Research">
  <data key="d0">Environmental Research</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The field of scientific investigation focused on understanding environmental systems, issues, and solutions, which can benefit from AI tools like ChatGPT.</data>
  <data key="d3">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="AI Methodologies">
  <data key="d0">AI Methodologies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques and approaches for developing, fine-tuning, and applying AI models, including reinforcement learning, supervised fine-tuning, and preference-based training.</data>
  <data key="d3">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Research on ChatGPT and environmental research">
  <data key="d0">Research on ChatGPT and environmental research</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study investigates how ChatGPT can be applied to environmental research, assessing its potential, benefits, and limitations.</data>
  <data key="d3">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Techniques">
  <data key="d0">Techniques</data>
  <data key="d3">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d2">Techniques are applied within specific application domains to enhance the effectiveness of domain-specific LLMs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge">
  <data key="d0">Knowledge</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d2">Lack of domain-specific knowledge can cause LLMs to hallucinate, generating inaccurate information.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Extraction Techniques">
  <data key="d0">Knowledge Extraction Techniques</data>
  <data key="d3">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d2">LLMs depend on knowledge extraction techniques to incorporate domain knowledge, but face difficulties due to static training data.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Performance Enhancement">
  <data key="d0">Performance Enhancement</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d2">Scaling models by increasing parameters or data size improves their capacity for various NLP tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Application of">
  <data key="d0">Application of</data>
  <data key="d3">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d2">Domain adaptation techniques are applied to general LLMs to improve their performance in specific fields like medicine or finance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sequence Models">
  <data key="d0">Sequence Models</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d2">Ms are used for sequence-to-sequence tasks like translation and summarization, demonstrating their core concepts.&lt;SEP&gt;Ms are used for sequence-to-sequence tasks, illustrating their application in NLP.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Domain-specific Data">
  <data key="d0">Domain-specific Data</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d2">Fine-tuning updates model parameters with domain-specific data to improve task performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Internal Knowledge">
  <data key="d0">Internal Knowledge</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d2">Updating internal model knowledge with domain-specific text enhances specialization.&lt;SEP&gt;Updating the model's internal knowledge with domain-specific data enhances its specialization.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot and Few-shot Learning">
  <data key="d0">Zero-shot and Few-shot Learning</data>
  <data key="d3">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d2">Prompt engineering involves designing prompts to facilitate zero-shot or few-shot learning for domain adaptation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stages">
  <data key="d0">Stages</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d2">The framework encompasses four core stages—Definition, Augmentation, Optimization, and Evaluation—structured to systematically adapt models to domains.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Stage">
  <data key="d0">Stage</data>
  <data key="d3">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d2">Defines the domain, objectives, and constraints to guide subsequent steps in model adaptation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Specialized Tasks">
  <data key="d0">Specialized Tasks</data>
  <data key="d3">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d2">Domain tools are designed to handle specific tasks within a domain, often requiring strict input formats, and complement the general capabilities of LLMs."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="APIs and Tools">
  <data key="d0">APIs and Tools</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d2">Scripts generated by LLMs invoke domain-specific APIs to perform specialized functions like search or automation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="APIs">
  <data key="d0">APIs</data>
  <data key="d3">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d2">Scripts generated by LLMs call domain-specific APIs to perform functions like search, database queries, or automation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zero-shot CoT">
  <data key="d0">Zero-shot CoT</data>
  <data key="d3">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d2">Zero-shot Chain-of-Thoughts (CoT) prompts add reasoning steps to improve logical reasoning in LLM outputs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="prompt pre-training">
  <data key="d0">prompt pre-training</data>
  <data key="d3">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d2">Self-supervised learning is used to pre-train prompts on unlabeled data, facilitating better transfer and initialization."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Black-box Tuning">
  <data key="d0">Black-box Tuning</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d2">Black-box tuning is a gradient-free approach suitable for models with restricted access, aiming to optimize prompts without model gradients.&lt;SEP&gt;Black-box tuning is a gradient-free approach suitable for models with restricted access, aiming to optimize prompts without model gradients."|&gt;"gradient-free, model access</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="CMA-ES">
  <data key="d0">CMA-ES</data>
  <data key="d3">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d2">CMA-ES is used within black-box tuning to optimize prompts in non-convex, gradient-inaccessible scenarios.&lt;SEP&gt;CMA-ES is used within black-box tuning to optimize prompts in non-convex, gradient-inaccessible scenarios."|&gt;"optimization, non-convex</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="object of study">
  <data key="d0">object of study</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d2">Neural adapters are a class of adapter modules with neural network architectures used for domain adaptation."|&lt;"object</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Low-rank adapters">
  <data key="d0">Low-rank adapters</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d2">Low-rank adapters utilize low-rank matrix approximations to reduce parameters in adapter modules."|&lt;"object</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Invertible adapters">
  <data key="d0">Invertible adapters</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d2">Invertible adapters are a reversible class of neural adapters inspired by autoencoders, allowing for invertible transformations."|&lt;"object</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hypercomplex multiplication layers">
  <data key="d0">Hypercomplex multiplication layers</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d2">Hypercomplex multiplication layers are used within adapters like Compacters to improve parameter efficiency through learning sums of Kronecker products."|&lt;"tool</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="tools">
  <data key="d0">tools</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d2">Hypercomplex multiplication layers are used within adapters like Compacters to improve parameter efficiency through learning sums of Kronecker products."|&lt;"tool</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multi-head attention">
  <data key="d0">Multi-head attention</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d2">Multi-head attention layers are key points in transformers where adapters are often inserted to facilitate adaptation."|&lt;"object</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="domain adapters">
  <data key="d0">domain adapters</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d2">AdapterSoup combines weights of multiple domain adapters during testing to improve adaptation efficiency."|&lt;"relationship</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="large language model">
  <data key="d0">large language model</data>
  <data key="d3">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d2">LLaMA is a large language model architecture designed for efficient adaptation using adapters."|&lt;"relationship</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Multiple Tasks">
  <data key="d0">Multiple Tasks</data>
  <data key="d3">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d2">AdapterFusion combines multiple task-specific adapters via a fusion layer to improve overall performance across tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Knowledge Updates">
  <data key="d0">Knowledge Updates</data>
  <data key="d3">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d2">Knowledge updates based on explicit instructions risk causing catastrophic forgetting, which limits the model's ability to retain previous knowledge when learning new information.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Specialization">
  <data key="d0">Model Specialization</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d2">LLMs are fine-tuned with domain-specific data to understand complex terminologies and norms, ensuring accurate content generation in finance and legal fields.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Deep Understanding">
  <data key="d0">Deep Understanding</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d2">LLMs are trained to understand domain-specific terminologies and workflows, improving interface design and software development tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="HCI and Software Engineering">
  <data key="d0">HCI and Software Engineering</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d2">LLMs are trained to understand domain-specific terminologies and workflows, improving interface design and software development tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Model Fine-Tuning">
  <data key="d0">Model Fine-Tuning</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d2">LLMs are fine-tuned with domain-specific datasets to understand complex financial terminology and trends for accurate content generation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="HCI">
  <data key="d0">HCI</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d2">LLMs are trained to understand domain-specific terminologies and workflows, improving user interface design and interaction in HCI and software engineering.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Code Assistance">
  <data key="d0">Code Assistance</data>
  <data key="d3">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d2">LLMs assist in code generation, bug detection, and documentation, enhancing software development processes.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al">
  <data key="d0">Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d2">The researchers conducted a comprehensive study on delta tuning, indicating their direct involvement with this methodology.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Decomposing Complex Questions">
  <data key="d0">Decomposing Complex Questions</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d2">These researchers focus on successive prompting techniques to decompose complex questions, linking them to this methodology in NLP.&lt;SEP&gt;They are exploring successive prompting techniques to decompose complex questions, establishing a relationship between researchers and the methodology.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="PAL">
  <data key="d0">PAL</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d2">Researchers are developing PAL: program-aided language models, directly connecting them to this methodology for reasoning and task performance.&lt;SEP&gt;Researchers are developing program-aided language models (PAL) to enhance reasoning, directly linking them to this approach.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neural Language Models with Cache">
  <data key="d0">Neural Language Models with Cache</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d2">The researchers improved neural language models by adding a continuous cache, linking this methodology to context modeling and prediction enhancement.&lt;SEP&gt;The researchers improved neural language models by integrating a continuous cache, linking them to this methodology.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Sparse Adapter">
  <data key="d0">Sparse Adapter</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d2">The authors introduce sparse adapters to improve parameter efficiency, establishing their research connection.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="PPT">
  <data key="d0">PPT</data>
  <data key="d3">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d2">The authors developed pre-trained prompt tuning (PPT) for few-shot learning, directly linking this methodology to low-resource NLP applications.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Instance-aware Prompt Learning">
  <data key="d0">Instance-aware Prompt Learning</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d2">This approach improves language understanding and generation by customizing prompts based on specific instances or contexts.&lt;SEP&gt;This methodology improves language understanding and generation by customizing prompts based on specific instances or contexts.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Language Understanding and Generation">
  <data key="d0">Language Understanding and Generation</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d2">This approach improves language understanding and generation by customizing prompts based on specific instances or contexts.&lt;SEP&gt;This methodology improves language understanding and generation by customizing prompts based on specific instances or contexts.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="GeneGPT">
  <data key="d0">GeneGPT</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d2">GeneGPT augments large language models with domain tools to improve access and retrieval of biomedical information.&lt;SEP&gt;GeneGPT augments large language models with domain-specific tools to enhance access and retrieval of biomedical information.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Neural Language Models">
  <data key="d0">Neural Language Models</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d2">Scaling laws describe how increasing size and data improves neural language model performance, guiding model development.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Scaling Laws">
  <data key="d0">Scaling Laws</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d2">Empirical relationships describing how increasing model size influences performance in neural language models.&lt;SEP&gt;Scaling laws describe how increasing size and data improves neural language model performance, guiding model development.</data>
  <data key="d1">Theories/Models</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Efficient Neural Networks">
  <data key="d0">Efficient Neural Networks</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d2">Adapter layers like Compacter enable efficient adaptation of large language models through low-rank hypercomplex layers.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Complex Tasks">
  <data key="d0">Complex Tasks</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d2">Decomposed prompting provides a modular approach to solving complex tasks by breaking them into manageable components.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Dialogue Systems">
  <data key="d0">Dialogue Systems</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d2">Augmenting dialogue generation with internet access enhances the system's ability to retrieve relevant external information.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Medical NLP">
  <data key="d0">Medical NLP</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d2">Debates continue on the necessity and effectiveness of specialized clinical language models in medical NLP applications.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Large-scale Models">
  <data key="d0">Large-scale Models</data>
  <data key="d3">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d2">Frozen large language models serve as foundational, unchanging bases for various downstream tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Researcher">
  <data key="d0">Researcher</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d2">Reiichiro Nakano is involved in human factors and AI research, contributing to publications on language models and human feedback mechanisms."|&lt;SEP&gt;Reiichiro Nakano is involved in research on human factors and AI, contributing to studies on language models and human-AI interaction."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Organization">
  <data key="d0">Organization</data>
  <data key="d3">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d2">OpenAI develops large language models like GPT-4 and provides tools such as ChatGPT plugins and publishes technical reports."|&lt;SEP&gt;OpenAI develops large language models like GPT-4, offers tools such as ChatGPT plugins, and publishes technical reports."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Studies">
  <data key="d0">Studies</data>
  <data key="d3">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d2">Conducts systematic review on ChatGPT's utility in healthcare education, research, and practice, assessing future implications."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Manuscript">
  <data key="d0">Manuscript</data>
  <data key="d3">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d2">The arXiv preprint details the development, methodology, and applications of GingGPT for AI task solving."|&lt;SEP&gt;The preprint describes the development, methodology, and applications of GingGPT for solving AI tasks."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="SEZERO paper">
  <data key="d0">SEZERO paper</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Jingfeng Yang authored the paper on SEQZERO, a semantic parsing methodology involving few-shot learning.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Survey on ChatGPT">
  <data key="d0">Survey on ChatGPT</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Haoming Jiang contributed to a survey regarding ChatGPT and large language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Credibility Rating">
  <data key="d0">Credibility Rating</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Kai-Cheng Yang's research involves rating news outlet credibility using large language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Prompt Tuning Framework">
  <data key="d0">Prompt Tuning Framework</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Xianjun Yang developed a unified framework for prompt tuning in language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Detoxifying and Debiasing">
  <data key="d0">Detoxifying and Debiasing</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Zonghan Yang's work involves detoxifying and debiasing language generation via inference-time optimization.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Zonghan Yang">
  <data key="d0">Zonghan Yang</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Zonghan Yang's work involves detoxifying and debiasing language generation via inference-time optimization.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hongbin Ye">
  <data key="d0">Hongbin Ye</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Hongbin Ye contributed to ontology-enhanced prompt tuning for few-shot learning.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Ontology-Enhanced Prompt Tuning">
  <data key="d0">Ontology-Enhanced Prompt Tuning</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Hongbin Ye contributed to ontology-enhanced prompt tuning for few-shot learning.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Hypercomplex Parameterization">
  <data key="d0">Hypercomplex Parameterization</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Aston Zhang investigated hypercomplex parameterizations like quaternions for model layers.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Survey on Generative AI">
  <data key="d0">Survey on Generative AI</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Chaoning Zhang authored a comprehensive survey on generative AI and ChatGPT evolution.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Chain of Thought Prompting">
  <data key="d0">Chain of Thought Prompting</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Zhuosheng Zhang's research involves automatic chain of thought prompting in large language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Large Language Models Survey">
  <data key="d0">Large Language Models Survey</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Wayne Xin Zhao conducted a survey of large language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Wayne Xin Zhao">
  <data key="d0">Wayne Xin Zhao</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Wayne Xin Zhao conducted a survey of large language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="Preference Fine-tuning">
  <data key="d0">Preference Fine-tuning</data>
  <data key="d3">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d2">Daniel M Ziegler worked on fine-tuning language models based on human preferences.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</node>
<node id="HumanEval">
  <data key="d0">HumanEval</data>
  <data key="d1">Study Design</data>
  <data key="d2">A new evaluation set created to measure the functional correctness of code generated by models from docstrings.&lt;SEP&gt;HumanEval is a new evaluation set created to measure the functional correctness of code generated by models from docstrings, used to assess Codex and other models.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-J">
  <data key="d0">GPT-J</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">GPT-J is a language model evaluated for code synthesis, achieving 11.4% success rate on HumanEval.&lt;SEP&gt;GPT-J is a language model similar in scope to GPT-Neo, evaluated for code generation capabilities.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Python Code-Writing Capabilities">
  <data key="d0">Python Code-Writing Capabilities</data>
  <data key="d1">Results</data>
  <data key="d2">The study measures Codex's ability to generate correct Python code from docstrings, with a success rate of 28.8% on HumanEval, and shows that repeated sampling improves success to 70.2% with 100 samples per problem.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety, Security, Economics">
  <data key="d0">Safety, Security, Economics</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Broader impacts discussed include safety concerns, security risks, and economic effects of deploying powerful code generation models.&lt;SEP&gt;The paper discusses potential broader impacts of deploying powerful code generation models, including safety concerns, security risks, and economic effects.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Alex Ray">
  <data key="d0">Alex Ray</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Raul Puri">
  <data key="d0">Raul Puri</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Gretchen Krueger">
  <data key="d0">Gretchen Krueger</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Michael Petrov">
  <data key="d0">Michael Petrov</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Heidy Khlaaf">
  <data key="d0">Heidy Khlaaf</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Girish Sastry">
  <data key="d0">Girish Sastry</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pamela Mishkin">
  <data key="d0">Pamela Mishkin</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Brooke Chan">
  <data key="d0">Brooke Chan</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Scott Gray">
  <data key="d0">Scott Gray</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Nick Ryder">
  <data key="d0">Nick Ryder</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Mikhail Pavlov">
  <data key="d0">Mikhail Pavlov</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Alethea Power">
  <data key="d0">Alethea Power</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Mohammad Bavarian">
  <data key="d0">Mohammad Bavarian</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Clemens Winter">
  <data key="d0">Clemens Winter</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Philippe Tillet">
  <data key="d0">Philippe Tillet</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Felipe Petroski Such">
  <data key="d0">Felipe Petroski Such</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dave Cummings">
  <data key="d0">Dave Cummings</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Matthias Plappert">
  <data key="d0">Matthias Plappert</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Fotios Chantzis">
  <data key="d0">Fotios Chantzis</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Elizabeth Barnes">
  <data key="d0">Elizabeth Barnes</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ariel Herbert-Voss">
  <data key="d0">Ariel Herbert-Voss</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="William Hebgen Guss">
  <data key="d0">William Hebgen Guss</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Alex Nichol">
  <data key="d0">Alex Nichol</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Alex Paino">
  <data key="d0">Alex Paino</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Nikolas Tezak">
  <data key="d0">Nikolas Tezak</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jie Tang">
  <data key="d0">Jie Tang</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Igor Babuschkin">
  <data key="d0">Igor Babuschkin</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Andrew N. Carr">
  <data key="d0">Andrew N. Carr</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Josh Achiam">
  <data key="d0">Josh Achiam</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Vedant Misra">
  <data key="d0">Vedant Misra</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Evan Morikawa">
  <data key="d0">Evan Morikawa</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Matthew Knight">
  <data key="d0">Matthew Knight</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Miles Brundage">
  <data key="d0">Miles Brundage</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Mira Murati">
  <data key="d0">Mira Murati</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Katie Mayer">
  <data key="d0">Katie Mayer</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Peter Welinder">
  <data key="d0">Peter Welinder</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bob McGrew">
  <data key="d0">Bob McGrew</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sam McCandlish">
  <data key="d0">Sam McCandlish</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ilya Sutskever">
  <data key="d0">Ilya Sutskever</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Wojciech Zaremba">
  <data key="d0">Wojciech Zaremba</data>
  <data key="d1">Researchers</data>
  <data key="d2">Contributing author, involved in the study of language models and code generation.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GitHub">
  <data key="d0">GitHub</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Platform hosting publicly available code used to train Codex and other models.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code">
  <data key="d0">Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The source data, including publicly available code from GitHub, used to train Codex.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Functional Correctness">
  <data key="d0">Functional Correctness</data>
  <data key="d1">Results</data>
  <data key="d2">A metric used to evaluate whether generated code correctly performs the intended function, as used in benchmarking models.&lt;SEP&gt;BLEU scores overlap significantly between correct and incorrect solutions, indicating BLEU may not reliably measure functional correctness.&lt;SEP&gt;The measure of whether the generated code correctly implements the intended functionality, with Codex achieving 28.8% success.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-ba9b42eee12401dc9fac455e631a8fd8&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sampling">
  <data key="d0">Sampling</data>
  <data key="d1">Methodology</data>
  <data key="d2">Repeated sampling from the model to generate multiple candidate solutions, significantly improving success rates to 70.2% with 100 samples per problem.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Limitations of Codex">
  <data key="d0">Limitations of Codex</data>
  <data key="d1">Limitations</data>
  <data key="d2">Challenges faced by Codex, including difficulty with long chains of operations and variable binding in docstrings.</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="HumanEval dataset">
  <data key="d0">HumanEval dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A benchmark dataset consisting of 164 programming problems with associated unit tests, used to evaluate the correctness and performance of code generation models like Codex.&lt;SEP&gt;A curated set of 164 hand-written programming problems used to evaluate the functional correctness and problem-solving ability of code-generation models, containing problem descriptions, test cases, and solutions.&lt;SEP&gt;A dataset of 164 handwritten programming problems used to evaluate the functional correctness of code-generating models, containing problem descriptions, test cases, and solutions.&lt;SEP&gt;A dataset of 164 programming problems with unit tests used to evaluate the correctness and performance of code generation models.&lt;SEP&gt;The HumanEval dataset comprises 158 programming problems with descriptions, reference solutions, and test cases, used for evaluating code-generation models' accuracy and alignment.&lt;SEP&gt;The HumanEval dataset comprises 158 programming problems with descriptions, reference solutions, and tests used for evaluating code models.&lt;SEP&gt;The HumanEval dataset is a benchmark consisting of programming problems used to evaluate Codex's performance in code generation.</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-f37ccebb4e61f6d64cd2096830d27b04&lt;SEP&gt;chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Unit Tests">
  <data key="d0">Unit Tests</data>
  <data key="d1">Tools</data>
  <data key="d2">Automated testing procedures used to verify the correctness of code solutions, with filtering based on passing these tests.&lt;SEP&gt;Automated tests used to evaluate whether generated code functions correctly by passing predefined test cases.&lt;SEP&gt;Automated tests used to verify the correctness of generated code solutions, filtering out solutions that do not pass all tests.&lt;SEP&gt;Tests generated to verify code correctness, used in code generation and debugging activities, as mentioned by Tufano et al. (2020).&lt;SEP&gt;Unit tests are automated tests used to automatically evaluate the correctness of generated code by checking if the code passes predefined test cases.&lt;SEP&gt;Unit tests are automated tests used to evaluate the correctness of generated code, serving as an automatic evaluation metric for models like Codex.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-ba9b42eee12401dc9fac455e631a8fd8&lt;SEP&gt;chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="pass@k metric">
  <data key="d0">pass@k metric</data>
  <data key="d1">Variables</data>
  <data key="d2">A performance metric indicating the probability that at least one of the top k generated code samples passes all unit tests, used to assess functional correctness.&lt;SEP&gt;A performance metric used to evaluate the probability that at least one of the top k generated samples passes all unit tests, indicating functional correctness.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code synthesis from docstrings">
  <data key="d0">Code synthesis from docstrings</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study investigates how effectively models like Codex can generate correct standalone Python functions from natural language descriptions (docstrings) and how performance improves with multiple samples and fine-tuning.&lt;SEP&gt;The study investigates how well models like Codex can generate correct standalone Python functions from natural language descriptions (docstrings) and how performance improves with multiple samples and fine-tuning.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Evaluation framework">
  <data key="d0">Evaluation framework</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The methodology for benchmarking models using datasets like HumanEval and metrics such as pass@k to assess code correctness and model performance.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model training">
  <data key="d0">Model training</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Training processes including initial training on large datasets and subsequent fine-tuning on specific, correctly implemented functions to enhance accuracy.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Software engineering practices">
  <data key="d0">Software engineering practices</data>
  <data key="d1">Disciplines</data>
  <data key="d2">The application of AI models like Codex in software development, including code generation, testing, and validation workflows.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automated code evaluation">
  <data key="d0">Automated code evaluation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Using unit tests and pass@k metrics to automatically assess the correctness of generated code samples.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Benchmarking datasets">
  <data key="d0">Benchmarking datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Datasets like HumanEval serve as standardized benchmarks to evaluate and compare the performance of different code generation models.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model comparison">
  <data key="d0">Model comparison</data>
  <data key="d1">Results</data>
  <data key="d2">Comparing models like GPT-J, GPT-12B, and Codex models to assess their effectiveness in code generation tasks, with larger models generally performing better.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code generation challenges">
  <data key="d0">Code generation challenges</data>
  <data key="d1">Limitations</data>
  <data key="d2">Issues include the difficulty in generating syntactically correct, semantically accurate code, and the need for multiple samples and heuristics for improvement.</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="test-driven development">
  <data key="d0">test-driven development</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A software development framework that emphasizes converting requirements into test cases before implementation, with success defined by passing these tests.&lt;SEP&gt;A software development methodology that emphasizes writing tests before implementation, ensuring that code meets specified requirements and passes all tests.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="unit tests">
  <data key="d0">unit tests</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Automated tests created from examples, problem statements, or additional test cases to verify correctness of functions in code.&lt;SEP&gt;Automated tests designed to verify individual units or components of code, used to validate correctness during development.&lt;SEP&gt;Automated tests designed to verify the correctness of individual code units, integral to test-driven development.&lt;SEP&gt;Unit tests are automated testing procedures created from examples, problem statements, or additional test cases to verify the correctness of code functions.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda&lt;SEP&gt;chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="pass@kmetric">
  <data key="d0">pass@kmetric</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A metric used to evaluate the functional correctness of models trained on code by measuring the proportion of problems solved with at least one passing sample among k samples, accounting for variance in evaluation.&lt;SEP&gt;A metric used to evaluate the functional correctness of models trained on code by measuring the proportion of problems solved with at least one passing sample among k samples.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="functional correctness">
  <data key="d0">functional correctness</data>
  <data key="d1">Results</data>
  <data key="d2">A measure of whether code performs its intended function, beyond just matching reference outputs.&lt;SEP&gt;A measure of whether the program performs its intended function, beyond syntactic similarity.&lt;SEP&gt;The degree to which a program's outputs align with its specified requirements, assessed through metrics like pass@k and unit test success.&lt;SEP&gt;The degree to which a program's outputs meet specified requirements, evaluated using metrics like pass@k and through unit tests.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83&lt;SEP&gt;chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Large Language Models trained on code">
  <data key="d0">Large Language Models trained on code</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models such as Codex that are trained on large datasets of code to generate and evaluate programming solutions.&lt;SEP&gt;Models such as Codex that are trained on large datasets of code to generate, evaluate, and improve programming solutions, demonstrating problem-solving capabilities.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="sandbox environment">
  <data key="d0">sandbox environment</data>
  <data key="d1">Tools</data>
  <data key="d2">A secure execution environment designed to safely run untrusted generated programs against unit tests, utilizing technologies like gVisor and eBPF firewalls.&lt;SEP&gt;A secure execution environment designed to safely run untrusted or generated code against unit tests, preventing malicious activity or host compromise, often utilizing containerization technologies.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="gVisor container runtime">
  <data key="d0">gVisor container runtime</data>
  <data key="d1">Tools</data>
  <data key="d2">A container runtime that emulates host resources to isolate and protect the host environment from malicious or faulty containers.&lt;SEP&gt;A container runtime that emulates host resources to isolate and protect the host system from malicious or faulty containers, used in the sandbox environment.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="BLEU score">
  <data key="d0">BLEU score</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A metric for comparing the similarity between generated code and reference solutions, often used for evaluation but may not reliably indicate functional correctness.&lt;SEP&gt;A metric for evaluating the similarity between generated code and reference solutions, which may not reliably indicate functional correctness.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="programming tasks in HumanEval">
  <data key="d0">programming tasks in HumanEval</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Specific programming problems in the HumanEval dataset that assess language comprehension, reasoning, algorithms, and mathematics, used to measure model problem-solving performance.&lt;SEP&gt;Tasks assessing language comprehension, reasoning, algorithms, and mathematics, used to measure model problem-solving capabilities.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="code fine-tuning">
  <data key="d0">code fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of adapting pre-trained GPT models on code datasets to enhance their ability to generate correct programming solutions.&lt;SEP&gt;The process of adapting pre-trained language models like GPT on code datasets to improve their ability to generate correct and efficient code solutions.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="problem-solving capabilities">
  <data key="d0">problem-solving capabilities</data>
  <data key="d1">Variables</data>
  <data key="d2">The ability of models to understand, reason about, and produce correct code solutions for programming problems.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="training datasets">
  <data key="d0">training datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Large collections of code repositories, such as GitHub, used to train models like Codex to learn programming patterns and solutions.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="security risk">
  <data key="d0">security risk</data>
  <data key="d1">Limitations</data>
  <data key="d2">Potential dangers associated with executing untrusted generated code, including malicious activity, data exfiltration, or system compromise, mitigated by sandboxing.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="problem generation">
  <data key="d0">problem generation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques used to create programming problems, either hand-written or automatically generated, for training or evaluation purposes.</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Fine-Tuning">
  <data key="d0">Fine-Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Fine-tuning is a process of training a pre-trained model on a smaller, task-specific dataset to enhance its performance on particular tasks.&lt;SEP&gt;Fine-tuning refers to the process of adapting a pre-trained language model, such as GPT, to specific tasks or datasets by further training on task-specific data, enhancing performance on those tasks.&lt;SEP&gt;Training a pre-trained model on additional data to improve its performance on specific tasks.</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT models">
  <data key="d0">GPT models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">GPT models are large-scale language models with up to 12 billion parameters, used as the base for fine-tuning to produce specialized models like Codex.</data>
  <data key="d3">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Language Modeling">
  <data key="d0">Language Modeling</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Language modeling involves developing algorithms and statistical models that can understand, generate, and predict human language, often used in natural language processing tasks.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sample Selection">
  <data key="d0">Sample Selection</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Sample selection strategies in language modeling include choosing samples based on highest mean token log probability or sum log probability to improve performance.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Token Log Probability">
  <data key="d0">Token Log Probability</data>
  <data key="d1">Variables</data>
  <data key="d2">Token log probability measures the likelihood of tokens in a sequence, used as a heuristic in evaluating sample quality.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pass@k">
  <data key="d0">Pass@k</data>
  <data key="d1">Results</data>
  <data key="d2">A performance metric indicating the percentage of correct solutions within the top k generated outputs, used to evaluate code models.&lt;SEP&gt;Pass@k measures the probability that the model's solution passes at least one of k attempts, used to evaluate code generation accuracy.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="BLEU Score">
  <data key="d0">BLEU Score</data>
  <data key="d1">Results</data>
  <data key="d2">BLEU scores evaluate the similarity between generated solutions and reference solutions, indicating potential correctness but not guaranteed functional accuracy.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex-12B">
  <data key="d0">Codex-12B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Codex-12B is a large language model designed for code generation, trained on extensive compute resources and internet-sourced code repositories like GitHub.&lt;SEP&gt;Codex-12B is a large language model designed for code generation, trained on significant computational resources and data sources like GitHub repositories.&lt;SEP&gt;Codex-12B is a large language model fine-tuned on training problems, used to generate code samples and verify problem solvability via unit tests.&lt;SEP&gt;Codex-12B is a large language model trained on code, used to generate and evaluate programming solutions.&lt;SEP&gt;Large language model trained on curated problems, used to generate code samples and verify solutions via unit tests.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda&lt;SEP&gt;chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-Neo">
  <data key="d0">GPT-Neo</data>
  <data key="d1">Model</data>
  <data key="d2">A family of large language models trained on code, evaluated for performance with different parameter sizes and filtering approaches.&lt;SEP&gt;A large-scale autoregressive language model designed for natural language processing tasks.&lt;SEP&gt;GPT-Neo is an open-source language model trained on diverse datasets, including code, evaluated for programming performance.&lt;SEP&gt;GPT-Neo is an open-source language model assessed for perplexity and code generation, with fine-tuning on HPC datasets to improve HPC-specific code generation.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879&lt;SEP&gt;chunk-08628624fca4ace77b10c93f87dd3bd5&lt;SEP&gt;chunk-54d0e5495bc4b24b68d3cbc1c13d835e&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="APPS Dataset">
  <data key="d0">APPS Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The APPS dataset contains 5000 training and 5000 test programming problems with unit tests, used to benchmark coding models.&lt;SEP&gt;The APPS dataset includes 5000 training and 5000 test programming problems with unit tests, used for benchmarking.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sample Diversity">
  <data key="d0">Sample Diversity</data>
  <data key="d1">Variables</data>
  <data key="d2">Higher temperature settings increase sample diversity, which can influence the performance of language models in generating solutions.&lt;SEP&gt;Increased diversity at higher temperatures can lead to better coverage of potential solutions.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Heuristics">
  <data key="d0">Heuristics</data>
  <data key="d1">Tools</data>
  <data key="d2">Heuristics such as selecting samples with highest mean log probability or back-translation scores are used to improve sample quality during evaluation.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Back-Translation Score">
  <data key="d0">Back-Translation Score</data>
  <data key="d1">Variables</data>
  <data key="d2">Back-translation score is a metric used to select the best solution among multiple samples, indicating solution quality.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Performance Scaling">
  <data key="d0">Performance Scaling</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Model performance scales smoothly with size following a sigmoid pattern as parameters increase.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Results on Benchmarks">
  <data key="d0">Results on Benchmarks</data>
  <data key="d1">Results</data>
  <data key="d2">Models like Codex, GPT-Neo, and GPT-J demonstrate varying levels of success on coding benchmarks, with Codex generally outperforming others.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Limitations of BLEU">
  <data key="d0">Limitations of BLEU</data>
  <data key="d1">Limitations</data>
  <data key="d2">BLEU scores may not reflect the actual functional correctness of solutions, as overlaps exist between correct and incorrect outputs.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Performance Scaling">
  <data key="d0">Model Performance Scaling</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Performance improves with larger models, following a sigmoid pattern as the number of parameters increases.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sample Selection Strategies">
  <data key="d0">Sample Selection Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Strategies such as highest mean log probability or back-translation scores improve the likelihood of selecting correct solutions from multiple samples.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Heuristic Effectiveness">
  <data key="d0">Heuristic Effectiveness</data>
  <data key="d1">Results</data>
  <data key="d2">Using heuristics like mean log probability enhances the chances of selecting functionally correct solutions compared to random sampling.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Trade-offs in Evaluation">
  <data key="d0">Trade-offs in Evaluation</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Evaluating whether BLEU scores correlate with functional correctness remains an open question, given significant overlap in score distributions.</data>
  <data key="d3">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Variance Reduction Measure">
  <data key="d0">Variance Reduction Measure</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A statistical approach used to decrease the variability of measurements by reporting a specific metric to improve accuracy.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Strict Accuracy">
  <data key="d0">Strict Accuracy</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A focused metric that emphasizes precise correctness in evaluating model performance.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-J 6B">
  <data key="d0">GPT-J 6B</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large language model evaluated for code generation, with performance metrics such as pass@1, pass@10, and pass@100, indicating its ability to generate correct code solutions.&lt;SEP&gt;A large language model evaluated for its code generation performance, with pass@1 between 11.62% and 15.74% depending on the setting.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex Models">
  <data key="d0">Codex Models</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A series of large language models trained on code, evaluated across different sizes (e.g., 12M to 12B parameters) for code generation accuracy.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="TabNine">
  <data key="d0">TabNine</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An AI code completion tool evaluated for its effectiveness in generating correct code snippets, with pass@k metrics.&lt;SEP&gt;An AI code completion tool evaluated for its performance in code generation, with pass@1 around 2.58% to 4.35%.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Filtered Pass@k">
  <data key="d0">Filtered Pass@k</data>
  <data key="d1">Results</data>
  <data key="d2">A modified pass@k metric calculated after filtering solutions that pass all unit tests, providing a more accurate measure of correct solutions.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Time-out">
  <data key="d0">Time-out</data>
  <data key="d1">Limitations</data>
  <data key="d2">A constraint where solutions exceeding a 3-second execution time are considered non-passing, affecting the evaluation of code efficiency.&lt;SEP&gt;A constraint where solutions exceeding a 3-second execution time are considered non-passing, impacting the evaluation of code efficiency.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Supervised Fine-Tuning">
  <data key="d0">Supervised Fine-Tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A training approach where models are further trained on curated datasets of correct solutions to improve performance.&lt;SEP&gt;A training process where models are further trained on curated datasets of correct solutions to improve performance on code generation tasks.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Problems from Competitive Programming">
  <data key="d0">Problems from Competitive Programming</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A dataset collection approach using problems with well-defined solutions and hidden test cases from programming contests to enhance model training.&lt;SEP&gt;A dataset collection method involving problems with hidden test cases and well-defined solutions to enhance model training.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Problems from Continuous Integration">
  <data key="d0">Problems from Continuous Integration</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A dataset collection approach using input/output traces from open-source projects during automated testing to improve model training.&lt;SEP&gt;A dataset collection method utilizing function input/output traces from open-source projects during automated testing.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Training Problems Dataset">
  <data key="d0">Training Problems Dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A curated set of 10,000 programming problems assembled from competitive programming and open-source projects for model fine-tuning.&lt;SEP&gt;A curated set of 10,000 programming problems assembled from competitive programming and open-source repositories for model fine-tuning.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Filtered pass@k">
  <data key="d0">Filtered pass@k</data>
  <data key="d1">Results</data>
  <data key="d2">A modified pass@k metric calculated after solutions pass all unit tests, giving a more accurate measure of correct solutions.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Performance Gains">
  <data key="d0">Performance Gains</data>
  <data key="d1">Results</data>
  <data key="d2">Improvements in model accuracy achieved through supervised fine-tuning on curated datasets.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dataset Curation">
  <data key="d0">Dataset Curation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The process of collecting and assembling datasets from competitive programming problems and open-source projects to facilitate supervised fine-tuning.</data>
  <data key="d3">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="examples">
  <data key="d0">examples</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Examples are sample inputs and outputs used to create and validate unit tests, aiding in verifying code correctness.&lt;SEP&gt;Sample input-output pairs used to generate and validate unit tests, aiding in ensuring code correctness.&lt;SEP&gt;Sample inputs and expected outputs illustrating the intended behavior of the multiply function.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda&lt;SEP&gt;chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="problem statements">
  <data key="d0">problem statements</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Descriptions of programming problems outlining requirements and specifications for solution development.&lt;SEP&gt;Problem statements define the requirements and specifications for coding problems, serving as a basis for creating test cases.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="additional test cases">
  <data key="d0">additional test cases</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Additional test cases are supplementary inputs and expected outputs used to expand testing coverage and ensure robustness.&lt;SEP&gt;Extra test inputs and expected outputs used to expand testing coverage and verify robustness of solutions.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="problems">
  <data key="d0">problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Curated programming challenges sourced from open source projects, used for training models and evaluating performance.&lt;SEP&gt;Problems refer to programming challenges curated from open source projects, used for training and testing models.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="continuous integration (CI)">
  <data key="d0">continuous integration (CI)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Continuous Integration is a practice where code is regularly tested and integrated through automated processes, often utilizing tools like Travis and Tox to run build and test commands.&lt;SEP&gt;Development practice involving automated building, testing, and integration of code changes, often using tools like Travis and Tox.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="sys.setprofile">
  <data key="d0">sys.setprofile</data>
  <data key="d1">Tools</data>
  <data key="d2">Python function used to trace function calls during execution, enabling collection of inputs and outputs for testing purposes.&lt;SEP&gt;sys.setprofile is a Python function used to trace and collect inputs and outputs during function calls in integration tests.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="tracing">
  <data key="d0">tracing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Process of monitoring function calls during code execution to gather data for creating unit tests and understanding code flow.&lt;SEP&gt;Tracing involves monitoring function calls during execution to gather data for creating unit tests and understanding code behavior.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GitHub repos">
  <data key="d0">GitHub repos</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">GitHub repositories are sources of open source code projects that employ CI frameworks like Travis and Tox for automated testing.&lt;SEP&gt;Open source code repositories hosting projects that employ CI frameworks like Travis and Tox for automated testing.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="travis and tox">
  <data key="d0">travis and tox</data>
  <data key="d1">Tools</data>
  <data key="d2">Popular CI tools used to automate build, dependency installation, and testing processes in software projects.&lt;SEP&gt;Travis and Tox are popular CI tools used to automate build, dependency installation, and testing processes in software projects.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Python Package Index (PyPI)">
  <data key="d0">Python Package Index (PyPI)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">PyPI is a repository of Python packages from which source code can be sourced for analysis and problem creation.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="evaluating large language models trained on code">
  <data key="d0">evaluating large language models trained on code</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigation into the performance of fine-tuned models like GPT-Neo and Codex on code generation tasks, assessing their ability to produce passing programs.&lt;SEP&gt;The study investigates the performance of fine-tuned GPT-Neo and Codex models on programming tasks, assessing their ability to generate passing programs based on test data.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="fine-tuned GPT-Neo">
  <data key="d0">fine-tuned GPT-Neo</data>
  <data key="d1">Methodologies</data>
  <data key="d2">GPT-Neo models are fine-tuned on curated programming problems to evaluate their code generation performance, using parameters like temperature during sampling.&lt;SEP&gt;GPT-Neo models are fine-tuned on curated programming problems to evaluate their coding performance, with specific parameters like temperature used during sampling.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="unit test failure">
  <data key="d0">unit test failure</data>
  <data key="d1">Results</data>
  <data key="d2">Failing unit tests indicate the generated program did not meet the problem specifications, highlighting issues with model accuracy or problem ambiguity.&lt;SEP&gt;Outcome where generated code does not pass the unit tests, indicating issues with model accuracy or problem ambiguity.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="python package index (PyPI)">
  <data key="d0">python package index (PyPI)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Repository of Python packages from which source code is sourced for analysis, problem creation, and model training.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="filtering problems">
  <data key="d0">filtering problems</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Process of selecting problems based on whether generated samples pass unit tests, to ensure quality and reduce ambiguity.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="sampling">
  <data key="d0">sampling</data>
  <data key="d1">Tools</data>
  <data key="d2">Technique of generating multiple code samples from models with specific parameters like temperature to assess performance.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="sandboxed environment">
  <data key="d0">sandboxed environment</data>
  <data key="d1">Tools</data>
  <data key="d2">Isolated execution environment used to run untrusted code safely during testing and evaluation.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="untrusted code">
  <data key="d0">untrusted code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code that has not been verified for safety or correctness, requiring sandboxed environments for execution.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="problem filtering">
  <data key="d0">problem filtering</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Technique of removing ambiguous or non-deterministic problems by re-evaluating generated samples against unit tests.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="learning rate">
  <data key="d0">learning rate</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameter controlling the speed of model training, set to a specific value (e.g., 1/10 of usual) during fine-tuning of Codex.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="validation loss">
  <data key="d0">validation loss</data>
  <data key="d1">Variables</data>
  <data key="d2">Metric used to determine when to stop training, indicating the model's performance on validation data.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="temperature">
  <data key="d0">temperature</data>
  <data key="d1">Variables</data>
  <data key="d2">Parameter controlling randomness in code sampling during model evaluation, affecting diversity and accuracy of generated outputs.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="pass@k evaluation">
  <data key="d0">pass@k evaluation</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Method of assessing model performance by measuring the percentage of solutions passing unit tests within the top k generated samples.</data>
  <data key="d3">chunk-18f91435491c87cd10d4cbb056061eda</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Temperature">
  <data key="d0">Temperature</data>
  <data key="d1">Variables</data>
  <data key="d2">Temperature controls the randomness of token sampling; lower temperatures make the model more conservative, higher temperatures increase diversity.&lt;SEP&gt;Temperature controls the randomness of token selection; lower temperatures favor high-probability tokens, higher temperatures promote diversity.&lt;SEP&gt;Temperature is a sampling parameter used during model evaluation to control randomness in generated outputs, with optimal temperatures varying based on the model and task.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="pass@100">
  <data key="d0">pass@100</data>
  <data key="d1">Results</data>
  <data key="d2">pass@100 measures the success rate when considering the top 100 generated samples, reflecting the model's ability to produce correct outputs within multiple attempts.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex-S">
  <data key="d0">Codex-S</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Codex-S is a variant of the Codex model that captures a narrower distribution, requiring adjustments in sampling temperature for optimal performance.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex-D">
  <data key="d0">Codex-D</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Codex-D is a model trained specifically for generating docstrings, aiming to produce descriptive comments for code to improve safety and understanding.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Training Dataset">
  <data key="d0">Training Dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The dataset used to train the language model, comprising data on which the model is fine-tuned.&lt;SEP&gt;The training dataset includes problems with function signatures, reference solutions, and docstrings used to train models like Codex-D for code and docstring generation.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Optimal Temperature">
  <data key="d0">Optimal Temperature</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Optimal temperature is determined empirically for evaluating pass@k, balancing the distribution of generated samples to maximize success rates.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Back-Translation">
  <data key="d0">Back-Translation</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Back-translation is an evaluation method where generated samples are translated back to the original format to assess quality, used for ranking samples in model selection.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Negative Log-Likelihood">
  <data key="d0">Negative Log-Likelihood</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Negative log-likelihood minimization is used during training to optimize models like Codex and Codex-D for generating reference solutions and docstrings respectively.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Human Grading">
  <data key="d0">Human Grading</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Manual grading of generated docstrings involves human assessment to determine correctness, especially when automatic evaluation is not feasible.</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Python code on GitHub">
  <data key="d0">Python code on GitHub</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A vast collection of publicly available Python source code used to train Codex, enabling it to learn coding patterns and syntax.&lt;SEP&gt;A vast dataset comprising hundreds of millions of lines of Python code used for training Codex.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code generation models">
  <data key="d0">Code generation models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models designed to automatically produce code snippets based on prompts, with performance measured by pass rates and accuracy.&lt;SEP&gt;Models designed to automatically produce code snippets or solutions based on natural language prompts, evaluated by metrics like pass rates and correctness.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Back-translation">
  <data key="d0">Back-translation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A heuristic method to rank generated code samples by translating code into another form (e.g., natural language) and assessing quality, though it underperforms compared to likelihood-based ranking.&lt;SEP&gt;A heuristic technique used to rank sample outputs by translating code back into natural language or other representations, though it underperforms compared to mean log-probability ranking.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Mean log-probability ranking">
  <data key="d0">Mean log-probability ranking</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A ranking approach based on the likelihood scores assigned to generated samples, shown to outperform back-translation in sample ranking tasks.&lt;SEP&gt;A ranking method based on the likelihood assigned to generated samples, shown to outperform back-translation in the study.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hazard analysis">
  <data key="d0">Hazard analysis</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A systematic assessment conducted to identify potential safety risks, societal hazards, and misuse potential associated with Codex's deployment.&lt;SEP&gt;A systematic assessment to identify potential safety risks, societal impacts, and hazards associated with deploying Codex.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Societal impacts">
  <data key="d0">Societal impacts</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Potential positive impacts include onboarding, reducing context switching, enabling non-programmers to write code, and educational uses, but also pose safety risks and potential misuse.&lt;SEP&gt;Potential positive uses include onboarding, reducing context switching, aiding non-programmers, and educational applications, but also include safety risks and misuse potential.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety challenges">
  <data key="d0">Safety challenges</data>
  <data key="d1">Results</data>
  <data key="d2">Identified risks such as unsafe code, misalignment with user intent, and societal hazards that require careful consideration in deployment.&lt;SEP&gt;Issues such as misaligned code, unsafe outputs, and hazards of misuse are identified as significant safety concerns.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="System-level synthesis">
  <data key="d0">System-level synthesis</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The ability of Codex to generate code that interacts with system components, which is limited and can lead to errors in complex tasks.&lt;SEP&gt;The ability of Codex to generate code that interacts with system components, which is limited and prone to errors, especially in complex, multi-operation scenarios.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Performance metrics">
  <data key="d0">Performance metrics</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics such as pass rates, which decrease exponentially with increasing complexity or length of prompts, reflecting the model's performance degradation.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Synthetic problem dataset">
  <data key="d0">Synthetic problem dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A set of artificially constructed problems from basic building blocks used to evaluate Codex's performance on chained operations and complexity.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Chained components in docstrings">
  <data key="d0">Chained components in docstrings</data>
  <data key="d1">Variables</data>
  <data key="d2">The number of chained operations or instructions in a docstring, which correlates with the exponential decrease in Codex's success rate.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Binding errors">
  <data key="d0">Binding errors</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Errors where Codex fails to correctly associate operations with variables, leading to incorrect code outputs, especially with multiple variables and operations.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Societal hazards">
  <data key="d0">Societal hazards</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Risks related to misuse, unsafe code, and societal impacts stemming from automated code generation systems like Codex.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Potential hazards">
  <data key="d0">Potential hazards</data>
  <data key="d1">Results</data>
  <data key="d2">Risks such as unsafe code, misaligned outputs, and societal harms identified through hazard analysis.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Broader impacts">
  <data key="d0">Broader impacts</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The broader societal and practical implications of deploying Codex, including benefits and safety concerns.</data>
  <data key="d3">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="safety features">
  <data key="d0">safety features</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Safety features refer to the attributes and mechanisms designed to ensure the safe use of code generation models, including risk mitigation strategies and oversight requirements.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="models">
  <data key="d0">models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Large language models based on GPT-2 and GPT-3 architectures, used for language modeling and code analysis, selected for their size, pre-training data, and deployability.&lt;SEP&gt;Large language models based on GPT-2 and GPT-3 architectures, used for language understanding, code analysis, and tasks related to natural language processing and code comprehension.&lt;SEP&gt;Models in this context refer to the code generation systems described in the paper, particularly focusing on their properties, limitations, and impact.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb&lt;SEP&gt;chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="impact analysis">
  <data key="d0">impact analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Impact analysis involves systematically assessing the potential effects, risks, and safety concerns associated with deploying code generation models.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="risk mitigation">
  <data key="d0">risk mitigation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Risk mitigation encompasses strategies and practices aimed at reducing the likelihood and severity of adverse outcomes from code generation models.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="over-reliance">
  <data key="d0">over-reliance</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Over-reliance is a key risk hypothesized to lead to safety issues, especially when users depend excessively on generated outputs without adequate oversight.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="misalignment">
  <data key="d0">misalignment</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Misalignment describes the discrepancy between what the model is capable of doing and what it actually does in practice, often leading to unhelpful or harmful outputs.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="bias and representation">
  <data key="d0">bias and representation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Bias and representation issues pertain to the tendency of models like Codex to generate outputs reflecting societal stereotypes, harmful biases, or prejudiced content, raising safety and ethical concerns.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="training distribution">
  <data key="d0">training distribution</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The training distribution refers to the data on which the models are trained, influencing their behavior, biases, and alignment with user intentions.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="empirical investigation">
  <data key="d0">empirical investigation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Empirical investigation involves collecting data and conducting experiments to understand how safety measures and vigilance can be reliably ensured across different user scenarios.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="human oversight">
  <data key="d0">human oversight</data>
  <data key="d1">Tools</data>
  <data key="d2">Human oversight refers to the active monitoring and intervention by humans to ensure the safe and correct use of code generation systems.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="automation bias">
  <data key="d0">automation bias</data>
  <data key="d1">Variables</data>
  <data key="d2">Automation bias is a cognitive bias where users overly trust automated outputs, potentially leading to safety risks in code generation.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety Features">
  <data key="d0">Safety Features</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Safety features encompass mechanisms, attributes, and practices designed to ensure the secure and responsible use of code generation models, including risk mitigation strategies, oversight, and impact analysis.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Impact Analysis">
  <data key="d0">Impact Analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Impact analysis refers to systematic evaluation of potential risks, harms, and societal effects associated with deploying code generation models, aiming to inform safety practices.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Risks">
  <data key="d0">Risks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Risks are potential adverse outcomes or harms that may arise from using code generation models, especially subtle or hard-to-detect issues like over-reliance, misalignment, and bias.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Over-reliance">
  <data key="d0">Over-reliance</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Over-reliance is hypothesized as a key risk, involving excessive dependence on generated outputs which may lead to safety and correctness issues, especially for novice users.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Misalignment">
  <data key="d0">Misalignment</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Misalignment describes the discrepancy between the model's outputs and the user's intentions, often leading to unhelpful, incorrect, or harmful code despite the model's capabilities.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias and Representation">
  <data key="d0">Bias and Representation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Bias and representation issues involve the tendency of models to generate outputs reflecting societal stereotypes, prejudices, or harmful biases, influenced by training data.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Training Distribution">
  <data key="d0">Training Distribution</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The training distribution refers to the dataset used to train models like Codex, significantly affecting their behavior, biases, and potential for misalignment.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Empirical Investigation">
  <data key="d0">Empirical Investigation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Empirical investigation involves data collection and experiments aimed at understanding how to reliably ensure safety, vigilance, and effective oversight across user scenarios.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Human Oversight">
  <data key="d0">Human Oversight</data>
  <data key="d1">Tools</data>
  <data key="d2">Human oversight includes active monitoring, review, and intervention by humans to mitigate risks, ensure safety, and correct model outputs.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automation Bias">
  <data key="d0">Automation Bias</data>
  <data key="d1">Variables</data>
  <data key="d2">Automation bias is a cognitive tendency where users overly trust automated outputs, which can lead to safety issues if not properly managed.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety Impact">
  <data key="d0">Safety Impact</data>
  <data key="d1">Results</data>
  <data key="d2">The safety impact encompasses the potential positive or negative effects of deploying code generation models, including harms, benefits, and societal implications.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Risk Mitigation Strategies">
  <data key="d0">Risk Mitigation Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Risk mitigation strategies include practices, guidelines, and technical measures designed to reduce hazards associated with code generation models.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Limitations">
  <data key="d0">Model Limitations</data>
  <data key="d1">Limitations</data>
  <data key="d2">Codex struggles with generating certain payloads like SQL and shell injection, and does not outperform basic security tools in vulnerability detection, indicating limitations in its security applications.&lt;SEP&gt;Current shortcomings of Codex, such as difficulty generating certain payloads, inability to outperform basic security tools, and tendencies to suggest insecure code.&lt;SEP&gt;Model limitations include inherent weaknesses or constraints, such as tendency to suggest insecure code or produce incorrect outputs, which impact safety.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb&lt;SEP&gt;chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="User Experience">
  <data key="d0">User Experience</data>
  <data key="d1">Variables</data>
  <data key="d2">User experience encompasses how users interact with models, including their trust, reliance, and vigilance, which affect safety outcomes.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Size Scaling">
  <data key="d0">Model Size Scaling</data>
  <data key="d1">Variables</data>
  <data key="d2">Scaling model size impacts capabilities, risks of misalignment, bias, and safety concerns, generally increasing with larger models.</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias and Representation Issues">
  <data key="d0">Bias and Representation Issues</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Bias and representation issues in code generation models, including stereotypes related to gender, race, emotion, class, and name structures, which may have safety and ethical implications.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Filtration or Modulation of Outputs">
  <data key="d0">Filtration or Modulation of Outputs</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Interventions such as filtration, documentation, and other measures aimed at mitigating risks associated with biased or problematic generated code.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Economic and Labor Market Impacts">
  <data key="d0">Economic and Labor Market Impacts</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Potential effects of code generation models like Codex on software production costs, programmer productivity, labor markets, and the economy, including possible advantages for certain package authors and shifts in demand for different roles.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Software-Related Tasks">
  <data key="d0">Software-Related Tasks</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Tasks including code writing, designing specifications, and software upgrades, which influence the extent to which Codex can reduce programmer workload.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Package Import Rates">
  <data key="d0">Package Import Rates</data>
  <data key="d1">Variables</data>
  <data key="d2">The frequency at which Codex imports software packages, which could advantage some package authors over others and influence dependency patterns.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Security Implications">
  <data key="d0">Security Implications</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Risks associated with Codex generating vulnerable or misaligned code, potential misuse in cybercrime, and challenges posed by non-determinism and code diversity for malware detection.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malware Development">
  <data key="d0">Malware Development</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Malware creation processes potentially aided by Codex, including polymorphic malware techniques that exploit non-determinism.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Mitigation Strategies">
  <data key="d0">Mitigation Strategies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Application security measures such as rate-limiting access, abuse monitoring, and review processes to manage security risks.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sensitive Data in Training Data">
  <data key="d0">Sensitive Data in Training Data</data>
  <data key="d1">Variables</data>
  <data key="d2">Presence of sensitive information in publicly available source code repositories used for training Codex, which may already be compromised or leaked.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Environmental Impacts">
  <data key="d0">Environmental Impacts</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Energy consumption and carbon footprint associated with training and inference of large models like Codex, and the use of renewable energy sources to mitigate environmental effects.</data>
  <data key="d3">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Petaflop/s-days">
  <data key="d0">Petaflop/s-days</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Petaflop per second-days measure the total computational capacity consumed during training and fine-tuning large AI models, reflecting the scale of compute resources used.&lt;SEP&gt;Petaflop/s-days refer to a measure of computational power used during model training and fine-tuning, indicating the total processing capacity consumed over time.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Azure platform">
  <data key="d0">Azure platform</data>
  <data key="d1">Tools</data>
  <data key="d2">Azure is a cloud computing platform used for training and fine-tuning AI models, notable for its commitment to renewable energy sourcing and purchasing carbon credits to reduce environmental impact.&lt;SEP&gt;Azure is a cloud computing platform used for training and fine-tuning AI models, notable for its renewable energy sourcing and carbon credit purchases.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Carbon footprint">
  <data key="d0">Carbon footprint</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The carbon footprint measures the environmental impact of compute activities, including energy consumption and associated emissions.&lt;SEP&gt;The carbon footprint quantifies the environmental impact associated with compute activities, including energy consumption and greenhouse gas emissions.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Legal considerations">
  <data key="d0">Legal considerations</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Legal considerations encompass issues related to training AI on internet data, intellectual property rights, fair use, and the legal implications of generated code."|&lt;SEP&gt;Legal considerations involve the implications of training AI on internet data, intellectual property issues, and fair use, affecting deployment and usage policies.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Fair use">
  <data key="d0">Fair use</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Fair use is a legal doctrine allowing limited use of copyrighted material, relevant here because training data from public repositories like GitHub may qualify under fair use."|&lt;SEP&gt;Fair use is a legal doctrine that allows limited use of copyrighted material without permission, relevant to training data sourced from public repositories.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generated code">
  <data key="d0">Generated code</data>
  <data key="d1">Results</data>
  <data key="d2">Generated code refers to the output produced by AI models like Codex, which is rarely identical to training data but may sometimes resemble common code snippets.&lt;SEP&gt;Generated code refers to the output produced by models like Codex, which rarely exactly reproduces training data but may sometimes resemble common code snippets or expressions."|</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Predictive weightings">
  <data key="d0">Predictive weightings</data>
  <data key="d1">Variables</data>
  <data key="d2">Predictive weightings are internal model parameters that influence code generation, rather than copies of training data, enabling the model to generate novel outputs."|&lt;SEP&gt;Predictive weightings are the internal parameters of the model that influence code generation, rather than direct copying of training data.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Environmental impact">
  <data key="d0">Environmental impact</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Assessing environmental impact involves analyzing energy consumption, carbon emissions, and sustainability efforts in data centers and compute infrastructure."|&lt;SEP&gt;Assessing the environmental impact of compute use involves analyzing energy consumption, carbon emissions, and sustainability efforts in data centers.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Renewable energy">
  <data key="d0">Renewable energy</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Renewable energy sources, such as those purchased by Microsoft, aim to power data centers and reduce the carbon footprint of large-scale compute activities."|&lt;SEP&gt;Renewable energy sourcing, such as by Microsoft, aims to reduce the environmental footprint of large-scale compute activities.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Risk mitigation">
  <data key="d0">Risk mitigation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Risk mitigation involves strategies like careful documentation, user interface design, content filtering, user review policies, monitoring, and rate limiting to prevent harms from AI deployment.&lt;SEP&gt;Risk mitigation strategies include careful documentation, user interface design, content filtering, user review policies, monitoring, and rate limiting to prevent harms from AI deployment."|</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Content controls">
  <data key="d0">Content controls</data>
  <data key="d1">Tools</data>
  <data key="d2">Content controls are mechanisms like filtering outputs to reduce offensive content or insecure code generation, enhancing safety in AI applications.&lt;SEP&gt;Content controls are mechanisms like output filtering and content moderation tools designed to reduce offensive, insecure, or harmful code generation."|</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Deep learning resurgence">
  <data key="d0">Deep learning resurgence</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The deep learning resurgence refers to recent advances leading to progress in neural program learning, including program induction and synthesis."|&lt;SEP&gt;The resurgence of deep learning has driven significant progress in neural program learning, including program induction and synthesis approaches.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Program induction">
  <data key="d0">Program induction</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Program induction involves models generating program outputs directly from latent representations, enabling tasks like addition and memorization.&lt;SEP&gt;Program induction involves neural models generating program outputs directly from latent representations, enabling learning of simple to complex algorithms."|</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Program synthesis">
  <data key="d0">Program synthesis</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Program synthesis involves generating executable code from specifications, often using neural models trained on large datasets."|&lt;SEP&gt;Program synthesis refers to generating code or programs from specifications, often using neural models trained on large datasets.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Turing Machine">
  <data key="d0">Neural Turing Machine</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Neural Turing Machines are neural network architectures with external memory components, inspired by traditional computers, used for algorithm learning."|&lt;SEP&gt;Neural Turing Machines are neural network models with external memory, inspired by traditional computing, used to learn algorithms.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural GPU">
  <data key="d0">Neural GPU</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Neural GPU is a neural network architecture designed to learn and execute algorithms like addition, leveraging GPU parallelism."|&lt;SEP&gt;Neural GPU is a neural network architecture designed to learn and execute algorithms like addition, leveraging GPU-like parallelism.</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Recurrent models">
  <data key="d0">Recurrent models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Recurrent models like the Neural Program Interpreter facilitate learning recursive and iterative algorithms in neural networks.&lt;SEP&gt;Recurrent neural models, such as the Neural Program Interpreter, facilitate learning recursive and iterative algorithms."|</data>
  <data key="d3">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Utskever">
  <data key="d0">Utskever</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Utskever is referenced as a researcher associated with neural network approaches in program synthesis.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Differentiable Neural Computer">
  <data key="d0">Differentiable Neural Computer</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A neural network architecture introduced by Graves et al. (2016), designed for complex data manipulation and reasoning tasks.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Program Interpreter">
  <data key="d0">Neural Program Interpreter</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A neural network-based approach for interpreting and executing programs, developed by Reed &amp; de Freitas (2016), Shin et al. (2018), and Pierrot et al. (2021).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Universal Transformer">
  <data key="d0">Universal Transformer</data>
  <data key="d1">Models/Theories</data>
  <data key="d2">A transformer-based model trained on code by Dehghani et al. (2019), emphasizing recurrence for program induction.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Probabilistic Context-Free Grammar (PCFG)">
  <data key="d0">Probabilistic Context-Free Grammar (PCFG)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A classical approach for generating program syntax trees used in program synthesis, as described in the text.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Abstract Syntax Tree (AST)">
  <data key="d0">Abstract Syntax Tree (AST)</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A tree representation of the structure of source code, used in program synthesis and analysis.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Text-to-Code Retrieval">
  <data key="d0">Text-to-Code Retrieval</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The task of retrieving code snippets based on natural language queries, explored by Allamanis et al. (2015).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code2Seq">
  <data key="d0">Code2Seq</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural model leveraging ASTs for translating code to text, introduced by Alon et al. (2018).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="N-gram Language Models">
  <data key="d0">N-gram Language Models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Statistical models that predict code sequences based on n-gram probabilities, investigated by Hindle et al. (2012).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Latent Predictor Networks">
  <data key="d0">Latent Predictor Networks</data>
  <data key="d1">Tools</data>
  <data key="d2">Neural models that generate code for specific tasks like Magic the Gathering cards, as per Ling et al. (2016).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="DeepCoder">
  <data key="d0">DeepCoder</data>
  <data key="d1">Tools</data>
  <data key="d2">A neural system trained to predict functions in source code to guide program search, developed by Balog et al. (2017).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Large Scale Transformers">
  <data key="d0">Large Scale Transformers</data>
  <data key="d1">Models/Theories</data>
  <data key="d2">Transformer architectures trained on large code corpora for program synthesis, including models like CodeBERT and PyMT5.</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="CodeBERT">
  <data key="d0">CodeBERT</data>
  <data key="d1">Tools</data>
  <data key="d2">A transformer-based model trained on code and docstrings for code search, by Feng et al. (2020).&lt;SEP&gt;A transformer-based model trained on code and natural language data to enhance code understanding and generation.&lt;SEP&gt;A transformer-based model trained on large datasets of code and natural language to improve code understanding, generation, and translation.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21&lt;SEP&gt;chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="PyMT5">
  <data key="d0">PyMT5</data>
  <data key="d1">Tools</data>
  <data key="d2">A multilingual transformer model trained with the T5 objective to translate between code and natural language, by Clement et al. (2020).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="SPoC">
  <data key="d0">SPoC</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A system that produces functionally correct code from pseudocode within a fixed compilation budget, by Kulal et al. (2019).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="TransCoder">
  <data key="d0">TransCoder</data>
  <data key="d1">Tools</data>
  <data key="d2">A system trained to translate code between programming languages in an unsupervised manner, by Lachaux et al. (2020).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ContraCode">
  <data key="d0">ContraCode</data>
  <data key="d1">Tools</data>
  <data key="d2">A contrastive learning model leveraging the space of functionally correct programs to improve code understanding, by Jain et al. (2020).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="RobustFill">
  <data key="d0">RobustFill</data>
  <data key="d1">Tools</data>
  <data key="d2">A program synthesis method that synthesizes multiple samples through beam search to find programs consistent with input examples, by Devlin et al. (2017).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="CodeSearchNet">
  <data key="d0">CodeSearchNet</data>
  <data key="d1">Datasets</data>
  <data key="d2">A large corpus of code from GitHub used for benchmarking code understanding and generation models, by Husain et al. (2019).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="CodeXGLUE">
  <data key="d0">CodeXGLUE</data>
  <data key="d1">Datasets</data>
  <data key="d2">A collection of benchmarks for code understanding, generation, and translation, aggregated by Lu et al. (2021).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="APPS">
  <data key="d0">APPS</data>
  <data key="d1">Datasets</data>
  <data key="d2">A benchmark for functional correctness based on competitive programming problems, by Hendrycks et al. (2021).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bug Fixing">
  <data key="d0">Bug Fixing</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Activities involving locating and repairing faults in source code, utilizing static/dynamic analysis, learned rules, or genetic programming, as discussed in recent works like Drain et al. (2021).</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Korel &amp; Rilling, 1997">
  <data key="d0">Korel &amp; Rilling, 1997</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">References to foundational works related to learning association rules and their applications in debugging and code analysis.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="learned association rules">
  <data key="d0">learned association rules</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A method for discovering patterns and relationships between variables in data, used here for debugging code.&lt;SEP&gt;Method for uncovering relationships between variables in data, used here for debugging code.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="genetic programming">
  <data key="d0">genetic programming</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">An evolutionary algorithm approach to automatically generate and optimize programs, applied to debugging faulty code.&lt;SEP&gt;Evolutionary algorithm-inspired approach to automatically generate programs and debug faulty code.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="test suite">
  <data key="d0">test suite</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A collection of automated tests designed to evaluate the correctness, functionality, and behavior of code during debugging.&lt;SEP&gt;A collection of tests used to evaluate the correctness and functionality of programs during debugging.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="execution trace">
  <data key="d0">execution trace</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A detailed record of program execution steps, used to identify errors and understand program behavior.&lt;SEP&gt;A record of the execution process of a program, used to identify errors and issues.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="search for a solution">
  <data key="d0">search for a solution</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">Exploring methods and approaches to find effective fixes for software bugs.&lt;SEP&gt;Investigating methods to find effective fixes for bugs in code.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="more recent works">
  <data key="d0">more recent works</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Recent research efforts that consider neural machine translation for bug fixing.&lt;SEP&gt;Recent research efforts that treat bug fixing as a neural machine translation problem from buggy to correct code.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="neural machine translation">
  <data key="d0">neural machine translation</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Application of neural networks to translate buggy code into correct code.&lt;SEP&gt;Applying neural network models to translate buggy code into corrected versions.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="exact match">
  <data key="d0">exact match</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An evaluation approach comparing generated code to a reference solution for correctness.&lt;SEP&gt;Evaluation approach that compares generated code to a reference solution for correctness.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="weak test suites">
  <data key="d0">weak test suites</data>
  <data key="d1">Limitations</data>
  <data key="d2">Test suites with limited coverage that can be bypassed by deleting non-essential functionality, leading to false positives.&lt;SEP&gt;Test suites with limited coverage that can be bypassed by deleting or altering non-essential functionality, leading to unreliable correctness assessment.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="human developers">
  <data key="d0">human developers</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The human programmers who create test suites and code, providing data for training and evaluation.&lt;SEP&gt;The human programmers who write test suites and code, providing the data for analysis.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="training large language models">
  <data key="d0">training large language models</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approach to fine-tune models like GPT on code datasets to improve code generation and correction.&lt;SEP&gt;The process of fine-tuning large models like GPT on code datasets to improve code generation and correction capabilities.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="natural language docstrings">
  <data key="d0">natural language docstrings</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Descriptive comments in code used as input for training models to generate code bodies.&lt;SEP&gt;Descriptive comments in code written in natural language, used as input data for training models to generate code bodies.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="fine-tuning GPT">
  <data key="d0">fine-tuning GPT</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Process of adapting GPT models on specific datasets to improve performance on code-related tasks.&lt;SEP&gt;The process of adapting GPT models on code datasets to enhance their ability to generate and correct code from natural language descriptions.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="dataset of human-written problems">
  <data key="d0">dataset of human-written problems</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A collection of programming problems written by humans, used to evaluate model performance.&lt;SEP&gt;Collection of programming problems used to evaluate model performance.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="producing docstrings from code bodies">
  <data key="d0">producing docstrings from code bodies</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A task of generating descriptive comments from code, used to assess model understanding and versatility.&lt;SEP&gt;Task of generating descriptive comments from code, used to evaluate model versatility.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="broader impacts of code generating models">
  <data key="d0">broader impacts of code generating models</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Discussion of societal, ethical, and technical consequences of deploying code generation models.&lt;SEP&gt;Discussion of societal, ethical, and technical effects of deploying code generation models.</data>
  <data key="d3">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="code2seq">
  <data key="d0">code2seq</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A method for generating sequences from structured representations of code, used to improve code understanding and processing.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Learning representations">
  <data key="d0">Learning representations</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Frameworks for understanding how models encode information from data such as code, speech, and images.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Aye, G. A., Kim, S., and Li, H.">
  <data key="d0">Aye, G. A., Kim, S., and Li, H.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors conducting research on autocompletion from real-world datasets, contributing to software engineering practices.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="2021 IEEE/ACM 43rd International Conference on Software Engineering">
  <data key="d0">2021 IEEE/ACM 43rd International Conference on Software Engineering</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference where research on software engineering, including autocompletion and dataset learning, is presented.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="wav2vec 2.0">
  <data key="d0">wav2vec 2.0</data>
  <data key="d1">Tools</data>
  <data key="d2">A framework for self-supervised learning of speech representations, enabling improved speech processing and recognition.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Self-supervised learning">
  <data key="d0">Self-supervised learning</data>
  <data key="d1">Methodology</data>
  <data key="d2">A training approach where models learn representations from unlabeled data, as exemplified by wav2vec 2.0.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Balog, M., Gaunt, A., Brockschmidt, M., Nowozin, S., and Tarlow, D.">
  <data key="d0">Balog, M., Gaunt, A., Brockschmidt, M., Nowozin, S., and Tarlow, D.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors developing Deepcoder, a system for learning to write programs using deep learning techniques.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Deepcoder">
  <data key="d0">Deepcoder</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A system that learns to generate code by training on datasets of programming tasks, facilitating automated code writing.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="5th International Conference on Learning Representations (ICLR)">
  <data key="d0">5th International Conference on Learning Representations (ICLR)</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference where research on learning to write programs and other models is presented.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Beit: Bert pre-training of image transformers">
  <data key="d0">Beit: Bert pre-training of image transformers</data>
  <data key="d1">Tools</data>
  <data key="d2">A pre-training framework for image transformers based on BERT, used to improve image understanding.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bao, H., Dong, L., and Wei, F.">
  <data key="d0">Bao, H., Dong, L., and Wei, F.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors working on Beit, a model for pre-training image transformers.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="parallel corpus of python functions and documentation strings">
  <data key="d0">parallel corpus of python functions and documentation strings</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset consisting of Python functions and their documentation, used for automated code documentation and generation.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Barone, A. V. M. and Sennrich, R.">
  <data key="d0">Barone, A. V. M. and Sennrich, R.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors creating a parallel corpus for code and documentation to facilitate automated documentation and code generation.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Lecture 3: Nondeterministic computation">
  <data key="d0">Lecture 3: Nondeterministic computation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A lecture resource explaining nondeterministic computation, a concept in theoretical computer science.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Barrington, I. M. and Maciel, A.">
  <data key="d0">Barrington, I. M. and Maciel, A.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors providing educational notes on nondeterministic computation.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S.">
  <data key="d0">Bender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors discussing the dangers of large language models and stochastic parrots, highlighting issues of bias and model size.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="stochastic parrots">
  <data key="d0">stochastic parrots</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A metaphor and concern regarding large language models' tendency to mimic data without understanding, raising ethical and safety issues.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Black, S., Gao, L., Wang, P., Leahy, C., and Biderman, S.">
  <data key="d0">Black, S., Gao, L., Wang, P., Leahy, C., and Biderman, S.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors developing GPT-Neo, a large-scale autoregressive language model based on mesh-tensorflow.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="arXiv preprint arXiv:2005.14050">
  <data key="d0">arXiv preprint arXiv:2005.14050</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A preprint discussing bias in NLP and language technology.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D.">
  <data key="d0">Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors of the GPT-3 language model, demonstrating that language models can perform few-shot learning across various tasks.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bureau of Labor Statistics, U. D. o. L.">
  <data key="d0">Bureau of Labor Statistics, U. D. o. L.</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Official data sources providing occupational outlooks for computer programmers and software developers.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Occupational Outlook Handbook">
  <data key="d0">Occupational Outlook Handbook</data>
  <data key="d1">Tools</data>
  <data key="d2">A resource providing information on job outlooks, required skills, and employment trends for various occupations.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Computer programmers">
  <data key="d0">Computer programmers</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Data on employment, job prospects, and skills needed for programming professionals, as compiled by BLS.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="BlS - software developers">
  <data key="d0">BlS - software developers</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Data on software development employment trends and requirements.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Carlini, N., Tramèr, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T., Song, D., Erlingsson, U., Oprea, A., and Raffel, C.">
  <data key="d0">Carlini, N., Tramèr, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T., Song, D., Erlingsson, U., Oprea, A., and Raffel, C.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors investigating methods for extracting training data from large language models.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Extracting training data from large language models">
  <data key="d0">Extracting training data from large language models</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">A research question exploring the possibility and methods of retrieving training data from models like GPT.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="USENIX Security Symposium">
  <data key="d0">USENIX Security Symposium</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference where security evaluations of large language models, including data extraction risks, are presented.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="generative pretraining from pixels">
  <data key="d0">generative pretraining from pixels</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A pretraining approach for models using pixel data, relevant in vision and multimodal learning.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Child, R., Gray, S., Radford, A., and Sutskever, I.">
  <data key="d0">Child, R., Gray, S., Radford, A., and Sutskever, I.</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors working on sequence generation with sparse transformers.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="generating long sequences with sparse transformers">
  <data key="d0">generating long sequences with sparse transformers</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique for efficient sequence generation in large models, improving scalability and performance.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Christiano, P.">
  <data key="d0">Christiano, P.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author discussing AI alignment, focusing on clarifying the concept and challenges of aligning AI systems with human values.&lt;SEP&gt;Author focusing on AI alignment, clarifying the conceptual and practical aspects of aligning AI systems with human values and safety.&lt;SEP&gt;Author providing insights into AI alignment, focusing on aligning AI behaviors with human values.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21&lt;SEP&gt;chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="AI alignment">
  <data key="d0">AI alignment</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A field of study focused on ensuring AI systems behave in ways that are beneficial and aligned with human interests.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Clarkson, M. R., Finkbeiner">
  <data key="d0">Clarkson, M. R., Finkbeiner</data>
  <data key="d1">Researcher Group</data>
  <data key="d2">Authors contributing to foundational knowledge in nondeterministic computation.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="2019.Alon, U., Brody, S., Levy, O., and Yahav, E.">
  <data key="d0">2019.Alon, U., Brody, S., Levy, O., and Yahav, E.</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset or research work from 2019 involving these authors, focusing on code-to-sequence models and structured representations of code.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Learning autocompletion from real-world datasets">
  <data key="d0">Learning autocompletion from real-world datasets</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A research question exploring how models can learn to autocomplete code based on real-world data.</data>
  <data key="d3">chunk-54d0e5495bc4b24b68d3cbc1c13d835e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="S., Radford, A., and Sutskever, I.">
  <data key="d0">S., Radford, A., and Sutskever, I.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a paper on generating long sequences with sparse transformers, contributing to AI research.&lt;SEP&gt;Authors of a seminal paper on generating long sequences with sparse transformers, contributing to advancements in natural language processing and sequence modeling.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generating long sequences with sparse transformers">
  <data key="d0">Generating long sequences with sparse transformers</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A research approach utilizing sparse transformer architectures to efficiently generate and model long sequences in data, impacting NLP and AI.&lt;SEP&gt;A research paper introducing methods for sequence generation using sparse transformer models, advancing natural language processing techniques.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="AI Alignment Forum">
  <data key="d0">AI Alignment Forum</data>
  <data key="d1">Platform</data>
  <data key="d2">An online community and forum dedicated to discussions, research, and dissemination of ideas related to AI alignment and safety.&lt;SEP&gt;Online forum dedicated to discussions and research on AI alignment and safety.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Clarifying 'ai alignment'">
  <data key="d0">Clarifying 'ai alignment'</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A conceptual explanation or framework aimed at making the ideas behind AI alignment clearer and more accessible.&lt;SEP&gt;A conceptual framework or detailed explanation aimed at making the complex ideas of AI alignment more understandable and transparent.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Clarkson, M. R., Finkbeiner, B., Koleini, M., Micinski, K. K., Rabe, M. N., and Sánchez, C.">
  <data key="d0">Clarkson, M. R., Finkbeiner, B., Koleini, M., Micinski, K. K., Rabe, M. N., and Sánchez, C.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a study on temporal logics for hyperproperties, contributing to formal verification, security, and trust in systems.&lt;SEP&gt;Authors of a study on temporal logics for hyperproperties, contributing to security and trust in formal methods.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Temporal logics for hyperproperties">
  <data key="d0">Temporal logics for hyperproperties</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A formal logic system designed to specify and reason about hyperproperties—properties relating multiple system executions—relevant to security and privacy.&lt;SEP&gt;A formal logical framework for specifying and reasoning about hyperproperties, which are properties of multiple system executions, relevant to security.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Clement, C., Drain, D., Timcheck, J., Svyatkovskiy, A., and Sundaresan, N.">
  <data key="d0">Clement, C., Drain, D., Timcheck, J., Svyatkovskiy, A., and Sundaresan, N.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of Pymt5, a multi-mode translation system that converts natural language to Python code and vice versa using transformers, advancing NLP and code generation.&lt;SEP&gt;Authors of a paper on Pymt5, a system for multi-mode translation of natural language and Python code using transformers.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pymt5">
  <data key="d0">Pymt5</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A model or system that enables translation between natural language and Python code employing transformer architectures.&lt;SEP&gt;A transformer-based system enabling multi-mode translation between natural language and programming language, facilitating natural language programming interfaces.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Crawford, K.">
  <data key="d0">Crawford, K.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author and speaker discussing bias in AI systems, and author of 'Atlas of AI' exploring the societal impacts of artificial intelligence.&lt;SEP&gt;Author and thinker on bias in AI and societal impacts, author of 'Atlas of AI' exploring the political, economic, and environmental costs of AI.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="The trouble with bias">
  <data key="d0">The trouble with bias</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A keynote presentation analyzing sources, implications, and mitigation of bias in AI systems.&lt;SEP&gt;A keynote talk analyzing biases inherent in AI systems and their societal implications.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Atlas of AI">
  <data key="d0">Atlas of AI</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A comprehensive book examining the political, economic, and environmental costs associated with artificial intelligence.&lt;SEP&gt;A comprehensive book examining the societal, political, and environmental costs associated with the development and deployment of artificial intelligence.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dai, A. M. and Le, Q. V.">
  <data key="d0">Dai, A. M. and Le, Q. V.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of work on semi-supervised sequence learning, contributing to neural network training methodologies for sequence data.&lt;SEP&gt;Authors of work on semi-supervised sequence learning, contributing to neural network training methodologies.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Semi-supervised sequence learning">
  <data key="d0">Semi-supervised sequence learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A training approach that leverages both labeled and unlabeled data to improve sequence modeling in neural networks.&lt;SEP&gt;A training paradigm utilizing both labeled and unlabeled data to improve sequence modeling performance in neural networks.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D.">
  <data key="d0">Das, A., Kottur, S., Gupta, K., Singh, A., Yadav, D., Moura, J. M., Parikh, D., and Batra, D.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a paper on visual dialog, advancing multi-modal AI systems.&lt;SEP&gt;Authors of a study on visual dialog, advancing multi-modal AI systems capable of understanding and generating dialog based on visual inputs.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Visual dialog">
  <data key="d0">Visual dialog</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A framework for developing AI systems that can process and generate dialogue conditioned on visual context, integrating vision and language.&lt;SEP&gt;A research framework for developing AI systems that can understand and generate dialogue based on visual input.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Davis, B.">
  <data key="d0">Davis, B.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author discussing application protection through automated software diversity, focusing on cybersecurity techniques.&lt;SEP&gt;Author discussing automated software diversity as a security technique to protect applications from attacks.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Protecting applications with automated software diversity">
  <data key="d0">Protecting applications with automated software diversity</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">A method to enhance application security by automatically diversifying software implementations to prevent attacks.&lt;SEP&gt;A security approach that automatically diversifies software implementations to prevent exploitation and enhance resilience.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dehghani, M., Gouws, S., Vinyals, O., Uszkoreit, J., and Łukasz Kaiser">
  <data key="d0">Dehghani, M., Gouws, S., Vinyals, O., Uszkoreit, J., and Łukasz Kaiser</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of Universal Transformers, a model extending standard transformer architectures for improved sequence processing.&lt;SEP&gt;Authors of Universal Transformers, an extension of the transformer architecture that incorporates recurrence and adaptive computation for improved sequence modeling.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Universal transformers">
  <data key="d0">Universal transformers</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A transformer-based model architecture that enhances standard transformers with recurrence and dynamic computation for better handling of complex sequences.&lt;SEP&gt;An extension of transformer models that incorporates recurrence and dynamic computation for better sequence understanding.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Devlin, J., Uesato, J., Bhupatiraju, S., Singh, R., Mohamed, A., and Kohli, P.">
  <data key="d0">Devlin, J., Uesato, J., Bhupatiraju, S., Singh, R., Mohamed, A., and Kohli, P.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of BERT, a deep bidirectional transformer model pre-trained for natural language understanding.&lt;SEP&gt;Authors of BERT, a pre-trained deep bidirectional transformer model for language understanding.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dhariwal, P., Jun, H., Payne, C., Kim, J. W., Radford, A., and Sutskever, I.">
  <data key="d0">Dhariwal, P., Jun, H., Payne, C., Kim, J. W., Radford, A., and Sutskever, I.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of Jukebox, a generative model for music creation.&lt;SEP&gt;Authors of Jukebox, a neural network model capable of generating high-fidelity music across genres.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jukebox">
  <data key="d0">Jukebox</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A neural generative model that creates music with diverse styles, demonstrating advances in AI-generated art.&lt;SEP&gt;A neural network model capable of generating music with high fidelity, capturing diverse genres and styles.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Drain, D., Wu, C., Svyatkovskiy, A., and Sundaresan, N.">
  <data key="d0">Drain, D., Wu, C., Svyatkovskiy, A., and Sundaresan, N.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of work on generating bug-fixes using pretrained transformers, contributing to automated software maintenance and repair.&lt;SEP&gt;Authors of work on generating bug-fixes using pretrained transformers, contributing to automated software maintenance.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generating bug-fixes using pretrained transformers">
  <data key="d0">Generating bug-fixes using pretrained transformers</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique employing transformer models to automatically generate code fixes for software bugs.&lt;SEP&gt;An automated approach employing transformer models to analyze code and generate bug fixes, improving software reliability.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Eghbal, N.">
  <data key="d0">Eghbal, N.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of 'Working in public', discussing open source software development and maintenance practices.&lt;SEP&gt;Author of 'Working in public', discussing open source software development, transparency, and community practices.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Working in public">
  <data key="d0">Working in public</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">A concept emphasizing transparency and community involvement in open source software development.&lt;SEP&gt;A philosophy and practice encouraging open, transparent, and community-driven development in open source software.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., et al.">
  <data key="d0">Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., et al.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of CodeBERT, a pre-trained model for programming and natural languages.&lt;SEP&gt;Authors of CodeBERT, a pre-trained model that jointly learns representations for programming and natural language.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Frey, C. B.">
  <data key="d0">Frey, C. B.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author of 'The technology trap', analyzing how technological advances can lead to societal and economic constraints.&lt;SEP&gt;Author of 'The technology trap', analyzing how technological development can lead to societal dependency and constraints.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="The technology trap">
  <data key="d0">The technology trap</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A conceptual framework describing how technological development can create dependency and limit societal options.&lt;SEP&gt;A conceptual framework explaining how technological advances can create societal lock-in, dependencies, and limit choices.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., Presser, S., and Leahy, C.">
  <data key="d0">Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., Presser, S., and Leahy, C.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of The Pile, a large diverse text dataset for language modeling.&lt;SEP&gt;Authors of The Pile, a large, diverse dataset of text used for training language models.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="The Pile">
  <data key="d0">The Pile</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">An 800GB dataset comprising diverse text sources used to train large language models.&lt;SEP&gt;An extensive dataset of 800GB of diverse text sources designed to facilitate training large-scale language models.&lt;SEP&gt;The Pile is an 800GB diverse text dataset used for training large language models, encompassing multiple domains and sources.&lt;SEP&gt;The Pile is an extensive 800GB dataset of diverse text sources used to train large language models across multiple domains.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63&lt;SEP&gt;chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Goldblum, M., Tsipras, D., Xie, C., Chen, X., Schwarzschild, A., Song, D., Madry, A., Li, B., and Goldstein, T.">
  <data key="d0">Goldblum, M., Tsipras, D., Xie, C., Chen, X., Schwarzschild, A., Song, D., Madry, A., Li, B., and Goldstein, T.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors studying dataset security issues such as data poisoning and backdoor attacks in machine learning.&lt;SEP&gt;Authors studying dataset security issues such as data poisoning, backdoors, and defenses in machine learning.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dataset security for machine learning">
  <data key="d0">Dataset security for machine learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A field focused on protecting training data and models from malicious attacks like poisoning and backdoor insertion, ensuring robustness.&lt;SEP&gt;A field focused on protecting training data and models from malicious manipulation like poisoning and backdoors.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Goues, C. L., Dewey-Vogt, M., Forrest, S., and Weimer, W.">
  <data key="d0">Goues, C. L., Dewey-Vogt, M., Forrest, S., and Weimer, W.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of a systematic study on automated program repair, demonstrating techniques to fix bugs efficiently and automatically.&lt;SEP&gt;Authors of a systematic study on automated program repair, fixing bugs efficiently.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automated program repair">
  <data key="d0">Automated program repair</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A set of automated techniques and tools for detecting and fixing bugs in software, reducing manual effort and increasing reliability.&lt;SEP&gt;Techniques and systems designed to automatically identify and fix bugs in software code.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Graves, A.">
  <data key="d0">Graves, A.</data>
  <data key="d1">Researcher</data>
  <data key="d2">A researcher known for work on sequence generation with recurrent neural networks and neural Turing machines.&lt;SEP&gt;A researcher renowned for work on sequence generation with recurrent neural networks and neural Turing machines, contributing to machine learning and neural network architectures.&lt;SEP&gt;Author of research on sequence generation with recurrent neural networks, foundational in neural sequence modeling.&lt;SEP&gt;Author of work on sequence generation with recurrent neural networks, contributing to neural sequence modeling.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21&lt;SEP&gt;chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generating sequences with recurrent neural networks">
  <data key="d0">Generating sequences with recurrent neural networks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A neural network approach for producing sequential data, essential for tasks like language modeling and time series prediction.&lt;SEP&gt;A neural network approach for producing sequential data, foundational in sequence modeling.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Graves, A., Wayne, G., and Danihelka, I.">
  <data key="d0">Graves, A., Wayne, G., and Danihelka, I.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of Neural Turing Machines, models that extend neural networks with external memory for complex reasoning.&lt;SEP&gt;Authors of Neural Turing Machines, models that integrate neural networks with external memory to enable complex reasoning and algorithmic tasks.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Turing Machines">
  <data key="d0">Neural Turing Machines</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A computational model combining neural networks with external memory to enable complex data manipulation.&lt;SEP&gt;A computational model that combines neural networks with external memory components, enabling complex data manipulation and learning algorithms.&lt;SEP&gt;A neural network architecture equipped with external memory modules, extending neural networks' capabilities for algorithmic tasks.&lt;SEP&gt;A neural network architecture that combines traditional neural nets with external memory resources to enhance computation capabilities.</data>
  <data key="d3">chunk-d82fbac5a45159b990b5c96afdf81c21&lt;SEP&gt;chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="2012 34th International Conference on Software Engineering (ICSE)">
  <data key="d0">2012 34th International Conference on Software Engineering (ICSE)</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference held in 2012 focusing on software engineering topics, presenting research papers and proceedings.&lt;SEP&gt;An academic conference held in 2012 focusing on advances, research, and developments in software engineering, featuring proceedings and papers.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hybrid Computing with Neural Networks">
  <data key="d0">Hybrid Computing with Neural Networks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A methodology involving neural networks with dynamic external memory for hybrid computing tasks.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Gulwani, S.">
  <data key="d0">Gulwani, S.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A researcher specializing in automating string processing and data manipulation in spreadsheets through input-output examples, advancing program synthesis.&lt;SEP&gt;A researcher specializing in automating string processing and spreadsheet data manipulation using input-output examples.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automating String Processing">
  <data key="d0">Automating String Processing</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A technique for automating string manipulations in spreadsheets through input-output examples.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Deberta">
  <data key="d0">Deberta</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A natural language processing model that enhances BERT with disentangled attention mechanisms.&lt;SEP&gt;An advanced NLP model that improves language understanding by disentangling attention mechanisms, leading to better contextual representations.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Helmuth, T. and Spector, L.">
  <data key="d0">Helmuth, T. and Spector, L.</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A benchmark suite designed for evaluating general program synthesis algorithms, consisting of diverse synthesis tasks.&lt;SEP&gt;A benchmark suite for general program synthesis, used to evaluate synthesis algorithms.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="General Program Synthesis Benchmark Suite">
  <data key="d0">General Program Synthesis Benchmark Suite</data>
  <data key="d1">Tools</data>
  <data key="d2">A collection of benchmark problems designed to evaluate program synthesis techniques.&lt;SEP&gt;A collection of standardized problems used to evaluate and compare program synthesis methods.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hendrycks, D. et al.">
  <data key="d0">Hendrycks, D. et al.</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigate how apps can objectively measure coding challenge competence in software development through empirical evaluation.&lt;SEP&gt;Investigating the ability of apps to measure coding challenge competence in software development.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Measuring Coding Challenge Competence with Apps">
  <data key="d0">Measuring Coding Challenge Competence with Apps</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Empirical studies and evaluations assessing the effectiveness of applications in measuring programming skills.&lt;SEP&gt;Empirical studies assessing the effectiveness of applications in evaluating coding skills.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hindle, A. et al.">
  <data key="d0">Hindle, A. et al.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The concept of the 'naturalness' of software, suggesting that code has statistical properties similar to natural language.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="On the Naturalness of Software">
  <data key="d0">On the Naturalness of Software</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A theory proposing that software code exhibits regularities akin to natural language, influencing code analysis.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Holtzman, A. et al.">
  <data key="d0">Holtzman, A. et al.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A study exploring issues of neural text degeneration, examining challenges in neural language generation.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Text Degeneration">
  <data key="d0">Neural Text Degeneration</data>
  <data key="d1">Results</data>
  <data key="d2">Findings highlight common problems like repetitive output and incoherence in neural language models, and potential mitigation strategies.&lt;SEP&gt;Findings related to the problematic aspects of neural text generation, such as repetition and incoherence.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Husain, H. et al.">
  <data key="d0">Husain, H. et al.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Evaluation of semantic code search systems, assessing how well they understand and retrieve code based on meaning.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codesearchnet Challenge">
  <data key="d0">Codesearchnet Challenge</data>
  <data key="d1">Study Designs</data>
  <data key="d2">An evaluation framework and benchmark for assessing the performance of semantic code search systems across multiple datasets and metrics.&lt;SEP&gt;An evaluation framework for semantic code search systems, measuring their performance.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Contrastive Code Representation Learning">
  <data key="d0">Contrastive Code Representation Learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A machine learning approach that learns code representations by contrasting different code snippets, improving semantic understanding and retrieval.&lt;SEP&gt;A method for learning code representations by contrasting different code snippets to improve semantic understanding.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jeffrey, D. et al.">
  <data key="d0">Jeffrey, D. et al.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A tool designed to assist developers in fixing bugs using machine learning techniques.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bugfix Tool">
  <data key="d0">Bugfix Tool</data>
  <data key="d1">Tools</data>
  <data key="d2">An automated bug fixing tool leveraging machine learning models to identify and suggest fixes for software bugs.&lt;SEP&gt;An automated tool leveraging machine learning to help identify and fix bugs in software.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jones, C. and Bonsignour, O.">
  <data key="d0">Jones, C. and Bonsignour, O.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The economics of software quality, analyzing costs and benefits associated with software quality management.&lt;SEP&gt;The study of economic aspects of software quality, analyzing costs, benefits, and economic impacts of quality assurance practices.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="The Economics of Software Quality">
  <data key="d0">The Economics of Software Quality</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A comprehensive analysis of how software quality impacts economic factors.&lt;SEP&gt;An analytical approach to understanding how software quality influences economic factors and project costs.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kaiser, Ł. and Sutskever, I.">
  <data key="d0">Kaiser, Ł. and Sutskever, I.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Neural GPUs that learn algorithms, enabling neural networks to perform algorithmic tasks.&lt;SEP&gt;Neural Gpus are neural network architectures designed to learn algorithms and perform complex computations, bridging neural networks and classical algorithms.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural GPUs">
  <data key="d0">Neural GPUs</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A neural network architecture designed to learn and execute algorithms, bridging neural networks and classical algorithms.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kenton, Z. et al.">
  <data key="d0">Kenton, Z. et al.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Alignment of language agents, focusing on ensuring that AI language models behave in accordance with human intentions.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Alignment of Language Agents">
  <data key="d0">Alignment of Language Agents</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A framework for aligning AI language models with human goals, including techniques for value alignment and safe deployment.&lt;SEP&gt;Frameworks and methods aimed at aligning AI language models with human values and goals.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Keskar, N. S. et al.">
  <data key="d0">Keskar, N. S. et al.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Conditional transformer language model (Ctrl) for controllable generation, enabling specific control over generated content.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ctrl: Conditional Transformer Language Model">
  <data key="d0">Ctrl: Conditional Transformer Language Model</data>
  <data key="d1">Tools</data>
  <data key="d2">A transformer-based model designed to generate controllable and specific outputs in language generation tasks.&lt;SEP&gt;A transformer-based model that allows users to control aspects of generated text, such as style, topic, or sentiment.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Korel, B. and Rilling, J.">
  <data key="d0">Korel, B. and Rilling, J.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Application of dynamic slicing in program debugging, to improve efficiency and accuracy in locating bugs.&lt;SEP&gt;Dynamic slicing is a program analysis technique used in debugging to isolate relevant code segments related to specific behaviors or bugs.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dynamic Slicing in Debugging">
  <data key="d0">Dynamic Slicing in Debugging</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique that analyzes program execution to isolate relevant code segments related to specific behaviors or bugs.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Koza, J. R. et al.">
  <data key="d0">Koza, J. R. et al.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Genetic programming as a method for automatic problem solving and invention, inspired by biological evolution.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kulal, S. et al.">
  <data key="d0">Kulal, S. et al.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Search-based pseudocode to code conversion, aimed at automatically translating pseudocode into executable code.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Spoc: Search-based Pseudocode to Code">
  <data key="d0">Spoc: Search-based Pseudocode to Code</data>
  <data key="d1">Tools</data>
  <data key="d2">A system that converts pseudocode into code by searching a database of code snippets, enabling automated programming assistance.&lt;SEP&gt;A system that searches for code snippets matching pseudocode descriptions to facilitate automatic code generation.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sequence Generation with Recurrent Neural Networks">
  <data key="d0">Sequence Generation with Recurrent Neural Networks</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A methodology for generating sequences, such as text or data, using RNNs, fundamental in sequence modeling tasks.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hybrid Computing using Neural Networks with External Memory">
  <data key="d0">Hybrid Computing using Neural Networks with External Memory</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A methodology integrating neural networks with dynamic external memory to perform hybrid computations, enabling advanced problem solving.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automating String Processing in Spreadsheets">
  <data key="d0">Automating String Processing in Spreadsheets</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A technique that automates string manipulation tasks in spreadsheets by learning from input-output examples, reducing manual effort.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Gulwani, S., Harris, W. R., and Singh, R.">
  <data key="d0">Gulwani, S., Harris, W. R., and Singh, R.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researchers focused on spreadsheet data manipulation, developing techniques for automating data processing using examples.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Spreadsheet Data Manipulation">
  <data key="d0">Spreadsheet Data Manipulation</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The process of transforming and managing data within spreadsheets, often using automated techniques.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="He, P., Liu, X., Gao, J., and Chen, W.">
  <data key="d0">He, P., Liu, X., Gao, J., and Chen, W.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Researchers who developed Deberta, an NLP model that enhances BERT with disentangled attention mechanisms for better language understanding.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hindle, A., Barr, E. T., Su, Z., Gabel, M., and Devanbu, P.">
  <data key="d0">Hindle, A., Barr, E. T., Su, Z., Gabel, M., and Devanbu, P.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The concept that software exhibits properties similar to natural language, termed 'the naturalness of software', impacting code analysis and comprehension.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="The Naturalness of Software">
  <data key="d0">The Naturalness of Software</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A theory suggesting that software code has statistical regularities similar to natural language, facilitating language modeling techniques in code analysis.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y.">
  <data key="d0">Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A study exploring issues related to neural text degeneration, such as repetition, incoherence, and loss of diversity in neural language generation.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Husain, H., Wu, H.-H., Gazit, T., Allamanis, M., and Brockschmidt, M.">
  <data key="d0">Husain, H., Wu, H.-H., Gazit, T., Allamanis, M., and Brockschmidt, M.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Evaluation of semantic code search systems, assessing their ability to understand, retrieve, and match code based on semantic meaning.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jeffrey, D., Feng, M., Gupta, N., and Gupta, R.">
  <data key="d0">Jeffrey, D., Feng, M., Gupta, N., and Gupta, R.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A tool that applies machine learning techniques to assist developers in automatically fixing bugs in software code.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Gpus">
  <data key="d0">Neural Gpus</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A neural network architecture that can learn and execute algorithms, enabling neural networks to perform tasks traditionally handled by explicit algorithms.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D.">
  <data key="d0">Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Scaling laws describe how the performance of neural language models improves predictably with increasing model size and data.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kenton, Z., Everitt, T., Weidinger, L., Gabriel, I., Mikulik, V., and Irving, G.">
  <data key="d0">Kenton, Z., Everitt, T., Weidinger, L., Gabriel, I., Mikulik, V., and Irving, G.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Alignment of language agents involves ensuring AI language models behave in ways aligned with human values and instructions.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C., and Socher, R.">
  <data key="d0">Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C., and Socher, R.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Ctrl is a conditional transformer language model enabling controllable generation of text based on specified attributes or constraints.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dynamic Slicing in Program Debugging">
  <data key="d0">Dynamic Slicing in Program Debugging</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique that dynamically analyzes program execution to identify relevant code slices, aiding debugging and fault localization.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Koza, J. R., Andre, D., Keane, M. A., and Bennett III, F. H.">
  <data key="d0">Koza, J. R., Andre, D., Keane, M. A., and Bennett III, F. H.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Genetic programming is an evolutionary algorithm-based method that automatically evolves programs or solutions to complex problems, inspired by biological evolution.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kulal, S., Pasupat, P., Chandra, K., Lee, M., Padon, O., Aiken, A., and Liang, P. S.">
  <data key="d0">Kulal, S., Pasupat, P., Chandra, K., Lee, M., Padon, O., Aiken, A., and Liang, P. S.</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Spoc is a search-based system that translates pseudocode into executable code by searching for matching code snippets, facilitating automatic code synthesis.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Information Processing Systems">
  <data key="d0">Neural Information Processing Systems</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A conference proceedings volume that includes research papers on neural information processing, published in 2019.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Wallach, H., Larochelle, H., Beygelzimer, A., d'Alchée-Buc, F., Fox, E., Garnett, R.">
  <data key="d0">Wallach, H., Larochelle, H., Beygelzimer, A., d'Alchée-Buc, F., Fox, E., Garnett, R.</data>
  <data key="d1">Authors/Editors</data>
  <data key="d2">Editors of the proceedings volume, responsible for compiling and overseeing the publication of research papers in neural information processing.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="gvisor">
  <data key="d0">gvisor</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A sandboxed container runtime that is open-sourced, designed for secure and isolated execution environments, developed in 2018.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Lacasse, N.">
  <data key="d0">Lacasse, N.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author who worked on open-sourcing gvisor, contributing to container security technology in 2018.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Unsupervised translation of programming languages">
  <data key="d0">Unsupervised translation of programming languages</data>
  <data key="d1">Research Topic</data>
  <data key="d2">A method or approach for translating programming languages without labeled data, explored in a 2020 arXiv paper.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Leveson, N.">
  <data key="d0">Leveson, N.</data>
  <data key="d1">Researcher</data>
  <data key="d2">Author focusing on improving risk assessment tools, specifically the standard risk matrix, in 2019.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Li, P. L., Ko, A. J., and Begel, A.">
  <data key="d0">Li, P. L., Ko, A. J., and Begel, A.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of empirical study on software engineers, analyzing traits that distinguish great engineers, published in 2020.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Latent predictor networks">
  <data key="d0">Latent predictor networks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A neural network approach for code generation that models latent variables to improve performance, discussed in a 2016 ACL paper.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Roberta">
  <data key="d0">Roberta</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A robustly optimized BERT pretraining approach designed to enhance natural language understanding, introduced in 2019.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Vilbert">
  <data key="d0">Vilbert</data>
  <data key="d1">Tools</data>
  <data key="d2">A pretraining task-agnostic visiolinguistic representation model for vision-and-language tasks, proposed in 2019.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codexglue">
  <data key="d0">Codexglue</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A benchmark dataset for code understanding and generation tasks, published in 2021, used for evaluating machine learning models.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Maddison, C. J., and Tarlow, D.">
  <data key="d0">Maddison, C. J., and Tarlow, D.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors of structured generative models for natural source code, presented at ICML in 2014.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Structured generative models of natural source code">
  <data key="d0">Structured generative models of natural source code</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Models that generate source code based on structured probabilistic frameworks, aimed at understanding and synthesizing code.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Manna, Z., and Waldinger, R. J.">
  <data key="d0">Manna, Z., and Waldinger, R. J.</data>
  <data key="d1">Researchers</data>
  <data key="d2">Authors exploring automatic program synthesis, published in 1971, focusing on automating code generation processes.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Recalibrating global data center energy-use estimates">
  <data key="d0">Recalibrating global data center energy-use estimates</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">A study investigating how to improve the accuracy of global data center energy consumption estimates, published in 2020.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Cryptography">
  <data key="d0">Cryptography</data>
  <data key="d1">Disciplines</data>
  <data key="d2">A field of study focused on secure communication, with the referenced book providing applied cryptography knowledge, published in 2018.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generating high fidelity images with subscale pixel networks">
  <data key="d0">Generating high fidelity images with subscale pixel networks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A technique for image generation using subscale pixel networks and multidimensional upscaling, developed in 2018.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Distributed representations of words and phrases">
  <data key="d0">Distributed representations of words and phrases</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A foundational concept in NLP where words are represented as vectors capturing semantic and syntactic properties, introduced by Mikolov et al. in 2013.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Open source software supply chain attacks">
  <data key="d0">Open source software supply chain attacks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A review that analyzes vulnerabilities and attack vectors within open-source software supply chains, published in 2020.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Request for comments on intellectual property protection">
  <data key="d0">Request for comments on intellectual property protection</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A formal process for gathering feedback on policies related to AI intellectual property, documented in 2019.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="15-1252.00 - software developers">
  <data key="d0">15-1252.00 - software developers</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A classification code from O*NET representing software developers, used for labor market and occupational analysis, available in 2021.</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="O*NET">
  <data key="d0">O*NET</data>
  <data key="d1">Study Dataset</data>
  <data key="d2">A comprehensive database providing detailed information on occupations, including job roles, skills, and related data, used for occupational analysis.&lt;SEP&gt;O*NET provides comprehensive data on job roles, including software developers, and includes links and summaries relevant to occupational analysis.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="15-1252.00">
  <data key="d0">15-1252.00</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The code 15-1252.00 refers to the occupation of software developers, detailing job responsibilities and skills.&lt;SEP&gt;The specific job code for software developers, detailing their roles, responsibilities, and skill requirements.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Oord, A. v. d., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Senior, A., and Kavukcuoglu, K.">
  <data key="d0">Oord, A. v. d., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Senior, A., and Kavukcuoglu, K.</data>
  <data key="d1">Research Study</data>
  <data key="d2">Authors of the Wavenet paper, introducing a deep generative model for raw audio signals, advancing speech synthesis technology.&lt;SEP&gt;Authors of the Wavenet paper, which introduces a generative model for raw audio, contributing to the field of deep generative modeling.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Wavenet">
  <data key="d0">Wavenet</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A deep generative model for raw audio signals, enabling high-fidelity speech synthesis by modeling the raw waveform directly.&lt;SEP&gt;A deep neural network architecture designed for high-quality, autoregressive generation of raw audio waveforms, enabling realistic speech synthesis.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="arXiv:1609.03499">
  <data key="d0">arXiv:1609.03499</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Preprint publication presenting the Wavenet model, providing experimental results and validation.&lt;SEP&gt;Preprint publication presenting the Wavenet model, serving as evidence of its development and validation.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Oord, A. v. d., Li, Y., and Vinyals, O.">
  <data key="d0">Oord, A. v. d., Li, Y., and Vinyals, O.</data>
  <data key="d1">Research Study</data>
  <data key="d2">Authors of the contrastive predictive coding (CPC) paper, proposing a method for unsupervised representation learning that captures predictive features from data sequences.&lt;SEP&gt;Authors of the contrastive predictive coding paper, proposing a representation learning method that captures useful features from data.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Contrastive Predictive Coding">
  <data key="d0">Contrastive Predictive Coding</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A framework for learning rich, high-level representations by predicting future segments of data in latent space, used in various domains including speech and vision.&lt;SEP&gt;A framework for unsupervised learning of representations by predicting future observations in latent space, enhancing feature extraction.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="arXiv:1807.03748">
  <data key="d0">arXiv:1807.03748</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Preprint detailing the CPC methodology, experiments, and results demonstrating its effectiveness.&lt;SEP&gt;Preprint publication detailing the contrastive predictive coding methodology.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="O’Neill, M. and Spector, L.">
  <data key="d0">O’Neill, M. and Spector, L.</data>
  <data key="d1">Research Study</data>
  <data key="d2">Authors discussing issues in automatic programming and genetic programming, highlighting open research challenges.&lt;SEP&gt;Authors exploring the challenges and open issues in automatic programming, including the use of genetic programming and evolvable machines.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automatic Programming">
  <data key="d0">Automatic Programming</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of automatically generating computer programs, often involving machine learning, genetic algorithms, or evolvable hardware, aimed at reducing manual coding.&lt;SEP&gt;The process of creating programs automatically, often involving genetic programming and evolvable machines, aimed at reducing manual coding effort.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Genetic Programming and Evolvable Machines">
  <data key="d0">Genetic Programming and Evolvable Machines</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques for evolving programs or hardware structures using evolutionary algorithms, enabling automatic code generation and adaptation.&lt;SEP&gt;Techniques used to evolve programs automatically through genetic algorithms and other evolutionary strategies.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pantridge, E., Helmuth, T., McPhee, N. F., and Spector, L.">
  <data key="d0">Pantridge, E., Helmuth, T., McPhee, N. F., and Spector, L.</data>
  <data key="d1">Research Study</data>
  <data key="d2">Authors analyzing the challenges of benchmarking inductive program synthesis methods, emphasizing the difficulty of fair evaluation.&lt;SEP&gt;Authors evaluating methods for benchmarking inductive program synthesis, assessing the difficulty of measuring model performance.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Inductive Program Synthesis">
  <data key="d0">Inductive Program Synthesis</data>
  <data key="d1">Study Design</data>
  <data key="d2">A research area focused on automatically generating programs from specifications or data, with emphasis on benchmarking methods.&lt;SEP&gt;A research area focused on automatically generating programs from specifications or data, with emphasis on evaluation methods and benchmarks.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Carbon emissions and large neural network training">
  <data key="d0">Carbon emissions and large neural network training</data>
  <data key="d1">Results</data>
  <data key="d2">The study quantifies the carbon footprint associated with training large neural networks, highlighting environmental impacts.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Patterson, D., Gonzalez, J., Le, Q., Liang, C., Munguia, L.-M., Rothchild, D., So, D., Texier, M., and Dean, J.">
  <data key="d0">Patterson, D., Gonzalez, J., Le, Q., Liang, C., Munguia, L.-M., Rothchild, D., So, D., Texier, M., and Dean, J.</data>
  <data key="d1">Research Study</data>
  <data key="d2">Authors analyzing the environmental impact of training large neural networks, emphasizing carbon emissions.&lt;SEP&gt;Authors quantifying the carbon footprint of training large neural networks, emphasizing environmental impacts and sustainability issues.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="arXiv:2104.10350">
  <data key="d0">arXiv:2104.10350</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Preprint documenting the carbon footprint of neural network training.&lt;SEP&gt;Preprint report detailing the carbon emissions involved in training large-scale neural models.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L.">
  <data key="d0">Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L.</data>
  <data key="d1">Research Study</data>
  <data key="d2">Authors developing deep contextualized word representations (like ELMo), improving NLP by generating dynamic, context-aware embeddings.&lt;SEP&gt;Authors developing deep contextualized word representations, advancing NLP models.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Deep Contextualized Word Representations">
  <data key="d0">Deep Contextualized Word Representations</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Advanced word embedding techniques such as ELMo that generate context-dependent representations for improved language understanding.&lt;SEP&gt;Techniques such as ELMo that generate dynamic, context-aware word embeddings for improved language understanding.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="arXiv:1802.05365">
  <data key="d0">arXiv:1802.05365</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">Preprint describing the methodology, models, and benefits of deep contextualized embeddings.&lt;SEP&gt;Preprint detailing the methodology and benefits of deep contextualized embeddings.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pierrot, T., Ligner, G., Reed, S., Sigaud, O., Perrin, N., Laterre, A., Kas, D., Beguir, K., and de Freitas, N.">
  <data key="d0">Pierrot, T., Ligner, G., Reed, S., Sigaud, O., Perrin, N., Laterre, A., Kas, D., Beguir, K., and de Freitas, N.</data>
  <data key="d1">Research Study</data>
  <data key="d2">Authors exploring neural program learning with recursive tree search and planning, focusing on neural program synthesis.&lt;SEP&gt;Authors investigating neural program learning, focusing on recursive tree search, planning, and the learning of compositional neural programs.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Program Learning">
  <data key="d0">Neural Program Learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Approaches that involve neural networks learning to generate or interpret programs, often using recursive and planning techniques.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Learning Compositional Neural Programs">
  <data key="d0">Learning Compositional Neural Programs</data>
  <data key="d1">Research Question/Hypotheses</data>
  <data key="d2">Approaches involving neural networks that learn to generate or interpret complex programs via recursive search and planning algorithms.&lt;SEP&gt;Investigates how neural networks can learn to generate complex, compositional programs through recursive search and planning.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Planning, S. The economic impacts of inadequate infrastructure for software testing">
  <data key="d0">Planning, S. The economic impacts of inadequate infrastructure for software testing</data>
  <data key="d1">Study Design</data>
  <data key="d2">A study analyzing economic impacts of infrastructure deficiencies in software testing processes.&lt;SEP&gt;A study analyzing how deficiencies in infrastructure for software testing impact economic factors and productivity.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sourcefinder">
  <data key="d0">Sourcefinder</data>
  <data key="d1">Tools</data>
  <data key="d2">A cybersecurity tool designed to locate malware source code within publicly available repositories such as GitHub, facilitating malware analysis and source code recovery.&lt;SEP&gt;A tool designed to find malware source code from publicly available repositories like GitHub, aiding cybersecurity analysis.&lt;SEP&gt;A tool designed to identify malware source code from publicly available repositories such as GitHub.&lt;SEP&gt;A tool designed to identify malware source code from repositories on GitHub, utilizing data analysis and pattern recognition techniques.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628&lt;SEP&gt;chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GitHub repositories">
  <data key="d0">GitHub repositories</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Public code repositories hosting source code, used as data sources for malware source-code analysis.&lt;SEP&gt;Public repositories hosting source code, used for malware source code analysis in cybersecurity.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Carbon Emissions and Neural Network Training">
  <data key="d0">Carbon Emissions and Neural Network Training</data>
  <data key="d1">Results</data>
  <data key="d2">Quantitative analysis of the environmental impact, specifically carbon footprint, associated with training large neural networks, highlighting sustainability concerns.</data>
  <data key="d3">chunk-b089b4639ea075693b83629858196628</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Biological Structure and Function">
  <data key="d0">Biological Structure and Function</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Biological structure and function emerge from scaling unsupervised learning to analyze 250 million protein sequences, highlighting the relationship between biological data and machine learning methods.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Scaling Unsupervised Learning">
  <data key="d0">Scaling Unsupervised Learning</data>
  <data key="d1">Methodology</data>
  <data key="d2">Applying unsupervised learning techniques to large-scale biological data to understand protein structures and functions.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Protein Sequences">
  <data key="d0">Protein Sequences</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A large dataset consisting of 250 million protein sequences used for modeling biological structures and functions.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Proceedings of the National Academy of Sciences">
  <data key="d0">Proceedings of the National Academy of Sciences</data>
  <data key="d1">Discipline</data>
  <data key="d2">A scientific journal publishing peer-reviewed research across disciplines including biology and computational sciences.&lt;SEP&gt;A scientific journal publishing research on biological and interdisciplinary sciences.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malware Source-Code">
  <data key="d0">Malware Source-Code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Malicious code stored in public repositories analyzed for source code identification.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Research in Attacks, Intrusions and Defenses (RAID 2020)">
  <data key="d0">Research in Attacks, Intrusions and Defenses (RAID 2020)</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference focusing on cybersecurity research, including malware source code analysis.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Poisoning Vulnerabilities in Neural Code Completion">
  <data key="d0">Poisoning Vulnerabilities in Neural Code Completion</data>
  <data key="d1">Results</data>
  <data key="d2">Research demonstrating vulnerabilities in neural code completion systems through poisoning attacks, highlighting security risks.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Program Synthesis">
  <data key="d0">Neural Program Synthesis</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The process of generating computer programs using neural networks, with improvements made via inferred execution traces.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sequence to Sequence Learning">
  <data key="d0">Sequence to Sequence Learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A neural network framework for translating sequences, foundational for tasks like translation and code generation.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="End-to-End Memory Networks">
  <data key="d0">End-to-End Memory Networks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Neural network models that incorporate memory components to improve reasoning and question-answering tasks.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Women’s Participation in Open Source Software">
  <data key="d0">Women’s Participation in Open Source Software</data>
  <data key="d1">Study Design</data>
  <data key="d2">A literature survey analyzing gender diversity and participation in open source communities.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Learning Bug-Fixing Patches">
  <data key="d0">Learning Bug-Fixing Patches</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigating whether neural machine translation can effectively learn to generate bug-fixing patches in real-world software.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Unit Test Case Generation">
  <data key="d0">Unit Test Case Generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using transformers and focal context to automatically generate unit tests, improving software testing processes.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pixel Recurrent Neural Networks">
  <data key="d0">Pixel Recurrent Neural Networks</data>
  <data key="d1">Tools</data>
  <data key="d2">Neural network architecture for image generation and processing, utilizing recurrent connections in pixel space.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Attention is All You Need">
  <data key="d0">Attention is All You Need</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A transformer-based model that relies solely on attention mechanisms to process sequences efficiently.&lt;SEP&gt;A transformer-based neural network architecture relying solely on attention mechanisms for sequence processing.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="GPT-J-6B">
  <data key="d0">GPT-J-6B</data>
  <data key="d1">Tools</data>
  <data key="d2">A 6-billion-parameter autoregressive language model designed for code generation and natural language understanding.&lt;SEP&gt;A large autoregressive language model with 6 billion parameters designed for code and language tasks.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Fun and Dystopia with AI-Based Code Generation">
  <data key="d0">Fun and Dystopia with AI-Based Code Generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Exploring creative and dystopian aspects of AI-generated code using models like GPT-J-6B.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="In-ide Code Generation from Natural Language">
  <data key="d0">In-ide Code Generation from Natural Language</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Assessing the potential and challenges of generating code directly from natural language descriptions.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Biological structure and function">
  <data key="d0">Biological structure and function</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Biological structure and function emerge from scaling unsupervised learning to analyze 250 million protein sequences, illustrating the relationship between large biological datasets and machine learning approaches.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Scaling unsupervised learning">
  <data key="d0">Scaling unsupervised learning</data>
  <data key="d1">Methodology</data>
  <data key="d2">Applying scaling of unsupervised learning techniques to large biological datasets to uncover biological insights.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Protein sequences">
  <data key="d0">Protein sequences</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A dataset comprising 250 million protein sequences used to model biological structures and functions.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Rokon, M. O. F., Islam, R., Darki, A., Papalexakis, E. E., and Faloutsos, M.">
  <data key="d0">Rokon, M. O. F., Islam, R., Darki, A., Papalexakis, E. E., and Faloutsos, M.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers involved in developing Sourcefinder and related cybersecurity research.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malware source code">
  <data key="d0">Malware source code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Malicious code stored in repositories analyzed for source code identification.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)">
  <data key="d0">23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)</data>
  <data key="d1">Study Design</data>
  <data key="d2">A cybersecurity conference where research on malware source code and vulnerabilities was presented.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Schuster, R., Song, C., Tromer, E., and Shmatikov, V.">
  <data key="d0">Schuster, R., Song, C., Tromer, E., and Shmatikov, V.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers studying vulnerabilities in neural code completion systems.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Poisoning vulnerabilities in neural code completion">
  <data key="d0">Poisoning vulnerabilities in neural code completion</data>
  <data key="d1">Results</data>
  <data key="d2">Findings demonstrating how neural code completion systems can be compromised through poisoning attacks, exposing security risks.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Schwartz, R., Dodge, J., Smith, N. A., and Etzioni, O.">
  <data key="d0">Schwartz, R., Dodge, J., Smith, N. A., and Etzioni, O.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers involved in AI ethics and applications, including green AI initiatives.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Green AI">
  <data key="d0">Green AI</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">An approach emphasizing environmentally sustainable and efficient AI models.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Shin, E. C., Polosukhin, I., and Song, D.">
  <data key="d0">Shin, E. C., Polosukhin, I., and Song, D.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers working on neural program synthesis, improving the process with inferred execution traces.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural program synthesis">
  <data key="d0">Neural program synthesis</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The automated generation of computer programs using neural networks, enhanced by inferred execution traces.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sequence-to-sequence learning">
  <data key="d0">Sequence-to-sequence learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">A neural network framework for translating input sequences into output sequences, foundational for tasks like translation and code generation.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Simon, H. A.">
  <data key="d0">Simon, H. A.</data>
  <data key="d1">Research Author</data>
  <data key="d2">Researcher known for experiments with heuristic compilers and computational models.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Experiments with a heuristic compiler">
  <data key="d0">Experiments with a heuristic compiler</data>
  <data key="d1">Study Design</data>
  <data key="d2">Research involving heuristic approaches to compiler design and optimization.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Stack Overflow Developer Survey 2020">
  <data key="d0">Stack Overflow Developer Survey 2020</data>
  <data key="d1">Evidence Type</data>
  <data key="d2">A survey collecting data on developer practices, languages, and technologies, providing insights into developer trends.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sukhbaatar, S., Szlam, A., Weston, J., and Fergus, R.">
  <data key="d0">Sukhbaatar, S., Szlam, A., Weston, J., and Fergus, R.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers developing end-to-end memory networks for reasoning tasks.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="End-to-end memory networks">
  <data key="d0">End-to-end memory networks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Neural networks with explicit memory components designed to improve reasoning and question answering.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sutskever, I., Vinyals, O., and Le, Q. V.">
  <data key="d0">Sutskever, I., Vinyals, O., and Le, Q. V.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers who developed sequence-to-sequence models with neural networks for various applications.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sequence to sequence learning with neural networks">
  <data key="d0">Sequence to sequence learning with neural networks</data>
  <data key="d1">Methodology</data>
  <data key="d2">A neural network training approach for translating sequences, critical for language and code tasks.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Trinkenreich, B., Wiese, I., Sarma, A., Gerosa, M., and Steinhmacher, I.">
  <data key="d0">Trinkenreich, B., Wiese, I., Sarma, A., Gerosa, M., and Steinhmacher, I.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers studying women's participation in open source software communities.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Women’s participation in open source software">
  <data key="d0">Women’s participation in open source software</data>
  <data key="d1">Study Design</data>
  <data key="d2">A literature survey analyzing gender participation and barriers in open source projects.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Tufano, M., Watson, C., Bavota, G., Penta, M. D., White, M., and Poshyvanyk, D.">
  <data key="d0">Tufano, M., Watson, C., Bavota, G., Penta, M. D., White, M., and Poshyvanyk, D.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers conducting empirical studies on neural machine translation for bug-fix patches.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Learning bug-fixing patches">
  <data key="d0">Learning bug-fixing patches</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigating whether neural machine translation models can learn to generate effective bug-fix patches from real-world data.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Tufano, M., Drain, D., Svyatkovskiy, A., Deng, S. K., and Sundaresan, N.">
  <data key="d0">Tufano, M., Drain, D., Svyatkovskiy, A., Deng, S. K., and Sundaresan, N.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers exploring unit test case generation using transformers and focal context.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Unit test case generation with transformers">
  <data key="d0">Unit test case generation with transformers</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Automating the creation of unit tests to improve software quality and developer productivity.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Van Oord, A., Kalchbrenner, N., and Kavukcuoglu, K.">
  <data key="d0">Van Oord, A., Kalchbrenner, N., and Kavukcuoglu, K.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers who developed pixel recurrent neural networks for image processing.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pixel recurrent neural networks">
  <data key="d0">Pixel recurrent neural networks</data>
  <data key="d1">Tools</data>
  <data key="d2">Neural network architecture for image generation and analysis, utilizing recurrent connections in pixel space.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I.">
  <data key="d0">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers who proposed the transformer architecture, foundational for many modern NLP and code models.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Wang, B. and Komatsuzaki, A.">
  <data key="d0">Wang, B. and Komatsuzaki, A.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers who developed GPT-J-6B, a large autoregressive language model for code and language tasks.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Weston, J., Chopra, S., and Bordes, A.">
  <data key="d0">Weston, J., Chopra, S., and Bordes, A.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers known for developing memory networks for reasoning tasks.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Woolf, M.">
  <data key="d0">Woolf, M.</data>
  <data key="d1">Research Author</data>
  <data key="d2">Researcher exploring AI-based code generation, including dystopian and creative applications.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Fun and dystopia with AI-based code generation">
  <data key="d0">Fun and dystopia with AI-based code generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Examining societal, ethical, and dystopian themes related to AI-generated code and its impact.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Xu, F. F., Vasilescu, B., and Neubig, G.">
  <data key="d0">Xu, F. F., Vasilescu, B., and Neubig, G.</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers investigating natural language-based code generation, including promises and challenges.</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="In-ide code generation from natural language">
  <data key="d0">In-ide code generation from natural language</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A process of automatically generating code snippets based on natural language descriptions, highlighting its potential benefits and challenges.&lt;SEP&gt;A process of automatically generating code snippets based on natural language descriptions, with emphasis on its potential and difficulties.&lt;SEP&gt;Assessing the feasibility and challenges of generating code directly from natural language descriptions within IDEs.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20&lt;SEP&gt;chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="F. F. Xu, B. Vasilescu, and G. Neubig">
  <data key="d0">F. F. Xu, B. Vasilescu, and G. Neubig</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers who authored a paper on in-ide code generation from natural language, discussing its promise and challenges.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Yin, P., and G. Neubig">
  <data key="d0">Yin, P., and G. Neubig</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers who developed a neural model for general-purpose code generation, presented at ACL, focusing on syntax-based neural approaches.&lt;SEP&gt;Researchers who developed a neural model for general-purpose code generation, presented at the ACL conference.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Syntactic neural model for general-purpose code generation">
  <data key="d0">Syntactic neural model for general-purpose code generation</data>
  <data key="d1">Theoretical concept</data>
  <data key="d2">A neural network architecture that incorporates syntax to improve code generation across various programming tasks.&lt;SEP&gt;A neural network-based approach utilizing syntax to generate code across various tasks.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="W. Zaremba and I. Sutskever">
  <data key="d0">W. Zaremba and I. Sutskever</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers who worked on learning to execute code, published as an arXiv preprint in 2014.&lt;SEP&gt;Researchers who worked on learning to execute code, published in 2014 as an arXiv preprint.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Learning to execute">
  <data key="d0">Learning to execute</data>
  <data key="d1">Theoretical concept</data>
  <data key="d2">A methodology or model aimed at enabling systems to learn how to perform code execution tasks effectively.&lt;SEP&gt;A methodology or model focused on enabling systems to learn how to execute code or instructions effectively.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="R. Zellers, X. Lu, J. Hessel, Y. Yu, J. S. Park, J. Cao, A. Farhadi, and Y. Choi">
  <data key="d0">R. Zellers, X. Lu, J. Hessel, Y. Yu, J. S. Park, J. Cao, A. Farhadi, and Y. Choi</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers who developed Merlot, a multimodal neural script knowledge model, presented as an arXiv preprint in 2021.&lt;SEP&gt;Researchers who developed Merlot, a multimodal neural script knowledge model, presented in 2021 as an arXiv preprint.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Merlot: Multimodal neural script knowledge models">
  <data key="d0">Merlot: Multimodal neural script knowledge models</data>
  <data key="d1">Theoretical concept</data>
  <data key="d2">A model integrating multiple modalities to understand and generate script knowledge using neural networks.&lt;SEP&gt;A neural model that integrates multiple modalities to understand and generate script knowledge, facilitating multimodal reasoning.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="T. Z. Zhao, E. Wallace, S. Feng, D. Klein, and S. S. Singh">
  <data key="d0">T. Z. Zhao, E. Wallace, S. Feng, D. Klein, and S. S. Singh</data>
  <data key="d1">Research Authors</data>
  <data key="d2">Researchers who worked on calibration techniques to improve few-shot learning performance of language models, published as an arXiv preprint in 2021.&lt;SEP&gt;Researchers who worked on improving few-shot performance of language models through calibration, published as an arXiv preprint in 2021.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Calibrate before use">
  <data key="d0">Calibrate before use</data>
  <data key="d1">Methodology</data>
  <data key="d2">A calibration approach designed to enhance the few-shot learning capabilities of language models before deployment.&lt;SEP&gt;A technique to enhance the performance of language models in few-shot learning scenarios by calibration prior to deployment.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="A. Ziegler">
  <data key="d0">A. Ziegler</data>
  <data key="d1">Researcher</data>
  <data key="d2">Researcher who analyzed rote learning in GitHub Copilot suggestions, published in June 2021.&lt;SEP&gt;Researcher who analyzed rote learning tendencies in GitHub Copilot suggestions, published in June 2021.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Rote learning in GitHub Copilot suggestions">
  <data key="d0">Rote learning in GitHub Copilot suggestions</data>
  <data key="d1">Research Topic</data>
  <data key="d2">The phenomenon of repetitive or memorized code suggestions generated by GitHub Copilot, analyzed for understanding its implications.&lt;SEP&gt;The phenomenon where GitHub Copilot suggests memorized or repetitive code snippets, raising questions about its implications and limitations.</data>
  <data key="d3">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="words">
  <data key="d0">words</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The string of words is the primary textual input from which entities are to be identified.</data>
  <data key="d3">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="return words">
  <data key="d0">return words</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The function 'return words' is intended to extract or process words from the input string.</data>
  <data key="d3">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="y">
  <data key="d0">y</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The letter 'y' is classified as a vowel only when it appears at the end of a word, highlighting its contextual phonetic role.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="vowels_count">
  <data key="d0">vowels_count</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A function designed to count vowels in a string, with specific logic to include 'y' only at the end of words.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="example">
  <data key="d0">example</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Sample function calls demonstrating counting vowels in different words, illustrating the application of the vowel counting methodology.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="vowels">
  <data key="d0">vowels</data>
  <data key="d1">Variables</data>
  <data key="d2">A string or list containing vowel characters ('a', 'e', 'i', 'o', 'u', 'y') used in the counting process.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="count">
  <data key="d0">count</data>
  <data key="d1">Variables</data>
  <data key="d2">An integer variable that accumulates the total number of vowels found in the input string.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="for loop">
  <data key="d0">for loop</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Iterative process to traverse each character in the input string for analysis.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="if condition">
  <data key="d0">if condition</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Conditional check to determine if the current character is a vowel or 'y' at the end of a word, guiding the counting logic.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="return">
  <data key="d0">return</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A keyword indicating a return statement in code, used to specify the output of a function.&lt;SEP&gt;Returns the total count of vowels identified in the input string.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e&lt;SEP&gt;chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="multiply">
  <data key="d0">multiply</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A function intended to multiply the unit digits of two integers, with multiple incorrect implementations provided for analysis.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="a, b">
  <data key="d0">a, b</data>
  <data key="d1">Variables</data>
  <data key="d2">Input integers for the multiply function, representing the numbers whose unit digits are to be multiplied.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="result">
  <data key="d0">result</data>
  <data key="d1">Variables</data>
  <data key="d2">Variable used to store the product of the unit digits or intermediate calculations during the multiplication process.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Vowels_Count">
  <data key="d0">Vowels_Count</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A function designed to count vowels in a string, with specific logic to include 'y' only when it appears at the end of a word, demonstrating a targeted approach to vowel counting.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sample_Calls">
  <data key="d0">Sample_Calls</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Example function calls demonstrating how the vowels_count function processes different inputs, illustrating its behavior and application.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Vowels">
  <data key="d0">Vowels</data>
  <data key="d1">Variables</data>
  <data key="d2">A collection of characters ('a', 'e', 'i', 'o', 'u', 'y') used within the counting function to identify vowels."|&gt;"vowel set</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Count">
  <data key="d0">Count</data>
  <data key="d1">Variables</data>
  <data key="d2">An integer variable that accumulates the total number of vowels identified in the input string during processing.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="For_Loop">
  <data key="d0">For_Loop</data>
  <data key="d1">Methodologies</data>
  <data key="d2">An iterative process that traverses each character in the input string to evaluate whether it is a vowel or 'y' at the end of a word, guiding the counting logic.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="If_Condition">
  <data key="d0">If_Condition</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A conditional check that determines whether the current character is a vowel or 'y' at the end of a word, influencing whether to increment the count.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Return">
  <data key="d0">Return</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The function returns the total count of vowels found after processing the input string, providing the final result.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Multiply_Functions">
  <data key="d0">Multiply_Functions</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Various implementations of a function to multiply the unit digits of two integers, with some incorrect approaches provided for analysis."|&gt;"code analysis</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Examples">
  <data key="d0">Examples</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Sample input-output pairs illustrating the expected behavior of the multiply function, used to evaluate correctness.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Number_A">
  <data key="d0">Number_A</data>
  <data key="d1">Variables</data>
  <data key="d2">First integer input for the multiply function, representing one of the numbers whose unit digit will be multiplied.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Number_B">
  <data key="d0">Number_B</data>
  <data key="d1">Variables</data>
  <data key="d2">Second integer input for the multiply function, representing the other number for unit digit multiplication.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Result">
  <data key="d0">Result</data>
  <data key="d1">Variables</data>
  <data key="d2">Variable to store the product of the unit digits or intermediate calculation results within the multiply function.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code_Analysis">
  <data key="d0">Code_Analysis</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The text analyzes multiple code snippets for correctness, logic, and efficiency in implementing vowel counting and number multiplication functions.</data>
  <data key="d3">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="b_digit">
  <data key="d0">b_digit</data>
  <data key="d1">Variables</data>
  <data key="d2">b_digit is a variable storing the last digit of variable b, obtained via modulo 10 operation.&lt;SEP&gt;b_digit is a variable used to store the last digit of variable b, calculated using modulo 10.</data>
  <data key="d3">chunk-758b1575f8afe059a0beaf2570df4bd6</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 4">
  <data key="d0">COMPLETION 4</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that compares string lengths and returns the longest string or None if the input list is empty.&lt;SEP&gt;A code snippet that returns x if n is divisible by x, else y, with incorrect logic.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 5">
  <data key="d0">COMPLETION 5</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that finds and returns the longest string in a list, or None if the list is empty.&lt;SEP&gt;A code snippet that returns n if n is less than x, else y, with incorrect logic.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 6">
  <data key="d0">COMPLETION 6</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that checks for factors of n and returns y if found, else x, with incorrect logic.&lt;SEP&gt;A code snippet that returns the longest string in a list or None if the list is empty, by comparing string lengths.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 7">
  <data key="d0">COMPLETION 7</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that finds and returns the longest string in a list, or None if the list is empty, using the max function.&lt;SEP&gt;A recursive code snippet that returns x if n is 2, y if n is 3, else calls itself with n-1, with incorrect logic.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 8">
  <data key="d0">COMPLETION 8</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that returns the longest string in a list or None if the list is empty, by iterating and comparing lengths.&lt;SEP&gt;A code snippet that returns x if n equals x, y if n equals y, else returns n, with incorrect logic.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 1">
  <data key="d0">COMPLETION 1</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that returns x if n is divisible by x, else y, with incorrect logic.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 2">
  <data key="d0">COMPLETION 2</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that attempts to return x if n is a prime number, else y, but contains errors.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="COMPLETION 3">
  <data key="d0">COMPLETION 3</data>
  <data key="d1">Results</data>
  <data key="d2">A code snippet that returns x if n is divisible by x, else y, with incorrect logic.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Building Blocks for Synthetic Tasks">
  <data key="d0">Building Blocks for Synthetic Tasks</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A description of 13 modular code and text manipulation blocks used to create synthetic evaluation tasks for language models.</data>
  <data key="d3">chunk-31212d7716c4c20f6aabfd8fb9a1905c</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Synthesis Evaluation Framework">
  <data key="d0">Code Synthesis Evaluation Framework</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A framework for assessing the capabilities of code synthesis and generation systems, focusing on metrics like correctness, complexity, and expressivity of specifications.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Metrics for Formal Specifications">
  <data key="d0">Metrics for Formal Specifications</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Attributes used to measure the expressivity and complexity of formal and natural language specifications, including reasoning over computations, states, and variable dependencies.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Natural Language Prompts">
  <data key="d0">Natural Language Prompts</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Natural language descriptions used as specifications for code synthesis, with varying levels of abstraction and complexity.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="High-Level Requirements">
  <data key="d0">High-Level Requirements</data>
  <data key="d1">Variables</data>
  <data key="d2">Specifications that define broad functionalities or goals, requiring the synthesis system to derive lower-level details, often with greater ambiguity.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Lower-Level Specifications">
  <data key="d0">Lower-Level Specifications</data>
  <data key="d1">Variables</data>
  <data key="d2">More detailed, well-defined constraints and structures within a specification, facilitating more constrained code synthesis.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Variable Interdependencies">
  <data key="d0">Variable Interdependencies</data>
  <data key="d1">Variables</data>
  <data key="d2">Relationships and nesting among multiple variables, including their state permutations and input-output relationships, critical for reasoning about code correctness.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Temporal Reasoning">
  <data key="d0">Temporal Reasoning</data>
  <data key="d1">Variables</data>
  <data key="d2">The ability to consider past and future states of a program, including safety (bad states never occur) and liveness (progress towards goals) properties.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Concurrency and Parallelism">
  <data key="d0">Concurrency and Parallelism</data>
  <data key="d1">Variables</data>
  <data key="d2">The reasoning over and synthesis of code involving multiple processes, interleavings, synchronization, fairness, and race conditions.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hyperproperties">
  <data key="d0">Hyperproperties</data>
  <data key="d1">Variables</data>
  <data key="d2">Information-flow policies and cryptographic algorithms requiring observational determinism, such as noninterference, ensuring security properties in programs.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Nondeterminism">
  <data key="d0">Nondeterminism</data>
  <data key="d1">Variables</data>
  <data key="d2">Algorithms capable of producing different outputs for the same input across different executions, representing non-deterministic processes.&lt;SEP&gt;Nondeterminism refers to the property of certain algorithms that can produce different outputs for the same input across different executions, exemplified by random number generators and some machine learning algorithms.&lt;SEP&gt;Property of algorithms where multiple outputs are possible for the same input, exemplified by random number generators and certain ML algorithms.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a&lt;SEP&gt;chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Evaluation of Synthesis Capabilities">
  <data key="d0">Evaluation of Synthesis Capabilities</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Assessing how well models like Codex understand and execute specifications of varying complexity and abstraction levels.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Benchmarks and Grand Challenges">
  <data key="d0">Benchmarks and Grand Challenges</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Standardized problems and challenges proposed to compare synthesis methodologies scientifically, emphasizing natural language and high-level specifications.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Complexity and Expressivity Attributes">
  <data key="d0">Complexity and Expressivity Attributes</data>
  <data key="d1">Variables</data>
  <data key="d2">Features such as variable dependencies, inter-procedural reasoning, and computational interleavings used to evaluate the sophistication of specifications.</data>
  <data key="d3">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Low-Security Users">
  <data key="d0">Low-Security Users</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Low-security users are individuals with limited access or privileges in a system, whose outputs are observed to be consistent regardless of inputs from high-security users, highlighting aspects of security and access control.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="High-Security Users">
  <data key="d0">High-Security Users</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">High-security users are individuals with elevated privileges in a system, whose inputs can influence system outputs, contrasting with low-security users.&lt;SEP&gt;Users with elevated privileges whose inputs can influence system outputs, contrasting with low-security users.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Deterministic Algorithm">
  <data key="d0">Deterministic Algorithm</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A deterministic algorithm always produces the same output for a given input, regardless of how many times it is run.&lt;SEP&gt;Algorithms that produce the same output for a given input in every execution.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Non-deterministic Algorithm">
  <data key="d0">Non-deterministic Algorithm</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A non-deterministic algorithm can produce different outputs for the same input on different executions, often involving randomness or probabilistic processes.&lt;SEP&gt;Algorithms capable of producing different outputs for the same input across different runs, often involving randomness or probabilistic processes.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Machine Learning Algorithms">
  <data key="d0">Machine Learning Algorithms</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Algorithms that can exhibit nondeterministic behavior, especially during training or inference, due to probabilistic elements.&lt;SEP&gt;ML algorithms are computational models that can exhibit nondeterministic behavior, especially in training processes or probabilistic inference.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Coding Practices">
  <data key="d0">Coding Practices</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Coding strategies that are specification-independent, necessary for achieving attributes like computational and state reasoning.&lt;SEP&gt;Specification-independent coding practices are coding strategies that do not depend on specific implementation details, essential for achieving attributes like computational and state reasoning.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Reuse">
  <data key="d0">Code Reuse</data>
  <data key="d1">Variables</data>
  <data key="d2">Code reuse involves reusing code segments or parameters to improve efficiency and maintainability in programming, relevant for synthesis techniques.&lt;SEP&gt;The practice of reusing code segments or parameters to improve efficiency, maintainability, and synthesis capabilities.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Program Architecture">
  <data key="d0">Program Architecture</data>
  <data key="d1">Variables</data>
  <data key="d2">Program architecture refers to the high-level structure of software systems, which can be automatically determined in advanced coding practices.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Specification-Independent Coding">
  <data key="d0">Specification-Independent Coding</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Coding practices that do not depend on specific specifications, enabling flexible and adaptable program generation.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Higher-Level Specifications">
  <data key="d0">Higher-Level Specifications</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Abstract descriptions of desired system behaviors that should guide code synthesis without requiring explicit constructs.&lt;SEP&gt;Higher-level specifications are abstract descriptions of desired system behaviors that should not require explicit programming constructs, challenging code generation techniques.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Alignment Problems">
  <data key="d0">Alignment Problems</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Alignment problems refer to issues where models do not perform as intended or preferred by users, potentially worsening as model capabilities improve, especially in AI systems.&lt;SEP&gt;Issues where models do not perform as intended or preferred by users, which may worsen as models become more capable.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Capability">
  <data key="d0">Model Capability</data>
  <data key="d1">Variables</data>
  <data key="d2">Model capability indicates the potential of a model to perform specific tasks, which can be enhanced via prompt engineering, fine-tuning, or model surgery.&lt;SEP&gt;The potential or ability of a model to perform specific tasks, which can be enhanced via prompt engineering, fine-tuning, or model modifications.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Intent Misalignment">
  <data key="d0">Intent Misalignment</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Intent misalignment occurs when a model produces outputs that do not match user preferences, despite being capable of producing the desired outputs, often due to the model's training objectives or inherent biases.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Surgery">
  <data key="d0">Model Surgery</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Model surgery refers to modifications or interventions applied to models to alter or improve their capabilities or behaviors.&lt;SEP&gt;Modifying existing models to alter or improve their capabilities or behaviors.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Task X">
  <data key="d0">Task X</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">A specific task or function used to evaluate a model's capability or alignment, often constructed or selected to test particular aspects.&lt;SEP&gt;Task X represents a specific task or function that a model is evaluated on to determine its capability or alignment.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Task Y">
  <data key="d0">Task Y</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">An auxiliary task designed to assess the model's ability to perform task X indirectly, used in capability evaluation.&lt;SEP&gt;Task Y is a related task constructed to assess the model's ability to perform task X indirectly, used in evaluating capabilities.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Capability">
  <data key="d0">Capability</data>
  <data key="d1">Variables</data>
  <data key="d2">Capability indicates whether a model can perform a specific task, often inferred through prompt engineering, fine-tuning, or observing performance on related tasks.&lt;SEP&gt;The ability of a model to perform a specific task or produce a desired output, often inferred through testing or prompting.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Intent">
  <data key="d0">Intent</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Intent refers to the purpose or desired outcome a user expects from a model's output, central to understanding alignment and misalignment.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Output A">
  <data key="d0">Output A</data>
  <data key="d1">Results</data>
  <data key="d2">Output A is the preferred or correct output that a user desires from a model in a given context.&lt;SEP&gt;The preferred or correct output that aligns with user intent in a given context.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Output B">
  <data key="d0">Output B</data>
  <data key="d1">Results</data>
  <data key="d2">An undesired or incorrect output that indicates misalignment or failure to meet user expectations.&lt;SEP&gt;Output B is an alternative or undesired output that a model might produce instead of the preferred output A, indicating misalignment.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Capability to Output A">
  <data key="d0">Capability to Output A</data>
  <data key="d1">Variables</data>
  <data key="d2">The model's ability to produce the desired output A, which may be latent or activated through specific techniques.&lt;SEP&gt;The model's potential or ability to produce the desired output A, which is central to proper alignment.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Capability to Distinguish">
  <data key="d0">Capability to Distinguish</data>
  <data key="d1">Variables</data>
  <data key="d2">The model's ability to recognize situations where output A is preferred over B, essential for proper alignment.&lt;SEP&gt;The model's ability to recognize when the user prefers output A over B, essential for correct behavior.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Security Observation">
  <data key="d0">Security Observation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Observation that outputs by low-security users remain consistent regardless of high-security users' inputs, highlighting aspects of system security and access control.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Random Number Generator">
  <data key="d0">Random Number Generator</data>
  <data key="d1">Tools</data>
  <data key="d2">A simple example of nondeterminism; produces different outputs each time, used in simulations and stochastic processes.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Automatic Program Architecture Determination">
  <data key="d0">Automatic Program Architecture Determination</data>
  <data key="d1">Variables</data>
  <data key="d2">The process of automatically inferring or selecting the high-level structure of programs, relevant in synthesis and code generation.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Programming Constructs">
  <data key="d0">Programming Constructs</data>
  <data key="d1">Variables</data>
  <data key="d2">The building blocks of code, such as loops, conditionals, and functions, which are essential for expressing complex algorithms.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Well-Defined">
  <data key="d0">Well-Defined</data>
  <data key="d1">Variables</data>
  <data key="d2">Attribute indicating that coding practices or specifications have clear, unambiguous definitions, facilitating synthesis.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Applicability">
  <data key="d0">Applicability</data>
  <data key="d1">Variables</data>
  <data key="d2">The extent to which coding practices or techniques can be applied across different contexts or systems.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Alignment">
  <data key="d0">Alignment</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The concept of models producing outputs aligned with user intent, with misalignments leading to potential issues in safety and reliability.</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="alignment evaluations">
  <data key="d0">alignment evaluations</data>
  <data key="d1">Results</data>
  <data key="d2">The results of alignment evaluations assess the model's ability to produce correct, bug-free code and identify misalignments in code-generation models like Codex.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex models">
  <data key="d0">Codex models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Codex models are large language models trained for code generation, capable of producing code but with limitations such as bugs and misalignment issues.&lt;SEP&gt;Codex models are large language models trained for code generation, with capabilities and limitations in producing accurate and secure code.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="alignment">
  <data key="d0">alignment</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Alignment refers to how well a model's outputs match the desired behavior, including correctness, safety, and helpfulness.&lt;SEP&gt;Alignment refers to how well a model's outputs match the desired behavior, including correctness, safety, helpfulness, and adherence to user instructions.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="bug-free code">
  <data key="d0">bug-free code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Bug-free code is code that operates correctly without errors, serving as a benchmark for evaluating model output quality and alignment.&lt;SEP&gt;Bug-free code is code that operates correctly without errors, serving as a benchmark for evaluating model output quality.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="pre-training dataset">
  <data key="d0">pre-training dataset</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The pre-training dataset is the collection of data used to initially train the models, which can be curated to improve output quality and safety.&lt;SEP&gt;The pre-training dataset is the collection of data used to initially train the models, which can be curated to improve output quality, safety, and alignment.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="RL from Human Feedback (RLHF)">
  <data key="d0">RL from Human Feedback (RLHF)</data>
  <data key="d1">Methodologies</data>
  <data key="d2">RLHF is a reinforcement learning approach that uses human feedback to improve model alignment and performance.&lt;SEP&gt;RLHF is a reinforcement learning approach that uses human feedback to improve model alignment, safety, and performance.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="formal analysis">
  <data key="d0">formal analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Formal analysis includes techniques such as formal verification and static code analysis to evaluate code quality, security, and identify bugs, aiding in dataset filtering and model training.&lt;SEP&gt;Formal analysis includes techniques such as formal verification to evaluate code quality and security, aiding in dataset filtering and model training.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="metrics for alignment">
  <data key="d0">metrics for alignment</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics for alignment are quantitative measures used to evaluate how well a model's outputs adhere to desired behaviors, including correctness and safety.&lt;SEP&gt;Metrics for alignment are quantitative measures used to evaluate how well a model's outputs adhere to desired behaviors, including correctness, safety, helpfulness, and robustness.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="transparency tools">
  <data key="d0">transparency tools</data>
  <data key="d1">Tools</data>
  <data key="d2">Transparency tools help interpret and understand model behavior, enabling assessment of alignment beyond input-output evaluation.&lt;SEP&gt;Transparency tools help interpret and understand model decision processes, enabling assessment of alignment, safety, and correctness beyond input-output evaluation.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="evaluation setup">
  <data key="d0">evaluation setup</data>
  <data key="d1">Study Design</data>
  <data key="d2">The evaluation involves testing model performance on a subset of problems with solutions containing subtle bugs, using specific prompts and examples, to assess correctness and robustness.&lt;SEP&gt;The evaluation involves testing model performance on a subset of problems with solutions containing subtle bugs, using specific prompts and examples.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="subtle bugs">
  <data key="d0">subtle bugs</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Subtle bugs are minor errors intentionally inserted into solutions to evaluate the model's ability to detect and correct errors, testing alignment and robustness.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="dataset curation">
  <data key="d0">dataset curation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Dataset curation involves selecting, filtering, and labeling data to improve training quality, reduce bugs, and enhance model safety and alignment.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model safety">
  <data key="d0">model safety</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Model safety encompasses measures to prevent models from producing harmful, insecure, or undesirable outputs, including bugs and unsafe code.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model helpfulness">
  <data key="d0">model helpfulness</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Model helpfulness refers to how effectively the model provides useful, correct, and relevant outputs to user prompts.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model robustness">
  <data key="d0">model robustness</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Model robustness indicates the model's ability to maintain performance across diverse inputs, including handling bugs and out-of-distribution data.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model interpretability">
  <data key="d0">model interpretability</data>
  <data key="d1">Tools</data>
  <data key="d2">Tools that help understand how models generate outputs, assess decision processes, and evaluate alignment and safety.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="metrics for correctness">
  <data key="d0">metrics for correctness</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics that quantify the accuracy of generated code, including correctness, bug detection, and alignment with specifications.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="metrics for safety">
  <data key="d0">metrics for safety</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics that assess the safety of model outputs, such as the absence of insecure or harmful code.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="metrics for helpfulness">
  <data key="d0">metrics for helpfulness</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics that evaluate how useful, relevant, and aligned the model outputs are with user needs.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="metrics for robustness">
  <data key="d0">metrics for robustness</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics that measure the model's ability to handle diverse or challenging inputs without failure.</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="planet2">
  <data key="d0">planet2</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A variable or placeholder representing a planet, possibly used in code or data processing contexts.&lt;SEP&gt;A variable or placeholder representing a second planet, used in code or data processing contexts.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="planet_names">
  <data key="d0">planet_names</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A list or array containing the names of planets, used for indexing or referencing planets.&lt;SEP&gt;A list or array containing the names of planets, used for indexing, referencing, or data retrieval.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="planet1_index">
  <data key="d0">planet1_index</data>
  <data key="d1">Variables</data>
  <data key="d2">An index variable indicating a position in the 'planet_names' list, used to select or reference the first planet.&lt;SEP&gt;An index variable indicating a position in the planet_names list, used to select or reference a specific planet.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="planet2_index">
  <data key="d0">planet2_index</data>
  <data key="d1">Variables</data>
  <data key="d2">An index variable indicating a position in the 'planet_names' list, used to select or reference the second planet.&lt;SEP&gt;An index variable indicating a position in the planet_names list, used to select or reference a specific planet.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="anti_shuffle">
  <data key="d0">anti_shuffle</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A function that takes a string and returns an ordered version of it, where all characters in each word are sorted in ascending ASCII order, preserving word order and spaces.&lt;SEP&gt;A function that takes a string and returns an ordered version of it, where all characters in each word are sorted in ascending ASCII order.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="count_up_to">
  <data key="d0">count_up_to</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A function that takes a non-negative integer n and returns a list of prime numbers less than n, including the first n primes.&lt;SEP&gt;A function that takes a non-negative integer n and returns a list of prime numbers less than n, up to the first n primes.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="smallest_change">
  <data key="d0">smallest_change</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A function that calculates the minimum number of element modifications required to make an array palindromic.&lt;SEP&gt;A function that determines the minimum number of element changes needed to make an array palindromic.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="F. Supplemental Bias Analysis">
  <data key="d0">F. Supplemental Bias Analysis</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">An exploration of biases present in generative models like Codex, particularly regarding harmful biases encoded in code generation, and their implications for safety and fairness.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Generative Models">
  <data key="d0">Bias in Generative Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The phenomenon where generative models, such as language models, encode biases present in training data, leading to biased or harmful outputs.&lt;SEP&gt;The phenomenon where models such as Codex encode and reproduce biases present in training data, leading to potential harms in generated outputs.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Generation Bias">
  <data key="d0">Code Generation Bias</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Generation of biased or harmful code when prompted with sensitive classification tasks, reflecting learned biases.&lt;SEP&gt;Theoretical frameworks explaining how biases manifest in code generated by large language models, including stereotypes and harmful associations.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12&lt;SEP&gt;chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Evaluation of Bias">
  <data key="d0">Evaluation of Bias</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods and probes developed to assess bias in code generation, including prompts for sensitive attributes like gender and race.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Harmful Biases">
  <data key="d0">Harmful Biases</data>
  <data key="d1">Results</data>
  <data key="d2">Instances where code generation models produce biased outputs, such as assuming binary gender or limited racial categories in response to prompts.&lt;SEP&gt;Instances where model outputs exhibit stereotypes, binary assumptions, or limited racial categories, indicating the presence of harmful biases.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety and Fairness Implications">
  <data key="d0">Safety and Fairness Implications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The importance of evaluating and mitigating biases in code generation models to prevent harms and ensure equitable outcomes.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Code Generation">
  <data key="d0">Bias in Code Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The specific bias related to code generation models like Codex, which can produce stereotypical or harmful code snippets based on biased training data.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Probes">
  <data key="d0">Bias Probes</data>
  <data key="d1">Tools</data>
  <data key="d2">Methods developed to assess and evaluate biases in generated code, including prompts for sensitive attributes like gender and race.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Assessment">
  <data key="d0">Bias Assessment</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The process of evaluating models for bias to inform safety, fairness, and mitigation strategies in deploying AI systems.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Mitigation">
  <data key="d0">Bias Mitigation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Strategies and techniques aimed at reducing or eliminating biases encoded in models to prevent harms.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generative Models">
  <data key="d0">Generative Models</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Models trained to generate text or code, such as Codex, which can encode biases from training data.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Natural Language Processing">
  <data key="d0">Bias in Natural Language Processing</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">The encoding and reproduction of societal biases within NLP models, affecting outputs and downstream applications.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Effects">
  <data key="d0">Bias Effects</data>
  <data key="d1">Results</data>
  <data key="d2">Harmful stereotypes, stereotypes reinforcement, and unfair representations in generated outputs.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Model Outputs">
  <data key="d0">Bias in Model Outputs</data>
  <data key="d1">Results</data>
  <data key="d2">Examples of biased outputs, such as binary gender assumptions and limited racial categories.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Impact">
  <data key="d0">Bias Impact</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Potential harms including stereotypes, discrimination, and unfair treatment based on model outputs.</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Protected Classes Prompts">
  <data key="d0">Protected Classes Prompts</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Prompts designed to classify or analyze social categories such as gender, race, and age, often leading or biased, used to evaluate model behavior.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Language Models">
  <data key="d0">Bias in Language Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Bias refers to prejudiced or harmful tendencies encoded in models due to training data or prompts, which can reinforce stereotypes or cause harm.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Harmful Code Generation">
  <data key="d0">Harmful Code Generation</data>
  <data key="d1">Results</data>
  <data key="d2">Generation of code that perpetuates biases or causes harm when prompted with sensitive classification tasks.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Behavior">
  <data key="d0">Model Behavior</data>
  <data key="d1">Variables</data>
  <data key="d2">The outputs and responses of models like Codex when prompted with sensitive or biased prompts, including bias amplification or harmful suggestions.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Correction">
  <data key="d0">Bias Correction</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques aimed at reducing or mitigating biases and harmful responses in models through training adjustments or prompt design.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Analysis">
  <data key="d0">Bias Analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Procedures such as co-occurrence tests to evaluate the presence and extent of biases in generated text or code.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Co-occurrence Tests">
  <data key="d0">Bias Co-occurrence Tests</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Tests measuring the likelihood of biased or prejudiced words appearing near group-related words in generated outputs, indicating bias presence.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Text Comments">
  <data key="d0">Bias in Text Comments</data>
  <data key="d1">Results</data>
  <data key="d2">Analysis showing that bias and prejudiced terms tend to co-occur with group-related words in model-generated comments, similar across models.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Reinforcement">
  <data key="d0">Bias Reinforcement</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Models can inadvertently reinforce harmful stereotypes and biases, especially in sensitive contexts, impacting societal perceptions.&lt;SEP&gt;Potential for models to reinforce harmful stereotypes when generating code or comments, especially in sensitive contexts.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Out-of-Distribution Usage">
  <data key="d0">Out-of-Distribution Usage</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The tendency of models to produce more biased or harmful outputs when prompted in unfamiliar or less typical contexts.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Prompts">
  <data key="d0">Bias in Prompts</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Prompts designed to classify or analyze social categories such as gender, race, and age, often leading or biased, used to evaluate model behavior.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Social Biases">
  <data key="d0">Social Biases</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Prejudiced or stereotypical representations encoded in training data and prompts, which can influence model outputs and reinforce harmful stereotypes.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Training Datasets">
  <data key="d0">Training Datasets</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Datasets containing social biases and encoded class representations that influence model responses.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Responses">
  <data key="d0">Model Responses</data>
  <data key="d1">Variables</data>
  <data key="d2">Outputs of models like Codex when prompted, including biased comments, harmful suggestions, or stereotyped content.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Mitigation Techniques">
  <data key="d0">Bias Mitigation Techniques</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Strategies such as prompt design, fine-tuning, or post-processing aimed at reducing biases in model outputs.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias Evaluation Methods">
  <data key="d0">Bias Evaluation Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Procedures like co-occurrence tests and statistical analyses to measure bias presence and extent in generated text and code.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Co-occurrence Tests">
  <data key="d0">Co-occurrence Tests</data>
  <data key="d1">Analytical Techniques</data>
  <data key="d2">Statistical tests measuring the likelihood of biased or prejudiced words appearing near group-related words in outputs, indicating bias.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Comments">
  <data key="d0">Bias in Comments</data>
  <data key="d1">Results</data>
  <data key="d2">Analysis shows that comments generated by models tend to co-occur with prejudiced or stereotypical terms, indicating bias reinforcement.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Out-of-Distribution Prompts">
  <data key="d0">Out-of-Distribution Prompts</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Prompts that fall outside the model's training distribution, often leading to increased bias or harmful responses.</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Threat Actors">
  <data key="d0">Threat Actors</data>
  <data key="d1">Threat Concepts</data>
  <data key="d2">Entities ranging from low-skilled individuals to organized APT groups that aim to exploit AI models for malicious purposes, driven by objectives such as financial gain, chaos, or operational goals.&lt;SEP&gt;Threat actors encompass a range of malicious entities from low-skilled individuals to organized APT groups, with strategic objectives including financial gain, chaos, information theft, and operational goals.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malicious Code Generation">
  <data key="d0">Malicious Code Generation</data>
  <data key="d1">Methods/Techniques</data>
  <data key="d2">Codex's ability to generate code that can be used in malware, phishing, or other unauthorized offensive activities, especially in creating components of complex malicious systems like polymorphic malware.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Vulnerability Discovery">
  <data key="d0">Vulnerability Discovery</data>
  <data key="d1">Study Design</data>
  <data key="d2">Experiments conducted to assess Codex's capability to identify security vulnerabilities, comparing its performance to static analysis tools.&lt;SEP&gt;The process of identifying security weaknesses in software, which AI models like Codex could assist or be misused to facilitate.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Supply Chain Attack">
  <data key="d0">Supply Chain Attack</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Attacks targeting software dependencies, where malicious or vulnerable packages are introduced, potentially facilitated by AI suggestions.&lt;SEP&gt;Potential for Codex to suggest malicious or vulnerable software dependencies, posing risks to software supply chains through typosquatting or malicious package recommendations.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Potential Misuse">
  <data key="d0">Potential Misuse</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The document investigates whether Codex models can be exploited for malicious purposes such as malware creation, vulnerability discovery, or supply chain attacks, and assesses the risks involved.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Training and Trust Boundary">
  <data key="d0">Model Training and Trust Boundary</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Pre-training and fine-tuning processes that influence the trustworthiness of Codex's outputs, with potential adversarial inputs increasing the risk of malicious suggestions.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Supplemental Security Analysis">
  <data key="d0">Supplemental Security Analysis</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A detailed examination of security risks and potential misuse related to AI models like Codex, including threat actors, attack vectors, and mitigation considerations.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Potential Misuse Applications">
  <data key="d0">Potential Misuse Applications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Possible malicious uses of Codex include generating malware, facilitating phishing, developing polymorphic malware, vulnerability discovery, and supply chain attacks.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Malware">
  <data key="d0">Malware</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Malware refers to malicious software that threat actors may develop or utilize with the help of AI models like Codex to compromise systems or data.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Phishing">
  <data key="d0">Phishing</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Phishing involves fraudulent attempts to obtain sensitive information, which could be aided by AI-generated pretexts or code snippets.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Polymorphic Malware">
  <data key="d0">Polymorphic Malware</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A sophisticated type of malware that changes its code to evade detection; potential target for AI-assisted development.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Static Application Security Testing (SAST) Tools">
  <data key="d0">Static Application Security Testing (SAST) Tools</data>
  <data key="d1">Tools</data>
  <data key="d2">Basic security tools used to identify simple vulnerabilities in code, compared against AI capabilities in vulnerability detection.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Typosquatted Packages">
  <data key="d0">Typosquatted Packages</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Malicious or hijacked software packages with similar names to legitimate ones, which AI might suggest or be exploited to recommend.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Adversarial Inputs">
  <data key="d0">Adversarial Inputs</data>
  <data key="d1">Variables</data>
  <data key="d2">Inputs crafted to manipulate AI models into producing malicious, insecure, or unintended outputs, increasing security risks.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pre-training and Fine-tuning">
  <data key="d0">Pre-training and Fine-tuning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The processes used to develop and adjust AI models like Codex, which influence their trustworthiness and susceptibility to adversarial manipulation.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Security Risks">
  <data key="d0">Security Risks</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Risks associated with the misuse of Codex include generating malicious code, aiding supply chain attacks, and suggesting insecure dependencies, which pose significant cybersecurity threats.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Risk of Malicious Use">
  <data key="d0">Risk of Malicious Use</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The document explores whether Codex can be exploited for malicious activities like malware creation, vulnerability discovery, or supply chain attacks, and assesses the associated risks.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Capabilities and Limitations">
  <data key="d0">Model Capabilities and Limitations</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">The capabilities of Codex are limited but can be exploited as its performance improves, especially in generating code that could be used maliciously.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Trust Boundary">
  <data key="d0">Trust Boundary</data>
  <data key="d1">Methodologies</data>
  <data key="d2">The boundary established by pre-training and fine-tuning processes, which affects how trustworthy or susceptible the model outputs are to adversarial prompts.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Supply Chain Risks">
  <data key="d0">Supply Chain Risks</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Risks arising from AI-suggested malicious or vulnerable dependencies, which can compromise software integrity.</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="tuning processes">
  <data key="d0">tuning processes</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Tuning processes involve methods and activities aimed at adjusting models, generally considered untrusted due to potential security and reliability risks.&lt;SEP&gt;Tuning processes refer to the methods and activities involved in adjusting and optimizing models, which are generally considered untrusted due to inherent risks and vulnerabilities.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model capabilities">
  <data key="d0">model capabilities</data>
  <data key="d1">Variables</data>
  <data key="d2">Model capabilities denote the functionalities and performance levels of models like Codex, which influence potential risks and misuse scenarios.&lt;SEP&gt;Model capabilities refer to the functionalities and performance levels of models like Codex, which influence their potential for misuse and risk generation.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="interest of potential attackers">
  <data key="d0">interest of potential attackers</data>
  <data key="d1">Variables</data>
  <data key="d2">The increasing interest of potential attackers indicates a growing threat landscape, influencing the importance of security measures in model deployment.&lt;SEP&gt;The increasing interest of potential attackers signifies the growing threat landscape and motivates the need for security considerations in model deployment.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex model">
  <data key="d0">Codex model</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The Codex model is an AI system capable of generating code, which can suggest insecure or malicious code, raising security concerns.&lt;SEP&gt;The Codex model is an AI system capable of generating code, which may suggest insecure or malicious code, posing security risks.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="supply chain risk">
  <data key="d0">supply chain risk</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">A new type of supply chain risk arises if Codex models become widespread infrastructure, potentially introducing vulnerabilities into software supply chains.&lt;SEP&gt;Widespread use of Codex as part of software infrastructure could introduce new vulnerabilities into supply chains, representing a novel security threat.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="security-relevant behaviors">
  <data key="d0">security-relevant behaviors</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Behaviors related to models generating insecure code, such as suggesting compromised packages, insecure functions, or secrets, which pose security risks.&lt;SEP&gt;Behaviors related to the generation of insecure code by models like Codex, which may include suggesting compromised packages, insecure functions, or secrets.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="insecure code">
  <data key="d0">insecure code</data>
  <data key="d1">Results</data>
  <data key="d2">Insecure code is code generated by models like Codex that contains vulnerabilities, often due to training on untrusted data, including insecure cryptographic configurations.&lt;SEP&gt;Insecure code refers to code generated by models like Codex that contain vulnerabilities, such as improper cryptographic configurations, due to training on untrusted data.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cryptographic libraries">
  <data key="d0">cryptographic libraries</data>
  <data key="d1">Tools</data>
  <data key="d2">Cryptographic libraries are used in code generation prompts to evaluate whether models produce insecure cryptographic configurations.&lt;SEP&gt;Cryptographic libraries are used in prompts to evaluate whether models produce secure or insecure cryptographic configurations.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="RSA keys">
  <data key="d0">RSA keys</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">RSA keys are cryptographic keys used for encryption; their insecure generation by models indicates vulnerabilities.&lt;SEP&gt;RSA keys are cryptographic keys used for encryption; their insecure generation indicates vulnerabilities in model outputs.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="AES contexts">
  <data key="d0">AES contexts</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">AES contexts are cryptographic configurations; insecure outputs such as ECB mode suggest security flaws.&lt;SEP&gt;AES contexts are cryptographic configurations; insecure outputs suggest security flaws in generated code.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cryptographic vulnerabilities">
  <data key="d0">cryptographic vulnerabilities</data>
  <data key="d1">Taxonomies</data>
  <data key="d2">Cryptographic vulnerabilities categorize common security flaws in cryptographic implementations, which models may inadvertently produce.&lt;SEP&gt;Cryptographic vulnerabilities categorize common security flaws, such as insecure key sizes or modes, that models may produce.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="insecure code production">
  <data key="d0">insecure code production</data>
  <data key="d1">Results</data>
  <data key="d2">Models frequently produce insecure cryptographic configurations, such as short RSA keys or ECB mode AES, reflecting alignment issues and lack of scale-related improvements.&lt;SEP&gt;The study finds that models frequently produce insecure cryptographic configurations, indicating alignment issues and lack of improvement with scale.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="economic and labor market implications">
  <data key="d0">economic and labor market implications</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">This explores how code generation impacts economic value, employment, and security, though current understanding remains preliminary.&lt;SEP&gt;This explores how code generation models impact economic value, labor markets, and potential misuse, though conclusions are preliminary.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="potential misuse">
  <data key="d0">potential misuse</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Potential misuse involves using models like Codex for malicious activities, including automating cybercrime or malware development.&lt;SEP&gt;Potential misuse involves using models like Codex for malicious purposes, such as automating cybercrime or generating malware.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="monitoring and research">
  <data key="d0">monitoring and research</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Monitoring forums and engaging threat analysts are methodologies to track and understand misuse scenarios involving language models.&lt;SEP&gt;Monitoring forums and engaging threat analysts are methodologies used to track and understand misuse scenarios involving language models.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="training on code">
  <data key="d0">training on code</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Training models on code datasets aims to improve capabilities but also raises risks of insecure or malicious code generation.&lt;SEP&gt;Training models on code datasets aims to improve their capabilities but also raises risks of generating insecure or malicious code.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cryptographic contexts">
  <data key="d0">cryptographic contexts</data>
  <data key="d1">Variables</data>
  <data key="d2">Cryptographic contexts are specific configurations or implementations of cryptographic algorithms, which models may generate insecurely.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cryptographic misconfigurations">
  <data key="d0">cryptographic misconfigurations</data>
  <data key="d1">Results</data>
  <data key="d2">Models often produce cryptographic configurations that are insecure, such as short RSA keys or ECB mode AES, indicating alignment issues and no clear scale trend.&lt;SEP&gt;Models often produce cryptographic configurations that are insecure, such as short RSA keys or ECB mode AES, reflecting alignment issues.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="cryptographic testing">
  <data key="d0">cryptographic testing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Testing models on cryptographic prompts to evaluate security of generated code, such as RSA keys and AES contexts.&lt;SEP&gt;Testing models with cryptographic prompts to evaluate security of generated code, such as RSA keys and AES configurations.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="economic impact">
  <data key="d0">economic impact</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Analyzing how code generation affects the economy, employment, and security risks, with recognition that these effects are still early and uncertain.&lt;SEP&gt;Understanding the economic implications of code generation involves assessing how automation may affect employment, productivity, and security risks.</data>
  <data key="d3">chunk-aa0dc077f44be79e1c2829e5cb3b62c2</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ECB">
  <data key="d0">ECB</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">ECB (European Central Bank) is an institution whose policies and decisions are analyzed in the context of financial and monetary stability, often considered in relation to currency management and economic regulation.&lt;SEP&gt;The European Central Bank (ECB) is the central bank for the euro and is responsible for monetary policy, financial stability, and banking supervision within the Eurozone.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Cryptography Experts">
  <data key="d0">Cryptography Experts</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Cryptography experts are specialists in secure communication, encryption standards, and security protocols, providing consensus on best practices and configurations.&lt;SEP&gt;Cryptography experts are specialists who analyze and establish security standards, configurations, and best practices for cryptographic systems.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Conﬁguration Parameters">
  <data key="d0">Conﬁguration Parameters</data>
  <data key="d1">Variables</data>
  <data key="d2">Configuration parameters are specific settings within cryptographic systems, such as key length and cipher mode, that influence security levels.&lt;SEP&gt;Configuration parameters refer to the specific settings and options used in cryptographic systems, such as key length and cipher mode, which impact security.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Encryption Keys">
  <data key="d0">Encryption Keys</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Encryption keys are cryptographic elements used to secure data; their size and configuration determine the strength of encryption.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="RSA Keys">
  <data key="d0">RSA Keys</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">RSA keys are asymmetric cryptographic keys used for encryption and digital signatures; their length (e.g., at least 2048 bits) determines security strength.&lt;SEP&gt;RSA keys are cryptographic keys used in asymmetric encryption, with security depending on key length, commonly recommended to be at least 2048 bits.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="AES Contexts">
  <data key="d0">AES Contexts</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">AES (Advanced Encryption Standard) contexts refer to configurations of AES encryption modes, such as ECB, which have security implications.&lt;SEP&gt;AES contexts refer to specific configurations of AES encryption, including mode of operation like ECB, which impacts security.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="AES Mode: ECB">
  <data key="d0">AES Mode: ECB</data>
  <data key="d1">Methodologies</data>
  <data key="d2">ECB (Electronic Codebook) mode is an AES cipher mode that is generally considered insecure for encrypting large or repetitive data due to pattern leakage.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Large Language Models Trained on Code">
  <data key="d0">Large Language Models Trained on Code</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">AI models like Codex trained on large datasets of source code to generate or assist with programming tasks, impacting workflows and productivity.&lt;SEP&gt;Large Language Models (LLMs) trained on code are AI models designed to generate or assist with programming code, with implications for security and productivity.&lt;SEP&gt;Large Language Models (LLMs) trained on code, such as Codex, are AI systems capable of generating programming code and documentation, with implications for security and productivity.&lt;SEP&gt;Models like Codex that generate code based on training data, with impacts on programming productivity, workforce dynamics, and codebase management.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b&lt;SEP&gt;chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Insecure Encryption Keys">
  <data key="d0">Insecure Encryption Keys</data>
  <data key="d1">Results</data>
  <data key="d2">Encryption keys that are too short (e.g., RSA &lt; 2048 bits) or use insecure modes like ECB are considered insecure and vulnerable to attacks.&lt;SEP&gt;Insecure encryption keys are cryptographic keys that do not meet security standards, such as RSA keys shorter than 2048 bits or AES in ECB mode, leading to vulnerabilities.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Security Standards">
  <data key="d0">Security Standards</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Security standards are established guidelines and best practices for cryptographic configurations to ensure data security and mitigate risks.&lt;SEP&gt;Security standards are guidelines and best practices for configuring cryptographic systems to ensure data confidentiality and integrity.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Impact on Programmers and Engineers">
  <data key="d0">Impact on Programmers and Engineers</data>
  <data key="d1">Results</data>
  <data key="d2">The deployment of AI tools like Codex can increase productivity, reduce costs, and potentially displace some roles, while also creating new markets and changing work dynamics.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Workforce Dynamics">
  <data key="d0">Workforce Dynamics</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Workforce dynamics refer to how AI and automation tools influence employment patterns, skill requirements, and role distributions among programmers and engineers.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Review and QA Testing">
  <data key="d0">Code Review and QA Testing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Code review and quality assurance testing are essential processes to ensure the correctness, security, and quality of code generated by AI tools like Codex.&lt;SEP&gt;Code review and quality assurance testing are essential processes to verify the correctness, security, and efficiency of generated code, especially when using AI tools.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Demographic Patterns of Python Users">
  <data key="d0">Demographic Patterns of Python Users</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Research data on Python users' demographics helps understand how AI tools like Codex impact different societal groups and roles in programming.&lt;SEP&gt;Research on the demographic distribution of Python programmers helps understand how AI impacts different societal groups and roles.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ECB Mode">
  <data key="d0">ECB Mode</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">ECB (Electronic Codebook) is an AES cipher mode that encrypts identical plaintext blocks into identical ciphertext, making it insecure for most applications.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Insecure Configurations">
  <data key="d0">Insecure Configurations</data>
  <data key="d1">Results</data>
  <data key="d2">Insecure configurations include cryptographic keys shorter than recommended (e.g., RSA &lt; 2048 bits) and use of insecure cipher modes like ECB, leading to vulnerabilities.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Impacts on Programmers and Engineers">
  <data key="d0">Impacts on Programmers and Engineers</data>
  <data key="d1">Results</data>
  <data key="d2">AI tools like Codex impact the work of programmers and engineers by increasing productivity, reducing costs, and potentially displacing some roles, while also creating new work opportunities.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Workflows and Work Dynamics">
  <data key="d0">Workflows and Work Dynamics</data>
  <data key="d1">Disciplines</data>
  <data key="d2">Workflows and work dynamics refer to how AI tools influence programming practices, role distributions, and collaboration patterns among software professionals.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Stack Overflow">
  <data key="d0">Stack Overflow</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Stack Overflow is an online community where programmers share knowledge, and it is referenced as a data source for understanding developer demographics and behaviors.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Women">
  <data key="d0">Women</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Women are represented more in data science and analysis roles compared to other technical roles such as DevOps, system administration, and site reliability.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Data Science and Analysis Roles">
  <data key="d0">Data Science and Analysis Roles</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Roles involving data analysis, interpretation, and scientific computing, with higher representation of women according to the referenced data.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="DevOps, System Administrator, Site Reliability">
  <data key="d0">DevOps, System Administrator, Site Reliability</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Technical roles in software engineering with comparatively lower representation of women.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Programmers and Engineers">
  <data key="d0">Programmers and Engineers</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Engineers and programmers whose workflows and productivity may be affected by the adoption of code generation tools like Codex.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Import Packages and Libraries">
  <data key="d0">Import Packages and Libraries</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Reusable code modules such as PyTorch, TensorFlow, Matplotlib, Seaborn that are imported into code files for various functionalities.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Economic and Security Implications">
  <data key="d0">Economic and Security Implications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Potential effects of differential package import rates include economic advantages for dominant package maintainers, safety risks, and security concerns.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Survey of Python Developers">
  <data key="d0">Survey of Python Developers</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A 2020 survey by Python Software Foundation and JetBrains providing data on Python usage patterns, demographics, and community participation.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Differential Package Import Rates">
  <data key="d0">Differential Package Import Rates</data>
  <data key="d1">Variables</data>
  <data key="d2">Patterns in how often different packages are imported by Codex, with potential effects on robustness, dominance, and economic outcomes.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Subtle Errors and Robustness">
  <data key="d0">Subtle Errors and Robustness</data>
  <data key="d1">Results</data>
  <data key="d2">Variations in package import patterns may lead to errors or increased robustness depending on the context and choice of packages.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dependence on Code Generation Models">
  <data key="d0">Dependence on Code Generation Models</data>
  <data key="d1">Results</data>
  <data key="d2">Growing reliance on AI tools for code import decisions and programming workflow, influenced by user adaptation and prompting strategies.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="users (Stack Overflow, 2020)">
  <data key="d0">users (Stack Overflow, 2020)</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Users of Stack Overflow, as surveyed in 2020, provide data on demographics, role representation, and community participation relevant for research on developer populations.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="women">
  <data key="d0">women</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Women are more represented in data science and analysis roles than in other engineering roles such as DevOps, system administration, and site reliability.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="data science and analysis roles">
  <data key="d0">data science and analysis roles</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Roles involving data analysis, scientific computing, and related tasks, with higher representation of women as indicated by the survey.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="DevOps, system administrator, site reliability roles">
  <data key="d0">DevOps, system administrator, site reliability roles</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Technical roles in software engineering with comparatively lower female representation.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="programmers and programmers">
  <data key="d0">programmers and programmers</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Engineers and developers whose workflows are affected by code generation tools.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code generation tools">
  <data key="d0">Code generation tools</data>
  <data key="d1">Tools</data>
  <data key="d2">Automated systems like Codex that generate code, facilitate programming, and automate repetitive tasks, influencing skill development and access.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="import packages and libraries">
  <data key="d0">import packages and libraries</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Reusable code modules such as PyTorch, TensorFlow, Matplotlib, Seaborn, which are imported into code files for various functionalities.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Patterns of package import rates">
  <data key="d0">Patterns of package import rates</data>
  <data key="d1">Variables</data>
  <data key="d2">The frequency and choice of imported packages by Codex, influenced by training data, affecting code robustness and economic implications.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Economic implications">
  <data key="d0">Economic implications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The differential import patterns could influence the economic landscape for package creators and maintainers, as well as security.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Security implications">
  <data key="d0">Security implications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Reliance on specific packages and import patterns could pose security risks or vulnerabilities in software.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Survey of Python Developers (2020)">
  <data key="d0">Survey of Python Developers (2020)</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A survey conducted by Python Software Foundation and JetBrains to gather data on Python usage, community demographics, and community participation.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Potential effects on non-engineers">
  <data key="d0">Potential effects on non-engineers</data>
  <data key="d1">Results</data>
  <data key="d2">Code generation tools may broaden programming access for non-engineers and shift skill requirements.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Impacts of differential package import rates">
  <data key="d0">Impacts of differential package import rates</data>
  <data key="d1">Results</data>
  <data key="d2">Variations in import rates can lead to errors, increased robustness, or dominance of certain packages, with economic and safety impacts.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Dependence on code generation models">
  <data key="d0">Dependence on code generation models</data>
  <data key="d1">Results</data>
  <data key="d2">Growing reliance on AI tools like Codex for code suggestions and import decisions, influencing programming workflows over time.</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Users">
  <data key="d0">Users</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Users are individuals interacting with large language models like Codex, adapting their behavior and decision-making processes based on AI suggestions.&lt;SEP&gt;Users are individuals who interact with Codex, learning to prompt engineer and potentially changing their workflows and decision-making processes.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Machine Learning Packages">
  <data key="d0">Machine Learning Packages</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Machine learning packages such as TensorFlow and PyTorch are software libraries used for developing machine learning models, with suggestions made by Codex influencing user choices.&lt;SEP&gt;Machine learning packages such as TensorFlow and PyTorch are software libraries used for developing machine learning models; their suggestions by Codex influence user choices and market entrenchment.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Generation Technologies">
  <data key="d0">Code Generation Technologies</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Code generation tools like Codex have implications for software development efficiency, worker productivity, and barriers to entry in programming.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Open-source Developers">
  <data key="d0">Open-source Developers</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Open-source developers maintain and update software packages, facing challenges like deprecated methods suggested by Codex, resource constraints, and maintaining backward compatibility.&lt;SEP&gt;Open-source developers maintain and update software packages, facing challenges related to backward compatibility and resource constraints, influenced by AI suggestions.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Biases in Training Data">
  <data key="d0">Biases in Training Data</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Biases in training data refer to the skewed representation of packages and methods in Codex's training set, which can influence its suggestions and perpetuate outdated or deprecated methods.&lt;SEP&gt;Biases in training data refer to the skewed representation of packages, methods, and practices within Codex's training set, which influence its suggestions and may perpetuate outdated or deprecated methods.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Impacts on Labor Market">
  <data key="d0">Impacts on Labor Market</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The research explores how AI code generation tools like Codex may affect labor market outcomes, wages, and worker productivity in high-skill domains.&lt;SEP&gt;The research hypothesizes that AI code generation tools like Codex could affect labor market outcomes, worker productivity, wages, and disparities across groups.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Documentation and Testing Practices">
  <data key="d0">Code Documentation and Testing Practices</data>
  <data key="d1">Variables</data>
  <data key="d2">Practices related to documenting code and writing tests are influenced by Codex, potentially improving quality but also risking propagation of subtle errors.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Future Directions">
  <data key="d0">Future Directions</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Future directions include assessing the economic value of improved code generation, impacts on productivity, barriers to entry, and policy responses to AI automation in coding.&lt;SEP&gt;Future research directions include quantifying economic value, assessing impacts on productivity, barriers to entry, biases, and policy responses related to AI-assisted coding.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Time">
  <data key="d0">Time</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Time refers to the ongoing process during which users adapt to working with AI systems like Codex, affecting their learning and decision-making over periods.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code Documentation Practices">
  <data key="d0">Code Documentation Practices</data>
  <data key="d1">Variables</data>
  <data key="d2">Practices related to documenting code and writing tests are influenced by Codex, potentially improving documentation quality but also propagating subtle errors or encouraging over-reliance.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Testing Practices">
  <data key="d0">Testing Practices</data>
  <data key="d1">Variables</data>
  <data key="d2">Testing practices for code may be affected by Codex, which can help generate tests but might lead to less thorough human verification and specification.</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Codex">
  <data key="d0">Codex</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Codex is an advanced AI language model trained on a vast corpus of publicly available code, primarily sourced from GitHub. It is a specialized version of GPT-3 designed explicitly for code generation and understanding programming tasks. Capable of producing, completing, and understanding code snippets across multiple programming languages, especially Python, Codex can assist or substitute human programmers, thereby impacting productivity, code import patterns, and the broader software development market. It is used in tools such as GitHub Copilot and the OpenAI API to generate code, documentation, and tests based on natural language prompts. 

Evaluated across various sizes, from 12 million to 12 billion parameters, Codex has demonstrated notable accuracy in code generation, including metrics like pass@k for functional correctness. It is also employed to assess bias and harm in AI-generated outputs, ensuring safer and more ethical applications. Despite its strengths, Codex has notable limitations, including inefficiencies, challenges with system-level synthesis, and difficulties handling complex prompts. There are security considerations as well, since insecure configurations could pose risks, and potential misuse for malicious purposes exists. Overall, Codex is a powerful, AI-driven tool that influences programming practices, developer behavior, and market dynamics through its ability to generate and suggest code, comments, and documentation.</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9&lt;SEP&gt;chunk-735818e62b066d03c2144cdb5db162c1&lt;SEP&gt;chunk-b15d5bb768f451028654d71370cc6879&lt;SEP&gt;chunk-bf1121c44634b616af61c49cd3adf29a&lt;SEP&gt;chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-10b08670a9cf75866c6b05fa5b5cfc12&lt;SEP&gt;chunk-706ca7a8d3fc8406a24b8328b849606b&lt;SEP&gt;chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-d25502af8737c59d857916af40cc4020&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Repeated Sampling">
  <data key="d0">Repeated Sampling</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d2">Repeated sampling from Codex significantly increases the likelihood of generating correct solutions, with 70.2% success using 100 samples per problem.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Broader Impacts">
  <data key="d0">Broader Impacts</data>
  <data key="d3">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d2">Discussion of safety, security, and economic implications of deploying large language models trained on code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model improvement">
  <data key="d0">Model improvement</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d2">Fine-tuning Codex on correctly implemented functions enhances its ability to generate accurate solutions, improving overall performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model capability">
  <data key="d0">Model capability</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d2">The research hypothesizes that models like Codex can effectively generate correct code from natural language descriptions, with performance improving through techniques like fine-tuning and multiple sampling.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model limitations">
  <data key="d0">Model limitations</data>
  <data key="d3">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d2">The models are limited by training data, computational resources, and the inherent complexity of programming tasks, affecting their overall accuracy and usefulness.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Models' problem-solving capabilities">
  <data key="d0">Models' problem-solving capabilities</data>
  <data key="d3">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d2">Metrics like pass@k and BLEU score are used to quantify the models' ability to generate correct code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Sample Ranking">
  <data key="d0">Sample Ranking</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d2">Back-translation is used as a technique to rank generated samples based on their quality, though it underperforms mean log-probability ranking in some cases.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model">
  <data key="d0">Model</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834&lt;SEP&gt;chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d2">Large Language Models (LLMs) such as GPT-Neo, PolyCoder, and GPT2 are used for code generation and classification tasks in HPC contexts.&lt;SEP&gt;The training dataset comprising problems, solutions, and docstrings is used to train models like Codex-D for code and docstring generation.</data>
  <data key="d1">Tools</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Manual Grading">
  <data key="d0">Manual Grading</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d2">Manual grading assesses the correctness of generated docstrings when automatic metrics are insufficient.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="pass@k and manual grading">
  <data key="d0">pass@k and manual grading</data>
  <data key="d3">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d2">Model evaluation includes measuring pass@k success rates and manual assessment of docstring correctness to determine overall quality.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Impact analysis">
  <data key="d0">Impact analysis</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Impact analysis is performed to understand how models' properties and behaviors influence safety and societal impact.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety features">
  <data key="d0">Safety features</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Over-reliance increases safety risks, highlighting the importance of safety features and oversight.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias and representation">
  <data key="d0">Bias and representation</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Bias and representation issues are influenced by the training data distribution and can lead to harmful outputs.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="user's intentions">
  <data key="d0">user's intentions</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Misalignment occurs when models generate outputs that do not align with the user's intended task, leading to potential safety issues.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Empirical investigation">
  <data key="d0">Empirical investigation</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Empirical investigation aims to determine how best to implement human oversight to ensure safety.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="User's Intentions">
  <data key="d0">User's Intentions</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Misalignment occurs when models generate outputs that do not align with the user's true intentions, leading to safety concerns.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety Practices">
  <data key="d0">Safety Practices</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Empirical investigation helps identify effective safety practices and vigilance methods across different user scenarios.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety and Risk Management">
  <data key="d0">Safety and Risk Management</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Human oversight is crucial for managing safety and mitigating risks, especially in complex or subtle situations.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety Risks">
  <data key="d0">Safety Risks</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Limitations of models contribute directly to safety risks, such as suggesting insecure code or producing incorrect results.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Model Safety">
  <data key="d0">Model Safety</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">Evaluation metrics are used to quantify how well models perform in terms of safety, bias, and alignment.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Safety and Vigilance">
  <data key="d0">Safety and Vigilance</data>
  <data key="d3">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d2">User experience factors like trust and reliance influence the level of vigilance needed for safe use.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Classical Approaches">
  <data key="d0">Classical Approaches</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">Classical probabilistic context-free grammar methods are foundational in program synthesis, with neural methods building upon or improving these approaches.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hindle et al. (2012)">
  <data key="d0">Hindle et al. (2012)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">Investigated the predictability of code using n-gram language models, showing code's relative predictability over natural language.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Ling et al. (2016)">
  <data key="d0">Ling et al. (2016)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">Demonstrated code generation for Magic the Gathering cards using character-level models aided by latent modes.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Balog et al. (2017)">
  <data key="d0">Balog et al. (2017)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">DeepCoder trained to predict functions in source code to guide program search, improving synthesis processes.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Devlin et al. (2017)">
  <data key="d0">Devlin et al. (2017)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">RobustFill synthesizes multiple code samples through beam search to find programs consistent with input examples, improving robustness.&lt;SEP&gt;RobustFill synthesizes multiple code samples via beam search to find consistent programs, enhancing synthesis robustness.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Feng et al. (2020)">
  <data key="d0">Feng et al. (2020)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">CodeBERT trained on docstrings and functions for code search, linking natural language and code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Clement et al. (2020)">
  <data key="d0">Clement et al. (2020)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">PyMT5 trained to translate between code and language, facilitating code translation tasks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kulal et al. (2019)">
  <data key="d0">Kulal et al. (2019)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">SPoC considers producing functionally correct code from pseudocode within a fixed compilation budget.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Lachaux et al. (2020)">
  <data key="d0">Lachaux et al. (2020)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">TransCoder translates code between languages in an unsupervised manner, improving cross-language code understanding.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jain et al. (2020)">
  <data key="d0">Jain et al. (2020)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">ContraCode leverages the space of functionally correct programs to improve code modeling and inference.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Husain et al. (2019)">
  <data key="d0">Husain et al. (2019)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">CodeSearchNet provides a large dataset for benchmarking code understanding and generation models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Lu et al. (2021)">
  <data key="d0">Lu et al. (2021)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">CodeXGLUE aggregates multiple code benchmarks, facilitating comprehensive evaluation of code models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hendrycks et al. (2021)">
  <data key="d0">Hendrycks et al. (2021)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">APPS benchmark measures functional correctness on programming problems, used for evaluating code models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Tufano et al. (2020)">
  <data key="d0">Tufano et al. (2020)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">Generation of unit tests for code to verify correctness, used in code synthesis and debugging.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Drain et al. (2021)">
  <data key="d0">Drain et al. (2021)</data>
  <data key="d3">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d2">Recent works focus on locating and fixing bugs in code, using static/dynamic analysis, learned rules, or genetic programming.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="He, P. et al.">
  <data key="d0">He, P. et al.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d2">He et al. developed Deberta, an NLP model that improves language understanding with disentangled attention mechanisms.&lt;SEP&gt;He et al. developed Deberta, an NLP model that improves language understanding with disentangled attention.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Hindley, A. et al.">
  <data key="d0">Hindley, A. et al.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d2">Hindley's benchmark suite is used to evaluate program synthesis algorithms.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Measuring Coding Challenge Competence">
  <data key="d0">Measuring Coding Challenge Competence</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d2">Hendrycks et al. investigate how applications can objectively assess programming skills through empirical studies.&lt;SEP&gt;Hendrycks et al. investigate how apps can measure software development skills.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Jain, P. et al.">
  <data key="d0">Jain, P. et al.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d2">Jain et al. propose a contrastive learning approach to improve semantic code representations, enhancing code understanding and retrieval.&lt;SEP&gt;Jain et al. propose contrastive learning methods to improve semantic code representations.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Economics of Software Quality">
  <data key="d0">Economics of Software Quality</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d2">Jones and Bonsignour analyze the economic impacts and costs associated with software quality management.&lt;SEP&gt;Jones and Bonsignour analyze the economic impacts, costs, and benefits associated with software quality assurance practices.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kaplan, J. et al.">
  <data key="d0">Kaplan, J. et al.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d2">Kaplan et al. empirically investigate how model size influences performance in neural language models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kaplan, J., McCandlish, S., Henighan, T., et al.">
  <data key="d0">Kaplan, J., McCandlish, S., Henighan, T., et al.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d2">Kaplan et al. empirically investigate how model size and training data influence performance, establishing scaling laws.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Kenton, Z., Everitt, T., Weidinger, L., et al.">
  <data key="d0">Kenton, Z., Everitt, T., Weidinger, L., et al.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d2">Kenton et al. focus on techniques and frameworks for aligning AI language models with human values and instructions.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Keskar, N. S., McCann, B., Varshney, L. R., et al.">
  <data key="d0">Keskar, N. S., McCann, B., Varshney, L. R., et al.</data>
  <data key="d3">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d2">Keskar et al. developed Ctrl, a conditional transformer model allowing controllable and attribute-specific language generation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Open-sourcing">
  <data key="d0">Open-sourcing</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">Lacasse, N. contributed to the open-source project of gvisor, a sandboxed container runtime, in 2018.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Research">
  <data key="d0">Research</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">A 2020 arXiv paper explores methods for translating programming languages without supervision, contributing to programming language processing techniques.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Leveson, N">
  <data key="d0">Leveson, N</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">Leveson proposed improvements to the standard risk matrix to enhance risk assessment practices in 2019.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Risk matrix">
  <data key="d0">Risk matrix</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">Leveson proposed improvements to the standard risk matrix to enhance risk assessment practices in 2019.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Li, P. L., Ko, A. J., and Begel, A">
  <data key="d0">Li, P. L., Ko, A. J., and Begel, A</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">The empirical study analyzes what traits distinguish great software engineers, published in 2020.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Software engineers">
  <data key="d0">Software engineers</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">The empirical study analyzes what traits distinguish great software engineers, published in 2020.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Code generation">
  <data key="d0">Code generation</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">A 2016 ACL paper discusses latent predictor networks used for generating code, advancing AI-driven code synthesis.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Pretraining approach">
  <data key="d0">Pretraining approach</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">Roberta is a pretraining method that improves BERT's performance, introduced in 2019.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Visiolinguistic representations">
  <data key="d0">Visiolinguistic representations</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">Vilbert provides visiolinguistic representations for vision-and-language tasks, introduced in 2019.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Benchmark dataset">
  <data key="d0">Benchmark dataset</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">Codexglue serves as a benchmark for code understanding and generation, released in 2021.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Structured generative models">
  <data key="d0">Structured generative models</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">They developed models for generating natural source code based on structure, presented at ICML 2014.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Energy research">
  <data key="d0">Energy research</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">The 2020 study aims to improve the accuracy of global data center energy consumption estimates, impacting energy policy and sustainability.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Applied cryptography">
  <data key="d0">Applied cryptography</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">The book provides foundational and applied cryptography knowledge, relevant to secure communications, published in 2018.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Generating high fidelity images">
  <data key="d0">Generating high fidelity images</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">The 2018 methodology uses subscale pixel networks to generate high-fidelity images, advancing image synthesis techniques.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Image generation">
  <data key="d0">Image generation</data>
  <data key="d3">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d2">The 2018 methodology uses subscale pixel networks to generate high-fidelity images, advancing image synthesis techniques.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Poisoning Vulnerabilities">
  <data key="d0">Poisoning Vulnerabilities</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Research demonstrates vulnerabilities in neural code completion systems, indicating security risks.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural Machine Translation">
  <data key="d0">Neural Machine Translation</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Neural machine translation techniques are applied to learn bug-fixing patches from code repositories.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Image Processing">
  <data key="d0">Image Processing</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Pixel RNNs are used for image generation and processing tasks, utilizing recurrent connections in pixel space.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="In-ide Code Generation">
  <data key="d0">In-ide Code Generation</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Natural language descriptions are used as input for in-IDE code generation models, enabling automatic code synthesis.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Natural Language">
  <data key="d0">Natural Language</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Natural language descriptions are used as input for in-IDE code generation models, enabling automatic code synthesis.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="AI-Based Code Generation">
  <data key="d0">AI-Based Code Generation</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Explores the societal and creative implications of AI-generated code, including dystopian themes.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Fun and Dystopia">
  <data key="d0">Fun and Dystopia</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Explores the societal and creative implications of AI-generated code, including dystopian themes.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Poisoning vulnerabilities">
  <data key="d0">Poisoning vulnerabilities</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Vulnerabilities in neural program synthesis systems can be exploited through poisoning attacks, highlighting security concerns.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Neural machine translation">
  <data key="d0">Neural machine translation</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Neural machine translation techniques are employed to learn bug-fixing patches from code repositories, aiding automated software maintenance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Image processing">
  <data key="d0">Image processing</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Pixel RNNs are used for image generation and analysis, leveraging recurrent connections in pixel space.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="In-ide code generation">
  <data key="d0">In-ide code generation</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Natural language descriptions are used as input to generate code within IDEs, enabling seamless code synthesis from natural language.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Natural language">
  <data key="d0">Natural language</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Natural language descriptions are used as input to generate code within IDEs, enabling seamless code synthesis from natural language.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="AI-based code generation">
  <data key="d0">AI-based code generation</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Explores societal implications, dystopian themes, and creative uses of AI-generated code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Fun and dystopia">
  <data key="d0">Fun and dystopia</data>
  <data key="d3">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d2">Explores societal implications, dystopian themes, and creative uses of AI-generated code.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="ML Algorithms">
  <data key="d0">ML Algorithms</data>
  <data key="d3">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d2">ML algorithms exemplify nondeterminism by producing different outputs for the same input across executions, especially in probabilistic models.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model behavior">
  <data key="d0">model behavior</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d2">Fine-tuning on curated datasets improves the model's ability to generate bug-free and helpful code outputs."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="RL from Human Feedback">
  <data key="d0">RL from Human Feedback</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d2">RLHF uses human feedback to guide models toward better alignment with user expectations and safety standards."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="model improvement">
  <data key="d0">model improvement</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d2">RLHF uses human feedback to guide models toward better alignment with user expectations and safety standards."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="dataset filtering">
  <data key="d0">dataset filtering</data>
  <data key="d3">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d2">Formal analysis techniques can identify insecure or buggy code, aiding in filtering datasets for better training."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Content Keywords">
  <data key="d0">Content Keywords</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d2">Main themes and overarching topics of the document</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Core Concepts, Theories/Models, Methodologies, Study Designs, Evidence Types, Research Questions/Hypotheses, Results, Objects of Study, Taxonomies, Variables, Tools, Analytical Techniques, Disciplines, Spatiotemporal Information, Study Populations/Dataset, Applications/Implications, Limitations">
  <data key="d0">Core Concepts, Theories/Models, Methodologies, Study Designs, Evidence Types, Research Questions/Hypotheses, Results, Objects of Study, Taxonomies, Variables, Tools, Analytical Techniques, Disciplines, Spatiotemporal Information, Study Populations/Dataset, Applications/Implications, Limitations</data>
  <data key="d3">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d2">Main themes and overarching topics of the document</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="string">
  <data key="d0">string</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">The 'anti_shuffle' function processes a string to produce an ordered version of each word, indicating a transformation or processing relationship."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="prime numbers">
  <data key="d0">prime numbers</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">The 'count_up_to' function generates prime numbers less than a given number, representing a generation or enumeration relationship."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="array">
  <data key="d0">array</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">The 'smallest_change' function analyzes an array to determine the minimal modifications needed to make it palindromic, indicating an analysis or transformation relationship."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="generative models">
  <data key="d0">generative models</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">The bias analysis explores how models like Codex encode harmful biases, indicating a relationship of investigation or exploration."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias">
  <data key="d0">Bias</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">Bias in models leads to harmful outputs, such as stereotypes, demonstrating a cause-effect relationship."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="harmful outputs">
  <data key="d0">harmful outputs</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">Bias in models leads to harmful outputs, such as stereotypes, demonstrating a cause-effect relationship."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="bias probes">
  <data key="d0">bias probes</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">Probes are used to evaluate the presence of bias in generated code, establishing a testing or assessment relationship."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Bias in Models">
  <data key="d0">Bias in Models</data>
  <data key="d3">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d2">Assessment methods evaluate the extent and nature of biases in model outputs to inform mitigation."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Prompts for Classification">
  <data key="d0">Prompts for Classification</data>
  <data key="d3">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d2">Prompts designed to classify social categories can lead to biased or harmful model responses.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Potential for Malicious Suggestion">
  <data key="d0">Potential for Malicious Suggestion</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d2">Codex's inability to reliably detect vulnerabilities or avoid suggesting insecure code indicates a risk for malicious exploitation.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Potential for Malicious Use">
  <data key="d0">Potential for Malicious Use</data>
  <data key="d3">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d2">Despite limitations, Codex's capacity to generate code can be exploited for malicious activities, especially as model capabilities improve.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Configuration Parameters">
  <data key="d0">Configuration Parameters</data>
  <data key="d3">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d2">Cryptography experts establish and recommend secure configuration parameters to prevent insecure cryptographic practices and vulnerabilities.&lt;SEP&gt;Cryptography experts establish consensus on secure configuration parameters to prevent insecure encryption practices.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Growing reliance">
  <data key="d0">Growing reliance</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d2">Users increasingly depend on AI tools for code import decisions, which may influence programming practices over time.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Errors and robustness">
  <data key="d0">Errors and robustness</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d2">Different import patterns can cause subtle errors or increase code robustness depending on context."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Economic and safety impacts">
  <data key="d0">Economic and safety impacts</data>
  <data key="d3">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d2">The pattern of package imports affects economic power and security in the software ecosystem."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Suggestions for Deprecated Methods">
  <data key="d0">Suggestions for Deprecated Methods</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d2">Biases in training data may cause Codex to recommend deprecated or outdated methods, impacting software maintenance and backward compatibility.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Impacts on Worker Productivity">
  <data key="d0">Impacts on Worker Productivity</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d2">Future research aims to measure how Codex impacts real-world coding performance, productivity, and quality of life for developers.&lt;SEP&gt;Future research aims to quantify how AI tools like Codex affect real-world worker productivity and quality of life.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="Impacts on Software Quality">
  <data key="d0">Impacts on Software Quality</data>
  <data key="d3">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d2">Codex may improve documentation practices but also propagate subtle errors, influencing downstream software quality and debugging.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</node>
<node id="HPC-Coder">
  <data key="d0">HPC-Coder</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A specialized large language model (LLM) designed and fine-tuned to handle high performance computing (HPC) and scientific codes, enabling tasks such as code auto-completion, decorating loops with OpenMP pragmas, and performance modeling.&lt;SEP&gt;HPC-Coder is a fine-tuned large language model designed specifically for HPC and scientific code tasks, outperforming other models in code generation, labeling, and performance prediction.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Modeling">
  <data key="d0">Performance Modeling</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The hypothesis that large language models can accurately predict execution time and performance characteristics of HPC and scientific codes based on source code features.&lt;SEP&gt;The hypothesis that large language models can effectively predict and model performance metrics such as execution time for HPC and scientific codes based on source code features.&lt;SEP&gt;The model can be used to analyze and predict performance properties of source code with minimal data.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Completion">
  <data key="d0">Code Completion</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A benchmark task where models generate code based on natural language prompts to evaluate code generation capabilities.&lt;SEP&gt;Automated prediction and insertion of code segments, functions, or directives (e.g., OpenMP pragmas) in HPC codebases using trained language models.&lt;SEP&gt;Automated prediction and insertion of code segments, functions, or directives in HPC codebases using trained language models.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenMP Pragmas">
  <data key="d0">OpenMP Pragmas</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Directive-based parallel programming constructs used to annotate loops and sections of code for parallel execution, which models can predict and insert.&lt;SEP&gt;OpenMP pragmas are compiler directives used to annotate code, specifically loops, to specify parallel execution behavior in shared-memory programming models.&lt;SEP&gt;OpenMP pragmas are compiler directives used to parallelize code, and their prediction and reproduction are evaluated for correctness and accuracy in the models.&lt;SEP&gt;OpenMP pragmas are compiler directives used to specify parallel regions in code, particularly for decorating loops to enable parallel execution in HPC applications.&lt;SEP&gt;Parallel programming directives that annotate loops and code sections for parallel execution, which models can predict and insert to facilitate parallelization.&lt;SEP&gt;Specific directives in OpenMP that instruct the compiler on how to parallelize code segments, including clauses and variables.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-c17dc636d560a988c23d0b7ee6ca279c&lt;SEP&gt;chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC and Scientific Code Dataset">
  <data key="d0">HPC and Scientific Code Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A newly assembled collection of HPC and scientific source codes used to train and evaluate the models' ability to perform code-related tasks.&lt;SEP&gt;A newly created collection of high performance and scientific source code used to fine-tune language models and evaluate their performance on HPC tasks.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Changes in Repositories">
  <data key="d0">Performance Changes in Repositories</data>
  <data key="d1">Results</data>
  <data key="d2">The observed ability of the HPC-Coder model to predict and model performance variations across different scientific application repositories and programming solutions.&lt;SEP&gt;The observed ability of the HPC-Coder model to predict and model performance variations across scientific application repositories and code solutions.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Automation of Development Tasks">
  <data key="d0">Automation of Development Tasks</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The potential for LLMs to automate complex development tasks in HPC, thereby increasing productivity and reducing errors.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Predictive Capabilities">
  <data key="d0">Predictive Capabilities</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The ability of large language models to predict code behavior, performance metrics, and to assist in code optimization.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Modeling Performance">
  <data key="d0">Modeling Performance</data>
  <data key="d1">Variables</data>
  <data key="d2">Variables such as code features, hardware specifications, input data, and system load that influence performance predictions made by the models.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="External Libraries">
  <data key="d0">External Libraries</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Libraries and dependencies that HPC codes rely on, affecting code analysis and performance modeling.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Open-Source Code Repositories">
  <data key="d0">Open-Source Code Repositories</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Platforms like GitHub and GitLab that provide large datasets of source code used for training and evaluating models.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Data Augmentation">
  <data key="d0">Data Augmentation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Methods to artificially expand training datasets, such as synthetically modifying code, to improve model robustness.</data>
  <data key="d3">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="transfer learning">
  <data key="d0">transfer learning</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Transfer learning involves leveraging pre-trained models, such as large language models (LLMs), to adapt knowledge from one domain to another, enabling effective learning with fewer samples.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="modeling parallel and HPC codes">
  <data key="d0">modeling parallel and HPC codes</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The focus is on modeling high-performance computing (HPC) and scientific codes to understand and predict their performance.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="code generation">
  <data key="d0">code generation</data>
  <data key="d1">Results</data>
  <data key="d2">HPC-Coder can generate HPC-specific code with up to 53% higher success rate than other models.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenMP pragma labeling">
  <data key="d0">OpenMP pragma labeling</data>
  <data key="d1">Results</data>
  <data key="d2">HPC-Coder accurately labels for loops with OpenMP pragmas at 97% accuracy, demonstrating its effectiveness in code annotation tasks.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="performance prediction">
  <data key="d0">performance prediction</data>
  <data key="d1">Results</data>
  <data key="d2">The model predicts relative performance of source code changes with up to 92% accuracy, indicating its utility in performance modeling.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="dataset of HPC and scientific codes">
  <data key="d0">dataset of HPC and scientific codes</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A curated collection of open-source HPC and scientific codes used to train and evaluate the models, providing diverse real-world examples.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC and scientific codes">
  <data key="d0">HPC and scientific codes</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The specific types of source code used to train the models, representing high-performance and scientific computing applications.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC-specific tasks">
  <data key="d0">HPC-specific tasks</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study investigates whether fine-tuned LLMs like HPC-Coder can outperform existing models in code generation, labeling, and performance prediction for HPC codes.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="state-of-the-art models">
  <data key="d0">state-of-the-art models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Existing leading models in source code modeling and generation, used as benchmarks to evaluate HPC-Coder's performance.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="training scores">
  <data key="d0">training scores</data>
  <data key="d1">Results</data>
  <data key="d2">HPC-Coder achieves better language modeling scores on HPC-related code compared to other models, indicating improved understanding and generation capabilities.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="code annotation">
  <data key="d0">code annotation</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Techniques used to label code features such as OpenMP pragmas, aiding in performance analysis and optimization.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="transformer-based language models">
  <data key="d0">transformer-based language models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Transformer architectures underpin many LLMs, utilizing self-attention mechanisms to process sequential data like source code effectively.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="perplexity">
  <data key="d0">perplexity</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A key metric used to evaluate language model performance, representing how well the model predicts tokens during training and validation.&lt;SEP&gt;A metric to evaluate the confidence of language models in predicting sequences; lower perplexity indicates better modeling of source code.&lt;SEP&gt;A metric used to evaluate the language model's performance during training and validation, representing how well the model predicts tokens.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7&lt;SEP&gt;chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="accuracy of predictions">
  <data key="d0">accuracy of predictions</data>
  <data key="d1">Results</data>
  <data key="d2">The model's ability to correctly predict code features and performance metrics demonstrates its effectiveness.</data>
  <data key="d3">chunk-c27a9a886dd19125bb1adb49ea7038f7</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Perplexity">
  <data key="d0">Perplexity</data>
  <data key="d1">Results</data>
  <data key="d2">A metric indicating the model's uncertainty, calculated as the exponential of the training loss, used to evaluate training progress and validation performance.&lt;SEP&gt;Perplexity measures a language model's confidence in predicting the next token, reflecting how well the model understands the data, but it does not directly measure accuracy.&lt;SEP&gt;Perplexity measures a language model's confidence in predicting the next token, serving as an indicator of the model's understanding and uncertainty, but it does not directly reflect accuracy.&lt;SEP&gt;Perplexity measures the exponential of the training loss, indicating the model's uncertainty during training and validation.&lt;SEP&gt;Perplexity measures the uncertainty or confidence of language models in predicting the next token, with lower values indicating better model performance.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-7c9dc700be1265a346cc35786ad23072&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Text Generation">
  <data key="d0">Text Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Text Generation involves producing coherent and contextually relevant text sequences using language models, often influenced by sampling methods and model confidence.&lt;SEP&gt;Text Generation involves using trained language models to produce new textual content based on learned patterns and probabilities.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Token Probability">
  <data key="d0">Token Probability</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Token probability is the likelihood assigned to each token during prediction, guiding sampling and generation processes.&lt;SEP&gt;Token probability refers to the likelihood assigned to each token (word or subword) by the language model during text generation.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Sampling Methods">
  <data key="d0">Sampling Methods</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Sampling methods like temperature, top-k, and nucleus sampling are techniques to select tokens during text generation, balancing diversity and relevance.&lt;SEP&gt;Sampling methods such as temperature, top-k, and nucleus sampling are techniques used to select tokens during text generation, balancing randomness and coherence.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Top-k Sampling">
  <data key="d0">Top-k Sampling</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Top-k sampling involves selecting the next token from the k most probable tokens, reducing randomness and focusing on high-probability options.&lt;SEP&gt;Top-k sampling restricts token selection to the k most probable tokens, reducing randomness and focusing on likely options.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="LLMs for Code Generation">
  <data key="d0">LLMs for Code Generation</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Large Language Models (LLMs) can be trained on source code to perform tasks like code generation, prediction, and translation, often using specialized training approaches.&lt;SEP&gt;Large Language Models trained on source code can perform tasks such as code generation, prediction, and translation, often utilizing specialized training and sampling techniques.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Left-to-Right Models">
  <data key="d0">Left-to-Right Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Left-to-right models generate text sequentially from start to finish, predicting the next token based on previous tokens, suitable for language and code generation.&lt;SEP&gt;Left-to-right models predict the next token based on prior tokens, generating text sequentially from start to finish, suitable for text generation tasks.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Masked Models">
  <data key="d0">Masked Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Masked models predict tokens at random positions in the text, allowing use of more context and enabling bidirectional understanding.&lt;SEP&gt;Masked models predict tokens at randomly masked positions within the sequence, enabling bidirectional context and improved understanding.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Encoder-Decoder Models">
  <data key="d0">Encoder-Decoder Models</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Encoder-decoder models encode input sequences and generate output sequences, commonly used in translation and code conversion tasks.&lt;SEP&gt;Encoder-decoder models process input sequences through an encoder and generate output sequences via a decoder, often used in sequence-to-sequence tasks like translation.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training Customization for Code">
  <data key="d0">Training Customization for Code</data>
  <data key="d1">Methodologies</data>
  <data key="d2">In code applications, tokenization is adapted to handle whitespace and syntax differences, and formatting is applied post-generation to maintain code structure.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC Source Code Dataset">
  <data key="d0">HPC Source Code Dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A large collection of high-performance computing (HPC) source code used to fine-tune language models for specialized tasks.&lt;SEP&gt;A large collection of high-performance computing (HPC) source code used to train and fine-tune language models for specialized applications.&lt;SEP&gt;A large dataset of HPC-related C/C++ source code collected from GitHub repositories, filtered and deduplicated for training the language model.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model Selection">
  <data key="d0">Model Selection</data>
  <data key="d1">Study Designs</data>
  <data key="d2">The process of evaluating and choosing the best performing language model after fine-tuning for downstream applications.&lt;SEP&gt;The process of evaluating and choosing the optimal language model for downstream HPC tasks, based on performance metrics.&lt;SEP&gt;The process of evaluating multiple models after fine-tuning to select the best performing one for downstream tasks based on performance metrics.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model Confidence">
  <data key="d0">Model Confidence</data>
  <data key="d1">Variables</data>
  <data key="d2">Model confidence refers to the degree of certainty the model has in its predictions, often reflected by metrics like perplexity.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Downstream Tasks">
  <data key="d0">Downstream Tasks</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Downstream tasks are applications or tasks that utilize the language model's outputs, such as translation, summarization, or question answering, which are influenced by model confidence and performance.&lt;SEP&gt;Tasks designed to evaluate the practical capabilities of the trained models in real HPC scenarios, including code generation, labeling, and performance prediction.&lt;SEP&gt;Tasks that evaluate the practical application of language models, such as code generation, to assess their real-world utility.&lt;SEP&gt;The paper investigates the model's ability to perform specific tasks: generate correct code, label OpenMP pragmas, and predict relative performance, to evaluate its practical usefulness.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training Approaches for Code">
  <data key="d0">Training Approaches for Code</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Training models on source code involves adapting tokenization to handle syntax and whitespace, and applying formatting after generation to maintain code structure.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Generation Applications">
  <data key="d0">Code Generation Applications</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Automated code generation facilitates faster development, automation, and code synthesis in HPC and software engineering contexts.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Sampling Techniques">
  <data key="d0">Sampling Techniques</data>
  <data key="d1">Tools</data>
  <data key="d2">Sampling techniques such as temperature, top-k, and nucleus sampling are tools used to control the diversity and relevance of generated text or code.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model Evaluation Metrics">
  <data key="d0">Model Evaluation Metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics used to assess the performance of language models, including perplexity, accuracy, and task-specific scores.</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Section V">
  <data key="d0">Section V</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Section V details the training setup and methodology for fine-tuning and selecting models for HPC code analysis.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Fig. 1">
  <data key="d0">Fig. 1</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Figure 1 provides an overview of the steps involved in training an HPC-specific model and applying it to downstream tasks such as code generation, labeling, and performance prediction.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Data Pre-processing">
  <data key="d0">Data Pre-processing</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Procedures including deduplication using sha256 hashing, removal of small and large files, and tokenization with GPT-2 BPE tokenizers to prepare data for model training.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Datasets">
  <data key="d0">Performance Datasets</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Two datasets of code paired with performance data: one capturing performance regressions across commits in HPC applications, and another with solutions from programming contests, used to model performance characteristics.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training Setup and Methodology">
  <data key="d0">Training Setup and Methodology</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Details the procedures for fine-tuning and selecting the best pre-trained language models for HPC code understanding and generation.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenMP Pragma Labeling">
  <data key="d0">OpenMP Pragma Labeling</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The task where the model identifies and labels OpenMP pragmas within HPC code, aiding in parallelization analysis.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Relative Performance Prediction">
  <data key="d0">Relative Performance Prediction</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A classification task where models predict whether the second code version is slower or faster based on concatenated code sequences separated by specific tokens.&lt;SEP&gt;A task where models predict the impact of code changes on performance, such as slowdown or speedup, using high accuracy (88%-92%).&lt;SEP&gt;A task where models predict whether code changes will lead to performance slowdown or speedup, achieving high classification accuracy (86%-92%).&lt;SEP&gt;The task where the model predicts the relative performance metrics of different HPC codes or configurations, useful for optimization.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94&lt;SEP&gt;chunk-e78a79fd58794ba9c2d3c38bb8b05368&lt;SEP&gt;chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Large Dataset of HPC Source Code">
  <data key="d0">Large Dataset of HPC Source Code</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A collection of HPC-related C/C++ source files from GitHub, filtered and deduplicated, used for training the language model.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Data Datasets">
  <data key="d0">Performance Data Datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Two datasets pairing code snippets with performance measurements: one capturing regressions over commits, another with solutions from programming contests, used for performance modeling.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Pair Datasets">
  <data key="d0">Code Pair Datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Datasets containing pairs of code with performance data, used to train models to understand performance differences and similarities.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Data Deduplication">
  <data key="d0">Data Deduplication</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Filtering process using sha256 hashes to remove duplicate files from the dataset to prevent bias during training.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="File Filtering">
  <data key="d0">File Filtering</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Removing files larger than 1MB or containing fewer than 15 tokens to ensure dataset quality and relevance.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Tokenization">
  <data key="d0">Tokenization</data>
  <data key="d1">Tools</data>
  <data key="d2">Using GPT-2 based Byte-Pair Encoding (BPE) tokenizers to convert source code into integer sequences suitable for model input.</data>
  <data key="d3">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="830 commits">
  <data key="d0">830 commits</data>
  <data key="d1">Results</data>
  <data key="d2">830 commits represent the total number of code submissions analyzed in the dataset, indicating the scale of data used for research.&lt;SEP&gt;Total number of code commits analyzed in the dataset, indicating the scale of data used for research and evaluation.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="programming competition solutions">
  <data key="d0">programming competition solutions</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Solutions submitted to various online programming contests, used to analyze code implementation, performance, and differences.&lt;SEP&gt;Solutions submitted to various online programming contests, used to analyze code performance and implementation differences.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="code contests dataset">
  <data key="d0">code contests dataset</data>
  <data key="d1">Study Population/Dataset</data>
  <data key="d2">A collection of data from multiple online programming competitions such as Aizu, AtCoder, CodeChef, CodeForces, and HackerEarth, used as the primary dataset for analysis.&lt;SEP&gt;A comprehensive collection of data from multiple online programming competitions such as Aizu, AtCoder, CodeChef, CodeForces, and HackerEarth, serving as the primary dataset for analysis.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="test cases">
  <data key="d0">test cases</data>
  <data key="d1">Tools</data>
  <data key="d2">Input datasets used to evaluate the correctness and performance of submitted solutions by running solutions against predefined inputs.&lt;SEP&gt;Input test cases used to evaluate the correctness and performance of submitted solutions in the dataset.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="run time">
  <data key="d0">run time</data>
  <data key="d1">Variables</data>
  <data key="d2">Measurement of execution duration for each solution on specific test cases, used to compare efficiency and performance.&lt;SEP&gt;Measurement of execution duration for each solution on specific test cases, used to compare solution efficiency.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="solutions">
  <data key="d0">solutions</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code solutions submitted for problems in the dataset, which are grouped and labeled based on performance.&lt;SEP&gt;Individual code submissions for programming problems, which are grouped into pairs based on their performance differences.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="pairs of solutions">
  <data key="d0">pairs of solutions</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Pairs of solutions that solve the same problem but differ in implementation, used for comparative analysis of efficiency and coding approaches.&lt;SEP&gt;Pairs of solutions that solve the same problem but differ in implementation, used for comparative analysis.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="slower and faster pairs">
  <data key="d0">slower and faster pairs</data>
  <data key="d1">Variables</data>
  <data key="d2">Categorization of solution pairs based on their run time, indicating which solution is slower or faster, used for performance benchmarking.&lt;SEP&gt;Categorization of solution pairs based on their run time, with labels indicating which solution is slower or faster.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="V. Fine-tuning methodology">
  <data key="d0">V. Fine-tuning methodology</data>
  <data key="d1">Methodologies</data>
  <data key="d2">A detailed description of the procedures for selecting, training, and optimizing models using the collected dataset, including hyperparameter tuning and model evaluation techniques.&lt;SEP&gt;A set of procedures describing how models are selected, trained, and optimized for the specific dataset and task.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="DeepSpeed">
  <data key="d0">DeepSpeed</data>
  <data key="d1">Tools</data>
  <data key="d2">A framework providing distributed training and memory optimization for large models, enabling efficient fine-tuning on GPU clusters.&lt;SEP&gt;A framework providing distributed training and memory optimization for large-scale neural network training, enabling efficient fine-tuning of large models on GPU clusters.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="AdamW">
  <data key="d0">AdamW</data>
  <data key="d1">Tools</data>
  <data key="d2">An optimizer used during training to update model weights, known for its effectiveness in training large neural networks with weight decay regularization.&lt;SEP&gt;An optimizer used for updating model weights during training, chosen for its effectiveness in training large neural networks.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="training dataset">
  <data key="d0">training dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">The portion of data used to train the models during fine-tuning, consisting of code and natural language data from the collected dataset.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="validation dataset">
  <data key="d0">validation dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A subset of data used to evaluate model performance during training, separate from the training data, to tune hyperparameters and prevent overfitting.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="model selection">
  <data key="d0">model selection</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The process of choosing appropriate models (GPT-2, GPT-Neo, PolyCoder) based on size, architecture, and pre-training data to optimize performance for code and language tasks.</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Validation Dataset">
  <data key="d0">Validation Dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A subset of data (5%) used to evaluate the model's performance during training, separate from the training dataset.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Optimizer Steps">
  <data key="d0">Optimizer Steps</data>
  <data key="d1">Variables</data>
  <data key="d2">The number of steps taken during optimization, used as checkpoints for recording model performance.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training Loss">
  <data key="d0">Training Loss</data>
  <data key="d1">Results</data>
  <data key="d2">A measure of the error during training, used to compute perplexity and assess how well the model fits the training data.&lt;SEP&gt;A measure of the model's error during training, used to compute perplexity.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Token Prediction Accuracy">
  <data key="d0">Token Prediction Accuracy</data>
  <data key="d1">Results</data>
  <data key="d2">The accuracy of the model in predicting tokens during validation, indicating performance.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HumanEval Benchmark">
  <data key="d0">HumanEval Benchmark</data>
  <data key="d1">Tools</data>
  <data key="d2">A standard benchmark comprising Python problems used to assess code generation models.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC Code Generation Problems">
  <data key="d0">HPC Code Generation Problems</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Custom high-performance computing code problems used to assess models' ability to generate numerics, parallel code, MPI routines, etc.&lt;SEP&gt;Custom problems designed to evaluate models' ability to generate high-performance computing code, including numerics, OpenMP, and MPI routines.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Generated Code">
  <data key="d0">Generated Code</data>
  <data key="d1">Results</data>
  <data key="d2">Code produced by the model in response to prompts, evaluated for correctness and functional equivalence.&lt;SEP&gt;Code produced by the model in response to prompts, evaluated for correctness, syntactic correctness, and functional equivalence.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Compiler Flags">
  <data key="d0">Compiler Flags</data>
  <data key="d1">Tools</data>
  <data key="d2">Options like '-O2', '-std=c++17', '-fopenmp', used during compilation of generated code to ensure correctness and enable parallel frameworks.&lt;SEP&gt;Options used in g++ and mpicxx to compile generated code, such as '-O2', '-std=c++17', and '-fopenmp' for optimization and parallel frameworks.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Parallel Frameworks">
  <data key="d0">Parallel Frameworks</data>
  <data key="d1">Tools</data>
  <data key="d2">OpenMP and MPI are parallel programming frameworks used to implement and test high-performance code generated by models.&lt;SEP&gt;OpenMP and MPI, used to implement and test parallel code generated by the model.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Hardware Environment">
  <data key="d0">Hardware Environment</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">The experiments are conducted on AMD EPYC 7763 CPUs with 64 cores at 2.45 GHz, providing the computational context for code testing.&lt;SEP&gt;The hardware setup for testing includes AMD EPYC 7763 CPUs with 64 cores at 2.45 GHz, providing the computational context for code execution and testing.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Validation Data">
  <data key="d0">Validation Data</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A subset (5%) of the full dataset used to validate and evaluate the model's performance during training.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Optimizer">
  <data key="d0">Optimizer</data>
  <data key="d1">Tools</data>
  <data key="d2">An algorithm used to update the model's parameters during training, with steps recorded every 1000 optimizer steps to monitor progress.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Downstream Inference Tasks">
  <data key="d0">Downstream Inference Tasks</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Tasks performed after model training to evaluate its practical capabilities, such as code generation and prediction.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Generation Benchmark">
  <data key="d0">Code Generation Benchmark</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A set of tasks designed to evaluate models' ability to generate code, including HumanEval and custom HPC problems.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Sampling Technique">
  <data key="d0">Sampling Technique</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Nucleus sampling (top-p sampling) with a cutoff of 0.93 used to generate diverse code samples from the model.</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Parallel Framework">
  <data key="d0">Parallel Framework</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Parallel frameworks like MPI and OpenMP provide structured models for implementing parallelism, allowing efficient utilization of multiple processing units in high-performance computing.&lt;SEP&gt;Parallel frameworks refer to structured approaches and models used to implement parallelism in computational tasks, such as MPI or OpenMP, to improve performance and efficiency.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC code dataset">
  <data key="d0">HPC code dataset</data>
  <data key="d1">Study Design</data>
  <data key="d2">A collection of high-performance computing source code samples used to train and evaluate models for tasks like pragma generation.&lt;SEP&gt;A curated collection of high-performance computing source code snippets used to train, validate, and evaluate models on code-related tasks, including pragma placement and performance classification.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Evaluation Metric">
  <data key="d0">Evaluation Metric</data>
  <data key="d1">Variables</data>
  <data key="d2">Metrics like accuracy, perplexity, and functional correctness are used to assess the performance of models in code generation and classification tasks.&lt;SEP&gt;Metrics such as accuracy, perplexity, and functional correctness are used to quantify model performance in code generation and classification tasks.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Token &quot;&lt;begin-omp&gt;">
  <data key="d0">Token "&lt;begin-omp&gt;</data>
  <data key="d1">Tools</data>
  <data key="d2">A unique separator token used in data formatting to indicate the position of the OpenMP pragma relative to the for loop, facilitating model training and inference.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Prediction">
  <data key="d0">Performance Prediction</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study investigates whether fine-tuned LLMs can accurately predict code performance slowdowns between different code versions.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Git commit data">
  <data key="d0">Git commit data</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset containing code changes associated with Git commits, used to train models for performance prediction.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code contest dataset">
  <data key="d0">Code contest dataset</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">A dataset of code pairs from programming contests, used for training models to predict relative performance.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training epochs">
  <data key="d0">Training epochs</data>
  <data key="d1">Study Design</data>
  <data key="d2">Number of complete passes over training datasets (e.g., three epochs) during model fine-tuning, influencing model learning and performance.&lt;SEP&gt;The process of repeatedly passing over the training dataset (e.g., three epochs) to optimize model performance during fine-tuning.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Validation perplexity">
  <data key="d0">Validation perplexity</data>
  <data key="d1">Results</data>
  <data key="d2">A metric indicating how well a model predicts unseen data; lower perplexity suggests better modeling of language in code.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Token &lt;begin-omp&gt;">
  <data key="d0">Token &lt;begin-omp&gt;</data>
  <data key="d1">Tools</data>
  <data key="d2">A special separator token used in data formatting to position the OpenMP pragma directly after the for loop, enabling the model to generate pragmas at the correct code location during inference.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Slowdown Prediction">
  <data key="d0">Performance Slowdown Prediction</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">The study investigates whether fine-tuned LLMs can accurately predict whether code modifications will lead to slower execution, assessing their effectiveness in performance forecasting.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code change datasets">
  <data key="d0">Code change datasets</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Datasets comprising code snippets before and after modifications, such as Git commit data and programming contest code pairs, used to train models for performance prediction and classification.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Syntactic correctness">
  <data key="d0">Syntactic correctness</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A measure of whether generated pragmas match the actual pragmas in syntax, used to evaluate the accuracy of code generation.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Functional correctness">
  <data key="d0">Functional correctness</data>
  <data key="d1">Evidence Types</data>
  <data key="d2">A measure of whether generated pragmas preserve the intended functionality, regardless of syntactic differences, used to assess pragmatic utility.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Prediction accuracy">
  <data key="d0">Prediction accuracy</data>
  <data key="d1">Results</data>
  <data key="d2">The proportion of correct predictions in code performance classification tasks, indicating the effectiveness of models in forecasting performance changes.</data>
  <data key="d3">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="GPT-2">
  <data key="d0">GPT-2</data>
  <data key="d1">Model</data>
  <data key="d2">GPT-2 is a language model evaluated for its perplexity and code generation capabilities, trained on general datasets and fine-tuned on HPC-specific data.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder">
  <data key="d0">PolyCoder</data>
  <data key="d1">Model</data>
  <data key="d2">A baseline large language model for code generation, with 94% accuracy in predicting OpenMP pragmas.&lt;SEP&gt;A baseline large language model used for code generation and prediction tasks, achieving 94% accuracy in predicting OpenMP pragmas.&lt;SEP&gt;PolyCoder is a language model specialized in code generation, particularly for C++, evaluated through perplexity and downstream code generation tasks.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder+HPC">
  <data key="d0">PolyCoder+HPC</data>
  <data key="d1">Model</data>
  <data key="d2">A fine-tuned language model specifically designed for HPC code generation and performance analysis, referred to as HPC-Coder.&lt;SEP&gt;A large language model fine-tuned for high-performance computing tasks, including predicting OpenMP pragmas with 97% accuracy, capable of understanding dependencies and clauses.&lt;SEP&gt;A large language model fine-tuned for high-performance computing tasks, including predicting OpenMP pragmas with 97% accuracy.&lt;SEP&gt;A specific fine-tuned language model designed for HPC code generation and performance analysis, referred to as HPC-Coder.&lt;SEP&gt;PolyCoder fine-tuned on HPC source code dataset, showing improved performance in HPC-specific code generation tasks.&lt;SEP&gt;PolyCoder+HPC is an enhanced version of Poly-Coder, incorporating high-performance computing features, showing improved compilation and code correctness.&lt;SEP&gt;PolyCoder+HPC is an enhanced version of Poly-Coder, incorporating high-performance computing features, showing improved compilation success and correctness.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4&lt;SEP&gt;chunk-3e334e5860963a6ca1939b6719cae953&lt;SEP&gt;chunk-cfcd5a8798f30da73fdaa3033d579b42&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="GPT-Neo+HPC">
  <data key="d0">GPT-Neo+HPC</data>
  <data key="d1">Model</data>
  <data key="d2">GPT-Neo fine-tuned on HPC data, aimed at generating HPC-related code with evaluation on code correctness and syntactic validity.&lt;SEP&gt;GPT-Neo+HPC is a language model with HPC capabilities that performs slightly worse than PolyCoder+HPC in code compilation success, likely due to less code in its pre-training dataset.&lt;SEP&gt;GPT-Neo+HPC is a language model with HPC capabilities that performs slightly worse than PolyCoder+HPC in code compilation success.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="GPT2+HPC">
  <data key="d0">GPT2+HPC</data>
  <data key="d1">Model</data>
  <data key="d2">GPT-2 fine-tuned on HPC dataset, tested for code generation performance, particularly on HPC-specific code like OpenMP and MPI.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Evaluation Performance">
  <data key="d0">Evaluation Performance</data>
  <data key="d1">Results</data>
  <data key="d2">Performance metrics such as pass@k rates and compilation success percentages used to assess the quality of generated code by different models.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training Samples">
  <data key="d0">Training Samples</data>
  <data key="d1">Study Design</data>
  <data key="d2">Number of data points (e.g., 45,000 samples) used during fine-tuning, influencing model performance and the onset of catastrophic forgetting.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Source Code Dataset">
  <data key="d0">Source Code Dataset</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">The dataset consisting of HPC source code used for fine-tuning the models to improve HPC-specific code generation.</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Poly-Coder">
  <data key="d0">Poly-Coder</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Poly-Coder is a code generation model evaluated for its ability to produce correct and compilable code, with high performance in compilation success rates.&lt;SEP&gt;Poly-Coder is a code generation model evaluated for its ability to produce correct, compilable code, with high success rates in compilation.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="GPT2-HPC">
  <data key="d0">GPT2-HPC</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">GPT2-HPC is a model with HPC features, with significantly lower compilation success, attributed to less training data on code.&lt;SEP&gt;GPT2-HPC is a model with HPC features, with significantly lower compilation success, likely due to less training data on code.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenMP code">
  <data key="d0">OpenMP code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">OpenMP code refers to parallel programming constructs used in the code examples, specifically for parallelizing computations in shared-memory environments.&lt;SEP&gt;OpenMP code refers to parallel programming constructs used in the code examples, specifically for parallelizing computations.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder output">
  <data key="d0">PolyCoder output</data>
  <data key="d1">Results</data>
  <data key="d2">PolyCoder produces correct sequential code but fails to add OpenMP pragmas for parallel execution, indicating limited understanding of parallel directives.&lt;SEP&gt;PolyCoder produces correct sequential code but fails to include OpenMP pragmas for parallelization.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder+HPC output">
  <data key="d0">PolyCoder+HPC output</data>
  <data key="d1">Results</data>
  <data key="d2">PolyCoder+HPC successfully tags the for loop with an OpenMP pragma, demonstrating improved ability to generate parallel code with directives.&lt;SEP&gt;PolyCoder+HPC successfully tags the for loop with an OpenMP pragma, demonstrating improved parallel code generation.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Figure 9">
  <data key="d0">Figure 9</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Figure 9 presents examples of MPI code generated by PolyCoder and PolyCoder+HPC, highlighting their capabilities and limitations in distributed memory parallelism.&lt;SEP&gt;Figure 9 presents examples of MPI code generated by PolyCoder and PolyCoder+HPC, highlighting their understanding and limitations in distributed memory parallelism.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="MPI code">
  <data key="d0">MPI code</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">MPI code involves message passing interface routines used for parallel computing across distributed systems.&lt;SEP&gt;MPI code involves message passing routines used for parallel computing across distributed systems.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder output (MPI)">
  <data key="d0">PolyCoder output (MPI)</data>
  <data key="d1">Results</data>
  <data key="d2">PolyCoder often generates long, incorrect MPI routines, indicating limited understanding despite some MPI calls being present in its training data.&lt;SEP&gt;PolyCoder often generates long, incorrect MPI routines, showing limited understanding despite some MPI calls being in its training data.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="PolyCoder+HPC output (MPI)">
  <data key="d0">PolyCoder+HPC output (MPI)</data>
  <data key="d1">Results</data>
  <data key="d2">PolyCoder+HPC produces correct MPI code for computing an average across ranks, demonstrating better understanding of MPI routines.&lt;SEP&gt;PolyCoder+HPC produces correct MPI code for computing an average across ranks, indicating better grasp of MPI routines.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Figure 10">
  <data key="d0">Figure 10</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Figure 10 compares speedups achieved by PolyCoder+HPC over sequential baselines, demonstrating the efficiency of generated parallel code.&lt;SEP&gt;Figure 10 compares speedups achieved by PolyCoder+HPC over sequential baselines, indicating the effectiveness of generated parallel code.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Section VI-B">
  <data key="d0">Section VI-B</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Section VI-B discusses the evaluation of models' ability to predict OpenMP pragmas, testing their understanding of parallelization constructs.&lt;SEP&gt;Section VI-B evaluates models' ability to predict OpenMP pragmas, testing their understanding of parallelization constructs.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model performance in OpenMP prediction">
  <data key="d0">Model performance in OpenMP prediction</data>
  <data key="d1">Results</data>
  <data key="d2">Both PolyCoder and PolyCoder+HPC generate functionally correct OpenMP pragmas with high accuracy, with PolyCoder+HPC showing improved performance.&lt;SEP&gt;Both PolyCoder and PolyCoder+HPC generate functionally correct OpenMP pragmas with high accuracy; PolyCoder+HPC performs better.</data>
  <data key="d3">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Functionally Correct OpenMP Pragmas">
  <data key="d0">Functionally Correct OpenMP Pragmas</data>
  <data key="d1">Results</data>
  <data key="d2">Pragmas that are syntactically and semantically correct, enabling proper parallel execution of code.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Exact Reproduction of Pragmas">
  <data key="d0">Exact Reproduction of Pragmas</data>
  <data key="d1">Results</data>
  <data key="d2">The models' ability to reproduce the exact sequence and structure of OpenMP pragmas as present in the dataset, with 67% and 61% accuracy respectively.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model Training Trends">
  <data key="d0">Model Training Trends</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Models learn construction and ordering patterns of OpenMP clauses, enabling them to predict pragmas even without prior exposure.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Proxy Applications">
  <data key="d0">Proxy Applications</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Representative code samples used to evaluate the models' ability to predict performance impacts in controlled scenarios.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Performance Modeling">
  <data key="d0">Code Performance Modeling</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Using LLMs to understand and predict code performance without extensive data collection, aiding optimization.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Slowdown">
  <data key="d0">Performance Slowdown</data>
  <data key="d1">Results</data>
  <data key="d2">A negative outcome where code executes more slowly after modifications, predicted with high accuracy by models.&lt;SEP&gt;A negative outcome where code execution becomes slower after modifications, predicted with high accuracy (88%-92%) by the models.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Pragmas">
  <data key="d0">Pragmas</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Compiler directives used within OpenMP to specify parallel regions, loops, and clauses for parallel execution.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Exact Reproduction">
  <data key="d0">Exact Reproduction</data>
  <data key="d1">Results</data>
  <data key="d2">The models' ability to reproduce the exact sequence and structure of pragmas from the dataset, with 67% and 61% accuracy respectively.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Construction and Ordering Trends">
  <data key="d0">Construction and Ordering Trends</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Patterns learned by models regarding how OpenMP clauses are constructed and ordered, enabling them to predict pragmas even without prior explicit examples.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Changes">
  <data key="d0">Code Changes</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Modifications in source code that impact performance, analyzed to predict their effects using models.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model Training Data">
  <data key="d0">Model Training Data</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Large datasets of C/C++ code, including open-source repositories and competitive programming datasets, used to train models for performance prediction.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Impact">
  <data key="d0">Performance Impact</data>
  <data key="d1">Variables</data>
  <data key="d2">The effect of code modifications on runtime performance, such as slowdown or speedup, predicted by models.</data>
  <data key="d3">chunk-c48289d50367366b4b4faa00d871ebb4</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="code2vec">
  <data key="d0">code2vec</data>
  <data key="d1">Methodologies</data>
  <data key="d2">Code2vec is a method that maps source code to an embedded space for analysis, used in performance-related modeling.&lt;SEP&gt;Code2vec is a technique that maps source code into an embedded vector space, used in prior performance-related analytical modeling.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="ir2vec">
  <data key="d0">ir2vec</data>
  <data key="d1">Methodologies</data>
  <data key="d2">ir2vec is a similar method to code2vec that embeds intermediate representations of source code for performance analysis.&lt;SEP&gt;ir2vec is a technique similar to code2vec, used to embed source code for performance analysis.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenCL Kernel Device Placement">
  <data key="d0">OpenCL Kernel Device Placement</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">This is a specific performance-related application involving the optimal placement of OpenCL kernels on hardware devices.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="DeepDevPERF">
  <data key="d0">DeepDevPERF</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">DeepDevPERF is a BART-based large language model (LLM) designed to suggest performance improvements for C# code.&lt;SEP&gt;DeepDevPERF is a BART-based large language model designed to suggest performance improvements to C# code.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Changes from Git Commits">
  <data key="d0">Code Changes from Git Commits</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code changes extracted from Git commits with performance-related keywords serve as a noisy dataset for training models.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Data">
  <data key="d0">Performance Data</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Real performance data used to train models for HPC and parallel code tasks.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC Code Generation">
  <data key="d0">HPC Code Generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The fine-tuned language model can generate high-performance HPC code, aiding computational scientists and developers.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Code Transformations">
  <data key="d0">Code Transformations</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigating how code transformations can improve performance and correctness in HPC code.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance Improvements">
  <data key="d0">Performance Improvements</data>
  <data key="d1">Results</data>
  <data key="d2">The model demonstrates up to 53% higher pass@k rate and 97% success in labeling OpenMP pragmas, indicating effective performance enhancement.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Future Analyses">
  <data key="d0">Future Analyses</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring additional capabilities of the language model in performance and code quality analysis.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Practical Tools">
  <data key="d0">Practical Tools</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Development of usable tools for scientists and developers to produce more efficient HPC code using the model.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Funding and Support">
  <data key="d0">Funding and Support</data>
  <data key="d1">Limitations</data>
  <data key="d2">The research was supported by the National Science Foundation and conducted under the auspices of the U.S. Department of Energy, indicating institutional backing and potential limitations related to funding scope.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="OpenCL kernel device placement">
  <data key="d0">OpenCL kernel device placement</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">This involves optimizing the placement of OpenCL kernels on hardware devices to improve performance.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Git commits with performance keywords">
  <data key="d0">Git commits with performance keywords</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Code changes extracted from Git commits containing performance-related keywords serve as a dataset for training models.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Real performance data">
  <data key="d0">Real performance data</data>
  <data key="d1">Study Populations/Dataset</data>
  <data key="d2">Actual performance data used to fine-tune models for HPC and parallel code tasks.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="HPC code generation">
  <data key="d0">HPC code generation</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The fine-tuned language model can generate correct HPC code, aiding in efficient code development.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance modeling">
  <data key="d0">Performance modeling</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">The model can analyze source code to predict and understand performance properties with minimal data.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance improvements">
  <data key="d0">Performance improvements</data>
  <data key="d1">Results</data>
  <data key="d2">The model achieved up to 53% higher pass@k rate and 97% success in labeling OpenMP pragmas, demonstrating effective performance enhancement.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Future analyses">
  <data key="d0">Future analyses</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Exploring additional capabilities and applications of the language model in performance and code quality analysis.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Practical tools">
  <data key="d0">Practical tools</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Developing tools based on the language model to help scientists and HPC developers produce better, more efficient code.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Funding and institutional support">
  <data key="d0">Funding and institutional support</data>
  <data key="d1">Limitations</data>
  <data key="d2">The research was supported by the National Science Foundation and conducted under the auspices of the U.S. Department of Energy, indicating funding sources and possible limitations related to scope.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="LLM (Large Language Model)">
  <data key="d0">LLM (Large Language Model)</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">A large language model trained on code and HPC data, capable of code generation, performance modeling, and transformation tasks.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model performance metrics">
  <data key="d0">Model performance metrics</data>
  <data key="d1">Results</data>
  <data key="d2">Metrics such as pass@k rate and success in labeling OpenMP pragmas quantify the effectiveness of the fine-tuned models.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Performance properties">
  <data key="d0">Performance properties</data>
  <data key="d1">Variables</data>
  <data key="d2">Performance properties include metrics and characteristics of source code that influence execution efficiency.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Model generalization">
  <data key="d0">Model generalization</data>
  <data key="d1">Research Questions/Hypotheses</data>
  <data key="d2">Investigating how well the fine-tuned models perform across different HPC codebases and tasks.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Practical tool development">
  <data key="d0">Practical tool development</data>
  <data key="d1">Applications/Implications</data>
  <data key="d2">Future work involves engineering the models into practical tools for computational scientists and HPC developers.</data>
  <data key="d3">chunk-cfcd5a8798f30da73fdaa3033d579b42</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Code Llama”">
  <data key="d0">“Code Llama”</data>
  <data key="d1">“Core Concepts”</data>
  <data key="d2">“An open foundation model designed for code-related tasks, such as code generation and understanding, released in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Open Foundation Models for Code”">
  <data key="d0">“Open Foundation Models for Code”</data>
  <data key="d1">“Theories/Models”</data>
  <data key="d2">“A set of large-scale pre-trained models aimed at code-related applications, enabling tasks like code summarization and repair.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Android Mobile Malware Detection”">
  <data key="d0">“Android Mobile Malware Detection”</data>
  <data key="d1">“Study Designs”</data>
  <data key="d2">“Research approach utilizing machine learning techniques to identify malicious software on Android devices, systematically reviewed in 2021.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Machine Learning”">
  <data key="d0">“Machine Learning”</data>
  <data key="d1">“Methodologies”</data>
  <data key="d2">“A set of algorithms and statistical models that enable computers to perform tasks by learning from data, applied here for malware detection and code analysis.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Systematic Review”">
  <data key="d0">“Systematic Review”</data>
  <data key="d1">“Study Designs”</data>
  <data key="d2">“A research methodology that systematically compiles and evaluates existing studies on Android malware detection using machine learning, published in 2021.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“ML4Code”">
  <data key="d0">“ML4Code”</data>
  <data key="d1">“Tools”</data>
  <data key="d2">“An online platform or resource dedicated to machine learning applications in code analysis, accessible since 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Code Summarization”">
  <data key="d0">“Code Summarization”</data>
  <data key="d1">“Core Concepts”</data>
  <data key="d2">“The process of generating concise descriptions of code functionalities, often using models like transformers, to aid understanding.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Transformer-Based Approach for Source Code Summarization”">
  <data key="d0">“Transformer-Based Approach for Source Code Summarization”</data>
  <data key="d1">“Methods”</data>
  <data key="d2">“A technique utilizing transformer neural networks to automatically generate summaries of source code, proposed in 2020.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Semantic Similarity Metrics”">
  <data key="d0">“Semantic Similarity Metrics”</data>
  <data key="d1">“Analytical Techniques”</data>
  <data key="d2">“Methods for evaluating the similarity between source code snippets, used to assess the quality of code summaries in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Learning from Developer Mistakes”">
  <data key="d0">“Learning from Developer Mistakes”</data>
  <data key="d1">“Research Questions/Hypotheses”</data>
  <data key="d2">“Investigates whether models can learn to localize and repair real bugs based on actual developer bug-fixes, explored in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Learning to Reduce False Positives in Bug Detectors”">
  <data key="d0">“Learning to Reduce False Positives in Bug Detectors”</data>
  <data key="d1">“Research Questions/Hypotheses”</data>
  <data key="d2">“Examines methods to improve the accuracy of static analysis tools by minimizing false alarms, discussed in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Attention is All You Need”">
  <data key="d0">“Attention is All You Need”</data>
  <data key="d1">“Theories/Models”</data>
  <data key="d2">“A foundational paper introducing the Transformer architecture, which relies solely on attention mechanisms for sequence modeling, published in 2017.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Large Language Models of Code”">
  <data key="d0">“Large Language Models of Code”</data>
  <data key="d1">“Core Concepts”</data>
  <data key="d2">“Massively scaled neural models trained on vast amounts of source code to perform various code-related tasks, systematically evaluated in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Adverse Effects of Code Duplication”">
  <data key="d0">“Adverse Effects of Code Duplication”</data>
  <data key="d1">“Limitations”</data>
  <data key="d2">“Research highlighting how duplicated code can negatively impact machine learning models of code, discussed in 2019.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Language Models as Multitask Learners”">
  <data key="d0">“Language Models as Multitask Learners”</data>
  <data key="d1">“Theories/Models”</data>
  <data key="d2">“The concept that large-scale language models can perform multiple tasks without task-specific training, introduced by Radford et al. in 2019.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“KRIPKE”">
  <data key="d0">“KRIPKE”</data>
  <data key="d1">“Tools”</data>
  <data key="d2">“A massively parallel transport mini-application used for high-performance computing simulations, developed by LLNL in 2015.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“High-Order Curvilinear Finite Element Methods”">
  <data key="d0">“High-Order Curvilinear Finite Element Methods”</data>
  <data key="d1">“Methodologies”</data>
  <data key="d2">“Numerical techniques for solving complex hydrodynamics problems with high accuracy, discussed in SIAM Journal in 2012.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Study Populations/Dataset”">
  <data key="d0">“Study Populations/Dataset”</data>
  <data key="d1">“Research Questions/Hypotheses”</data>
  <data key="d2">“Data sets or subjects used in the referenced studies, such as code repositories, bug reports, malware samples, or scientific data, as referenced across the sources.”&lt;SEP&gt;“Refers to the collection of data or subjects used in the various studies, such as code repositories, bug fixes, or malware samples, as referenced across the articles.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“B. Rozi `ere”">
  <data key="d0">“B. Rozi `ere”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the study of code foundation models, contributing to the development and evaluation of models like Code Llama in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“J. Gehring”">
  <data key="d0">“J. Gehring”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher collaborating on foundation models for code, contributing to the development of Code Llama in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“F. Gloeckle”">
  <data key="d0">“F. Gloeckle”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in foundational code model research, contributing to the 2023 publication on Code Llama.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“S. Sootla”">
  <data key="d0">“S. Sootla”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher participating in the development of open foundation models for code in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“I. Gat”">
  <data key="d0">“I. Gat”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A contributor to the research on open foundation models for code, published in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“X. E. Tan”">
  <data key="d0">“X. E. Tan”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the development of code foundation models, contributing to the 2023 study.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Y. Adi”">
  <data key="d0">“Y. Adi”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher collaborating on foundation models for code, contributing to the 2023 publication.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“J. Liu”">
  <data key="d0">“J. Liu”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in foundational code model research, contributing to the 2023 study on Code Llama.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“T. Remez”">
  <data key="d0">“T. Remez”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher participating in the development and evaluation of code foundation models in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“J. Rapin”">
  <data key="d0">“J. Rapin”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to the 2023 publication on open foundation models for code.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“A. Kozhevnikov”">
  <data key="d0">“A. Kozhevnikov”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the development of code foundation models, contributing to the 2023 study.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“I. Evtimov”">
  <data key="d0">“I. Evtimov”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher participating in the research on open foundation models for code in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“J. Bitton”">
  <data key="d0">“J. Bitton”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to foundational models for code, as published in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“M. Bhatt”">
  <data key="d0">“M. Bhatt”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the development of Code Llama, contributing to 2023 research.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“C. C. Ferrer”">
  <data key="d0">“C. C. Ferrer”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher collaborating on the 2023 study of open foundation models for code.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“A. Grattaﬁori”">
  <data key="d0">“A. Grattaﬁori”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in foundational code model research, contributing to the 2023 publication.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“W. Xiong”">
  <data key="d0">“W. Xiong”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher participating in the development and evaluation of Code Llama in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“A. D ´efossez”">
  <data key="d0">“A. D ´efossez”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to the development of foundation models for code in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“J. Copet”">
  <data key="d0">“J. Copet”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the 2023 study on open foundation models for code.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“F. Azhar”">
  <data key="d0">“F. Azhar”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to the development and evaluation of Code Llama in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“H. Touvron”">
  <data key="d0">“H. Touvron”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in foundational model research, contributing to the 2023 publication on Code Llama.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“L. Martin”">
  <data key="d0">“L. Martin”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher participating in the development of open foundation models for code in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“N. Usunier”">
  <data key="d0">“N. Usunier”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the research on foundation models for code, published in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“T. Scialom”">
  <data key="d0">“T. Scialom”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to the study of open foundation models for code, published in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“G. Synnaeve”">
  <data key="d0">“G. Synnaeve”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the development and evaluation of foundation models for code, published in 2023.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“J. Senanayake”">
  <data key="d0">“J. Senanayake”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher conducting a systematic review on Android mobile malware detection using machine learning, published in 2021.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“H. Kalutarage”">
  <data key="d0">“H. Kalutarage”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the systematic review of malware detection techniques on Android in 2021.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“M. O. Al-Kadri”">
  <data key="d0">“M. O. Al-Kadri”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher participating in the systematic review of Android malware detection using machine learning, published in 2021.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Electronics”">
  <data key="d0">“Electronics”</data>
  <data key="d1">“Discipline”</data>
  <data key="d2">“A scientific discipline focusing on electronic systems, devices, and components, as the publication venue for the systematic review.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="““ML4Code””">
  <data key="d0">““ML4Code””</data>
  <data key="d1">“Tools”</data>
  <data key="d2">“A platform or resource dedicated to machine learning applications in coding, accessible since 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“J. Gu”">
  <data key="d0">“J. Gu”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher working on automatic code summarization using foundation models, presented at IEEE SANER 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“P. Salza”">
  <data key="d0">“P. Salza”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the development of models for automatic code summarization, presented at IEEE SANER 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“H. C. Gall”">
  <data key="d0">“H. C. Gall”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to the study of automatic code summarization at IEEE SANER 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“T. Ahmed”">
  <data key="d0">“T. Ahmed”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher exploring learning from small and local datasets for code summarization, published on arXiv in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“P. Devanbu”">
  <data key="d0">“P. Devanbu”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher investigating methods for learning code summarization from limited data, published on arXiv in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“S. Haque”">
  <data key="d0">“S. Haque”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher evaluating semantic similarity metrics for source code summarization, presented at ICPC 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Z. Eberhart”">
  <data key="d0">“Z. Eberhart”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the evaluation of code summarization techniques, presented at ICPC 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“A. Bansal”">
  <data key="d0">“A. Bansal”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher working on semantic similarity metrics for source code summarization, presented at ICPC 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“C. McMillan”">
  <data key="d0">“C. McMillan”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the evaluation of source code summarization techniques, presented at ICPC 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“W. U. Ahmad”">
  <data key="d0">“W. U. Ahmad”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher developing transformer-based models for source code summarization, published on arXiv in 2020.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“S. Chakraborty”">
  <data key="d0">“S. Chakraborty”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher working on transformer models for code summarization, published on arXiv in 2020.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“B. Ray”">
  <data key="d0">“B. Ray”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the development of transformer-based approaches for source code summarization, published on arXiv in 2020.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“K.-W. Chang”">
  <data key="d0">“K.-W. Chang”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to transformer models for code summarization, published on arXiv in 2020.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“C. Richter”">
  <data key="d0">“C. Richter”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher studying how to learn from developer mistakes to localize and repair bugs, published on arXiv in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“H. Wehrheim”">
  <data key="d0">“H. Wehrheim”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in bug localization and repair research, published on arXiv in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“A. Kharkar”">
  <data key="d0">“A. Kharkar”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher working on reducing false positives in bug detectors, published in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“R. Z. Moghaddam”">
  <data key="d0">“R. Z. Moghaddam”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to bug detection accuracy improvement, published in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“M. Jin”">
  <data key="d0">“M. Jin”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in bug localization and repair research, published in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“X. Liu”">
  <data key="d0">“X. Liu”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher working on bug detection and repair, published in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“X. Shi”">
  <data key="d0">“X. Shi”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to bug localization and repair techniques, published in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“C. B. Clement”">
  <data key="d0">“C. B. Clement”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in bug detection and repair research, published in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“N. Sundaresan”">
  <data key="d0">“N. Sundaresan”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher working on bug localization and repair, published in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“A. Vaswani”">
  <data key="d0">“A. Vaswani”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher co-author of ‘Attention is All You Need,’ foundational for transformer models, published in 2017.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“N. Shazeer”">
  <data key="d0">“N. Shazeer”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher co-author of the Transformer architecture paper, published in 2017.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“N. Parmar”">
  <data key="d0">“N. Parmar”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher co-author of the ‘Attention is All You Need’ paper, published in 2017.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“J. Uszkoreit”">
  <data key="d0">“J. Uszkoreit”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher co-author of the Transformer architecture paper, published in 2017.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“L. Jones”">
  <data key="d0">“L. Jones”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher co-author of the ‘Attention is All You Need’ paper, published in 2017.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“A. N. Gomez”">
  <data key="d0">“A. N. Gomez”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher co-author of the Transformer architecture paper, published in 2017.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“L. Kaiser”">
  <data key="d0">“L. Kaiser”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher co-author of the ‘Attention is All You Need’ paper, published in 2017.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“I. Polosukhin”">
  <data key="d0">“I. Polosukhin”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher co-author of the Transformer architecture paper, published in 2017.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“F. F. Xu”">
  <data key="d0">“F. F. Xu”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher conducting a systematic evaluation of large language models of code, published in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“U. Alon”">
  <data key="d0">“U. Alon”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in evaluating large language models of code, published in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“G. Neubig”">
  <data key="d0">“G. Neubig”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to the evaluation of large language models of code, published in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“V. J. Hellendoorn”">
  <data key="d0">“V. J. Hellendoorn”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the systematic evaluation of large language models of code, published in 2022.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“M. Allamanis”">
  <data key="d0">“M. Allamanis”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher studying the adverse effects of code duplication on machine learning models of code, discussed in 2019.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“A. Radford”">
  <data key="d0">“A. Radford”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher known for work on unsupervised multitask learning with language models, published in 2019.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“J. Wu”">
  <data key="d0">“J. Wu”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the development of large language models, co-authoring Radford et al. 2019.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“R. Child”">
  <data key="d0">“R. Child”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to language models’ development, involved in Radford et al. 2019.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“D. Luan”">
  <data key="d0">“D. Luan”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in the development of large-scale language models, co-authoring Radford et al. 2019.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“D. Amodei”">
  <data key="d0">“D. Amodei”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher contributing to the development of large language models, co-authoring Radford et al. 2019.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“I. Sutskever”">
  <data key="d0">“I. Sutskever”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher co-author of the Radford et al. 2019 paper on language models, influential in AI research.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“V. A. Dobrev”">
  <data key="d0">“V. A. Dobrev”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher working on high-order finite element methods for hydrodynamics, published in 2012.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“T. V. Kolev”">
  <data key="d0">“T. V. Kolev”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher involved in high-order finite element methods for scientific computing, published in 2012.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“R. N. Rieben”">
  <data key="d0">“R. N. Rieben”</data>
  <data key="d1">“Researcher”</data>
  <data key="d2">“A researcher working on advanced numerical methods for hydrodynamics, published in 2012.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“High-order Curvilinear Finite Element Methods”">
  <data key="d0">“High-order Curvilinear Finite Element Methods”</data>
  <data key="d1">“Methodologies”</data>
  <data key="d2">“Numerical techniques for solving complex hydrodynamics equations with high accuracy, discussed in SIAM Journal in 2012.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“SIAM Journal on Scientific Computing”">
  <data key="d0">“SIAM Journal on Scientific Computing”</data>
  <data key="d1">“Discipline”</data>
  <data key="d2">“A scientific journal publishing research on numerical methods and scientific computing, including the 2012 hydrodynamics paper.”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Computing">
  <data key="d0">Computing</data>
  <data key="d1">Core Concepts</data>
  <data key="d2">Computing involves the use of algorithms, hardware, and software to process data, perform calculations, and automate tasks across various fields.&lt;SEP&gt;Computing refers to the systematic use of computers and algorithms to process, analyze, and generate information, often involving programming, data processing, and computational techniques.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="vol. 34, no. 5, pp. B606–B641, 2012">
  <data key="d0">vol. 34, no. 5, pp. B606–B641, 2012</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A scholarly journal volume and issue indicating a published research article or review in a scientific journal.&lt;SEP&gt;This reference indicates a published journal volume and issue, representing a scholarly article or report within a scientific journal.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="D. Choi">
  <data key="d0">D. Choi</data>
  <data key="d1">Researcher</data>
  <data key="d2">D. Choi is a researcher collaborating on projects involving AI and code generation, contributing to scholarly articles.&lt;SEP&gt;D. Choi is a researcher working on AI and machine learning, contributing to studies on code generation models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Chung">
  <data key="d0">J. Chung</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Chung is an author involved in AI research, particularly in code synthesis and reinforcement learning techniques.&lt;SEP&gt;J. Chung is an author involved in research on AI, specifically in code generation and related methodologies.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="N. Kushman">
  <data key="d0">N. Kushman</data>
  <data key="d1">Researcher</data>
  <data key="d2">N. Kushman is a researcher contributing to studies on AI code generation and machine learning techniques.&lt;SEP&gt;N. Kushman is a researcher specializing in AI, focusing on language models and code generation systems.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Schrittwieser">
  <data key="d0">J. Schrittwieser</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Schrittwieser is an AI researcher working on reinforcement learning and algorithm development for AI systems.&lt;SEP&gt;J. Schrittwieser is an author involved in AI research, particularly in reinforcement learning and game-playing algorithms.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="R. Leblond">
  <data key="d0">R. Leblond</data>
  <data key="d1">Researcher</data>
  <data key="d2">R. Leblond is a researcher contributing to AI and machine learning studies, often collaborating on publications.&lt;SEP&gt;R. Leblond is a researcher involved in AI system evaluation and algorithmic development.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="T. Eccles">
  <data key="d0">T. Eccles</data>
  <data key="d1">Researcher</data>
  <data key="d2">T. Eccles is an author contributing to AI research, with focus on algorithms and computational methods.&lt;SEP&gt;T. Eccles is an author involved in AI research, focusing on algorithms and computational models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Keeling">
  <data key="d0">J. Keeling</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Keeling is a researcher working on AI and machine learning, contributing to scientific publications.&lt;SEP&gt;J. Keeling is a researcher working on AI models, particularly in code synthesis and evaluation.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="F. Gimeno">
  <data key="d0">F. Gimeno</data>
  <data key="d1">Researcher</data>
  <data key="d2">F. Gimeno is a researcher involved in AI research, particularly in code generation and related fields.&lt;SEP&gt;F. Gimeno is an author involved in AI and machine learning research, especially in code generation and evaluation.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. D. Lago">
  <data key="d0">A. D. Lago</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. D. Lago is a researcher contributing to AI research, focusing on code synthesis, reinforcement learning, and algorithms.&lt;SEP&gt;A. D. Lago is an author contributing to studies on AI, machine learning, and code generation techniques.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="T. Hubert">
  <data key="d0">T. Hubert</data>
  <data key="d1">Researcher</data>
  <data key="d2">T. Hubert is a researcher involved in AI research, often collaborating on technical publications.&lt;SEP&gt;T. Hubert is an author involved in AI research, particularly in algorithm development and system evaluation.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="P. Choy">
  <data key="d0">P. Choy</data>
  <data key="d1">Researcher</data>
  <data key="d2">P. Choy is a researcher working on AI methodologies and code generation, contributing to scholarly articles.&lt;SEP&gt;P. Choy is a researcher working on AI, focusing on code generation, reinforcement learning, and algorithmic techniques.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. d. M. d’Autume">
  <data key="d0">C. d. M. d’Autume</data>
  <data key="d1">Researcher</data>
  <data key="d2">C. d. M. d’Autume is an author involved in AI research, focusing on algorithms and machine learning models.&lt;SEP&gt;C. d. M. d’Autume is an author involved in AI research, particularly in reinforcement learning and code synthesis.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="I. Babuschkin">
  <data key="d0">I. Babuschkin</data>
  <data key="d1">Researcher</data>
  <data key="d2">I. Babuschkin is a researcher contributing to AI and reinforcement learning studies.&lt;SEP&gt;I. Babuschkin is a researcher contributing to AI systems, with focus on reinforcement learning and system evaluation.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="X. Chen">
  <data key="d0">X. Chen</data>
  <data key="d1">Researcher</data>
  <data key="d2">X. Chen is an author involved in AI research, particularly in language models and code generation.&lt;SEP&gt;X. Chen is an author working on AI algorithms, reinforcement learning, and code generation models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="P.-S. Huang">
  <data key="d0">P.-S. Huang</data>
  <data key="d1">Researcher</data>
  <data key="d2">P.-S. Huang is a researcher involved in AI, focusing on code synthesis, reinforcement learning, and algorithm optimization.&lt;SEP&gt;P.-S. Huang is a researcher working on AI algorithms and language modeling.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Welbl">
  <data key="d0">J. Welbl</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Welbl is a researcher involved in AI research, contributing to publications on language models and code generation.&lt;SEP&gt;J. Welbl is an author involved in AI research, emphasizing reinforcement learning and code generation techniques.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Gowal">
  <data key="d0">S. Gowal</data>
  <data key="d1">Researcher</data>
  <data key="d2">S. Gowal is a researcher working on reinforcement learning, AI algorithms, and system evaluation.&lt;SEP&gt;S. Gowal is an author involved in AI research, focusing on large-scale language modeling.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Cherepanov">
  <data key="d0">A. Cherepanov</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. Cherepanov is a researcher contributing to AI and machine learning studies.&lt;SEP&gt;A. Cherepanov is an author contributing to AI research in code synthesis and reinforcement learning.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Molloy">
  <data key="d0">J. Molloy</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Molloy is a researcher involved in AI systems, especially in reinforcement learning and code generation models.&lt;SEP&gt;J. Molloy is an author involved in AI research, particularly in language models and code generation.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="D. J. Mankowitz">
  <data key="d0">D. J. Mankowitz</data>
  <data key="d1">Researcher</data>
  <data key="d2">D. J. Mankowitz is a researcher working on reinforcement learning and AI methodologies.&lt;SEP&gt;D. J. Mankowitz is an author working on reinforcement learning algorithms and AI system development.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="E. S. Robson">
  <data key="d0">E. S. Robson</data>
  <data key="d1">Researcher</data>
  <data key="d2">E. S. Robson is a researcher involved in AI, focusing on reinforcement learning and system evaluation.&lt;SEP&gt;E. S. Robson is an author involved in AI research, focusing on algorithms and language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="P. Kohli">
  <data key="d0">P. Kohli</data>
  <data key="d1">Researcher</data>
  <data key="d2">P. Kohli is a researcher contributing to AI and machine learning research publications.&lt;SEP&gt;P. Kohli is an author contributing to AI research, especially in reinforcement learning and code synthesis.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="N. de Freitas">
  <data key="d0">N. de Freitas</data>
  <data key="d1">Researcher</data>
  <data key="d2">N. de Freitas is a researcher working on reinforcement learning, AI algorithms, and system optimization.&lt;SEP&gt;N. de Freitas is an author involved in AI research, especially in machine learning and code generation.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="K. Kavukcuoglu">
  <data key="d0">K. Kavukcuoglu</data>
  <data key="d1">Researcher</data>
  <data key="d2">K. Kavukcuoglu is a researcher working on AI and deep learning models.&lt;SEP&gt;K. Kavukcuoglu is an AI researcher known for work on reinforcement learning, neural architectures, and deep learning systems.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="O. Vinyals">
  <data key="d0">O. Vinyals</data>
  <data key="d1">Researcher</data>
  <data key="d2">O. Vinyals is a prominent researcher in AI, known for work on neural networks and language models.&lt;SEP&gt;O. Vinyals is a prominent researcher in AI, particularly in reinforcement learning, neural networks, and language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Competition-level code generation with alphacode”">
  <data key="d0">“Competition-level code generation with alphacode”</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">This publication discusses AlphaCode, a model designed for competitive programming, highlighting advancements in AI code generation.&lt;SEP&gt;This publication discusses AlphaCode, an AI system designed to generate code at competitive programming levels, highlighting advancements in AI code synthesis.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Gokaslan">
  <data key="d0">A. Gokaslan</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. Gokaslan is an author involved in NLP datasets and corpus creation for AI training.&lt;SEP&gt;A. Gokaslan is an author involved in creating and curating large text corpora for NLP research.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="V. Cohen">
  <data key="d0">V. Cohen</data>
  <data key="d1">Researcher</data>
  <data key="d2">V. Cohen is a researcher contributing to datasets and corpora used for training language models.&lt;SEP&gt;V. Cohen is a researcher contributing to large text datasets used for training language and code generation models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Openwebtext corpus">
  <data key="d0">Openwebtext corpus</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Openwebtext is a large-scale dataset of web-based text used for training language models, representing diverse textual data.&lt;SEP&gt;Openwebtext is a large-scale, web-scraped text dataset used for training NLP models, representing diverse textual sources.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Black">
  <data key="d0">S. Black</data>
  <data key="d1">Researcher</data>
  <data key="d2">S. Black is an AI researcher involved in large-scale language modeling, contributing to projects like GPT-Neo and AI datasets.&lt;SEP&gt;S. Black is an AI researcher involved in large-scale language modeling, contributing to projects like GPT-Neo.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="G. Leo">
  <data key="d0">G. Leo</data>
  <data key="d1">Researcher</data>
  <data key="d2">G. Leo is a researcher working on NLP datasets and large language models.&lt;SEP&gt;G. Leo is a researcher working on language models and datasets for NLP applications.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. Leahy">
  <data key="d0">C. Leahy</data>
  <data key="d1">Researcher</data>
  <data key="d2">C. Leahy is a researcher contributing to NLP datasets and model training.&lt;SEP&gt;C. Leahy is an author contributing to large-scale language model research.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Biderman">
  <data key="d0">S. Biderman</data>
  <data key="d1">Researcher</data>
  <data key="d2">S. Biderman is a researcher working on language models and datasets, notably The Pile dataset.&lt;SEP&gt;S. Biderman is an author involved in dataset curation and large-scale language modeling, notably The Pile dataset.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="L. Gao">
  <data key="d0">L. Gao</data>
  <data key="d1">Researcher</data>
  <data key="d2">L. Gao is a researcher working on datasets for NLP and large language models.&lt;SEP&gt;L. Gao is an author involved in NLP datasets and language modeling research.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Presser">
  <data key="d0">S. Presser</data>
  <data key="d1">Researcher</data>
  <data key="d2">S. Presser is a researcher contributing to NLP datasets and language modeling.&lt;SEP&gt;S. Presser is a researcher contributing to datasets for training language models.&lt;SEP&gt;S. Presser is a researcher involved in datasets for training large language models.&lt;SEP&gt;S. Presser is an author contributing to datasets used in training large language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. Foster">
  <data key="d0">C. Foster</data>
  <data key="d1">Researcher</data>
  <data key="d2">C. Foster is a researcher working on large-scale NLP datasets and models.&lt;SEP&gt;C. Foster is an author contributing to large NLP datasets and models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Phang">
  <data key="d0">J. Phang</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Phang is a researcher working on NLP datasets and language models.&lt;SEP&gt;J. Phang is an author involved in language modeling research.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="H. He">
  <data key="d0">H. He</data>
  <data key="d1">Researcher</data>
  <data key="d2">H. He is a researcher contributing to NLP datasets and language models.&lt;SEP&gt;H. He is involved in NLP datasets, model training, and large language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Thite">
  <data key="d0">A. Thite</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. Thite is a researcher involved in language model datasets and training.&lt;SEP&gt;A. Thite is a researcher working on datasets for NLP and language modeling.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="N. Nabeshima">
  <data key="d0">N. Nabeshima</data>
  <data key="d1">Researcher</data>
  <data key="d2">N. Nabeshima is a researcher involved in large-scale NLP datasets and model training.&lt;SEP&gt;N. Nabeshima is a researcher working on large-scale NLP datasets.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="T. B. Brown">
  <data key="d0">T. B. Brown</data>
  <data key="d1">Researcher</data>
  <data key="d2">T. B. Brown is a prominent researcher involved in developing large language models like GPT-3, known for their few-shot learning capabilities.&lt;SEP&gt;T. B. Brown is a researcher at OpenAI known for developing GPT-3, emphasizing few-shot learning in language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="B. Mann">
  <data key="d0">B. Mann</data>
  <data key="d1">Researcher</data>
  <data key="d2">B. Mann is an author contributing to large-scale language model research.&lt;SEP&gt;B. Mann is an author involved in large-scale language model research, including GPT-3.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="N. Ryder">
  <data key="d0">N. Ryder</data>
  <data key="d1">Researcher</data>
  <data key="d2">N. Ryder is a researcher involved in language modeling and AI research.&lt;SEP&gt;N. Ryder is a researcher working on large language models and AI system development.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="M. Subbiah">
  <data key="d0">M. Subbiah</data>
  <data key="d1">Researcher</data>
  <data key="d2">M. Subbiah is a researcher involved in large language models, focusing on scaling and capabilities.&lt;SEP&gt;M. Subbiah is a researcher working on large language models and AI techniques.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Kaplan">
  <data key="d0">J. Kaplan</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Kaplan is a key researcher at OpenAI, contributing to GPT-3 and language model scaling.&lt;SEP&gt;J. Kaplan is a key researcher in AI, contributing to GPT development and language modeling.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="P. Dhariwal">
  <data key="d0">P. Dhariwal</data>
  <data key="d1">Researcher</data>
  <data key="d2">P. Dhariwal is an author involved in large language model research, including GPT-3 and related models.&lt;SEP&gt;P. Dhariwal is an author involved in large language models, especially GPT-3, focusing on model training and optimization.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Neelakantan">
  <data key="d0">A. Neelakantan</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. Neelakantan is a researcher working on AI models and algorithms.&lt;SEP&gt;A. Neelakantan is a researcher working on AI models, including training techniques and optimization.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="P. Shyam">
  <data key="d0">P. Shyam</data>
  <data key="d1">Researcher</data>
  <data key="d2">P. Shyam is involved in AI research related to language models.&lt;SEP&gt;P. Shyam is involved in AI research, especially in large language models and training algorithms.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="G. Sastry">
  <data key="d0">G. Sastry</data>
  <data key="d1">Researcher</data>
  <data key="d2">G. Sastry is a researcher contributing to AI and large language models.&lt;SEP&gt;G. Sastry is a researcher contributing to AI models and large language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Askell">
  <data key="d0">A. Askell</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. Askell is a researcher focusing on AI safety and large-scale language models.&lt;SEP&gt;A. Askell is a researcher involved in AI safety and large-scale language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Agarwal">
  <data key="d0">S. Agarwal</data>
  <data key="d1">Researcher</data>
  <data key="d2">S. Agarwal is an author working on AI models and datasets.&lt;SEP&gt;S. Agarwal is involved in AI research, especially in training large language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Herbert-Voss">
  <data key="d0">A. Herbert-Voss</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. Herbert-Voss is a researcher contributing to large language model research.&lt;SEP&gt;A. Herbert-Voss is a researcher working on large language models and their training methodologies.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="G. Krueger">
  <data key="d0">G. Krueger</data>
  <data key="d1">Researcher</data>
  <data key="d2">G. Krueger is an AI researcher involved in large-scale language models and AI scaling techniques.&lt;SEP&gt;G. Krueger is involved in AI research, especially in large-scale models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="T. Henighan">
  <data key="d0">T. Henighan</data>
  <data key="d1">Researcher</data>
  <data key="d2">T. Henighan is a researcher working on AI and language modeling.&lt;SEP&gt;T. Henighan is a researcher working on training large language models and scaling methods.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="R. Child">
  <data key="d0">R. Child</data>
  <data key="d1">Researcher</data>
  <data key="d2">R. Child is an author involved in AI research and language models.&lt;SEP&gt;R. Child is involved in AI research, particularly in training and evaluating large language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Ramesh">
  <data key="d0">A. Ramesh</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. Ramesh is a researcher contributing to AI and generative models, including large language models.&lt;SEP&gt;A. Ramesh is a researcher contributing to AI and generative models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="D. M. Ziegler">
  <data key="d0">D. M. Ziegler</data>
  <data key="d1">Researcher</data>
  <data key="d2">D. M. Ziegler is an author involved in large language model research, focusing on scaling and capabilities.&lt;SEP&gt;D. M. Ziegler is involved in AI research, particularly in large-scale language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Wu">
  <data key="d0">J. Wu</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Wu is a researcher working on AI and language modeling.&lt;SEP&gt;J. Wu is a researcher working on AI models, especially in the context of large language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. Winter">
  <data key="d0">C. Winter</data>
  <data key="d1">Researcher</data>
  <data key="d2">C. Winter is an author involved in AI research, especially in large models.&lt;SEP&gt;C. Winter is an author involved in large language model research and system scaling.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. Hesse">
  <data key="d0">C. Hesse</data>
  <data key="d1">Researcher</data>
  <data key="d2">C. Hesse is a researcher contributing to AI and NLP datasets.&lt;SEP&gt;C. Hesse is a researcher contributing to datasets and training large NLP models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="M. Chen">
  <data key="d0">M. Chen</data>
  <data key="d1">Researcher</data>
  <data key="d2">M. Chen is an author involved in AI and language model research.&lt;SEP&gt;M. Chen is an author involved in AI research, focusing on optimization algorithms, training methods, and large-scale models.&lt;SEP&gt;M. Chen is an author involved in AI research, including optimization techniques and large-scale training.&lt;SEP&gt;M. Chen is an author involved in AI research, particularly in language models and training datasets.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="E. Sigler">
  <data key="d0">E. Sigler</data>
  <data key="d1">Researcher</data>
  <data key="d2">E. Sigler is a researcher working on AI models and datasets.&lt;SEP&gt;E. Sigler is a researcher working on large language models, training methods, and datasets.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="M. Litwin">
  <data key="d0">M. Litwin</data>
  <data key="d1">Researcher</data>
  <data key="d2">M. Litwin is involved in AI research, especially in large-scale language models and training data.&lt;SEP&gt;M. Litwin is involved in AI research, particularly in large language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Gray">
  <data key="d0">S. Gray</data>
  <data key="d1">Researcher</data>
  <data key="d2">S. Gray is a researcher contributing to AI and NLP datasets.&lt;SEP&gt;S. Gray is a researcher contributing to large language models and their training datasets.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="B. Chess">
  <data key="d0">B. Chess</data>
  <data key="d1">Researcher</data>
  <data key="d2">B. Chess is a researcher involved in AI and language modeling.&lt;SEP&gt;B. Chess is an author involved in AI and large language model research.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Clark">
  <data key="d0">J. Clark</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Clark is a researcher working on large-scale language models and AI system scaling.&lt;SEP&gt;J. Clark is an author working on large-scale language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. Berner">
  <data key="d0">C. Berner</data>
  <data key="d1">Researcher</data>
  <data key="d2">C. Berner&lt;SEP&gt;C. Berner is an AI researcher contributing to language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. McCandlish">
  <data key="d0">S. McCandlish</data>
  <data key="d1">Researcher</data>
  <data key="d2">S. McCandlish is a researcher contributing to AI scaling, model architecture, and large language models.&lt;SEP&gt;S. McCandlish is a researcher involved in AI research, especially in model scaling.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Radford">
  <data key="d0">A. Radford</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. Radford is a co-developer of GPT models, focusing on large language model architectures and training.&lt;SEP&gt;A. Radford is a key researcher at OpenAI, known for GPT models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="I. Sutskever">
  <data key="d0">I. Sutskever</data>
  <data key="d1">Researcher</data>
  <data key="d2">I. Sutskever is a leading AI researcher, co-founder of OpenAI, involved in developing large language models like GPT.&lt;SEP&gt;I. Sutskever is a prominent AI researcher, co-founder of OpenAI, involved in language models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="D. Amodei">
  <data key="d0">D. Amodei</data>
  <data key="d1">Researcher</data>
  <data key="d2">D. Amodei is an AI researcher and executive, involved in large language model development.&lt;SEP&gt;D. Amodei is an AI researcher and executive, involved in large-scale language model development and safety.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Language models are few-shot learners”">
  <data key="d0">“Language models are few-shot learners”</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">This paper discusses the capabilities of large language models like GPT-3 to perform new tasks with minimal examples, emphasizing few-shot learning.&lt;SEP&gt;This paper discusses the few-shot learning capabilities of large language models like GPT-3, highlighting their ability to perform tasks with minimal examples.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Gpt-4 technical report”">
  <data key="d0">“Gpt-4 technical report”</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">This report details the architecture, capabilities, and advancements of GPT-4, a large-scale language model developed by OpenAI.&lt;SEP&gt;This report provides detailed technical information about GPT-4, including architecture, training, and capabilities.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="T. Wolf">
  <data key="d0">T. Wolf</data>
  <data key="d1">Researcher</data>
  <data key="d2">T. Wolf is an AI researcher involved in NLP, transformer models, and datasets for language modeling.&lt;SEP&gt;T. Wolf is involved in NLP research, contributing to transformer models and datasets.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="L. Debut">
  <data key="d0">L. Debut</data>
  <data key="d1">Researcher</data>
  <data key="d2">L. Debut is a researcher working on NLP and transformer models.&lt;SEP&gt;L. Debut is a researcher working on transformer architectures and NLP datasets.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="V. Sanh">
  <data key="d0">V. Sanh</data>
  <data key="d1">Researcher</data>
  <data key="d2">V. Sanh is an author contributing to transformer-based NLP models and datasets.&lt;SEP&gt;V. Sanh is an author contributing to transformer-based NLP models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Chaumond">
  <data key="d0">J. Chaumond</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Chaumond is involved in NLP research and transformer architectures.&lt;SEP&gt;J. Chaumond is involved in NLP research, focusing on transformer models and scalable training.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. Delangue">
  <data key="d0">C. Delangue</data>
  <data key="d1">Researcher</data>
  <data key="d2">C. Delangue is a researcher working on NLP datasets and transformer architectures.&lt;SEP&gt;C. Delangue is a researcher working on NLP models and datasets.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Moi">
  <data key="d0">A. Moi</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. Moi is an author involved in NLP research, especially transformer models.&lt;SEP&gt;A. Moi is an author involved in NLP research.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="P. Cistac">
  <data key="d0">P. Cistac</data>
  <data key="d1">Researcher</data>
  <data key="d2">P. Cistac is a researcher working on transformer models and NLP datasets.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. Ma">
  <data key="d0">C. Ma</data>
  <data key="d1">Researcher</data>
  <data key="d2">C. Ma is a researcher involved in transformer architectures and NLP datasets.&lt;SEP&gt;C. Ma is involved in NLP research and transformer architectures.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Y. Jernite">
  <data key="d0">Y. Jernite</data>
  <data key="d1">Researcher</data>
  <data key="d2">Y. Jernite is a researcher contributing to NLP datasets and models.&lt;SEP&gt;Y. Jernite is a researcher working on NLP datasets and transformer models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Plu">
  <data key="d0">J. Plu</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Plu is an author contributing to transformer-based NLP research.&lt;SEP&gt;J. Plu is involved in NLP research, focusing on transformer models.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="T. Le Scao">
  <data key="d0">T. Le Scao</data>
  <data key="d1">Researcher</data>
  <data key="d2">T. Le Scao is an author involved in transformer-based NLP research.&lt;SEP&gt;T. Le Scao is involved in transformer NLP research and datasets.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Gugger">
  <data key="d0">S. Gugger</data>
  <data key="d1">Researcher</data>
  <data key="d2">S. Gugger is a researcher contributing to transformer models and NLP datasets.&lt;SEP&gt;S. Gugger is an author working on transformer models and NLP datasets.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="M. Drame">
  <data key="d0">M. Drame</data>
  <data key="d1">Researcher</data>
  <data key="d2">M. Drame is a researcher involved in transformer architectures and NLP research.&lt;SEP&gt;M. Drame is involved in NLP research, especially transformer architectures.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Q. Lhoest">
  <data key="d0">Q. Lhoest</data>
  <data key="d1">Researcher</data>
  <data key="d2">Q. Lhoest is a researcher working on datasets and transformer models for NLP.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. M. Rush">
  <data key="d0">A. M. Rush</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. M. Rush is an author involved in NLP and transformer-based models.&lt;SEP&gt;A. M. Rush is an author involved in transformer NLP models and datasets.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Transformers: State-of-the-Art Natural Language Processing”">
  <data key="d0">“Transformers: State-of-the-Art Natural Language Processing”</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">This publication reviews the transformer architecture, its dominance in NLP, and various applications and advancements.&lt;SEP&gt;This publication reviews transformer architectures, the current state-of-the-art in NLP, and their applications.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Deepspeed">
  <data key="d0">Deepspeed</data>
  <data key="d1">Tools</data>
  <data key="d2">Deepspeed is a software library developed by Microsoft that enables efficient training of large AI models at scale.&lt;SEP&gt;Deepspeed is a software tool developed by Microsoft that enables extreme-scale training of large AI models efficiently.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="J. Ren">
  <data key="d0">J. Ren</data>
  <data key="d1">Researcher</data>
  <data key="d2">J. Ren is involved in AI research, focusing on democratizing large-scale model training and parallelization techniques.&lt;SEP&gt;J. Ren is involved in AI research, focusing on large-scale model training and democratization of AI.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Rajbhandari">
  <data key="d0">S. Rajbhandari</data>
  <data key="d1">Researcher</data>
  <data key="d2">S. Rajbhandari is a researcher working on distributed training and parallelism for large models.&lt;SEP&gt;S. Rajbhandari is an author working on distributed AI training frameworks.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="R. Y. Aminabadi">
  <data key="d0">R. Y. Aminabadi</data>
  <data key="d1">Researcher</data>
  <data key="d2">R. Y. Aminabadi is a researcher focusing on scalable AI training, model offloading, and democratization.&lt;SEP&gt;R. Y. Aminabadi is a researcher involved in AI model training methodologies.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="O. Ruwase">
  <data key="d0">O. Ruwase</data>
  <data key="d1">Researcher</data>
  <data key="d2">O. Ruwase is a researcher working on parallel and distributed deep learning systems.&lt;SEP&gt;O. Ruwase is involved in research on parallel and distributed deep learning systems.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Yang">
  <data key="d0">S. Yang</data>
  <data key="d1">Researcher</data>
  <data key="d2">S. Yang is a researcher working on system efficiency and parallel training of large models.&lt;SEP&gt;S. Yang is involved in AI training infrastructure research.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="M. Zhang">
  <data key="d0">M. Zhang</data>
  <data key="d1">Researcher</data>
  <data key="d2">M. Zhang is a researcher working on scalable AI training frameworks.&lt;SEP&gt;M. Zhang is involved in scalable AI training frameworks and parallel computing.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="D. Li">
  <data key="d0">D. Li</data>
  <data key="d1">Researcher</data>
  <data key="d2">D. Li is a researcher working on distributed training and model offloading techniques.&lt;SEP&gt;D. Li is involved in AI model training and parallel computing.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Y. He">
  <data key="d0">Y. He</data>
  <data key="d1">Researcher</data>
  <data key="d2">Y. He is a researcher working on distributed deep learning systems.&lt;SEP&gt;Y. He is involved in large-scale distributed deep learning and model training infrastructure.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Zero-offload: Democratizing billion-scale model training”">
  <data key="d0">“Zero-offload: Democratizing billion-scale model training”</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">This paper discusses methods for enabling training of billion-scale models through offloading techniques, making large-scale training more accessible.&lt;SEP&gt;This paper discusses offloading techniques that enable training of billion-parameter models without requiring extensive local resources, making large-scale AI training more accessible.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="T. Ben-Nun">
  <data key="d0">T. Ben-Nun</data>
  <data key="d1">Researcher</data>
  <data key="d2">T. Ben-Nun is an author analyzing parallel and distributed deep learning architectures and their efficiency.&lt;SEP&gt;T. Ben-Nun is an author analyzing parallel and distributed deep learning architectures.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="T. Hoeffler">
  <data key="d0">T. Hoeffler</data>
  <data key="d1">Researcher</data>
  <data key="d2">T. Hoeffler is a researcher specializing in concurrency and scalability in deep learning.&lt;SEP&gt;T. Hoeffler is a researcher specializing in concurrency, scalability, and system optimization in deep learning.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Demystifying parallel and distributed deep learning”">
  <data key="d0">“Demystifying parallel and distributed deep learning”</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">This publication provides an in-depth analysis of parallel and distributed deep learning architectures and their efficiencies.&lt;SEP&gt;This publication provides an in-depth analysis of parallel and distributed deep learning architectures, their challenges, and efficiencies.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="D. Nichols">
  <data key="d0">D. Nichols</data>
  <data key="d1">Researcher</data>
  <data key="d2">D. Nichols is a researcher performing empirical evaluations of deep learning frameworks and systems.&lt;SEP&gt;D. Nichols is involved in empirical evaluation of deep learning frameworks.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Singh">
  <data key="d0">S. Singh</data>
  <data key="d1">Researcher</data>
  <data key="d2">S. Singh is a researcher working on parallel deep learning systems.&lt;SEP&gt;S. Singh is involved in research on parallel deep learning systems and their performance.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S.-H. Lin">
  <data key="d0">S.-H. Lin</data>
  <data key="d1">Researcher</data>
  <data key="d2">S.-H. Lin is a researcher working on concurrency, parallelization, and scalability in deep learning frameworks.&lt;SEP&gt;S.-H. Lin is involved in deep learning research, especially in parallelization techniques.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Bhatele">
  <data key="d0">A. Bhatele</data>
  <data key="d1">Researcher</data>
  <data key="d2">A. Bhatele&lt;SEP&gt;A. Bhatele is a researcher focusing on scalable AI training frameworks.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“A survey and empirical evaluation of parallel deep learning frameworks”">
  <data key="d0">“A survey and empirical evaluation of parallel deep learning frameworks”</data>
  <data key="d1">Study Designs</data>
  <data key="d2">This survey evaluates different parallel deep learning frameworks through empirical analysis, assessing performance and scalability.&lt;SEP&gt;This survey evaluates various parallel deep learning frameworks through empirical experiments to assess performance, scalability, and efficiency.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="I. Loshchilov">
  <data key="d0">I. Loshchilov</data>
  <data key="d1">Researcher</data>
  <data key="d2">I. Loshchilov is an author known for work on optimization algorithms in deep learning.&lt;SEP&gt;I. Loshchilov is an author working on optimization techniques, particularly weight decay regularization in training algorithms.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="F. Hutter">
  <data key="d0">F. Hutter</data>
  <data key="d1">Researcher</data>
  <data key="d2">F. Hutter is a researcher involved in AI optimization and regularization techniques.&lt;SEP&gt;F. Hutter is a researcher involved in AI optimization, regularization, and training stability.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Fixing weight decay regularization in Adam”">
  <data key="d0">“Fixing weight decay regularization in Adam”</data>
  <data key="d1">Methodologies</data>
  <data key="d2">This paper proposes modifications to the Adam optimizer to improve weight decay regularization, enhancing training stability and performance.&lt;SEP&gt;This study proposes improvements to the Adam optimizer by addressing weight decay regularization issues.</data>
  <data key="d3">chunk-171366f30e20f3d5db56b06a48c19e63</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Loshchilov and Hutter 2017">
  <data key="d0">Loshchilov and Hutter 2017</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A research paper discussing the method of fixing weight decay regularization in the Adam optimizer, contributing to optimization methodology in machine learning.&lt;SEP&gt;A research paper discussing the methodology for fixing weight decay regularization in the Adam optimizer, contributing to optimization techniques in machine learning.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arXiv 1711.05101">
  <data key="d0">arXiv 1711.05101</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A preprint repository hosting the study on weight decay regularization in Adam.&lt;SEP&gt;Repository hosting the preprint of the study on weight decay regularization in Adam.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Chen et al. 2021">
  <data key="d0">Chen et al. 2021</data>
  <data key="d1">Study Designs</data>
  <data key="d2">A comprehensive evaluation of large language models trained on code, assessing their capabilities and performance.&lt;SEP&gt;A comprehensive evaluation of large language models trained on code, assessing their capabilities, performance, and applications.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arXiv 2021">
  <data key="d0">arXiv 2021</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Repository hosting the study evaluating large language models trained on code.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Devlin et al. 2019">
  <data key="d0">Devlin et al. 2019</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Development and pre-training of BERT, a deep bidirectional transformer model designed for language understanding tasks.&lt;SEP&gt;Development and pre-training of BERT, a deep bidirectional transformer model for language understanding.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Proceedings of NAACL 2019">
  <data key="d0">Proceedings of NAACL 2019</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Conference proceedings where the BERT model was published.&lt;SEP&gt;Conference proceedings where the BERT paper was published.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Liu et al. 2019">
  <data key="d0">Liu et al. 2019</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Development of RoBERTa, an optimized BERT pretraining approach that improves language model performance.&lt;SEP&gt;Development of RoBERTa, an optimized BERT pretraining approach, enhancing language model performance.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arXiv 1907.11692">
  <data key="d0">arXiv 1907.11692</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Repository hosting the RoBERTa study.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Wei et al. 2023">
  <data key="d0">Wei et al. 2023</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Introduction of MagicCoder, a large language model specialized for source code, with applications in code generation.&lt;SEP&gt;Introduction of MagicCoder, a source code model based on large language models.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arXiv 2312.02120">
  <data key="d0">arXiv 2312.02120</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Repository hosting the MagicCoder study.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Döderlein et al. 2022">
  <data key="d0">Döderlein et al. 2022</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Analysis of piloting CoPilot and Codex, examining prompt temperature effects.&lt;SEP&gt;Analysis of piloting OpenAI's CoPilot and Codex, focusing on prompt temperature effects and performance.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arXiv 2022.14699">
  <data key="d0">arXiv 2022.14699</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Repository hosting the study on piloting CoPilot and Codex.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Barke et al. 2022">
  <data key="d0">Barke et al. 2022</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Research on how programmers interact with code-generating AI models, examining user interaction patterns.&lt;SEP&gt;Research on how programmers interact with code-generating AI models, grounded in empirical analysis.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arXiv 2206.15000">
  <data key="d0">arXiv 2206.15000</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Repository hosting the grounded CoPilot interaction study.&lt;SEP&gt;Repository hosting the grounded CoPilot study.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Sarkar et al. 2022">
  <data key="d0">Sarkar et al. 2022</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Exploration of programmer experiences and perceptions when programming with artificial intelligence assistance.&lt;SEP&gt;Qualitative exploration of programming experiences with artificial intelligence.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arXiv 2208.06213">
  <data key="d0">arXiv 2208.06213</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Repository hosting the study on programming with AI assistance.&lt;SEP&gt;Repository hosting the study on programming with AI.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Chen et al. 2023">
  <data key="d0">Chen et al. 2023</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Development of data race detection methods using large language models.&lt;SEP&gt;Development of methods for data race detection in software using large language models.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arXiv 2023">
  <data key="d0">arXiv 2023</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Repository hosting the compiler validation testsuite study.&lt;SEP&gt;Repository hosting the study on LLM-based compiler testing.&lt;SEP&gt;Repository hosting the study on data race detection techniques.&lt;SEP&gt;Repository hosting the study on data race detection with language models.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Munley et al. 2023">
  <data key="d0">Munley et al. 2023</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Design of LLM-driven test suites for compiler validation.&lt;SEP&gt;Design of LLM-driven testsuites for compiler validation, improving compiler testing methodologies.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Alon et al. 2018">
  <data key="d0">Alon et al. 2018</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Development of code2vec, a model for learning distributed representations of code.&lt;SEP&gt;Introduction of code2vec, a model for learning distributed representations of source code for code analysis.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arXiv 1803.09473">
  <data key="d0">arXiv 1803.09473</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Repository hosting the code2vec study.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="VenkataKeerthy et al. 2020">
  <data key="d0">VenkataKeerthy et al. 2020</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Creation of IR2V, scalable program embeddings based on LLVM IR.&lt;SEP&gt;Development of IR2V, a scalable program embedding technique based on LLVM IR for program analysis.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="ACM Transactions on Architecture and Code Optimization 2020">
  <data key="d0">ACM Transactions on Architecture and Code Optimization 2020</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Journal publishing the IR2V program embedding methodology.&lt;SEP&gt;Journal publishing the IR2V study.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Garg et al. 2022">
  <data key="d0">Garg et al. 2022</data>
  <data key="d1">Study Designs</data>
  <data key="d2">Application of deep learning techniques to improve software performance, demonstrating AI's impact in software engineering.&lt;SEP&gt;Application of deep learning to improve software performance.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Proceedings of the 30th ACM JOSE 2022">
  <data key="d0">Proceedings of the 30th ACM JOSE 2022</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Conference proceedings where the deepdev-perf study was published.</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Deepdev-perf">
  <data key="d0">Deepdev-perf</data>
  <data key="d1">Methodology</data>
  <data key="d2">Deepdev-perf is a deep learning-based approach aimed at improving software performance, involving the application of neural network techniques to optimize and evaluate software systems.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Software Performance">
  <data key="d0">Software Performance</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">Software performance refers to the efficiency and effectiveness of software systems, which is the focus of the Deepdev-perf methodology.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering">
  <data key="d0">ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering</data>
  <data key="d1">Study Design</data>
  <data key="d2">A conference where research like Deepdev-perf is presented, serving as a platform for disseminating findings in software engineering.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Deep Learning">
  <data key="d0">Deep Learning</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Deep learning is a subset of machine learning involving neural networks with multiple layers, used here to enhance software performance.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Natural Language Generation, Translation, and Comprehension">
  <data key="d0">Natural Language Generation, Translation, and Comprehension</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">These are tasks in natural language processing that are addressed by models like BART, focusing on language understanding and generation.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Sequence-to-Sequence Pre-training">
  <data key="d0">Sequence-to-Sequence Pre-training</data>
  <data key="d1">Theories/Models</data>
  <data key="d2">Sequence-to-sequence pre-training involves training models to predict entire sequences, enhancing performance in language tasks.&lt;SEP&gt;Sequence-to-sequence pre-training involves training models to predict sequences of data, enhancing capabilities in language tasks.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="dec 2020">
  <data key="d0">dec 2020</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Dec 2020 is a timestamp indicating the date of the document or data collection, providing temporal context.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="https://doi.org/10.1145/3418463">
  <data key="d0">https://doi.org/10.1145/3418463</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A digital object representing the DOI link for a research publication, used for referencing.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="S. Garg">
  <data key="d0">S. Garg</data>
  <data key="d1">Authors</data>
  <data key="d2">S. Garg is a researcher involved in developing Deepdev-perf, contributing to methodology and performance optimization studies.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="R. Z. Moghaddam">
  <data key="d0">R. Z. Moghaddam</data>
  <data key="d1">Authors</data>
  <data key="d2">R. Z. Moghaddam is a researcher collaborating on Deepdev-perf, focusing on software performance improvements.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. B. Clement">
  <data key="d0">C. B. Clement</data>
  <data key="d1">Authors</data>
  <data key="d2">C. B. Clement is a researcher contributing to the development and evaluation of the Deepdev-perf approach.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="N. Sundaresan">
  <data key="d0">N. Sundaresan</data>
  <data key="d1">Authors</data>
  <data key="d2">N. Sundaresan is involved in research on deep learning applications for software performance enhancement.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="C. Wu">
  <data key="d0">C. Wu</data>
  <data key="d1">Authors</data>
  <data key="d2">C. Wu is a researcher associated with the Deepdev-perf study, focusing on performance optimization techniques.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="2019">
  <data key="d0">2019</data>
  <data key="d1">Spatiotemporal Information</data>
  <data key="d2">Year of the publication or preprint release, providing temporal context.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="arxiv.org">
  <data key="d0">arxiv.org</data>
  <data key="d1">Objects of Study</data>
  <data key="d2">A digital repository hosting preprints of research papers, including the BART model paper.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Y. Liu">
  <data key="d0">Y. Liu</data>
  <data key="d1">Authors</data>
  <data key="d2">Y. Liu is a researcher involved in natural language processing and pre-training models like BART.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="M. Goyal">
  <data key="d0">M. Goyal</data>
  <data key="d1">Authors</data>
  <data key="d2">M. Goyal is a researcher contributing to the development of BART for language generation tasks.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="N. Ghazvininejad">
  <data key="d0">N. Ghazvininejad</data>
  <data key="d1">Authors</data>
  <data key="d2">N. Ghazvininejad is involved in research on denoising sequence-to-sequence models for NLP.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="A. Mohamed">
  <data key="d0">A. Mohamed</data>
  <data key="d1">Authors</data>
  <data key="d2">A. Mohamed is a researcher working on language models such as BART for translation and comprehension.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="O. Levy">
  <data key="d0">O. Levy</data>
  <data key="d1">Authors</data>
  <data key="d2">O. Levy is a contributor to the BART pre-training methodology, focusing on NLP applications.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="V. Stoyanov">
  <data key="d0">V. Stoyanov</data>
  <data key="d1">Authors</data>
  <data key="d2">V. Stoyanov is involved in research on language models and sequence-to-sequence pre-training.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="L. Zettlemoyer">
  <data key="d0">L. Zettlemoyer</data>
  <data key="d1">Authors</data>
  <data key="d2">L. Zettlemoyer is a researcher specializing in language understanding and pre-training models like BART.</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Training Approaches">
  <data key="d0">Training Approaches</data>
  <data key="d3">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d2">LLMs trained on source code can be adapted for code generation, prediction, and translation tasks, with specialized training strategies.&lt;SEP&gt;LLMs trained on source code can be used for code generation, prediction, and translation, often with specialized training strategies.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="training">
  <data key="d0">training</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d2">The AdamW optimizer updates model weights during training, helping to minimize loss and improve convergence.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="research questions/hypotheses">
  <data key="d0">research questions/hypotheses</data>
  <data key="d3">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d2">Selecting models based on architecture, size, and pre-training data addresses research questions about optimal model performance.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Benchmark Tasks">
  <data key="d0">Benchmark Tasks</data>
  <data key="d3">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d2">Code completion tasks are used as benchmarks to evaluate models' ability to generate correct code from natural language descriptions.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="GPT2">
  <data key="d0">GPT2</data>
  <data key="d3">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d2">GPT-2's ability to generate HPC code is limited due to lack of source code in its pre-training dataset; slight improvements are observed after fine-tuning.&lt;SEP&gt;GPT-2's ability to generate correct HPC code is limited due to lack of source code in its pre-training dataset, but slight improvements are observed after fine-tuning.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Limitations”">
  <data key="d0">“Limitations”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d2">“A. Kharkar’s work on reducing false positives addresses limitations in bug detection tools, published in 2022.”</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Theories/Models”">
  <data key="d0">“Theories/Models”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d2">“A co-author of ‘Attention is All You Need,’ foundational paper introducing the Transformer architecture, published in 2017.”</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Content_keywords”">
  <data key="d0">“Content_keywords”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d2">“Systematic evaluation of large language models of code, highlighting their capabilities and limitations, published in 2022.”</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“F. Xu”">
  <data key="d0">“F. Xu”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d2">“Systematic evaluation of large language models of code, highlighting their capabilities and limitations, published in 2022.”</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="“Objects of Study”">
  <data key="d0">“Objects of Study”</data>
  <data key="d3">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d2">“V. A. Dobrev studies high-order curvilinear finite element methods for hydrodynamics, contributing to scientific computing.”</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="ACM 2020">
  <data key="d0">ACM 2020</data>
  <data key="d3">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d2">Presents IR2V, a scalable program embedding technique based on LLVM IR for program analysis and representation."|&lt;SEP&gt;Presents IR2V, scalable program embeddings based on LLVM IR, facilitating program analysis."|</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="ACM Conference">
  <data key="d0">ACM Conference</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d2">Deepdev-perf research was presented at the conference, indicating peer-reviewed dissemination of the methodology.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<node id="Bart">
  <data key="d0">Bart</data>
  <data key="d3">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d2">Bart is designed for tasks involving natural language generation, translation, and comprehension, serving as a tool for NLP applications.</data>
  <data key="d1">UNKNOWN</data>
  <data key="d4">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</node>
<edge source="Large Language Models" target="Code Generation">
  <data key="d5">25.0</data>
  <data key="d6">LLMs are used in code generation tools to automatically produce programming code, improving automation and developer assistance.&lt;SEP&gt;LLMs are utilized in code generation tools to automatically produce programming code, enhancing developer productivity.&lt;SEP&gt;Large Language Models are used to automate and assist in generating code based on natural language descriptions.</data>
  <data key="d7">AI assistance, automation&lt;SEP&gt;application, automation&lt;SEP&gt;automation, AI assistance</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35&lt;SEP&gt;chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf&lt;SEP&gt;Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Large Language Models" target="Benchmark ParEval">
  <data key="d5">16.0</data>
  <data key="d6">The benchmark ParEval is designed to evaluate the capabilities of large language models in generating parallel code.&lt;SEP&gt;The benchmark ParEval is designed to evaluate the capabilities of large language models in generating parallel code."|&gt;"evaluation, benchmarking</data>
  <data key="d7">8&lt;SEP&gt;evaluation, benchmarking</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Large Language Models" target="Metrics for Code Evaluation">
  <data key="d5">18.0</data>
  <data key="d6">The newly developed metrics are used to assess the performance of the models' generated code."|&gt;"performance assessment, evaluation&lt;SEP&gt;The novel metrics are used to assess the performance of the language models' generated code."|&gt;"performance assessment, evaluation metrics</data>
  <data key="d7">9</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Large Language Models" target="Research Questions/Hypotheses">
  <data key="d5">12.0</data>
  <data key="d6">The study hypothesizes that large language models can generate effective parallel code for scientific computing tasks."|&gt;"research hypothesis, capability assessment</data>
  <data key="d7">6</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Large Language Models" target="Program Synthesis">
  <data key="d5">16.0</data>
  <data key="d6">Program synthesis leverages LLMs to automatically generate code from specifications, with research evaluating their effectiveness.&lt;SEP&gt;Program synthesis leverages LLMs to generate code from specifications, with research evaluating their effectiveness.</data>
  <data key="d7">automated coding, evaluation&lt;SEP&gt;automatic coding, evaluation</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Large Language Models" target="Domain Specialization">
  <data key="d5">32.0</data>
  <data key="d6">Domain specialization techniques are developed to adapt large language models to specific domains, enhancing their applicability and disruptive potential.&lt;SEP&gt;Domain specialization techniques are developed to adapt large language models to specific domains, enhancing their effectiveness, relevance, and disruptive potential in targeted applications."|"&lt;application, adaptation, impact&lt;SEP&gt;Specializing large language models in specific domains enhances their disruptive potential by tailoring their capabilities to particular fields.&lt;SEP&gt;Specializing large language models in specific domains enhances their effectiveness and disruptive potential in those fields.</data>
  <data key="d7">7&lt;SEP&gt;9&lt;SEP&gt;application, adaptation, impact&lt;SEP&gt;domain adaptation, model specialization</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd&lt;SEP&gt;chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Natural Language Processing">
  <data key="d5">9.0</data>
  <data key="d6">LLMs are a central technology within NLP, enabling advanced language understanding and generation tasks.</data>
  <data key="d7">technology integration</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Domain Tools">
  <data key="d5">16.0</data>
  <data key="d6">LLMs can call domain tools to enhance task performance by leveraging specialized functionalities.&lt;SEP&gt;LLMs can invoke domain tools to perform specialized tasks, leveraging their functionalities for improved performance.</data>
  <data key="d7">capability, tool invocation&lt;SEP&gt;tool integration, capability enhancement</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Task Planners">
  <data key="d5">8.0</data>
  <data key="d6">LLMs can act as task planners by decomposing tasks and coordinating multiple tool calls for efficient problem-solving.&lt;SEP&gt;LLMs can act as task planners by decomposing tasks and coordinating multiple tool calls.</data>
  <data key="d7">task management, coordination</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Knowledge Bases">
  <data key="d5">3.0</data>
  <data key="d6">Knowledge bases provide structured information that LLMs can access to improve task accuracy and relevance.</data>
  <data key="d7">information access, domain knowledge</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Result Accuracy">
  <data key="d5">2.0</data>
  <data key="d6">The accuracy of LLM outputs is critical for reliable task completion, especially when combined with domain tools.</data>
  <data key="d7">performance, reliability</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Result Validation">
  <data key="d5">1.0</data>
  <data key="d6">Validation procedures ensure the outputs generated by LLMs and tools are correct and trustworthy.</data>
  <data key="d7">quality assurance, correctness</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Question-Answer Systems">
  <data key="d5">18.0</data>
  <data key="d6">LLMs act as question-answer systems, assisting Earth scientists with knowledge retrieval, code examples, and scenario development.&lt;SEP&gt;LLMs serve as question-answer systems, providing knowledge, code examples, and scenario development support in Earth science and related fields.</data>
  <data key="d7">AI assistance, knowledge support</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Climate Scenario Generation">
  <data key="d5">16.0</data>
  <data key="d6">LLMs are capable of generating climate scenarios to aid in environmental research and policy planning.&lt;SEP&gt;LLMs are capable of generating climate scenarios, aiding in environmental research and planning.</data>
  <data key="d7">model application, environmental prediction</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Parameter-Efficient Prompt Tuning">
  <data key="d5">7.0</data>
  <data key="d6">Parameter-efficient tuning enables effective adaptation of large models with minimal parameters, improving resource efficiency.</data>
  <data key="d7">model optimization, prompt tuning</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models" target="Universal Transformer">
  <data key="d5">8.0</data>
  <data key="d6">The Universal Transformer is a model that extends the Transformer architecture with recurrence, applied to code tasks.</data>
  <data key="d7">model architecture, recurrence</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Large Language Models" target="Performance Modeling">
  <data key="d5">18.0</data>
  <data key="d6">Large language models are used to predict execution times and performance metrics of HPC codes based on source code features.&lt;SEP&gt;Large language models are utilized to predict execution time and performance characteristics of HPC and scientific codes.</data>
  <data key="d7">predictive modeling, performance analysis</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Generation" target="Core Concepts">
  <data key="d5">8.0</data>
  <data key="d6">Automated generation of source code from specifications or natural language."|&gt;"task, AI</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Code Generation" target="Methodologies">
  <data key="d5">16.0</data>
  <data key="d6">Code generation involves translating intermediate code into optimized executable code, incorporating techniques like inlining and loop unrolling.&lt;SEP&gt;Code generation translates intermediate code into optimized executable code, incorporating techniques like inlining and loop unrolling.</data>
  <data key="d7">compiler technique, optimization</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Code Generation" target="Python">
  <data key="d5">9.0</data>
  <data key="d6">Adding the 'def' keyword in Python prompts significantly improves code quality, and libraries like numpy, cuPy, and pyCUDA are effectively supported.</data>
  <data key="d7">prompt specificity, library support</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Code Generation" target="Limitations of AI Tools">
  <data key="d5">9.0</data>
  <data key="d6">Current limitations of AI tools like Codex impact their ability to generate accurate and reliable HPC code, highlighting areas for improvement.</data>
  <data key="d7">technology constraints, development challenges</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Code Generation" target="Higher-Level Specifications">
  <data key="d5">7.0</data>
  <data key="d6">Higher-level specifications aim to abstractly define desired behaviors, challenging code generation algorithms to infer necessary constructs.</data>
  <data key="d7">abstraction, inference</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation" target="Security Standards">
  <data key="d5">12.0</data>
  <data key="d6">AI-generated code should adhere to established security standards to prevent insecure configurations and vulnerabilities.</data>
  <data key="d7">security compliance, best practices</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation" target="Applications/Implications">
  <data key="d5">18.0</data>
  <data key="d6">Automated code generation accelerates development workflows and supports code synthesis in HPC environments.&lt;SEP&gt;Automated code generation from models can accelerate development processes and support code synthesis in HPC environments.</data>
  <data key="d7">automation, development support</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Generation" target="Evaluation Metrics">
  <data key="d5">9.0</data>
  <data key="d6">The accuracy of code generation is assessed using specific metrics to determine correctness and quality.</data>
  <data key="d7">performance evaluation, correctness</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Generation" target="PolyCoder">
  <data key="d5">18.0</data>
  <data key="d6">PolyCoder is evaluated for code generation capabilities, showing high accuracy in HPC-specific code generation tasks.&lt;SEP&gt;PolyCoder is evaluated for its ability to generate correct and syntactically valid HPC code, showing high performance in these tasks.</data>
  <data key="d7">model capability, code accuracy&lt;SEP&gt;model performance, code accuracy</data>
  <data key="d8">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Generation" target="GPT-Neo">
  <data key="d5">16.0</data>
  <data key="d6">GPT-Neo's code generation performance improves with fine-tuning on HPC data, especially for HPC-specific functions like OpenMP and MPI.&lt;SEP&gt;GPT-Neo's performance in code generation improves with fine-tuning on HPC data, especially for HPC-specific functions.</data>
  <data key="d7">model adaptation, HPC code</data>
  <data key="d8">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Generation" target="GPT2">
  <data key="d5">14.0</data>
  <data key="d6">GPT-2's ability to generate HPC code is limited due to lack of source code in its pre-training dataset; slight improvements are observed after fine-tuning.&lt;SEP&gt;GPT-2's ability to generate correct HPC code is limited due to lack of source code in its pre-training dataset, but slight improvements are observed after fine-tuning.</data>
  <data key="d7">model limitation, HPC code</data>
  <data key="d8">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-specific models" target="Fine-tuning">
  <data key="d5">8.0</data>
  <data key="d6">HPC-specific models are created by fine-tuning general LLMs on high-quality HPC datasets to better generate parallel code.</data>
  <data key="d7">specialization, training</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-specific models" target="Applying LLMs to Parallel and HPC Code">
  <data key="d5">16.0</data>
  <data key="d6">Models like HPCCoder are trained on HPC codebases to generate HPC code, label pragmas, and predict performance, enhancing HPC software development.&lt;SEP&gt;Specialized models like HPCCoder are trained on HPC code to generate and analyze high-performance computing applications.</data>
  <data key="d7">domain-specific training, HPC applications</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Code" target="Parallel Programming Models">
  <data key="d5">14.0</data>
  <data key="d6">Parallel code is structured according to various parallel programming models such as MPI, OpenMP, CUDA, etc."|&gt;"model application, code structure</data>
  <data key="d7">7</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Code" target="Serial Code">
  <data key="d5">9.0</data>
  <data key="d6">Serial code serves as the initial implementation which is translated into parallel code to improve performance and scalability.</data>
  <data key="d7">code translation, parallelization</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Code" target="MPI">
  <data key="d5">8.0</data>
  <data key="d6">MPI is a target execution model for translating serial code to enable message passing in parallel systems.</data>
  <data key="d7">communication, parallel execution</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Code" target="OpenMP">
  <data key="d5">8.0</data>
  <data key="d6">OpenMP is used as a methodology for parallelizing serial code to improve execution speed on shared-memory architectures.</data>
  <data key="d7">parallelization, shared memory</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Code" target="Kokkos">
  <data key="d5">7.0</data>
  <data key="d6">Kokkos provides a performance-portable framework for writing parallel code that can target multiple hardware architectures.</data>
  <data key="d7">performance portability, hardware abstraction</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Code" target="CUDA">
  <data key="d5">8.0</data>
  <data key="d6">CUDA enables GPU acceleration for parallel code, often used to enhance performance of compute-intensive tasks.</data>
  <data key="d7">GPU acceleration, high-performance computing</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Fine-tuning" target="HPC-INSTRUCT">
  <data key="d5">10.0</data>
  <data key="d6">The HPC-INSTRUCT dataset is used to fine-tune code LLMs to improve their ability to generate HPC parallel code.</data>
  <data key="d7">training data, model improvement</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fine-tuning" target="Model Performance">
  <data key="d5">41.0</data>
  <data key="d6">Fine-tuning enhances models' ability to generate HPC-specific code, but excessive fine-tuning leads to catastrophic forgetting, reducing downstream task performance.&lt;SEP&gt;Fine-tuning models on HPC datasets enhances their ability to generate HPC-specific code but can lead to catastrophic forgetting if overdone.&lt;SEP&gt;Fine-tuning on HPC-INSTRUCT improves the performance of HPC-Coder-V2 in parallel code generation tasks.&lt;SEP&gt;The process of fine-tuning directly impacts the model's ability to generate high-quality parallel code.&lt;SEP&gt;The process of fine-tuning improves the model's ability to generate relevant and accurate parallel code based on synthetic data.</data>
  <data key="d7">model adaptation, task specialization&lt;SEP&gt;model adaptation, task-specific training&lt;SEP&gt;training process, model degradation&lt;SEP&gt;training, model improvement</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726&lt;SEP&gt;chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Fine-tuning" target="Synthetic Data">
  <data key="d5">16.0</data>
  <data key="d6">Synthetic data is used to fine-tune pre-trained code LLMs, improving their performance on HPC parallel code generation tasks.&lt;SEP&gt;Synthetic data is used to further train pre-trained code LLMs, improving their ability to generate accurate parallel code in HPC contexts.</data>
  <data key="d7">training data, model improvement&lt;SEP&gt;training process, model improvement</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fine-tuning" target="Model performance">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning models on the dataset improves their parallel code generation capabilities.</data>
  <data key="d7">training, performance</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fine-tuning" target="Large Language Models for Code">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning adapts pre-trained models to specific domains like code, enhancing their performance on code-related tasks.&lt;SEP&gt;Fine-tuning on code datasets improves model performance on specific code generation tasks and domain applications.</data>
  <data key="d7">domain adaptation, model specialization</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Fine-tuning" target="Methods">
  <data key="d5">10.0</data>
  <data key="d6">Fine-tuning modifies the model's internal parameters using domain-specific data, resulting in more profound and persistent domain adaptation.</data>
  <data key="d7">parameter adjustment, model behavior</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-tuning" target="In-context Learning">
  <data key="d5">14.0</data>
  <data key="d6">Fine-tuning aims to improve or preserve the in-context learning ability of LLMs during domain adaptation.</data>
  <data key="d7">learning capability, knowledge retention</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-tuning" target="Regularized Optimization">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning involves applying regularized optimization techniques to adapt pre-trained models effectively while preventing overfitting.&lt;SEP&gt;Fine-tuning involves applying regularized optimization techniques to adapt pre-trained models to specific tasks while controlling overfitting.</data>
  <data key="d7">8&lt;SEP&gt;training methodology, model adaptation</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-tuning" target="Model improvement">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning Codex on correctly implemented functions enhances its ability to generate accurate solutions, improving overall performance.</data>
  <data key="d7">training methodology, accuracy</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Fine-tuning" target="HPC-Coder">
  <data key="d5">14.0</data>
  <data key="d6">HPC-Coder is fine-tuned on a dataset of HPC and scientific codes to improve its task-specific capabilities.&lt;SEP&gt;HPC-Coder is fine-tuned on a new dataset of HPC and scientific codes to improve its ability to perform domain-specific tasks.</data>
  <data key="d7">domain adaptation, model training&lt;SEP&gt;domain adaptation, training</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Fine-tuning" target="Methodologies">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning adjusts a pre-trained language model on HPC source code to improve its relevance and performance for specialized tasks.&lt;SEP&gt;Fine-tuning adjusts a pre-trained model on specific HPC code data to improve its relevance and performance for specialized tasks.</data>
  <data key="d7">domain adaptation, training</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Fine-tuning" target="Model Size">
  <data key="d5">6.0</data>
  <data key="d6">Fine-tuning can lead to a reduction in model size by optimizing parameters and efficiency.</data>
  <data key="d7">optimization, model compression</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Fine-tuning" target="Model">
  <data key="d5">9.0</data>
  <data key="d6">Fine-tuning involves training models on specific datasets to improve their accuracy in tasks like pragma generation.</data>
  <data key="d7">model training, adaptation</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC datasets" target="StarCoder2">
  <data key="d5">7.0</data>
  <data key="d6">StarCoder2 models are trained on The Stack v2 dataset, which is used as a benchmark for general code generation performance.</data>
  <data key="d7">training data, performance comparison</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-INSTRUCT" target="Data Collection">
  <data key="d5">8.0</data>
  <data key="d6">HPC-INSTRUCT is created by mapping existing parallel code samples to high-quality instruct-answer pairs for training models.</data>
  <data key="d7">dataset creation, data quality</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-INSTRUCT" target="Synthetic Data">
  <data key="d5">18.0</data>
  <data key="d6">HPC-INSTRUCT is a synthetic dataset of parallel code instruction-response pairs created to enhance the training of HPC-capable code LLMs.&lt;SEP&gt;HPC-INSTRUCT is a synthetic dataset of parallel code samples created to fine-tune HPC code LLMs, enhancing their ability to generate parallel code.</data>
  <data key="d7">dataset creation, code training&lt;SEP&gt;dataset creation, training data</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ParEval" target="HPC-Coder-V2">
  <data key="d5">9.0</data>
  <data key="d6">HPC-Coder-V2 is evaluated against ParEval to assess its parallel code generation performance.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ParEval" target="Mixtral-8x7B">
  <data key="d5">16.0</data>
  <data key="d6">Mixtral-8x7B is evaluated using the ParEval benchmark to test its code generation capabilities across diverse problem types.</data>
  <data key="d7">benchmark testing, model assessment</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ParEval" target="Model Performance">
  <data key="d5">18.0</data>
  <data key="d6">ParEval is used to measure the correctness of generated code, providing a basis for comparing different models.</data>
  <data key="d7">performance evaluation, correctness</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ParEval" target="Code Correctness">
  <data key="d5">8.0</data>
  <data key="d6">ParEval tests the correctness of generated code across diverse problem types and execution models.</data>
  <data key="d7">validation, benchmarking</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ParEval" target="Results">
  <data key="d5">16.0</data>
  <data key="d6">ParEval provides quantitative results indicating the accuracy of different models across various problem types.&lt;SEP&gt;ParEval provides quantitative success metrics (pass@1) for models across different problem types, indicating their accuracy and reliability.</data>
  <data key="d7">performance metrics, correctness&lt;SEP&gt;performance metrics, evaluation</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ParEval" target="Content">
  <data key="d5">9.0</data>
  <data key="d6">ParEval is a benchmark designed to evaluate LLMs' ability to generate parallel code across various problem types and execution models, using standardized prompts and evaluation techniques.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="ParEval" target="content_keywords">
  <data key="d5">9.0</data>
  <data key="d6">ParEval is a benchmark designed to evaluate LLMs' ability to generate parallel code across various problem types and execution models, using standardized prompts and evaluation techniques.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="ParEval" target="Core Concepts">
  <data key="d5">10.0</data>
  <data key="d6">ParEval is the central benchmark used to evaluate LLMs' capacity to generate parallel code and measure performance metrics.</data>
  <data key="d7">benchmarking, parallel code generation</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="StarCoder2" target="Theories/Models">
  <data key="d5">16.0</data>
  <data key="d6">StarCoder2 is a foundational model used as a baseline for code generation tasks.&lt;SEP&gt;StarCoder2 serves as a foundational model trained on large code datasets, providing baseline performance for code tasks.</data>
  <data key="d7">model baseline, code data</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="Model Performance">
  <data key="d5">10.0</data>
  <data key="d6">HPC-Coder-V2's performance indicates it is the best open-source model for parallel code generation, nearing GPT-4.</data>
  <data key="d7">results, model capability</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="Model Evaluation">
  <data key="d5">9.0</data>
  <data key="d6">HPC-Coder-V2 is evaluated against ParEval to measure its effectiveness in parallel code generation.</data>
  <data key="d7">evaluation, performance</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="HPC-I NSTRUCT">
  <data key="d5">18.0</data>
  <data key="d6">The synthetic dataset HPC-I NSTRUCT is used to fine-tune HPC-Coder-V2, aiming to improve its ability to generate parallel code.&lt;SEP&gt;The synthetic dataset HPC-I NSTRUCT is used to fine-tune the code LLM HPC-Coder-V2 for improved parallel code generation.</data>
  <data key="d7">training data, model fine-tuning&lt;SEP&gt;training data, model training</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="ParEval benchmark">
  <data key="d5">9.0</data>
  <data key="d6">HPC-Coder-V2 is evaluated using the ParEval benchmark suite to measure its code generation performance across various problem types and execution models.</data>
  <data key="d7">model evaluation, benchmarking</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="Comparison with Other Models">
  <data key="d5">9.0</data>
  <data key="d6">HPC-Coder-V2 models outperform some existing models in parallel code generation, showing their competitiveness in the field.</data>
  <data key="d7">model comparison, performance advantage</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="parEval benchmark">
  <data key="d5">10.0</data>
  <data key="d6">HPC-Coder-V2 is evaluated using the ParEval benchmark to measure its performance across different problem types and execution models.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="fine-tuning">
  <data key="d5">10.0</data>
  <data key="d6">HPC-Coder-V2 is a result of fine-tuning a base model using HPC-specific data, aiming to improve code generation for HPC tasks."|</data>
  <data key="d7">10</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2" target="model performance metrics">
  <data key="d5">8.0</data>
  <data key="d6">The performance metrics evaluate how well HPC-Coder-V2 generates accurate and efficient parallel code."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Model Evaluation">
  <data key="d5">8.0</data>
  <data key="d6">HPC-Coder-V2's performance approaching GPT-4 levels demonstrates the success of the fine-tuning approach.</data>
  <data key="d7">evaluation, results</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Data Representation">
  <data key="d5">16.0</data>
  <data key="d6">Effective data representation enhances the model's ability to learn and generate parallel code accurately.&lt;SEP&gt;Effective data representation positively influences the model's ability to learn and generate accurate parallel code.</data>
  <data key="d7">data quality, learning efficiency</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Training Parameters">
  <data key="d5">15.0</data>
  <data key="d6">Optimized training parameters improve the fine-tuning process, leading to better model performance in parallel code generation.&lt;SEP&gt;Optimizing training parameters leads to better fine-tuning outcomes and higher-quality code generation.</data>
  <data key="d7">training optimization, model accuracy</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Synthetic Dataset">
  <data key="d5">18.0</data>
  <data key="d6">The quality and size of the synthetic dataset directly impact the effectiveness of the fine-tuning process and the resulting model's performance.&lt;SEP&gt;The quality and size of the synthetic dataset influence the effectiveness of fine-tuning and the resulting model's performance.</data>
  <data key="d7">training data quality, model accuracy</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Research Questions">
  <data key="d5">12.0</data>
  <data key="d6">The research questions are designed to explore how different factors affect the performance of code LLMs in parallel code generation.&lt;SEP&gt;The research questions guide the investigation into how different factors affect the performance of code LLMs in parallel code generation.</data>
  <data key="d7">study focus, performance factors</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Model Size">
  <data key="d5">30.0</data>
  <data key="d6">Increasing model size generally enhances the capacity and potential performance of the model, but with diminishing returns.&lt;SEP&gt;Larger models generally have a greater capacity to learn from synthetic data and improve code generation quality.&lt;SEP&gt;Larger models generally have higher capacity, which can lead to improved performance, but with diminishing returns and increased computational costs.&lt;SEP&gt;Larger models tend to have greater capacity to learn from synthetic data, enhancing their parallel code generation capabilities.</data>
  <data key="d7">capacity, learning ability&lt;SEP&gt;capacity, scalability</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa&lt;SEP&gt;chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Instruction Masking">
  <data key="d5">14.0</data>
  <data key="d6">Applying instruction masking during fine-tuning helps prevent the model from learning undesirable patterns, thus improving response quality.&lt;SEP&gt;Using instruction masking during fine-tuning helps prevent the model from learning undesirable patterns, improving response quality.</data>
  <data key="d7">training technique, response accuracy</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Impact of Data Quality">
  <data key="d5">9.0</data>
  <data key="d6">High-quality synthetic data improves the model's ability to generate accurate parallel code, while low-quality data hampers performance.</data>
  <data key="d7">data quality, model effectiveness</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Impact of Fine-tuning Parameters">
  <data key="d5">8.0</data>
  <data key="d6">Proper selection of fine-tuning parameters enhances the model's ability to learn and generate high-quality code.</data>
  <data key="d7">training configuration, model accuracy</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Impact of Model Size">
  <data key="d5">8.0</data>
  <data key="d6">Increasing model size generally improves capacity to learn from synthetic data, leading to better code generation.</data>
  <data key="d7">model capacity, performance</data>
  <data key="d8">chunk-ab4503fb357b566fec504fb7c7f77bfa</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Parallel Code Data">
  <data key="d5">18.0</data>
  <data key="d6">The amount and quality of parallel code data directly impact the model's ability to generate accurate and efficient code.&lt;SEP&gt;The amount and quality of parallel code data influence the model's ability to generate accurate code.</data>
  <data key="d7">data impact, code generation capability&lt;SEP&gt;data impact, model capability</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="MPI Code Samples">
  <data key="d5">16.0</data>
  <data key="d6">MPI code samples are used as a benchmark to evaluate the model's proficiency in generating parallel MPI code.&lt;SEP&gt;MPI code samples are used to evaluate how well models generate parallel programming code, especially for MPI.</data>
  <data key="d7">code generation, evaluation&lt;SEP&gt;evaluation, code quality</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Synthetic Data">
  <data key="d5">18.0</data>
  <data key="d6">The quality of synthetic data impacts the effectiveness of fine-tuned models in code generation tasks.&lt;SEP&gt;The quality of synthetic data influences the effectiveness of fine-tuned models in code generation tasks, especially for MPI code.</data>
  <data key="d7">data quality, model accuracy</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Data Quantity">
  <data key="d5">16.0</data>
  <data key="d6">Increasing the amount of training data can improve model performance, but gains may plateau beyond a certain point.&lt;SEP&gt;More data can improve model performance up to a point, after which gains may plateau.</data>
  <data key="d7">data volume, performance plateau</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Data Quality">
  <data key="d5">18.0</data>
  <data key="d6">Higher data quality is hypothesized to enhance model performance, especially when data quantity is limited.&lt;SEP&gt;Higher quality data is hypothesized to lead to better model performance, especially when data quantity is limited.</data>
  <data key="d7">data quality, model accuracy</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="pass@k">
  <data key="d5">20.0</data>
  <data key="d6">pass@k scores are used to quantify the likelihood of correct code generation within k attempts for each model.</data>
  <data key="d7">accuracy metrics, probabilistic evaluation</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Performance Metrics">
  <data key="d5">8.0</data>
  <data key="d6">Metrics such as pass@k evaluate the effectiveness and accuracy of models in code generation tasks.</data>
  <data key="d7">evaluation, accuracy</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Trade-offs">
  <data key="d5">7.0</data>
  <data key="d6">Higher performance models may require more computational resources, leading to trade-offs in practicality."|&gt;"resource trade-offs, efficiency</data>
  <data key="d7">7</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance" target="Retrieval Ablations">
  <data key="d5">16.0</data>
  <data key="d6">Ablation studies demonstrate that learned retrieval mechanisms improve results over fixed retrieval methods like BM25.</data>
  <data key="d7">retrieval mechanism, performance</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Model Performance" target="Training Data">
  <data key="d5">7.0</data>
  <data key="d6">The training datasets influence the models' capabilities, accuracy, and biases in code generation.</data>
  <data key="d7">training data, model quality</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Model Performance" target="Results">
  <data key="d5">8.0</data>
  <data key="d6">Quantitative scores such as pass@k, speedup n@k, and efficiency n@k quantify how well each model generates correct and efficient code.</data>
  <data key="d7">performance metrics, evaluation outcomes</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Model Performance" target="Evaluation Metrics">
  <data key="d5">24.0</data>
  <data key="d6">Evaluation metrics are used to quantify how well a model performs in terms of accuracy, interpretability, and domain relevance.&lt;SEP&gt;Metrics such as pass@k and filtered pass@k are used to evaluate and compare models' code generation success.&lt;SEP&gt;Metrics like pass@k and compile success rate are used to evaluate the accuracy and syntactic validity of generated code.</data>
  <data key="d7">assessment, code quality&lt;SEP&gt;performance assessment, measurement&lt;SEP&gt;performance measurement, evaluation</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5&lt;SEP&gt;chunk-b15d5bb768f451028654d71370cc6879&lt;SEP&gt;chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf&lt;SEP&gt;Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="Codex-12B">
  <data key="d5">7.0</data>
  <data key="d6">Codex-12B's performance is evaluated and compared with other models like GPT-Neo and GPT-J.</data>
  <data key="d7">model comparison</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="GPT-Neo">
  <data key="d5">6.0</data>
  <data key="d6">GPT-Neo's performance metrics indicate its capabilities in code generation relative to other models.</data>
  <data key="d7">benchmarking</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="GPT-J">
  <data key="d5">7.0</data>
  <data key="d6">GPT-J achieves notable pass rates, demonstrating its coding competence in evaluations.</data>
  <data key="d7">performance evaluation</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="APPS Dataset">
  <data key="d5">8.0</data>
  <data key="d6">The APPS dataset provides a benchmark for assessing coding competence of language models.</data>
  <data key="d7">benchmarking, dataset</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="Sample Diversity">
  <data key="d5">6.0</data>
  <data key="d6">Higher sample diversity at increased temperatures can improve the likelihood of generating correct solutions.</data>
  <data key="d7">diversity, solution quality</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="Training Problems Dataset">
  <data key="d5">8.0</data>
  <data key="d6">The curated dataset of 10,000 problems serves as training data to improve model accuracy and robustness in code generation.</data>
  <data key="d7">dataset, performance</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Performance" target="Catastrophic Forgetting">
  <data key="d5">16.0</data>
  <data key="d6">Excessive fine-tuning causes models to forget previously learned information, decreasing downstream evaluation performance despite improved perplexity.&lt;SEP&gt;Over-fine-tuning causes models to forget prior knowledge, decreasing their effectiveness in downstream evaluation despite improvements in perplexity.</data>
  <data key="d7">learning phenomenon, model performance</data>
  <data key="d8">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Performance" target="Training Samples">
  <data key="d5">7.0</data>
  <data key="d6">The number of training samples (around 45,000) influences when models start to decline in evaluation performance due to overfitting or forgetting.</data>
  <data key="d7">training data, model degradation</data>
  <data key="d8">chunk-26223e383a1876273c0d63ed52102a6e</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC" target="Kernel Generation">
  <data key="d5">16.0</data>
  <data key="d6">The process of creating optimized numerical kernels is central to high-performance computing applications.</data>
  <data key="d7">computational efficiency, numerical methods</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Synthetic Dataset" target="Data Collection">
  <data key="d5">10.0</data>
  <data key="d6">The synthetic dataset HPC-INSTRUCT is used to enhance model training by providing high-quality parallel code instruction data.</data>
  <data key="d7">training data, data quality</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Evaluation" target="VerilogEval">
  <data key="d5">8.0</data>
  <data key="d6">VerilogEval provides a benchmark to evaluate the performance of language models in generating Verilog code."|&gt;"evaluation, hardware description language</data>
  <data key="d7">8</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Model Evaluation" target="Performance Metrics">
  <data key="d5">8.0</data>
  <data key="d6">Metrics like pass@k and BLEU scores are used to quantify the effectiveness of language models on coding tasks.</data>
  <data key="d7">performance measurement</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Evaluation" target="Unit Tests">
  <data key="d5">16.0</data>
  <data key="d6">Unit tests are used to automatically evaluate the correctness of generated code in the HumanEval dataset.</data>
  <data key="d7">evaluation method, correctness assessment</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Evaluation" target="Manual Grading">
  <data key="d5">14.0</data>
  <data key="d6">Manual grading assesses the correctness of generated docstrings when automatic metrics are insufficient.</data>
  <data key="d7">evaluation method, qualitative assessment</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Evaluation" target="pass@k and manual grading">
  <data key="d5">8.0</data>
  <data key="d6">Model evaluation includes measuring pass@k success rates and manual assessment of docstring correctness to determine overall quality.</data>
  <data key="d7">performance metrics, qualitative evaluation</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Data Quality" target="Challenges in HPC Code Generation">
  <data key="d5">9.0</data>
  <data key="d6">The intrinsic difficulty of generating correct parallel code is exacerbated by limited high-quality data and the complexity of HPC tasks.</data>
  <data key="d7">difficulty, data limitations</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Data Quality" target="Model Performance Metrics">
  <data key="d5">9.0</data>
  <data key="d6">High data quality improves model accuracy and effectiveness in code generation tasks."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Data Collection" target="Challenges in HPC Code Generation">
  <data key="d5">7.0</data>
  <data key="d6">Collecting high-quality parallel code data is difficult due to underrepresentation and data scarcity in existing datasets.</data>
  <data key="d7">data challenges, domain-specific data</data>
  <data key="d8">chunk-99b6ab3dd30e07713288e985bc1e0726</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Data Collection" target="Methods">
  <data key="d5">14.0</data>
  <data key="d6">Data collection provides the training data necessary for fine-tuning Codex, involving filtering and compiling code repositories.</data>
  <data key="d7">dataset creation, data filtering</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Limitations" target="Bias and Misinformation">
  <data key="d5">16.0</data>
  <data key="d6">Biases and inaccuracies in external knowledge sources can negatively affect model outputs and trustworthiness.&lt;SEP&gt;Biases and inaccuracies in external knowledge sources can negatively impact model outputs and trustworthiness.</data>
  <data key="d7">limitations, reliability</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Limitations" target="Results">
  <data key="d5">7.0</data>
  <data key="d6">Limitations affect the interpretation of Results, indicating potential biases or constraints.</data>
  <data key="d7">study constraints, interpretative limits</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Limitations" target="Issues of PPL prototype">
  <data key="d5">7.0</data>
  <data key="d6">The current problems identified within the prototype, including possible solutions and plans for a production-ready version."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Limitations" target="Performance variability">
  <data key="d5">14.0</data>
  <data key="d6">Some kernels (e.g., Monte Carlo, neural network) show instability or performance issues, indicating areas for further optimization and refinement.&lt;SEP&gt;Some kernels show instability or performance issues, indicating areas for further optimization.</data>
  <data key="d7">performance challenges, optimization limits</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Limitations" target="AI Tools">
  <data key="d5">9.0</data>
  <data key="d6">Current limitations of AI tools like Codex impact their practical use in HPC software development, necessitating further research and improvement.</data>
  <data key="d7">technology constraints, development challenges</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Limitations" target="Knowledge Update Challenges">
  <data key="d5">7.0</data>
  <data key="d6">Updating knowledge in LLMs is challenging due to their architecture and computational resource demands.</data>
  <data key="d7">technical limitation, resource cost</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Limitations" target="Risks of Generic LLMs">
  <data key="d5">8.0</data>
  <data key="d6">Applying generic models to sensitive domains risks inaccuracies, lack of originality, and ethical issues.</data>
  <data key="d7">risk assessment, ethical concerns</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Limitations" target="Black-Box Methods">
  <data key="d5">12.0</data>
  <data key="d6">Black-box methods lack transparency, which limits their interpretability and fine-tuning capabilities in domain-specific contexts.&lt;SEP&gt;Black-box methods lack transparency, which limits understanding and fine-tuning in domain-specific applications.</data>
  <data key="d7">interpretability, model control</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Limitations" target="Codex">
  <data key="d5">12.0</data>
  <data key="d6">The model exhibits specific limitations, including difficulty with complex chains and variable binding in code generation.&lt;SEP&gt;The model's limitations include difficulty with complex, long chains of operations and variable binding in docstrings.</data>
  <data key="d7">model weaknesses, technical challenge&lt;SEP&gt;weaknesses, technical challenges</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Limitations" target="Model limitations">
  <data key="d5">7.0</data>
  <data key="d6">The models are limited by training data, computational resources, and the inherent complexity of programming tasks, affecting their overall accuracy and usefulness.</data>
  <data key="d7">performance constraints, challenges</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Limitations" target="Tools">
  <data key="d5">18.0</data>
  <data key="d6">Limitations</data>
  <data key="d7">Limitations such as tokenizer inefficiency and resource demands constrain the scope and applicability of the research findings.</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Limitations" target="Code generation models">
  <data key="d5">19.0</data>
  <data key="d6">Limitations such as inefficiency, difficulty with long docstrings, syntactic errors, and poor system-level synthesis capabilities are highlighted.&lt;SEP&gt;The limitations of Codex include inefficiency, difficulty with long docstrings, syntactic errors, and poor system-level synthesis.</data>
  <data key="d7">model limitations, performance issues</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="HPC-I NSTRUCT" target="dataset">
  <data key="d5">8.0</data>
  <data key="d6">HPC-I NSTRUCT serves as a training and evaluation dataset for models focused on high-performance computing code generation and understanding.</data>
  <data key="d7">training data, dataset purpose</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-I NSTRUCT" target="Model fine-tuning">
  <data key="d5">8.0</data>
  <data key="d6">The dataset is used to fine-tune the HPC code LLMs, improving their parallel code generation abilities.</data>
  <data key="d7">dataset, training</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Instruction Masking" target="Model Training">
  <data key="d5">12.0</data>
  <data key="d6">Instruction masking affects the training process by potentially reducing noise and undesirable patterns in learned responses.&lt;SEP&gt;Instruction masking affects training by potentially reducing noise and focusing the model on learning responses, which impacts performance.</data>
  <data key="d7">training technique, noise reduction</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="Performance">
  <data key="d5">12.0</data>
  <data key="d6">Larger models tend to have greater capacity to learn complex parallel code tasks, impacting their performance.&lt;SEP&gt;Larger models tend to have greater capacity to learn complex patterns in parallel code, leading to better performance on generation tasks.</data>
  <data key="d7">model capacity, learning ability</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="HPC-I NSTRUCT dataset">
  <data key="d5">21.0</data>
  <data key="d6">Different model sizes (1.3B, 6.7B, 16B) are fine-tuned on the HPC-I NSTRUCT dataset to compare their performance.&lt;SEP&gt;Different model sizes are fine-tuned on the HPC-I NSTRUCT dataset to compare their performance across sizes.</data>
  <data key="d7">comparison, resource utilization&lt;SEP&gt;model comparison, resource efficiency</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="Trade-offs">
  <data key="d5">14.0</data>
  <data key="d6">Larger models tend to perform better but require more resources, presenting a trade-off between performance and practicality.</data>
  <data key="d7">efficiency, resource allocation</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="Performance Metrics">
  <data key="d5">7.0</data>
  <data key="d6">Larger models tend to perform better across most problem types, but may perform worse on specific problems such as geometric ones, suggesting size-performance trade-offs.</data>
  <data key="d7">model scaling, problem structure</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="Model Performance Metrics">
  <data key="d5">7.0</data>
  <data key="d6">Larger models generally achieve higher performance metrics but require more resources."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="Model Resource Requirements">
  <data key="d5">7.0</data>
  <data key="d6">Larger models demand more memory and computational resources during training and inference."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Size" target="Prompt Initialization">
  <data key="d5">6.0</data>
  <data key="d6">Larger models tend to be more robust to different initialization strategies, influencing prompt tuning outcomes."|</data>
  <data key="d7">correlation</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Size" target="Codex">
  <data key="d5">7.0</data>
  <data key="d6">Larger Codex models (e.g., 12B) tend to perform better in code generation tasks, reflected in higher pass@k scores.</data>
  <data key="d7">model size, performance</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Size" target="Performance Gains">
  <data key="d5">7.0</data>
  <data key="d6">Larger models with more parameters tend to achieve higher pass@k scores, indicating better code generation capabilities.</data>
  <data key="d7">model size, performance</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Size" target="Misalignment">
  <data key="d5">7.0</data>
  <data key="d6">Larger models tend to have higher risks of misalignment due to increased complexity and capabilities.</data>
  <data key="d7">model scaling, misalignment risk</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Base Model" target="Model Fine-tuning">
  <data key="d5">14.0</data>
  <data key="d6">Fine-tuning is performed starting from a base model, which influences subsequent performance outcomes.&lt;SEP&gt;Fine-tuning starts from a pre-trained base model, which influences subsequent training outcomes and performance.</data>
  <data key="d7">initialization, transfer learning</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Performance Evaluation">
  <data key="d5">8.0</data>
  <data key="d6">Metrics are used to quantify the success of code generation in terms of correctness and performance."|&gt;"assessment, measurement</data>
  <data key="d7">8</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="StarCoderBase">
  <data key="d5">18.0</data>
  <data key="d6">Metrics like pass@k, speedup n@k, and efficiency n@k are used to assess the performance of StarCoderBase in code generation tasks.</data>
  <data key="d7">performance assessment, benchmarking</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Phind-CodeLlama-V2">
  <data key="d5">14.0</data>
  <data key="d6">Metrics such as pass@k are applied to evaluate Phind-CodeLlama-V2's code generation accuracy and compare it with other models.</data>
  <data key="d7">model evaluation, comparison</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="GPT-3.5 and GPT-4">
  <data key="d5">12.0</data>
  <data key="d6">These models are assessed using pass@k and other metrics to determine their effectiveness in code generation, despite limited transparency about training data.</data>
  <data key="d7">performance evaluation, model comparison</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Study Designs">
  <data key="d5">16.0</data>
  <data key="d6">Metrics are employed within study designs to compare the correctness and efficiency of different language models on code prompts.</data>
  <data key="d7">research methodology, performance comparison</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Taxonomy">
  <data key="d5">9.0</data>
  <data key="d6">The proposed taxonomy is intended to provide a structured way to evaluate the accuracy and trustworthiness of AI-generated HPC code, but requires expansion for community-wide adoption.</data>
  <data key="d7">assessment framework, metrics</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Model Safety">
  <data key="d5">7.0</data>
  <data key="d6">Evaluation metrics are used to quantify how well models perform in terms of safety, bias, and alignment.</data>
  <data key="d7">assessment, safety metrics</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="OpenMP Pragma Labeling">
  <data key="d5">10.0</data>
  <data key="d6">The labeling task is evaluated based on accuracy and relevance of the identified pragmas.</data>
  <data key="d7">labeling accuracy, relevance</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Relative Performance Prediction">
  <data key="d5">9.0</data>
  <data key="d6">The prediction models are assessed on their ability to accurately estimate performance differences.</data>
  <data key="d7">prediction accuracy, performance metrics</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Evaluation Metrics" target="Generated Code">
  <data key="d5">28.0</data>
  <data key="d6">Generated code samples are assessed using pass@k and correctness tests to determine their validity.&lt;SEP&gt;Generated code samples are assessed using pass@k scores and correctness tests to determine functional accuracy.&lt;SEP&gt;Metrics like pass@k and success rate after compilation evaluate the quality and correctness of generated code.</data>
  <data key="d7">9&lt;SEP&gt;performance metrics, correctness</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Synthetic Data" target="HPC-INSTRUCT Dataset">
  <data key="d5">9.0</data>
  <data key="d6">Synthetic data contributed to the HPC-INSTRUCT dataset, which supports fine-tuning models for HPC tasks."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Data Representation and Quality" target="Performance">
  <data key="d5">20.0</data>
  <data key="d6">Better data representation and higher quality improve the ability of code LLMs to generate accurate parallel code.&lt;SEP&gt;Higher quality and well-structured data improve the model's ability to generate accurate and relevant parallel code.</data>
  <data key="d7">training effectiveness, model accuracy&lt;SEP&gt;training effectiveness, output accuracy</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Prompt Construction" target="Generation Quality">
  <data key="d5">16.0</data>
  <data key="d6">Careful design of prompts influences the diversity, relevance, and correctness of generated code outputs.&lt;SEP&gt;Careful prompt design influences the diversity and correctness of generated code outputs.</data>
  <data key="d7">prompt engineering, output quality</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Ablation Studies" target="Impact of Data and Model">
  <data key="d5">18.0</data>
  <data key="d6">Ablation studies analyze how changes in data, model size, and prompts affect code generation capabilities.&lt;SEP&gt;Ablation studies systematically assess how variations in data, model size, and prompts affect code generation capabilities.</data>
  <data key="d7">experimental analysis, performance impact&lt;SEP&gt;study methodology, model performance</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Ablation Studies" target="Model Fine-tuning">
  <data key="d5">16.0</data>
  <data key="d6">Ablation studies involve fine-tuning models with different configurations to analyze their individual effects on performance.&lt;SEP&gt;Ablation studies systematically vary model axes and data parameters to analyze their effects on performance.</data>
  <data key="d7">study methodology, experimental analysis</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ParEval Benchmark" target="Models">
  <data key="d5">16.0</data>
  <data key="d6">Models are evaluated against the ParEval benchmark to assess their effectiveness in parallel code generation.&lt;SEP&gt;Models are evaluated against the ParEval benchmark to quantify their effectiveness in parallel code generation.</data>
  <data key="d7">performance assessment, benchmarking</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance Evaluation" target="Model Generalization">
  <data key="d5">7.0</data>
  <data key="d6">Models with better generalization perform well on benchmarks like HumanEval, indicating robust capabilities."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance Evaluation" target="Benchmark ParEval">
  <data key="d5">16.0</data>
  <data key="d6">The benchmark is used to evaluate the performance of different language models on 420 tasks."|&gt;"performance measurement, model comparison&lt;SEP&gt;The benchmark is used to systematically evaluate how well different language models perform on 420 tasks."|&gt;"performance measurement, model comparison</data>
  <data key="d7">8</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Performance Evaluation" target="State-of-the-art Language Models">
  <data key="d5">18.0</data>
  <data key="d6">The models are assessed for their ability to generate correct, efficient, and complex parallel code."|&gt;"model capability, effectiveness&lt;SEP&gt;The models are evaluated for their ability to generate correct and efficient parallel code."|&gt;"model capability, effectiveness</data>
  <data key="d7">9</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Performance Evaluation" target="Code Correctness">
  <data key="d5">7.0</data>
  <data key="d6">Correctness metrics are used to determine whether the generated code functions as intended."|&gt;"accuracy, validation</data>
  <data key="d7">7</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Performance Evaluation" target="Code Performance">
  <data key="d5">7.0</data>
  <data key="d6">Performance metrics evaluate the efficiency and scalability of generated parallel code."|&gt;"efficiency, scalability</data>
  <data key="d7">7</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Performance Evaluation" target="Models">
  <data key="d5">8.0</data>
  <data key="d6">Different models are compared based on their ability to generate correct and efficient parallel code."|&gt;"comparison, effectiveness</data>
  <data key="d7">8</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Performance Evaluation" target="Reproducible Methodology">
  <data key="d5">7.0</data>
  <data key="d6">The methodology ensures that evaluation procedures can be replicated and verified by others."|&gt;"reproducibility, transparency</data>
  <data key="d7">7</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Seed Snippets" target="Diversity in Data">
  <data key="d5">14.0</data>
  <data key="d6">Seed snippets from open-source HPC codebases are used to generate diverse synthetic code samples, increasing data variability.&lt;SEP&gt;Seed snippets from open-source HPC repositories are used to generate diverse synthetic code samples, increasing data variability and robustness.</data>
  <data key="d7">data diversity, sample generation</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Study of Data and Model Impact" target="Implications">
  <data key="d5">14.0</data>
  <data key="d6">Findings inform best practices for fine-tuning HPC code LLMs, guiding future research and deployment.&lt;SEP&gt;Findings inform best practices for fine-tuning HPC code LLMs, guiding future research, and deployment strategies.</data>
  <data key="d7">application, best practices</data>
  <data key="d8">chunk-e33bd393ed70103fd66f1645d1888b19</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Pre-trained Model" target="fine-tuning">
  <data key="d5">8.0</data>
  <data key="d6">Pre-trained models are further refined through fine-tuning on specific datasets like HPC-I NSTRUCT to improve task-specific performance.</data>
  <data key="d7">initial training, adaptation</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="fine-tuning" target="AxoNN">
  <data key="d5">16.0</data>
  <data key="d6">AxoNN framework facilitates parallelized training across multiple GPUs, enabling efficient fine-tuning of large models.&lt;SEP&gt;AxoNN framework facilitates the fine-tuning of large models across multiple GPUs, enabling efficient training on large datasets.</data>
  <data key="d7">parallelization, training efficiency&lt;SEP&gt;training infrastructure, efficiency</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="fine-tuning" target="Adapters">
  <data key="d5">8.0</data>
  <data key="d6">Adapters are inserted into pre-trained models to facilitate task-specific fine-tuning without altering the entire model."|&lt;"method</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="fine-tuning" target="adapters">
  <data key="d5">8.0</data>
  <data key="d6">Adapters are used during fine-tuning to adapt pre-trained models to specific tasks or domains efficiently."|&lt;"relationship</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="fine-tuning" target="model behavior">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning on curated datasets improves the model's ability to generate bug-free and helpful code outputs."|</data>
  <data key="d7">training refinement, behavior adjustment</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="fine-tuning" target="models">
  <data key="d5">20.0</data>
  <data key="d6">Models are fine-tuned on the dataset to adapt them for code and natural language tasks.</data>
  <data key="d7">model adaptation, training</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="fine-tuning" target="hyperparameters">
  <data key="d5">22.0</data>
  <data key="d6">Hyperparameters like learning rate and optimizer settings are set to optimize model training and performance.&lt;SEP&gt;Hyperparameters like learning rate and optimizer settings are set to optimize model training.</data>
  <data key="d7">optimization, training control</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="fine-tuning" target="DeepSpeed">
  <data key="d5">24.0</data>
  <data key="d6">DeepSpeed is used as the backend framework to facilitate efficient training of large models, enabling distributed training and memory optimization.&lt;SEP&gt;DeepSpeed is used as the backend framework to facilitate efficient training of large models.</data>
  <data key="d7">distributed training, memory efficiency&lt;SEP&gt;distributed training, memory optimization</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="DeepSeek-Coder" target="code modeling">
  <data key="d5">9.0</data>
  <data key="d6">DeepSeek-Coder is a model architecture designed specifically for code modeling tasks, outperforming other models on benchmarks.</data>
  <data key="d7">specialization, benchmarking</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="DeepSeek-Coder" target="model">
  <data key="d5">9.0</data>
  <data key="d6">DeepSeek-Coder is a specialized model architecture designed for code modeling, outperforming other models on benchmarks.</data>
  <data key="d7">model architecture, performance</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="synthetic HPC code data" target="training data">
  <data key="d5">16.0</data>
  <data key="d6">Synthetic HPC code data is used to fine-tune models like DeepSeek-Coder, enhancing their ability to generate HPC-related code.&lt;SEP&gt;Synthetic HPC code data is used to train or fine-tune models like DeepSeek-Coder, enhancing their ability to generate HPC-specific code.</data>
  <data key="d7">training data, data augmentation&lt;SEP&gt;training, data augmentation</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="hyperparameters" target="model performance">
  <data key="d5">7.0</data>
  <data key="d6">Adjusting hyperparameters like batch size and sequence length directly impacts the training efficiency and the quality of the resulting models.</data>
  <data key="d7">optimization, training settings</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="hyperparameters" target="training process">
  <data key="d5">7.0</data>
  <data key="d6">Adjustments to hyperparameters like batch size and sequence length influence training speed and model quality.</data>
  <data key="d7">optimization, training setup</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ablation studies" target="model components">
  <data key="d5">16.0</data>
  <data key="d6">Ablation studies help determine the importance of different model components or training choices by systematically removing or altering them.&lt;SEP&gt;Ablation studies systematically evaluate the importance of different components or parameters in the training process.</data>
  <data key="d7">model analysis, methodology</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="model architecture" target="performance">
  <data key="d5">7.0</data>
  <data key="d6">The choice of model architecture impacts the scalability, efficiency, and effectiveness of code modeling performance.</data>
  <data key="d7">design, performance</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="prompt formatting" target="training methodology">
  <data key="d5">7.0</data>
  <data key="d6">Proper prompt formatting is essential for guiding the model during training and improving output quality.</data>
  <data key="d7">training methodology, input design</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="performance evaluation" target="results">
  <data key="d5">9.0</data>
  <data key="d6">Evaluation metrics and benchmarks measure the effectiveness of fine-tuned models in generating accurate code.</data>
  <data key="d7">performance assessment, benchmarks</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="performance evaluation" target="small language models (e.g., llama2-13b-chat, T5-Large)">
  <data key="d5">16.0</data>
  <data key="d6">DSPy demonstrates that even small language models can achieve high performance through optimized modular pipelines.&lt;SEP&gt;DSPy demonstrates that even smaller models can achieve high performance when utilizing optimized modular pipelines.</data>
  <data key="d7">efficiency, resource utilization</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="performance evaluation" target="model comparison">
  <data key="d5">16.0</data>
  <data key="d6">Performance evaluation compares different models' pass@1 scores and runtime to determine which model generates the best code.&lt;SEP&gt;Performance evaluation compares different models' pass@1 scores and runtime to determine which model performs best at code generation.</data>
  <data key="d7">benchmarking, effectiveness&lt;SEP&gt;model effectiveness, benchmarking</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="training hyperparameters" target="model performance">
  <data key="d5">7.0</data>
  <data key="d6">Tuning hyperparameters like batch size and sequence length directly affects training efficiency and model outcomes.</data>
  <data key="d7">hyperparameter tuning, training</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="training hyperparameters" target="model">
  <data key="d5">18.0</data>
  <data key="d6">Hyperparameters are tuned to optimize training efficiency and model performance.</data>
  <data key="d7">training optimization, hyperparameter tuning</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="generation" target="model">
  <data key="d5">9.0</data>
  <data key="d6">Generation is a core concept produced by models, enabling the creation of new code or text based on learned patterns.</data>
  <data key="d7">core concept, AI output</data>
  <data key="d8">chunk-f3db4d8ebe5bafa5d9d7ae540d506e1f</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="model" target="perplexity">
  <data key="d5">13.0</data>
  <data key="d6">Perplexity is used to evaluate the trained model's predictive performance during training and validation.</data>
  <data key="d7">model evaluation, performance metric</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="model" target="training dataset">
  <data key="d5">15.0</data>
  <data key="d6">The training dataset provides the data used to fine-tune the models, including code and natural language samples.</data>
  <data key="d7">training data, dataset source</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="model" target="validation dataset">
  <data key="d5">16.0</data>
  <data key="d6">The validation dataset is used to evaluate model performance during training, guiding hyperparameter tuning and preventing overfitting.</data>
  <data key="d7">evaluation, hyperparameter tuning</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Domain-specific Data">
  <data key="d5">9.0</data>
  <data key="d6">Fine-tuning updates model parameters with domain-specific data to improve task performance.</data>
  <data key="d7">training process, domain adaptation</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="White Box">
  <data key="d5">16.0</data>
  <data key="d6">White box scenarios enable full access, allowing detailed fine-tuning of internal parameters.&lt;SEP&gt;White box scenarios involve full access, enabling comprehensive fine-tuning of the model.</data>
  <data key="d7">full access, internal modification</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Knowledge Update">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning updates internal model parameters with domain-specific data, effectively updating its internal knowledge.</data>
  <data key="d7">training, internal knowledge</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Prompt-tuning">
  <data key="d5">16.0</data>
  <data key="d6">Prompt-tuning is a form of fine-tuning that adjusts prompts to guide model outputs for specific tasks or domains."|&gt;"task-specific, prompt adjustment&lt;SEP&gt;Prompt-tuning is a form of model fine-tuning where prompts are adjusted to steer model outputs for specific tasks or domains.</data>
  <data key="d7">8&lt;SEP&gt;prompt adjustment, task adaptation</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Domain-specific Knowledge">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning with domain-specific data enhances LLMs' performance in specialized areas by incorporating targeted knowledge.&lt;SEP&gt;Fine-tuning with domain-specific data enhances LLMs' performance in specialized areas by incorporating targeted knowledge."|&gt;"domain adaptation, knowledge integration</data>
  <data key="d7">8&lt;SEP&gt;domain adaptation, knowledge integration</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Perplexity">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning affects the model's perplexity by optimizing parameters to better fit the data, thus reducing uncertainty during inference."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Fine-tuning" target="Methodologies">
  <data key="d5">9.0</data>
  <data key="d6">Fine-tuning involves training models on domain-specific datasets to improve their accuracy for tasks like pragma generation and performance prediction.</data>
  <data key="d7">model training, domain adaptation</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Llama-3-70B" target="HPC-I NSTRUCT dataset">
  <data key="d5">16.0</data>
  <data key="d6">Llama-3-70B is fine-tuned on the HPC-I NSTRUCT dataset to assess its performance across different sizes.</data>
  <data key="d7">training data, model evaluation</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-I NSTRUCT dataset" target="Study Designs">
  <data key="d5">6.0</data>
  <data key="d6">The dataset is used in study designs to evaluate code generation models and ensure reproducibility.</data>
  <data key="d7">dataset, evaluation</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-I NSTRUCT dataset" target="Reproducibility">
  <data key="d5">6.0</data>
  <data key="d6">The HPC-I NSTRUCT dataset supports reproducibility by providing a standardized set of problem statements and solutions for model training and evaluation.</data>
  <data key="d7">dataset, validation</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="pass@k" target="pass@1">
  <data key="d5">17.0</data>
  <data key="d6">pass@1 is a specific case of pass@k with k=1, used as a primary measure of model accuracy in generating correct code on the first try."|"&lt;performance measurement, evaluation&lt;SEP&gt;pass@k extends the concept of pass@1 by considering multiple attempts, providing a broader view of model performance.</data>
  <data key="d7">9&lt;SEP&gt;performance measurement, multiple attempts</data>
  <data key="d8">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="pass@k" target="performance plateau">
  <data key="d5">13.0</data>
  <data key="d6">Scores tend to level off at higher attempts, indicating diminishing returns in accuracy improvements with more tries."|"&lt;performance limit, diminishing returns&lt;SEP&gt;The scores tend to plateau at higher attempts, indicating an upper limit to the models' ability to improve correctness with more tries.</data>
  <data key="d7">7&lt;SEP&gt;performance limit, diminishing returns</data>
  <data key="d8">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="pass@k" target="Codex Models">
  <data key="d5">7.0</data>
  <data key="d6">Different sizes of Codex models show varying pass@k performance, with larger models generally performing better.</data>
  <data key="d7">model size, performance</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="pass@k" target="Codex">
  <data key="d5">18.0</data>
  <data key="d6">Codex's performance is evaluated using pass@k metrics, which measure success rates at different sample sizes.</data>
  <data key="d7">evaluation metrics, performance assessment</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="pass@k" target="Temperature">
  <data key="d5">16.0</data>
  <data key="d6">Optimal sampling temperature affects the success rates of pass@k metrics, with different temperatures preferred for models like Codex and Codex-S.</data>
  <data key="d7">parameter tuning, model performance</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="pass@k" target="Codex-S">
  <data key="d5">16.0</data>
  <data key="d6">Codex-S outperforms Codex on pass@1 and pass@100, indicating higher efficiency and accuracy in code generation.</data>
  <data key="d7">model comparison, performance improvement</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="pass@k" target="Codex-D">
  <data key="d5">14.0</data>
  <data key="d6">Codex-D generates docstrings with success rates measured by manual grading, which are comparable but generally lower than Codex-S.</data>
  <data key="d7">evaluation, model accuracy</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Correctness" target="Performance Metrics">
  <data key="d5">9.0</data>
  <data key="d6">Code correctness is the key outcome measured by benchmarks like ParEval to determine if generated code solutions are valid.</data>
  <data key="d7">validation, correctness</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Parallel Code Generation" target="Research Questions/Hypotheses">
  <data key="d5">8.0</data>
  <data key="d6">The study aims to assess how different model sizes and fine-tuning strategies affect parallel code generation capabilities.</data>
  <data key="d7">performance impact, research inquiry</data>
  <data key="d8">chunk-1ee2903e9d138e70e07c1af3cf2fa9a3</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Parallel Code Generation" target="Models">
  <data key="d5">18.0</data>
  <data key="d6">This study evaluates the ability of various LLMs to generate parallel code based on prompts."|</data>
  <data key="d7">AI code generation, parallel programming</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Code Generation" target="Large Language Models (LLMs)">
  <data key="d5">7.0</data>
  <data key="d6">LLMs are evaluated for their ability to generate parallel code efficiently.</data>
  <data key="d7">AI capability, code synthesis</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Code Generation" target="Execution Models">
  <data key="d5">8.0</data>
  <data key="d6">Execution models such as OpenMP, MPI, Kokkos, CUDA, and HIP are employed to implement the generated parallel code.</data>
  <data key="d7">implementation strategies, parallel frameworks</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Performance Metrics" target="Problem Types">
  <data key="d5">8.0</data>
  <data key="d6">The model's performance varies depending on the problem type, performing better on dense structured problems and worse on sparse unstructured problems like geometric ones.</data>
  <data key="d7">problem difficulty, model capability</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance Metrics" target="Execution Models">
  <data key="d5">8.0</data>
  <data key="d6">The models perform best on serial and OpenMP code, with decreasing performance on GPU and MPI models, indicating challenges in generating certain parallel code types.</data>
  <data key="d7">parallelization, code complexity</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance Metrics" target="Fine-tuning Strategies">
  <data key="d5">8.0</data>
  <data key="d6">Effective data and training strategies improve the models' ability to generate correct and efficient parallel code, as demonstrated by performance results.</data>
  <data key="d7">training data, model accuracy</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance Metrics" target="Trade-offs in Model Design">
  <data key="d5">7.0</data>
  <data key="d6">The study explores how model size, speed, and memory requirements influence practical usability and code quality, aiming for optimal balance.</data>
  <data key="d7">efficiency, usability</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance Metrics" target="speedup𝑛@𝑘">
  <data key="d5">9.0</data>
  <data key="d6">This metric compares generated code performance to the baseline, indicating the efficiency of parallel code execution."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Performance Metrics" target="speedupmax@𝑘">
  <data key="d5">8.0</data>
  <data key="d6">This metric estimates the peak speedup across all resource counts, highlighting the maximum performance potential."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Performance Metrics" target="efficiency𝑛@𝑘">
  <data key="d5">9.0</data>
  <data key="d6">The efficiency metric measures how effectively the generated code utilizes resources, normalized by the number of resources."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Performance Metrics" target="Results">
  <data key="d5">22.0</data>
  <data key="d6">Metrics such as execution time, resource utilization, and data transfer volume evaluate the effectiveness of the optimization.&lt;SEP&gt;Performance metrics such as runtime are used to compare different code implementations and optimizations.&lt;SEP&gt;Performance metrics such as runtime are used to compare different code versions and optimization strategies.</data>
  <data key="d7">evaluation, performance measurement&lt;SEP&gt;performance measurement, benchmarking</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8&lt;SEP&gt;chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Magicoder" target="Theories/Models">
  <data key="d5">14.0</data>
  <data key="d6">Magicoder is a fine-tuned model based on DeepseekCoder-6.7B, trained on synthetic data for improved code generation.&lt;SEP&gt;Magicoder is a fine-tuned variant of DeepseekCoder-6.7B, trained on synthetic data for improved code modeling.</data>
  <data key="d7">fine-tuning, synthetic data</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Magicoder" target="Knowledge distillation of large language models">
  <data key="d5">7.0</data>
  <data key="d6">Magicoder may utilize knowledge distillation techniques to improve or streamline source code models, suggesting a relationship where Magicoder benefits from or applies knowledge distillation methods.</data>
  <data key="d7">method application, model improvement</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Magicoder" target="Source code">
  <data key="d5">7.0</data>
  <data key="d6">MagicCoder emphasizes source code as a core component of its architecture, highlighting the importance of source code in AI models.</data>
  <data key="d7">core component, AI modeling</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Phind-V2" target="Theories/Models">
  <data key="d5">16.0</data>
  <data key="d6">Phind-V2 is a fine-tuned CodeLlama model recognized for top performance on code benchmarks.&lt;SEP&gt;Phind-V2 is a fine-tuned CodeLlama model, optimized for code tasks and recognized for top leaderboard performance.</data>
  <data key="d7">model fine-tuning, leaderboard performance&lt;SEP&gt;model fine-tuning, leaderboard ranking</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Gemini-1.5-flash" target="Theories/Models">
  <data key="d5">12.0</data>
  <data key="d6">Gemini-1.5-flash is a commercial API-accessible model from Google used for code generation.&lt;SEP&gt;Gemini-1.5-flash is a commercial API-based model from Google used for code generation.</data>
  <data key="d7">commercial model, API access</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="GPT-3.5" target="Theories/Models">
  <data key="d5">16.0</data>
  <data key="d6">GPT-3.5 is a state-of-the-art OpenAI model used for complex language and code tasks.&lt;SEP&gt;GPT-3.5 is an advanced OpenAI model used for state-of-the-art code and language tasks.</data>
  <data key="d7">state-of-the-art, OpenAI&lt;SEP&gt;state-of-the-art, OpenAI models</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="GPT-3.5" target="answer EM">
  <data key="d5">10.0</data>
  <data key="d6">GPT-3.5's performance is compared to DSPy-based systems, highlighting differences in capabilities.&lt;SEP&gt;GPT-3.5's performance is used as a benchmark to compare with DSPy-based systems, highlighting differences in capabilities.</data>
  <data key="d7">benchmark comparison, performance&lt;SEP&gt;benchmark, comparison</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GPT-3.5" target="Research Questions/Hypotheses">
  <data key="d5">16.0</data>
  <data key="d6">Assesses GPT-3.5's ability to generate correct, performant parallel code and how translation improves with additional context.&lt;SEP&gt;Evaluates GPT-3.5's effectiveness in translating and generating parallel code, especially in complex or unstructured problems.</data>
  <data key="d7">model capability, code accuracy&lt;SEP&gt;model performance, correctness</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="GPT-3.5" target="Evaluation">
  <data key="d5">9.0</data>
  <data key="d6">GPT-3.5 is used as a language model for evaluation purposes in the research paper."|&gt;"language models, evaluation</data>
  <data key="d7">9</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="GPT-4" target="Theories/Models">
  <data key="d5">16.0</data>
  <data key="d6">GPT-4 is an advanced OpenAI model providing enhanced capabilities for language and code generation.&lt;SEP&gt;GPT-4 is an improved OpenAI model providing enhanced capabilities for code and language understanding.</data>
  <data key="d7">advanced AI, OpenAI&lt;SEP&gt;advanced AI, OpenAI models</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="GPT-4" target="Problem Types">
  <data key="d5">18.0</data>
  <data key="d6">GPT-4 is evaluated on the ParEval benchmark across different problem types, indicating its performance on diverse tasks.&lt;SEP&gt;GPT-4 is evaluated on the ParEval benchmark with various problem types, reflecting its ability to perform across diverse AI tasks.</data>
  <data key="d7">benchmark, performance assessment&lt;SEP&gt;performance assessment, benchmarking</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="GPT-4" target="Execution Model">
  <data key="d5">18.0</data>
  <data key="d6">GPT-4's performance scores are reported across multiple execution models, reflecting its adaptability to different computational setups.&lt;SEP&gt;GPT-4's scores are reported across different execution models, indicating its adaptability to various computational environments.</data>
  <data key="d7">performance, model flexibility&lt;SEP&gt;performance, model versatility</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="GPT-4" target="CoT">
  <data key="d5">16.0</data>
  <data key="d6">GPT-4 reportedly outperforms CoT with a higher score of 92%, indicating an improved reasoning approach.".&lt;SEP&gt;GPT-4's performance surpasses that with CoT reasoning, achieving 92%, indicating enhanced reasoning capabilities.".</data>
  <data key="d7">model performance, reasoning enhancement&lt;SEP&gt;reasoning, performance boost</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GPT-4" target="MBPP results">
  <data key="d5">14.0</data>
  <data key="d6">GPT-4's evaluation results are derived from MBPP, providing performance metrics for code generation.&lt;SEP&gt;GPT-4's performance is evaluated through MBPP benchmark results, providing metrics for code generation effectiveness.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="GPT-4" target="Research Questions/Hypotheses">
  <data key="d5">18.0</data>
  <data key="d6">Assesses whether GPT-4 outperforms other models in generating correct, efficient, and scalable parallel code.&lt;SEP&gt;Evaluates whether GPT-4 outperforms other models in correctness, efficiency, and scalability of generated parallel code.</data>
  <data key="d7">model performance, efficiency&lt;SEP&gt;model performance, scalability</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="GPT-4" target="Evaluation">
  <data key="d5">9.0</data>
  <data key="d6">GPT-4 is used alongside GPT-3.5 for evaluation in the study."|&gt;"language models, evaluation</data>
  <data key="d7">9</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="GPT-4" target="OpenAI">
  <data key="d5">20.0</data>
  <data key="d6">OpenAI developed GPT-4, a large language model designed to follow instructions and perform complex language tasks.&lt;SEP&gt;OpenAI developed GPT-4, a state-of-the-art large language model designed for instruction following, reasoning, and complex language understanding."|</data>
  <data key="d7">model development, AI advancement</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Results of Ablation Studies" target="Theories/Models">
  <data key="d5">9.0</data>
  <data key="d6">The ablation study results analyze how different configurations affect model performance in code generation.</data>
  <data key="d7">performance analysis, training configurations</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Results of Ablation Studies" target="Results">
  <data key="d5">9.0</data>
  <data key="d6">The ablation studies analyze how different training configurations and data affect model performance in code generation tasks, especially parallel code.</data>
  <data key="d7">performance analysis, training configurations</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Parallel Code Generation Performance" target="Results">
  <data key="d5">18.0</data>
  <data key="d6">Performance metrics evaluate how well models generate parallel code, such as MPI, in benchmarks like ParEval."|&gt;"performance metrics, code benchmarks&lt;SEP&gt;Performance scores such as Pass@1 measure the models' ability to generate correct parallel code like MPI in benchmarks.</data>
  <data key="d7">9&lt;SEP&gt;performance metrics, code benchmarks</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Choice of Base Model and Instruction Masking" target="Research Questions/Hypotheses">
  <data key="d5">16.0</data>
  <data key="d6">Investigates how different fine-tuning choices impact model effectiveness in code generation tasks."|&gt;"fine-tuning strategies, model performance&lt;SEP&gt;Investigates how the selection of base models and instruction masking strategies impact code generation performance.</data>
  <data key="d7">8&lt;SEP&gt;fine-tuning strategies, model performance</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Impact of Fine-Tuning Data Quantity and Quality" target="Research Questions/Hypotheses">
  <data key="d5">16.0</data>
  <data key="d6">Examines how varying amounts of MPI training samples influence model performance and generalization.&lt;SEP&gt;Studies how the amount of MPI samples used for fine-tuning influences the models' MPI code generation success."|&gt;"training data size, model performance</data>
  <data key="d7">8&lt;SEP&gt;training data size, performance</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="MPI Code Generation" target="Objects of Study">
  <data key="d5">16.0</data>
  <data key="d6">MPI code generation performance assesses models' ability to generate Message Passing Interface code, which is crucial for parallel computing."|&gt;"parallel programming, code generation&lt;SEP&gt;MPI code generation performance assesses the models' ability to generate Message Passing Interface code, a complex parallel programming task.</data>
  <data key="d7">8&lt;SEP&gt;parallel programming, code generation</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Sizes (1.3B and 6.7B)" target="Variables">
  <data key="d5">14.0</data>
  <data key="d6">Model size impacts how training data quantity affects performance, with smaller models benefiting more from additional data.&lt;SEP&gt;Model size impacts how training data quantity affects performance, with smaller models benefiting more from increased data."|&gt;"model capacity, data effectiveness</data>
  <data key="d7">7&lt;SEP&gt;model capacity, data effectiveness</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Training Data Amount (0k to 12k MPI samples)" target="Variables">
  <data key="d5">14.0</data>
  <data key="d6">The number of MPI samples used for fine-tuning influences MPI code generation performance, with diminishing returns at higher data volumes.&lt;SEP&gt;The quantity of MPI training samples used for fine-tuning influences the MPI code generation performance, with diminishing returns observed."|&gt;"training data, performance gains</data>
  <data key="d7">7&lt;SEP&gt;training data, performance gains</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fine-Tuning Configurations" target="Tools">
  <data key="d5">16.0</data>
  <data key="d6">Different fine-tuning strategies, such as gradient masking and instruct vs. base models, serve as tools to enhance model performance."|&gt;"fine-tuning methods, performance optimization&lt;SEP&gt;Different fine-tuning strategies, such as masked/unmasked gradients and instruct/base models, are tools to optimize performance.</data>
  <data key="d7">8&lt;SEP&gt;fine-tuning methods, performance optimization</data>
  <data key="d8">chunk-87968a35d8273787998be04f169d03c8</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Training Data" target="The Stack">
  <data key="d5">8.0</data>
  <data key="d6">The dataset (The Stack) provides the training material for models like StarCoderBase, influencing their capabilities and biases.</data>
  <data key="d7">training data, model development</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Training Data" target="Suggestion Quality">
  <data key="d5">7.0</data>
  <data key="d6">The volume and diversity of training data impact the relevance and correctness of suggestions.</data>
  <data key="d7">training data, suggestion accuracy</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Training Data" target="Bias and Representation">
  <data key="d5">16.0</data>
  <data key="d6">Bias and representation issues are influenced by the training data, which can embed societal stereotypes and prejudices into model outputs.&lt;SEP&gt;Training data influences the biases and stereotypes reflected in model outputs.</data>
  <data key="d7">data influence, societal bias&lt;SEP&gt;training data influence, societal bias</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Training Data" target="Sensitive Data in Training Data">
  <data key="d5">14.0</data>
  <data key="d6">Presence of sensitive data in training repositories may already compromise privacy and security, influencing model behavior.</data>
  <data key="d7">privacy, data security</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Training Data" target="Environmental Impacts">
  <data key="d5">20.0</data>
  <data key="d6">Training large models like Codex consumes significant energy, affecting environmental sustainability, mitigated by renewable energy sourcing.</data>
  <data key="d7">sustainability, energy consumption</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Training Data" target="Bias in Language Models">
  <data key="d5">9.0</data>
  <data key="d6">Biases present in training data influence the model's responses and potential for harm.</data>
  <data key="d7">data bias, model influence</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Training Data" target="Validation Data">
  <data key="d5">8.0</data>
  <data key="d6">The validation dataset is a subset (5%) of the training data, used to evaluate model performance during training.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Performance" target="Impact of Data and Model Size">
  <data key="d5">8.0</data>
  <data key="d6">Both the amount and quality of data, along with model size, jointly influence the final performance of fine-tuned models in code generation.</data>
  <data key="d7">performance factors, combined impact</data>
  <data key="d8">chunk-8ea08005bc62e40cce7faf8139912fa4</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance" target="Tasks">
  <data key="d5">16.0</data>
  <data key="d6">The effectiveness of prompting strategies like zero-shot-CoT and few-shot prompts is reflected in task performance metrics such as accuracy and reasoning success rate.&lt;SEP&gt;The performance of LLMs varies depending on the prompting strategy and task complexity, with zero-shot-CoT showing significant improvements in reasoning tasks.</data>
  <data key="d7">evaluation, effectiveness&lt;SEP&gt;evaluation, reasoning accuracy</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Performance" target="Model size">
  <data key="d5">16.0</data>
  <data key="d6">Larger models like 12B parameters generally perform better at code generation tasks compared to smaller models like 300M parameters, indicating a size-performance relationship.</data>
  <data key="d7">model capacity, performance</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Performance" target="Model Scaling">
  <data key="d5">7.0</data>
  <data key="d6">Model size correlates with performance, following a sigmoid scaling pattern as parameters increase.</data>
  <data key="d7">scaling law, model size</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Knowledge Distillation" target="Knowledge Editing">
  <data key="d5">7.0</data>
  <data key="d6">Knowledge distillation focuses on creating a smaller, domain-specific model from an LLM, transferring knowledge without updating all parameters.</data>
  <data key="d7">model compression, transfer</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Benchmark" target="Objects of Study">
  <data key="d5">18.0</data>
  <data key="d6">A collection of prompts designed to evaluate LLM performance on parallel code generation across multiple problem types and models.&lt;SEP&gt;A collection of prompts designed to evaluate LLMs' performance on parallel code generation across multiple problem types and models.</data>
  <data key="d7">evaluation framework, comprehensive testing</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Model Training" target="Trust Boundary">
  <data key="d5">7.0</data>
  <data key="d6">The training and fine-tuning processes define the trust boundary, affecting how susceptible Codex is to adversarial inputs and malicious exploitation.</data>
  <data key="d7">trust model, security risk</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Training" target="Performance Datasets">
  <data key="d5">7.0</data>
  <data key="d6">The datasets of paired code and performance data are used to fine-tune models to understand and predict performance characteristics.</data>
  <data key="d7">performance modeling, training data</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Training" target="Large Dataset of HPC Source Code">
  <data key="d5">7.0</data>
  <data key="d6">The large dataset provides the necessary data for training the language model to understand HPC code.</data>
  <data key="d7">training data, source code</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Training" target="Performance Data Datasets">
  <data key="d5">6.0</data>
  <data key="d6">The performance datasets are used to fine-tune models for performance prediction tasks.</data>
  <data key="d7">performance modeling, fine-tuning</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Comparison" target="Generation Diversity">
  <data key="d5">18.0</data>
  <data key="d6">Diversity metrics compare the output variety of models like RAG and BART, showing RAG's higher factuality and specificity.</data>
  <data key="d7">output diversity, model performance</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Model Comparison" target="Results">
  <data key="d5">8.0</data>
  <data key="d6">Evaluation of different pre-trained LLMs shows HPC-Coder's superior ability to perform HPC-specific tasks.</data>
  <data key="d7">model evaluation, comparative analysis</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="ParEval benchmark" target="HPC-Coder-V2-6.7B">
  <data key="d5">9.0</data>
  <data key="d6">The model's performance was evaluated on the ParEval benchmark, demonstrating its capabilities in parallel code generation.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="ParEval benchmark" target="performance">
  <data key="d5">8.0</data>
  <data key="d6">The ParEval benchmark provides a standardized way to evaluate the performance and correctness of LLM-generated parallel code.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Code Generation Performance" target="Prompt Queries">
  <data key="d5">6.0</data>
  <data key="d6">Structured prompts influence the quality and correctness of code suggestions generated by Copilot.</data>
  <data key="d7">prompt design, code quality</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Problem Types" target="HPC-Coder-V2-6.7B">
  <data key="d5">16.0</data>
  <data key="d6">HPC-Coder-V2-6.7B is evaluated across multiple problem types, indicating its applicability to diverse computational tasks.&lt;SEP&gt;The 6.7B model is evaluated across various problem types, demonstrating its versatility in high-performance computing tasks.</data>
  <data key="d7">evaluation, problem diversity&lt;SEP&gt;system evaluation, problem diversity</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Problem Types" target="HPC-Coder-V2-16B">
  <data key="d5">16.0</data>
  <data key="d6">HPC-Coder-V2-16B is assessed on various problem types similar to other models, demonstrating its versatility.&lt;SEP&gt;The 16B model is assessed on multiple problem types, indicating its capability to handle diverse computational workloads.</data>
  <data key="d7">evaluation, system performance&lt;SEP&gt;performance testing, problem scope</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Problem Types" target="Phind-V2-34B">
  <data key="d5">16.0</data>
  <data key="d6">Phind-V2-34B's performance is measured across different problem categories, showing its adaptability.&lt;SEP&gt;Phind-V2-34B's performance is tested on multiple problem types, reflecting its capability to handle diverse computational challenges.</data>
  <data key="d7">benchmarking, problem diversity&lt;SEP&gt;evaluation, problem scope</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Problem Types" target="Speedup">
  <data key="d5">7.0</data>
  <data key="d6">Speedup varies across different problem types, reflecting the models' performance on specific tasks.</data>
  <data key="d7">performance variation, task-specific analysis</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Execution Models" target="Models">
  <data key="d5">18.0</data>
  <data key="d6">Different execution models define paradigms for parallel and distributed programming used in code generation."|</data>
  <data key="d7">parallel programming, model paradigms</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Fine-tuning Strategies" target="Methods">
  <data key="d5">16.0</data>
  <data key="d6">Various fine-tuning approaches, including adapter-based, neural, low-rank, and instruction-based, are used for domain adaptation.&lt;SEP&gt;Various fine-tuning methods are used to adapt LLMs to specific domains, including adapter-based and instruction-based approaches.</data>
  <data key="d7">training techniques, adaptation methods&lt;SEP&gt;training techniques, domain adaptation</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Fine-tuning Strategies" target="Training Memory">
  <data key="d5">12.0</data>
  <data key="d6">Reducing training memory consumption can be achieved through architectural designs or efficient fine-tuning methods.</data>
  <data key="d7">efficiency, resource management</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="problem types" target="performance metrics">
  <data key="d5">9.0</data>
  <data key="d6">The model's effectiveness varies by problem type, performing better on dense structured problems and worse on sparse unstructured problems like geometric problems.</data>
  <data key="d7">problem difficulty, model capability</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="execution models" target="performance metrics">
  <data key="d5">9.0</data>
  <data key="d6">The models perform best on serial and OpenMP code, with performance decreasing on GPU and MPI models, indicating the complexity of generating certain parallel codes.</data>
  <data key="d7">parallelization, code complexity</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="model sizes" target="performance metrics">
  <data key="d5">8.0</data>
  <data key="d6">Larger models tend to perform better across most problem types, but may underperform on specific problems like geometric ones, illustrating size-performance trade-offs.</data>
  <data key="d7">model scaling, problem structure</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="performance metrics" target="fine-tuning strategies">
  <data key="d5">8.0</data>
  <data key="d6">Effective data and training strategies improve code correctness and efficiency, especially for parallel code generation.</data>
  <data key="d7">training data, model accuracy</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="performance metrics" target="training and data strategies">
  <data key="d5">8.0</data>
  <data key="d6">High-quality fine-tuning data enhances the models' ability to generate correct, efficient parallel code, as reflected in performance metrics.</data>
  <data key="d7">training data, code quality</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="performance metrics" target="model size">
  <data key="d5">7.0</data>
  <data key="d6">Larger models tend to have higher performance metrics but require more resources."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="performance metrics" target="parallel code">
  <data key="d5">10.0</data>
  <data key="d6">Metrics assess the correctness, speed, and scalability of the parallel code generated by LLMs.</data>
  <data key="d7">10</data>
  <data key="d8">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance metrics" target="generated code">
  <data key="d5">18.0</data>
  <data key="d6">Performance metrics are used to assess the quality and effectiveness of the generated code, including correctness and runtime.&lt;SEP&gt;The generated code is evaluated using performance metrics like runtime and pass@1 scores to assess quality.</data>
  <data key="d7">evaluation, quality assessment&lt;SEP&gt;performance assessment</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance metrics" target="runtime">
  <data key="d5">7.0</data>
  <data key="d6">The runtime of generated code impacts its efficiency and usability, serving as a key performance indicator.</data>
  <data key="d7">efficiency, measurement</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance metrics" target="execution environment">
  <data key="d5">7.0</data>
  <data key="d6">The execution environment influences performance metrics such as runtime and correctness, affecting overall evaluation.</data>
  <data key="d7">hardware influence, environment</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="trade-offs in model design" target="results">
  <data key="d5">8.0</data>
  <data key="d6">The study explores how model size, speed, and memory requirements influence practical usability and code quality, aiming for optimal balance.</data>
  <data key="d7">efficiency, usability</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="limitations" target="performance">
  <data key="d5">6.0</data>
  <data key="d6">Limitations highlight areas where LLMs underperform, such as in MPI code generation and unstructured problem handling.</data>
  <data key="d7">6</data>
  <data key="d8">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="synthetic data" target="HPC instruction dataset">
  <data key="d5">9.0</data>
  <data key="d6">Synthetic data generated from LLMs and open-source code was used to create the HPC instruction dataset, HPC-INSTRUCT."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="model performance metrics" target="data quality">
  <data key="d5">7.0</data>
  <data key="d6">High-quality data enhances model performance metrics like pass@1 and throughput, while low-quality data limits effectiveness."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="model performance metrics" target="prompt configuration">
  <data key="d5">6.0</data>
  <data key="d6">Prompt design influences the model's output quality and accuracy, affecting performance metrics."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="parallel code generation" target="Applications/Implications">
  <data key="d5">8.0</data>
  <data key="d6">Effective fine-tuned HPC models can generate parallel code efficiently, impacting HPC workflows."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="model size" target="performance comparison">
  <data key="d5">12.0</data>
  <data key="d6">Larger models like GPT-4 and CodeLlama-34B tend to generate more confident outputs but may sometimes produce less diverse or less correct results, affecting overall performance.&lt;SEP&gt;Larger models like GPT-4 or CodeLlama-34B tend to generate more confident outputs but may sometimes perform worse in correctness or diversity compared to smaller models.</data>
  <data key="d7">model size impact, confidence</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="pass@1" target="Results">
  <data key="d5">18.0</data>
  <data key="d6">Higher pass@1 scores indicate a greater likelihood that the generated code is correct on the first attempt.&lt;SEP&gt;pass@1 scores reflect the correctness of the first attempt at code generation by LLMs, with higher scores indicating better accuracy.</data>
  <data key="d7">accuracy, code correctness&lt;SEP&gt;accuracy, correctness</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="pass@1" target="GPT-J 6B">
  <data key="d5">8.0</data>
  <data key="d6">GPT-J's pass@1 (11.62%) indicates its ability to generate correct code solutions, demonstrating its effectiveness as a code-generation model.</data>
  <data key="d7">performance, evaluation</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="High-Quality Fine-Tuning Data" target="Model Performance Metrics">
  <data key="d5">10.0</data>
  <data key="d6">High-quality data enhances model performance metrics such as pass@1 and throughput, leading to better code generation results."|</data>
  <data key="d7">10</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance Metrics" target="Prompt Configuration">
  <data key="d5">8.0</data>
  <data key="d6">The way prompts are configured influences the quality and accuracy of model outputs, affecting performance metrics."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance Metrics" target="Model Architecture">
  <data key="d5">8.0</data>
  <data key="d6">The underlying architecture determines the model's capacity to learn and generalize, impacting performance."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model Performance Metrics" target="Model Evaluation Benchmarks">
  <data key="d5">8.0</data>
  <data key="d6">Benchmarks like HumanEval provide standardized metrics to evaluate model effectiveness."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Pass@1" target="Results">
  <data key="d5">9.0</data>
  <data key="d6">Pass@1 is a specific result metric indicating model accuracy in top-1 predictions.</data>
  <data key="d7">performance metric, accuracy</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Pass@1" target="GPT-J 6B">
  <data key="d5">8.0</data>
  <data key="d6">GPT-J's pass@1 performance (11.62%) indicates its ability to generate correct code solutions on the HumanEval benchmark.</data>
  <data key="d7">performance, evaluation</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Data Collection Methods" target="Synthetic Data Generation Techniques">
  <data key="d5">9.0</data>
  <data key="d6">Methods like semi-synthetic data creation and LLM-generated data are used to augment training datasets."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Data Limitations" target="Synthetic Data Generation Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Synthetic data approaches aim to overcome data scarcity caused by limitations in available real data."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-a491810c484f5945ed0c9ade326607dd</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2-6.7B" target="Execution Model">
  <data key="d5">18.0</data>
  <data key="d6">HPC-Coder-V2-6.7B is tested with various execution models, showing its adaptability to different parallel computing paradigms.&lt;SEP&gt;The 6.7B model is tested with multiple parallel execution models, demonstrating its flexibility in different high-performance environments.</data>
  <data key="d7">system adaptability, parallel frameworks&lt;SEP&gt;system flexibility, parallel models</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2-16B" target="Execution Model">
  <data key="d5">18.0</data>
  <data key="d6">HPC-Coder-V2-16B's performance varies across execution models, indicating its compatibility with multiple parallel frameworks.&lt;SEP&gt;The 16B model's performance varies across different execution models, indicating compatibility with multiple parallel architectures.</data>
  <data key="d7">performance variation, parallel execution&lt;SEP&gt;performance, parallel execution</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model fine-tuning" target="Synthetic data">
  <data key="d5">7.0</data>
  <data key="d6">Synthetic data generated from LLMs and open-source code was used to fine-tune the models.</data>
  <data key="d7">training data, data quality</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Data quality" target="Model performance">
  <data key="d5">9.0</data>
  <data key="d6">Higher quality fine-tuning data significantly enhances the models' ability to generate parallel code.</data>
  <data key="d7">data quality, effectiveness</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model size" target="Model performance">
  <data key="d5">8.0</data>
  <data key="d6">Moving from small to medium models yields significant improvements, while larger models show diminishing returns.</data>
  <data key="d7">model size, performance</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model size" target="misalignment">
  <data key="d5">7.0</data>
  <data key="d6">Larger models tend to have higher risks of misalignment due to increased capabilities and complexity.</data>
  <data key="d7">model scaling, safety risk</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model performance" target="pass@k metric">
  <data key="d5">18.0</data>
  <data key="d6">The pass@k metric quantifies the likelihood that at least one of the top k generated code samples passes all unit tests, serving as a key performance indicator.</data>
  <data key="d7">performance metric, evaluation</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model performance" target="Results">
  <data key="d5">8.0</data>
  <data key="d6">Perplexity scores after fine-tuning indicate how well models model HPC code, with lower scores reflecting better performance.</data>
  <data key="d7">model evaluation, language modeling</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Open-source models" target="Model evaluation">
  <data key="d5">11.0</data>
  <data key="d6">Open-source models like Llama 2 are evaluated using benchmarks to determine their performance.</data>
  <data key="d7">benchmarking, performance assessment</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Open-source models" target="performance comparison">
  <data key="d5">15.0</data>
  <data key="d6">Open-source models like Phind-V2 often outperform some open-source counterparts but generally lag behind larger proprietary models in accuracy."|"&lt;model comparison, open vs. closed source&lt;SEP&gt;Open-source models like Phind-V2 perform close to or better than some closed-source models in certain metrics, though generally lagging behind larger proprietary models.</data>
  <data key="d7">8&lt;SEP&gt;model comparison, open vs. closed source</data>
  <data key="d8">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Model efficiency" target="Model training techniques">
  <data key="d5">12.0</data>
  <data key="d6">Training techniques like knowledge distillation and sparsity exploitation are aimed at improving model efficiency.</data>
  <data key="d7">training optimization, efficiency</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Code llama" target="Gpt-4o system card">
  <data key="d5">6.0</data>
  <data key="d6">The Gpt-4o system card likely documents or discusses the capabilities and applications of Code llama models, indicating a relationship of documentation and description.</data>
  <data key="d7">documentation, system description</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Deepseek-coder" target="Deepseek-coder-v2">
  <data key="d5">16.0</data>
  <data key="d6">Deepseek-coder-v2 is an advanced iteration that likely builds upon Deepseek-coder, indicating a developmental relationship where v2 improves or extends the original model.&lt;SEP&gt;Deepseek-coder-v2 is an improved version of Deepseek-coder, indicating a developmental relationship with enhancements in code intelligence capabilities.</data>
  <data key="d7">model evolution, enhancement&lt;SEP&gt;model evolution, improvement</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Deepseek-coder" target="Objects of Study">
  <data key="d5">16.0</data>
  <data key="d6">A large language model focused on code intelligence, studied in 2024 for its impact on programming tasks.&lt;SEP&gt;A large language model focused on code understanding and intelligence, studied in 2024 for its impact on programming tasks.</data>
  <data key="d7">code intelligence, AI models&lt;SEP&gt;code understanding, AI models</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Deepseek-coder" target="Knowledge transfer from high-resource to low-resource programming languages">
  <data key="d5">15.0</data>
  <data key="d6">Deepseek-coder advances code intelligence by facilitating knowledge transfer across languages, impacting how code generation models learn and generalize.&lt;SEP&gt;Deepseek-coder's development and application are based on the idea of transferring knowledge across programming languages, impacting how models learn and generalize.</data>
  <data key="d7">model training, knowledge transfer</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Deepseek-coder" target="Luo, Y">
  <data key="d5">6.0</data>
  <data key="d6">Luo, Y contributed to research involving Deepseek-coder, a large language model for code intelligence, indicating authorship or collaboration.</data>
  <data key="d7">authors, research contribution</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Llama 2" target="Open foundation and fine-tuned chat models">
  <data key="d5">9.0</data>
  <data key="d6">Llama 2 serves as the basis for open foundation models and can be fine-tuned for specific tasks, establishing a relationship of foundational architecture and customization.</data>
  <data key="d7">base model, fine-tuning</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Llama 2" target="arXiv preprint arXiv:2307.09288">
  <data key="d5">8.0</data>
  <data key="d6">The publication details the development and features of Llama 2, linking it to foundational research in language models.</data>
  <data key="d7">publication, research documentation</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Efficient large scale language modeling with mixtures of experts" target="large language models">
  <data key="d5">10.0</data>
  <data key="d6">This methodology is used to develop or optimize large language models, indicating a relationship of technical approach to model scalability.</data>
  <data key="d7">scalability, efficiency</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Wizardcoder" target="evol-instruct">
  <data key="d5">11.0</data>
  <data key="d6">Wizardcoder leverages evol-instruct techniques to enhance code modeling capabilities, showing a relationship of instructional training methods to model performance.</data>
  <data key="d7">training methodology, instruction-based learning</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Exploiting sparsity in pruned neural networks" target="large model training">
  <data key="d5">12.0</data>
  <data key="d6">This technique aims to optimize training of large models by exploiting sparsity, indicating a relationship of optimization to model training efficiency.</data>
  <data key="d7">training optimization, sparsity</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="PyTorch" target="HuggingFace library">
  <data key="d5">11.0</data>
  <data key="d6">PyTorch serves as the backend framework for running LLM inference via HuggingFace pipelines, enabling efficient model execution on GPUs."|&lt;|"software infrastructure, model inference&lt;SEP&gt;PyTorch serves as the backend framework for running inference on models via HuggingFace pipelines."|</data>
  <data key="d7">5&lt;SEP&gt;6</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="OpenAI" target="GPT-4o system card">
  <data key="d5">6.0</data>
  <data key="d6">The GPT-4o system card documents the features, capabilities, and specifications of the GPT-4O model, associated with OpenAI.</data>
  <data key="d7">documentation, model description</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="OpenAI" target="ChatGPT plugins">
  <data key="d5">18.0</data>
  <data key="d6">OpenAI provides ChatGPT plugins to extend ChatGPT's capabilities by integrating external tools and services."|&lt;SEP&gt;OpenAI provides ChatGPT plugins to extend the functionality of ChatGPT, enabling integration with external tools and services.</data>
  <data key="d7">tool extension, AI customization</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="OpenAI" target="Organization">
  <data key="d5">2.0</data>
  <data key="d6">OpenAI develops large language models like GPT-4 and provides tools such as ChatGPT plugins and publishes technical reports."|&lt;SEP&gt;OpenAI develops large language models like GPT-4, offers tools such as ChatGPT plugins, and publishes technical reports."|</data>
  <data key="d7">organization role, AI development</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="W. Liang" target="Verilogeval">
  <data key="d5">7.0</data>
  <data key="d6">W. Liang is involved in evaluating large language models for Verilog code generation using Verilogeval, highlighting their focus on hardware description language models.</data>
  <data key="d7">evaluation, hardware description language</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Large language models" target="Model evaluation">
  <data key="d5">9.0</data>
  <data key="d6">Large language models are assessed through benchmarks like the big code models leaderboard to measure performance.</data>
  <data key="d7">performance assessment, benchmarking</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model optimization" target="Model scalability">
  <data key="d5">10.0</data>
  <data key="d6">Optimization techniques such as sparsity exploitation and knowledge distillation aim to improve scalability and efficiency of large models.</data>
  <data key="d7">performance improvement, scalability</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Model evaluation" target="HumanEval dataset">
  <data key="d5">18.0</data>
  <data key="d6">The HumanEval dataset is used to benchmark models like Codex and GPT-J by assessing their ability to generate code that passes unit tests.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model evaluation" target="Unit Tests">
  <data key="d5">20.0</data>
  <data key="d6">Unit tests serve as the criteria for determining whether generated code is functionally correct, directly impacting the pass@k metric.</data>
  <data key="d7">performance measurement, correctness</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model evaluation" target="Evaluation framework">
  <data key="d5">8.0</data>
  <data key="d6">The evaluation framework, including datasets and metrics like pass@k, is used to systematically assess and compare the performance of code generation models.</data>
  <data key="d7">benchmarking, methodology</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model scalability" target="Model training techniques">
  <data key="d5">13.0</data>
  <data key="d6">Training techniques impact the scalability of models by enabling them to handle larger sizes and complexities.</data>
  <data key="d7">scalability, training methods</data>
  <data key="d8">chunk-354c52be46cd0307688197f61d891210</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Pytorch" target="Deep learning library">
  <data key="d5">16.0</data>
  <data key="d6">Pytorch is a deep learning library used for building neural networks and training models, as described in 2019.&lt;SEP&gt;Pytorch is a deep learning library used for constructing neural network models, as described in 2019.</data>
  <data key="d7">tool, deep learning framework</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Fixing weight decay regularization in adam" target="Optimization">
  <data key="d5">7.0</data>
  <data key="d6">A methodology aimed at improving the Adam optimizer by addressing regularization issues, proposed in 2017.</data>
  <data key="d7">optimization, regularization</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Large language models trained on code" target="Objects of Study">
  <data key="d5">9.0</data>
  <data key="d6">These models are studied to evaluate their ability to understand and generate programming code, as in 2021.</data>
  <data key="d7">model evaluation, code generation</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Phind-codellama-34b-v2" target="Tools">
  <data key="d5">12.0</data>
  <data key="d6">A large language model designed for code tasks, used as a tool for code generation and understanding in 2023.&lt;SEP&gt;A specific large language model designed for code tasks, used as a tool in 2023.</data>
  <data key="d7">tool, code generation&lt;SEP&gt;tool, code model</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Gemini" target="Theories/Models">
  <data key="d5">16.0</data>
  <data key="d6">Gemini models represent a family of multimodal AI models introduced in 2023, integrating multiple data types for advanced AI applications.&lt;SEP&gt;Gemini models represent a family of multimodal models introduced in 2023, capable of processing multiple data types for advanced AI applications.</data>
  <data key="d7">multimodal models, AI architectures&lt;SEP&gt;multimodal, AI models</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Language models are few-shot learners" target="Theories/Models">
  <data key="d5">20.0</data>
  <data key="d6">This concept demonstrates that large language models can perform tasks with minimal examples, as shown in 2020.&lt;SEP&gt;This theory demonstrates that large language models can perform tasks with minimal examples, as shown in 2020.</data>
  <data key="d7">learning capability, few-shot learning&lt;SEP&gt;learning, few-shot</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Gpt-4 technical report" target="Results">
  <data key="d5">18.0</data>
  <data key="d6">The 2023 report details GPT-4's architecture, capabilities, and benchmarks, illustrating its advanced performance.&lt;SEP&gt;The report from 2023 details the architecture, capabilities, and performance metrics of GPT-4.</data>
  <data key="d7">model performance, AI development&lt;SEP&gt;performance, AI model</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Mpirigen" target="Tools">
  <data key="d5">14.0</data>
  <data key="d6">A tool for MPI code generation via domain-specific language models, described in 2024, aiding parallel computing.&lt;SEP&gt;A tool for MPI code generation via domain-specific language models, described in 2024, supporting automated parallel code development.</data>
  <data key="d7">code generation, MPI&lt;SEP&gt;parallel computing, code generation</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Llm4vv" target="Tools">
  <data key="d5">12.0</data>
  <data key="d6">A testing suite for compiler validation driven by large language models, developed in 2023.&lt;SEP&gt;An LLM-driven compiler validation test suite developed in 2023 for automating compiler testing processes.</data>
  <data key="d7">compiler testing, validation&lt;SEP&gt;compiler, validation</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Data race detection using large language models" target="Study Designs">
  <data key="d5">16.0</data>
  <data key="d6">A 2023 study exploring how LLMs can be used to detect data races in parallel programs.&lt;SEP&gt;Research exploring the application of LLMs to detect data races in parallel code, conducted in 2023.</data>
  <data key="d7">parallel programming, bug detection</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Scope is all you need: Transforming llms for hpc code" target="Research Questions/Hypotheses">
  <data key="d5">14.0</data>
  <data key="d6">A 2023 hypothesis proposing that transforming LLMs can optimize HPC code performance and efficiency.&lt;SEP&gt;Hypothesizes that transforming LLMs can optimize HPC code performance, as proposed in 2023.</data>
  <data key="d7">optimization, HPC</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Modeling parallel programs using large language models" target="Study Designs">
  <data key="d5">16.0</data>
  <data key="d6">A 2024 study applying LLMs to model, simulate, and analyze parallel scientific programs.&lt;SEP&gt;A 2024 study on applying LLMs to model and analyze parallel programs.</data>
  <data key="d7">parallel computing, modeling&lt;SEP&gt;parallel programs, modeling</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Performance-aligned llms for generating fast code" target="Results">
  <data key="d5">18.0</data>
  <data key="d6">A 2024 study demonstrating that aligning LLMs with performance metrics produces faster, more efficient code.&lt;SEP&gt;Demonstrates that aligning LLMs with performance metrics leads to faster code generation, in 2024.</data>
  <data key="d7">performance, code efficiency&lt;SEP&gt;performance, efficiency</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="chathpc" target="Applications/Implications">
  <data key="d5">16.0</data>
  <data key="d6">A 2025 application aimed at empowering HPC users with LLMs to improve supercomputing workflows.&lt;SEP&gt;A 2025 application designed to empower HPC users with LLMs, improving supercomputing workflows and user productivity.</data>
  <data key="d7">HPC, user empowerment&lt;SEP&gt;HPC, user support</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Lassi" target="Tools">
  <data key="d5">14.0</data>
  <data key="d6">An automated pipeline introduced in 2024 for translating parallel scientific codes using LLMs, improving scientific workflows.&lt;SEP&gt;An automated, self-correcting pipeline introduced in 2024 for translating scientific codes using LLMs, enhancing scientific computing workflows.</data>
  <data key="d7">scientific computing, automation</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Ompgpt" target="Tools">
  <data key="d5">14.0</data>
  <data key="d6">A transformer model for OpenMP code, developed in 2024 to facilitate parallel programming.&lt;SEP&gt;A transformer-based model developed in 2024 for OpenMP code, aiding in parallel programming and code generation.</data>
  <data key="d7">parallel programming, code generation</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="A systematic evaluation of large language models of code" target="Evidence Types">
  <data key="d5">18.0</data>
  <data key="d6">A 2022 comprehensive evaluation assessing LLMs' capabilities in code understanding and generation.&lt;SEP&gt;A 2022 study systematically evaluating LLMs' capabilities in code understanding and generation.</data>
  <data key="d7">evaluation, code models</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Biocoder" target="Objects of Study">
  <data key="d5">14.0</data>
  <data key="d6">A benchmark dataset for bioinformatics code generation, used to evaluate models on bioinformatics tasks.&lt;SEP&gt;A benchmark dataset used for evaluating bioinformatics code generation models.</data>
  <data key="d7">bioinformatics, code generation</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Biocoder" target="Reproducibility">
  <data key="d5">6.0</data>
  <data key="d6">Biocoder provides datasets and benchmarks that support reproducibility in bioinformatics code generation research.</data>
  <data key="d7">dataset, validation</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Biocoder" target="Xiong, W">
  <data key="d5">5.0</data>
  <data key="d6">Xiong, W is associated with the development or evaluation of Biocoder, a benchmark for bioinformatics code generation, indicating their role in bioinformatics research.</data>
  <data key="d7">research, bioinformatics</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Weight Decay Regularization in Adam" target="Optimization">
  <data key="d5">7.0</data>
  <data key="d6">A methodology for fixing weight decay regularization issues in the Adam optimizer, proposed in 2017.</data>
  <data key="d7">optimization, regularization</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Large Language Models trained on Code" target="Objects of Study">
  <data key="d5">9.0</data>
  <data key="d6">These models are studied to evaluate their ability to understand, generate, and evaluate programming code, as in 2021.</data>
  <data key="d7">model evaluation, code understanding</data>
  <data key="d8">chunk-9605dfcbeda0fc2efdc5d6c829baafeb</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Verilogeval" target="Results">
  <data key="d5">8.0</data>
  <data key="d6">Verilogeval assesses the performance of language models in generating Verilog code, contributing to understanding model accuracy.</data>
  <data key="d7">evaluation, model performance</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Reproducibility" target="Tools">
  <data key="d5">5.0</data>
  <data key="d6">Reproducibility is supported by providing scripts and datasets, enabling others to replicate the study's results.</data>
  <data key="d7">transparency, validation</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="HPC-Coder-V2 models" target="Results">
  <data key="d5">18.0</data>
  <data key="d6">HPC-Coder-V2 models are evaluated for correctness using ParEval, producing results that measure their performance in code generation tasks.&lt;SEP&gt;These models are evaluated for correctness, providing results that measure their performance in code generation tasks.</data>
  <data key="d7">model evaluation, correctness</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="parallelize the aggregation process" target="Research Questions/Hypotheses">
  <data key="d5">20.0</data>
  <data key="d6">Parallelizing the aggregation process is hypothesized to improve performance in high-performance computing applications, forming the core research question.&lt;SEP&gt;Parallelizing the aggregation process is hypothesized to significantly improve performance in high-performance computing systems, forming the core research question.</data>
  <data key="d7">optimization, performance improvement&lt;SEP&gt;performance optimization, parallel computing</data>
  <data key="d8">chunk-96146f0e8f16426a7bc0a0002ded1479</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="compute_metric" target="aggregate_metrics">
  <data key="d5">18.0</data>
  <data key="d6">The aggregate_metrics function calls compute_metric on each data point to accumulate the total metric value.&lt;SEP&gt;The aggregate_metrics function calls compute_metric on each data point to accumulate total metrics."|</data>
  <data key="d7">function invocation, data processing</data>
  <data key="d8">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="aggregate_metrics" target="sum">
  <data key="d5">20.0</data>
  <data key="d6">The sum variable is updated with the result of compute_metric for each data point, accumulating total metrics."|</data>
  <data key="d7">variable update, accumulation</data>
  <data key="d8">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="aggregate_metrics" target="parallelization">
  <data key="d5">20.0</data>
  <data key="d6">The outer loop of aggregate_metrics is parallelized using OpenMP's parallel for directive, with reduction to safely sum partial results."|</data>
  <data key="d7">parallel for, reduction clause</data>
  <data key="d8">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="data" target="rows">
  <data key="d5">16.0</data>
  <data key="d6">The dataset's rows are iterated over in the outer loop, distributing workload across threads in parallel execution."|</data>
  <data key="d7">dataset iteration, parallelization scope</data>
  <data key="d8">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="data" target="cols">
  <data key="d5">14.0</data>
  <data key="d6">Columns define the inner loop's range, which remains sequential within each thread during parallel execution."|</data>
  <data key="d7">loop control, sequential execution within threads</data>
  <data key="d8">chunk-0e2888ba86c90678f67636c1c02fe25c</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="OpenMP" target="Methodology">
  <data key="d5">8.0</data>
  <data key="d6">OpenMP is used as a parallelization approach in the code translation tasks evaluated in the study.</data>
  <data key="d7">parallel programming, code translation</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="OpenMP" target="Parallel Programming Model">
  <data key="d5">14.0</data>
  <data key="d6">OpenMP is a core concept used as a baseline in the evaluation setup."|&lt;SEP&gt;OpenMP serves as the baseline parallel programming model against which the new tools and approaches are evaluated."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="OpenMP" target="code correctness">
  <data key="d5">14.0</data>
  <data key="d6">OpenMP generally produces higher correctness levels in code suggestions, especially for simpler kernels like AXPY.&lt;SEP&gt;OpenMP generally yields higher correctness levels in code suggestions compared to other models, especially for simpler kernels like AXPY.</data>
  <data key="d7">model performance, code accuracy</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenMP" target="Fortran">
  <data key="d5">16.0</data>
  <data key="d6">OpenMP provides better results for Fortran code due to its maturity and legacy status, making it a preferred parallelization approach in this language.</data>
  <data key="d7">parallel programming, legacy support</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenMP" target="Multi-core CPUs">
  <data key="d5">7.0</data>
  <data key="d6">OpenMP enables shared-memory parallelism on multi-core CPUs, improving computational efficiency.</data>
  <data key="d7">parallelization, multi-core processing</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenMP" target="OpenMP Architecture Review Board">
  <data key="d5">8.0</data>
  <data key="d6">The OpenMP Architecture Review Board oversees the OpenMP API, which facilitates shared-memory parallel programming.</data>
  <data key="d7">standardization, parallel programming</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Phind-V2-34B" target="Execution Model">
  <data key="d5">18.0</data>
  <data key="d6">Phind-V2-34B is evaluated under different execution models, demonstrating its robustness in various computational environments.&lt;SEP&gt;Phind-V2-34B is evaluated under various parallel execution models, showing robustness in different high-performance computing setups.</data>
  <data key="d7">system robustness, parallel frameworks</data>
  <data key="d8">chunk-727ea750122a5bed30ad781918446611</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Models" target="Applications/Implications">
  <data key="d5">7.0</data>
  <data key="d6">The fine-tuned HPC code LLMs are valuable for HPC developers and future research in code generation for high-performance computing.</data>
  <data key="d7">practical impact, future research</data>
  <data key="d8">chunk-cdd832b6a605bd8b46aec4e0615ea5df</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="Models" target="Scaling language modeling with pathways">
  <data key="d5">7.0</data>
  <data key="d6">A framework or model that involves scaling language models using pathways for enhanced capabilities.</data>
  <data key="d7">model, scaling, pathways</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Models" target="Knowledge-Intensive Tasks">
  <data key="d5">8.0</data>
  <data key="d6">Combining parametric and non-parametric memory in RAG models improves performance on knowledge-intensive tasks.</data>
  <data key="d7">performance, knowledge access</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Models" target="Supervision Signals">
  <data key="d5">13.0</data>
  <data key="d6">Many models operate without supervision on retrieved evidence, broadening their applicability in real-world tasks.&lt;SEP&gt;Many models, including RAG, can operate without supervision on retrieved evidence, broadening their applicability in real-world scenarios.</data>
  <data key="d7">training signals, applicability&lt;SEP&gt;training, applicability</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Models" target="Results">
  <data key="d5">16.0</data>
  <data key="d6">Models like RAG and variants achieve state-of-the-art results on benchmarks such as FEVER, MS-MARCO, and open-domain QA datasets.&lt;SEP&gt;The models discussed, especially RAG, achieve state-of-the-art results on various benchmarks, indicating their high performance.</data>
  <data key="d7">performance, benchmarks</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Models" target="Prompts">
  <data key="d5">16.0</data>
  <data key="d6">Prompts are instructions used to elicit code generation from models across different execution paradigms."|</data>
  <data key="d7">prompt engineering, code generation</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="Research Questions/Hypotheses">
  <data key="d5">14.0</data>
  <data key="d6">The core hypothesis is that different LLMs vary in their effectiveness at generating parallel code."|</data>
  <data key="d7">model comparison, research hypothesis</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="performance comparison">
  <data key="d5">19.0</data>
  <data key="d6">Different models are compared based on their pass@k scores across various parallel execution models, highlighting strengths and weaknesses.&lt;SEP&gt;Different models are ranked based on their pass@k scores across various parallel execution models, highlighting their strengths and weaknesses."|"&lt;benchmarking, model evaluation</data>
  <data key="d7">10&lt;SEP&gt;model evaluation, benchmarking</data>
  <data key="d8">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="Figure 7">
  <data key="d5">16.0</data>
  <data key="d6">Figure 7 illustrates the efficiency@1 for MPI, OpenMP, and Kokkos prompts across different models, showing performance trends.&lt;SEP&gt;Figure 7 visualizes efficiency@1 across models and thread counts, illustrating performance differences and trends in parallel code execution.</data>
  <data key="d7">performance visualization, comparative analysis&lt;SEP&gt;performance visualization, model comparison</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="Figure 6">
  <data key="d5">16.0</data>
  <data key="d6">Figure 6 compares pass@1 scores and speedup metrics, highlighting GPT-4's high speedup but low efficiency, emphasizing performance trade-offs.&lt;SEP&gt;Figure 6 compares pass@1 scores and speedups, highlighting GPT-4's superior performance in parallel code generation.</data>
  <data key="d7">performance comparison, efficiency&lt;SEP&gt;performance comparison, efficiency analysis</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="Figure 8">
  <data key="d5">14.0</data>
  <data key="d6">Figure 8 shows the maximum expected speedup and efficiency across resource counts, illustrating scalability and resource utilization.&lt;SEP&gt;Figure 8 shows the maximum expected speedup and efficiency across resource counts, illustrating the scalability of models.</data>
  <data key="d7">scalability, efficiency analysis&lt;SEP&gt;scalability, resource efficiency</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="Experiment 2">
  <data key="d5">18.0</data>
  <data key="d6">An experiment designed to assess the translation ability of LLMs between different parallel execution models and their performance/scalability outcomes."|&gt;"study focus, evaluation of translation capabilities&lt;SEP&gt;The experiment assesses how well LLMs translate between execution models and their performance/scalability.</data>
  <data key="d7">9&lt;SEP&gt;study focus, translation capability</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="pass@1 scores">
  <data key="d5">18.0</data>
  <data key="d6">Pass@1 scores are used as metrics to evaluate the correctness of code translation tasks.&lt;SEP&gt;Pass@1 scores serve as the primary performance metric to evaluate the correctness of code translation by LLMs.</data>
  <data key="d7">evaluation metric, performance measurement&lt;SEP&gt;performance measurement, correctness</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Models" target="Downstream Task Learning">
  <data key="d5">8.0</data>
  <data key="d6">Downstream task learning involves training models on specific datasets to improve task performance, but it is resource-intensive and complex.</data>
  <data key="d7">training, specialization</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Models" target="Impact analysis">
  <data key="d5">8.0</data>
  <data key="d6">Impact analysis is performed to understand how models' properties and behaviors influence safety and societal impact.</data>
  <data key="d7">safety assessment, impact evaluation</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Models" target="risk mitigation">
  <data key="d5">7.0</data>
  <data key="d6">Implementing risk mitigation strategies is essential to reduce safety risks associated with models.</data>
  <data key="d7">risk reduction, safety practices</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Models" target="Section VI-B">
  <data key="d5">7.0</data>
  <data key="d6">The section evaluates the models' ability to predict OpenMP pragmas, testing their understanding of parallelization constructs."|</data>
  <data key="d7">research methodology, evaluation</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Implications" target="model safety">
  <data key="d5">10.0</data>
  <data key="d6">The findings on bias have implications for the safety and fairness of deploying such models, indicating a consequential relationship."|</data>
  <data key="d7">10</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Implications" target="Demographic Patterns of Python Users">
  <data key="d5">12.0</data>
  <data key="d6">Demographic data on Python users helps understand how AI tools like Codex impact different social groups and programming roles.&lt;SEP&gt;Understanding demographic patterns helps assess how AI tools like Codex affect different societal groups and roles in programming.</data>
  <data key="d7">social impact, skill distribution</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="training data" target="code complexity">
  <data key="d5">8.0</data>
  <data key="d6">Limited exposure to niche or verbose parallel programming paradigms like Kokkos can hinder models' ability to generate correct code."|"&lt;training data, model capability</data>
  <data key="d7">8</data>
  <data key="d8">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="training data" target="self-instruct demonstrations">
  <data key="d5">6.0</data>
  <data key="d6">Self-instruct demonstrations are used as training data or instructions to guide models in learning specific tasks or behaviors."|&lt;"relationship</data>
  <data key="d7">6</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="model performance" target="dataset of human-written problems">
  <data key="d5">18.0</data>
  <data key="d6">Model performance is evaluated based on how well it generates correct code for problems in the dataset.&lt;SEP&gt;Model performance is measured by how well the models generate correct code for the problems in the dataset.</data>
  <data key="d7">evaluation, accuracy</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="model performance" target="producing docstrings from code bodies">
  <data key="d5">14.0</data>
  <data key="d6">Models trained on code can generate descriptive docstrings, demonstrating understanding of code semantics.&lt;SEP&gt;Models trained to produce docstrings from code demonstrate versatility in understanding code semantics.</data>
  <data key="d7">reverse task, model capability</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="model performance" target="pre-training dataset">
  <data key="d5">7.0</data>
  <data key="d6">The quality and curation of the pre-training dataset influence the model's ability to generate high-quality, secure code."|</data>
  <data key="d7">dataset quality, training data</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="performance" target="13b variant">
  <data key="d5">8.0</data>
  <data key="d6">The 13b variant is shown to be competitive with larger models despite not using human reasoning chains.".</data>
  <data key="d7">model performance, competitiveness</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="performance" target="Models evaluated for their accuracy and effectiveness on benchmarks like GSM8K and HotPotQA.&quot;.">
  <data key="d5">7.0</data>
  <data key="d6">model evaluation, benchmark performance</data>
  <data key="d7">7</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="performance" target="Benchmarks">
  <data key="d5">9.0</data>
  <data key="d6">Benchmarks are designed to evaluate the performance of LLMs in generating parallel code, covering various computational problem types and execution models.</data>
  <data key="d7">9</data>
  <data key="d8">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance" target="state-of-the-art LLMs">
  <data key="d5">7.0</data>
  <data key="d6">The effectiveness of current models is measured by their success rates and scalability metrics on the ParEval benchmark.</data>
  <data key="d7">7</data>
  <data key="d8">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance" target="research questions">
  <data key="d5">8.0</data>
  <data key="d6">The research questions aim to understand the capabilities and limitations of LLMs in parallel code generation and translation.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-ecf1af014959d2db25d1a41ffd04a15c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance" target="Results">
  <data key="d5">16.0</data>
  <data key="d6">Overall performance encompasses correctness, efficiency, and scalability of the generated parallel code.&lt;SEP&gt;The models' overall ability to generate correct parallel code and improve translation accuracy, with performance metrics reflecting strengths and weaknesses."|&gt;"performance outcomes, accuracy</data>
  <data key="d7">8&lt;SEP&gt;code quality, evaluation metrics</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7&lt;SEP&gt;chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="results" target="performance comparison">
  <data key="d5">9.0</data>
  <data key="d6">HPC-Coder-V2 models outperform some existing models like StarCoder2-3B and Phind-V2-34B in parallel code generation, demonstrating competitiveness.</data>
  <data key="d7">model comparison, performance advantage</data>
  <data key="d8">chunk-aec2ac03d71774b2a191de2c6ebcd45e</data>
  <data key="d9">Chaturvedi et al. - 2024 - HPC-Coder-V2 Studying Code LLMs Across Low-Resource Parallel Languages.pdf</data>
</edge>
<edge source="results" target="accuracy">
  <data key="d5">8.0</data>
  <data key="d6">Accuracy measures whether the generated code produces correct outputs, directly reflecting code quality.</data>
  <data key="d7">quality, correctness</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="results" target="correctness">
  <data key="d5">8.0</data>
  <data key="d6">Correctness assesses whether the generated code functions as intended without errors, crucial for evaluating code effectiveness.</data>
  <data key="d7">validation, reliability</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="results" target="model evaluation">
  <data key="d5">19.0</data>
  <data key="d6">Evaluation metrics like perplexity and accuracy determine the effectiveness of fine-tuning and model readiness.</data>
  <data key="d7">performance assessment, results</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Objects of Study">
  <data key="d5">17.0</data>
  <data key="d6">Objects of Study are defined based on the Research Questions or Hypotheses.&lt;SEP&gt;Objects of Study are defined based on the research questions or hypotheses.&lt;SEP&gt;Research Questions/Hypotheses are formulated based on Objects of Study to specify what is being investigated.</data>
  <data key="d7">research focus, investigation target&lt;SEP&gt;study focus, inquiry scope</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="CodeLlama-7B">
  <data key="d5">14.0</data>
  <data key="d6">Investigates how providing correct implementations influences the translation accuracy and performance of this smaller LLM.&lt;SEP&gt;Investigates the impact of providing correct implementation examples on LLM performance in parallel code generation.</data>
  <data key="d7">training data, performance impact&lt;SEP&gt;training data, performance improvement</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="CodeLlama-13B">
  <data key="d5">8.0</data>
  <data key="d6">Evaluates the effectiveness of a larger LLM in translating complex parallel code and its performance benefits.</data>
  <data key="d7">model capacity, code quality</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Wasi Uddin Ahmad et al.">
  <data key="d5">8.0</data>
  <data key="d6">Investigate transformer-based models for source code summarization."|&gt;"research, code summarization</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Toufique Ahmed and Prem Devanbu">
  <data key="d5">7.0</data>
  <data key="d6">Explore learning techniques for code summarization from small datasets."|&gt;"research, data efficiency</data>
  <data key="d7">7</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Jacob Austin et al.">
  <data key="d5">8.0</data>
  <data key="d6">Study program synthesis using large language models."|&gt;"research, program synthesis</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Tom B. Brown et al.">
  <data key="d5">8.0</data>
  <data key="d6">Assess large language models' capabilities as few-shot learners."|&gt;"research, few-shot learning</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Data Race Detection Using Large Language Models">
  <data key="d5">8.0</data>
  <data key="d6">Investigate applying language models to detect data races in concurrent code."|&gt;"research, concurrency, code analysis</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Mark Chen and et al.">
  <data key="d5">8.0</data>
  <data key="d6">Evaluate large language models trained on code datasets."|&gt;"research, model evaluation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Optimization Objectives">
  <data key="d5">7.0</data>
  <data key="d6">The objectives include minimizing synchronization, data transfer, execution time, and resource usage to enhance overall performance.</data>
  <data key="d7">performance goals, hypotheses</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Model capability">
  <data key="d5">16.0</data>
  <data key="d6">The research hypothesizes that models like Codex can effectively generate correct code from natural language descriptions, with performance improving through techniques like fine-tuning and multiple sampling.</data>
  <data key="d7">research focus, hypothesis</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Performance Prediction">
  <data key="d5">9.0</data>
  <data key="d6">The study hypothesizes that fine-tuned LLMs can accurately predict code performance slowdowns between code versions.</data>
  <data key="d7">performance forecasting, model evaluation</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Research Questions/Hypotheses" target="Performance Slowdown Prediction">
  <data key="d5">9.0</data>
  <data key="d6">The study hypothesizes that fine-tuned LLMs can accurately predict whether code modifications will lead to slower execution.</data>
  <data key="d7">performance forecasting, model validation</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Theories/Models" target="DSPy">
  <data key="d5">8.0</data>
  <data key="d6">DSPy's core premise is that module composition rather than prompt engineering is key to enhancing reasoning.</data>
  <data key="d7">theoretical basis, module composition</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Theories/Models" target="Dense Passage Retrieval for Open-Domain Question Answering">
  <data key="d5">9.0</data>
  <data key="d6">DPR is a dense retrieval technique that improves open-domain question answering by retrieving relevant passages using dense vector representations.</data>
  <data key="d7">retrieval technique, QA systems</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="Generalization through Memorization">
  <data key="d5">8.0</data>
  <data key="d6">This concept explains how language models can memorize information to improve their ability to generalize to new data.</data>
  <data key="d7">concept, model behavior</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="Addressing semantic drift in question generation for semi-supervised question answering">
  <data key="d5">8.0</data>
  <data key="d6">The study proposes models to address semantic drift in question generation.</data>
  <data key="d7">model, semantic stability</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="Reasoning over semantic-level graph for fact checking">
  <data key="d5">8.0</data>
  <data key="d6">Employs semantic graphs as models for reasoning and fact verification.</data>
  <data key="d7">model, reasoning</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Theories/Models" target="Core Concepts">
  <data key="d5">8.0</data>
  <data key="d6">Core Concepts underpin the development of Theories/Models, providing foundational ideas that inform their structure and assumptions.</data>
  <data key="d7">conceptual foundation, theoretical framework</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Theories/Models" target="Transformer-based Approach">
  <data key="d5">9.0</data>
  <data key="d6">A model leveraging transformer architecture to improve source code summarization."|&gt;"model architecture, source code</data>
  <data key="d7">9</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Theories/Models" target="Language Models as Few-Shot Learners">
  <data key="d5">9.0</data>
  <data key="d6">Concept that large language models can perform various tasks with minimal training data."|&gt;"model capability, training efficiency</data>
  <data key="d7">9</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Theories/Models" target="LP-based global optimization">
  <data key="d5">7.0</data>
  <data key="d6">The current approach under assessment for issues and potential improvements."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Theories/Models" target="Polyhedral compilers">
  <data key="d5">8.0</data>
  <data key="d6">They focus on optimizing nested loop structures and data access patterns, often used in high-performance code."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Theories/Models" target="Parallel Patterns">
  <data key="d5">8.0</data>
  <data key="d6">Parallel patterns are abstract models that define how computations are structured and executed in parallel, enabling optimization strategies.</data>
  <data key="d7">parallelism, modeling</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Theories/Models" target="Optimization">
  <data key="d5">16.0</data>
  <data key="d6">Optimization strategies are based on models that identify parallelism potential and ensure semantic correctness according to MILP constraints.&lt;SEP&gt;Optimization strategies are based on models that recognize parallelism potential and adhere to MILP semantics to generate correct, efficient code.</data>
  <data key="d7">parallelism, correctness</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Theories/Models" target="Systematic Taxonomy">
  <data key="d5">16.0</data>
  <data key="d6">A taxonomy categorizes domain specialization techniques based on their accessibility and methodological framework, guiding research and application.&lt;SEP&gt;A taxonomy categorizes domain specialization techniques based on their accessibility and methodological frameworks, guiding research and application."|"&lt;classification, framework</data>
  <data key="d7">8&lt;SEP&gt;classification, framework</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Theories/Models" target="Colin Raffel">
  <data key="d5">18.0</data>
  <data key="d6">Explores transfer learning limits with a unified text-to-text transformer, contributing to foundational ML theories."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Theories/Models" target="Ori Ram">
  <data key="d5">16.0</data>
  <data key="d6">Develops retrieval-augmented language models, enhancing contextual understanding and knowledge retrieval."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Theories/Models" target="Adam Roberts">
  <data key="d5">16.0</data>
  <data key="d6">Studies the knowledge capacity of language models, contributing to understanding model parameterization."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Theories/Models" target="Victor Sanh">
  <data key="d5">18.0</data>
  <data key="d6">Develops multitask prompted training for zero-shot task generalization, contributing to model training theories."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Theories/Models" target="Dale Schuurmans">
  <data key="d5">18.0</data>
  <data key="d6">Shows that memory-augmented large language models are computationally universal, contributing to theoretical understanding."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Theories/Models" target="Methodologies">
  <data key="d5">16.0</data>
  <data key="d6">Theories or Models often guide the development or selection of Methodologies in research to ensure appropriate frameworks are used.&lt;SEP&gt;Theories or Models often inform the choice of methodologies used in research to ensure appropriate approaches are applied.</data>
  <data key="d7">theoretical foundation, methodological guidance&lt;SEP&gt;theoretical guidance, methodological design</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Theories/Models" target="Disciplines">
  <data key="d5">14.0</data>
  <data key="d6">Disciplines develop and utilize Theories or Models to understand phenomena within their scope.&lt;SEP&gt;Disciplines often develop and utilize theories or models to understand phenomena within their scope.</data>
  <data key="d7">conceptual frameworks, disciplinary theories</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Theories/Models" target="Left-to-Right Models">
  <data key="d5">16.0</data>
  <data key="d6">Left-to-right models generate sequences sequentially, predicting the next token based on prior tokens, suitable for natural language and code generation tasks.&lt;SEP&gt;Left-to-right models generate text sequentially, predicting the next token based on previous tokens, suitable for natural language and code generation.</data>
  <data key="d7">sequential prediction, generation&lt;SEP&gt;sequential prediction, natural language tasks</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Theories/Models" target="Masked Models">
  <data key="d5">14.0</data>
  <data key="d6">Masked models predict tokens at masked positions, allowing bidirectional context use and better understanding of the entire sequence.&lt;SEP&gt;Masked models predict tokens at randomly masked positions, enabling bidirectional context use and improved understanding of the entire sequence.</data>
  <data key="d7">bidirectional context, prediction</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Theories/Models" target="Encoder-Decoder Models">
  <data key="d5">14.0</data>
  <data key="d6">Encoder-decoder models encode input sequences and generate output sequences, enabling tasks like translation and code conversion.&lt;SEP&gt;Encoder-decoder models encode input sequences and generate output sequences, useful for tasks like translation and code conversion.</data>
  <data key="d7">sequence-to-sequence, translation</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Results" target="Benchmark Numbers and Qualitative Measures">
  <data key="d5">16.0</data>
  <data key="d6">Empirical results demonstrate DSPy’s capability to build high-quality LM systems, validated through benchmarks and qualitative assessments.&lt;SEP&gt;Empirical results demonstrate DSPy’s effectiveness in constructing high-performance LM systems, validated through benchmarks and qualitative assessments."|&gt;"evaluation, validation</data>
  <data key="d7">8&lt;SEP&gt;evaluation, performance validation</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Results" target="Zero-Shot Evaluation">
  <data key="d5">7.0</data>
  <data key="d6">Zero-shot evaluation provides a baseline that shows significant improvements when compilation strategies are applied.</data>
  <data key="d7">baseline, performance comparison</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Results" target="GSM8K Dataset">
  <data key="d5">6.0</data>
  <data key="d6">The dataset serves as the benchmark for evaluating the effectiveness of different compilation and prompting strategies.</data>
  <data key="d7">evaluation, benchmark</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Results" target="GPT-3.5 and Llama2-13B-Chat">
  <data key="d5">8.0</data>
  <data key="d6">These models' performance is improved through DSPy compilation, approaching or surpassing previous benchmarks.</data>
  <data key="d7">performance, model evaluation</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Results" target="Human Reasoning Chains (humanCoT)">
  <data key="d5">9.0</data>
  <data key="d6">Incorporating human reasoning chains boosts model accuracy significantly, demonstrating the value of human-in-the-loop data.</data>
  <data key="d7">training data, performance boost</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Results" target="Large language models can self-improve">
  <data key="d5">9.0</data>
  <data key="d6">Indicates that large language models possess self-improvement capabilities.</data>
  <data key="d7">self-improvement, AI capability</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Results" target="Generation and Classification Test Scores">
  <data key="d5">7.0</data>
  <data key="d6">Performance metrics indicating the effectiveness of models like RAG on various datasets and tasks.</data>
  <data key="d7">evaluation, performance</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Results" target="Open-domain QA">
  <data key="d5">16.0</data>
  <data key="d6">Applying RAG models results in state-of-the-art performance on open-domain question answering benchmarks.&lt;SEP&gt;The application of RAG models leads to improved results in open-domain question answering tasks, demonstrating their effectiveness.</data>
  <data key="d7">performance, evaluation</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Results" target="Model Comparisons">
  <data key="d5">8.0</data>
  <data key="d6">Comparative analysis of models' correctness and efficiency metrics to identify the best-performing models.</data>
  <data key="d7">benchmarking, performance analysis</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="performance of a sequential baseline">
  <data key="d5">8.0</data>
  <data key="d6">The baseline performance provides a reference point for calculating speedup and efficiency."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Evidence Types">
  <data key="d5">20.0</data>
  <data key="d6">Results are derived from data classified into different Evidence Types.&lt;SEP&gt;Results are supported by various Evidence Types collected or generated during the research process.&lt;SEP&gt;Results provide evidence that can be classified into different evidence types, such as qualitative or quantitative data.</data>
  <data key="d7">data outcomes, proof&lt;SEP&gt;data support, empirical evidence</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="Study Populations/Dataset">
  <data key="d5">8.0</data>
  <data key="d6">Results are derived from analyses conducted on the Study Populations or Datasets.</data>
  <data key="d7">data analysis, sample data</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Applications/Implications">
  <data key="d5">8.0</data>
  <data key="d6">Results inform Applications and Implications, translating findings into practical or theoretical advancements.</data>
  <data key="d7">practical application, knowledge transfer</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Speedup@k">
  <data key="d5">8.0</data>
  <data key="d6">Speedup@k quantifies the performance improvement at different process or thread counts.</data>
  <data key="d7">performance measurement, scalability</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Efficiency@k">
  <data key="d5">8.0</data>
  <data key="d6">Efficiency@k assesses resource utilization effectiveness at various parallelism levels.</data>
  <data key="d7">resource efficiency, parallel performance</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="speedup n@1">
  <data key="d5">8.0</data>
  <data key="d6">speedup n@1 measures how well the generated code scales and performs in parallel execution contexts.</data>
  <data key="d7">performance, scalability</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="efficiency@1">
  <data key="d5">8.0</data>
  <data key="d6">Efficiency@1 measures the relative performance or speedup of generated code, indicating effectiveness in execution.</data>
  <data key="d7">performance, scalability</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="speedup@1">
  <data key="d5">8.0</data>
  <data key="d6">Speedup@1 assesses how well the code scales with increasing resources or problem size, reflecting performance gains.</data>
  <data key="d7">scalability, performance</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="correctness">
  <data key="d5">8.0</data>
  <data key="d6">Correctness measures the functional accuracy of the generated code in implementing parallel algorithms.</data>
  <data key="d7">accuracy, functional correctness</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="scalability">
  <data key="d5">8.0</data>
  <data key="d6">Scalability assesses how the code performs as problem size or resources increase, indicating robustness.</data>
  <data key="d7">performance scaling, robustness</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Results" target="Measurement methodology">
  <data key="d5">16.0</data>
  <data key="d6">The methodology involves manual timing, multiple repetitions, and avoiding artificial dependencies to ensure accurate performance measurement.&lt;SEP&gt;The methodology involves manual timing, multiple repetitions, and avoiding artificial synchronization points to ensure measurement accuracy and reproducibility.</data>
  <data key="d7">measurement procedure, data collection method</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="Generator Results">
  <data key="d5">16.0</data>
  <data key="d6">Performance outcomes comparing different code versions across kernels, highlighting speedups and slowdowns.&lt;SEP&gt;The performance data comparing different code versions (naive, handwritten, generated) across various kernels, highlighting speedups, slowdowns, and stability issues.</data>
  <data key="d7">performance analysis, experimental results</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="Performance measurements">
  <data key="d5">16.0</data>
  <data key="d6">Quantitative runtime data collected over multiple runs, used to compare code versions and configurations, providing metrics like execution time and speedup.&lt;SEP&gt;Quantitative runtime data used to assess code performance and compare configurations.</data>
  <data key="d7">performance metrics, data analysis</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="Speedups and slowdowns">
  <data key="d5">16.0</data>
  <data key="d6">Metrics indicating relative performance improvements or regressions, used to assess effectiveness of optimizations.&lt;SEP&gt;Metrics indicating relative performance improvements or regressions.</data>
  <data key="d7">performance metrics, efficiency indicators</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Results" target="Proficiency Metric">
  <data key="d5">14.0</data>
  <data key="d6">The metric provides quantitative evaluation of AI-generated code suggestions, guiding improvements.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Results" target="Benchmarking">
  <data key="d5">6.0</data>
  <data key="d6">Benchmarking results compare AI-generated code performance against standards, informing future improvements.</data>
  <data key="d7">performance evaluation, standards</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Results" target="kernel complexity">
  <data key="d5">18.0</data>
  <data key="d6">Higher kernel complexity reduces the likelihood of correct code generation by AI models, indicating a relationship between problem difficulty and output accuracy."|&gt;"complexity, correctness&lt;SEP&gt;Higher kernel complexity reduces the success rate of correct code generation by AI models, indicating a direct relationship between complexity and accuracy."|&gt;"complexity, correctness</data>
  <data key="d7">9</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Results" target="Popularity or Accessibility of Programming Languages">
  <data key="d5">10.0</data>
  <data key="d6">While popularity or accessibility can influence results, less popular languages may still yield good results due to their targeted nature, indicating a nuanced relationship.&lt;SEP&gt;While popularity or accessibility of programming languages influences results, less popular languages can also produce good results due to their targeted nature, showing a nuanced relationship.</data>
  <data key="d7">language popularity, result quality&lt;SEP&gt;language prominence, result effectiveness</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Results" target="Security of GitHub Copilot">
  <data key="d5">9.0</data>
  <data key="d6">Studies have found potential security vulnerabilities in AI-generated code contributions from GitHub Copilot.</data>
  <data key="d7">security risks, vulnerabilities</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Results" target="Evaluation">
  <data key="d5">8.0</data>
  <data key="d6">Performance assessments show that advanced prompting techniques can substantially enhance LLM reasoning and task execution.</data>
  <data key="d7">assessment, model capabilities</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Results" target="Arya Rao">
  <data key="d5">14.0</data>
  <data key="d6">Evaluates ChatGPT as an adjunct for radiologic decision-making, providing evidence of AI utility in healthcare."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Results" target="Joshua Robinson">
  <data key="d5">16.0</data>
  <data key="d6">Leverages large language models for multiple-choice question answering, demonstrating application results."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Results" target="Methods">
  <data key="d5">16.0</data>
  <data key="d6">The training methodology, including optimizer settings and tokenizer modifications, directly impacts Codex's performance and scaling behavior.</data>
  <data key="d7">training methodology, performance outcomes</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="Tools">
  <data key="d5">14.0</data>
  <data key="d6">Results</data>
  <data key="d7">The results demonstrate the effectiveness of tools like the tokenizer and sampling strategies in improving code generation performance.</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="Variables">
  <data key="d5">12.0</data>
  <data key="d6">Variables such as model size and sampling temperature influence the performance metrics obtained in experiments.</data>
  <data key="d7">experimental variables, performance metrics</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="Analytical Techniques">
  <data key="d5">26.0</data>
  <data key="d6">Analytical Techniques are applied to data to generate results.&lt;SEP&gt;Analytical Techniques are applied to data to produce the Results.&lt;SEP&gt;Analytical techniques like measuring test loss and pass@k provide insights into model performance and scaling behavior.</data>
  <data key="d7">data analysis, outcome derivation&lt;SEP&gt;data analysis, outcome generation&lt;SEP&gt;performance analysis, evaluation methods</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e&lt;SEP&gt;chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="Study Designs">
  <data key="d5">14.0</data>
  <data key="d6">Study Designs determine how data is collected and analyzed, leading to the Results obtained.&lt;SEP&gt;Study Designs determine how results are obtained and interpreted, linking the planning phase to the outcomes.</data>
  <data key="d7">research planning, data collection&lt;SEP&gt;research planning, outcome generation</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Results" target="Prediction accuracy">
  <data key="d5">9.0</data>
  <data key="d6">The accuracy of models in predicting code performance slowdown or speedup demonstrates their effectiveness in performance forecasting.</data>
  <data key="d7">performance metrics, model effectiveness</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Objects of Study" target="The Dark Heroine">
  <data key="d5">5.0</data>
  <data key="d6">The Dark Heroine is a contemporary vampire-themed fantasy romance novel series that exemplifies modern genre themes, contrasting with Victorian media."|"&lt;media, genre contrast</data>
  <data key="d7">5</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Objects of Study" target="The Victorian (comics)">
  <data key="d5">6.0</data>
  <data key="d6">The Victorian comic book series visually and thematically explores Victorian themes, illustrating media influence."|"&lt;media, historical influence</data>
  <data key="d7">6</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Objects of Study" target="The Caxtons">
  <data key="d5">4.0</data>
  <data key="d6">The Victorian novel 'The Caxtons' exemplifies Victorian literature and provides historical context for Victorian cultural studies."|"&lt;literature, era</data>
  <data key="d7">4</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Objects of Study" target="Jeopardy Question Generation">
  <data key="d5">6.0</data>
  <data key="d6">A task designed to evaluate models' ability to generate Jeopardy-style questions.</data>
  <data key="d7">task, evaluation</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Objects of Study" target="MS-MARCO">
  <data key="d5">6.0</data>
  <data key="d6">A dataset used for evaluating question answering models, especially for information retrieval and ranking.</data>
  <data key="d7">dataset, evaluation</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Objects of Study" target="FVR3 (FEVER 3)">
  <data key="d5">6.0</data>
  <data key="d6">A dataset or variant used for model evaluation in fact verification.</data>
  <data key="d7">dataset, evaluation</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Objects of Study" target="FVR2 (FEVER 2)">
  <data key="d5">6.0</data>
  <data key="d6">Another dataset or variant for evaluating fact verification models.</data>
  <data key="d7">dataset, evaluation</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Objects of Study" target="Knowledge Base">
  <data key="d5">9.0</data>
  <data key="d6">Wikipedia functions as a comprehensive external knowledge base used to support factual grounding in models.</data>
  <data key="d7">knowledge base, external source</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Objects of Study" target="Prompt">
  <data key="d5">16.0</data>
  <data key="d6">A prompt is an individual text input to an LLM for code generation, which is then tested for correctness.</data>
  <data key="d7">test input, code generation</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="Problem">
  <data key="d5">16.0</data>
  <data key="d6">A set of tasks or prompts testing the LLM's ability to generate code for the same computational work with different execution models.&lt;SEP&gt;A set of tasks or prompts testing the ability of an LLM to generate code for the same computational work, possibly with different execution models.</data>
  <data key="d7">test set, computational ability</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="Problem Type">
  <data key="d5">16.0</data>
  <data key="d6">A category of problems testing similar computational tasks, such as sorting, graph algorithms, or linear algebra, used within the benchmark."|&gt;"problem categorization, evaluation scope&lt;SEP&gt;A category of problems, such as sorting or graph algorithms, used within the benchmark to test specific capabilities.</data>
  <data key="d7">8&lt;SEP&gt;problem categorization, evaluation scope</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="OpenMP, MPI, MPI+OpenMP, Kokkos, CUDA, HIP">
  <data key="d5">16.0</data>
  <data key="d6">These execution models are the focus of the code translation experiments, testing the models' ability to translate code between them.&lt;SEP&gt;These execution models are the focus of the translation experiments, serving as the source and target models for translation tasks.</data>
  <data key="d7">code translation, execution models</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="Serial results">
  <data key="d5">16.0</data>
  <data key="d6">Serial execution outputs serve as baseline results for comparison against parallel implementations in the evaluation.&lt;SEP&gt;Serial results serve as baseline outputs for comparison with parallel implementations.</data>
  <data key="d7">baseline comparison, performance evaluation&lt;SEP&gt;baseline, performance comparison</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="Pairs: serial→OpenMP, serial→MPI, CUDA→Kokkos">
  <data key="d5">16.0</data>
  <data key="d6">Specific translation pairs evaluated for model performance in the experiment.&lt;SEP&gt;Specific translation pairs tested to analyze model performance and translation accuracy.</data>
  <data key="d7">translation pairs, relevance</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="parallel code">
  <data key="d5">16.0</data>
  <data key="d6">Parallel code is the subject of performance evaluation, specifically regarding how it makes use of resources."|&lt;SEP&gt;The generated or translated code used to evaluate model performance in parallel programming contexts."|&gt;"evaluation objects, code quality</data>
  <data key="d7">8</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7&lt;SEP&gt;chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="resources">
  <data key="d5">8.0</data>
  <data key="d6">Resources such as processes or threads are used to execute parallel code."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="hardware cores">
  <data key="d5">7.0</data>
  <data key="d6">Hardware cores are physical units that serve as the fundamental resources for parallel processing."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="prompt">
  <data key="d5">7.0</data>
  <data key="d6">A prompt is an input to the model, whose runtime performance is analyzed."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="set of resource counts">
  <data key="d5">8.0</data>
  <data key="d6">The collection of different resource numbers over which experiments are performed, affecting scalability analysis."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="procs">
  <data key="d5">8.0</data>
  <data key="d6">Set of resource counts used to evaluate maximum speedup across hardware configurations."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="Spatiotemporal Information">
  <data key="d5">19.0</data>
  <data key="d6">Spatiotemporal Information describes the spatial and temporal aspects of the Objects of Study, providing contextual data.&lt;SEP&gt;Spatiotemporal Information pertains to the objects of study, providing context such as location and time.&lt;SEP&gt;Spatiotemporal Information provides context for Objects of Study, such as location and time.</data>
  <data key="d7">contextual data, environmental factors&lt;SEP&gt;contextual data, spatial-temporal context</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe&lt;SEP&gt;chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf&lt;SEP&gt;Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Objects of Study" target="serial to OpenMP">
  <data key="d5">9.0</data>
  <data key="d6">A specific translation task used to evaluate LLMs' ability to convert serial code into OpenMP parallel code."|&gt;"task evaluation, translation capability</data>
  <data key="d7">9</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="serial to MPI">
  <data key="d5">9.0</data>
  <data key="d6">A translation task assessing LLMs' ability to convert serial code into MPI parallel code."|&gt;"task evaluation, translation capability</data>
  <data key="d7">9</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="CUDA to Kokkos">
  <data key="d5">9.0</data>
  <data key="d6">A translation task to evaluate LLMs' ability to convert CUDA code into Kokkos code."|&gt;"task evaluation, translation capability</data>
  <data key="d7">9</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="SantaCoder">
  <data key="d5">8.0</data>
  <data key="d6">A neural code generation model designed for code synthesis tasks."|&gt;"model, code generation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Objects of Study" target="Single CPU Node">
  <data key="d5">6.0</data>
  <data key="d6">The baseline configuration for performance comparison, representing a single-node setup."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Distributed setup with CPUs and GPUs">
  <data key="d5">6.0</data>
  <data key="d6">A more complex hardware configuration used to evaluate scalability and performance of the approach."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Abstract Pattern Tree (APT)">
  <data key="d5">8.0</data>
  <data key="d6">A data structure used for representing code patterns and enabling optimizations such as inlining and unrolling."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Rodinia benchmark suite">
  <data key="d5">8.0</data>
  <data key="d6">A set of benchmark kernels used to evaluate the performance and correctness of the tool/concept."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Shared Memory">
  <data key="d5">8.0</data>
  <data key="d6">Shared memory systems allow multiple processing units to access common memory spaces, enabling pattern-independent read/write operations.</data>
  <data key="d7">memory sharing, concurrency</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Memory Offloading">
  <data key="d5">8.0</data>
  <data key="d6">Memory offloading involves transferring data and computations to accelerators like GPUs to improve performance.</data>
  <data key="d7">accelerator utilization, data transfer</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Write-After-Write and Write-After-Read Dependencies">
  <data key="d5">8.0</data>
  <data key="d6">These dependencies are critical considerations in parallel programming to prevent data hazards and ensure correctness.</data>
  <data key="d7">data hazard, concurrency control</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Deep Copy">
  <data key="d5">13.0</data>
  <data key="d6">Deep copying nodes ensures safe modifications during function inlining and loop unrolling by avoiding shared references.&lt;SEP&gt;Deep copying nodes prevents side effects during code transformation, especially in function inlining and loop unrolling.</data>
  <data key="d7">data integrity, safety&lt;SEP&gt;data integrity, transformation safety</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Jump Label">
  <data key="d5">14.0</data>
  <data key="d6">Jump labels are used to manage control flow, especially for function returns and deallocating local data during code transformations.&lt;SEP&gt;Jump labels are used to manage control flow, especially for returning from functions and deallocating local data.</data>
  <data key="d7">control flow, resource management</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Function Call Replacer">
  <data key="d5">16.0</data>
  <data key="d6">The call.replacer variable encapsulates return values to replace function calls during code inlining.&lt;SEP&gt;The call.replacer variable encapsulates return values, enabling replacement of function calls with inlined code.</data>
  <data key="d7">code optimization, inlining&lt;SEP&gt;code transformation, inlining</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="OpenMP Version of Rodinia Benchmark Suite">
  <data key="d5">8.0</data>
  <data key="d6">The benchmark suite serves as a standard for evaluating parallel code performance.</data>
  <data key="d7">benchmarking, performance evaluation</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Write-After-Write Dependencies">
  <data key="d5">8.0</data>
  <data key="d6">Write-after-write dependencies are critical data hazards in parallel programming, affecting correctness and optimization.</data>
  <data key="d7">data hazard, concurrency</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Write-After-Read Dependencies">
  <data key="d5">8.0</data>
  <data key="d6">Write-after-read dependencies are data hazards that can cause incorrect behavior if not properly managed in parallel code.</data>
  <data key="d7">data hazard, synchronization</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="ReturnNode">
  <data key="d5">7.0</data>
  <data key="d6">Return nodes mark the points where functions return, guiding control flow in code transformations.</data>
  <data key="d7">control flow, function return</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Hashing Variables">
  <data key="d5">7.0</data>
  <data key="d6">Hashing variables facilitates variable replacement during code inlining and other transformations.</data>
  <data key="d7">variable management, code transformation</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Rodinia Benchmark Suite">
  <data key="d5">8.0</data>
  <data key="d6">The benchmark suite provides a standard set of parallel programs for evaluating performance.</data>
  <data key="d7">benchmarking, performance evaluation</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="NVIDIA V100 GPUs">
  <data key="d5">14.0</data>
  <data key="d6">The GPUs are hardware resources used to accelerate GPU kernels, enabling high-performance GPU computations.&lt;SEP&gt;The GPUs are hardware resources used to accelerate GPU-based kernels in the experiments.</data>
  <data key="d7">accelerator hardware, computational resource</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Rocky 8.9">
  <data key="d5">12.0</data>
  <data key="d6">The operating system environment on which the experiments are conducted, providing system services and resource management.&lt;SEP&gt;The operating system environment on which the experiments are conducted.</data>
  <data key="d7">software environment, system platform</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Parallel kernels">
  <data key="d5">14.0</data>
  <data key="d6">Specific computational tasks (e.g., classification, solvers, Monte Carlo, neural networks) used to evaluate performance across CPU and GPU environments.&lt;SEP&gt;Specific computational tasks used to evaluate performance in different environments.</data>
  <data key="d7">test cases, workload samples</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Distributed kernels">
  <data key="d5">14.0</data>
  <data key="d6">Kernels executed across multiple nodes or GPUs, with performance impacted by implementation details.&lt;SEP&gt;Kernels executed across multiple nodes or GPUs, with performance influenced by implementation details like local reduction patterns and communication overhead.</data>
  <data key="d7">distributed computing, performance impact</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="PPL">
  <data key="d5">9.0</data>
  <data key="d6">The PPL framework analyzes static code to enable automatic optimization for heterogeneous architectures.</data>
  <data key="d7">static code analysis, optimization</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Objects of Study" target="Application Domains">
  <data key="d5">21.0</data>
  <data key="d6">Application domains are the key areas where specialized LLMs can be deployed to address specific needs and challenges.&lt;SEP&gt;Specific sectors and fields where domain-specialized LLMs are deployed to address unique challenges and needs."|"&lt;impact, deployment&lt;SEP&gt;Specific sectors like medical, legal, and finance are focus areas for deploying specialized LLMs.</data>
  <data key="d7">7&lt;SEP&gt;impact, deployment&lt;SEP&gt;sector applications, domain focus</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c&lt;SEP&gt;chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Objects of Study" target="External Knowledge Sources">
  <data key="d5">8.0</data>
  <data key="d6">External knowledge sources are utilized to provide domain-specific information that enhances the model's depth and accuracy.</data>
  <data key="d7">knowledge sources, domain enhancement</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Objects of Study" target="Transformers">
  <data key="d5">7.0</data>
  <data key="d6">Transformers are the architecture within which adapters are inserted for domain adaptation."|&lt;"object</data>
  <data key="d7">7</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Objects of Study" target="Multi-head attention">
  <data key="d5">7.0</data>
  <data key="d6">Multi-head attention layers are key points in transformers where adapters are often inserted to facilitate adaptation."|&lt;"object</data>
  <data key="d7">7</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Objects of Study" target="Jerret Ross">
  <data key="d5">16.0</data>
  <data key="d6">Uses chemical language representations to capture molecular structures and properties, advancing molecular modeling."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Objects of Study" target="Shohreh Shaghaghian">
  <data key="d5">16.0</data>
  <data key="d6">Customizes contextualized language models for legal document review, advancing legal NLP applications."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Objects of Study" target="External Libraries">
  <data key="d5">7.0</data>
  <data key="d6">External libraries and dependencies affect code analysis and performance modeling in HPC codes.</data>
  <data key="d7">libraries, dependencies</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Objects of Study" target="Open-Source Code Repositories">
  <data key="d5">8.0</data>
  <data key="d6">Repositories provide source code datasets for training and evaluating large language models.</data>
  <data key="d7">datasets, training data</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Objects of Study" target="Code Generation Benchmark">
  <data key="d5">9.0</data>
  <data key="d6">The benchmark tasks, including HumanEval and HPC problems, are used to evaluate the model's code generation capabilities.</data>
  <data key="d7">9</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Variables" target="B-1 (BLEU-1)">
  <data key="d5">6.0</data>
  <data key="d6">A metric used to evaluate the quality of generated text by measuring unigram overlap.</data>
  <data key="d7">evaluation, text quality</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Variables" target="QB-1 (Question BERT-1)">
  <data key="d5">6.0</data>
  <data key="d6">A BERT-based metric for assessing question relevance or quality.</data>
  <data key="d7">evaluation, relevance</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Variables" target="R-L (Rouge-L)">
  <data key="d5">6.0</data>
  <data key="d6">A metric measuring the longest common subsequence for evaluating generated text.</data>
  <data key="d7">evaluation, text similarity</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Variables" target="speedup𝑛@𝑘">
  <data key="d5">9.0</data>
  <data key="d6">This metric compares generated code performance to the baseline, indicating the efficiency of parallelism for fixed resources and attempts."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="speedupmax@𝑘">
  <data key="d5">8.0</data>
  <data key="d6">This metric estimates the peak speedup over all resource counts, highlighting the maximum potential of parallel execution."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="efficiency𝑛@𝑘">
  <data key="d5">9.0</data>
  <data key="d6">The efficiency metric measures the ratio of speedup to resources, assessing how well parallel code utilizes available hardware."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="execution time">
  <data key="d5">8.0</data>
  <data key="d6">Execution time is used to compute speedup, efficiency, and performance metrics."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="𝑇∗𝑝">
  <data key="d5">8.0</data>
  <data key="d6">The expected best runtime for prompt p, used as a benchmark in speedup calculations."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="𝑇𝑝">
  <data key="d5">8.0</data>
  <data key="d6">The runtime of prompt p on specific resources, used to determine speedup."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="𝑘">
  <data key="d5">7.0</data>
  <data key="d6">Number of attempts or samples, influencing the calculation of performance metrics."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="𝑛">
  <data key="d5">8.0</data>
  <data key="d6">Number of processes or threads, directly affecting parallel performance and speedup."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="𝑁">
  <data key="d5">7.0</data>
  <data key="d6">Total number of generated samples, used in probability and expected value calculations."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="𝑗">
  <data key="d5">7.0</data>
  <data key="d6">Sample index, used to order samples from slowest to fastest in statistical calculations."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="probability">
  <data key="d5">8.0</data>
  <data key="d6">The likelihood that a sample is the j-th slowest or fastest, used in calculating expected maximum speedup."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="𝑁𝑘">
  <data key="d5">7.0</data>
  <data key="d6">Total samples considering attempts 𝑘, used in speedup and performance analysis."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="efficiency">
  <data key="d5">7.0</data>
  <data key="d6">Efficiency measures how well the parallel code utilizes computational resources, with low values indicating poor resource utilization despite high speedup."|&gt;"resource utilization, performance efficiency</data>
  <data key="d7">7</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="speedup">
  <data key="d5">7.0</data>
  <data key="d6">Speedup quantifies how much faster the parallel code runs compared to the sequential baseline, with GPT-4 reaching a speedup of 20.28."|&gt;"performance metric, resource effectiveness</data>
  <data key="d7">7</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="scalability">
  <data key="d5">7.0</data>
  <data key="d6">Scalability assesses how performance metrics like speedup and efficiency change as resource counts increase."|&gt;"performance scaling, resource management</data>
  <data key="d7">7</data>
  <data key="d8">chunk-a1b2a0e4b767a0658ae2b70b61e208a7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Variables" target="Mapping">
  <data key="d5">8.0</data>
  <data key="d6">Mapping refers to assigning tasklets to hardware resources, such as cores or GPUs, to optimize execution.</data>
  <data key="d7">task assignment, resource utilization</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Variables" target="Cost Models">
  <data key="d5">8.0</data>
  <data key="d6">Cost models estimate execution time, network transfer time, and resource utilization to guide optimization decisions.</data>
  <data key="d7">performance estimation, decision support</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Variables" target="Execution Cost">
  <data key="d5">7.0</data>
  <data key="d6">Execution cost estimates the time required to perform tasks, guiding optimization strategies.</data>
  <data key="d7">performance metric, optimization</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Variables" target="Network Cost">
  <data key="d5">7.0</data>
  <data key="d6">Network cost estimates the data transfer time between devices, influencing data movement optimization.</data>
  <data key="d7">data transfer, performance</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Variables" target="code correctness">
  <data key="d5">7.0</data>
  <data key="d6">Variables such as correctness and proficiency levels are used to evaluate the quality of code generated by AI models.</data>
  <data key="d7">evaluation metrics, code quality</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Variables" target="Yongxiang Sheng">
  <data key="d5">8.0</data>
  <data key="d6">Studies the popularity and usage patterns of programming languages in open source communities.</data>
  <data key="d7">software community, language usage</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Variables" target="Variable Interdependencies">
  <data key="d5">7.0</data>
  <data key="d6">Understanding how variables interrelate and nest is essential for reasoning about correctness and complexity in code synthesis.</data>
  <data key="d7">state dependencies, correctness</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Variables" target="Temporal Reasoning">
  <data key="d5">7.0</data>
  <data key="d6">Temporal reasoning involves understanding past and future states, which is critical for safety and liveness properties in synthesized code.</data>
  <data key="d7">state transitions, property verification</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Variables" target="Concurrency and Parallelism">
  <data key="d5">8.0</data>
  <data key="d6">Handling concurrency requires reasoning about multiple processes, interleavings, and synchronization mechanisms in code generation.</data>
  <data key="d7">process coordination, race conditions</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Variables" target="Hyperproperties">
  <data key="d5">8.0</data>
  <data key="d6">Hyperproperties such as noninterference relate to variables' security levels and information flow, ensuring security in synthesized code.</data>
  <data key="d7">security policies, information flow</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Variables" target="Nondeterminism">
  <data key="d5">6.0</data>
  <data key="d6">Nondeterministic algorithms involve multiple possible outcomes for the same input, affecting the predictability of synthesized code.</data>
  <data key="d7">algorithm variability, unpredictability</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Variables" target="Tools">
  <data key="d5">12.0</data>
  <data key="d6">Tools are used to measure or manipulate Variables in research.&lt;SEP&gt;Tools are used to measure or manipulate variables within a study.</data>
  <data key="d7">measurement, data collection</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Variables" target="Performance Modeling">
  <data key="d5">8.0</data>
  <data key="d6">Performance predictions depend on variables such as code features, hardware, input data, and system load.</data>
  <data key="d7">performance factors, variables</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Variables" target="Code Complexity">
  <data key="d5">6.0</data>
  <data key="d6">Code complexity influences the difficulty of modeling and automation tasks.</data>
  <data key="d7">difficulty, code attributes</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Variables" target="Evaluation Metric">
  <data key="d5">16.0</data>
  <data key="d6">Metrics like accuracy and perplexity serve as quantitative measures of model performance.&lt;SEP&gt;Metrics like accuracy, perplexity, and correctness are used to evaluate model performance.</data>
  <data key="d7">performance evaluation, metrics&lt;SEP&gt;performance metrics, model assessment</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Tools" target="Language Model Pipelines">
  <data key="d5">16.0</data>
  <data key="d6">Language model pipelines integrate models and external tools to perform complex, multi-step tasks in a cohesive framework."|&gt;"system integration, multi-stage processing&lt;SEP&gt;Language model pipelines integrate various models and tools to perform complex, multi-step tasks in a cohesive manner.</data>
  <data key="d7">8&lt;SEP&gt;system integration, multi-stage processing</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="DSPy Compiler">
  <data key="d5">16.0</data>
  <data key="d6">The DSPy compiler automates the assembly, tuning, and optimization of language model pipelines, supporting techniques like cross-validation and reinforcement learning."|&gt;"automation, optimization&lt;SEP&gt;The DSPy compiler automates the construction and optimization of language model pipelines, supporting various techniques like cross-validation and RL.</data>
  <data key="d7">8&lt;SEP&gt;automation, optimization</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="Model Selection Techniques">
  <data key="d5">14.0</data>
  <data key="d6">Model selection techniques such as cross-validation, RL, and Bayesian optimization are employed within DSPy to enhance pipeline performance.&lt;SEP&gt;Techniques like cross-validation, RL, and Bayesian optimization are employed within DSPy to improve pipeline performance based on empirical metrics."|&gt;"performance tuning, model selection</data>
  <data key="d7">7&lt;SEP&gt;optimization, performance tuning</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="Toolkits (e.g., LangChain, Semantic Kernel, LlamaIndex)">
  <data key="d5">9.0</data>
  <data key="d6">Toolkits provide pre-built modules and interfaces to connect language models with external tools, simplifying pipeline construction."|&gt;"tool integration, automation</data>
  <data key="d7">9</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="Torch">
  <data key="d5">6.0</data>
  <data key="d6">Torch is a software library used for building machine learning models, developed by Ronan Collobert.</data>
  <data key="d7">software, ML library</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Tools" target="RAG-Token Model">
  <data key="d5">9.0</data>
  <data key="d6">The RAG-Token model utilizes the DPR retriever and BART generator to produce answers based on retrieved documents, integrating retrieval and generation processes.</data>
  <data key="d7">integrated retrieval-generation</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Tools" target="BART">
  <data key="d5">6.0</data>
  <data key="d6">BART is used as a baseline generative model for comparison in question answering and text generation tasks.</data>
  <data key="d7">baseline, comparison</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Tools" target="Huggingface’s transformers">
  <data key="d5">7.0</data>
  <data key="d6">The library provides advanced NLP models used across multiple studies for various language understanding tasks.</data>
  <data key="d7">NLP tools, models</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Tools" target="Evidence aggregation for answer re-ranking in open-domain question answering">
  <data key="d5">7.0</data>
  <data key="d6">Tools like transformers may be employed to facilitate evidence aggregation processes.</data>
  <data key="d7">tools, techniques</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Tools" target="Prompt in Listing 1">
  <data key="d5">12.0</data>
  <data key="d6">The prompt format is used to evaluate how well LLMs can generate code based on natural language prompts.&lt;SEP&gt;The prompt format is used to standardize evaluation of LLMs' code generation abilities from natural language descriptions.</data>
  <data key="d7">prompt design, evaluation methodology</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="Listing 2">
  <data key="d5">18.0</data>
  <data key="d6">Listing 2 provides the prompt used to instruct models to perform code translation tasks.&lt;SEP&gt;The prompt used to instruct models to perform code translation tasks between execution models.</data>
  <data key="d7">prompt design, translation task&lt;SEP&gt;prompt format, translation task</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="Models: CodeLlama (CL-7B, CL-13B, CL-34B), StarCoderBase">
  <data key="d5">16.0</data>
  <data key="d6">Models used in the evaluation, all fine-tuned for code generation and translation tasks, with specific properties and sizes.&lt;SEP&gt;The models evaluated are fine-tuned code-focused language models with different sizes and training data, supporting code generation, translation, and infilling.</data>
  <data key="d7">model capabilities, comparison&lt;SEP&gt;model comparison, capabilities</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="Analytical Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Tools are applied to perform Analytical Techniques, enabling data analysis and interpretation.</data>
  <data key="d7">analytical methods, data processing</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="Kokkos">
  <data key="d5">7.0</data>
  <data key="d6">Kokkos is utilized as a performance-portable programming model in the evaluation of LLM-generated code.</data>
  <data key="d7">performance portability, code generation</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="MultiPL-E">
  <data key="d5">8.0</data>
  <data key="d6">A benchmarking tool for evaluating neural code generation across multiple languages."|&gt;"benchmarking, multi-language evaluation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="arXiv">
  <data key="d5">8.0</data>
  <data key="d6">Repository hosting preprints on AI, code models, and related research."|&gt;"research dissemination, repositories</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Tools" target="Code generator">
  <data key="d5">8.0</data>
  <data key="d6">A component of the toolchain that produces code for the PPL prototype, enabling automation of code creation."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="MILP">
  <data key="d5">8.0</data>
  <data key="d6">MILP formulations are used to optimize task scheduling and mapping during global optimization, solved by solvers like Gurobi.</data>
  <data key="d7">optimization solving, scheduling</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="Xeon Platinum 8160">
  <data key="d5">12.0</data>
  <data key="d6">The CPU model is a hardware resource used for parallel computations and performance benchmarking within the systems.&lt;SEP&gt;The Xeon CPU is a hardware resource used to perform parallel computations in the experiments.</data>
  <data key="d7">hardware component, processing resource</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="Intel Omni-Path 100G">
  <data key="d5">12.0</data>
  <data key="d6">The high-speed network fabric connects nodes and facilitates fast data transfer, supporting parallel and distributed processing.&lt;SEP&gt;The high-speed network fabric connects nodes, enabling fast data transfer for parallel processing.</data>
  <data key="d7">network infrastructure, communication tool</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="Intel OneAPI C/C++ Compiler 2022.1.0">
  <data key="d5">14.0</data>
  <data key="d6">Compiler used for code compilation and optimization in the experiments.&lt;SEP&gt;The compiler is used for code compilation, optimization, and generating high-performance executable code for the experiments.</data>
  <data key="d7">software tool, compilation environment</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="IntelMPI 2021.6.0">
  <data key="d5">14.0</data>
  <data key="d6">MPI implementation used for message passing and parallel communication, especially in distributed kernels.&lt;SEP&gt;MPI implementation used for parallel communication in distributed kernels.</data>
  <data key="d7">communication protocol, parallel computing tool&lt;SEP&gt;communication protocol, parallel processing tool</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="CUDA 11.8">
  <data key="d5">14.0</data>
  <data key="d6">GPU programming toolkit used to compile and run GPU-accelerated code.&lt;SEP&gt;GPU programming toolkit used to develop, compile, and run GPU kernels, supporting GPU-accelerated computations.</data>
  <data key="d7">GPU development environment, software toolkit</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="Gurobi">
  <data key="d5">14.0</data>
  <data key="d6">Optimization solver used for scheduling and MILP optimization, with multiple seeds to mitigate instability.&lt;SEP&gt;Optimization solver used for scheduling and MILP optimization, with multiple seeds to mitigate stochastic instabilities in results.</data>
  <data key="d7">optimization tool, solver</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tools" target="CuPy">
  <data key="d5">2.0</data>
  <data key="d6">CuPy provides correct raw CUDA kernel source code, making it suitable for GPU programming in Python, especially for community-preferred lightweight layers.</data>
  <data key="d7">GPU programming, community preference</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Tools" target="pyCUDA">
  <data key="d5">2.0</data>
  <data key="d6">pyCUDA enables direct CUDA kernel programming within Python, with correct source code generated, supporting GPU instances.</data>
  <data key="d7">GPU kernel development, code correctness</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Tools" target="Numba">
  <data key="d5">14.0</data>
  <data key="d6">Numba supports JIT compilation for Python, but it performs less well on GPU kernels and has deprecated AMD GPU support, indicating limitations in current GPU code generation.</data>
  <data key="d7">performance, hardware support</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Tools" target="zero-init attention mechanism">
  <data key="d5">6.0</data>
  <data key="d6">A mechanism where attention weights are initialized to zero to promote stable training and effective adaptation."|&lt;"relationship</data>
  <data key="d7">6</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tools" target="AdapterHub">
  <data key="d5">7.0</data>
  <data key="d6">AdapterHub provides an extensive library supporting various adapters and language models for fine-tuning.</data>
  <data key="d7">tool support, integration</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tools" target="LLM-adapters">
  <data key="d5">8.0</data>
  <data key="d6">LLM-adapters framework supports open-access large language models and multiple adapter types, facilitating domain-specific adaptation.</data>
  <data key="d7">extensibility, domain adaptation</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tools" target="Generated Code">
  <data key="d5">17.0</data>
  <data key="d6">Compiler flags and frameworks are used to compile and test the generated code samples for correctness.&lt;SEP&gt;Compiler flags and frameworks are used to compile and test the generated code, ensuring correctness and parallel framework usage.</data>
  <data key="d7">8&lt;SEP&gt;compilation, testing</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Tools" target="Token &lt;begin-omp&gt;">
  <data key="d5">14.0</data>
  <data key="d6">The separator token &lt;begin-omp&gt; is used in data formatting to position the pragma correctly relative to the for loop during model inference.&lt;SEP&gt;The separator token &lt;begin-omp&gt; is used to format data so that models can generate pragmas at the correct position in code sequences.</data>
  <data key="d7">data formatting, model input</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Tools" target="Model">
  <data key="d5">8.0</data>
  <data key="d6">LLMs such as GPT-Neo, PolyCoder, and GPT2 are employed for code generation and classification tasks in HPC contexts.</data>
  <data key="d7">language models, code tasks</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Tools" target="LLMs">
  <data key="d5">8.0</data>
  <data key="d6">Large Language Models such as GPT-Neo, PolyCoder, and GPT2 are employed to generate code, predict performance, and classify code changes in HPC contexts.</data>
  <data key="d7">language models, code tasks</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="performance comparison" target="parallel execution models">
  <data key="d5">17.0</data>
  <data key="d6">The effectiveness of LLMs varies depending on the parallel execution environment, with serial and OpenMP being easier and MPI/MPI+OpenMP more challenging for correct code generation."|"&lt;environment impact, difficulty&lt;SEP&gt;The effectiveness of LLMs varies depending on the parallel execution model, with serial and OpenMP being easier and MPI/MPI+OpenMP more challenging for code generation.</data>
  <data key="d7">9&lt;SEP&gt;execution environment, model difficulty</data>
  <data key="d8">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance comparison" target="cost of generation">
  <data key="d5">7.0</data>
  <data key="d6">Higher k-values for models like GPT-3.5 and GPT-4 are limited by the monetary or computational cost of sample generation."|"&lt;cost, model scalability</data>
  <data key="d7">7</data>
  <data key="d8">chunk-0c18728de6eaa2dba619a8f9da01a39a</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="Interpretability">
  <data key="d5">14.0</data>
  <data key="d6">Improved interpretability enhances user trust and facilitates deployment in critical domains like healthcare.&lt;SEP&gt;Improved interpretability of models increases user trust and facilitates deployment in critical domains like healthcare.</data>
  <data key="d7">trust, transparency</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Applications/Implications" target="LM4HPC">
  <data key="d5">8.0</data>
  <data key="d6">Applying language models to high-performance computing tasks, including data race detection."|&gt;"application, HPC, code analysis</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="Application of generated code">
  <data key="d5">16.0</data>
  <data key="d6">The code aims to enhance performance and scalability for HPC applications, impacting computational efficiency.&lt;SEP&gt;The code is intended to enhance performance, scalability, and efficiency of HPC applications, impacting computational workflows and high-performance computing strategies.</data>
  <data key="d7">performance improvement, scalability</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Applications/Implications" target="Future directions">
  <data key="d5">8.0</data>
  <data key="d6">Future research aims to improve prompt techniques, expand datasets, and better integrate AI into HPC workflows, influencing future scientific computing practices."|"&lt;research development, innovation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Applications/Implications" target="Reproducibility of the study">
  <data key="d5">9.0</data>
  <data key="d6">The detailed artifact descriptions in Appendix A ensure the study can be reproduced and validated, supporting transparency and further research."|"&lt;validation, transparency</data>
  <data key="d7">9</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Applications/Implications" target="Code Generation Tools">
  <data key="d5">16.0</data>
  <data key="d6">Tools powered by LLMs aim to automate coding tasks, enhance productivity, and assist developers.&lt;SEP&gt;Tools powered by LLMs aim to improve software development efficiency and automation.</data>
  <data key="d7">automation, developer support&lt;SEP&gt;productivity, automation</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Applications/Implications" target="White-Box Methods">
  <data key="d5">18.0</data>
  <data key="d6">White-box approaches enable detailed analysis and customization of LLMs for specific domains, improving effectiveness.&lt;SEP&gt;White-box approaches enable detailed analysis, customization, and transparency, improving the effectiveness of LLMs in specific domains.</data>
  <data key="d7">model transparency, customization</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Applications/Implications" target="Yongliang Shen">
  <data key="d5">16.0</data>
  <data key="d6">Develops HuggingGPT to solve AI tasks by integrating ChatGPT with HuggingFace, impacting AI deployment."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Applications/Implications" target="Codex">
  <data key="d5">9.0</data>
  <data key="d6">The paper discusses potential broader impacts of deploying powerful code generation models, including safety concerns, security risks, and economic effects.</data>
  <data key="d7">ethical considerations, societal impact</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="Broader Impacts">
  <data key="d5">9.0</data>
  <data key="d6">Discussion of safety, security, and economic implications of deploying large language models trained on code.</data>
  <data key="d7">ethical, societal impact</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="broader impacts of code generating models">
  <data key="d5">16.0</data>
  <data key="d6">Discussion on societal and technical impacts of deploying code generation models.&lt;SEP&gt;Discussion on societal, ethical, and technical impacts of deploying code generation models.</data>
  <data key="d7">ethical considerations, societal impact</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="model limitations">
  <data key="d5">18.0</data>
  <data key="d6">Identifying limitations guides future improvements and responsible deployment.&lt;SEP&gt;Identifying limitations helps guide future improvements and responsible deployment.</data>
  <data key="d7">model shortcomings, future directions&lt;SEP&gt;model shortcomings, future work</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="Study Populations/Dataset">
  <data key="d5">14.0</data>
  <data key="d6">Characteristics of Study Populations or Datasets influence the Applications and Implications of research outcomes.&lt;SEP&gt;The characteristics of study populations or datasets influence the applications and implications of research.</data>
  <data key="d7">generalizability, real-world impact&lt;SEP&gt;generalizability, societal impact</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Applications/Implications" target="HPC-Coder">
  <data key="d5">7.0</data>
  <data key="d6">HPC-Coder has implications for automating development, optimizing performance, and reducing errors in HPC workflows.</data>
  <data key="d7">automation, optimization</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="large language models" target="multi-modal reasoning">
  <data key="d5">6.0</data>
  <data key="d6">Large language models like LLaMA can be extended for multi-modal reasoning tasks involving multiple data modalities."|&lt;"relationship</data>
  <data key="d7">6</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Optimization" target="Polyhedral Compilers">
  <data key="d5">8.0</data>
  <data key="d6">They focus on optimizing polyhedral loop nests in high-performance computing contexts."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Optimization" target="Inlining">
  <data key="d5">16.0</data>
  <data key="d6">Inlining flattens nested functions, enabling better optimization and facilitating nested parallel pattern handling.&lt;SEP&gt;Inlining is used to flatten nested functions and enable further optimization, especially for nested parallel patterns.</data>
  <data key="d7">code flattening, optimization</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Optimization" target="Loop Unrolling">
  <data key="d5">16.0</data>
  <data key="d6">Loop unrolling expands loops to reduce control overhead and improve kernel performance.&lt;SEP&gt;Loop unrolling expands loops to reduce overhead and improve performance in GPU kernels.</data>
  <data key="d7">performance enhancement, code optimization</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Optimization" target="Kmeans">
  <data key="d5">9.0</data>
  <data key="d6">The Kmeans benchmark's kernels are optimized for better parallelism, achieving significant speedups.</data>
  <data key="d7">kernel optimization, parallelism</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Optimization" target="Stage">
  <data key="d5">6.0</data>
  <data key="d6">Focuses on enhancing model performance via techniques like gradient descent or output filtering.</data>
  <data key="d7">performance tuning, output refinement</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Study Designs" target="Methodologies">
  <data key="d5">9.0</data>
  <data key="d6">Methodologies are implemented through specific Study Designs to systematically investigate research questions.</data>
  <data key="d7">research approach, systematic investigation</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Study Designs" target="Disciplines">
  <data key="d5">7.0</data>
  <data key="d6">Disciplines influence the choice of Study Designs based on methodological standards and theoretical frameworks.</data>
  <data key="d7">disciplinary standards, methodological influence</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Study Designs" target="Evaluating Large Language Models Trained on Code">
  <data key="d5">8.0</data>
  <data key="d6">A systematic assessment of language models' performance on code tasks."|&gt;"evaluation, research design</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Study Designs" target="Evaluation">
  <data key="d5">8.0</data>
  <data key="d6">An assessment of the current prototype's capabilities, issues, and potential improvements, including performance metrics."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Study Designs" target="Evaluation against Rodinia kernels">
  <data key="d5">8.0</data>
  <data key="d6">The process of benchmarking the tool against existing implementations to assess performance, correctness, and scalability."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Study Designs" target="Evaluation Study">
  <data key="d5">7.0</data>
  <data key="d6">Evaluation compares generated code performance against benchmarks, focusing on runtime and efficiency metrics.</data>
  <data key="d7">performance assessment, benchmarking</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Study Designs" target="Rodinia benchmarks">
  <data key="d5">16.0</data>
  <data key="d6">A benchmark suite used to evaluate the applicability and coverage of generated and optimized code on HPC workloads based on the Berkeley dwarfs.&lt;SEP&gt;Benchmark suite used to evaluate the applicability and coverage of the generated code.</data>
  <data key="d7">evaluation framework, benchmark suite</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Study Designs" target="Model Selection">
  <data key="d5">14.0</data>
  <data key="d6">Evaluation of multiple fine-tuned models to identify the best for downstream applications based on performance metrics.&lt;SEP&gt;Model selection involves evaluating performance metrics of various fine-tuned models to choose the most effective one for downstream tasks.</data>
  <data key="d7">performance evaluation, optimization&lt;SEP&gt;performance evaluation, selection</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Evidence Types" target="Metrics">
  <data key="d5">18.0</data>
  <data key="d6">Metrics are used to quantify the accuracy and effectiveness of code translation and generation.&lt;SEP&gt;Metrics are used to quantitatively evaluate the accuracy, correctness, and quality of generated or translated code.</data>
  <data key="d7">performance metrics, evaluation</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Evidence Types" target="Explicit Knowledge">
  <data key="d5">8.0</data>
  <data key="d6">Explicit knowledge is structured, clearly defined information that can be directly retrieved and used by models.</data>
  <data key="d7">structured data, accessible knowledge</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Evidence Types" target="Implicit Knowledge">
  <data key="d5">7.0</data>
  <data key="d6">Implicit knowledge is latent, embedded within data or models, requiring inference to utilize effectively.</data>
  <data key="d7">latent information, inference needed</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Evidence Types" target="Accuracy">
  <data key="d5">9.0</data>
  <data key="d6">Accuracy measures the correctness of model outputs, such as generated pragmas or performance predictions.</data>
  <data key="d7">performance metrics, correctness</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Text Transformation Graphs" target="Building">
  <data key="d5">9.0</data>
  <data key="d6">The work involves building and developing text transformation graphs to improve systematic use of language models.</data>
  <data key="d7">research development, system design</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Text Transformation Graphs" target="building">
  <data key="d5">9.0</data>
  <data key="d6">The process of designing and developing text transformation graphs to improve the systematic use of language models.</data>
  <data key="d7">research development, system design</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Math Word Problems" target="GSM8K Dataset">
  <data key="d5">14.0</data>
  <data key="d6">The dataset provides the testbed for evaluating the impact of different program and prompt strategies on reasoning accuracy."|&lt;SEP&gt;The dataset serves as the basis for evaluating the effectiveness of different program strategies and modules.</data>
  <data key="d7">7&lt;SEP&gt;benchmark, evaluation</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompting Techniques" target="Executable Commands">
  <data key="d5">5.0</data>
  <data key="d6">Prompting methods are used to elicit executable commands or code from LLMs with minimal examples, facilitating automation.</data>
  <data key="d7">prompt engineering, minimal data</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Performance Improvement" target="Scaling of Models">
  <data key="d5">7.0</data>
  <data key="d6">Increasing the size or data of LLMs enhances their capacity to perform a wide range of NLP tasks.</data>
  <data key="d7">model capacity, performance enhancement</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Preprint" target="Wenhu Chen et al.">
  <data key="d5">6.0</data>
  <data key="d6">The preprint presents research on program of thoughts prompting and numerical reasoning tasks, authored by Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen.</data>
  <data key="d7">research dissemination, early findings</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Omar Khattab" target="contribution">
  <data key="d5">4.0</data>
  <data key="d6">Supports</data>
  <data key="d7">Omar Khattab supports and contributes to AI research, particularly in the development and application of systematic frameworks.</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy programming model" target="string-based prompting techniques">
  <data key="d5">18.0</data>
  <data key="d6">DSPy translates complex prompting techniques into modular components, enabling automation and learning.</data>
  <data key="d7">translation, modularization</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="neural network layers" target="DSPy modules">
  <data key="d5">16.0</data>
  <data key="d6">DSPy modules abstract and emulate neural network layers, enabling flexible composition of text transformations.&lt;SEP&gt;DSPy modules are abstractions of neural network layers, allowing flexible composition of text transformation components.</data>
  <data key="d7">abstraction, neural architecture</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="bootstrapping demonstrations" target="self-improving NLP systems">
  <data key="d5">14.0</data>
  <data key="d6">Demonstrations are used within DSPy to bootstrap modules, facilitating iterative learning and system enhancement.&lt;SEP&gt;Demonstrations provide examples that help modules learn behaviors, enabling systems to self-improve iteratively.</data>
  <data key="d7">learning, self-improvement&lt;SEP&gt;learning, system improvement</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy compiler" target="optimization strategies (teleprompters)">
  <data key="d5">16.0</data>
  <data key="d6">The compiler employs teleprompters to automatically optimize modules and pipeline performance.&lt;SEP&gt;The compiler employs teleprompters to optimize module learning, improving system performance.</data>
  <data key="d7">optimization, automation&lt;SEP&gt;optimization, self-improvement</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="multi-hop question answering (HotPotQA)" target="math word problems (GMS8K)">
  <data key="d5">12.0</data>
  <data key="d6">Both datasets serve as case studies for evaluating DSPy's effectiveness in reasoning and structured problem-solving tasks.&lt;SEP&gt;Both datasets serve as case studies to evaluate DSPy's reasoning and problem-solving capabilities across different domains.</data>
  <data key="d7">evaluation, reasoning</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="prompting techniques" target="self-improving NLP systems">
  <data key="d5">14.0</data>
  <data key="d6">Prompting techniques like Chain of Thought are central to guiding reasoning, which DSPy seeks to automate and enhance.&lt;SEP&gt;Prompting techniques like Chain of Thought are central to guiding system reasoning, which DSPy aims to automate and improve.</data>
  <data key="d7">guidance, automation</data>
  <data key="d8">chunk-061790de1df7d16a1cc9252b2f75290c</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ReAct" target="HotPotQA">
  <data key="d5">16.0</data>
  <data key="d6">ReAct is evaluated as a multi-step tool use agent for answering questions in HotPotQA.".</data>
  <data key="d7">multi-step reasoning, tool use</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Radford et al. 2018" target="Brown et al. 2020">
  <data key="d5">18.0</data>
  <data key="d6">Both are foundational publications that contribute to understanding foundation models and their programming mechanisms.&lt;SEP&gt;Both works are foundational publications that contribute to the understanding of foundation models and their programming mechanisms.</data>
  <data key="d7">literature, foundational research</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Instruction Tuning" target="Prompting">
  <data key="d5">14.0</data>
  <data key="d6">Instruction tuning enhances prompting effectiveness by training models to better interpret prompts and follow instructions.&lt;SEP&gt;Instruction tuning enhances the effectiveness of prompting by training models to better interpret and follow instructions.</data>
  <data key="d7">training, instruction adherence&lt;SEP&gt;training, instruction following</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Weak Supervision" target="Language Models">
  <data key="d5">16.0</data>
  <data key="d6">Weak supervision signals are generated or processed by language models to automate task-specific heuristics, reducing manual effort."|&gt;"supervision, automation&lt;SEP&gt;Weak supervision techniques are implemented via language models to replace traditional heuristics, enabling task-specific or heuristic-based training through models.</data>
  <data key="d7">8&lt;SEP&gt;supervised learning, automation</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="In-context Learning" target="Language Models">
  <data key="d5">16.0</data>
  <data key="d6">In-context learning leverages language models' ability to adapt to new tasks based on provided examples without retraining.&lt;SEP&gt;In-context learning leverages language models' ability to adapt to tasks based on provided examples without additional training.</data>
  <data key="d7">adaptation, few-shot learning&lt;SEP&gt;learning paradigm, task adaptation</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Language Model Pipelines" target="Toolkits (e.g., LangChain, Semantic Kernel, LlamaIndex)">
  <data key="d5">9.0</data>
  <data key="d6">Toolkits provide pre-packaged modules and interfaces to connect language models with external tools, facilitating pipeline construction.</data>
  <data key="d7">tool integration, automation</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompt Engineering Challenges" target="DSPy">
  <data key="d5">16.0</data>
  <data key="d6">DSPy addresses prompt engineering challenges by offering modular abstractions and high-level signatures, reducing reliance on hand-crafted prompts.&lt;SEP&gt;DSPy addresses prompt engineering challenges by offering modular abstractions and high-level signatures, reducing the need for manual prompt design."|&gt;"problem-solving, system design</data>
  <data key="d7">8&lt;SEP&gt;problem-solving, system design</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Formative Work by Bergstra, Paszke, Wolf" target="Core Concepts">
  <data key="d5">18.0</data>
  <data key="d6">These foundational studies support the development of high-level, modular programming models that combine quantitative benchmarks with qualitative measures."|&gt;"literature, foundational research&lt;SEP&gt;These foundational studies support the development of programming models that combine quantitative benchmarks with qualitative evaluation for language systems.</data>
  <data key="d7">9&lt;SEP&gt;literature, foundational research</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompt Engineering" target="Language Models">
  <data key="d5">16.0</data>
  <data key="d6">Prompt engineering directly influences model responses; the work explores replacing handcrafted prompts with modular, programmable prompts to improve performance and reproducibility."|&lt;SEP&gt;Prompt engineering directly influences the effectiveness of language model outputs, especially in task-specific contexts.</data>
  <data key="d7">8&lt;SEP&gt;prompt design, model performance</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Prompt Engineering" target="Evaluation of Domain Adaptation">
  <data key="d5">7.0</data>
  <data key="d6">Prompt engineering is a methodology used within domain adaptation to customize LLM outputs for particular tasks.</data>
  <data key="d7">methodology, task-specific tuning</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Engineering" target="Zero-shot and Few-shot Learning">
  <data key="d5">8.0</data>
  <data key="d6">Prompt engineering involves designing prompts to facilitate zero-shot or few-shot learning for domain adaptation.</data>
  <data key="d7">prompt design, learning paradigms</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Engineering" target="Methods">
  <data key="d5">7.0</data>
  <data key="d6">Prompt engineering involves designing input prompts to guide the model's inference toward domain-specific responses, without changing internal parameters.</data>
  <data key="d7">input design, inference steering</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Engineering" target="Model Capability">
  <data key="d5">7.0</data>
  <data key="d6">Prompt engineering can activate or demonstrate a model's latent capabilities, affecting its performance on specific tasks.</data>
  <data key="d7">technique, capability</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Prompt Engineering" target="Code Review and QA Testing">
  <data key="d5">14.0</data>
  <data key="d6">Effective prompt engineering can improve the quality and security of generated code, reducing the need for extensive review.&lt;SEP&gt;Effective prompt engineering improves the security and quality of generated code, reducing the burden on review and testing processes.</data>
  <data key="d7">prompt design, quality assurance</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Signatures" target="DSPy">
  <data key="d5">9.0</data>
  <data key="d6">DSPy uses signatures to define structured interfaces for tasks, enabling modular and predictable prompting.</data>
  <data key="d7">framework-structure</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Signatures" target="Predict">
  <data key="d5">16.0</data>
  <data key="d6">Predict executes prompts based on signatures, managing demonstrations and parsing outputs.&lt;SEP&gt;Predict executes prompts based on signatures, managing demonstrations and parsing structured outputs.</data>
  <data key="d7">module-function</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Signatures" target="dspy">
  <data key="d5">9.0</data>
  <data key="d6">dspy uses signatures to define structured interfaces for tasks, enabling modular, predictable prompting and output parsing.</data>
  <data key="d7">framework-structure</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Predict" target="ChainOfThought">
  <data key="d5">14.0</data>
  <data key="d6">ChainOfThought modifies the signature to include reasoning steps, which Predict then uses to generate step-by-step reasoning before final answers.</data>
  <data key="d7">prompting-approach</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Modules" target="DSPy">
  <data key="d5">12.0</data>
  <data key="d6">Modules like ChainOfThought and ReAct extend DSPy's capabilities by providing specialized reasoning and multi-stage prompting techniques.&lt;SEP&gt;Modules like ChainOfThought, ReAct, and MultiChainComparison extend DSPy's prompting techniques for specialized reasoning and multi-stage tasks.</data>
  <data key="d7">extension</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Modules" target="Parameterization">
  <data key="d5">10.0</data>
  <data key="d6">Parameterization allows customizing modules and signatures for specific tasks, enhancing flexibility.&lt;SEP&gt;Parameterization allows customizing prompts and modules for specific tasks, enhancing flexibility and adaptability.</data>
  <data key="d7">customization</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Structured Prompting" target="dspy">
  <data key="d5">3.0</data>
  <data key="d6">Structured prompting involves designing prompts with explicit formats and fields to improve model understanding and output consistency.</data>
  <data key="d7">prompt design</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Bootstrapping" target="Self-Improving">
  <data key="d5">10.0</data>
  <data key="d6">Bootstrapping involves using demonstrations and iterative feedback to improve model performance and prompt effectiveness.&lt;SEP&gt;Bootstrapping involves using demonstrations to iteratively improve model performance, a key aspect of DSPy's methodology.&lt;SEP&gt;Self-improving techniques leverage demonstrations and iterative refinement to enhance model outputs over time.</data>
  <data key="d7">feedback loop&lt;SEP&gt;training strategy</data>
  <data key="d8">chunk-484caa2ba6025add81052bdcfed482a4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Bootstrapping" target="Evaluation Technique">
  <data key="d5">10.0</data>
  <data key="d6">Bootstrapping is discussed as a future method to dynamically improve model adaptation and evaluation robustness.&lt;SEP&gt;Bootstrapping is mentioned as a future technique to dynamically adapt and evaluate model performance, especially for test-time improvements."|</data>
  <data key="d7">5&lt;SEP&gt;resampling, dynamic adaptation</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Demonstrations" target="Predictors">
  <data key="d5">14.0</data>
  <data key="d6">Demonstrations involve the use of predictors to generate or evaluate specific instances or steps within a program.&lt;SEP&gt;Demonstrations utilize predictors to generate or test specific instances or steps within the program, illustrating its behavior."|&gt;"study design, example generation</data>
  <data key="d7">7&lt;SEP&gt;study design, evaluation process</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Demonstrations" target="BootstrapFewShot">
  <data key="d5">12.0</data>
  <data key="d6">BootstrapFewShot generates a large number of demonstrations to enhance program development or testing.&lt;SEP&gt;BootstrapFewShot generates numerous demonstrations to improve the diversity and robustness of training or testing samples."|&gt;"data augmentation, methodology</data>
  <data key="d7">6&lt;SEP&gt;data augmentation, methodology</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Outputs" target="Low-Security Users">
  <data key="d5">6.0</data>
  <data key="d6">Outputs observed from low-security users are consistent regardless of inputs from high-security users, highlighting security considerations.</data>
  <data key="d7">security, system behavior</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Outputs" target="Intent Misalignment">
  <data key="d5">9.0</data>
  <data key="d6">Intent misalignment occurs when models produce outputs (B) that do not match user preferences (A), despite having the capacity to produce the preferred outputs.</data>
  <data key="d7">user preference, output discrepancy</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Outputs" target="Output A">
  <data key="d5">8.0</data>
  <data key="d6">Output A is the desired result that aligns with user intent, indicating successful performance.</data>
  <data key="d7">user goal, correctness</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Outputs" target="Output B">
  <data key="d5">8.0</data>
  <data key="d6">Output B represents a deviation from user preference, indicating potential misalignment.</data>
  <data key="d7">error, misalignment</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Evaluation" target="Program">
  <data key="d5">16.0</data>
  <data key="d6">The evaluation assesses the performance of the program using metrics like score.&lt;SEP&gt;The evaluation process measures how well the program performs based on metrics like score, indicating effectiveness."|&gt;"performance assessment</data>
  <data key="d7">8&lt;SEP&gt;performance assessment</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Evaluation" target="Rodinia Benchmark Suite">
  <data key="d5">8.0</data>
  <data key="d6">The tool/concept is evaluated against nearly all kernels from the Rodinia benchmark suite."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Evaluation" target="Study Design">
  <data key="d5">7.0</data>
  <data key="d6">Evaluation compares the performance of generated code against benchmarks, measuring runtime and efficiency.</data>
  <data key="d7">performance assessment, benchmarking</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Evaluation" target="Stage">
  <data key="d5">7.0</data>
  <data key="d6">Tests the adapted model against benchmarks, gathers feedback, and refines accordingly.</data>
  <data key="d7">performance assessment, feedback loop</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Evaluation" target="bias probes">
  <data key="d5">9.0</data>
  <data key="d6">Probes are used to evaluate the presence of bias in generated code, establishing a testing or assessment relationship."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Evaluation" target="Hardware Environment">
  <data key="d5">16.0</data>
  <data key="d6">The hardware environment provides the context for executing and testing generated code, influencing performance and correctness.&lt;SEP&gt;The hardware setup provides the context for running and testing generated code, affecting performance and correctness.</data>
  <data key="d7">8&lt;SEP&gt;computational environment, testing</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="answer_exact_match" target="T5-Large">
  <data key="d5">14.0</data>
  <data key="d6">The exact match metric is used to evaluate the accuracy of T5-Large's answers.".</data>
  <data key="d7">evaluation metric, answer accuracy&lt;SEP&gt;evaluation, accuracy</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Majority Voting" target="Ensemble Decision">
  <data key="d5">12.0</data>
  <data key="d6">Majority voting is used as a custom ensemble method to aggregate multiple model outputs for more reliable answers.&lt;SEP&gt;Majority voting is used as an ensemble method to aggregate multiple outputs from different model runs, improving overall answer reliability and accuracy."|</data>
  <data key="d7">6&lt;SEP&gt;ensemble, decision-making</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Program Modules" target="DSPy">
  <data key="d5">18.0</data>
  <data key="d6">DSPy enables the creation and compilation of modular programs that replace traditional prompts, leading to improved model performance.&lt;SEP&gt;DSPy enables the creation, assembly, and compilation of modular programs, replacing traditional prompts, leading to performance improvements."|</data>
  <data key="d7">9&lt;SEP&gt;modularity, program optimization</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Program Modules" target="Evaluation Results">
  <data key="d5">20.0</data>
  <data key="d6">The use of program modules compiled into optimized forms results in significant accuracy improvements compared to string prompts.&lt;SEP&gt;Using compiled program modules yields significant accuracy improvements compared to string prompts, demonstrating the effectiveness of modular approaches."|</data>
  <data key="d7">10&lt;SEP&gt;performance, optimization</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Program Compilation Strategies" target="Evaluation Results">
  <data key="d5">12.0</data>
  <data key="d6">Different compilation strategies (zero-shot, few-shot, bootstrap, ensemble) are evaluated for their impact on accuracy, with compiled strategies showing notable improvements."|</data>
  <data key="d7">12</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Evaluation Results" target="Hypotheses">
  <data key="d5">11.0</data>
  <data key="d6">Results support the hypotheses that modular, compiled programs outperform handcrafted prompts in accuracy and adaptability."|</data>
  <data key="d7">11</data>
  <data key="d8">chunk-0696a875ae026175ba36c9e8529f7efd</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Compilation Strategies" target="DSPy">
  <data key="d5">8.0</data>
  <data key="d6">DSPy employs various compilation strategies to optimize program performance, demonstrating the importance of module composition.</data>
  <data key="d7">methodology, optimization</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Bootstrapping with Random Search" target="Ensembling">
  <data key="d5">9.0</data>
  <data key="d6">Bootstrapped demonstration chains are further optimized through random search and can be ensembled to improve model accuracy.</data>
  <data key="d7">optimization, ensemble methods</data>
  <data key="d8">chunk-8148b67fb57a98685f653eb2824cfd6f</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="llama2-34b" target="program">
  <data key="d5">14.0</data>
  <data key="d6">The 34b model variant is evaluated using specific performance benchmarks and comparison to other models.".&lt;SEP&gt;The 34b variant is evaluated using the program's procedures for performance metrics.</data>
  <data key="d7">model evaluation, benchmarking&lt;SEP&gt;model evaluation, performance assessment</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="llama2-70b" target="program">
  <data key="d5">12.0</data>
  <data key="d6">The 70b model's performance is assessed similarly, comparing its results with other model variants.".&lt;SEP&gt;The 70b variant's performance is assessed similarly, comparing with other models.".</data>
  <data key="d7">model comparison, performance evaluation&lt;SEP&gt;model evaluation, benchmarking</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="GPT-3.5-turbo" target="GSM8K">
  <data key="d5">7.0</data>
  <data key="d6">GPT-3.5-turbo's scores are compared to GPT-4, with GPT-4 showing significant improvements.".</data>
  <data key="d7">benchmark comparison, reasoning accuracy</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="HotPotQA" target="ColBERTv2">
  <data key="d5">18.0</data>
  <data key="d6">Passages retrieved by ColBERTv2 are used as input for multi-hop reasoning in HotPotQA.".&lt;SEP&gt;Passages retrieved by ColBERTv2 are used for multi-hop reasoning tasks in HotPotQA.".</data>
  <data key="d7">retrieval, question answering</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="HotPotQA" target="in-context learning">
  <data key="d5">6.0</data>
  <data key="d6">In-context learning techniques are applied to improve multi-hop question answering performance on HotPotQA.&lt;SEP&gt;In-context learning techniques are used to improve question answering performance on HotPotQA.</data>
  <data key="d7">learning paradigm, QA&lt;SEP&gt;learning paradigm, QA performance</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="HotPotQA" target="self-consistency">
  <data key="d5">4.0</data>
  <data key="d6">Self-consistency improves answer accuracy by aggregating multiple reasoning paths in HotPotQA.</data>
  <data key="d7">accuracy enhancement, reasoning&lt;SEP&gt;accuracy, reasoning</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="HotPotQA" target="Wang et al. (2022a)">
  <data key="d5">2.0</data>
  <data key="d6">Wang et al. (2022a) achieved EM and F1 scores on HotPotQA using advanced prompting and self-consistency techniques.&lt;SEP&gt;Wang et al. (2022a) achieved EM and F1 scores on HotPotQA using advanced prompting techniques.</data>
  <data key="d7">research achievement, evaluation</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="dspy.Retrieve" target="BasicMultiHop">
  <data key="d5">16.0</data>
  <data key="d6">The BasicMultiHop module uses the retrieve component to gather passages for each hop in reasoning.".&lt;SEP&gt;The BasicMultiHop module uses the retrieve component to gather relevant passages for each reasoning hop.".</data>
  <data key="d7">retrieval, multi-hop reasoning</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="BootstrapFewShotWithRandomSearch" target="T5-Large">
  <data key="d5">14.0</data>
  <data key="d6">Bootstrap and fine-tuning techniques are applied to T5-Large to improve performance on the task.".&lt;SEP&gt;This approach is used for fine-tuning T5-Large to improve its performance in the question answering task.".</data>
  <data key="d7">fine-tuning, bootstrapping</data>
  <data key="d8">chunk-9596cd861216e68aa0fdb35edbc9a132</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="answer EM" target="multihop t5defined">
  <data key="d5">12.0</data>
  <data key="d6">The T5-Large program scores 39.3% answer EM, indicating its ability to produce correct answers in the evaluation.&lt;SEP&gt;The multihop T5 program scores 39.3% answer EM, measuring its ability to correctly answer questions in the evaluation.</data>
  <data key="d7">performance metric, evaluation</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="expert human reasoning" target="Yao et al. (2022)">
  <data key="d5">16.0</data>
  <data key="d6">Yao et al. (2022) discusses adaptation of expert reasoning for retrieval settings, forming a theoretical basis for current methods.&lt;SEP&gt;Yao et al. (2022) discusses the adaptation of expert reasoning to retrieval settings, providing theoretical underpinnings for current approaches.</data>
  <data key="d7">theoretical foundation, adaptation</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Yao et al. (2022)" target="Prompt 3">
  <data key="d5">14.0</data>
  <data key="d6">Yao et al. (2022) explores the ReAct methodology, which combines reasoning and acting in language models, relevant to the activity's focus on reasoning techniques.&lt;SEP&gt;Yao et al. (2022) is related to ReAct methodology, suggesting it contributes to research on reasoning or action-based models.</data>
  <data key="d7">Research Methods</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="case studies" target="DSPy">
  <data key="d5">7.0</data>
  <data key="d6">The case studies demonstrate DSPy's application in various tasks, illustrating its practical effectiveness.</data>
  <data key="d7">application, validation</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="model evaluation" target="evaluation metrics">
  <data key="d5">3.0</data>
  <data key="d6">Evaluation metrics quantify the performance of models on tasks like code generation and correctness.</data>
  <data key="d7">performance evaluation</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="model evaluation" target="metrics for alignment">
  <data key="d5">9.0</data>
  <data key="d6">Metrics quantify how well models meet alignment goals, including correctness, safety, and helpfulness."|</data>
  <data key="d7">performance measurement, evaluation criteria</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="model evaluation" target="perplexity">
  <data key="d5">14.0</data>
  <data key="d6">Perplexity is used to evaluate how well the language model predicts tokens during training and validation, indicating model quality.</data>
  <data key="d7">performance metric, evaluation</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Stanford DAWN project" target="Support">
  <data key="d5">6.0</data>
  <data key="d6">Supports</data>
  <data key="d7">The DAWN project supports AI research including the development of systematic frameworks, with industry backing from Facebook, Google, VMware.</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Stanford DAWN project" target="supports">
  <data key="d5">6.0</data>
  <data key="d6">Supports</data>
  <data key="d7">The DAWN project supports collaborative AI research, including the development of systematic frameworks, with industry backing from Facebook, Google, and VMware.</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="NSF CAREER grant CNS-1651570" target="Funding">
  <data key="d5">5.0</data>
  <data key="d6">Supports</data>
  <data key="d7">The NSF grant provides funding for AI research projects related to systematic frameworks.</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="NSF CAREER grant CNS-1651570" target="funding">
  <data key="d5">5.0</data>
  <data key="d6">Supports</data>
  <data key="d7">The NSF grant provides financial support for research in systematic AI frameworks and related projects.</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Program of thoughts prompting" target="Disentangling computation from reasoning">
  <data key="d5">8.0</data>
  <data key="d6">The methodology aims to separate computation from reasoning processes in AI models to improve numerical reasoning.</data>
  <data key="d7">methodology, reasoning, computation</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Training verifiers to solve math word problems" target="Methods">
  <data key="d5">8.0</data>
  <data key="d6">A method involving training models to verify solutions to math problems, enhancing reasoning accuracy.</data>
  <data key="d7">method, verification, math problems</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Language model cascades" target="Methods">
  <data key="d5">7.0</data>
  <data key="d6">A layered approach where multiple language models are used sequentially to improve task performance.</data>
  <data key="d7">method, layered models</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Training classifiers with natural language explanations" target="Methods">
  <data key="d5">8.0</data>
  <data key="d6">Uses natural language explanations to train classifiers, improving interpretability and accuracy.</data>
  <data key="d7">explanations, interpretability</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Robust Multi-Hop Reasoning at Scale via Condensed Retrieval" target="Methods">
  <data key="d5">8.0</data>
  <data key="d6">A retrieval-based approach designed to perform large-scale multi-hop reasoning efficiently.</data>
  <data key="d7">multi-hop reasoning, retrieval</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Relevance-guided supervision for openqa with ColBERT" target="Methods">
  <data key="d5">8.0</data>
  <data key="d6">Supervision technique using relevance feedback with ColBERT for open-domain QA.</data>
  <data key="d7">supervision, relevance feedback, QA</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Knowledge-Intensive NLP" target="Retrieval-augmented Generation">
  <data key="d5">8.0</data>
  <data key="d6">Retrieval-augmented generation enhances knowledge-intensive NLP tasks by integrating external knowledge sources.</data>
  <data key="d7">knowledge retrieval, generative models</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Decomposed Prompting" target="Complex Tasks">
  <data key="d5">8.0</data>
  <data key="d6">Decomposed prompting provides a modular approach to solving complex tasks by breaking them into manageable components.</data>
  <data key="d7">task decomposition, modular prompting</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Zero-Shot Reasoning" target="Language Models">
  <data key="d5">8.0</data>
  <data key="d6">Large language models are capable of zero-shot reasoning, performing tasks without explicit training examples for those tasks.</data>
  <data key="d7">zero-shot learning, reasoning capability</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Retrieval-Augmented Generation (RAG)" target="Sequence-to-Sequence Models">
  <data key="d5">9.0</data>
  <data key="d6">RAG combines seq2seq models with retrieval mechanisms to enhance knowledge-based generation.</data>
  <data key="d7">integration, hybrid</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="LlamaIndex" target="Prompt 7">
  <data key="d5">15.0</data>
  <data key="d6">LlamaIndex&lt;SEP&gt;LlamaIndex is used for relevant document retrieval, supporting document-based reasoning and evidence gathering.</data>
  <data key="d7">Tools and Application&lt;SEP&gt;is used for relevant documents retrieval, supporting document-based AI applications.</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="LlamaIndex" target="Prompt 8">
  <data key="d5">16.0</data>
  <data key="d6">LlamaIndex&lt;SEP&gt;LlamaIndex supports the development of AI chatbots for IRS, facilitating conversational access to information, illustrating its application in AI tools.</data>
  <data key="d7">Tools and Application&lt;SEP&gt;is employed for an IRS chatbot, demonstrating its utility in conversational AI and information retrieval.</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Large Language Models (LLMs)" target="Pre-trained Language Models (PLMs)">
  <data key="d5">16.0</data>
  <data key="d6">PLMs are a type of LLMs that are pre-trained on large text corpora, forming the basis for more specialized models.&lt;SEP&gt;PLMs are a type of LLMs that are pre-trained on large text corpora, forming the foundation for further specialization.</data>
  <data key="d7">model foundation, hierarchy&lt;SEP&gt;model hierarchy, foundational models</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models (LLMs)" target="Transformer Architecture">
  <data key="d5">18.0</data>
  <data key="d6">Transformer architecture underpins many LLMs and PLMs, enabling their capacity to process sequential data effectively.&lt;SEP&gt;Transformer architecture underpins many LLMs, enabling their ability to process and generate human-like language.</data>
  <data key="d7">architectural basis, NLP processing</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Training language models to follow instructions with human feedback" target="Long Ouyang">
  <data key="d5">16.0</data>
  <data key="d6">Long Ouyang contributed to research on training language models using human feedback to enhance instruction adherence and performance."|&lt;SEP&gt;Long Ouyang contributed to research on training language models using human feedback to improve instruction following.</data>
  <data key="d7">research contribution, instruction following&lt;SEP&gt;research contribution, model training</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Interleaving retrieval with chain-of-thought reasoning" target="arXiv preprint arXiv:2212.10509">
  <data key="d5">7.0</data>
  <data key="d6">This preprint introduces a methodology combining retrieval and reasoning to improve complex question answering.</data>
  <data key="d7">methodology, research approach</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Backpropagation with callbacks" target="Advances in Neural Information Processing Systems">
  <data key="d5">6.0</data>
  <data key="d6">This conference publication discusses foundational techniques for efficient differentiable programming.</data>
  <data key="d7">conference, research dissemination</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Rationale-augmented ensembles in language models" target="arXiv preprint arXiv:2207.00747">
  <data key="d5">8.0</data>
  <data key="d6">This preprint presents a model that enhances language reasoning through ensemble-based rationale integration.</data>
  <data key="d7">research, model enhancement</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Self-consistency improves chain of thought reasoning in language models" target="arXiv preprint arXiv:2203.11171">
  <data key="d5">7.0</data>
  <data key="d6">This work proposes mechanisms to improve reasoning consistency and accuracy in language models.</data>
  <data key="d7">research, reasoning improvement</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Transformers: State-of-the-art natural language processing" target="Proceedings of EMNLP 2020">
  <data key="d5">8.0</data>
  <data key="d6">This publication details the transformer architecture as a state-of-the-art NLP model.</data>
  <data key="d7">conference, foundational model</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Large language models as optimizers" target="arXiv preprint arXiv:2309.03409">
  <data key="d5">6.0</data>
  <data key="d6">This research explores the application of large language models in optimization tasks, with implications for AI capabilities.</data>
  <data key="d7">application, AI development</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="HotpotQA: A dataset for diverse, explainable multi-hop question answering" target="arXiv preprint arXiv:1809.09600">
  <data key="d5">7.0</data>
  <data key="d6">This dataset is used to evaluate multi-hop reasoning and explainability in question answering systems.</data>
  <data key="d7">dataset, evaluation tool</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="React: Synergizing reasoning and acting in language models" target="arXiv preprint arXiv:2210.03629">
  <data key="d5">8.0</data>
  <data key="d6">This framework aims to improve language models by integrating reasoning and action capabilities.</data>
  <data key="d7">model framework, reasoning and acting</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Answering questions by meta-reasoning over multiple chains of thought" target="arXiv preprint arXiv:2304.13007">
  <data key="d5">7.0</data>
  <data key="d6">This research introduces meta-reasoning techniques to enhance multi-chain reasoning in question answering.</data>
  <data key="d7">research, reasoning enhancement</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Automatic chain of thought prompting in large language models" target="arXiv preprint arXiv:2210.03493">
  <data key="d5">7.0</data>
  <data key="d6">This method automates prompt generation to induce chain-of-thought reasoning in language models.</data>
  <data key="d7">technique, prompting</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ExpeL: LLM agents are experiential learners" target="arXiv preprint arXiv:2308.10144">
  <data key="d5">6.0</data>
  <data key="d6">This framework conceptualizes LLM agents as experiential learners to facilitate adaptive learning processes.</data>
  <data key="d7">application, learning paradigm</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Automatic model selection with large language models for reasoning" target="arXiv preprint arXiv:2305.14333">
  <data key="d5">7.0</data>
  <data key="d6">This research focuses on using LLMs to automatically select models suited for specific reasoning tasks.</data>
  <data key="d7">methodology, model selection</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="arXiv preprint arXiv:2203.14465" target="Star: Bootstrapping reasoning with reasoning">
  <data key="d5">6.0</data>
  <data key="d6">This approach uses iterative reasoning to bootstrap and improve model reasoning capabilities.</data>
  <data key="d7">methodology, reasoning improvement</data>
  <data key="d8">chunk-2a8c8185b8c21a596df9bcd098f56ca4</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Zhuosheng Zhang" target="Chain of Thought Prompting">
  <data key="d5">16.0</data>
  <data key="d6">Zhuosheng Zhang's research involves automatic chain of thought prompting in large language models.</data>
  <data key="d7">technique, reasoning enhancement</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Aston Zhang" target="Hypercomplex Parameterization">
  <data key="d5">16.0</data>
  <data key="d6">Aston Zhang investigated hypercomplex parameterizations like quaternions for model layers.</data>
  <data key="d7">model architecture, parameterization</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LangChain" target="Prompt 2">
  <data key="d5">16.0</data>
  <data key="d6">LangChain is used as a framework to build and run language models for solving math word problems, demonstrating its application in AI reasoning tasks.&lt;SEP&gt;LangChain is used in conjunction with Gao et al. (2023b) for handling math word problems, indicating its role as a tool or framework facilitating such tasks.</data>
  <data key="d7">Tools and Application</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="LangChain" target="Prompt 4">
  <data key="d5">15.0</data>
  <data key="d6">LangChain is used for Zero-shot ReAct, enabling language models to perform reasoning tasks without prior examples, illustrating its role as a tool.&lt;SEP&gt;LangChain is used for Zero-shot ReAct, indicating its application in zero-shot reasoning or task execution.</data>
  <data key="d7">Tools and Application</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="LangChain" target="Prompt 5">
  <data key="d5">16.0</data>
  <data key="d6">LangChain&lt;SEP&gt;LangChain is employed in QA with sources, supporting source retrieval and answer generation, crucial for evidence-based responses.</data>
  <data key="d7">Prompt 5 involves QA with sources, showing LangChain's role in question-answering systems that incorporate source retrieval.&lt;SEP&gt;Tools and Application</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="LangChain" target="Prompt 6">
  <data key="d5">15.0</data>
  <data key="d6">LangChain</data>
  <data key="d7">Prompt 6 involves SQL querying, indicating its use for database or data retrieval tasks.&lt;SEP&gt;enables SQL querying, which is used for data retrieval and analysis, showing its utility in structured data handling.</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Gao et al. (2023a)" target="Prompt 1">
  <data key="d5">14.0</data>
  <data key="d6">Gao et al. (2023a) is referenced in relation to checking text evidence, implying it provides research or data relevant to the activity.&lt;SEP&gt;Gao et al. (2023a) provides evidence or data related to verifying text statements, supporting the activity's goal of checking text evidence.</data>
  <data key="d7">Research Support</data>
  <data key="d8">chunk-d47a0e3d5d118be72a9f7b527b440956</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Ava Etemadzadeh" target="Sexual Harassment Allegations">
  <data key="d5">6.0</data>
  <data key="d6">Ava Etemadzadeh was the Labour activist allegedly harassed by Kelvin Hopkins.</data>
  <data key="d7">victim, allegation</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Ava Etemadzadeh" target="Kelvin Hopkins">
  <data key="d5">6.0</data>
  <data key="d6">Ava Etemadzadeh was allegedly targeted by Kelvin Hopkins for inappropriate behavior.</data>
  <data key="d7">victim, allegation</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Kelvin Hopkins" target="Sexual Harassment Allegations">
  <data key="d5">26.0</data>
  <data key="d6">Kelvin Hopkins was accused of sexual harassment and inappropriate contact, prompting investigation.&lt;SEP&gt;Kelvin Hopkins was accused of sexual harassment, leading to investigation and suspension.</data>
  <data key="d7">accusation, misconduct</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Kelvin Hopkins" target="Labour Party">
  <data key="d5">19.0</data>
  <data key="d6">Kelvin Hopkins was suspended by the Labour Party following allegations and pending investigation.&lt;SEP&gt;The Labour Party suspended Kelvin Hopkins following the allegations of misconduct.</data>
  <data key="d7">disciplinary action, organizational response&lt;SEP&gt;disciplinary action, suspension</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Kelvin Hopkins" target="2017">
  <data key="d5">8.0</data>
  <data key="d6">Kelvin Hopkins was accused of misconduct in 2017, leading to suspension.</data>
  <data key="d7">temporal, causality</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Kelvin Hopkins" target="Investigation">
  <data key="d5">7.0</data>
  <data key="d6">The Labour Party conducted an investigation into Kelvin Hopkins' misconduct allegations.</data>
  <data key="d7">process, inquiry</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Kelvin Hopkins" target="Disciplinary Action">
  <data key="d5">10.0</data>
  <data key="d6">The Labour Party's disciplinary action was to suspend Kelvin Hopkins pending further investigation.</data>
  <data key="d7">organizational response, disciplinary measure</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Kelvin Hopkins" target="Inappropriate Physical Contact">
  <data key="d5">8.0</data>
  <data key="d6">Kelvin Hopkins was accused of inappropriate physical contact as part of misconduct allegations.</data>
  <data key="d7">accusation, misconduct</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Labour Party" target="Investigation">
  <data key="d5">7.0</data>
  <data key="d6">The Labour Party conducted an investigation into Kelvin Hopkins' conduct.</data>
  <data key="d7">organizational process, misconduct inquiry</data>
  <data key="d8">chunk-e7179702fce1ff6441001accbe9a590e</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Leah" target="Chocolates Eaten">
  <data key="d5">16.0</data>
  <data key="d6">Leah's chocolates are reduced by the amount eaten, affecting total chocolates remaining.</data>
  <data key="d7">causality, quantity reduction</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Sister" target="Chocolates Eaten">
  <data key="d5">16.0</data>
  <data key="d6">Sister's chocolates are reduced by the amount eaten, influencing total chocolates remaining.</data>
  <data key="d7">causality, quantity reduction</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Total Chocolates" target="Chocolates Eaten">
  <data key="d5">18.0</data>
  <data key="d6">Total chocolates are the sum of Leah's and her sister's initial chocolates, used to compute remaining chocolates after eating.</data>
  <data key="d7">aggregation, calculation</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Chocolates Eaten" target="Remaining Chocolates">
  <data key="d5">8.0</data>
  <data key="d6">Remaining chocolates are obtained by subtracting chocolates eaten from total chocolates.</data>
  <data key="d7">arithmetic, subtraction</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Chocolates Eaten" target="Chocolates Left">
  <data key="d5">8.0</data>
  <data key="d6">Remaining chocolates are obtained by subtracting chocolates eaten from total chocolates.</data>
  <data key="d7">arithmetic, subtraction</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Cars Initial" target="Cars in Parking Lot">
  <data key="d5">14.0</data>
  <data key="d6">The initial number of cars in the parking lot is 3, before new cars arrive.</data>
  <data key="d7">initial quantity, baseline</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Cars Initial" target="Total Cars">
  <data key="d5">16.0</data>
  <data key="d6">Total cars after new arrivals are calculated by adding the initial cars to the new arrivals.</data>
  <data key="d7">addition, sum</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Trees in Grove" target="Trees After">
  <data key="d5">16.0</data>
  <data key="d6">The number of trees after planting is obtained by adding the number of trees planted to the initial count.&lt;SEP&gt;The number of trees after planting is obtained by the initial number plus the trees planted, which is the difference between after and initial counts.</data>
  <data key="d7">addition, planting&lt;SEP&gt;arithmetic, difference</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Trees in Grove" target="Trees Planted">
  <data key="d5">8.0</data>
  <data key="d6">The trees planted are calculated as the difference between the number of trees after planting and the initial count.</data>
  <data key="d7">subtraction, planting</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Trees in Grove" target="Initial Trees">
  <data key="d5">7.0</data>
  <data key="d6">The initial number of trees in the grove is 15, before planting.</data>
  <data key="d7">initial count, baseline</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Trees in Grove" target="Trees Added">
  <data key="d5">8.0</data>
  <data key="d6">The number of trees planted is calculated as the difference between trees after and initial trees.</data>
  <data key="d7">subtraction, planting</data>
  <data key="d8">chunk-d85df6d86061474b90ef1ebb5195d860</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Elia Kazan" target="Rebel Without a Cause">
  <data key="d5">16.0</data>
  <data key="d6">Elia Kazan directed the film Rebel Without a Cause, making it a key work in his filmography and cultural history.&lt;SEP&gt;Elia Kazan directed the influential 1955 film Rebel Without a Cause, which is a significant part of his filmography.</data>
  <data key="d7">film direction, cultural impact</data>
  <data key="d8">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Arthur’s Magazine" target="First for Women">
  <data key="d5">14.0</data>
  <data key="d6">Arthur’s Magazine was published earlier (1844-1846) than First for Women (started in 1989), establishing a chronological publication order.&lt;SEP&gt;Arthur’s Magazine was published earlier (1844-1846) than First for Women (started in 1989), making it the first magazine of the two.</data>
  <data key="d7">publication history, chronological order&lt;SEP&gt;publication history, chronology</data>
  <data key="d8">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Pavel Urysohn" target="Leonid Levin">
  <data key="d5">11.0</data>
  <data key="d6">Both Pavel Urysohn and Leonid Levin are renowned mathematicians, but Urysohn is known for dimension theory while Levin is recognized for computational complexity, indicating different areas of expertise.&lt;SEP&gt;Both are prominent mathematicians but specialized in different fields—Urysohn in dimension theory and Levin in computational complexity, highlighting their distinct areas of expertise.</data>
  <data key="d7">disciplinary differences&lt;SEP&gt;mathematical specialization, research focus</data>
  <data key="d8">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Pavel Urysohn" target="Dimension Theory">
  <data key="d5">6.0</data>
  <data key="d6">Pavel Urysohn is known for his contributions to dimension theory, a branch of mathematics.</data>
  <data key="d7">mathematical specialization</data>
  <data key="d8">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Leonid Levin" target="Computational Complexity">
  <data key="d5">6.0</data>
  <data key="d6">Leonid Levin is recognized for his work in computational complexity, a core area of theoretical computer science.</data>
  <data key="d7">research focus</data>
  <data key="d8">chunk-e384ac8e647dff2556f72fe5244aa59d</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="ParameterLM" target="Prediction">
  <data key="d5">16.0</data>
  <data key="d6">The ParameterLM generates predictions which are encapsulated in Prediction objects."|&gt;"model output, text generation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-06f4652e3f59fe7bb73c99f5346f2b82</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Optuna" target="Best Program">
  <data key="d5">18.0</data>
  <data key="d6">Optuna optimizes the program parameters to find the configuration that yields the highest evaluation score."|&gt;"hyperparameter tuning, optimization&lt;SEP&gt;Optuna optimizes the program to find the highest scoring configuration.</data>
  <data key="d7">9&lt;SEP&gt;optimization, hyperparameter tuning</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Training Set" target="Validation Set">
  <data key="d5">10.0</data>
  <data key="d6">The training set is used to develop the program, while the validation set assesses its performance and generalization."|&gt;"dataset management, evaluation&lt;SEP&gt;The training set is used to develop the program, while the validation set assesses its performance.</data>
  <data key="d7">5&lt;SEP&gt;dataset management, evaluation</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Score" target="Best Program">
  <data key="d5">20.0</data>
  <data key="d6">The score measures how well the best program performs based on evaluation metrics.&lt;SEP&gt;The score quantifies the performance of the best program configuration after optimization."|&gt;"performance metric</data>
  <data key="d7">10&lt;SEP&gt;performance metric</data>
  <data key="d8">chunk-f43aff49a19ae4052ebd930786a46d8b</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Twilight" target="Harper Connelly Mysteries">
  <data key="d5">12.0</data>
  <data key="d6">Both are vampire-themed fantasy romance novel series, illustrating genre diversity and thematic exploration.</data>
  <data key="d7">genre, thematic diversity</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Victorian art and culture" target="Core Concepts">
  <data key="d5">9.0</data>
  <data key="d6">The documentary series 'The Victorians - Their Story In Pictures' explores Victorian art and culture, serving as the central theme of the text."|"&lt;theme, cultural focus</data>
  <data key="d7">9</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Jeremy Paxman" target="The Victorians - Their Story In Pictures">
  <data key="d5">14.0</data>
  <data key="d6">Jeremy Paxman is the presenter and possibly the creator of the documentary series about Victorian art and culture, linking his biography to the content.</data>
  <data key="d7">biography, content creation</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Jeremy Paxman" target="Research Question/Hypotheses">
  <data key="d5">24.0</data>
  <data key="d6">The inquiry about Jeremy Paxman's birth year relates to understanding his background in relation to the Victorian documentary series he authored.&lt;SEP&gt;The question about Jeremy Paxman's birth year is relevant to biographical context and understanding his connection to Victorian era themes."|"&lt;biographical context</data>
  <data key="d7">8&lt;SEP&gt;biographical research, context</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Jeremy Paxman" target="Content of Series">
  <data key="d5">7.0</data>
  <data key="d6">Jeremy Paxman is the presenter and likely the author of the Victorian-themed documentary series, connecting his biography and expertise to the content."|"&lt;biography, content creation</data>
  <data key="d7">7</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="The Caxtons" target="Victorian">
  <data key="d5">8.0</data>
  <data key="d6">The novel is a Victorian-era literary work, establishing its historical and cultural context.</data>
  <data key="d7">literature, era</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="Methodology">
  <data key="d5">16.0</data>
  <data key="d6">DSPy is a framework that abstracts language model operations into modular units, enabling systematic pipeline optimization without hand-crafted prompts.&lt;SEP&gt;DSPy is a framework that enables modular, high-level pipeline construction and optimization for language models, replacing traditional prompt engineering."|&gt;"system design, abstraction</data>
  <data key="d7">8&lt;SEP&gt;system design, modularity</data>
  <data key="d8">chunk-26c6a2c314e1450a2c8d666abac03b85</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="programs, training sets">
  <data key="d5">8.0</data>
  <data key="d6">The development and evaluation of programs against training sets are core to the methodology for system validation.&lt;SEP&gt;The development of programs against training sets is part of the methodology for system evaluation.</data>
  <data key="d7">methodology, development</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="DSPy" target="study">
  <data key="d5">7.0</data>
  <data key="d6">The case studies demonstrate DSPy's practical application in various tasks, validating its effectiveness and versatility.</data>
  <data key="d7">application, validation</data>
  <data key="d8">chunk-ed0f2ed4617819fd44b380fe3e3951f0</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Language Models" target="Unsupervised Multitask Learners">
  <data key="d5">18.0</data>
  <data key="d6">Language models are characterized as unsupervised multitask learners, capable of performing various language tasks without explicit supervision.</data>
  <data key="d7">learning paradigm, multitask training</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Language Models" target="Transfer Learning">
  <data key="d5">16.0</data>
  <data key="d6">Transfer learning enhances language models by allowing them to apply knowledge from one task to improve performance on others.</data>
  <data key="d7">knowledge transfer, model enhancement</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Language Models" target="Text-to-Text Transformer">
  <data key="d5">14.0</data>
  <data key="d6">The Text-to-Text Transformer architecture is a methodology used within language models to unify multiple NLP tasks into a single framework.</data>
  <data key="d7">model architecture, task unification</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Language Models" target="K-adapters">
  <data key="d5">7.0</data>
  <data key="d6">K-adapters inject knowledge learned from multiple domains into language models by concatenation, enhancing their multi-domain capabilities.</data>
  <data key="d7">knowledge transfer, multi-domain learning</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Language Models" target="LoRA">
  <data key="d5">9.0</data>
  <data key="d6">LoRA modules are added in parallel to pre-trained weights, enabling efficient fine-tuning without altering the original parameters.</data>
  <data key="d7">parameter freezing, efficient fine-tuning</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Language Models" target="Hindle et al. (2012)">
  <data key="d5">14.0</data>
  <data key="d6">Investigated the predictability of code using n-gram language models, showing code's relative predictability over natural language.</data>
  <data key="d7">predictability, language modeling</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Methodology" target="Pal">
  <data key="d5">8.0</data>
  <data key="d6">Integrates programmatic reasoning into language models to enhance their reasoning capabilities.</data>
  <data key="d7">methodology, programmatic reasoning</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Methodology" target="Realm">
  <data key="d5">8.0</data>
  <data key="d6">Uses retrieval mechanisms during pre-training to augment language model knowledge and performance.</data>
  <data key="d7">retrieval, pre-training</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Methodology" target="Retrieve and refine: Improved sequence generation models for dialogue">
  <data key="d5">8.0</data>
  <data key="d6">This work introduces models that retrieve relevant information and refine dialogue responses to improve conversational AI.</data>
  <data key="d7">dialogue systems, response generation</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Methodology" target="Reasoning over semantic-level graph for fact checking">
  <data key="d5">9.0</data>
  <data key="d6">This approach employs semantic graphs to facilitate reasoning and verify factual correctness.</data>
  <data key="d7">fact checking, semantic graphs</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Methodology" target="MPI">
  <data key="d5">9.0</data>
  <data key="d6">MPI serves as a target execution model for translating serial code, with LLM performance assessed on this translation.</data>
  <data key="d7">parallel communication, code translation</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Methodology" target="CUDA">
  <data key="d5">8.0</data>
  <data key="d6">CUDA is a target platform for code translation, used to assess LLMs' ability to generate GPU-accelerated code.</data>
  <data key="d7">GPU computing, code translation</data>
  <data key="d8">chunk-873e4d15525881588c22e6d0a81e435e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Methodology" target="Zero-Shot Replication Framework">
  <data key="d5">8.0</data>
  <data key="d6">A framework enabling experiments to be replicated without prior training, supporting zero-shot learning approaches."|&gt;"research methodology, replication</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Core Concepts" target="Source Code Summarization">
  <data key="d5">16.0</data>
  <data key="d6">Automated techniques to produce brief descriptions of code functionalities."|&gt;"task, AI&lt;SEP&gt;The task of generating summaries for source code to facilitate understanding."|&gt;"task, AI application</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Core Concepts" target="Program Synthesis with Large Language Models">
  <data key="d5">9.0</data>
  <data key="d6">Automated generation of code fulfilling specified functionalities using language models."|&gt;"task, AI, code</data>
  <data key="d7">9</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Core Concepts" target="Neural Code Generation">
  <data key="d5">8.0</data>
  <data key="d6">Using neural networks to generate or synthesize source code."|&gt;"model, AI</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Core Concepts" target="Data Race Detection">
  <data key="d5">8.0</data>
  <data key="d6">Identifying issues related to concurrent access to shared data in programs."|&gt;"software engineering, concurrency</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Core Concepts" target="Parallel algorithms">
  <data key="d5">8.0</data>
  <data key="d6">Recurring structures like OpenMP, MPI, and CUDA are fundamental to parallel algorithm design and implementation."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Core Concepts" target="Parallelism">
  <data key="d5">8.0</data>
  <data key="d6">Parallelism refers to executing multiple computations simultaneously, enabled by task partitioning, patterns, and hardware capabilities.</data>
  <data key="d7">concurrency, hardware utilization</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Core Concepts" target="Domain Knowledge">
  <data key="d5">9.0</data>
  <data key="d6">Domain knowledge includes facts, principles, and patterns specific to a field, which can be explicit or implicit in form.</data>
  <data key="d7">field-specific information, embedded knowledge</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Stanford Institute for Human-Centered AI" target="Support">
  <data key="d5">8.0</data>
  <data key="d6">Supports</data>
  <data key="d7">The institute supports research into systematic AI frameworks, including text transformation graphs.</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Support" target="IBM, Oracle, Virtusa, Cigna Healthcare">
  <data key="d5">7.0</data>
  <data key="d6">Support</data>
  <data key="d7">These organizations provide resources, funding, or support for research on AI systems like text transformation graphs.</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="IBM, Oracle, Virtusa, Cigna Healthcare" target="supports">
  <data key="d5">7.0</data>
  <data key="d6">Support</data>
  <data key="d7">These organizations provide funding, resources, or strategic support for research and development of AI frameworks like text transformation graphs.</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Stanford Institute for Human-Centered Artificial Intelligence" target="supports">
  <data key="d5">8.0</data>
  <data key="d6">Supports</data>
  <data key="d7">The institute provides support, resources, and funding for research into systematic AI frameworks, including text transformation graphs.</data>
  <data key="d8">chunk-583d728170557abef78a4cab2b68abb2</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Methods" target="Enabling intelligent interactions between an agent and an LLM">
  <data key="d5">7.0</data>
  <data key="d6">Applies reinforcement learning to facilitate interactions between agents and language models.</data>
  <data key="d7">reinforcement learning, agent-LLM interaction</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Methods" target="Few-shot learning with retrieval-augmented language models">
  <data key="d5">8.0</data>
  <data key="d6">Employs retrieval mechanisms to enhance few-shot learning performance.</data>
  <data key="d7">few-shot learning, retrieval</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Methods" target="Mrkl systems">
  <data key="d5">8.0</data>
  <data key="d6">A neuro-symbolic architecture combining language models with external knowledge sources and reasoning modules.</data>
  <data key="d7">neuro-symbolic, external knowledge, reasoning</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Methods" target="Neural Adapters">
  <data key="d5">6.0</data>
  <data key="d6">Neural adapters serve as modules that adapt the model to specific domains, balancing performance improvements and implementation complexity.</data>
  <data key="d7">modular adaptation, domain tuning</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Rarr" target="Research Question/Hypotheses">
  <data key="d5">9.0</data>
  <data key="d6">Researching how language models can be used to evaluate and revise their own outputs.</data>
  <data key="d7">self-evaluation, model improvement</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Research Question/Hypotheses" target="Connecting large language models with evolutionary algorithms">
  <data key="d5">7.0</data>
  <data key="d6">Investigates whether combining language models with evolutionary algorithms can optimize prompts.</data>
  <data key="d7">prompt optimization, evolutionary algorithms</data>
  <data key="d8">chunk-1154df731c16a689d34b73768a34217a</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="The Victorian (comics)" target="Victorian">
  <data key="d5">10.0</data>
  <data key="d6">The comic series is based on Victorian themes, connecting media to historical era.</data>
  <data key="d7">media, historical influence</data>
  <data key="d8">chunk-66e5a3f496b5e1530da70355696b5224</data>
  <data key="d9">DSPY - COMPILING DECLARATIVE LANGUAGE MODEL CALLS INTO SELF-IMPROVING PIPELINES - 2310.03714v1.pdf</data>
</edge>
<edge source="Wikipedia" target="Fact Veriﬁcation (FEVER)">
  <data key="d5">16.0</data>
  <data key="d6">Wikipedia serves as the evidence source for retrieving information to support or refute claims in the FEVER task.</data>
  <data key="d7">evidence retrieval, fact support</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Wikipedia" target="FEVER">
  <data key="d5">18.0</data>
  <data key="d6">FEVER relies on Wikipedia as the evidence source for classifying claims, linking the core concept of fact verification to the object of study of Wikipedia.&lt;SEP&gt;FEVER relies on Wikipedia as the evidence source for verifying claims, linking the core concept of claim verification to the object of study of Wikipedia.</data>
  <data key="d7">evidence source, verification</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Wikipedia" target="RAG models">
  <data key="d5">18.0</data>
  <data key="d6">RAG models use Wikipedia as a primary source for retrieving relevant documents to inform generation and fact verification.</data>
  <data key="d7">source usage, information retrieval</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Wikipedia" target="Factual Knowledge">
  <data key="d5">18.0</data>
  <data key="d6">Wikipedia provides the factual content that models retrieve and utilize to generate accurate answers.&lt;SEP&gt;Wikipedia serves as a primary external source providing factual content that models retrieve and utilize for accurate responses.</data>
  <data key="d7">knowledge base, external source</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Evaluation metrics" target="Assessment of GPT-3 capabilities">
  <data key="d5">10.0</data>
  <data key="d6">The assessment employs specific metrics to evaluate the correctness, relevance, and quality of code outputs generated by GPT-3 and Codex.</data>
  <data key="d7">evaluation process</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Evaluation metrics" target="Scientific kernels for HPC">
  <data key="d5">8.0</data>
  <data key="d6">The generated scientific kernels are evaluated using defined metrics to determine correctness, efficiency, and suitability for HPC applications."|"&lt;performance assessment</data>
  <data key="d7">8</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Interpretability" target="WARP">
  <data key="d5">14.0</data>
  <data key="d6">WARP studies highlight that soft prompt tuning often results in prompts that are non-interpretable and lack meaningful content, raising interpretability concerns.&lt;SEP&gt;WARP studies reveal that soft prompts are often non-interpretable and lack meaningful content, raising interpretability concerns."|&gt;"interpretability, soft prompts</data>
  <data key="d7">7&lt;SEP&gt;interpretability, soft prompts</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Interpretability" target="KnowPrompt">
  <data key="d5">12.0</data>
  <data key="d6">KnowPrompt discovers domain-related prompt tokens, which can improve interpretability by linking prompts to meaningful domain terms.&lt;SEP&gt;KnowPrompt discovers domain-related prompt tokens, which can make prompts more interpretable by linking them to meaningful domain terms."|&gt;"domain relevance, interpretability</data>
  <data key="d7">6&lt;SEP&gt;domain relevance, prompt tokens</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="BART" target="RAG">
  <data key="d5">8.0</data>
  <data key="d6">BART serves as the generative component conditioned on retrieved documents in RAG models.</data>
  <data key="d7">generation, conditioning</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="BART" target="Jeopardy Question Generation">
  <data key="d5">12.0</data>
  <data key="d6">BART is compared with RAG models, showing that while BART can complete titles from partial prompts, it is less factual and specific than RAG models in this context.</data>
  <data key="d7">model comparison, factuality</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Knowledge Updating" target="Index Hot-Swapping">
  <data key="d5">16.0</data>
  <data key="d6">Replacing indices allows models like RAG to update world knowledge efficiently without retraining.</data>
  <data key="d7">knowledge update, index management</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG-Token Model" target="Top-K Documents">
  <data key="d5">7.0</data>
  <data key="d6">Allows different retrieved documents for each token, enabling more flexible content selection.</data>
  <data key="d7">model architecture, token-level marginalization</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG-Token Model" target="retriever">
  <data key="d5">9.0</data>
  <data key="d6">The RAG-Token model incorporates the retriever component to select relevant documents during generation.</data>
  <data key="d7">integration, retrieval</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="BART-large" target="RAG">
  <data key="d5">8.0</data>
  <data key="d6">BART-large functions as the generator component in RAG, producing output sequences conditioned on input and retrieved documents.</data>
  <data key="d7">generation, sequence modeling</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Training" target="RAG">
  <data key="d5">7.0</data>
  <data key="d6">The joint training process optimizes both the retriever and generator components simultaneously to improve overall performance on knowledge-intensive tasks.</data>
  <data key="d7">training methodology</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG-Token" target="Jeopardy Question Generation">
  <data key="d5">16.0</data>
  <data key="d6">RAG-Token performs better than RAG-Sequence in Jeopardy question generation tasks, indicating its superior ability to generate relevant, diverse responses.</data>
  <data key="d7">model performance, diversity</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG-Token" target="Fact Verification">
  <data key="d5">14.0</data>
  <data key="d6">RAG-Token achieves competitive accuracy on FEVER, demonstrating its effectiveness in fact verification tasks without extensive domain-specific engineering.</data>
  <data key="d7">accuracy, fact verification</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Wikipedia dump (December 2018)" target="Document encoder">
  <data key="d5">16.0</data>
  <data key="d6">The Wikipedia dump is processed by the document encoder to generate embeddings for retrieval and knowledge source in experiments.</data>
  <data key="d7">knowledge source, retrieval</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Document encoder" target="FAISS">
  <data key="d5">14.0</data>
  <data key="d6">The document encoder's embeddings are stored and retrieved efficiently using the FAISS index.</data>
  <data key="d7">retrieval efficiency, embedding</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="MSMARCO NLG task v2.1" target="RAG">
  <data key="d5">16.0</data>
  <data key="d6">RAG is applied to generate answers for MSMARCO questions using retrieved passages, testing its natural language generation capabilities.</data>
  <data key="d7">NLG, knowledge reliance</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jeopardy Question Generation" target="RAG">
  <data key="d5">18.0</data>
  <data key="d6">RAG is used to generate Jeopardy-style questions conditioned on entity answers, demonstrating its knowledge-based generation abilities.</data>
  <data key="d7">factuality, question generation</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Y" target="Vowels">
  <data key="d5">7.0</data>
  <data key="d6">The letter 'y' is considered a vowel only at the end of words, affecting the vowel counting logic in the function.</data>
  <data key="d7">contextual phonetics, language rules</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Y" target="Vowels_Count">
  <data key="d5">8.0</data>
  <data key="d6">The function counts 'y' as a vowel only when it appears at the end of a word, demonstrating a context-dependent classification."|&gt;"logic, language rules</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Beam Search" target="Tasklet Scheduling">
  <data key="d5">8.0</data>
  <data key="d6">Beam search offers a pruning strategy to manage the exponential search space in tasklet scheduling, improving predictability and stability.</data>
  <data key="d7">search algorithm, scheduling stability</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="FEVER" target="Label Accuracy">
  <data key="d5">7.0</data>
  <data key="d6">Label accuracy measures how well models classify claims correctly in FEVER.</data>
  <data key="d7">evaluation, classification</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="FEVER" target="Study Dataset">
  <data key="d5">14.0</data>
  <data key="d6">FEVER provides a benchmark dataset for fact extraction and verification, used to evaluate model performance.</data>
  <data key="d7">dataset, evaluation</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="3.4 Fact Verification" target="Retrieval Problem">
  <data key="d5">8.0</data>
  <data key="d6">FEVER frames claim verification as a retrieval problem coupled with entailment reasoning to determine claim support or refutation.</data>
  <data key="d7">retrieval, reasoning</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="3.4 Fact Verification" target="Entailment Reasoning">
  <data key="d5">8.0</data>
  <data key="d6">Entailment reasoning is used within FEVER to assess whether retrieved evidence supports or refutes claims.</data>
  <data key="d7">reasoning, support/refute</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Retrieval Problem" target="Entailment Reasoning">
  <data key="d5">8.0</data>
  <data key="d6">FEVER combines retrieval with entailment reasoning to classify claims, showing the relationship between the retrieval process and logical inference.</data>
  <data key="d7">retrieval, reasoning</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG Models" target="Open-domain Question Answering">
  <data key="d5">14.0</data>
  <data key="d6">RAG models are applied to open-domain QA tasks, demonstrating their ability to combine retrieval and generation effectively.&lt;SEP&gt;RAG models are applied to open-domain QA tasks, demonstrating their effectiveness in combining retrieval and generative capabilities.</data>
  <data key="d7">application, performance</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Open-domain Question Answering" target="RAG">
  <data key="d5">18.0</data>
  <data key="d6">RAG is evaluated for its ability to answer questions by retrieving relevant documents and generating answers, compared to other QA paradigms.</data>
  <data key="d7">model evaluation, knowledge-intensive tasks</data>
  <data key="d8">chunk-99d4d675d4565ed5a3ce6fb12d24e2ee</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG models" target="Retrieval">
  <data key="d5">16.0</data>
  <data key="d6">Semantic parsing and retrieval components work together in RAG models to improve factual accuracy and relevance of generated responses.&lt;SEP&gt;The retrieval component in RAG models supports the generation process by providing relevant evidence, improving factual accuracy.</data>
  <data key="d7">model architecture, evidence support&lt;SEP&gt;model architecture, information support</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG models" target="Latent Retrieval">
  <data key="d5">14.0</data>
  <data key="d6">Latent retrieval techniques are integrated into RAG models to learn implicit representations that aid in retrieving relevant evidence.&lt;SEP&gt;Latent retrieval techniques enable models to learn implicit representations that improve retrieval relevance and efficiency.</data>
  <data key="d7">representation learning, model enhancement</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Document Posterior" target="Generation Process">
  <data key="d5">16.0</data>
  <data key="d6">The document posterior influences which document the model relies on during generation, affecting the factual accuracy and relevance of outputs.</data>
  <data key="d7">model interpretability, document influence</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Parametric Knowledge" target="Title Completion">
  <data key="d5">14.0</data>
  <data key="d6">Parametric knowledge stored in BART's parameters allows it to complete titles without external documents, indicating internalized information.</data>
  <data key="d7">internal knowledge, title completion</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Non-parametric Memory" target="Generation Guidance">
  <data key="d5">8.0</data>
  <data key="d6">External retrieval guides generation by providing relevant documents, improving factual accuracy and specificity.</data>
  <data key="d7">retrieval influence, generation quality</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Document 1" target="Document 2">
  <data key="d5">7.0</data>
  <data key="d6">Both documents contain information about Hemingway's works and are used collectively for retrieval to support accurate fact verification and question generation.</data>
  <data key="d7">complementary sources, retrieval</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Document 2" target="Document 5">
  <data key="d5">7.0</data>
  <data key="d6">Supporting document for fact verification, providing supplementary evidence for claims about Hemingway.</data>
  <data key="d7">evidence support, verification</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Document 3" target="Document 4">
  <data key="d5">6.0</data>
  <data key="d6">Additional documents are used to enhance retrieval coverage and improve overall factual correctness.</data>
  <data key="d7">additional sources, coverage</data>
  <data key="d8">chunk-16f8966714d5949d2ce008e4018d6933</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Purgatorio" target="Paradiso">
  <data key="d5">16.0</data>
  <data key="d6">Both are parts of Dante's Divine Comedy, representing different stages of the soul's journey in the afterlife.</data>
  <data key="d7">literary structure, thematic progression</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Thorne" target="Vlachos">
  <data key="d5">14.0</data>
  <data key="d6">Thorne and Vlachos's models are used as benchmarks for classifying claims and evidence in fact verification tasks.</data>
  <data key="d7">model comparison, evidence classification</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RoBERTa" target="Claim Classification">
  <data key="d5">18.0</data>
  <data key="d6">RoBERTa is employed to classify claims as true or false based on evidence sentences.</data>
  <data key="d7">model application, natural language understanding</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Gold Evidence Sentence" target="Claim Verification">
  <data key="d5">16.0</data>
  <data key="d6">Gold evidence sentences serve as the ground truth for verifying the correctness of claims.</data>
  <data key="d7">verification, ground truth</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Top k documents" target="Document Title Overlap">
  <data key="d5">16.0</data>
  <data key="d6">Overlap analysis assesses the accuracy of retrieval by comparing document titles with gold evidence.</data>
  <data key="d7">retrieval accuracy, evaluation</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="BM25" target="Relevance Framework">
  <data key="d5">16.0</data>
  <data key="d6">The probabilistic relevance framework, including BM25, is used to rank documents based on their relevance to queries in information retrieval systems.</data>
  <data key="d7">ranking algorithms, information retrieval</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Index Hot-Swapping" target="World Leaders">
  <data key="d5">16.0</data>
  <data key="d6">Using different indices from 2016 or 2018 to evaluate the model's ability to update and retrieve current information.</data>
  <data key="d7">knowledge update, retrieval accuracy</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Accuracy" target="Validation Data">
  <data key="d5">7.0</data>
  <data key="d6">Validation accuracy measures the model's token prediction correctness on the validation dataset.</data>
  <data key="d7">7</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Accuracy" target="Evaluation Metric">
  <data key="d5">9.0</data>
  <data key="d6">Accuracy measures the correctness of model predictions, such as generated pragmas or performance classifications.</data>
  <data key="d7">performance measurement, correctness</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Semantic Parsing" target="Retrieval">
  <data key="d5">18.0</data>
  <data key="d6">Semantic parsing enhances retrieval accuracy by converting natural language questions into structured queries, enabling precise evidence fetching.&lt;SEP&gt;Semantic parsing enhances retrieval by converting natural language questions into structured queries, improving the accuracy of evidence fetching.</data>
  <data key="d7">methodology, information extraction</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Semantic Parsing" target="Andrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, and Denny Zhou">
  <data key="d5">16.0</data>
  <data key="d6">The researchers are working on compositional semantic parsing with large language models, establishing a direct relationship to this research area.&lt;SEP&gt;The researchers are working on compositional semantic parsing with large language models, linking them to this research area.</data>
  <data key="d7">semantic understanding, large models</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Factual Knowledge" target="Societal Benefits">
  <data key="d5">14.0</data>
  <data key="d6">Grounding models in factual knowledge can lead to societal benefits such as improved information accuracy and decision-making support.</data>
  <data key="d7">application, societal impact</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Model Retraining" target="Knowledge Source Bias">
  <data key="d5">12.0</data>
  <data key="d6">Retraining models with external data sources like Wikipedia can introduce or reinforce biases present in those sources.&lt;SEP&gt;Retraining models with external sources like Wikipedia can introduce or reinforce biases present in those sources.</data>
  <data key="d7">training data, bias propagation</data>
  <data key="d8">chunk-6c82d084cc6bf7773cde2e068c3bcedc</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Association for Computational Linguistics" target="Eunsol Choi">
  <data key="d5">10.0</data>
  <data key="d6">The ACL organization is associated with Eunsol Choi's research activities in NLP.&lt;SEP&gt;The organization is associated with the publication and research activities of Eunsol Choi in NLP.</data>
  <data key="d7">organizational affiliation</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Eunsol Choi" target="Coarse-to-fine question answering for long documents">
  <data key="d5">16.0</data>
  <data key="d6">Eunsol Choi authored the study on question answering for long documents.</data>
  <data key="d7">authorship, research contribution</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Christopher Clark" target="Simple and Effective Multi-Paragraph Reading Comprehension">
  <data key="d5">16.0</data>
  <data key="d6">Christopher Clark authored the paper on multi-paragraph reading comprehension.</data>
  <data key="d7">authorship, research contribution</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jacob Devlin" target="BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding">
  <data key="d5">18.0</data>
  <data key="d6">Jacob Devlin authored or co-authored the BERT paper, a foundational NLP model.&lt;SEP&gt;Jacob Devlin authored the BERT paper, a foundational NLP model.</data>
  <data key="d7">authorship, model development</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Ming-Wei Chang" target="Structured Prediction">
  <data key="d5">8.0</data>
  <data key="d6">Ming-Wei Chang contributed to structured prediction frameworks and retrieval-based NLP models.</data>
  <data key="d7">research contribution, structured NLP</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Kenton Lee" target="Retrieval Models">
  <data key="d5">8.0</data>
  <data key="d6">Kenton Lee contributed to retrieval models and language understanding in NLP systems.</data>
  <data key="d7">research contribution, retrieval models</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Emily Dinan" target="Wizard of Wikipedia: Knowledge-powered conversational agents">
  <data key="d5">16.0</data>
  <data key="d6">Emily Dinan contributed to research on knowledge-powered conversational agents.</data>
  <data key="d7">research topic, authorship</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Angela Fan" target="Hierarchical neural story generation">
  <data key="d5">16.0</data>
  <data key="d6">Angela Fan authored the work on hierarchical story generation.</data>
  <data key="d7">research contribution, methodology</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Angela Fan" target="ELI5: Long form question answering">
  <data key="d5">16.0</data>
  <data key="d6">Angela Fan contributed to research on long-form question answering.</data>
  <data key="d7">research topic, authorship</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Angela Fan" target="Augmenting transformers with KNN-based composite memory">
  <data key="d5">16.0</data>
  <data key="d6">Angela Fan developed or contributed to this methodology for transformer enhancement.</data>
  <data key="d7">methodology development</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Thibault Févry" target="Entities as experts: Sparse memory access with entity supervision">
  <data key="d5">16.0</data>
  <data key="d6">Thibault Févry contributed to research on sparse memory and entity supervision in NLP.</data>
  <data key="d7">research contribution, methodology</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Tom Kwiatkowski" target="Natural Questions Dataset">
  <data key="d5">18.0</data>
  <data key="d6">Kwiatkowski's work involves the Natural Questions dataset as a benchmark for question answering systems.&lt;SEP&gt;Kwiatkowski's work involves the Natural Questions dataset as a benchmark for question answering.</data>
  <data key="d7">dataset utilization, NLP benchmarking&lt;SEP&gt;dataset, evaluation</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Marjan Ghazvininejad" target="A knowledge-grounded neural conversation model">
  <data key="d5">16.0</data>
  <data key="d6">Marjan Ghazvininejad contributed to neural conversation models grounded in knowledge.</data>
  <data key="d7">research topic, authorship</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="When will AI exceed human performance? evidence from AI experts" target="Katja Grace">
  <data key="d5">16.0</data>
  <data key="d6">Katja Grace contributed to research on AI performance prediction and expert surveys.&lt;SEP&gt;Katja Grace contributed to research on AI performance prediction.</data>
  <data key="d7">research contribution, expertise</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Search engine guided neural machine translation" target="Jiatao Gu">
  <data key="d5">16.0</data>
  <data key="d6">Jiatao Gu authored or contributed to the methodology for search engine guided neural translation.&lt;SEP&gt;Jiatao Gu authored or contributed to the search engine-guided translation methodology.</data>
  <data key="d7">research contribution, methodology</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jiatao Gu" target="AAAI Conference on Artificial Intelligence 2018">
  <data key="d5">14.0</data>
  <data key="d6">Presented research on neural machine translation at the conference.</data>
  <data key="d7">conference presentation, research dissemination</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Kelvin Guu" target="REALM">
  <data key="d5">16.0</data>
  <data key="d6">Kelvin Guu contributed to the development of the retrieval-augmented language model framework, integrating retrieval into pretraining.&lt;SEP&gt;Kelvin Guu contributed to the development of the retrieval-augmented language model framework.</data>
  <data key="d7">model development, research contribution</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Retrieve-and-Edit Framework" target="Tatsunori Hashimoto">
  <data key="d5">16.0</data>
  <data key="d6">Hashimoto contributed to structured output prediction frameworks involving retrieve-and-edit techniques.</data>
  <data key="d7">research contribution, framework development</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Nabil Hossain" target="Simple and Effective Retrieve-Edit-Rerank Text Generation">
  <data key="d5">18.0</data>
  <data key="d6">Hossain developed methods combining retrieval, editing, and reranking for text generation.&lt;SEP&gt;Hossain developed methods combining retrieval, editing, and reranking to improve text generation quality.</data>
  <data key="d7">methodology development, NLP improvement</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jeff Johnson" target="Similarity Search with GPUs">
  <data key="d5">16.0</data>
  <data key="d6">Johnson worked on scalable similarity search methods utilizing GPU acceleration for efficient retrieval systems.&lt;SEP&gt;Johnson worked on scalable similarity search methods utilizing GPU acceleration.</data>
  <data key="d7">technology development, scalable search</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Zora Tung" target="Retrieval Models">
  <data key="d5">8.0</data>
  <data key="d6">Zora Tung worked on retrieval techniques and language modeling for NLP tasks.</data>
  <data key="d7">research contribution, retrieval techniques</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Panupong Pasupat" target="Structured Prediction">
  <data key="d5">8.0</data>
  <data key="d6">Pasupat is involved in structured prediction tasks that utilize retrieval and language understanding.</data>
  <data key="d7">research focus, structured NLP</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Urvashi Khandelwal" target="Generalization through Memorization">
  <data key="d5">16.0</data>
  <data key="d6">Khandelwal's research explores how language models can memorize and generalize from data.&lt;SEP&gt;Khandelwal's research explores how language models memorize data to improve generalization and retrieval capabilities.</data>
  <data key="d7">research focus, model generalization</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Omer Levy" target="Dense Passage Retrieval">
  <data key="d5">8.0</data>
  <data key="d6">Levy contributed to the development of dense retrieval methods for NLP, especially for question answering.</data>
  <data key="d7">research contribution, retrieval methods</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Dan Jurafsky" target="Language Understanding">
  <data key="d5">8.0</data>
  <data key="d6">Jurafsky's work encompasses language understanding, models, and applications in NLP.</data>
  <data key="d7">research focus, NLP applications</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Luke Zettlemoyer" target="Language Modeling and Retrieval">
  <data key="d5">8.0</data>
  <data key="d6">Zettlemoyer contributed to language modeling, retrieval, and structured prediction frameworks.</data>
  <data key="d7">research contribution, NLP models</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Mike Lewis" target="Language Models and Retrieval">
  <data key="d5">8.0</data>
  <data key="d6">Lewis worked on integrating retrieval into language models and improving generalization in NLP.</data>
  <data key="d7">research contribution, retrieval-enhanced models</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Diederik P. Kingma" target="Adam Optimization">
  <data key="d5">9.0</data>
  <data key="d6">Kingma developed the Adam optimizer, a widely used method for training neural networks efficiently.</data>
  <data key="d7">methodology, optimization</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jimmy Ba" target="Adam Optimization">
  <data key="d5">9.0</data>
  <data key="d6">Ba co-developed the Adam optimizer, improving training processes for neural networks.</data>
  <data key="d7">methodology, training efficiency</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Matthijs Douze" target="Similarity Search with GPUs">
  <data key="d5">8.0</data>
  <data key="d6">Douze contributed to scalable similarity search algorithms and large-scale retrieval systems.</data>
  <data key="d7">research contribution, scalable retrieval</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Hervé Jégou" target="Similarity Search with GPUs">
  <data key="d5">8.0</data>
  <data key="d6">Jégou developed algorithms for efficient similarity search at scale, often leveraging GPU acceleration.</data>
  <data key="d7">technology development, high-performance retrieval</data>
  <data key="d8">chunk-b5a1ae2fdbff2671d10e6572fa6fc442</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Advances in Neural Information Processing Systems 32" target="Research Team">
  <data key="d5">7.0</data>
  <data key="d6">The publication is edited by the research team, disseminating advancements in neural information processing.</data>
  <data key="d7">publication, dissemination</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Advances in Neural Information Processing Systems 32" target="Alché-Buc, E. Fox, and R. Garnett">
  <data key="d5">7.0</data>
  <data key="d6">The publication edited by the research team disseminates research findings in neural information processing.</data>
  <data key="d7">publication, dissemination</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="BERT" target="Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova">
  <data key="d5">9.0</data>
  <data key="d6">These researchers co-developed BERT, a foundational language understanding model, establishing a direct relationship between authors and the model.</data>
  <data key="d7">transformer, pre-training</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Transfer Learning" target="Domain Adaptation">
  <data key="d5">8.0</data>
  <data key="d6">Transfer learning techniques underpin domain adaptation efforts, enabling prompts and models to generalize across domains."|</data>
  <data key="d7">concept</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Transfer Learning" target="Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig">
  <data key="d5">8.0</data>
  <data key="d6">They explore parameter-efficient transfer learning, aiming to unify various approaches, directly linking researchers to this concept.</data>
  <data key="d7">transfer learning, efficiency</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Transfer Learning" target="Methodologies">
  <data key="d5">7.0</data>
  <data key="d6">Transfer learning is employed to adapt pre-trained models to HPC-specific tasks with limited data.</data>
  <data key="d7">knowledge transfer, domain adaptation</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Parameters" target="Knowledge Packing">
  <data key="d5">12.0</data>
  <data key="d6">The capacity of language models to encode knowledge depends on the number of parameters, influencing their ability to perform complex tasks.</data>
  <data key="d7">model capacity, information encoding</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Memory Networks" target="Fact Extraction and Verification Dataset (FEVER)">
  <data key="d5">14.0</data>
  <data key="d6">Memory networks are employed in tasks like fact verification to reason over stored information and extract facts from large datasets like FEVER.</data>
  <data key="d7">reasoning, knowledge retrieval</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Catastrophic Forgetting" target="Downstream Task Learning">
  <data key="d5">8.0</data>
  <data key="d6">Fine-tuning on new tasks can cause catastrophic forgetting, leading to loss of previously learned knowledge.</data>
  <data key="d7">knowledge retention, model stability</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Catastrophic Forgetting" target="Knowledge Updates">
  <data key="d5">6.0</data>
  <data key="d6">Knowledge updates based on explicit instructions risk causing catastrophic forgetting, which limits the model's ability to retain previous knowledge when learning new information.</data>
  <data key="d7">limitations, knowledge retention</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Attention Mechanism" target="Neural Network Architectures">
  <data key="d5">14.0</data>
  <data key="d6">Attention mechanisms are a core component of modern neural architectures, enabling models to focus on relevant input parts for better performance.</data>
  <data key="d7">model component, focus mechanism</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Diverse Beam Search" target="Natural Language Generation">
  <data key="d5">16.0</data>
  <data key="d6">Diverse beam search improves the quality of generated language by promoting output variety in sequence models.</data>
  <data key="d7">generation technique, diversity enhancement</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Model Biases" target="Social Impacts of Language Models">
  <data key="d5">16.0</data>
  <data key="d6">Biases in language models can contribute to societal issues such as misinformation and unfair stereotypes, highlighting the importance of understanding and mitigating biases.</data>
  <data key="d7">ethical considerations, societal impact</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Model Biases" target="Elastic Weight Consolidation">
  <data key="d5">12.0</data>
  <data key="d6">EWC is used to mitigate biases and prevent catastrophic forgetting, thereby improving model fairness and stability.</data>
  <data key="d7">bias mitigation, continual learning</data>
  <data key="d8">chunk-19e79205b492f438828e7baefec8588e</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, Jing Jiang" target="R3: Reinforced ranker-reader for open-domain question answering">
  <data key="d5">8.0</data>
  <data key="d6">The study presents a reinforcement learning-based methodology for open-domain question answering systems.</data>
  <data key="d7">methodology, question answering</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, Jing Jiang" target="Evidence aggregation for answer re-ranking in open-domain question answering">
  <data key="d5">9.0</data>
  <data key="d6">This research focuses on techniques for aggregating evidence to improve answer ranking in open-domain QA.</data>
  <data key="d7">evidence, answer ranking</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="R3: Reinforced ranker-reader for open-domain question answering" target="Shuohang Wang">
  <data key="d5">8.0</data>
  <data key="d6">This study presents a reinforcement learning approach to improve answer ranking in open-domain QA systems.</data>
  <data key="d7">methodology, question answering</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="R3: Reinforced ranker-reader for open-domain question answering" target="Memory networks">
  <data key="d5">7.0</data>
  <data key="d6">The R3 methodology may incorporate memory networks to enhance answer retrieval.</data>
  <data key="d7">model architecture, enhancement</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Evidence aggregation for answer re-ranking in open-domain question answering" target="Shuohang Wang">
  <data key="d5">8.0</data>
  <data key="d6">This research develops techniques for aggregating evidence to enhance answer accuracy.</data>
  <data key="d7">evidence, answer re-ranking</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Evidence aggregation for answer re-ranking in open-domain question answering" target="Xiaoxiao Guo">
  <data key="d5">8.0</data>
  <data key="d6">Xiaoxiao Guo's work focuses on evidence aggregation techniques to improve answer ranking.</data>
  <data key="d7">evidence, answer ranking</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Memory networks" target="Theoretical Model">
  <data key="d5">8.0</data>
  <data key="d6">Memory networks are used as a model architecture to enhance reasoning and information retrieval in NLP tasks.</data>
  <data key="d7">model architecture, reasoning</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Memory networks" target="Mo Yu">
  <data key="d5">8.0</data>
  <data key="d6">Mo Yu's research involves the development and application of memory networks for reasoning in NLP tasks.</data>
  <data key="d7">model, reasoning</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Memory networks" target="Program induction">
  <data key="d5">7.0</data>
  <data key="d6">Memory networks support program induction by providing external memory for reasoning and algorithm learning."|</data>
  <data key="d7">neural architectures</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Addressing semantic drift in question generation for semi-supervised question answering" target="Research Study">
  <data key="d5">8.0</data>
  <data key="d6">This study aims to reduce semantic drift in question generation to improve semi-supervised QA.</data>
  <data key="d7">question generation, semantic drift</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Zhiguo Wang" target="Question answering">
  <data key="d5">8.0</data>
  <data key="d6">Zhiguo Wang contributes to developing NLP models for question answering systems.</data>
  <data key="d7">model, question answering</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Tim Klinger" target="Question answering">
  <data key="d5">8.0</data>
  <data key="d6">Tim Klinger works on AI models related to question answering and evidence retrieval.</data>
  <data key="d7">model, evidence retrieval</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Shiyu Chang" target="Evidence aggregation">
  <data key="d5">8.0</data>
  <data key="d6">Shiyu Chang's research involves improving evidence aggregation techniques to enhance answer accuracy.</data>
  <data key="d7">evidence, answer accuracy</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Gerry Tesauro" target="Reinforcement learning">
  <data key="d5">8.0</data>
  <data key="d6">Gerry Tesauro's work focuses on reinforcement learning approaches for AI systems.</data>
  <data key="d7">learning technique, AI systems</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Bowen Zhou" target="Question answering">
  <data key="d5">8.0</data>
  <data key="d6">Bowen Zhou contributes to developing AI models for open-domain question answering.</data>
  <data key="d7">model, question answering</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Jing Jiang" target="Evidence aggregation">
  <data key="d5">8.0</data>
  <data key="d6">Jing Jiang's work involves techniques for evidence aggregation in question answering systems.</data>
  <data key="d7">evidence, question answering</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="DPR" target="RAG">
  <data key="d5">41.0</data>
  <data key="d6">DPR provides the non-parametric memory by retrieving relevant documents that inform the generator in RAG models.&lt;SEP&gt;DPR provides the non-parametric memory component by retrieving relevant documents for RAG models.&lt;SEP&gt;DPR provides the retrieval component for RAG models, using supervised signals to initialize effective retrieval in open-domain QA.&lt;SEP&gt;DPR provides the retrieval component for RAG, trained with supervised signals from datasets like Natural Questions and TriviaQA.&lt;SEP&gt;DPR serves as the retrieval component within the RAG framework, providing relevant documents for the generator to use.</data>
  <data key="d7">retrieval initialization, model component&lt;SEP&gt;retrieval, external knowledge&lt;SEP&gt;retrieval, initialization&lt;SEP&gt;retrieval, knowledge base</data>
  <data key="d8">chunk-3a383a22868857a4e9fe55978176d008&lt;SEP&gt;chunk-20aafa58f3d7697ab6ba5015b31cda9b&lt;SEP&gt;chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG" target="Evidence Retrieval and Generation">
  <data key="d5">20.0</data>
  <data key="d6">RAG integrates document retrieval with generative models to improve factual accuracy in tasks like question answering.</data>
  <data key="d7">retrieval, generation, evidence</data>
  <data key="d8">chunk-02a741669060d492fb68529287d315dd</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="RAG-Sequence Model" target="Top-K Documents">
  <data key="d5">7.0</data>
  <data key="d6">Uses the same retrieved document for entire sequence generation, marginalizing over the top K documents.</data>
  <data key="d7">model architecture, marginalization</data>
  <data key="d8">chunk-e185b4ac016fe0595175efaf985eeacb</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Decoding Strategies" target="RAG-Token and RAG-Sequence">
  <data key="d5">7.0</data>
  <data key="d6">Different decoding approaches are used to approximate the maximum likelihood of output sequences, balancing accuracy and efficiency.</data>
  <data key="d7">decoding, approximation</data>
  <data key="d8">chunk-20aafa58f3d7697ab6ba5015b31cda9b</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Matthew Dunn" target="SearchQA: A New Q&amp;A Dataset Augmented with Context from a Search Engine">
  <data key="d5">16.0</data>
  <data key="d6">Matthew Dunn authored or contributed to the SearchQA dataset study.&lt;SEP&gt;Matthew Dunn authored or contributed to the dataset study.</data>
  <data key="d7">dataset creation, authorship</data>
  <data key="d8">chunk-f649fd9f0abb33568aa0dd91ee5a605f</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Question answering" target="Wei Zhang">
  <data key="d5">8.0</data>
  <data key="d6">Wei Zhang develops AI models for open-domain question answering systems.</data>
  <data key="d7">model, question answering</data>
  <data key="d8">chunk-b576e2170fa3612deda92305d2850446</data>
  <data key="d9">NeurIPS-2020-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks-Paper.pdf</data>
</edge>
<edge source="Parallel Programming Models" target="HPC Numerical Kernels">
  <data key="d5">16.0</data>
  <data key="d6">HPC numerical kernels are designed to target parallel programming models, which are frameworks for concurrent computation in HPC.&lt;SEP&gt;HPC numerical kernels are designed to target parallel programming models, which facilitate concurrent computation in high-performance computing environments.</data>
  <data key="d7">object of study, computational framework</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Model Capabilities" target="Tasks">
  <data key="d5">6.0</data>
  <data key="d6">Different tasks' complexity influences the evaluation of model performance and capability."|&gt;"difficulty, assessment</data>
  <data key="d7">6</data>
  <data key="d8">chunk-4b0500ce797f3002cd2bbbd0d398db00</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Model Capabilities" target="Risks">
  <data key="d5">8.0</data>
  <data key="d6">Increased model capabilities can lead to higher risks of misalignment, bias, and unsafe outputs.</data>
  <data key="d7">capability, risk</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Capabilities" target="Potential for Malicious Use">
  <data key="d5">7.0</data>
  <data key="d6">Despite limitations, Codex's capacity to generate code can be exploited for malicious activities, especially as model capabilities improve.</data>
  <data key="d7">threat potential, AI capabilities</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Capabilities" target="Codex">
  <data key="d5">7.0</data>
  <data key="d6">While capable of code generation, Codex's limitations mean it cannot reliably detect vulnerabilities or always avoid insecure suggestions, but its potential for malicious use remains.</data>
  <data key="d7">threat potential, capability assessment</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="evaluation metrics" target="assessment of GPT-3 capabilities">
  <data key="d5">10.0</data>
  <data key="d6">The assessment employs specific metrics to evaluate the quality and correctness of code generated by GPT-3 models.</data>
  <data key="d7">evaluation process</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="evaluation metrics" target="scientific kernels for HPC">
  <data key="d5">8.0</data>
  <data key="d6">The generated kernels are evaluated using defined metrics to determine their correctness, efficiency, and suitability for HPC applications.</data>
  <data key="d7">evaluation criteria</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="evaluation metrics" target="Models' problem-solving capabilities">
  <data key="d5">7.0</data>
  <data key="d6">Metrics like pass@k and BLEU score are used to quantify the models' ability to generate correct code.</data>
  <data key="d7">performance measurement</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Transformer-based models" target="Large Language Models for Code">
  <data key="d5">18.0</data>
  <data key="d6">Transformer architectures underpin large language models trained on code, enabling advanced code generation and understanding functionalities.&lt;SEP&gt;Transformer models form the basis for large language models trained on code, enabling advanced code generation and understanding.</data>
  <data key="d7">model architecture, NLP, code generation</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Large Language Models for Code" target="Pre-training corpus">
  <data key="d5">15.0</data>
  <data key="d6">The pre-training corpus provides the foundational data on which code LLMs are trained, influencing their capabilities and scope.&lt;SEP&gt;The pre-training corpus provides the foundational data that shapes the model's knowledge and capabilities in code generation and understanding.</data>
  <data key="d7">training data, dataset influence&lt;SEP&gt;training data, knowledge base</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Token selection strategy" target="Code Generation Tasks">
  <data key="d5">20.0</data>
  <data key="d6">Token selection strategies like nucleus sampling and temperature control are crucial for producing high-quality code outputs from language models.&lt;SEP&gt;Token selection strategies like nucleus sampling and temperature control influence the quality, diversity, and correctness of generated code outputs.</data>
  <data key="d7">generation quality, sampling methods</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Nucleus Sampling" target="Model Temperature">
  <data key="d5">18.0</data>
  <data key="d6">Nucleus sampling and temperature are complementary techniques used to control the randomness and diversity of code generated by language models.&lt;SEP&gt;Nucleus sampling and temperature are techniques used together to control the randomness and diversity of generated code in language models.</data>
  <data key="d7">sampling techniques, output diversity</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Nucleus Sampling" target="Sampling Methods">
  <data key="d5">16.0</data>
  <data key="d6">Nucleus sampling selects tokens based on a cumulative probability p, aiming for more contextually appropriate and meaningful choices.&lt;SEP&gt;Nucleus sampling selects tokens based on a cumulative probability threshold p, aiming for more meaningful and contextually appropriate choices.</data>
  <data key="d7">probability threshold, contextual relevance</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Nucleus Sampling" target="Generated Code">
  <data key="d5">7.0</data>
  <data key="d6">Nucleus sampling with a cutoff of 0.93 is used to generate diverse code samples from the model.</data>
  <data key="d7">sampling technique, diversity</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Benchmarking LLMs for Code" target="Evaluation datasets">
  <data key="d5">16.0</data>
  <data key="d6">Standardized datasets like HumanEval and MBPP are used to evaluate and compare the performance of different code-generating models.&lt;SEP&gt;Standardized datasets such as HumanEval, MBPP, DS-1000, GSM8K, and CoderEval are used to evaluate model performance on various code generation tasks.</data>
  <data key="d7">benchmark datasets, performance evaluation</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Applying LLMs to Parallel and HPC Code" target="HPC tokenizer">
  <data key="d5">16.0</data>
  <data key="d6">HPC tokenizers like TOKOMPILER improve model understanding and processing of HPC code structures.&lt;SEP&gt;Specialized tokenizers like TOKOMPILER improve the model's ability to process HPC code syntax and structure, facilitating better code generation and analysis.</data>
  <data key="d7">specialized tokenization, model training</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Applying LLMs to Parallel and HPC Code" target="Parallel code">
  <data key="d5">8.0</data>
  <data key="d6">Models trained on parallel code can generate or analyze code that runs across multiple processors, aiding HPC workflows.</data>
  <data key="d7">code generation, parallel processing</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Applying LLMs to Parallel and HPC Code" target="OpenMP pragmas">
  <data key="d5">8.0</data>
  <data key="d6">Models can label or generate OpenMP pragmas to facilitate parallelization directives in HPC code.</data>
  <data key="d7">directive labeling, code annotation</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Applying LLMs to Parallel and HPC Code" target="Performance prediction">
  <data key="d5">8.0</data>
  <data key="d6">Models trained on HPC code can predict performance metrics, optimizing code efficiency in high-performance environments.</data>
  <data key="d7">performance estimation, optimization</data>
  <data key="d8">chunk-107fb981331e6facca90c9849f179ee2</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Nichols et al." target="HPCCoder">
  <data key="d5">18.0</data>
  <data key="d6">Nichols et al. introduce HPCCoder, a model fine-tuned on HPC code, and evaluate its performance in generating HPC code and related tasks.</data>
  <data key="d7">research development, model evaluation</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="TOKOMPILER" target="Kadosh et al.">
  <data key="d5">16.0</data>
  <data key="d6">Kadosh et al. introduce TOKOMPILER, an HPC-specific tokenizer, and use it to train COMPCODER.</data>
  <data key="d7">tool development, model training</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="COMPCODER" target="Kadosh et al.">
  <data key="d5">14.0</data>
  <data key="d6">Kadosh et al. train COMPCODER on C, C++, and Fortran code using TOKOMPILER.</data>
  <data key="d7">model training, HPC code generation</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Munley et al." target="LLMs">
  <data key="d5">16.0</data>
  <data key="d6">Munley et al. evaluate LLMs' ability to generate compiler verification tests for parallel OpenACC code.</data>
  <data key="d7">performance evaluation, parallel programming</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Chen et al." target="DRB-ML">
  <data key="d5">16.0</data>
  <data key="d6">Chen et al. develop the DRB-ML dataset to identify data races in parallel code and incorporate it into the LM4HPC framework.</data>
  <data key="d7">dataset creation, data race detection</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Godoy et al." target="LLMs">
  <data key="d5">14.0</data>
  <data key="d6">Godoy et al. evaluate LLMs' capabilities in generating HPC kernels, noting limitations in problem scope and evaluation practices.</data>
  <data key="d7">performance assessment, HPC kernel generation</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Valero-Lara et al." target="LLMs">
  <data key="d5">14.0</data>
  <data key="d6">Valero-Lara et al. similarly evaluate LLMs' ability to generate HPC kernels with limited problem sets.</data>
  <data key="d7">performance assessment, HPC kernel generation</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Prompt" target="Generated Code">
  <data key="d5">16.0</data>
  <data key="d6">The prompt guides the model to generate code, which is then evaluated for correctness and functional equivalence.&lt;SEP&gt;The prompt guides the model to generate code, which is then evaluated for correctness and functionality.</data>
  <data key="d7">8&lt;SEP&gt;prompt engineering, output evaluation</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Problem Type" target="Sort">
  <data key="d5">16.0</data>
  <data key="d6">The sort problem type involves generating code to sort arrays or sub-arrays, either in-place or out-of-place.</data>
  <data key="d7">problem definition, code generation</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problem Type" target="Scan">
  <data key="d5">16.0</data>
  <data key="d6">The scan problem type involves generating code to perform prefix sums or similar operations on arrays.</data>
  <data key="d7">problem definition, parallel operation</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problem Type" target="Dense Linear Algebra">
  <data key="d5">16.0</data>
  <data key="d6">Involves generating code for dense linear algebra functions from BLAS libraries.</data>
  <data key="d7">problem scope, linear algebra</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problem Type" target="Sparse Linear Algebra">
  <data key="d5">16.0</data>
  <data key="d6">Involves generating code for sparse linear algebra functions from BLAS libraries.</data>
  <data key="d7">problem scope, linear algebra</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problem Type" target="Search">
  <data key="d5">16.0</data>
  <data key="d6">Involves generating code to search for elements or properties within arrays.</data>
  <data key="d7">problem scope, search algorithms</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problem Type" target="Reduce">
  <data key="d5">16.0</data>
  <data key="d6">Involves generating code for reduction operations like summing array elements.</data>
  <data key="d7">problem scope, reduction operations</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problem Type" target="Histogram">
  <data key="d5">16.0</data>
  <data key="d6">Involves generating code to bin data values based on properties.</data>
  <data key="d7">problem scope, data binning</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problem Type" target="Stencil">
  <data key="d5">16.0</data>
  <data key="d6">Involves generating code for stencil computations such as Jacobi relaxation.&lt;SEP&gt;Involves generating code for stencil computations, such as Jacobi relaxation.</data>
  <data key="d7">problem scope, stencil computations</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problem Type" target="Graph">
  <data key="d5">16.0</data>
  <data key="d6">Involves generating code for graph algorithms like component counting.</data>
  <data key="d7">problem scope, graph algorithms</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problem Type" target="Geometry">
  <data key="d5">16.0</data>
  <data key="d6">Involves generating code to compute geometric properties such as convex hulls.</data>
  <data key="d7">problem scope, geometric computations</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problem Type" target="Fourier Transform">
  <data key="d5">16.0</data>
  <data key="d6">Involves generating code for Fourier transforms and their inverses.</data>
  <data key="d7">problem scope, Fourier analysis</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problem Type" target="Transform">
  <data key="d5">16.0</data>
  <data key="d6">Involves generating code to map a constant function to each element of an array.</data>
  <data key="d7">problem scope, array operations</data>
  <data key="d8">chunk-08927f4020e77ca8974c06ceacee30f7</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Sparse Linear Algebra" target="pass@1 score">
  <data key="d5">1.0</data>
  <data key="d6">Unstructured, Sparse Problems</data>
  <data key="d7">These are the most challenging problem types for LLMs, reflected in lower pass@1 scores.</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Geometry" target="Component counting">
  <data key="d5">14.0</data>
  <data key="d6">Component counting is used within geometric analysis to quantify elements like points or shapes, essential for geometric computations."|</data>
  <data key="d7">core concepts, geometric analysis</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Geometry" target="Convex Hull">
  <data key="d5">16.0</data>
  <data key="d6">Convex hull is a geometric object computed from a set of points, representing the minimal convex shape containing all points."|</data>
  <data key="d7">geometric objects, computational geometry</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Fourier Transform" target="Transform">
  <data key="d5">18.0</data>
  <data key="d6">Fourier Transform is a mathematical technique used to analyze the frequency components of signals or functions."|</data>
  <data key="d7">signal processing, mathematical analysis</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Transform" target="Problems">
  <data key="d5">12.0</data>
  <data key="d6">Transform maps a constant function to an array element, which can be used as a problem in computational tasks."|</data>
  <data key="d7">data transformation, problem design</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Problems" target="Problem Variations">
  <data key="d5">14.0</data>
  <data key="d6">Variations of problems are small modifications designed to evaluate the understanding of core functionalities."|</data>
  <data key="d7">problem design, evaluation</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Kokkos" target="Prompts">
  <data key="d5">16.0</data>
  <data key="d6">Kokkos prompts involve data structures like Kokkos::View for parallel code in portability libraries."|</data>
  <data key="d7">parallel libraries, code prompts</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Kokkos" target="Complete Node Coverage">
  <data key="d5">7.0</data>
  <data key="d6">Kokkos supports performance portability across entire nodes, similar to PPL's broader scope."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Kokkos" target="Complete node coverage">
  <data key="d5">7.0</data>
  <data key="d6">Kokkos supports performance portability across entire nodes, similar to PPL's goal of supporting cluster-wide applications."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Kokkos" target="code correctness">
  <data key="d5">5.0</data>
  <data key="d6">Kokkos's correctness varies with kernel complexity, generally lower for more complex kernels.</data>
  <data key="d7">model performance, code accuracy</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Kokkos" target="Kernel Performance">
  <data key="d5">12.0</data>
  <data key="d6">Kokkos performs poorly over several kernels, likely due to its smaller user community and abstraction complexity.&lt;SEP&gt;Kokkos performs poorly over several kernels, potentially due to the smaller user community and complexity of high-level abstractions.</data>
  <data key="d7">community size, abstraction complexity</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Prompts" target="C++">
  <data key="d5">14.0</data>
  <data key="d6">C++ is used as the language in prompts for serial, OpenMP, MPI, and MPI+OpenMP models."|</data>
  <data key="d7">programming languages, code prompts</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Prompts" target="CUDA">
  <data key="d5">16.0</data>
  <data key="d6">CUDA prompts are designed for GPU code generation targeting NVIDIA GPUs."|</data>
  <data key="d7">GPU programming, code generation</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Prompts" target="HIP">
  <data key="d5">16.0</data>
  <data key="d6">HIP prompts are used for GPU code targeting AMD GPUs."|</data>
  <data key="d7">GPU programming, code generation</data>
  <data key="d8">chunk-dfe74b691919432b3bb0f4652ee2468c</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="C++" target="model sensitivity">
  <data key="d5">16.0</data>
  <data key="d6">C++ exhibits variable sensitivity depending on the use of 'function' and the programming model, affecting code correctness.&lt;SEP&gt;C++ exhibits variable sensitivity depending on the use of the word 'function' and the programming model, affecting code correctness.</data>
  <data key="d7">programming language sensitivity, code correctness&lt;SEP&gt;programming language, model response</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="CUDA" target="Accelerator Offloading">
  <data key="d5">16.0</data>
  <data key="d6">CUDA provides the framework for offloading computation to GPUs, managing kernel execution and data transfer.&lt;SEP&gt;CUDA provides the framework for offloading computation to GPUs, managing kernel launches, memory transfers, and execution synchronization.</data>
  <data key="d7">GPU acceleration, offloading&lt;SEP&gt;GPU computing, offloading</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="CUDA" target="Thread Pool">
  <data key="d5">16.0</data>
  <data key="d6">CUDA provides the API and platform support for creating and managing thread pools that facilitate GPU offloading and concurrent task execution.&lt;SEP&gt;CUDA provides the underlying API and platform support for creating and managing thread pools for GPU offloading and parallel task execution.</data>
  <data key="d7">tools, parallel computing</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="CUDA" target="CUDA Calls">
  <data key="d5">18.0</data>
  <data key="d6">CUDA API functions manage memory and data transfer between CPU and GPU, enabling data movement essential for parallel processing.&lt;SEP&gt;CUDA calls like cudaMalloc, cudaFree, and cudaMemcpy are used to manage GPU memory and data transfer, enabling data movement essential for GPU-based parallel processing.</data>
  <data key="d7">memory management, data transfer</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="CUDA" target="GPU">
  <data key="d5">16.0</data>
  <data key="d6">CUDA is a hardware platform comprising GPUs used to accelerate parallel computations and offload processing from CPUs.&lt;SEP&gt;CUDA is a hardware platform that leverages GPUs for parallel processing, offloading computations from CPU to accelerate tasks.</data>
  <data key="d7">hardware acceleration, parallel processing</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="CUDA" target="code correctness">
  <data key="d5">8.0</data>
  <data key="d6">CUDA generally achieves higher correctness levels, especially for simpler kernels like AXPY and GEMV.</data>
  <data key="d7">model performance, code accuracy</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="CUDA" target="Language">
  <data key="d5">7.0</data>
  <data key="d6">CUDA's effectiveness depends on specific keywords like 'kernel' or '__global__', and improper prompt language can decrease code quality.</data>
  <data key="d7">prompt sensitivity, community syntax</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="CUDA" target="Kernel Syntax">
  <data key="d5">7.0</data>
  <data key="d6">The effectiveness of CUDA code generation depends on using community-specific keywords like 'kernel' or '__global__', and improper prompts can decrease quality.</data>
  <data key="d7">prompt sensitivity, community syntax</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="HIP" target="code correctness">
  <data key="d5">6.0</data>
  <data key="d6">HIP's correctness is comparable to CUDA for simpler kernels but lower for complex ones.</data>
  <data key="d7">model performance, code accuracy</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Section 7" target="Metrics">
  <data key="d5">5.0</data>
  <data key="d6">Section 7 describes the metrics used to evaluate the model outputs in code generation tasks.</data>
  <data key="d7">evaluation criteria, performance measurement</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Section 7" target="Study Design">
  <data key="d5">6.0</data>
  <data key="d6">Section 7 describes the evaluation metrics and procedures used to assess model performance in code generation and translation.</data>
  <data key="d7">evaluation methodology, metrics</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Experiment 2" target="Study Design">
  <data key="d5">16.0</data>
  <data key="d6">The experiment aims to evaluate how well models can translate code between specified pairs of execution models.&lt;SEP&gt;The experiment evaluates the ability of LLMs to translate code between specified pairs of execution models.</data>
  <data key="d7">translation capability, experimental design&lt;SEP&gt;translation capability, experimental setup</data>
  <data key="d8">chunk-8044b7aee8628a78f321eae0291f7292</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="StarCoderBase" target="The Stack">
  <data key="d5">8.0</data>
  <data key="d6">The dataset (The Stack) is used to train or evaluate the StarCoderBase model, which is designed for code infilling and supporting multiple programming languages.</data>
  <data key="d7">training data, model development</data>
  <data key="d8">chunk-aba26da203f4fd14ca664e347342978e</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="The Stack" target="Denis Kocetkov">
  <data key="d5">18.0</data>
  <data key="d6">The Stack is a large dataset of permissively licensed source code used for training and evaluating AI models.</data>
  <data key="d7">dataset, source code</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Speedup" target="Equation (2)">
  <data key="d5">18.0</data>
  <data key="d6">Equation (2) defines the expected maximum speedup for a prompt based on the ratio of the baseline runtime to the runtime of samples, linking mathematical modeling to performance evaluation."|&lt;SEP&gt;Equation (2) mathematically defines the expected best speedup relative to a sequential baseline for a given prompt, linking the concept of speedup to specific computational metrics."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Speedup" target="Equation (3)">
  <data key="d5">16.0</data>
  <data key="d6">Equation (3) calculates the average speedup across prompts, connecting individual prompt performance to overall model evaluation."|&lt;SEP&gt;Equation (3) calculates the average speedup over prompts, connecting individual sample performance metrics to overall model efficiency."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Speedup" target="Equation (4)">
  <data key="d5">16.0</data>
  <data key="d6">Equation (4) estimates the maximum achievable speedup over varying resource counts, relating resource scalability to performance."|&lt;SEP&gt;Equation (4) estimates the maximum speedup achievable over varying resource counts, relating hardware scalability to performance limits."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Speedup" target="Hotspot3D">
  <data key="d5">10.0</data>
  <data key="d6">Hotspot3D experienced a speedup of 2.72 due to optimized parallel execution of stencil borders.</data>
  <data key="d7">parallelization, performance gain</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Speedup" target="lavaMD">
  <data key="d5">16.0</data>
  <data key="d6">The speedup in lavaMD was partly due to optimizations from the Intel OneAPI compiler, enabling more aggressive optimizations.&lt;SEP&gt;lavaMD achieved a speedup of more than two, aided by compiler optimizations from Intel OneAPI.</data>
  <data key="d7">compiler optimization, performance improvement&lt;SEP&gt;compiler optimizations, performance</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Speedup" target="Backprop">
  <data key="d5">6.0</data>
  <data key="d6">The backprop benchmark experienced a slowdown of 0.81, indicating minimal or negative speedup.</data>
  <data key="d7">performance, optimization limitation</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Speedup" target="Hotspot">
  <data key="d5">8.0</data>
  <data key="d6">Hotspot's static code structure allowed for almost complete elimination of synchronization, leading to runtime reduction.</data>
  <data key="d7">synchronization reduction, runtime improvement</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Equation (3)" target="efficiency𝑛@𝑘">
  <data key="d5">17.0</data>
  <data key="d6">Equation (5)</data>
  <data key="d7">Equation (5) formalizes the calculation of efficiency𝑛@𝑘 by dividing by 𝑛, providing a standardized performance metric."|&lt;SEP&gt;Equation (5) modifies the definition of efficiency𝑛@𝑘 by dividing by 𝑛, formalizing the performance metric for code efficiency evaluation.</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="efficiency𝑛@𝑘" target="performance of the generated code">
  <data key="d5">19.0</data>
  <data key="d6">The metric defines the expected best performance efficiency of generated code based on attempts, reflecting how well the code utilizes parallel resources.&lt;SEP&gt;The metric quantifies how effectively the generated code utilizes resources and scales, reflecting overall performance."|</data>
  <data key="d7">10&lt;SEP&gt;performance measurement, resource utilization</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="parallel code" target="Resources">
  <data key="d5">8.0</data>
  <data key="d6">Parallel code relies on computational resources such as processes or threads to execute operations simultaneously."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="performance of the generated code" target="benchmarks (HumanEval, MBPP, DS-1000)">
  <data key="d5">15.0</data>
  <data key="d6">The benchmarks are used to measure speedup1@𝑘, which helps compare the efficiency of generated code against human baselines, providing insights into code quality and performance.&lt;SEP&gt;These benchmarks are used to measure speedup1@𝑘, comparing generated code performance to human baselines."|</data>
  <data key="d7">8&lt;SEP&gt;benchmark evaluation, performance comparison</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs (Large Language Models)" target="HuggingFace library">
  <data key="d5">13.0</data>
  <data key="d6">The HuggingFace library facilitates loading and inference of LLMs like GPT-3.5 and GPT-4 for code generation."|&lt;SEP&gt;The HuggingFace library is used to load and run inference on LLMs like GPT-3.5 and GPT-4, facilitating code generation for evaluation."|&lt;|"tool utilization, inference setup</data>
  <data key="d7">6&lt;SEP&gt;7</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs (Large Language Models)" target="NVIDIA A100 80GB GPU">
  <data key="d5">9.0</data>
  <data key="d6">The high-performance GPU hardware enables efficient inference of large models for code generation."|&lt;SEP&gt;The high-performance GPU hardware is used to run inference for code generation, ensuring efficient processing of large models."|&lt;|"hardware support, inference performance</data>
  <data key="d7">4&lt;SEP&gt;5</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs (Large Language Models)" target="OpenAI API">
  <data key="d5">7.0</data>
  <data key="d6">The OpenAI API is used to generate outputs from GPT-3.5 and GPT-4 models, with specific sampling configurations for diversity and quality."|&lt;|"API utilization, model output generation&lt;SEP&gt;The OpenAI API provides access to GPT-3.5 and GPT-4 for code output generation with specified parameters."|</data>
  <data key="d7">3&lt;SEP&gt;4</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs (Large Language Models)" target="Nucleus sampling">
  <data key="d5">5.0</data>
  <data key="d6">Nucleus sampling is a decoding method applied during inference to produce diverse outputs within a probability threshold p=0.95."|&lt;|"sampling technique, output diversity&lt;SEP&gt;Nucleus sampling is a decoding method used during inference to produce diverse outputs."|</data>
  <data key="d7">2&lt;SEP&gt;3</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="OpenAI API" target="Codex">
  <data key="d5">16.0</data>
  <data key="d6">The OpenAI API provides access to Codex models for code generation, facilitating integration into various programming workflows.&lt;SEP&gt;The OpenAI API provides access to Codex models for programmatic code generation, enabling integration into various software workflows.</data>
  <data key="d7">tool integration, accessibility</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Test harness (ParEval)" target="performance evaluation process">
  <data key="d5">3.0</data>
  <data key="d6">The ParEval test harness compiles, runs, and evaluates generated code, recording correctness and execution times to assess performance."|&lt;|"evaluation methodology, correctness verification&lt;SEP&gt;The test harness automates compilation, execution, and correctness verification of generated code, recording performance metrics."|</data>
  <data key="d7">1&lt;SEP&gt;2</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Test harness (ParEval)" target="GCC, OpenMP, Kokkos, MPI, CUDA, HIP">
  <data key="d5">1.0</data>
  <data key="d6">Various compiler and parallelization tools are used within the test harness to compile and run generated code across different hardware and software configurations."|</data>
  <data key="d7">1</data>
  <data key="d8">chunk-d1ed35f0489d99675c43fbbee04d61fd</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="generated code" target="test harness">
  <data key="d5">16.0</data>
  <data key="d6">The test harness executes the generated code to verify correctness and measure performance metrics.&lt;SEP&gt;The test harness runs the generated code to verify correctness and measure performance metrics, ensuring the code meets specified criteria.</data>
  <data key="d7">verification, evaluation</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="generated code" target="parallel programming model">
  <data key="d5">14.0</data>
  <data key="d6">The parallel programming model guides how the code is structured to enable parallel execution, affecting correctness and efficiency.&lt;SEP&gt;The parallel programming model influences how the generated code is structured and executed, affecting correctness and efficiency.</data>
  <data key="d7">model influence, code structure</data>
  <data key="d8">chunk-0263fe0a192189f09d40327b5d776e30</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="code correctness" target="OpenACC">
  <data key="d5">6.0</data>
  <data key="d6">OpenACC shows variable correctness levels depending on the kernel, often lower for complex kernels.</data>
  <data key="d7">model performance, code accuracy</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="code correctness" target="Thrust">
  <data key="d5">4.0</data>
  <data key="d6">Thrust tends to yield lower correctness levels across most kernels, especially complex ones.</data>
  <data key="d7">model performance, code accuracy</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="code correctness" target="SyCL">
  <data key="d5">5.0</data>
  <data key="d6">SyCL shows variable correctness, generally lower than CUDA and OpenMP for complex kernels.</data>
  <data key="d7">model performance, code accuracy</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="code correctness" target="Kernel">
  <data key="d5">8.0</data>
  <data key="d6">Different kernels like AXPY, GEMV, GEMM, etc., influence the correctness level of generated code.</data>
  <data key="d7">kernel complexity, code accuracy</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="pass@1 score" target="Transform Problems">
  <data key="d5">1.0</data>
  <data key="d6">Structured, Dense Problems</data>
  <data key="d7">LLMs tend to achieve higher pass@1 scores on transform problems, which are data parallel and simpler to parallelize.</data>
  <data key="d8">chunk-71ff485ed5de2f1a53b77145285b1a49</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLMs" target="Knowledge Extraction">
  <data key="d5">9.0</data>
  <data key="d6">LLMs rely on knowledge extraction techniques to stay current with domain-specific information, which is challenging due to their static training data.</data>
  <data key="d7">knowledge update, domain adaptation</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Knowledge Extraction Techniques">
  <data key="d5">9.0</data>
  <data key="d6">LLMs depend on knowledge extraction techniques to incorporate domain knowledge, but face difficulties due to static training data.</data>
  <data key="d7">knowledge update, domain adaptation</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Explicit Knowledge">
  <data key="d5">16.0</data>
  <data key="d6">Explicit Knowledge sources are retrieved and prioritized by LLMs to improve task-specific responses, anchoring predictions in external data rather than solely relying on memorized information."|&lt;SEP&gt;Explicit knowledge sources are retrieved and prioritized by LLMs to improve task-specific responses, anchoring predictions in external data rather than solely relying on memorized information."|</data>
  <data key="d7">knowledge integration, external data influence</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="External Knowledge">
  <data key="d5">16.0</data>
  <data key="d6">External knowledge, whether explicit or implicit, is integrated into LLMs to improve domain-specific performance without the need for extensive retraining."|</data>
  <data key="d7">knowledge augmentation, domain adaptation</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Seamless Integration">
  <data key="d5">16.0</data>
  <data key="d6">Developing methods for seamless integration of external knowledge into LLMs is crucial for balancing relevance, completeness, and model flexibility."|</data>
  <data key="d7">system design, knowledge management</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Adapters">
  <data key="d5">18.0</data>
  <data key="d6">Adapters are integrated into LLMs to enable domain-specific adaptation without full model retraining.</data>
  <data key="d7">model adaptation, modularity</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Task-oriented Fine-tuning">
  <data key="d5">16.0</data>
  <data key="d6">Task-oriented fine-tuning involves updating LLMs on specific datasets to enhance their performance on particular tasks.</data>
  <data key="d7">performance improvement, specialization</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLMs" target="Reinforcement Learning from Human Feedback (RLHF)">
  <data key="d5">20.0</data>
  <data key="d6">RLHF aligns LLM outputs with human preferences through iterative feedback and policy updates.</data>
  <data key="d7">alignment, safety, human-centric tuning</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="MPI" target="MPI Communication">
  <data key="d5">18.0</data>
  <data key="d6">MPI enables explicit data transfer between distributed nodes, supporting synchronization and collective operations like reductions.&lt;SEP&gt;MPI enables explicit data transfer between distributed nodes, supporting synchronization and collective operations.</data>
  <data key="d7">distributed communication, data transfer&lt;SEP&gt;distributed data transfer, synchronization</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="MPI" target="MPI Reduction">
  <data key="d5">16.0</data>
  <data key="d6">MPI reduction is used to combine data across nodes for distributed memory reduction patterns.&lt;SEP&gt;MPI reduction is used to combine data from multiple nodes or processes into a single result during distributed reduction operations.</data>
  <data key="d7">collective computation, data aggregation&lt;SEP&gt;data aggregation, collective operation</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="MPI" target="Parallel Framework">
  <data key="d5">16.0</data>
  <data key="d6">MPI is a fundamental parallel framework used in high-performance computing to facilitate message passing among processes.&lt;SEP&gt;MPI is a parallel framework used to facilitate message passing in high-performance computing environments.</data>
  <data key="d7">parallel computing, message passing</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Methodologies" target="Learning from Small and Local Datasets">
  <data key="d5">8.0</data>
  <data key="d6">Techniques focusing on training models with limited, localized data for code summarization."|&gt;"training methods, data limitations</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Methodologies" target="Code Summarization from a Small Dataset">
  <data key="d5">8.0</data>
  <data key="d6">Approaches that train models effectively with limited data for code summarization."|&gt;"training, data efficiency</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Methodologies" target="Inlining">
  <data key="d5">7.0</data>
  <data key="d6">An optimization applied within the code to improve performance by replacing function calls with inline code."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Loop unrolling">
  <data key="d5">7.0</data>
  <data key="d6">An optimization technique used within the code to increase instruction-level parallelism and reduce loop overhead."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Global Optimization">
  <data key="d5">16.0</data>
  <data key="d6">Global optimization techniques are applied across the application to improve performance, involving strategies like loop fusion and data flow optimization.</data>
  <data key="d7">optimization techniques, performance enhancement</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Static Analysis">
  <data key="d5">8.0</data>
  <data key="d6">Static analysis examines data dependencies and control flow in the code without executing it, enabling optimization and correctness checking.</data>
  <data key="d7">dependency analysis, correctness</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Partitioning">
  <data key="d5">8.0</data>
  <data key="d6">Partitioning divides the computation into smaller tasklets or patterns, facilitating parallel execution and resource management.</data>
  <data key="d7">task decomposition, resource management</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Optimization Pipeline">
  <data key="d5">8.0</data>
  <data key="d6">The optimization pipeline involves steps like synchronization minimization, data transfer reduction, and task fusion to improve performance.</data>
  <data key="d7">performance enhancement, process flow</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Loop Unrolling">
  <data key="d5">13.0</data>
  <data key="d6">Loop unrolling is applied by replicating loop bodies multiple times, provided no break or continue statements are present, to optimize performance.&lt;SEP&gt;Loop unrolling is applied to optimize loops by replicating the loop body, avoiding uncertainties with break or continue statements.</data>
  <data key="d7">optimization, control flow</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Algorithm 1: Simplified APT Function Inlining">
  <data key="d5">18.0</data>
  <data key="d6">This algorithm describes the process of inlining functions through node copying, jump label management, variable replacement, and handling return nodes.&lt;SEP&gt;This algorithm details the process of function inlining through node copying, jump label management, variable replacement, and handling return nodes, improving code efficiency.</data>
  <data key="d7">optimization technique, code transformation&lt;SEP&gt;optimization, code transformation</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Global optimization">
  <data key="d5">16.0</data>
  <data key="d6">Optimization approach that avoids artificial dependencies, ensuring measurement correctness.&lt;SEP&gt;The optimization approach aims to prevent artificial dependencies during measurements, ensuring valid performance data and correctness of results.</data>
  <data key="d7">optimization technique, experimental validity</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Methodologies" target="Anastasia Razdaibiedina">
  <data key="d5">16.0</data>
  <data key="d6">Works on progressive prompts for continual learning, proposing methodologies for language model training."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="Sylvestre-Alvise Rebuffi">
  <data key="d5">16.0</data>
  <data key="d6">Proposes residual adapters for learning multiple visual domains, introducing a methodology for multi-domain learning."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="Timo Schick">
  <data key="d5">18.0</data>
  <data key="d6">Proposes Toolformer, a methodology enabling language models to teach themselves to use external tools."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="Thomas Scialom">
  <data key="d5">16.0</data>
  <data key="d6">Studies fine-tuned language models as continual learners, proposing training methodologies."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Methodologies" target="OpenMP Pragmas">
  <data key="d5">19.0</data>
  <data key="d6">OpenMP pragmas are directives used to annotate loops, enabling parallel execution in shared-memory environments.&lt;SEP&gt;OpenMP pragmas are used to specify parallel regions in code, particularly for decorating loops to enable parallel execution.</data>
  <data key="d7">parallel programming, code annotation</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Disciplines" target="High-Performance Computing">
  <data key="d5">8.0</data>
  <data key="d6">A field focused on advanced computing for scientific and engineering problems."|&gt;"field, computing</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Disciplines" target="Heterogeneous Systems">
  <data key="d5">8.0</data>
  <data key="d6">Heterogeneous systems involve combining different types of computing resources, such as CPUs and GPUs, for optimized performance.</data>
  <data key="d7">system design, resource management</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Disciplines" target="HPC Community">
  <data key="d5">6.0</data>
  <data key="d6">The HPC community is involved in evaluating, adopting, and advancing AI-generated kernels and methodologies.</data>
  <data key="d7">research, application</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Spatiotemporal Information" target="System Environment">
  <data key="d5">12.0</data>
  <data key="d6">The hardware setup influences the measured performance and evaluation outcomes.&lt;SEP&gt;The hardware setup influences the performance results and evaluation context.</data>
  <data key="d7">hardware context, performance analysis</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Study Populations/Dataset" target="Stack Overflow">
  <data key="d5">7.0</data>
  <data key="d6">Stack Overflow provides data on developer demographics and community participation, which can inform studies on representation and behavior.</data>
  <data key="d7">data source, demographic analysis</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Study Populations/Dataset" target="HPC Source Code Dataset">
  <data key="d5">16.0</data>
  <data key="d6">A large corpus of HPC source code used for training and fine-tuning models to adapt to domain-specific language and syntax.&lt;SEP&gt;A large dataset of HPC source code used for training and fine-tuning models to adapt to domain-specific language and syntax.</data>
  <data key="d7">domain-specific data, training</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Study Populations/Dataset" target="Git commit data">
  <data key="d5">16.0</data>
  <data key="d6">Git commit data is used to train models to predict performance changes based on code modifications.</data>
  <data key="d7">dataset, code change analysis</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Study Populations/Dataset" target="Code contest dataset">
  <data key="d5">14.0</data>
  <data key="d6">Code pairs from contests are used to train models for performance classification.&lt;SEP&gt;Code pairs from programming contests are used to train models for performance classification.</data>
  <data key="d7">training data, performance prediction</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Study Populations/Dataset" target="HPC code dataset">
  <data key="d5">8.0</data>
  <data key="d6">The dataset provides code samples used to train and evaluate models for code annotation and performance tasks.</data>
  <data key="d7">training data, code samples</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Data" target="Figures">
  <data key="d5">8.0</data>
  <data key="d6">Data is visually represented in Figures to illustrate performance metrics and data distributions.</data>
  <data key="d7">visualization, data representation</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Efficiency" target="Process Counts">
  <data key="d5">8.0</data>
  <data key="d6">Efficiency is analyzed across different process and thread counts to assess scalability.</data>
  <data key="d7">scalability analysis, resource utilization</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Kernel Threads" target="GPU Performance">
  <data key="d5">7.0</data>
  <data key="d6">Kernel threads are a key factor in measuring GPU parallel performance and efficiency.</data>
  <data key="d7">GPU computing, parallelism</data>
  <data key="d8">chunk-2c69fe176c580c07a9269d7a20e4e011</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Figure 7" target="PolyCoder+HPC">
  <data key="d5">9.0</data>
  <data key="d6">PolyCoder+HPC performs better than other models in compilation success rate, with 86% of samples compiling correctly, indicating higher effectiveness in code generation."|</data>
  <data key="d7">performance, code correctness</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Figure 8" target="PolyCoder+HPC">
  <data key="d5">8.0</data>
  <data key="d6">PolyCoder+HPC successfully generates code with OpenMP pragmas, demonstrating its ability to incorporate parallel directives correctly."|</data>
  <data key="d7">parallel programming, code generation</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="National Energy Research Scientific Computing Center" target="Resources">
  <data key="d5">8.0</data>
  <data key="d6">Provides high-performance computing resources for scientific research activities.</data>
  <data key="d7">resource allocation, scientific computing</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="NERSC" target="DDR-ERCAP0025593">
  <data key="d5">7.0</data>
  <data key="d6">Funding or resource award associated with computational resource usage at NERSC.</data>
  <data key="d7">funding, resource management</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Big Code Models Leaderboard" target="Benchmarking Platform">
  <data key="d5">8.0</data>
  <data key="d6">Serves as a platform to benchmark and compare large code models."|&gt;"benchmarking, model evaluation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="HIP Documentation" target="Documentation Resource">
  <data key="d5">7.0</data>
  <data key="d6">Provides technical documentation for HIP programming environment."|&gt;"software documentation, tools</data>
  <data key="d7">7</data>
  <data key="d8">chunk-409a22222a0092123b63b598c4b30bad</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Learning to Reduce False Positives in Analytic Bug Detectors" target="Anant Kharkar">
  <data key="d5">16.0</data>
  <data key="d6">The research focuses on developing methodologies to improve bug detection accuracy by reducing false positives in software analytics.&lt;SEP&gt;The research focuses on developing methodologies to improve bug detection by reducing false positives in software analytics tools.</data>
  <data key="d7">research focus, bug detection</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Harm de Vries" target="Harm de Vries">
  <data key="d5">6.0</data>
  <data key="d6">Harm de Vries collaborates on AI research and model development, contributing to the development of models like StarCoder.</data>
  <data key="d7">collaboration, AI models</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="StarCoder" target="Source Code Generation">
  <data key="d5">9.0</data>
  <data key="d6">StarCoder is a large language model used specifically for source code generation tasks, inspired by sci-fi themes."|&gt;"model, source code generation</data>
  <data key="d7">9</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="VerilogEval" target="Mingjie Liu et al.">
  <data key="d5">16.0</data>
  <data key="d6">VerilogEval is used to evaluate large language models' performance in Verilog hardware description language code generation.</data>
  <data key="d7">evaluation, hardware description language</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLM4VV" target="Christian Munley et al.">
  <data key="d5">16.0</data>
  <data key="d6">They develop or utilize LLM4VV as a test suite for validating compiler outputs and behaviors using large language models.</data>
  <data key="d7">validation, compiler testing</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="LLM4VV" target="Validation Framework">
  <data key="d5">8.0</data>
  <data key="d6">LLM4VV serves as a framework for validating compiler correctness and behavior using large language models."|&gt;"validation, compiler</data>
  <data key="d7">8</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Modeling Parallel Programs" target="Daniel Nichols et al.">
  <data key="d5">16.0</data>
  <data key="d6">They focus on modeling parallel programs using large language models to analyze concurrency and performance.</data>
  <data key="d7">modeling, parallel programs</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Modeling Parallel Programs" target="Analysis Method">
  <data key="d5">8.0</data>
  <data key="d6">A methodology for representing and analyzing parallel programs with large language models to understand concurrency."|&gt;"methodology, parallel programs</data>
  <data key="d7">8</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Modeling Parallel Programs" target="HPC-Coder">
  <data key="d5">16.0</data>
  <data key="d6">HPC-Coder is designed to model and automate tasks related to parallel programs in HPC, including code completion and performance prediction.&lt;SEP&gt;HPC-Coder is specifically designed to model and automate tasks related to parallel programs in HPC, including code completion and performance prediction.</data>
  <data key="d7">specialized modeling, automation</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Source Code Datasets" target="Raymond Li et al.">
  <data key="d5">8.0</data>
  <data key="d6">They contribute to research involving large source code datasets and their licensing, analysis, and applications in AI.</data>
  <data key="d7">research, source code datasets</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Benchmarks" target="Performance Optimization">
  <data key="d5">16.0</data>
  <data key="d6">The benchmarks are used to evaluate the potential speedups and effectiveness of the proposed optimization techniques.&lt;SEP&gt;The benchmarks evaluate the effectiveness of the proposed optimization techniques by measuring speedups and overhead reductions.</data>
  <data key="d7">performance evaluation&lt;SEP&gt;performance evaluation, benchmarking</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Resources" target="Hardware cores">
  <data key="d5">7.0</data>
  <data key="d6">Resources include hardware cores, which are physical units that support parallel execution."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-aebb652b359c14534612e14559754bbc</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="DS-1000 Benchmark" target="Yuhang Lai et al.">
  <data key="d5">14.0</data>
  <data key="d6">DS-1000 is a benchmark dataset for data science code generation, designed to evaluate the performance of models in generating reliable data science code.&lt;SEP&gt;DS-1000 is designed as a reliable benchmark for data science code generation, used to evaluate model performance.</data>
  <data key="d7">benchmark dataset, data science code</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Raymond Li et al." target="Source Code Research">
  <data key="d5">8.0</data>
  <data key="d6">They contribute to research involving large source code datasets and their licensing, analysis, and applications in AI.</data>
  <data key="d7">research, source code datasets</data>
  <data key="d8">chunk-c0b8d49beacd06e5cfcb389ea3120718</data>
  <data key="d9">Nichols et al. - 2024 - Can Large Language Models Write Parallel Code.pdf</data>
</edge>
<edge source="Parallel Pattern Language Code Generation" target="Rodinia benchmark suite">
  <data key="d5">16.0</data>
  <data key="d6">The code generator is evaluated against Rodinia benchmarks to assess performance and optimization capabilities.</data>
  <data key="d7">benchmark evaluation, performance assessment</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Pattern Language Code Generation" target="Speedups in Rodinia benchmarks">
  <data key="d5">18.0</data>
  <data key="d6">The prototype achieves significant speedups on several benchmarks, demonstrating its effectiveness.</data>
  <data key="d7">performance improvement, optimization success</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Pattern Language Code Generation" target="Assignment between tasklets and architecture">
  <data key="d5">14.0</data>
  <data key="d6">The code generator calculates tasklet-to-architecture mappings during compile time to optimize resource utilization.</data>
  <data key="d7">compile-time mapping, resource allocation</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Pattern Language Code Generation" target="Static global optimizations">
  <data key="d5">12.0</data>
  <data key="d6">The approach applies global optimizations automatically during compilation to improve performance across heterogeneous hardware.</data>
  <data key="d7">compiler optimization, global performance</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Memory and power constraints" target="Heterogeneity in HPC systems">
  <data key="d5">23.0</data>
  <data key="d6">Heterogeneity contributes to constraints that limit scaling and performance.&lt;SEP&gt;Memory and power limitations drive the need for hardware specialization and complex code optimization.</data>
  <data key="d7">hardware constraints, software challenges&lt;SEP&gt;system limitations, hardware diversity</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Heterogeneity in HPC systems" target="Accelerator offloading">
  <data key="d5">14.0</data>
  <data key="d6">Heterogeneity necessitates offloading computations to accelerators like GPUs to achieve better performance.</data>
  <data key="d7">hardware offloading, performance optimization</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Heterogeneity in HPC systems" target="HPC systems">
  <data key="d5">7.0</data>
  <data key="d6">Heterogeneity in hardware components complicates software development and performance optimization.</data>
  <data key="d7">hardware complexity, software challenge</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Heterogeneity in HPC systems" target="Heterogeneous cluster architecture">
  <data key="d5">6.0</data>
  <data key="d6">The hardware configuration comprising CPUs, GPUs, and accelerators used for testing and optimization.</data>
  <data key="d7">testbed, hardware configuration</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Rodinia benchmark suite" target="Performance evaluation">
  <data key="d5">16.0</data>
  <data key="d6">The benchmark suite is used to evaluate the effectiveness of the code generator in optimizing HPC applications.</data>
  <data key="d7">benchmark testing, performance metrics</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Global optimizations" target="Source code generator">
  <data key="d5">14.0</data>
  <data key="d6">The code generator implements global optimizations during source code generation to enhance performance.</data>
  <data key="d7">optimization implementation, code efficiency</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Global optimizations" target="Parallel patterns">
  <data key="d5">7.0</data>
  <data key="d6">Parallel patterns enable high-level descriptions that are globally optimized during compilation.</data>
  <data key="d7">optimization scope, parallelism</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel patterns" target="Source code generator">
  <data key="d5">12.0</data>
  <data key="d6">Parallel patterns define the high-level structure that the code generator uses to produce optimized code.</data>
  <data key="d7">code structure, parallelism</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Static global optimizations" target="Speedups in Rodinia benchmarks">
  <data key="d5">16.0</data>
  <data key="d6">Global optimizations contribute to the observed speedups in benchmark performance.</data>
  <data key="d7">performance gains, optimization impact</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Source code generator" target="Evaluation setup">
  <data key="d5">8.0</data>
  <data key="d6">The generator's effectiveness is assessed through experiments using benchmarks and hardware configurations.</data>
  <data key="d7">evaluation, performance testing</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Speedups in Rodinia benchmarks" target="Code optimization techniques">
  <data key="d5">8.0</data>
  <data key="d6">Optimizations applied by the code generator lead to performance improvements.</data>
  <data key="d7">performance gains, optimization techniques</data>
  <data key="d8">chunk-e6eb755f9f73ae3f7c76aff0920fdfae</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Single CPU Node" target="Distributed Setup with CPUs and GPUs">
  <data key="d5">6.0</data>
  <data key="d6">The distributed setup includes multiple CPUs and GPUs, contrasting with the single CPU node baseline."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="LULESH" target="Benchmark Suite">
  <data key="d5">16.0</data>
  <data key="d6">LULESH is used as a benchmark application to evaluate scalability and performance of computational setups."|&lt;SEP&gt;LULESH is used as a representative benchmark application to evaluate the performance and scalability of the proposed prototype and setups."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Code Generator" target="PPLprototype Toolchain">
  <data key="d5">8.0</data>
  <data key="d6">The code generator is implemented specifically for the PPLprototype toolchain."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Code Generator" target="Kernels (batch, jacobi, monte)">
  <data key="d5">14.0</data>
  <data key="d6">The code generator produces optimized code for specific kernels, though some kernels do not yet reach speedup targets due to pending optimizations like kernel fusion or reduction strategies.&lt;SEP&gt;The code generator produces optimized implementations for specific kernels, although some do not yet achieve desired speedups.</data>
  <data key="d7">optimization, kernel performance</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Inlining" target="APT">
  <data key="d5">7.0</data>
  <data key="d6">Inlining is applied to the Abstract Pattern Tree in the tool to optimize code."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Loop Unrolling" target="APT">
  <data key="d5">7.0</data>
  <data key="d6">Loop unrolling is used as an optimization technique within the Abstract Pattern Tree."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="PPL" target="OpenMP Implementation">
  <data key="d5">8.0</data>
  <data key="d6">The PPL toolchain is compared against existing OpenMP implementations of Rodinia kernels."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="PPL" target="Issues and Solutions">
  <data key="d5">7.0</data>
  <data key="d6">An analysis of current issues in the PPL prototype includes potential solutions for a future release."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="PPL" target="Application Range">
  <data key="d5">8.0</data>
  <data key="d6">The PPL aims to support a broad range of applications and hardware by separating semantics from hardware specifics."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="PPL" target="Application range">
  <data key="d5">8.0</data>
  <data key="d6">The PPL aims to support a broad spectrum of applications across hardware architectures by abstracting parallel semantics."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="PPL" target="Static Code">
  <data key="d5">9.0</data>
  <data key="d6">The PPL approach analyzes static code to enable automatic optimization for heterogeneous architectures.</data>
  <data key="d7">static analysis, code optimization</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="LLVM" target="Julia">
  <data key="d5">16.0</data>
  <data key="d6">Julia leverages the LLVM compiler infrastructure to generate optimized machine code for high-performance numerical computations."|&gt;"compiler infrastructure, performance</data>
  <data key="d7">8</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Lift" target="Michel Steuwer">
  <data key="d5">18.0</data>
  <data key="d6">Michel Steuwer contributed to the development of Lift, a functional data-parallel IR for GPU code generation, advancing high-performance GPU programming techniques.&lt;SEP&gt;Michel Steuwer contributed to the development of Lift, a functional data-parallel IR for GPU code generation.</data>
  <data key="d7">research contribution, GPU programming</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="YASK" target="Charles Yount">
  <data key="d5">16.0</data>
  <data key="d6">Charles Yount and team developed YASK, a framework for HPC stencil code-generation and tuning.&lt;SEP&gt;Charles Yount and team developed YASK, a framework for generating and tuning high-performance stencil computations in HPC.</data>
  <data key="d7">code-generation, high-performance computing</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="YASK" target="Charles Yount and colleagues' YASK framework is focused on optimizing stencil code for HPC applications.">
  <data key="d5">8.0</data>
  <data key="d6">optimization, stencil computations</data>
  <data key="d7">8</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Thrust" target="Kernel Performance">
  <data key="d5">12.0</data>
  <data key="d6">Thrust's performance issues over complex kernels reflect its community size and usage limitations in high-performance contexts.&lt;SEP&gt;Thrust's performance issues over complex kernels reflect its limited community and usage in high-performance contexts.</data>
  <data key="d7">community, kernel complexity</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Thrust" target="CUDA Toolkit">
  <data key="d5">7.0</data>
  <data key="d6">Thrust is a library within the CUDA ecosystem, providing high-level parallel algorithms for GPU programming.</data>
  <data key="d7">library, parallel algorithms</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Thrust" target="NVIDIA">
  <data key="d5">7.0</data>
  <data key="d6">Thrust is a library within NVIDIA's CUDA ecosystem, providing high-level parallel algorithms to simplify GPU programming.</data>
  <data key="d7">library, parallel algorithms</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="SDFGs" target="Optimization Strategy">
  <data key="d5">7.0</data>
  <data key="d6">SDFGs use rule-based optimization, which can be complemented or extended by PPL's flexible approach."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="SDFGs" target="Optimization strategy">
  <data key="d5">7.0</data>
  <data key="d6">SDFGs utilize rule-based transformations for optimization, which can complement or be integrated with PPL's flexible optimization approach."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="SDFGs" target="Data Dependency Analysis">
  <data key="d5">9.0</data>
  <data key="d6">SDFGs enable detailed dependency analysis, aliasing elimination, and extraction of dependency chains for static scheduling.&lt;SEP&gt;SDFGs provide detailed dependency analysis capabilities, enabling aliasing elimination and better static scheduling.</data>
  <data key="d7">dependency analysis, aliasing&lt;SEP&gt;dependency analysis, aliasing elimination</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Patterns" target="Execution Range">
  <data key="d5">14.0</data>
  <data key="d6">The execution range determines how many iterations each thread performs, directly affecting workload distribution and efficiency.&lt;SEP&gt;The execution range determines the number of iterations per thread, affecting workload distribution and performance.</data>
  <data key="d7">workload distribution, performance&lt;SEP&gt;workload distribution, performance optimization</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Patterns" target="Pattern Implementation">
  <data key="d5">16.0</data>
  <data key="d6">Pattern implementation involves explicitly assigning iteration counts per thread, structuring how computations are distributed across GPU cores.&lt;SEP&gt;Pattern implementation involves explicitly assigning iterations per thread, shaping how parallel execution is structured.</data>
  <data key="d7">workload management, parallel execution</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Parallel Patterns" target="Function Arguments">
  <data key="d5">7.0</data>
  <data key="d6">Function arguments often contain nested patterns that influence how parallel computations are structured and executed.</data>
  <data key="d7">conceptual dependency</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Data Dependency Analysis" target="Dynamic Behavior">
  <data key="d5">9.0</data>
  <data key="d6">Understanding dynamic workloads through dependency analysis helps adapt static approaches to runtime variability and optimize accordingly.&lt;SEP&gt;Understanding dynamic workloads through dependency analysis helps adapt static approaches to runtime variability.</data>
  <data key="d7">dependency analysis, dynamic workloads</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Synchronization" target="Data Dependencies">
  <data key="d5">18.0</data>
  <data key="d6">Data dependencies are managed through synchronization mechanisms like barriers to prevent data races and ensure correct data flow between tasks.&lt;SEP&gt;Data dependencies are managed through synchronization mechanisms to prevent data races and ensure correct data flow.</data>
  <data key="d7">data integrity, coordination</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Synchronization" target="GPU Offloading">
  <data key="d5">16.0</data>
  <data key="d6">Synchronization mechanisms coordinate GPU kernel execution and data consistency between host and device, ensuring correct order.&lt;SEP&gt;Synchronization mechanisms ensure correct order of GPU kernel execution and data consistency across host and device.</data>
  <data key="d7">execution order, data consistency</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Synchronization" target="Shared Memory Synchronization">
  <data key="d5">16.0</data>
  <data key="d6">Shared memory synchronization ensures correct data access among threads during parallel execution, preventing race conditions.&lt;SEP&gt;Shared memory synchronization ensures correct data access among threads, preventing race conditions during parallel execution.</data>
  <data key="d7">data consistency, race condition prevention</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Synchronization" target="Data Management">
  <data key="d5">16.0</data>
  <data key="d6">Data management and synchronization are interconnected, with synchronization ensuring data integrity during concurrent GPU and CPU operations.&lt;SEP&gt;Data management and synchronization are interconnected; synchronization mechanisms ensure data integrity during concurrent GPU and CPU operations.</data>
  <data key="d7">data integrity, concurrency control</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Global Optimization" target="Synchronization Efficiency">
  <data key="d5">12.0</data>
  <data key="d6">Synchronization efficiency evaluates how well dependency-based synchronization is minimized during global optimization.</data>
  <data key="d7">synchronization reduction, parallelism</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Global Optimization" target="Inter-processor Dataflow Efficiency">
  <data key="d5">14.0</data>
  <data key="d6">This efficiency aims to minimize data transfer and execution costs between processing units, enhancing overall performance.</data>
  <data key="d7">data transfer optimization, execution cost</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Global Optimization" target="Gurobi Solver">
  <data key="d5">16.0</data>
  <data key="d6">The Gurobi solver is used to solve MILP problems generated during global optimization to find optimal task mappings.</data>
  <data key="d7">optimization solving, task scheduling</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="TheHWL" target="APG Generation">
  <data key="d5">16.0</data>
  <data key="d6">The HWL defines execution units that support the creation of an APG, enabling hierarchical representation of parallel code.</data>
  <data key="d7">hardware abstraction, parallelism</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="APG Generation" target="Nodes">
  <data key="d5">18.0</data>
  <data key="d6">Nodes in the APG represent computations (expressions) and control flow (statements), which are analyzed for data dependencies and parallelism.&lt;SEP&gt;Nodes in the APG represent computations and control flow, which are analyzed for data dependencies and parallel execution.</data>
  <data key="d7">data flow analysis, program structure</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Data Dependencies" target="APG Nodes">
  <data key="d5">14.0</data>
  <data key="d6">Data dependencies link expressions within the APG, allowing static analysis of data flow across program components.</data>
  <data key="d7">data flow, dependency analysis</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tasklets" target="AMT">
  <data key="d5">14.0</data>
  <data key="d6">Tasklets are derived units of computation assigned to hardware units, optimized to improve resource utilization and performance.</data>
  <data key="d7">parallel units, optimization</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Tasklets" target="Lambda Functions">
  <data key="d5">16.0</data>
  <data key="d6">Tasklets are stored as lambda functions for deferred execution, allowing flexible scheduling of parallel tasks.&lt;SEP&gt;Tasklets are stored as lambda functions to enable deferred, flexible scheduling of units of work within the thread pool.</data>
  <data key="d7">task management, deferred execution&lt;SEP&gt;task scheduling, deferred execution</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Data Transfer" target="AMT">
  <data key="d5">16.0</data>
  <data key="d6">Data transfer nodes represent synchronization and data movement, derived from dataflow analysis, to facilitate communication between devices.</data>
  <data key="d7">data movement, synchronization</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="GPU Memory Management" target="AMT">
  <data key="d5">14.0</data>
  <data key="d6">Special nodes in the AMT manage offloaded parallel patterns and GPU memory, enabling heterogeneous execution.</data>
  <data key="d7">memory management, offloading</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Patterns" target="Parallel Algorithms">
  <data key="d5">8.0</data>
  <data key="d6">Recurring structures like OpenMP, MPI, and CUDA are used in parallel algorithms."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Heterogeneous Systems" target="OpenACC">
  <data key="d5">8.0</data>
  <data key="d6">OpenACC facilitates programming for heterogeneous systems by providing a standardized API for offloading computations to accelerators like GPUs.</data>
  <data key="d7">parallel programming, hardware acceleration</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Shared Memory Parallelism" target="POSIX Threads">
  <data key="d5">16.0</data>
  <data key="d6">Shared memory parallelism is implemented through POSIX threads, which enable concurrent execution within a shared memory environment, managed via thread APIs.&lt;SEP&gt;Shared memory parallelism is implemented through POSIX threads, which enable concurrent execution within a shared memory environment.</data>
  <data key="d7">parallel execution, threading</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="POSIX Threads" target="Thread Pinning">
  <data key="d5">14.0</data>
  <data key="d6">Thread pinning is achieved using pthread_setaffinity_np to bind threads to specific cores, optimizing cache usage and performance.&lt;SEP&gt;Thread pinning is achieved using pthread_setaffinity_np to bind threads to specific cores, optimizing performance.</data>
  <data key="d7">performance optimization, thread affinity&lt;SEP&gt;performance optimization, thread management</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Thread Pool" target="Memory Locality">
  <data key="d5">14.0</data>
  <data key="d6">A thread pool manages task execution across cores or GPUs, optimizing memory locality and reducing overhead.&lt;SEP&gt;The thread pool manages task execution across cores and GPUs, optimizing memory locality to improve performance and reduce latency.</data>
  <data key="d7">task management, performance&lt;SEP&gt;task scheduling, performance</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Kernel" target="Data Movement">
  <data key="d5">16.0</data>
  <data key="d6">Kernels require data to be transferred to GPU memory before execution and results to be transferred back afterward.&lt;SEP&gt;Kernels require data to be transferred to GPU memory before execution and results transferred back after, managed explicitly for efficiency.</data>
  <data key="d7">data transfer, execution&lt;SEP&gt;data transfer, kernel execution</data>
  <data key="d8">chunk-b09f2e415a74aadae0bd890a74b69f3d</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Data Movement" target="CUDA Calls">
  <data key="d5">18.0</data>
  <data key="d6">CUDA functions facilitate data movement between CPU and GPU memory, which is critical for maintaining data locality and performance.&lt;SEP&gt;CUDA functions facilitate data transfer between host and device memory, integral to correct and efficient GPU computations.</data>
  <data key="d7">data transfer, memory management</data>
  <data key="d8">chunk-e376cabd5c2bdbbf8ecdd095bfa831b5</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Function Arguments" target="Nested Parallel Patterns">
  <data key="d5">8.0</data>
  <data key="d6">Function arguments often contain nested parallel patterns that influence how computations are organized and executed in parallel programs.</data>
  <data key="d7">conceptual dependency</data>
  <data key="d8">chunk-5f6ee49c82aaaf22c167cac791d43a0f</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Environment" target="RWTH Aachen University">
  <data key="d5">14.0</data>
  <data key="d6">The university provides the infrastructure and environment for conducting the measurements and experiments.&lt;SEP&gt;The university provides the infrastructure and environment necessary for conducting the experiments and measurements.</data>
  <data key="d7">research environment, institutional support</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="CLAIX18 systems" target="Measurement methodology">
  <data key="d5">16.0</data>
  <data key="d6">Measurements are performed on the CLAIX18 systems following specific procedures to ensure accuracy and reproducibility, such as multiple runs and manual timing.&lt;SEP&gt;Measurements are performed on the CLAIX18 systems using specified procedures to ensure accuracy and reproducibility.</data>
  <data key="d7">measurement setup, experimental environment</data>
  <data key="d8">chunk-f51d6561a383e764adb74f234469e637</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="PPLin" target="Rodinia">
  <data key="d5">8.0</data>
  <data key="d6">PPLin is used to optimize the benchmarks within the Rodinia suite for better performance.</data>
  <data key="d7">benchmark optimization</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Rodinia" target="PPLport">
  <data key="d5">7.0</data>
  <data key="d6">The PPLport is adapted to fit the sizes and configurations of the Rodinia benchmarks.</data>
  <data key="d7">porting, configuration</data>
  <data key="d8">chunk-71ae4149c46ebd3eaae68a58bc6a57e2</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Legion, StarPU" target="Dynamic Task Scheduling">
  <data key="d5">16.0</data>
  <data key="d6">These tools support execution of dynamic workloads, load balancing, and GPU offloading, addressing limitations of static approaches in handling runtime variability.&lt;SEP&gt;These tools support execution of dynamic workloads, load balancing, and GPU offloading, addressing limitations of static approaches.</data>
  <data key="d7">dynamic scheduling, load balancing</data>
  <data key="d8">chunk-0223d4c2805a1c339a5639baaa802cfc</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Scalability" target="Future Techniques">
  <data key="d5">6.0</data>
  <data key="d6">Scaling domain adaptation methods is essential for applying these models across many domains efficiently and effectively.</data>
  <data key="d7">scalability, resource management</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="C2Rust Development Team" target="C2Rust Manual">
  <data key="d5">16.0</data>
  <data key="d6">The C2Rust Development Team authored the C2Rust Manual, providing documentation and guidelines for code conversion from C to Rust.&lt;SEP&gt;The C2Rust Development Team authored the C2Rust Manual, providing documentation for code conversion tools.</data>
  <data key="d7">software documentation, tool usage</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Christian R. Trott" target="Kokkos 3">
  <data key="d5">16.0</data>
  <data key="d6">Christian R. Trott and colleagues contributed to programming model extensions for exascale computing, including Kokkos 3.&lt;SEP&gt;Christian R. Trott and colleagues contributed to the development of Kokkos 3, a programming model extension for exascale computing, enabling scalable performance across architectures.</data>
  <data key="d7">model extension, high-performance computing</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Lukas Trümper" target="Automatic Mapping of Parallel Pattern-Based Algorithms">
  <data key="d5">16.0</data>
  <data key="d6">Lukas Trümper and colleagues developed methods for automating the mapping of parallel algorithms onto heterogeneous hardware architectures to optimize performance.&lt;SEP&gt;Lukas Trümper and team developed methods for automating the mapping of parallel algorithms to heterogeneous architectures.</data>
  <data key="d7">algorithm optimization, hardware mapping</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Samuel Williams" target="Roofline">
  <data key="d5">18.0</data>
  <data key="d6">Samuel Williams and colleagues developed the Roofline model to analyze performance of multicore architectures.&lt;SEP&gt;Samuel Williams and colleagues introduced the Roofline performance model to analyze and visualize the performance limits of multicore architectures.</data>
  <data key="d7">performance modeling, multicore architectures</data>
  <data key="d8">chunk-28e67ca955e33292ea0d23b1e10bb450</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="Current Issues" target="LP-based Global Optimization">
  <data key="d5">7.0</data>
  <data key="d6">The evaluation assesses issues related to the LP-based global optimization approach."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-2379c714e7223550ff7a193355127f04</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="AMT" target="APG">
  <data key="d5">16.0</data>
  <data key="d6">The AMT extends the APG by including optimization and mapping data, representing heterogeneous and distributed task execution.</data>
  <data key="d7">mapping, heterogeneity</data>
  <data key="d8">chunk-21fd6197daae9574ed63e4ade119d5f8</data>
  <data key="d9">Schmitz et al. - 2024 - Parallel Pattern Language Code Generation.pdf</data>
</edge>
<edge source="OpenAI Codex" target="Kernel Generation">
  <data key="d5">18.0</data>
  <data key="d6">OpenAI Codex is used to generate implementations of numerical kernels across various programming models.</data>
  <data key="d7">AI code generation, HPC kernels</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenAI Codex" target="Programming Models">
  <data key="d5">16.0</data>
  <data key="d6">OpenAI Codex supports multiple programming models, facilitating diverse HPC kernel implementations.</data>
  <data key="d7">multi-language support, model versatility</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenAI Codex" target="GitHub Copilot">
  <data key="d5">18.0</data>
  <data key="d6">GitHub Copilot is based on OpenAI Codex, utilizing its large language model to assist in code generation for scientific kernels.&lt;SEP&gt;GitHub Copilot is based on OpenAI Codex, utilizing its large language model to assist in code generation tasks.</data>
  <data key="d7">model-tool relationship</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenAI Codex" target="GPT-3">
  <data key="d5">16.0</data>
  <data key="d6">OpenAI Codex is a descendant of GPT-3, built specifically for code generation, inheriting and extending GPT-3's capabilities.&lt;SEP&gt;OpenAI Codex is a descendant of GPT-3, built specifically for code generation, inheriting and extending GPT-3's natural language processing capabilities.</data>
  <data key="d7">model-application relationship</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Kernel Generation" target="Programming Models">
  <data key="d5">14.0</data>
  <data key="d6">Different programming models support the implementation of generated kernels, affecting their performance and compatibility.</data>
  <data key="d7">software frameworks, hardware support</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Kernel Generation" target="GitHub Copilot">
  <data key="d5">16.0</data>
  <data key="d6">GitHub Copilot uses OpenAI Codex to generate code snippets for HPC kernels within development environments.</data>
  <data key="d7">development tools, AI assistance</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="AI-assisted generative capabilities" target="Proficiency Metric">
  <data key="d5">12.0</data>
  <data key="d6">The proficiency metric assesses the effectiveness of AI-generated code suggestions, impacting the evaluation of AI tools in HPC development.</data>
  <data key="d7">performance assessment, code quality</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Programming Models" target="Implementation Quality">
  <data key="d5">7.0</data>
  <data key="d6">The support and maturity of programming models influence the quality and support for generated kernels.</data>
  <data key="d7">support level, maturity</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GitHub Copilot" target="correctness levels">
  <data key="d5">17.0</data>
  <data key="d6">Copilot's suggestions are categorized into correctness levels, assessing its proficiency.&lt;SEP&gt;The evaluation of suggestions using correctness levels helps quantify Copilot's proficiency in code generation.</data>
  <data key="d7">performance evaluation, proficiency</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GitHub Copilot" target="evaluation results">
  <data key="d5">7.0</data>
  <data key="d6">The evaluation results summarize the accuracy and proficiency of Copilot's code suggestions across kernels and prompts.</data>
  <data key="d7">performance metrics, code quality</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GitHub Copilot" target="Saki Imai">
  <data key="d5">16.0</data>
  <data key="d6">Imai empirically evaluates the effectiveness of Copilot as a substitute for human programmers.&lt;SEP&gt;Imai's study empirically assesses whether GitHub Copilot can substitute human pair programming.</data>
  <data key="d7">empirical study, AI in software engineering&lt;SEP&gt;software engineering, AI-assisted programming</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GitHub Copilot" target="Security">
  <data key="d5">9.0</data>
  <data key="d6">Studies assess the security implications of code contributions generated by GitHub Copilot, identifying potential vulnerabilities.</data>
  <data key="d7">security assessment, AI-generated code</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GitHub Copilot" target="Codex">
  <data key="d5">27.0</data>
  <data key="d6">Codex powers GitHub Copilot, indicating a direct application of the model in a commercial coding assistant.&lt;SEP&gt;GitHub Copilot utilizes Codex models to assist developers by generating code snippets, demonstrating a practical application of Codex in software development.&lt;SEP&gt;GitHub Copilot utilizes Codex models to assist developers by generating code snippets, showing a direct application of the Codex technology in software development.</data>
  <data key="d7">application, deployment&lt;SEP&gt;application, practical use</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Numerical Kernels" target="Implementation Quality">
  <data key="d5">7.0</data>
  <data key="d6">The quality of AI-generated implementations for core numerical routines impacts their suitability for HPC applications.</data>
  <data key="d7">performance, correctness</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Numerical Kernels" target="Experimental Results">
  <data key="d5">8.0</data>
  <data key="d6">Experimental data demonstrates how well AI-generated kernels perform in practice across different models.</data>
  <data key="d7">performance metrics, validation</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Implementation Quality" target="Code Prompts">
  <data key="d5">7.0</data>
  <data key="d6">The nature of the input prompts affects the quality and relevance of the generated code.</data>
  <data key="d7">prompt design, output quality</data>
  <data key="d8">chunk-8184ca90cae86b58652f2117d440bd17</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GPT-3" target="Luciano Floridi">
  <data key="d5">18.0</data>
  <data key="d6">Floridi and Chiriatti analyze GPT-3's nature, scope, limits, and societal impacts.&lt;SEP&gt;Floridi and Chiriatti's work discusses the nature, scope, and limits of GPT-3, analyzing its attributes and implications.</data>
  <data key="d7">theoretical analysis, AI language models</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="GPT-3" target="HumanEval">
  <data key="d5">7.0</data>
  <data key="d6">GPT-3's performance on HumanEval (0%) serves as a baseline to compare with Codex and GPT-J.</data>
  <data key="d7">benchmark, comparison</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="GPT-3" target="Codex">
  <data key="d5">16.0</data>
  <data key="d6">Codex is derived from GPT-3 and specialized for code generation, indicating an evolutionary relationship where Codex builds upon GPT-3's architecture and capabilities.&lt;SEP&gt;Codex is derived from GPT-3 and tailored for code generation, indicating an evolutionary relationship where Codex builds upon GPT-3's architecture and capabilities.</data>
  <data key="d7">model derivation, specialization</data>
  <data key="d8">chunk-fa78213378585b3030dac86aee61a21d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="prompt input pattern methodology" target="assessment of GPT-3 capabilities">
  <data key="d5">7.0</data>
  <data key="d6">The prompt input methodology is used to systematically interact with GPT-3 to generate and optimize scientific kernels.</data>
  <data key="d7">methodology-assessment</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="prompt trade-off options" target="current status of prompt engineering">
  <data key="d5">6.0</data>
  <data key="d6">The effectiveness of prompt engineering is assessed by analyzing different prompt configurations and their impact on output quality.</data>
  <data key="d7">research evaluation</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="related efforts in computer science" target="background">
  <data key="d5">7.0</data>
  <data key="d6">The background section discusses recent research efforts and highlights the focus on code generation and AI-assisted scientific computing.</data>
  <data key="d7">literature context</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="future directions" target="applications/implications">
  <data key="d5">8.0</data>
  <data key="d6">Future directions include improving prompt techniques, dataset expansion, and integration of AI in HPC workflows, impacting scientific computing practices.</data>
  <data key="d7">research development</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="reproducibility of the study" target="applications/implications">
  <data key="d5">9.0</data>
  <data key="d6">Providing artifact descriptions ensures that the study can be reproduced, validating the findings and supporting further research.</data>
  <data key="d7">validation and transparency</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Prompt input pattern methodology" target="Assessment of GPT-3 capabilities">
  <data key="d5">7.0</data>
  <data key="d6">The prompt input methodology is used to systematically interact with GPT-3/Codex to generate, refine, and evaluate scientific kernels."|"&lt;high-level prompt design, optimization</data>
  <data key="d7">7</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Prompt trade-off options" target="Current status of prompt engineering">
  <data key="d5">6.0</data>
  <data key="d6">The effectiveness of prompt engineering practices is assessed by analyzing different prompt configurations and their impact on output quality and correctness."|"&lt;prompt optimization</data>
  <data key="d7">6</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Copilot" target="Code Quality">
  <data key="d5">16.0</data>
  <data key="d6">Copilot generates code snippets whose quality is assessed based on correctness, efficiency, and security.</data>
  <data key="d7">code generation, AI tools, quality assessment</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Genetic Programming" target="Code Quality">
  <data key="d5">14.0</data>
  <data key="d6">Genetic programming approaches are compared to Copilot to evaluate differences in code correctness and efficiency.</data>
  <data key="d7">algorithm comparison, program synthesis</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Genetic Programming" target="Program Synthesis">
  <data key="d5">14.0</data>
  <data key="d6">Genetic programming is compared to LLM-based code synthesis in performance to evaluate different methodologies.&lt;SEP&gt;Genetic programming is compared to LLM-based program synthesis in performance, as part of research on code generation methodologies.</data>
  <data key="d7">comparative analysis, performance&lt;SEP&gt;performance comparison, methodologies</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Genetic Programming" target="Koza, J. R. et al.">
  <data key="d5">9.0</data>
  <data key="d6">Koza and colleagues advanced genetic programming as an evolutionary method for automatic invention and problem solving.</data>
  <data key="d7">method, problem solving</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Genetic Programming" target="Koza, J. R., Andre, D., Keane, M. A., and Bennett III, F. H.">
  <data key="d5">9.0</data>
  <data key="d6">Koza and colleagues advanced genetic programming as an evolutionary approach for automatic invention, problem solving, and program synthesis.</data>
  <data key="d7">method, problem solving</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Genetic Programming" target="Coding Practices">
  <data key="d5">7.0</data>
  <data key="d6">Genetic programming discusses coding practices like reuse, automatic architecture determination, and applicability, which are relevant for specification-independent coding.</data>
  <data key="d7">programming strategies, synthesis</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="PSB2 Program Synthesis Benchmarks" target="Code Quality">
  <data key="d5">8.0</data>
  <data key="d6">The benchmarks are used to evaluate the effectiveness of Copilot and genetic programming in generating correct code.</data>
  <data key="d7">benchmark evaluation, code correctness</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="HumanEval Dataset" target="Code Quality">
  <data key="d5">8.0</data>
  <data key="d6">The dataset is used to assess the correctness and validity of AI-generated code.</data>
  <data key="d7">dataset evaluation, code correctness</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Code Quality" target="Security Vulnerabilities">
  <data key="d5">9.0</data>
  <data key="d6">High vulnerability rates in Copilot-generated code highlight security concerns and limitations.</data>
  <data key="d7">security assessment, vulnerability</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Code Quality" target="Programming Languages">
  <data key="d5">7.0</data>
  <data key="d6">The choice of programming language influences the quality and correctness of AI-generated code, correlating with data availability and language complexity.</data>
  <data key="d7">language influence, code correctness</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Code Quality" target="Python">
  <data key="d5">9.0</data>
  <data key="d6">Adding the 'def' keyword in Python prompts significantly improves code quality, with libraries like numpy, cuPy, and pyCUDA being effectively supported.</data>
  <data key="d7">prompt specificity, library support</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Security Vulnerabilities" target="Suggestion Quality">
  <data key="d5">7.0</data>
  <data key="d6">Lower quality code suggestions may lead to higher security vulnerabilities in generated code.</data>
  <data key="d7">code quality, security risk</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Programming Languages" target="Yongxiang Sheng">
  <data key="d5">8.0</data>
  <data key="d6">Sheng studies the popularity and usage of programming languages in open source communities.</data>
  <data key="d7">software community, language analysis</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="HPC Kernels" target="Research Gap">
  <data key="d5">6.0</data>
  <data key="d6">The lack of application studies on Copilot for HPC kernels highlights an important research gap.</data>
  <data key="d7">research gap, HPC</data>
  <data key="d8">chunk-5adc1bc605f86b4e3648d3a3ef16f8a3</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Fortran" target="model sensitivity">
  <data key="d5">7.0</data>
  <data key="d6">Fortran shows sensitivity to keywords like 'subroutine' in code suggestions, influencing correctness.</data>
  <data key="d7">language sensitivity, code accuracy</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Fortran" target="Code Availability">
  <data key="d5">16.0</data>
  <data key="d6">Copilot can generate correct Fortran code, especially with 'optimized' prompts and 'subroutine' keyword, due to Fortran's legacy and domain-specific nature.&lt;SEP&gt;Copilot can generate good Fortran code due to its domain-specific nature and legacy code base, especially when using an 'optimized' prompt and 'subroutine' keyword.</data>
  <data key="d7">prompt optimization, legacy code</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Python" target="model sensitivity">
  <data key="d5">6.0</data>
  <data key="d6">Python is sensitive to the 'def' keyword, impacting the correctness of generated code.</data>
  <data key="d7">language sensitivity, code correctness</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Python" target="Codex">
  <data key="d5">23.0</data>
  <data key="d6">Codex is designed to generate Python code, demonstrating capabilities in this programming language.&lt;SEP&gt;Codex's increasing use facilitates Python programming, making coding more accessible and potentially broadening participation."|&lt;SEP&gt;The increasing use of Python is facilitated by Codex, which can generate Python code and make programming more accessible.</data>
  <data key="d7">7&lt;SEP&gt;application, language focus&lt;SEP&gt;language adoption, accessibility</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b&lt;SEP&gt;chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Julia" target="model sensitivity">
  <data key="d5">16.0</data>
  <data key="d6">Julia demonstrates low sensitivity to the 'function' postfix, affecting code suggestion accuracy.&lt;SEP&gt;Julia shows little sensitivity to the 'function' postfix, impacting the correctness of generated code.&lt;SEP&gt;Julia's low sensitivity to 'function' postfix leads to variable correctness in code suggestions.</data>
  <data key="d7">language sensitivity, code accuracy&lt;SEP&gt;language sensitivity, code generation&lt;SEP&gt;language sensitivity, code performance</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Julia" target="CUDA.jl">
  <data key="d5">16.0</data>
  <data key="d6">CUDA.jl allows Julia code to run on NVIDIA GPUs, bridging Julia's high-level syntax with GPU acceleration."|&gt;"GPU computing, language integration</data>
  <data key="d7">8</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Julia" target="AMDGPU.jl">
  <data key="d5">14.0</data>
  <data key="d6">AMDGPU.jl enables Julia to target AMD GPUs, expanding hardware support for GPU kernels."|&gt;"hardware support, GPU programming&lt;SEP&gt;AMDGPU.jl enables Julia to target AMD GPUs, supporting GPU kernels on AMD hardware."|&gt;"hardware support, GPU programming</data>
  <data key="d7">7</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Julia" target="KernelAbstractions.jl">
  <data key="d5">16.0</data>
  <data key="d6">KernelAbstractions.jl provides a unified interface for writing portable GPU kernels across multiple vendors."|&gt;"portability, kernel development</data>
  <data key="d7">8</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Julia" target="Tobias Knopp">
  <data key="d5">16.0</data>
  <data key="d6">Knopp supports multi-threading support in Julia for high-performance technical computing.&lt;SEP&gt;Supports multi-threading support in Julia for HPC applications.</data>
  <data key="d7">programming language support, multi-threading&lt;SEP&gt;programming support, multi-threading</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenACC" target="OpenACC Architecture Review Board">
  <data key="d5">8.0</data>
  <data key="d6">The OpenACC Architecture Review Board develops the OpenACC standard to enable portable programming across heterogeneous systems.</data>
  <data key="d7">standard development, programming model</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="SyCL" target="Kernel Performance">
  <data key="d5">10.0</data>
  <data key="d6">SyCL shows poor performance over several kernels, possibly due to limited adoption or community support.</data>
  <data key="d7">adoption, community support</data>
  <data key="d8">chunk-49dc2215d7813b7181583fe38186e482</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="prompts" target="code suggestions">
  <data key="d5">15.0</data>
  <data key="d6">Structured prompts combining kernel and programming model influence the quality and correctness of generated code.&lt;SEP&gt;Structured prompts combining kernel and programming model influence the quality of code generated by AI models.</data>
  <data key="d7">prompt design, code quality</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Code correctness" target="Binding errors">
  <data key="d5">13.0</data>
  <data key="d6">Binding errors contribute to incorrect code outputs, especially in complex scenarios with multiple variables and operations.</data>
  <data key="d7">errors, code correctness</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="CuPy" target="numpy">
  <data key="d5">16.0</data>
  <data key="d6">CuPy is designed as a GPU-accelerated drop-in replacement for NumPy, enabling faster array computations on compatible hardware."|&gt;"tool compatibility, acceleration&lt;SEP&gt;CuPy is designed to be a GPU-accelerated drop-in replacement for NumPy, enabling faster computations on compatible hardware."|&gt;"tool compatibility, acceleration</data>
  <data key="d7">8</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="CuPy" target="pyCUDA">
  <data key="d5">14.0</data>
  <data key="d6">pyCUDA provides low-level access to GPU kernels, complementing CuPy's high-level array operations for custom GPU programming."|&gt;"GPU programming, kernel execution</data>
  <data key="d7">7</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Numba" target="&lt;kernel&gt;">
  <data key="d5">18.0</data>
  <data key="d6">Numba can compile Python functions into optimized machine code, including GPU kernels, facilitating high-performance computing."|&gt;"JIT compilation, acceleration</data>
  <data key="d7">9</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Numba" target="Siu Kwan Lam">
  <data key="d5">16.0</data>
  <data key="d6">He works on Numba, a JIT compiler that accelerates Python code for HPC applications.&lt;SEP&gt;Lam's work involves the LLVM-based JIT compiler Numba, used for accelerating Python code in HPC.</data>
  <data key="d7">compiler technology, high-performance computing&lt;SEP&gt;compiler, high-performance computing</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="public repositories" target="code availability">
  <data key="d5">14.0</data>
  <data key="d6">The abundance of publicly available code influences the success rate of AI code generation models across different languages."|&gt;"code access, model performance&lt;SEP&gt;The abundance of publicly available code influences the success rate of code generation models across languages."|&gt;"code access, model performance</data>
  <data key="d7">7</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="prompt keywords" target="code quality">
  <data key="d5">8.0</data>
  <data key="d6">Use of specific, targeted keywords in prompts improves the proficiency and correctness of AI-generated code."|&gt;"prompt design, output quality</data>
  <data key="d7">8</data>
  <data key="d8">chunk-07477bd37f9598e434f96bc52e2aea53</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Code Complexity" target="Generating High-Quality Multistep or Multikernel Codes">
  <data key="d5">14.0</data>
  <data key="d6">As code complexity increases, generating high-quality multistep or multikernel codes becomes more difficult, highlighting a challenge in HPC code generation.&lt;SEP&gt;As code complexity increases, the difficulty of generating high-quality multistep or multikernel codes also increases, indicating a challenge in AI code generation capabilities.</data>
  <data key="d7">difficulty, complexity</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Keywords" target="Improving Answer Proficiency">
  <data key="d5">12.0</data>
  <data key="d6">Proper selection of keywords enhances the quality and relevance of AI-generated answers, emphasizing the importance of keyword sensitivity and specificity.&lt;SEP&gt;Using keywords enhances the proficiency of answers in programming tasks, emphasizing the importance of correct keyword selection.</data>
  <data key="d7">keywords, answer quality</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="OpenAI Codex via Copilot" target="HPC Numerical Kernels">
  <data key="d5">16.0</data>
  <data key="d6">OpenAI Codex via Copilot is evaluated for its capacity to generate HPC kernels, with the study assessing its strengths and limitations in this context.&lt;SEP&gt;OpenAI Codex via Copilot is used to generate HPC numerical kernels, assessing its capacity and limitations in this context.</data>
  <data key="d7">AI tool, code generation</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Taxonomy" target="Accuracy and Trustworthiness">
  <data key="d5">9.0</data>
  <data key="d6">A proposed taxonomy is necessary to evaluate the accuracy and trustworthiness of AI-generated HPC results, but it needs expansion for community-wide adoption.</data>
  <data key="d7">evaluation metrics, methodology</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Human-in-the-loop" target="Metadata-rich Suggestions">
  <data key="d5">16.0</data>
  <data key="d6">Incorporating human oversight with metadata-rich suggestions can refine AI outputs and improve HPC modernization processes.&lt;SEP&gt;Incorporating human oversight with metadata-rich suggestions can refine AI outputs, improving the reliability and relevance of generated HPC code.</data>
  <data key="d7">human-AI collaboration, refinement</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="HPC Software Modernization Initiatives" target="AI Tools">
  <data key="d5">14.0</data>
  <data key="d6">Large HPC modernization initiatives are exploring the integration of AI tools like generative models to enhance development and maintenance.&lt;SEP&gt;Large HPC modernization initiatives are exploring the integration of AI tools like generative models to enhance development, automation, and maintenance processes.</data>
  <data key="d7">project scope, technological integration</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Ecosystem Features Automation" target="Educational Aspects of HPC">
  <data key="d5">12.0</data>
  <data key="d6">Automating ecosystem features could influence educational approaches, making HPC more accessible and easier to learn.&lt;SEP&gt;Automating ecosystem features such as building, validation, and deployment could influence and improve educational strategies and training in HPC.</data>
  <data key="d7">automation impact, education&lt;SEP&gt;automation, education</data>
  <data key="d8">chunk-04aecdc2586d2c7966e70e02cac846b0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="William F. Godoy" target="Julia, Python/Numba, Kokkos">
  <data key="d5">16.0</data>
  <data key="d6">He evaluates performance and portability of high-level programming models on exascale nodes, including Julia, Python/Numba, and Kokkos.&lt;SEP&gt;He evaluates performance and portability of these programming models on exascale hardware.</data>
  <data key="d7">performance evaluation, HPC&lt;SEP&gt;performance evaluation, high-performance computing</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Association for Computing Machinery" target="ACE ’22">
  <data key="d5">16.0</data>
  <data key="d6">The conference ACE ’22 was organized by ACM, serving as a platform for presenting research in computing.&lt;SEP&gt;The conference ACE ’22 was organized by the ACM, focusing on computing research.</data>
  <data key="d7">organization, conference&lt;SEP&gt;organization, conference hosting</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Thomas Helmuth" target="PSB2: The Second Program Synthesis Benchmark Suite">
  <data key="d5">16.0</data>
  <data key="d6">He developed and proposes PSB2 for assessing program synthesis techniques.&lt;SEP&gt;Helmuth developed the PSB2 benchmark suite for evaluating program synthesis methods.</data>
  <data key="d7">benchmark development, program synthesis&lt;SEP&gt;benchmark, program synthesis</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Zheming Jin" target="Rodinia Benchmarks in SYCL">
  <data key="d5">16.0</data>
  <data key="d6">Jin works on implementing and analyzing benchmarks for heterogeneous computing using SYCL.&lt;SEP&gt;Jin's work involves implementing and analyzing the Rodinia benchmarks using SYCL for heterogeneous computing.</data>
  <data key="d7">benchmarking, heterogeneous computing</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Hecbench" target="Zhemin Jin">
  <data key="d5">16.0</data>
  <data key="d6">Developed Hecbench for HPC performance benchmarking.&lt;SEP&gt;Jin developed Hecbench, a benchmark suite for high-performance computing performance evaluation.</data>
  <data key="d7">benchmarking, HPC performance</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Srinath Kailasa" target="PyExaFMM">
  <data key="d5">32.0</data>
  <data key="d6">Kailasa's research involves designing high-performance software with Python and Numba, exemplified by PyExaFMM.&lt;SEP&gt;Kailasa's work involves high-performance software design using Python and Numba, exemplified by PyExaFMM.&lt;SEP&gt;Kailasa's work on high-performance software includes PyExaFMM, demonstrating Python and Numba capabilities.&lt;SEP&gt;Researches high-performance software with Python and Numba, exemplified by PyExaFMM.</data>
  <data key="d7">software development, HPC&lt;SEP&gt;software development, high-performance computing&lt;SEP&gt;software, HPC</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Andreas Klöckner" target="pycuda and pyopencl">
  <data key="d5">16.0</data>
  <data key="d6">He developed and documented these libraries for GPU runtime code generation.&lt;SEP&gt;Klöckner developed and documented pycuda and pyopencl for GPU runtime code generation.</data>
  <data key="d7">GPU programming, software tools</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Douglas Kothe" target="Exascale Computing in the United States">
  <data key="d5">16.0</data>
  <data key="d6">Discusses the current state and future prospects of exascale supercomputing in the US.&lt;SEP&gt;Kothe discusses the state and prospects of exascale computing efforts in the US.</data>
  <data key="d7">supercomputing, national infrastructure</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Yunsup Lee" target="GPU Computing">
  <data key="d5">16.0</data>
  <data key="d6">Focuses on GPU acceleration frameworks and high-performance software.&lt;SEP&gt;Lee's research focuses on GPU acceleration and high-performance software frameworks.</data>
  <data key="d7">parallel computing, software development&lt;SEP&gt;parallel computing, software frameworks</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Bryan Catanzaro" target="GPU Acceleration">
  <data key="d5">16.0</data>
  <data key="d6">Catanzaro contributes to GPU-accelerated deep learning frameworks and tools.&lt;SEP&gt;Contributes to GPU-accelerated deep learning frameworks and tools.</data>
  <data key="d7">deep learning, GPU acceleration&lt;SEP&gt;deep learning, parallel processing</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Paul Ivanov" target="GPU Programming Tools">
  <data key="d5">16.0</data>
  <data key="d6">Ivanov works on GPU programming frameworks and tools like pycuda.&lt;SEP&gt;Works on GPU programming frameworks like pycuda.</data>
  <data key="d7">software tools, GPU programming</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Ahmed Fasih" target="GPU Computing">
  <data key="d5">16.0</data>
  <data key="d6">Fasih's research involves GPU-based parallel computing and software.&lt;SEP&gt;Researcher in GPU-based parallel algorithms and high-performance software.</data>
  <data key="d7">parallel algorithms, HPC&lt;SEP&gt;parallel processing, high-performance computing</data>
  <data key="d8">chunk-5da9b3b8fd36c0504bd8f232a5c91252</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Cupy" target="NVIDIA CUDA Toolkit">
  <data key="d5">8.0</data>
  <data key="d6">Cupy is built to be compatible with NVIDIA's CUDA Toolkit, enabling GPU-accelerated computations using familiar numpy-like syntax.</data>
  <data key="d7">compatibility, GPU computing</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="JuliaGPU/AMDGPU.jl" target="GPU Programming">
  <data key="d5">16.0</data>
  <data key="d6">JuliaGPU/AMDGPU.jl enables high-performance GPU programming on AMD hardware, facilitating scientific and computational tasks.&lt;SEP&gt;JuliaGPU/AMDGPU.jl provides tools for high-performance GPU programming on AMD hardware, enabling advanced computational tasks.</data>
  <data key="d7">GPU computing, high-performance&lt;SEP&gt;GPU programming, high-performance computing</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Program Synthesis" target="Classical Approaches">
  <data key="d5">14.0</data>
  <data key="d6">Classical probabilistic context-free grammar methods are foundational in program synthesis, with neural methods building upon or improving these approaches.</data>
  <data key="d7">methodology, classical techniques</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation Tools" target="Programmers and Engineers">
  <data key="d5">9.0</data>
  <data key="d6">Tools like Codex automate tasks and may widen access to programming, affecting skills required.</data>
  <data key="d7">automation, skill shift</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation Tools" target="Import Packages and Libraries">
  <data key="d5">8.0</data>
  <data key="d6">Codex imports packages at different rates based on training data patterns, influencing code robustness and economic effects.</data>
  <data key="d7">import patterns, economic impact</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation Tools" target="Impacts on Labor Market">
  <data key="d5">9.0</data>
  <data key="d6">The deployment of Codex and similar tools can influence worker productivity, wages, and the structure of the programming job market.</data>
  <data key="d7">labor market impact, productivity, economic effects</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Security of GitHub Copilot" target="Hammond Pearce">
  <data key="d5">9.0</data>
  <data key="d6">Hammond Pearce conducted security assessments of GitHub Copilot's code contributions, analyzing vulnerabilities.</data>
  <data key="d7">security research, vulnerability assessment</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Security of GitHub Copilot" target="Baleegh Ahmad">
  <data key="d5">9.0</data>
  <data key="d6">Baleegh Ahmad contributed to security evaluations of AI-generated code, focusing on vulnerabilities.</data>
  <data key="d7">security analysis, vulnerability</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Security of GitHub Copilot" target="Benjamin Tan">
  <data key="d5">9.0</data>
  <data key="d6">Benjamin Tan's work involves assessing security implications of AI code contributions.</data>
  <data key="d7">security evaluation, AI code</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Security of GitHub Copilot" target="Brendan Dolan-Gavitt">
  <data key="d5">9.0</data>
  <data key="d6">Brendan Dolan-Gavitt's research includes analyzing security risks associated with AI-generated code.</data>
  <data key="d7">security research, vulnerabilities</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Security of GitHub Copilot" target="Ramesh Karri">
  <data key="d5">9.0</data>
  <data key="d6">Ramesh Karri contributed to understanding security vulnerabilities in AI code contributions.</data>
  <data key="d7">security analysis, vulnerabilities</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="NVIDIA" target="CUDA Toolkit Documentation">
  <data key="d5">8.0</data>
  <data key="d6">NVIDIA develops and maintains the CUDA Toolkit, which is essential for GPU programming and high-performance computing.</data>
  <data key="d7">developer, software documentation</data>
  <data key="d8">chunk-7d291b4c5bc433808e3d40f3b84dae35</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="T. Peterka, M. Strout, and J. Wilke" target="Extreme Heterogeneity 2018">
  <data key="d5">16.0</data>
  <data key="d6">The report authored by these researchers provides foundational knowledge on productive computational science strategies in heterogeneous environments.</data>
  <data key="d7">author-report, foundational knowledge</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="T. Peterka, M. Strout, and J. Wilke" target="DOE ASCR Workshop on Extreme Heterogeneity">
  <data key="d5">6.0</data>
  <data key="d6">The workshop organized by these authors' institution aims to address challenges in computational science posed by extreme heterogeneity, fostering productive strategies."|&gt;"workshop, scientific challenge</data>
  <data key="d7">6</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Yaqing Wang, Quanming Yao, James T. Kwok, and Lionel M. Ni" target="Generalizing from a Few Examples">
  <data key="d5">28.0</data>
  <data key="d6">The survey discusses approaches to few-shot learning, which is relevant for developing models that can learn from limited data, influencing AI methodology.&lt;SEP&gt;This survey reviews methods for enabling machine learning models to generalize from limited data, addressing a key challenge in AI.</data>
  <data key="d7">literature review, AI challenge&lt;SEP&gt;methodology, AI development</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Yaqing Wang, Quanming Yao, James T. Kwok, and Lionel M. Ni" target="ACM Comput. Surv.">
  <data key="d5">9.0</data>
  <data key="d6">The survey provides a comprehensive overview of few-shot learning techniques, contributing to research methodology and theoretical frameworks in AI."|&gt;"literature review, AI theory</data>
  <data key="d7">9</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Michel Wermelinger" target="Using GitHub Copilot to Solve Simple Programming Problems">
  <data key="d5">21.0</data>
  <data key="d6">The research demonstrates practical AI tool application in education, showing how GitHub Copilot can assist students and programmers."|&gt;"AI application, educational technology&lt;SEP&gt;The study investigates the effectiveness of GitHub Copilot in assisting with basic programming tasks, highlighting practical applications of AI in education.</data>
  <data key="d7">7&lt;SEP&gt;AI application, programming assistance</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Burak Yetistiren, Isik Ozsoy, and Eray Tuzun" target="Assessing the Quality of GitHub Copilot’s Code Generation">
  <data key="d5">24.0</data>
  <data key="d6">The study's findings inform best practices and limitations in AI code generation tools, impacting software engineering."|&gt;"performance assessment, software engineering&lt;SEP&gt;This research evaluates how well GitHub Copilot generates code, providing insights into its reliability and potential limitations.</data>
  <data key="d7">8&lt;SEP&gt;performance evaluation, AI reliability</data>
  <data key="d8">chunk-26eb2867fee2b7e0f5aa834b5b5d9096</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Background" target="Related efforts in computer science">
  <data key="d5">7.0</data>
  <data key="d6">The background discusses recent research efforts in AI code generation, prompt-based learning, and the application of large language models in scientific computing."|"&lt;literature review, context</data>
  <data key="d7">7</data>
  <data key="d8">chunk-38bf816094395541632173a71659ec3b</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Content-level keywords" target="main concepts">
  <data key="d5">9.0</data>
  <data key="d6">Main themes include programming languages, model sensitivity, code correctness, and evaluation metrics.</data>
  <data key="d7">main themes, overarching concepts</data>
  <data key="d8">chunk-64e7fd510c0d613c9975fe3385d6f3a0</data>
  <data key="d9">Godoy et al. - 2023 - Evaluation of OpenAI Codex for HPC Parallel Progra.pdf</data>
</edge>
<edge source="Domain Specification Techniques" target="Application Domains">
  <data key="d5">16.0</data>
  <data key="d6">These techniques are applied within various critical application domains to improve model performance and domain fit.&lt;SEP&gt;These techniques are applied within various critical application domains to improve model performance and domain relevance."|"&lt;application, domain adaptation</data>
  <data key="d7">8&lt;SEP&gt;application, domain adaptation</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specification Techniques" target="Heterogeneity of Domain Data">
  <data key="d5">15.0</data>
  <data key="d6">Addressing data heterogeneity is a key challenge that domain specification techniques aim to overcome.&lt;SEP&gt;Addressing data heterogeneity is a primary goal of domain-specific techniques to enable effective LLM deployment in diverse fields."|"&lt;data heterogeneity, challenge, solution</data>
  <data key="d7">8&lt;SEP&gt;data heterogeneity, challenge, solution</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specification Techniques" target="Sophistication of Domain Knowledge">
  <data key="d5">13.0</data>
  <data key="d6">Techniques aim to incorporate complex, domain-specific knowledge into LLMs to improve understanding and reasoning."|"&lt;knowledge integration, complexity&lt;SEP&gt;Techniques are designed to incorporate and manage complex domain knowledge within LLMs.</data>
  <data key="d7">7&lt;SEP&gt;knowledge integration, complexity</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specification Techniques" target="Uniqueness of Domain Objectives">
  <data key="d5">14.0</data>
  <data key="d6">Customization methods consider the specific objectives and constraints of each domain to optimize LLM performance."|"&lt;objectives, customization&lt;SEP&gt;Tailoring techniques consider the specific objectives and constraints of each domain to optimize LLM performance.</data>
  <data key="d7">7&lt;SEP&gt;objectives, customization</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specification Techniques" target="Diversity of Constraints">
  <data key="d5">16.0</data>
  <data key="d6">Handling social, cultural, ethical, and normative constraints is essential for deploying LLMs responsibly and effectively in various domains."|"&lt;constraints, ethical standards&lt;SEP&gt;Handling various social, cultural, and ethical constraints is a critical aspect of domain-specific LLM development.</data>
  <data key="d7">8&lt;SEP&gt;constraints, ethical standards</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Techniques">
  <data key="d5">9.0</data>
  <data key="d6">Techniques are applied within specific application domains to enhance the effectiveness of domain-specific LLMs.</data>
  <data key="d7">application context</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Framework for Subcategories">
  <data key="d5">8.0</data>
  <data key="d6">The framework organizes subcategories that define the relationships and differences among various domain-specific applications of LLMs.</data>
  <data key="d7">structural organization</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Practical Significance">
  <data key="d5">7.0</data>
  <data key="d6">Application domains benefit from specialized LLMs by achieving significant practical improvements in their respective fields.</data>
  <data key="d7">impact</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Social Norms, Cultural Conformity, Religious Beliefs, Legal Requirements, Ethical Practice">
  <data key="d5">3.0</data>
  <data key="d6">These social, cultural, and legal factors influence how LLMs must be adapted and regulated within different application domains.</data>
  <data key="d7">contextual adaptation</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Domain Specialization Techniques">
  <data key="d5">9.0</data>
  <data key="d6">Techniques are developed to adapt models for specific application domains, improving their effectiveness.</data>
  <data key="d7">domain adaptation, application-specific performance</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Technical Taxonomy of Domain Specialization">
  <data key="d5">8.0</data>
  <data key="d6">The taxonomy classifies techniques used for domain-specific LLM adaptation, guiding future developments.</data>
  <data key="d7">classification, systematic understanding</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Application Domains" target="Future Research Directions">
  <data key="d5">16.0</data>
  <data key="d6">Expanding application domains and developing new techniques are key future directions to enhance the utility of domain-specific LLMs.&lt;SEP&gt;Future research aims to expand application domains and develop new techniques to overcome current limitations in domain-specific LLMs.</data>
  <data key="d7">research expansion, innovation</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Open Challenges" target="Future Trends">
  <data key="d5">12.0</data>
  <data key="d6">Identifying current limitations informs future research directions and the evolution of domain-specific LLMs.&lt;SEP&gt;Understanding current limitations helps shape future research directions and the evolution of domain-specific LLM techniques."|"&lt;research, development, future</data>
  <data key="d7">6&lt;SEP&gt;research, development, future</data>
  <data key="d8">chunk-1c77a184d805ecadcb8dd5b0d1057e7c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Open Challenges" target="Research Trends">
  <data key="d5">8.0</data>
  <data key="d6">Current research trends aim to address open challenges such as resource demands and knowledge integration.</data>
  <data key="d7">future directions, research focus</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Pre-trained Language Models (PLMs)" target="Scaling law">
  <data key="d5">8.0</data>
  <data key="d6">The scaling law explains how increasing the size and data of PLMs can improve their performance, leading to the development of larger models like GPT-3.</data>
  <data key="d7">model scaling</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain specialization of LLMs" target="Knowledge cut-off">
  <data key="d5">7.0</data>
  <data key="d6">Domain-specific customization helps mitigate issues caused by knowledge cut-off, enabling LLMs to stay relevant in specialized fields.</data>
  <data key="d7">knowledge update</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Challenges in domain specialization" target="Future trends">
  <data key="d5">6.0</data>
  <data key="d6">Addressing current challenges is key to enabling future advancements and broader deployment of domain-specialized LLMs.</data>
  <data key="d7">research direction</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Update" target="Knowledge Cut-off">
  <data key="d5">6.0</data>
  <data key="d6">Updating mechanisms are necessary to overcome the knowledge cut-off and keep LLMs relevant in fast-evolving domains.</data>
  <data key="d7">knowledge maintenance</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Update" target="Scaling up Model and Data">
  <data key="d5">5.0</data>
  <data key="d6"> Scaling models and data can help address the knowledge cut-off by enabling models to learn from larger, more recent datasets.</data>
  <data key="d7">scaling benefits</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Update" target="Proprietary Knowledge Resources">
  <data key="d5">4.0</data>
  <data key="d6"> Proprietary knowledge resources are critical for domain-specific LLMs but pose challenges for updating and sharing.</data>
  <data key="d7">data privacy, proprietary constraints</data>
  <data key="d8">chunk-130e4012ca037ccaf70ac4ffd0928777</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Update" target="High-Confidence Rationale-Augmented Answers">
  <data key="d5">8.0</data>
  <data key="d6">Huang et al.'s method uses high-confidence, rationale-augmented answers generated by pre-trained LLMs to improve reasoning without ground truth labels, expanding knowledge safely.</data>
  <data key="d7">method, reasoning</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Update" target="Continual Learning via Rehearsal">
  <data key="d5">8.0</data>
  <data key="d6">Scialom et al. expand LLM abilities without forgetting previous skills by fine-tuning across tasks and employing rehearsal techniques to mitigate catastrophic forgetting.</data>
  <data key="d7">technique, knowledge retention</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Discoveries" target="Regulations">
  <data key="d5">16.0</data>
  <data key="d6">Discoveries often lead to new regulations or updates in practices to incorporate new knowledge safely and effectively.&lt;SEP&gt;New discoveries often lead to updates or creation of regulations to ensure safe and effective application of knowledge.</data>
  <data key="d7">knowledge advancement, regulation&lt;SEP&gt;knowledge regulation</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Regulations" target="Best Practices">
  <data key="d5">14.0</data>
  <data key="d6">Best practices evolve based on regulations and discoveries to ensure compliance and optimal performance.&lt;SEP&gt;Best practices evolve based on regulations and discoveries to optimize practices and ensure compliance.</data>
  <data key="d7">practice evolution, compliance</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Extraction" target="Re-Training">
  <data key="d5">8.0</data>
  <data key="d6">Re-Training is used to incorporate newly extracted knowledge into models, maintaining relevance in dynamic fields.</data>
  <data key="d7">model updating, relevance</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Re-Training" target="Continuous Learning">
  <data key="d5">8.0</data>
  <data key="d6">Re-Training supports continuous learning mechanisms, allowing models to adapt over time with new data.</data>
  <data key="d7">adaptation, model evolution</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hallucination" target="Knowledge">
  <data key="d5">9.0</data>
  <data key="d6">Lack of domain-specific knowledge can cause LLMs to hallucinate, generating inaccurate information.</data>
  <data key="d7">accuracy, knowledge gaps</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hallucination" target="Task-Specific Demonstrations">
  <data key="d5">8.0</data>
  <data key="d6">Providing task-specific demonstrations can reduce hallucinations by guiding models toward accurate outputs.</data>
  <data key="d7">guidance, accuracy</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Downstream Task Learning" target="Hyperparameters">
  <data key="d5">7.0</data>
  <data key="d6">Hyperparameters influence the success of downstream learning by affecting training dynamics and model performance.</data>
  <data key="d7">optimization, training</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Computational Power" target="Model Complexity">
  <data key="d5">8.0</data>
  <data key="d6">Training large, complex models requires substantial computational power, often limiting accessibility for smaller organizations.</data>
  <data key="d7">resource constraint, scalability</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Complexity" target="Model Explainability">
  <data key="d5">8.0</data>
  <data key="d6">Higher model complexity often reduces explainability, creating a trade-off that impacts trust and interpretability.</data>
  <data key="d7">trade-off, interpretability</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Taxonomy of Techniques" target="Evaluation Methods">
  <data key="d5">8.0</data>
  <data key="d6">The taxonomy helps categorize techniques based on their accessibility and applicability, aiding evaluation and selection.</data>
  <data key="d7">classification, assessment</data>
  <data key="d8">chunk-51f3018c9cc02b8c33f697aa15c2c906</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt-based Learning" target="Evaluation of Domain Adaptation">
  <data key="d5">6.0</data>
  <data key="d6">Prompt engineering is a methodology used to adapt LLMs for specific tasks without extensive retraining, relevant in evaluating domain adaptation techniques.</data>
  <data key="d7">methodology, task adaptation</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Evaluation of Domain Adaptation" target="Open Challenges in Domain Specialization">
  <data key="d5">16.0</data>
  <data key="d6">Evaluations reveal current limitations and challenges faced when adapting LLMs to specific domains.&lt;SEP&gt;Systematic evaluations highlight the current limitations and challenges in adapting LLMs to specific domains.</data>
  <data key="d7">assessment, limitations&lt;SEP&gt;research assessment, limitations</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Open Challenges in Domain Specialization" target="Future Trends in LLM Research">
  <data key="d5">10.0</data>
  <data key="d6">Future research aims to address existing bottlenecks and explore new strategies for domain-specific LLM development.</data>
  <data key="d7">research directions, innovation</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Open Challenges in Domain Specialization" target="Future Directions in LLM Research">
  <data key="d5">9.0</data>
  <data key="d6">Future research aims to address existing bottlenecks such as architecture inaccessibility and high computational costs.</data>
  <data key="d7">research goals, innovation</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Scaling" target="Performance Enhancement">
  <data key="d5">7.0</data>
  <data key="d6">Scaling models by increasing parameters or data size improves their capacity for various NLP tasks.</data>
  <data key="d7">capacity, performance boost</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Adaptation Techniques" target="Application of">
  <data key="d5">8.0</data>
  <data key="d6">Domain adaptation techniques are applied to general LLMs to improve their performance in specific fields like medicine or finance.</data>
  <data key="d7">method application, specialization</data>
  <data key="d8">chunk-bb9f9f9e90a0c162892181da55ffb7b4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Ms" target="Sequence Models">
  <data key="d5">14.0</data>
  <data key="d6">Ms are used for sequence-to-sequence tasks like translation and summarization, demonstrating their core concepts.&lt;SEP&gt;Ms are used for sequence-to-sequence tasks, illustrating their application in NLP.</data>
  <data key="d7">model application, NLP tasks</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="T5" target="Sequence-to-Sequence Tasks">
  <data key="d5">16.0</data>
  <data key="d6">T5 exemplifies a model used for sequence-to-sequence tasks like translation and summarization.&lt;SEP&gt;T5 is a model designed for sequence-to-sequence tasks such as translation and summarization, exemplifying the application of core concepts.</data>
  <data key="d7">application, model architecture</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="GPT" target="Autoregressive Language Models">
  <data key="d5">16.0</data>
  <data key="d6">GPT is an autoregressive model generating contextually relevant content based on previous tokens.&lt;SEP&gt;GPT is an example of an autoregressive language model that generates contextually relevant content.</data>
  <data key="d7">model type, content generation</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Autoregressive Language Models" target="Sequence of Tokens">
  <data key="d5">9.0</data>
  <data key="d6">Autoregressive models generate each token based on previous tokens in a sequence.</data>
  <data key="d7">generation process, sequence modeling</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Sequence of Tokens" target="Vector Representation">
  <data key="d5">16.0</data>
  <data key="d6">Sequences of tokens are mapped into vector representations for processing by models.&lt;SEP&gt;Token sequences are mapped into vector representations for processing by models.</data>
  <data key="d7">data representation, model input</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Sequence of Tokens" target="Autoregressive Modeling">
  <data key="d5">9.0</data>
  <data key="d6">Autoregressive models generate each token based on preceding tokens in a sequence.</data>
  <data key="d7">generation process, sequence modeling</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Vector Representation" target="Contextually Relevant Content">
  <data key="d5">14.0</data>
  <data key="d6">Vector representations enable models to generate content relevant to the context.&lt;SEP&gt;Vector representations enable models to generate relevant content based on context.</data>
  <data key="d7">content relevance, model output</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Specialization of LLMs" target="Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Domain specialization involves external augmentation, prompt crafting, and fine-tuning to adapt LLMs.</data>
  <data key="d7">methodology, adaptation techniques</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="External Augmentation" target="Domain Knowledge">
  <data key="d5">8.0</data>
  <data key="d6">External augmentation incorporates domain knowledge via tools or resources without internal model changes.</data>
  <data key="d7">knowledge integration, external resources</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="External Augmentation" target="Black Box">
  <data key="d5">14.0</data>
  <data key="d6">Black box scenarios rely on external augmentation methods without internal model access.&lt;SEP&gt;Black box scenarios rely on external augmentation without internal model access.</data>
  <data key="d7">model access, external methods</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Crafting" target="Domain Knowledge">
  <data key="d5">7.0</data>
  <data key="d6">Prompt crafting involves designing prompts to guide models towards domain-specific responses.</data>
  <data key="d7">prompt design, domain specificity</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Crafting" target="Grey Box">
  <data key="d5">14.0</data>
  <data key="d6">Grey box scenarios involve designing prompts with limited internal model information.&lt;SEP&gt;Grey box scenarios involve prompt crafting with limited internal model information.</data>
  <data key="d7">model understanding, prompt design</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="External Knowledge" target="Knowledge-updated Domain Specialization">
  <data key="d5">7.0</data>
  <data key="d6">External knowledge sources contribute to internal model updates, leading to domain-specific improvements.</data>
  <data key="d7">knowledge integration, domain adaptation</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="External Knowledge" target="Scalability and Adaptability">
  <data key="d5">14.0</data>
  <data key="d6">Addressing scalability and adaptability challenges is essential for managing large, evolving knowledge bases in external knowledge augmentation systems."|</data>
  <data key="d7">system scalability, knowledge management</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="External Knowledge" target="Knowledge Augmentation">
  <data key="d5">8.0</data>
  <data key="d6">Knowledge augmentation involves using external or embedded knowledge to improve model performance and handle complex tasks."|</data>
  <data key="d7">performance enhancement, domain knowledge</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="External Knowledge" target="Relevance Verification">
  <data key="d5">9.0</data>
  <data key="d6">Verifying the relevance and accuracy of retrieved information ensures the reliability of the augmented model outputs."|</data>
  <data key="d7">validation, accuracy</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge-updated Domain Specialization" target="Internal Knowledge">
  <data key="d5">16.0</data>
  <data key="d6">Updating internal model knowledge with domain-specific text enhances specialization.&lt;SEP&gt;Updating the model's internal knowledge with domain-specific data enhances its specialization.</data>
  <data key="d7">knowledge update, internal model</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Knowledge Augmentation" target="External Resources">
  <data key="d5">8.0</data>
  <data key="d6">External resources such as databases or external knowledge bases are used to enhance domain-specific performance in language models.</data>
  <data key="d7">knowledge sources, external data</data>
  <data key="d8">chunk-3c24b46980eea930fd6590d61f0b0f25</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Instruction-based Fine-tuning" target="Zero-shot Performance">
  <data key="d5">18.0</data>
  <data key="d6">Instruction tuning enhances zero-shot capabilities by providing explicit task instructions during training.</data>
  <data key="d7">task generalization, performance boost</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Parameters to Incorporate" target="Approaches in Different Categories">
  <data key="d5">8.0</data>
  <data key="d6">Parameters to incorporate domain knowledge are operationalized through various approaches like external augmentation, prompt engineering, and fine-tuning, each with distinct mechanisms and effects.</data>
  <data key="d7">approach integration, model customization</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="External Knowledge Augmentation" target="Explicit Knowledge">
  <data key="d5">9.0</data>
  <data key="d6">External knowledge sources provide explicit, structured domain information that can be retrieved and used to refine model outputs.</data>
  <data key="d7">knowledge retrieval, domain accuracy</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Framework for Domain Specialization" target="Stages">
  <data key="d5">8.0</data>
  <data key="d6">The framework encompasses four core stages—Definition, Augmentation, Optimization, and Evaluation—structured to systematically adapt models to domains.</data>
  <data key="d7">process structure, systematic adaptation</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Definition" target="Stage">
  <data key="d5">7.0</data>
  <data key="d6">Defines the domain, objectives, and constraints to guide subsequent steps in model adaptation.</data>
  <data key="d7">goal setting, scope definition</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Augmentation" target="Stage">
  <data key="d5">8.0</data>
  <data key="d6">Involves adding domain-specific knowledge or tools to the model or inputs, such as through fine-tuning or prompt crafting.</data>
  <data key="d7">knowledge integration, input modification</data>
  <data key="d8">chunk-384c5ce5a8f4d5429d6ef56e99c277dd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Explicit Knowledge" target="Neural Retriever">
  <data key="d5">14.0</data>
  <data key="d6">Neural retrievers search knowledge bases to find relevant explicit information, which is then used to inform or refine LLM predictions."|</data>
  <data key="d7">information retrieval, external context</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Implicit Knowledge" target="Attention Mechanisms">
  <data key="d5">18.0</data>
  <data key="d6">Attention mechanisms enable models to access and retrieve implicit knowledge embedded as vectorized representations, enhancing understanding and response accuracy."|</data>
  <data key="d7">latent knowledge access, data patterns</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Neural adapters" target="object of study">
  <data key="d5">8.0</data>
  <data key="d6">Neural adapters are a class of adapter modules with neural network architectures used for domain adaptation."|&lt;"object</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Tool" target="Specialized Tasks">
  <data key="d5">12.0</data>
  <data key="d6">Domain tools are designed to handle specific tasks within a domain, often requiring strict input formats, and complement the general capabilities of LLMs."|</data>
  <data key="d7">specialization, task handling</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Explainability" target="Retrieval Transparency">
  <data key="d5">8.0</data>
  <data key="d6">Transparent retrieval processes contribute to model explainability by making the source and reasoning behind outputs understandable."|</data>
  <data key="d7">trust, interpretability</data>
  <data key="d8">chunk-8bf110218e64d416737ff57117ec74cc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Tools" target="APIs and Tools">
  <data key="d5">6.0</data>
  <data key="d6">Scripts generated by LLMs invoke domain-specific APIs to perform specialized functions like search or automation.</data>
  <data key="d7">API interaction, domain specialization</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Tools" target="APIs">
  <data key="d5">6.0</data>
  <data key="d6">Scripts generated by LLMs call domain-specific APIs to perform functions like search, database queries, or automation.</data>
  <data key="d7">API interaction, domain specialization</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Collaboration Approach" target="Multi-stage Pipeline">
  <data key="d5">9.0</data>
  <data key="d6">The collaboration approach employs a multi-stage pipeline where LLMs generate commands, execute them via domain tools, and process results.</data>
  <data key="d7">workflow, task automation</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Multi-stage Pipeline" target="Collaborative Integration Approach">
  <data key="d5">9.0</data>
  <data key="d6">The approach employs a pipeline where LLMs generate commands, execute them via domain tools, and process outputs to solve complex tasks.</data>
  <data key="d7">workflow, task automation</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Executable Commands" target="Python Script">
  <data key="d5">20.0</data>
  <data key="d6">LLMs generate executable Python scripts to solve arithmetic problems, demonstrating how code can be used as a domain tool.&lt;SEP&gt;LLMs generate executable Python scripts to solve specific arithmetic problems, demonstrating direct code generation for domain tasks.</data>
  <data key="d7">code generation, problem solving</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Executable Commands" target="Zero-shot and Few-shot Prompting">
  <data key="d5">5.0</data>
  <data key="d6">Prompting techniques are used to elicit executable commands from LLMs with minimal task-specific examples.</data>
  <data key="d7">prompt engineering, minimal data</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Task Decomposition" target="Task Planners">
  <data key="d5">14.0</data>
  <data key="d6">Task planners decompose complex problems into subtasks, enabling coordinated calling of multiple domain tools for comprehensive solutions.&lt;SEP&gt;Task planners decompose complex tasks into subtasks, enabling coordinated calling of multiple domain tools for comprehensive solutions.</data>
  <data key="d7">complexity management, coordination&lt;SEP&gt;complexity management, task coordination</data>
  <data key="d8">chunk-d8772ec3475b4e5b1b113032265f9d74</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Zero-shot Discrete Prompts" target="LLM">
  <data key="d5">17.0</data>
  <data key="d6">Zero-shot prompts are used to evaluate LLMs' ability to perform tasks without prior examples, relying solely on task descriptions.&lt;SEP&gt;Zero-shot prompts are used to evaluate the model's ability to perform tasks solely based on task descriptions without prior examples.</data>
  <data key="d7">evaluation, generalization&lt;SEP&gt;evaluation, task generalization</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Zero-shot Discrete Prompts" target="Instruction alignment pre-training">
  <data key="d5">13.0</data>
  <data key="d6">Instruction alignment pre-training enhances the model's ability to perform unseen tasks by aligning training objectives with human instructions.&lt;SEP&gt;Pre-training methods improve zero-shot performance by aligning instructions with model capabilities.</data>
  <data key="d7">training, model enhancement&lt;SEP&gt;training, performance boost</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Few-shot Discrete Prompts" target="LLM">
  <data key="d5">15.0</data>
  <data key="d6">Few-shot prompts include a small set of examples to help the model understand the task better, improving performance.&lt;SEP&gt;Few-shot prompts provide a small number of examples to help LLMs better understand and perform the task.</data>
  <data key="d7">learning efficiency, task clarity&lt;SEP&gt;sample efficiency, task learning</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Few-shot Discrete Prompts" target="Task description">
  <data key="d5">7.0</data>
  <data key="d6">Few-shot prompts include task descriptions and examples to guide LLMs in performing specific tasks.</data>
  <data key="d7">training data, prompt design</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLM" target="Zero-shot CoT">
  <data key="d5">8.0</data>
  <data key="d6">Zero-shot-CoT enhances reasoning ability by prompting models to think step-by-step before answering.</data>
  <data key="d7">reasoning, prompt strategy</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLM" target="Zero-shot-CoT">
  <data key="d5">9.0</data>
  <data key="d6">Zero-shot-CoT significantly improves the model's logical reasoning capabilities without additional training data.</data>
  <data key="d7">reasoning, performance improvement</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Reasoning sentences" target="Zero-shot CoT">
  <data key="d5">9.0</data>
  <data key="d6">Zero-shot Chain-of-Thoughts (CoT) prompts add reasoning steps to improve logical reasoning in LLM outputs.</data>
  <data key="d7">multi-step reasoning, prompt engineering</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Reasoning sentences" target="Zero-shot-CoT">
  <data key="d5">10.0</data>
  <data key="d6">Zero-shot-CoT prompts the model to generate reasoning steps before final answers, leading to improved reasoning performance.</data>
  <data key="d7">multi-step reasoning, prompt design</data>
  <data key="d8">chunk-daac5179ef8fa77fe775da37eb1276f3</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="APGAR Scores" target="Hypothesis">
  <data key="d5">5.0</data>
  <data key="d6">The hypothesis proposes that the subject had low APGAR scores, directly relating the hypothesis to the clinical measurement."|&gt;"research question, clinical assessment</data>
  <data key="d7">5</data>
  <data key="d8">chunk-03fe9b9ee91cb6d7d1e6d86d23f22ae9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="APGAR Scores" target="Neonatal Health">
  <data key="d5">9.0</data>
  <data key="d6">APGAR scores are used as a measure to evaluate neonatal health status."|&gt;"measurement, health assessment</data>
  <data key="d7">9</data>
  <data key="d8">chunk-03fe9b9ee91cb6d7d1e6d86d23f22ae9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="APGAR Scores" target="Clinical Assessment">
  <data key="d5">8.0</data>
  <data key="d6">APGAR scores are a component of clinical assessment tools used for newborn evaluation."|&gt;"assessment tools, clinical evaluation</data>
  <data key="d7">8</data>
  <data key="d8">chunk-03fe9b9ee91cb6d7d1e6d86d23f22ae9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hypothesis" target="Low APGAR Scores">
  <data key="d5">8.0</data>
  <data key="d6">The hypothesis directly proposes that the subject had low APGAR scores, linking the research question to a specific variable of interest."|&gt;"research question, variable</data>
  <data key="d7">8</data>
  <data key="d8">chunk-03fe9b9ee91cb6d7d1e6d86d23f22ae9</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="prompt tuning" target="prompt content enhancement">
  <data key="d5">8.0</data>
  <data key="d6">Prompt content enhancement is a component of prompt tuning aimed at improving task-specific initialization and knowledge transfer."|</data>
  <data key="d7">component</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="prompt tuning" target="prompt initialization">
  <data key="d5">7.0</data>
  <data key="d6">Proper initialization of prompts impacts the convergence and effectiveness of prompt tuning methods."|</data>
  <data key="d7">causal</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="prompt transferability" target="prompt transfer">
  <data key="d5">9.0</data>
  <data key="d6">The transferability of prompts allows knowledge learned in one domain or task to benefit others, enhancing adaptability."|</data>
  <data key="d7">concept</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="self-supervised learning" target="prompt pre-training">
  <data key="d5">8.0</data>
  <data key="d6">Self-supervised learning is used to pre-train prompts on unlabeled data, facilitating better transfer and initialization."|</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Tuning" target="Prompt Content">
  <data key="d5">8.0</data>
  <data key="d6">Prompt content forms the core of prompt tuning, representing embedded task information that can be optimized and enhanced."|</data>
  <data key="d7">component</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Tuning" target="Prompt Initialization">
  <data key="d5">7.0</data>
  <data key="d6">Initialization of prompts directly impacts the convergence speed and final performance of prompt tuning methods."|</data>
  <data key="d7">causal</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Tuning" target="Prompt Transferability">
  <data key="d5">9.0</data>
  <data key="d6">Transferability allows prompts trained in one context to be reused or adapted in others, facilitating domain and task transfer."|</data>
  <data key="d7">concept</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Tuning" target="Prompt Transfer">
  <data key="d5">9.0</data>
  <data key="d6">Applying prompts learned in one task or domain to another enhances efficiency and performance in new settings."|</data>
  <data key="d7">application</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Tuning" target="Discreet Prompt Methods">
  <data key="d5">6.0</data>
  <data key="d6">Discreet prompt methods are a subset of prompt tuning that rely on manually designed prompts, which can be sensitive and less flexible."|&gt;"technique, manual design</data>
  <data key="d7">6</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt Initialization" target="Self-supervised Learning">
  <data key="d5">8.0</data>
  <data key="d6">Self-supervised learning is used to pre-train prompts on unlabeled data, leading to better initialization and transfer capabilities."|</data>
  <data key="d7">methodology</data>
  <data key="d8">chunk-6f045498b0e63780c3aef4b9daf795b6</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Adaptation" target="OPTIMA">
  <data key="d5">17.0</data>
  <data key="d6">OPTIMA achieves domain adaptation by tuning prompts to regularize decision boundaries and improve transferability across similar data distributions.&lt;SEP&gt;OPTIMA tunes prompts to regularize decision boundaries, enhancing transferability across similar data distributions."|&gt;"domain transfer, adversarial learning</data>
  <data key="d7">8&lt;SEP&gt;domain transfer, adversarial learning</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="WARP" target="Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May">
  <data key="d5">16.0</data>
  <data key="d6">The team developed WARP, a word-level adversarial reprogramming technique, linking researchers to this adversarial methodology.&lt;SEP&gt;The team developed WARP: Word-level Adversarial ReProgramming, linking them to adversarial robustness and input manipulation techniques.</data>
  <data key="d7">adversarial reprogramming, word-level</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Limited Access to LLMs" target="Derivative-Free Prompt Search">
  <data key="d5">15.0</data>
  <data key="d6">Limited access to large models motivates the development of derivative-free prompt search methods that do not require gradient information.&lt;SEP&gt;Limited access to large models motivates the development of derivative-free prompt search methods that do not require gradient information."|&gt;"model access restriction, optimization</data>
  <data key="d7">7&lt;SEP&gt;model access restriction, optimization methods</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Clip-Tuning" target="Black-box Tuning">
  <data key="d5">14.0</data>
  <data key="d6">Clip-Tuning employs deterministic clipping of model instances to facilitate prompt optimization when gradient access is limited.&lt;SEP&gt;Clip-Tuning employs deterministic clipping of model instances to facilitate prompt optimization when gradient access is limited."|&gt;"model clipping, prompt optimization</data>
  <data key="d7">7&lt;SEP&gt;model clipping, prompt optimization</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Derivative-Free Prompt Search" target="Black-box Tuning">
  <data key="d5">17.0</data>
  <data key="d6">Black-box tuning is a gradient-free approach suitable for models with restricted access, aiming to optimize prompts without model gradients.&lt;SEP&gt;Black-box tuning is a gradient-free approach suitable for models with restricted access, aiming to optimize prompts without model gradients."|&gt;"gradient-free, model access</data>
  <data key="d7">8&lt;SEP&gt;gradient-free, model access</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="LLaMA-adapter">
  <data key="d5">7.0</data>
  <data key="d6">LLaMA-adapter is designed for efficient adaptation of large language models like LLaMA, incorporating self-instruct demonstrations and special attention mechanisms."|&lt;"tool</data>
  <data key="d7">7</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="AdapterFusion">
  <data key="d5">7.0</data>
  <data key="d6">AdapterFusion combines multiple adapters to improve domain adaptation performance, typically through weighted averaging."|&lt;"tool</data>
  <data key="d7">7</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="UniPELT">
  <data key="d5">6.0</data>
  <data key="d6">UniPELT activates different combinations of adapters based on data or task via a gating mechanism, enabling flexible adaptation.</data>
  <data key="d7">adaptive activation, task-specific tuning</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="AdaMix">
  <data key="d5">7.0</data>
  <data key="d6">AdaMix stacks adapters of the same type and employs stochastic routing to reduce computational overhead.</data>
  <data key="d7">cost efficiency, stacking</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Polytropon">
  <data key="d5">8.0</data>
  <data key="d6">Polytropon jointly learns an inventory of adapters and routing functions for multi-task sharing across different tasks.</data>
  <data key="d7">multi-task sharing, routing</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Backpropagation">
  <data key="d5">16.0</data>
  <data key="d6">Backpropagation is used to train neural networks, including the training of adapters within LLMs, to optimize their performance.</data>
  <data key="d7">training, optimization</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Stability and Universality">
  <data key="d5">14.0</data>
  <data key="d6">Theories or models addressing the stability and universality of adapters across different architectures and tasks.</data>
  <data key="d7">theoretical challenges, generalization</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapters" target="Computational Resources">
  <data key="d5">12.0</data>
  <data key="d6">The size and complexity of adapters influence the computational resources needed for training and deployment.</data>
  <data key="d7">cost, scalability</data>
  <data key="d8">chunk-891622908a24bf5367903ed1b9780d8b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Parameter-efficient Fine-tuning" target="Elad Ben Zaken">
  <data key="d5">18.0</data>
  <data key="d6">Elad Ben Zaken developed Bitfit, a parameter-efficient fine-tuning method for transformers.</data>
  <data key="d7">methodology, efficiency</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="adapters" target="parameter-efficient fine-tuning">
  <data key="d5">9.0</data>
  <data key="d6">Adapters enable parameter-efficient fine-tuning by allowing models to adapt to new tasks or domains with minimal additional parameters.</data>
  <data key="d7">technique</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="adapters" target="domain adaptation">
  <data key="d5">8.0</data>
  <data key="d6">Adapters are used specifically for domain adaptation, learning domain-invariant representations to generalize across different data domains.</data>
  <data key="d7">application</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="adapters" target="parameter sharing">
  <data key="d5">9.0</data>
  <data key="d6">Adapters enable parameter sharing by allowing multiple domain-specific modules to utilize the same underlying parameters, promoting efficiency."|&lt;"relationship</data>
  <data key="d7">9</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="adapters" target="frozen parameters">
  <data key="d5">8.0</data>
  <data key="d6">During training, adapters operate with frozen original model parameters, focusing learning on the adapter modules."|&lt;"relationship</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="adapters" target="domain-invariant representations">
  <data key="d5">9.0</data>
  <data key="d6">Adapters are trained to learn representations that are effective across multiple domains, enabling cross-domain generalization."|&lt;"relationship</data>
  <data key="d7">9</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="adapters" target="parameter efficiency">
  <data key="d5">8.0</data>
  <data key="d6">Adapters are designed to achieve high performance with minimal additional parameters, making models more efficient."|&lt;"relationship</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="AdapterFusion" target="Multiple Tasks">
  <data key="d5">7.0</data>
  <data key="d6">AdapterFusion combines multiple task-specific adapters via a fusion layer to improve overall performance across tasks.</data>
  <data key="d7">multi-task learning, performance boost</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLaMA-adapter" target="LLaMA">
  <data key="d5">7.0</data>
  <data key="d6">The LLaMA-adapter is an adaptation module designed specifically for the LLaMA model to facilitate domain-specific fine-tuning."|&lt;"relationship</data>
  <data key="d7">7</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="SparseAdapter" target="tools">
  <data key="d5">6.0</data>
  <data key="d6">SparseAdapter prunes parameters at initialization to reduce training parameters, enhancing efficiency in neural adapters."|&lt;"tool</data>
  <data key="d7">6</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="SparseAdapter" target="Kronecker Products">
  <data key="d5">8.0</data>
  <data key="d6">SparseAdapter's approach to parameter reduction is inspired by the use of Kronecker products, which enable efficient sum of products in neural layers.</data>
  <data key="d7">technique inspiration, parameter efficiency</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="SparseAdapter" target="Shwai He, Liang Ding, Daize Dong, Miao Zhang, and Dacheng Tao">
  <data key="d5">8.0</data>
  <data key="d6">The authors introduce sparse adapters to neural networks to improve parameter efficiency during fine-tuning, establishing a direct link to this methodology.</data>
  <data key="d7">parameter efficiency, adapters</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="domain adaptation" target="two-step training strategy">
  <data key="d5">8.0</data>
  <data key="d6">A method involving domain-fusion training followed by task fine-tuning to improve domain adaptation."|&lt;"relationship</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="two-step training strategy" target="domain-fusion training">
  <data key="d5">8.0</data>
  <data key="d6">Domain-fusion training is the initial phase where models learn to integrate data from multiple domains using MLM loss."|&lt;"relationship</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="two-step training strategy" target="task fine-tuning">
  <data key="d5">8.0</data>
  <data key="d6">Task fine-tuning is the subsequent phase where models are optimized on specific task data within a domain."|&lt;"relationship</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="UDApter" target="domain adapter">
  <data key="d5">8.0</data>
  <data key="d6">The domain adapter learns domain-invariant features to enable models to perform well across different domains."|&lt;"relationship</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="UDApter" target="task adapter">
  <data key="d5">8.0</data>
  <data key="d6">The task adapter is trained on task-specific data, often kept frozen during domain adaptation to preserve task performance."|&lt;"relationship</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="AdapterSoup" target="domain adapters">
  <data key="d5">7.0</data>
  <data key="d6">AdapterSoup combines weights of multiple domain adapters during testing to improve adaptation efficiency."|&lt;"relationship</data>
  <data key="d7">7</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LLaMA" target="large language model">
  <data key="d5">7.0</data>
  <data key="d6">LLaMA is a large language model architecture designed for efficient adaptation using adapters."|&lt;"relationship</data>
  <data key="d7">7</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="adaptive modules" target="training parameters">
  <data key="d5">8.0</data>
  <data key="d6">Adaptive modules like adapters are trained by adjusting their parameters to improve task-specific performance."|&lt;"relationship</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="DyLora" target="LoRA">
  <data key="d5">6.0</data>
  <data key="d6">DyLora improves LoRA by dynamically searching for optimal rank and block size, enhancing adaptation performance.</data>
  <data key="d7">optimization, dynamic search</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="LoRA" target="KronA">
  <data key="d5">8.0</data>
  <data key="d6">KronA replaces standard SVD modules in LoRA with Kronecker product modules to improve representation power.</data>
  <data key="d7">representation, module design</data>
  <data key="d8">chunk-bc782afdd6c18f4e206e464038047556</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Reward Model" target="Content Generation Process">
  <data key="d5">9.0</data>
  <data key="d6">The reward model evaluates generated content to guide the optimization of the content generation process, improving alignment with evaluator preferences.</data>
  <data key="d7">evaluation, optimization</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Policy" target="Reinforcement Learning">
  <data key="d5">8.0</data>
  <data key="d6">The model policy is updated through reinforcement learning techniques to maximize reward, aligning model outputs with human preferences.</data>
  <data key="d7">learning, optimization</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Content Generation Process" target="Human Feedback">
  <data key="d5">7.0</data>
  <data key="d6">Human feedback is integrated into the content generation process to refine and improve model outputs based on evaluator preferences.</data>
  <data key="d7">feedback, refinement</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Partial Knowledge Update" target="Knowledge Editing">
  <data key="d5">9.0</data>
  <data key="d6">Partial knowledge update involves editing specific parameters of an LLM to incorporate new knowledge efficiently, often focusing on small subsets of parameters to avoid full retraining.</data>
  <data key="d7">efficiency, targeted update</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Editing" target="Gradient Masking">
  <data key="d5">8.0</data>
  <data key="d6">Gradient masking is a technique used to selectively update parts of an LLM during fine-tuning by masking gradients, reducing resource consumption and preventing unwanted forgetting.</data>
  <data key="d7">technique, resource efficiency</data>
  <data key="d8">chunk-ce8332c6d0b3d23f38189ff80650d4bc</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Useful in the field of biology" target="Genomic and Proteomic Data">
  <data key="d5">9.0</data>
  <data key="d6">Genomic and proteomic data are used to train LLMs for biological analysis, including function prediction and drug discovery.</data>
  <data key="d7">application, biological data</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Useful in the field of biology" target="Medical Records">
  <data key="d5">8.0</data>
  <data key="d6">Medical records are processed by LLMs for pattern recognition, diagnosis, and personalized treatment recommendations.</data>
  <data key="d7">medical data, healthcare support</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Medical Records" target="Biomedical Research">
  <data key="d5">9.0</data>
  <data key="d6">Medical records are processed by LLMs to identify patterns, support diagnoses, and assist in personalized treatments in healthcare.</data>
  <data key="d7">application, medical data</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Medical Image Analysis" target="Biomedical Research">
  <data key="d5">8.0</data>
  <data key="d6">LLMs aid in analyzing medical images like X-rays and MRIs to identify features relevant for diagnosis.</data>
  <data key="d7">AI application, medical imaging</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Earth Science" target="Spatial Analysis">
  <data key="d5">14.0</data>
  <data key="d6">Spatial analysis techniques are employed to analyze geographic data and understand environmental and societal phenomena.&lt;SEP&gt;Spatial analysis techniques are employed within Earth science to investigate environmental phenomena across different regions and scales.</data>
  <data key="d7">methodology, environmental analysis&lt;SEP&gt;methodology, geographic analysis</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Earth Science" target="Earth Observation">
  <data key="d5">16.0</data>
  <data key="d6">Earth observation datasets and tools are used to monitor and analyze climate change, land-use, and natural disasters.&lt;SEP&gt;Earth observation datasets and tools are used to monitor environmental phenomena like climate change, land use, and natural disasters.</data>
  <data key="d7">data collection, environmental monitoring&lt;SEP&gt;data, environmental monitoring</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Earth Science" target="Climate Change">
  <data key="d5">8.0</data>
  <data key="d6">Climate change is a key object of study involving environmental and atmospheric data, analyzed through Earth science methods.</data>
  <data key="d7">environmental science, climate data</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Finance and Law" target="Model Specialization">
  <data key="d5">9.0</data>
  <data key="d6">LLMs are fine-tuned with domain-specific data to understand complex terminologies and norms, ensuring accurate content generation in finance and legal fields.</data>
  <data key="d7">domain adaptation, specialized training</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Finance and Law" target="Ethical Guardrails">
  <data key="d5">7.0</data>
  <data key="d6">Implementing ethical constraints is essential for responsible AI use in high-stakes fields like finance and law.</data>
  <data key="d7">ethics, safety</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Ethical Guardrails" target="Finance">
  <data key="d5">7.0</data>
  <data key="d6">Implementing ethical constraints is crucial for responsible AI deployment in finance to ensure accuracy and compliance.</data>
  <data key="d7">ethics, safety</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Ethical Guardrails" target="Law">
  <data key="d5">7.0</data>
  <data key="d6">Legal AI systems require strict ethical guidelines to prevent misuse and ensure compliance with legal standards.</data>
  <data key="d7">ethics, regulation</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Software Engineering" target="Code Assistance">
  <data key="d5">8.0</data>
  <data key="d6">LLMs assist in code generation, bug detection, and documentation, enhancing software development processes.</data>
  <data key="d7">application, software development</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Finance" target="Model Fine-Tuning">
  <data key="d5">9.0</data>
  <data key="d6">LLMs are fine-tuned with domain-specific datasets to understand complex financial terminology and trends for accurate content generation.</data>
  <data key="d7">domain adaptation, training</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Law" target="Model Fine-Tuning">
  <data key="d5">9.0</data>
  <data key="d6">LLMs are adapted with legal datasets to comprehend laws, legal language, and court rulings for precise legal document processing.</data>
  <data key="d7">domain adaptation, training</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Balancing General and Domain Knowledge" target="Explainability and Trust">
  <data key="d5">7.0</data>
  <data key="d6">Balancing general and domain knowledge is crucial for building trustworthy and contextually appropriate language models, impacting explainability.</data>
  <data key="d7">conceptual, trust</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Adapting to Domain Evolution" target="Future Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Future techniques aim to help models keep pace with evolving domain knowledge and terminology, ensuring relevance and accuracy.</data>
  <data key="d7">adaptation, evolution</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hybrid Approaches" target="Meta-Learning or AutoML Techniques">
  <data key="d5">8.0</data>
  <data key="d6">Hybrid approaches can leverage meta-learning strategies to optimize the combination of different domain adaptation methods, improving efficiency.</data>
  <data key="d7">optimization, resource efficiency</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Incorporating More Explicit World Knowledge" target="Future Techniques">
  <data key="d5">9.0</data>
  <data key="d6">Incorporating structured knowledge sources like knowledge graphs can enhance model reasoning and accuracy in domain-specific tasks.</data>
  <data key="d7">knowledge integration, model reasoning</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Human-in-the-loop Learning" target="Active Learning">
  <data key="d5">18.0</data>
  <data key="d6">Human feedback facilitates active learning by providing targeted information, improving model accuracy and domain understanding.&lt;SEP&gt;Human feedback guides active learning processes, allowing models to query and incorporate new domain knowledge actively.</data>
  <data key="d7">feedback, knowledge acquisition&lt;SEP&gt;feedback, targeted learning</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Future Techniques" target="Challenges of Domain Specialization">
  <data key="d5">7.0</data>
  <data key="d6">Research Questions/Hypotheses</data>
  <data key="d7">Addressing the challenges identified in domain adaptation requires exploring new techniques and strategies.</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain Evolution" target="Model Adaptation">
  <data key="d5">9.0</data>
  <data key="d6">Models need to adapt continuously to domain evolution to maintain relevance and accuracy.</data>
  <data key="d7">adaptation, relevance</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Model Adaptation" target="Model Relevance">
  <data key="d5">8.0</data>
  <data key="d6">Successful adaptation to domain evolution increases the relevance and utility of models over time.</data>
  <data key="d7">relevance, adaptation</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hybrid Approach" target="Meta-Learning">
  <data key="d5">8.0</data>
  <data key="d6">Hybrid approaches can leverage meta-learning to optimize the combination of different modeling strategies for better performance and resource efficiency.</data>
  <data key="d7">optimization, resource management</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Graphs in LLMs" target="Model Relevance">
  <data key="d5">9.0</data>
  <data key="d6">Incorporating structured knowledge sources like knowledge graphs enhances the relevance and reasoning capabilities of domain-specific models.</data>
  <data key="d7">knowledge integration, reasoning</data>
  <data key="d8">chunk-8405c501f648b7138a3c272cd94a6fd5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Medical Ontology" target="Knowledge Elicitation">
  <data key="d5">16.0</data>
  <data key="d6">Medical ontologies are used as a formalized source of domain knowledge to facilitate knowledge elicitation processes.&lt;SEP&gt;Medical ontologies serve as formalized sources of domain knowledge that facilitate the process of knowledge elicitation for improving LLM understanding.</data>
  <data key="d7">knowledge formalization, domain knowledge</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain-Specific Techniques" target="Challenges and Limitations">
  <data key="d5">14.0</data>
  <data key="d6">Domain-specific techniques aim to address challenges like knowledge gaps and model complexity in applying LLMs to specialized fields.&lt;SEP&gt;Domain-specific techniques are designed to address challenges like knowledge gaps, model complexity, and the need for specialized adaptation in applying LLMs to domains.</data>
  <data key="d7">problem-solving, domain adaptation</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Domain-Specific Techniques" target="Future Research Directions">
  <data key="d5">7.0</data>
  <data key="d6">Future research aims to refine techniques and address limitations in domain adaptation of LLMs.</data>
  <data key="d7">technique improvement, challenge overcoming</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Knowledge Elicitation" target="Challenges and Limitations">
  <data key="d5">8.0</data>
  <data key="d6">Effective knowledge elicitation is crucial for overcoming knowledge gaps and improving domain-specific LLM performance.</data>
  <data key="d7">knowledge gaps, expertise</data>
  <data key="d8">chunk-4068ec6ee794d8ae5ed33ac825ff37d4</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Dario Amodei" target="Fine-tuning language models from human preferences">
  <data key="d5">12.0</data>
  <data key="d6">Dario Amodei's expertise influences AI safety and model alignment practices.&lt;SEP&gt;Dario Amodei's research emphasizes AI safety and ethical considerations in model training.</data>
  <data key="d7">safety, alignment&lt;SEP&gt;safety, ethics</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Gupta, Christine Kaeser-Chen, Kenneth Marino, Arun Ahuja, Sheila Babayan, Felix Hill, and Rob Fergus" target="Collaborating with language models for embodied reasoning">
  <data key="d5">16.0</data>
  <data key="d6">The authors collectively contribute to research on language models and embodied reasoning, indicating collaboration and shared focus.&lt;SEP&gt;The authors contribute to research on language models and embodied reasoning, indicating collaboration and shared research focus.</data>
  <data key="d7">collaboration, embodied reasoning&lt;SEP&gt;collaboration, research focus</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Nicola De Cao, Wilker Aziz, and Ivan Titov" target="Editing Factual Knowledge in Language Models">
  <data key="d5">14.0</data>
  <data key="d6">These researchers focus on editing and updating factual knowledge within language models, establishing a direct link between their work and the research topic.&lt;SEP&gt;These researchers focus on methods to modify factual information within language models, indicating a relationship between researchers and the research topic.</data>
  <data key="d7">knowledge editing, NLP</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric P. Xing, and Zhiting Hu" target="RLPrompt">
  <data key="d5">16.0</data>
  <data key="d6">The team developed RLPrompt, a reinforcement learning approach to optimize prompts, directly linking researchers with the methodology.&lt;SEP&gt;The team developed RLPrompt, a reinforcement learning-based approach to optimize discrete text prompts, directly connecting researchers to this methodology.</data>
  <data key="d7">reinforcement learning, prompt optimization</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova" target="Bert">
  <data key="d5">9.0</data>
  <data key="d6">These researchers co-developed BERT, a foundational language understanding model, establishing a direct relationship between authors and the model.</data>
  <data key="d7">pre-training, transformer models</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Delta tuning" target="Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al">
  <data key="d5">8.0</data>
  <data key="d6">The researchers conducted a comprehensive study on delta tuning, indicating their direct involvement with this methodology.</data>
  <data key="d7">parameter-efficient tuning, NLP</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Dheeru Dua, Shivanshu Gupta, Sameer Singh, and Matt Gardner" target="Decomposing Complex Questions">
  <data key="d5">16.0</data>
  <data key="d6">These researchers focus on successive prompting techniques to decompose complex questions, linking them to this methodology in NLP.&lt;SEP&gt;They are exploring successive prompting techniques to decompose complex questions, establishing a relationship between researchers and the methodology.</data>
  <data key="d7">prompt engineering, question decomposition&lt;SEP&gt;question decomposition, prompt engineering</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Ali Edalati, Marzieh Tahaei, Ivan Kobyzev, Vahid Partovi Nia, James J Clark, and Mehdi Rezagholizadeh" target="KronA">
  <data key="d5">16.0</data>
  <data key="d6">The researchers developed KronA, a parameter-efficient tuning method based on Kronecker products, directly linking them to this approach.&lt;SEP&gt;These researchers developed KronA, a parameter-efficient tuning method using Kronecker adapters, directly linking them to this methodology.</data>
  <data key="d7">parameter-efficient tuning, adapters</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick Pérez, and Raoul de Charette" target="P{\O}DA">
  <data key="d5">16.0</data>
  <data key="d6">The team introduced P{\O}DA, a prompt-driven zero-shot domain adaptation approach, connecting researchers to this technique.&lt;SEP&gt;The team introduced P{\O}DA, a prompt-driven zero-shot domain adaptation framework, establishing a direct link between researchers and this methodology.</data>
  <data key="d7">domain adaptation, zero-shot learning</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Yang Feng, Shiyue Zhang, Andi Zhang, Dong Wang, and Andrew Abel" target="Memory-augmented Neural Machine Translation">
  <data key="d5">16.0</data>
  <data key="d6">The authors focus on memory-augmented NMT models, establishing their relationship to this methodology.&lt;SEP&gt;The authors focus on memory-augmented NMT models, linking them to this methodology for improving translation tasks.</data>
  <data key="d7">neural translation, external memory&lt;SEP&gt;neural translation, memory</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig" target="PAL">
  <data key="d5">16.0</data>
  <data key="d6">Researchers are developing PAL: program-aided language models, directly connecting them to this methodology for reasoning and task performance.&lt;SEP&gt;Researchers are developing program-aided language models (PAL) to enhance reasoning, directly linking them to this approach.</data>
  <data key="d7">program-aided models, reasoning&lt;SEP&gt;program-aided models, reasoning enhancement</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Chunjiang Ge, Rui Huang, Mixue Xie, Zihang Lai, Shiji Song, Shuang Li, and Gao Huang" target="Domain Adaptation via Prompt Learning">
  <data key="d5">16.0</data>
  <data key="d6">Researchers focus on adapting models to specific domains through prompt learning techniques, establishing a direct relationship.&lt;SEP&gt;Researchers focus on domain adaptation using prompt learning techniques, establishing a direct relationship.</data>
  <data key="d7">domain adaptation, prompt learning&lt;SEP&gt;domain adaptation, prompt tuning</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Edouard Grave, Armand Joulin, and Nicolas Usunier" target="Neural Language Models with Cache">
  <data key="d5">16.0</data>
  <data key="d6">The researchers improved neural language models by adding a continuous cache, linking this methodology to context modeling and prediction enhancement.&lt;SEP&gt;The researchers improved neural language models by integrating a continuous cache, linking them to this methodology.</data>
  <data key="d7">cache mechanisms, language modeling&lt;SEP&gt;cache, neural language models</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Yuxian Gu, Xu Han, Zhiyuan Liu, and Minlie Huang" target="Pre-trained Prompt Tuning (PPT)">
  <data key="d5">8.0</data>
  <data key="d6">The authors developed PPT for few-shot learning, connecting them directly to this methodology.</data>
  <data key="d7">few-shot learning, prompt tuning</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Yuxian Gu, Xu Han, Zhiyuan Liu, and Minlie Huang" target="PPT">
  <data key="d5">8.0</data>
  <data key="d6">The authors developed pre-trained prompt tuning (PPT) for few-shot learning, directly linking this methodology to low-resource NLP applications.</data>
  <data key="d7">prompt tuning, few-shot learning</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Xu Guo, Boyang Li, and Han Yu" target="Domain Adaptation and Generalization">
  <data key="d5">16.0</data>
  <data key="d6">These researchers study how to improve the adaptability and robustness of pretrained language models, establishing their relation to this research area.&lt;SEP&gt;These researchers work on methods to improve domain adaptation and generalization of pretrained language models, establishing their connection to robustness and transferability.</data>
  <data key="d7">domain adaptation, robustness&lt;SEP&gt;domain generalization, robustness</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hangfeng He, Hongming Zhang, and Dan Roth" target="Retrieval-based Inference">
  <data key="d5">16.0</data>
  <data key="d6">The researchers propose rethinking inference with retrieval mechanisms to improve faithfulness of large language models, establishing a relationship.&lt;SEP&gt;The researchers propose retrieval mechanisms to improve inference faithfulness and factual accuracy in large language models, establishing a relationship.</data>
  <data key="d7">retrieval, inference, faithfulness</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Shwai He, Liang Ding, Daize Dong, Miao Zhang, and Dacheng Tao" target="Sparse Adapter">
  <data key="d5">8.0</data>
  <data key="d6">The authors introduce sparse adapters to improve parameter efficiency, establishing their research connection.</data>
  <data key="d7">parameter efficiency, adapters</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Delta Tuning" target="Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al">
  <data key="d5">8.0</data>
  <data key="d6">The researchers conducted a comprehensive study on delta tuning, linking them directly to this parameter-efficient tuning methodology.</data>
  <data key="d7">parameter-efficient tuning, NLP</data>
  <data key="d8">chunk-00db2a825cc87520492b47392ed31c71</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Prompt-based Distribution Alignment" target="Domain Generalization">
  <data key="d5">16.0</data>
  <data key="d6">This technique aims to improve domain generalization by aligning data distributions through prompt-based methods, making models more robust across diverse domains.&lt;SEP&gt;This technique aims to improve domain generalization by aligning distributions in prompt-based training, making models more robust across domains.</data>
  <data key="d7">8&lt;SEP&gt;domain adaptation, distribution alignment</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Biomedical Information Access" target="GeneGPT">
  <data key="d5">16.0</data>
  <data key="d6">GeneGPT augments large language models with domain tools to improve access and retrieval of biomedical information.&lt;SEP&gt;GeneGPT augments large language models with domain-specific tools to enhance access and retrieval of biomedical information.</data>
  <data key="d7">8&lt;SEP&gt;domain-specific tools, biomedical NLP</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Scaling Laws for Neural Language Models" target="Kaplan, J. et al.">
  <data key="d5">9.0</data>
  <data key="d6">Kaplan et al. empirically investigate how model size influences performance in neural language models.</data>
  <data key="d7">research, scaling laws</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Scaling Laws for Neural Language Models" target="Kaplan, J., McCandlish, S., Henighan, T., et al.">
  <data key="d5">9.0</data>
  <data key="d6">Kaplan et al. empirically investigate how model size and training data influence performance, establishing scaling laws.</data>
  <data key="d7">research, scaling laws</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Adapter Layers" target="Efficient Neural Networks">
  <data key="d5">7.0</data>
  <data key="d6">Adapter layers like Compacter enable efficient adaptation of large language models through low-rank hypercomplex layers.</data>
  <data key="d7">model efficiency, transfer learning</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Internet-Augmented Dialogue Generation" target="Dialogue Systems">
  <data key="d5">7.0</data>
  <data key="d6">Augmenting dialogue generation with internet access enhances the system's ability to retrieve relevant external information.</data>
  <data key="d7">knowledge retrieval, dialogue enhancement</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Clinical Language Models" target="Medical NLP">
  <data key="d5">7.0</data>
  <data key="d6">Debates continue on the necessity and effectiveness of specialized clinical language models in medical NLP applications.</data>
  <data key="d7">domain-specific NLP, medical AI</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Financial Sentiment Analysis" target="Sentiment Spin">
  <data key="d5">8.0</data>
  <data key="d6">Sentiment Spin uses GPT-3 to analyze and attack financial sentiment, demonstrating NLP's application in finance.</data>
  <data key="d7">financial NLP, sentiment analysis</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Giant Frozen Language Models" target="Large-scale Models">
  <data key="d5">7.0</data>
  <data key="d6">Frozen large language models serve as foundational, unchanging bases for various downstream tasks.</data>
  <data key="d7">model deployment, foundational models</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="ChatGPT" target="GingGPT">
  <data key="d5">18.0</data>
  <data key="d6">GingGPT is built upon ChatGPT, utilizing its conversational and reasoning capabilities for solving AI tasks.&lt;SEP&gt;GingGPT is built upon ChatGPT, utilizing its conversational and reasoning capabilities to solve AI tasks."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="ChatGPT" target="Environmental Research">
  <data key="d5">8.0</data>
  <data key="d6">The application of ChatGPT aims to support and enhance environmental research activities, exploring its utility in this domain.</data>
  <data key="d7">application, interdisciplinary research</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="ChatGPT" target="Research on ChatGPT and environmental research">
  <data key="d5">8.0</data>
  <data key="d6">The study explores how ChatGPT can be utilized in environmental research contexts.</data>
  <data key="d7">application, interdisciplinary research</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Geoffrey Irving" target="Fine-tuning language models from human preferences">
  <data key="d5">12.0</data>
  <data key="d6">Geoffrey Irving supports methodologies for aligning AI models with human values.&lt;SEP&gt;Geoffrey Irving's research supports methodologies for aligning AI outputs with human values.</data>
  <data key="d7">alignment, safety</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Reiichiro Nakano" target="Researcher">
  <data key="d5">14.0</data>
  <data key="d6">Reiichiro Nakano is involved in human factors and AI research, contributing to publications on language models and human feedback mechanisms."|&lt;SEP&gt;Reiichiro Nakano is involved in research on human factors and AI, contributing to studies on language models and human-AI interaction."|</data>
  <data key="d7">research involvement, human factors</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Jacob Hilton" target="Researcher">
  <data key="d5">12.0</data>
  <data key="d6">Jacob Hilton works on AI and human-computer interaction, contributing to question-answering and feedback systems."|&lt;SEP&gt;Jacob Hilton works on AI, human-computer interaction, and question-answering systems, contributing to related publications."|</data>
  <data key="d7">research focus, AI systems</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Suchir Balaji" target="Researcher">
  <data key="d5">10.0</data>
  <data key="d6">Suchir Balaji researches AI systems, focusing on human feedback mechanisms and language model training."|&lt;SEP&gt;Suchir Balaji researches AI systems, focusing on human feedback, instruction tuning, and language model training methodologies."|</data>
  <data key="d7">research area, feedback mechanisms</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Jeff Wu" target="Researcher">
  <data key="d5">8.0</data>
  <data key="d6">Jeff Wu is involved in AI research related to language models and human feedback."|&lt;SEP&gt;Jeff Wu is involved in AI research, particularly in training language models with human feedback and improving model instruction-following capabilities."|</data>
  <data key="d7">research activity, language models</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Vineet Kosaraju" target="Researcher">
  <data key="d5">6.0</data>
  <data key="d6">Vineet Kosaraju contributes to AI research, particularly in human-AI interaction and feedback processes."|&lt;SEP&gt;Vineet Kosaraju works on human-AI interaction, feedback, and language model alignment in AI research."|</data>
  <data key="d7">research contribution, human-AI interaction</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="William Saunders" target="Researcher">
  <data key="d5">4.0</data>
  <data key="d6">William Saunders contributes to AI research, focusing on language models, human feedback, and system evaluation."|&lt;SEP&gt;William Saunders is engaged in AI research focusing on language models and feedback."|</data>
  <data key="d7">research focus, AI models</data>
  <data key="d8">chunk-f7b1fd0aca9367181c74acfbf0c25a9b</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Malik Sallam" target="Studies">
  <data key="d5">18.0</data>
  <data key="d6">Conducts systematic review on ChatGPT's utility in healthcare education, research, and practice, assessing future implications."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-8945fa45930b3a8b5decf88507c783df</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="GingGPT" target="HuggingFace">
  <data key="d5">14.0</data>
  <data key="d6">GingGPT leverages HuggingFace's platform and tools for model deployment and integration.&lt;SEP&gt;GingGPT leverages HuggingFace's platform and tools for model deployment, sharing, and integration."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="arXiv:2303.17580" target="Manuscript">
  <data key="d5">16.0</data>
  <data key="d6">The arXiv preprint details the development, methodology, and applications of GingGPT for AI task solving."|&lt;SEP&gt;The preprint describes the development, methodology, and applications of GingGPT for solving AI tasks."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hanul Shin, Jung Kwon Lee, Jaehong Kim, Jiwon Kim" target="Researcher">
  <data key="d5">12.0</data>
  <data key="d6">These authors contributed foundational research on continual learning with deep generative replay, relevant to neural information processing."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Kumar Shridhar, Alessandro Stolfo, Mrinmaya Sachan" target="Researcher">
  <data key="d5">12.0</data>
  <data key="d6">Their work on semantic decompositions relates to model distillation and reasoning capabilities in large language models."|&lt;SEP&gt;These authors' work on semantic decompositions relates to model distillation and reasoning capabilities."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Devendra Singh, Siva Reddy, Will Hamilton, Chris Dyer, Dani Yogatama" target="Researcher">
  <data key="d5">14.0</data>
  <data key="d6">Authors developed end-to-end training methods for multi-document question answering, advancing NLP retrieval and comprehension techniques."|&lt;SEP&gt;This team developed methods for end-to-end training of multi-document QA systems, relevant for NLP methodology."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, Animesh Garg" target="Researcher">
  <data key="d5">16.0</data>
  <data key="d6">Their work on ProgPrompt involves generating situated robot task plans with language models, bridging NLP and robotics."|&lt;SEP&gt;These authors created ProgPrompt, generating situated robot task plans using large language models, integrating NLP with robotics."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Yusheng Su, Xiaozhi Wang, Yujia Qin, Chi-Min Chan, Yankai Lin, Huadong Wang, Kaiyue Wen, Zhiyuan Liu, Peng Li, Juanzi Li" target="Researcher">
  <data key="d5">14.0</data>
  <data key="d6">These authors study prompt tuning transferability in NLP, impacting model adaptation methodologies."|&lt;SEP&gt;This group studies transferability of prompt tuning in NLP, impacting model adaptation techniques."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, Xipeng Qiu" target="Researcher">
  <data key="d5">16.0</data>
  <data key="d6">Authors explore black-box tuning methods for language models in MLaaS, relevant for deployment and API-based NLP solutions."|&lt;SEP&gt;Their research on black-box tuning pertains to model deployment in MLaaS environments."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Yi-Lin Sung, Jaemin Cho, Mohit Bansal" target="Researcher">
  <data key="d5">16.0</data>
  <data key="d6">Propose Ladder Side-Tuning, an efficient transfer learning methodology."|&lt;SEP&gt;Propose Ladder Side-Tuning, an efficient transfer learning technique for large models."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Dídac Surís, Sachit Menon, Carl Vondrick" target="Researcher">
  <data key="d5">18.0</data>
  <data key="d6">Authors introduce ViperGPT, combining visual inference and reasoning via Python execution."|&lt;SEP&gt;Authors introduce ViperGPT, combining visual inference with Python execution to enable reasoning."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al." target="Researcher">
  <data key="d5">16.0</data>
  <data key="d6">Developers of Llama, a highly efficient open foundation language model for NLP applications."|&lt;SEP&gt;Developers of Llama, an open and efficient foundation language model."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Mojtaba Valipour, Mehdi Rezagholizadeh, Ivan Kobyzev, Ali Ghodsi" target="Researcher">
  <data key="d5">16.0</data>
  <data key="d6">Authors of DyLoRA, a method for parameter-efficient tuning of large language models using dynamic low-rank adaptation."|&lt;SEP&gt;Their DyLoRA method enhances parameter-efficient tuning of language models."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Josef Valvoda, Ryan Cotterell, Simone Teufel" target="Researcher">
  <data key="d5">14.0</data>
  <data key="d6">Authors analyze the role of negative precedent in legal outcome prediction, linking NLP and legal studies."|&lt;SEP&gt;Authors investigate the role of negative precedent in legal outcome prediction, applying NLP techniques to legal NLP."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin" target="Researcher">
  <data key="d5">18.0</data>
  <data key="d6">Authors of 'Attention is All You Need', foundational for transformer architecture in NLP."|&lt;SEP&gt;Authors' 'Attention is All You Need' paper underpins transformer architecture, foundational for NLP."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tu Vu, Brian Lester, Noah Constant, Rami Al-Rfou, Daniel Matthew Cer" target="Researcher">
  <data key="d5">16.0</data>
  <data key="d6">Authors proposing SPoT, an approach for better frozen model adaptation via soft prompt transfer."|&lt;SEP&gt;Propose SPoT for better frozen model adaptation, impacting NLP model deployment."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Danilo Vucetic, Mohammadreza Tayaranian, Maryam Ziaeefard, James J Clark, Brett H Meyer, Warren J Gross" target="Researcher">
  <data key="d5">16.0</data>
  <data key="d6">Authors focus on efficient fine-tuning of compressed language models using learner modules."|&lt;SEP&gt;Authors focus on efficient fine-tuning of compressed language models with learners, reducing resource needs."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Zhongwei Wan, Yichun Yin, Wei Zhang, Jiaxin Shi, Lifeng Shang, Guangyong Chen, Xin Jiang, Qun Liu" target="Researcher">
  <data key="d5">16.0</data>
  <data key="d6">Authors of G-MAP, a general memory-augmented pre-trained language model tailored for domain-specific NLP tasks."|&lt;SEP&gt;Develop G-MAP, a memory-augmented pre-trained language model for domain-specific tasks."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang, Dian Yu, Shuming Shi, Zhaopeng Tu" target="Researcher">
  <data key="d5">16.0</data>
  <data key="d6">Authors working on document-level machine translation with large language models, improving translation accuracy."|&lt;SEP&gt;Work on document-level machine translation with large language models."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Ruijie Wang, Zheng Li, Dachun Sun, Shengzhong Liu, Jinning Li, Bing Yin, Tarek Abdelzaher" target="Researcher">
  <data key="d5">14.0</data>
  <data key="d6">Authors focus on learning to sample and aggregate for reasoning over temporal knowledge graphs, linking ML and graph reasoning."|&lt;SEP&gt;Authors focusing on learning to sample and aggregate for reasoning over temporal knowledge graphs, integrating ML with graph reasoning."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-0fedeaf17a30ea46b3aacf96752c0053</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Jingfeng Yang" target="SEZERO paper">
  <data key="d5">16.0</data>
  <data key="d6">Jingfeng Yang authored the paper on SEQZERO, a semantic parsing methodology involving few-shot learning.</data>
  <data key="d7">authorship, research contribution</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Haoming Jiang" target="Survey on ChatGPT">
  <data key="d5">14.0</data>
  <data key="d6">Haoming Jiang contributed to a survey regarding ChatGPT and large language models.</data>
  <data key="d7">research survey, model evaluation</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Kai-Cheng Yang" target="Credibility Rating">
  <data key="d5">18.0</data>
  <data key="d6">Kai-Cheng Yang's research involves rating news outlet credibility using large language models.</data>
  <data key="d7">application, credibility assessment</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Xianjun Yang" target="Prompt Tuning Framework">
  <data key="d5">16.0</data>
  <data key="d6">Xianjun Yang developed a unified framework for prompt tuning in language models.</data>
  <data key="d7">methodology, framework development</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Chaoning Zhang" target="Survey on Generative AI">
  <data key="d5">16.0</data>
  <data key="d6">Chaoning Zhang authored a comprehensive survey on generative AI and ChatGPT evolution.</data>
  <data key="d7">literature review, AI development</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Daniel M Ziegler" target="Preference Fine-tuning">
  <data key="d5">18.0</data>
  <data key="d6">Daniel M Ziegler worked on fine-tuning language models based on human preferences.</data>
  <data key="d7">alignment, training methodology</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Daniel M Ziegler" target="Fine-tuning language models from human preferences">
  <data key="d5">14.0</data>
  <data key="d6">Daniel M Ziegler contributed to research on AI fine-tuning methodologies based on human preferences, influencing how models are trained.&lt;SEP&gt;Daniel M Ziegler is an author of research that contributes to methodologies for refining AI models based on human feedback.</data>
  <data key="d7">methodology, AI training&lt;SEP&gt;research contribution, methodology development</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Nisan Stiennon" target="Fine-tuning language models from human preferences">
  <data key="d5">14.0</data>
  <data key="d6">Nisan Stiennon co-authored work on AI model fine-tuning, impacting how models are trained with human preferences.&lt;SEP&gt;Nisan Stiennon's work supports the development of refined AI models through preference-based training.</data>
  <data key="d7">methodology, AI training&lt;SEP&gt;model refinement, human feedback</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Jeffrey Wu" target="Fine-tuning language models from human preferences">
  <data key="d5">14.0</data>
  <data key="d6">Jeffrey Wu contributed to research on improving language models through human preference data.&lt;SEP&gt;Jeffrey Wu's research advances methods for aligning language models with human preferences.</data>
  <data key="d7">alignment, safety&lt;SEP&gt;model optimization, human feedback</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Tom B Brown" target="Fine-tuning language models from human preferences">
  <data key="d5">14.0</data>
  <data key="d6">Tom B Brown's contributions underpin large-scale AI models trained with preference-based techniques.&lt;SEP&gt;Tom B Brown's work supports the development of large language models refined by human preferences.</data>
  <data key="d7">model development, training techniques&lt;SEP&gt;model scale, training methodology</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Alec Radford" target="Fine-tuning language models from human preferences">
  <data key="d5">14.0</data>
  <data key="d6">Alec Radford's pioneering work in GPT models influences current AI fine-tuning practices.&lt;SEP&gt;Alec Radford's research underpins advanced AI language model training methodologies.</data>
  <data key="d7">model architecture, training</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Paul Christiano" target="Fine-tuning language models from human preferences">
  <data key="d5">12.0</data>
  <data key="d6">Paul Christiano's work contributes to understanding how human preferences can guide AI model training.&lt;SEP&gt;Paul Christiano's work informs theories on preferences and safety in AI models.</data>
  <data key="d7">preferences, safety</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="ChatGPT and environmental research" target="Environmental Science &amp; Technology">
  <data key="d5">8.0</data>
  <data key="d6">The article discusses how ChatGPT can be applied within environmental research, exploring its potential and implications.</data>
  <data key="d7">application, interdisciplinary research</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Environmental Science &amp; Technology" target="Research on ChatGPT and environmental research">
  <data key="d5">6.0</data>
  <data key="d6">The journal publishes research that includes applications of ChatGPT in environmental science.</data>
  <data key="d7">publication, interdisciplinary research</data>
  <data key="d8">chunk-0cdbfe705edb382a6ee1927e70804633</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Black-box Tuning" target="CMA-ES">
  <data key="d5">15.0</data>
  <data key="d6">CMA-ES is used within black-box tuning to optimize prompts in non-convex, gradient-inaccessible scenarios.&lt;SEP&gt;CMA-ES is used within black-box tuning to optimize prompts in non-convex, gradient-inaccessible scenarios."|&gt;"optimization, non-convex</data>
  <data key="d7">7&lt;SEP&gt;optimization, non-convex</data>
  <data key="d8">chunk-03d4474943225c24f9a066079ecfcaf5</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="object of study" target="Low-rank adapters">
  <data key="d5">8.0</data>
  <data key="d6">Low-rank adapters utilize low-rank matrix approximations to reduce parameters in adapter modules."|&lt;"object</data>
  <data key="d7">8</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="object of study" target="Invertible adapters">
  <data key="d5">7.0</data>
  <data key="d6">Invertible adapters are a reversible class of neural adapters inspired by autoencoders, allowing for invertible transformations."|&lt;"object</data>
  <data key="d7">7</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hypercomplex multiplication layers" target="tools">
  <data key="d5">6.0</data>
  <data key="d6">Hypercomplex multiplication layers are used within adapters like Compacters to improve parameter efficiency through learning sums of Kronecker products."|&lt;"tool</data>
  <data key="d7">6</data>
  <data key="d8">chunk-3346afc27fba0a6e366bb328d5882c1d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Deep Understanding" target="HCI and Software Engineering">
  <data key="d5">8.0</data>
  <data key="d6">LLMs are trained to understand domain-specific terminologies and workflows, improving interface design and software development tasks.</data>
  <data key="d7">domain knowledge, AI assistance</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Deep Understanding" target="HCI">
  <data key="d5">8.0</data>
  <data key="d6">LLMs are trained to understand domain-specific terminologies and workflows, improving user interface design and interaction in HCI and software engineering.</data>
  <data key="d7">domain knowledge, user experience</data>
  <data key="d8">chunk-f3c94db4d83b03209953445c36e8cb0d</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Instance-aware Prompt Learning" target="Language Understanding and Generation">
  <data key="d5">18.0</data>
  <data key="d6">This approach improves language understanding and generation by customizing prompts based on specific instances or contexts.&lt;SEP&gt;This methodology improves language understanding and generation by customizing prompts based on specific instances or contexts.</data>
  <data key="d7">9&lt;SEP&gt;prompt engineering, task-specific adaptation</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Neural Language Models" target="Scaling Laws">
  <data key="d5">9.0</data>
  <data key="d6">Scaling laws describe how increasing size and data improves neural language model performance, guiding model development.</data>
  <data key="d7">performance scaling, model size</data>
  <data key="d8">chunk-50aebbb39645b3b6929fbd72650593cd</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Detoxifying and Debiasing" target="Zonghan Yang">
  <data key="d5">16.0</data>
  <data key="d6">Zonghan Yang's work involves detoxifying and debiasing language generation via inference-time optimization.</data>
  <data key="d7">technique, model safety</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Hongbin Ye" target="Ontology-Enhanced Prompt Tuning">
  <data key="d5">16.0</data>
  <data key="d6">Hongbin Ye contributed to ontology-enhanced prompt tuning for few-shot learning.</data>
  <data key="d7">methodology, enhancement technique</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="Large Language Models Survey" target="Wayne Xin Zhao">
  <data key="d5">16.0</data>
  <data key="d6">Wayne Xin Zhao conducted a survey of large language models.</data>
  <data key="d7">overview, research synthesis</data>
  <data key="d8">chunk-fbf68cc2a5698b4c63c49f1529f3175c</data>
  <data key="d9">Domain Specialization as the Key to Make Large Language Models Disruptive - 2305.18703v7.pdf</data>
</edge>
<edge source="HumanEval" target="Codex">
  <data key="d5">16.0</data>
  <data key="d6">Codex is evaluated on HumanEval to measure its code synthesis performance, demonstrating its functional capabilities.&lt;SEP&gt;Codex is evaluated on the HumanEval set to measure its ability to synthesize correct programs from docstrings.</data>
  <data key="d7">evaluation, performance&lt;SEP&gt;evaluation, performance measurement</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="GitHub" target="Codex">
  <data key="d5">9.0</data>
  <data key="d6">Codex was trained on publicly available code from GitHub, establishing a direct data source.</data>
  <data key="d7">training data, source</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code" target="Codex">
  <data key="d5">8.0</data>
  <data key="d6">The model's training involved large datasets of code, and its performance is evaluated based on code correctness.</data>
  <data key="d7">training data, evaluation</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Sampling" target="Codex">
  <data key="d5">10.0</data>
  <data key="d6">Repeated sampling from Codex improves the likelihood of producing correct code solutions.</data>
  <data key="d7">methodology, performance</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="HumanEval dataset" target="Large Language Models trained on code">
  <data key="d5">14.0</data>
  <data key="d6">Models are evaluated on the HumanEval dataset to assess their problem-solving and code generation capabilities.&lt;SEP&gt;Models are evaluated on the HumanEval dataset to measure their problem-solving and code generation capabilities.</data>
  <data key="d7">model benchmarking, performance assessment&lt;SEP&gt;model evaluation, benchmarking</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="HumanEval dataset" target="Codex">
  <data key="d5">16.0</data>
  <data key="d6">Codex's performance is evaluated on the HumanEval dataset, which contains programming problems.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Unit Tests" target="Filtered Pass@k">
  <data key="d5">9.0</data>
  <data key="d6">Solutions passing all unit tests are used to calculate filtered pass@k, providing a more accurate correctness measure.</data>
  <data key="d7">test filtering, accuracy</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Unit Tests" target="Filtered pass@k">
  <data key="d5">9.0</data>
  <data key="d6">Solutions that pass all unit tests are used to compute filtered pass@k, providing a more accurate measure of correctness.</data>
  <data key="d7">test filtering, accuracy</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Unit Tests" target="Tufano et al. (2020)">
  <data key="d5">12.0</data>
  <data key="d6">Generation of unit tests for code to verify correctness, used in code synthesis and debugging.</data>
  <data key="d7">testing, verification</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="test-driven development" target="unit tests">
  <data key="d5">18.0</data>
  <data key="d6">Test-driven development relies on creating and passing unit tests to validate software requirements before implementation, ensuring correctness.&lt;SEP&gt;Test-driven development relies on creating and passing unit tests to validate software requirements before implementation.</data>
  <data key="d7">development methodology, validation</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="pass@kmetric" target="functional correctness">
  <data key="d5">16.0</data>
  <data key="d6">The pass@k metric measures the likelihood that at least one sample among k passes unit tests, serving as an indicator of model correctness.&lt;SEP&gt;pass@k metric evaluates the proportion of problems where at least one generated sample passes unit tests, indicating correctness.</data>
  <data key="d7">evaluation metric, code testing&lt;SEP&gt;evaluation metric, correctness</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="functional correctness" target="BLEU score">
  <data key="d5">12.0</data>
  <data key="d6">BLEU scores are used to compare generated code with reference solutions, but may not accurately reflect functional equivalence or correctness.&lt;SEP&gt;BLEU scores are used to compare generated code with reference solutions, but may not reliably indicate functional correctness.</data>
  <data key="d7">evaluation limitation&lt;SEP&gt;evaluation limitation, code similarity</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="functional correctness" target="weak test suites">
  <data key="d5">16.0</data>
  <data key="d6">Weak test suites may fail to ensure functional correctness, as they can be bypassed by deleting functionality.&lt;SEP&gt;Weak test suites may not reliably assess functional correctness, as they can be bypassed by deleting or altering functionality.</data>
  <data key="d7">test coverage, correctness</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Large Language Models trained on code" target="code fine-tuning">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning improves model performance on programming tasks by training on code datasets like GitHub solutions.&lt;SEP&gt;Fine-tuning improves model performance on programming tasks by training on datasets like GitHub solutions.</data>
  <data key="d7">training methodology, model enhancement&lt;SEP&gt;training methodology, model improvement</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Large Language Models trained on code" target="problem-solving capabilities">
  <data key="d5">6.0</data>
  <data key="d6">The models' ability to understand and solve programming problems is assessed using datasets like HumanEval.</data>
  <data key="d7">model capability, assessment</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Large Language Models trained on code" target="training datasets">
  <data key="d5">5.0</data>
  <data key="d6">Training datasets such as GitHub repositories enable models to learn coding patterns and solutions.</data>
  <data key="d7">training data, learning sources</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="sandbox environment" target="gVisor container runtime">
  <data key="d5">20.0</data>
  <data key="d6">The sandbox environment employs gVisor to securely execute untrusted code, preventing host compromise.&lt;SEP&gt;The sandbox uses gVisor to securely execute untrusted code, preventing host system compromise during evaluation.</data>
  <data key="d7">security, execution isolation</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="sandbox environment" target="security risk">
  <data key="d5">4.0</data>
  <data key="d6">Executing untrusted code poses security risks, mitigated by sandboxing techniques like gVisor.</data>
  <data key="d7">security, risk mitigation</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="training datasets" target="problem generation">
  <data key="d5">2.0</data>
  <data key="d6">Problems are created or curated from datasets, either hand-written or automatically generated, for training and evaluation.</data>
  <data key="d7">dataset curation, problem creation</data>
  <data key="d8">chunk-f37ccebb4e61f6d64cd2096830d27b04</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Fine-Tuning" target="GPT models">
  <data key="d5">18.0</data>
  <data key="d6">Fine-tuning involves training GPT models further on code data to produce models like Codex capable of code generation.</data>
  <data key="d7">training process, model adaptation</data>
  <data key="d8">chunk-fd545f17fc1dff68e5c09ae892fd670e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Fine-Tuning" target="Model Capability">
  <data key="d5">6.0</data>
  <data key="d6">Fine-tuning can enhance a model's ability to perform specific tasks, thereby influencing its overall capability.</data>
  <data key="d7">training, enhancement</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Language Modeling" target="Sample Selection">
  <data key="d5">7.0</data>
  <data key="d6">Sample selection strategies are based on heuristics like token log probability to improve language model outputs.</data>
  <data key="d7">heuristics, sample quality</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Sample Selection" target="Token Log Probability">
  <data key="d5">6.0</data>
  <data key="d6">Token log probability serves as a criterion for selecting higher-quality samples in model evaluation.</data>
  <data key="d7">evaluation metric, heuristic</data>
  <data key="d8">chunk-08628624fca4ace77b10c93f87dd3bd5</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex-12B" target="Generated code">
  <data key="d5">15.0</data>
  <data key="d6">Codex-12B generates code outputs based on its training, with occurrences of identical code snippets being extremely rare, indicating model generalization rather than memorization."|&lt;SEP&gt;Codex-12B produces code outputs based on learned patterns, with occurrences of exact matches to training snippets being extremely rare, indicating generalization."|</data>
  <data key="d7">model output&lt;SEP&gt;model output, training data</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Supervised Fine-Tuning" target="Problems from Competitive Programming">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning on problems from competitive programming websites enhances models' ability to generate correct solutions by training on high-quality, well-structured datasets.&lt;SEP&gt;Fine-tuning on problems from competitive programming websites improves model accuracy by providing high-quality, well-structured examples.</data>
  <data key="d7">training data, performance enhancement&lt;SEP&gt;training data, performance improvement</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Supervised Fine-Tuning" target="Problems from Continuous Integration">
  <data key="d5">14.0</data>
  <data key="d6">Collecting input/output traces from open-source projects enables targeted fine-tuning to improve model performance.&lt;SEP&gt;Using input/output traces from open-source projects during CI helps adapt models to real-world code and improve accuracy.</data>
  <data key="d7">dataset creation, model adaptation&lt;SEP&gt;dataset creation, model improvement</data>
  <data key="d8">chunk-b15d5bb768f451028654d71370cc6879</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="examples" target="vowels">
  <data key="d5">6.0</data>
  <data key="d6">Sample function calls demonstrate how the vowel counting function behaves with different inputs, illustrating its application."|&gt;"application, testing</data>
  <data key="d7">6</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="examples" target="multiply">
  <data key="d5">5.0</data>
  <data key="d6">a, b</data>
  <data key="d7">Sample inputs for the multiply function show how it should process and produce outputs based on unit digit multiplication."|&gt;"function behavior, testing</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Temperature" target="Sampling Methods">
  <data key="d5">14.0</data>
  <data key="d6">Adjusting temperature alters the confidence distribution, affecting the randomness and diversity of token sampling.&lt;SEP&gt;Temperature adjusts the confidence level in token sampling, affecting diversity and predictability of generated text.</data>
  <data key="d7">diversity control, prediction variability&lt;SEP&gt;sampling variability, confidence adjustment</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Training Dataset" target="Model">
  <data key="d5">16.0</data>
  <data key="d6">The training dataset comprising problems, solutions, and docstrings is used to train models like Codex-D for code and docstring generation.</data>
  <data key="d7">training data, model training</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Training Dataset" target="Validation Dataset">
  <data key="d5">8.0</data>
  <data key="d6">The validation dataset is a separate subset (5%) of the training data, used to evaluate model performance during training.</data>
  <data key="d7">dataset division, evaluation</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Back-Translation" target="Sample Ranking">
  <data key="d5">12.0</data>
  <data key="d6">Back-translation is used as a technique to rank generated samples based on their quality, though it underperforms mean log-probability ranking in some cases.</data>
  <data key="d7">evaluation technique, sample selection</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Negative Log-Likelihood" target="Model">
  <data key="d5">14.0</data>
  <data key="d6">Negative log-likelihood minimization is the training objective for Codex and Codex-D, guiding the models to generate accurate reference solutions and docstrings.</data>
  <data key="d7">training method, optimization</data>
  <data key="d8">chunk-9ff3c43f969888578a1b963a36023834</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Python code on GitHub" target="Codex">
  <data key="d5">17.0</data>
  <data key="d6">The training data for Codex consists of publicly available Python code, enabling it to learn programming patterns and syntax.&lt;SEP&gt;The training dataset for Codex consists of publicly available Python code, enabling its learning and performance.</data>
  <data key="d7">training data, code learning&lt;SEP&gt;training data, learning</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code generation models" target="Performance metrics">
  <data key="d5">15.0</data>
  <data key="d6">Models are evaluated based on pass rates, which decline exponentially with increased prompt complexity, indicating performance degradation.&lt;SEP&gt;The models are evaluated based on pass rates, with performance decreasing exponentially as task complexity increases.</data>
  <data key="d7">evaluation, performance&lt;SEP&gt;performance evaluation, complexity</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Back-translation" target="Mean log-probability ranking">
  <data key="d5">13.0</data>
  <data key="d6">Back-translation is a heuristic that underperforms compared to likelihood ranking but still outperforms random methods in sample quality.&lt;SEP&gt;Back-translation underperforms compared to mean log-probability ranking in sample ranking tasks, though it outperforms random ranking.</data>
  <data key="d7">ranking methods, performance comparison&lt;SEP&gt;ranking techniques, performance comparison</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Hazard analysis" target="Safety challenges">
  <data key="d5">21.0</data>
  <data key="d6">Hazard analysis identifies risks such as unsafe code, misalignment with user intent, and societal hazards, informing safety considerations.&lt;SEP&gt;Hazard analysis identifies safety and societal risks like unsafe code, misalignment, and misuse potential, informing safety protocols.</data>
  <data key="d7">risk assessment, safety</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Societal impacts" target="Broader impacts">
  <data key="d5">15.0</data>
  <data key="d6">The analysis discusses both beneficial and hazardous societal impacts of Codex, emphasizing the importance of safety considerations.</data>
  <data key="d7">impact analysis, societal implications</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Performance metrics" target="Synthetic problem dataset">
  <data key="d5">12.0</data>
  <data key="d6">The dataset reveals that as the number of chained components increases, Codex's success rate decreases exponentially, demonstrating performance degradation.</data>
  <data key="d7">performance evaluation, complexity</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Societal hazards" target="Broader impacts">
  <data key="d5">14.0</data>
  <data key="d6">Societal hazards such as misuse and unsafe code are identified as key risks associated with Codex's deployment.</data>
  <data key="d7">societal impact, safety risks</data>
  <data key="d8">chunk-d25502af8737c59d857916af40cc4020</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="training distribution" target="Bias and representation">
  <data key="d5">8.0</data>
  <data key="d6">Bias and representation issues are influenced by the training data distribution and can lead to harmful outputs.</data>
  <data key="d7">data influence, societal bias</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="human oversight" target="Empirical investigation">
  <data key="d5">6.0</data>
  <data key="d6">Empirical investigation aims to determine how best to implement human oversight to ensure safety.</data>
  <data key="d7">research, safety practices</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Safety Features" target="Impact Analysis">
  <data key="d5">8.0</data>
  <data key="d6">Implementing safety features directly influences the outcomes of impact analysis by reducing potential harms and improving safety.</data>
  <data key="d7">safety, impact, risk reduction</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Impact Analysis" target="Risks">
  <data key="d5">9.0</data>
  <data key="d6">Impact analysis evaluates the risks associated with model deployment to inform safety measures.</data>
  <data key="d7">risk assessment, safety evaluation</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Over-reliance" target="Safety features">
  <data key="d5">9.0</data>
  <data key="d6">Over-reliance increases safety risks, highlighting the importance of safety features and oversight.</data>
  <data key="d7">risk management, safety concern</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Over-reliance" target="Human Oversight">
  <data key="d5">8.0</data>
  <data key="d6">Over-reliance increases the necessity for human oversight to mitigate safety risks.</data>
  <data key="d7">user dependence, safety oversight</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Misalignment" target="user's intentions">
  <data key="d5">9.0</data>
  <data key="d6">Misalignment occurs when models generate outputs that do not align with the user's intended task, leading to potential safety issues.</data>
  <data key="d7">user intent, output discrepancy</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Misalignment" target="User's Intentions">
  <data key="d5">9.0</data>
  <data key="d6">Misalignment occurs when models generate outputs that do not align with the user's true intentions, leading to safety concerns.</data>
  <data key="d7">intent mismatch, safety risk</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Empirical Investigation" target="Safety Practices">
  <data key="d5">7.0</data>
  <data key="d6">Empirical investigation helps identify effective safety practices and vigilance methods across different user scenarios.</data>
  <data key="d7">research, safety, vigilance</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Human Oversight" target="Safety and Risk Management">
  <data key="d5">8.0</data>
  <data key="d6">Human oversight is crucial for managing safety and mitigating risks, especially in complex or subtle situations.</data>
  <data key="d7">monitoring, safety management</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Automation Bias" target="User Experience">
  <data key="d5">7.0</data>
  <data key="d6">Automation bias affects user trust and reliance on models, which can impact safety if not properly addressed.</data>
  <data key="d7">trust, reliance, safety</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Limitations" target="Safety Risks">
  <data key="d5">9.0</data>
  <data key="d6">Limitations of models contribute directly to safety risks, such as suggesting insecure code or producing incorrect results.</data>
  <data key="d7">weaknesses, safety</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Limitations" target="Potential for Malicious Suggestion">
  <data key="d5">8.0</data>
  <data key="d6">Codex's inability to reliably detect vulnerabilities or avoid suggesting insecure code indicates a risk for malicious exploitation.</data>
  <data key="d7">security risk, model limitations</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Limitations" target="Codex">
  <data key="d5">8.0</data>
  <data key="d6">Codex's tendency to suggest insecure code or dependencies indicates risks for malicious exploitation and underscores its limitations.</data>
  <data key="d7">security vulnerability, model weakness</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="User Experience" target="Safety and Vigilance">
  <data key="d5">8.0</data>
  <data key="d6">User experience factors like trust and reliance influence the level of vigilance needed for safe use.</data>
  <data key="d7">trust, vigilance, safety</data>
  <data key="d8">chunk-eec372249525c58f53cd0e9c24744ffb</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias and Representation Issues" target="Filtration or Modulation of Outputs">
  <data key="d5">14.0</data>
  <data key="d6">Implementing filtration and moderation can help address bias and safety issues in generated code, reducing risks.</data>
  <data key="d7">risk mitigation, safety</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Economic and Labor Market Impacts" target="Software-Related Tasks">
  <data key="d5">12.0</data>
  <data key="d6">Increased productivity from Codex may reduce costs but also alter labor demands for programmers and developers.</data>
  <data key="d7">labor market, productivity</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Software-Related Tasks" target="Package Import Rates">
  <data key="d5">10.0</data>
  <data key="d6">Variations in package import rates influence dependency patterns and can impact software ecosystem dynamics.</data>
  <data key="d7">dependency management, software ecosystem</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Security Implications" target="Malware Development">
  <data key="d5">16.0</data>
  <data key="d6">Codex's ability to generate code can both aid in security (by finding vulnerabilities) and pose risks (by enabling malware creation).</data>
  <data key="d7">cybersecurity, malware</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Malware Development" target="Mitigation Strategies">
  <data key="d5">18.0</data>
  <data key="d6">Security measures like rate-limiting and monitoring are necessary to prevent misuse of Codex in cybercrime.</data>
  <data key="d7">security measures, misuse prevention</data>
  <data key="d8">chunk-96b489f22f60397ff887486ccf77f457</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Petaflop/s-days" target="Azure platform">
  <data key="d5">16.0</data>
  <data key="d6">The Azure platform was used to perform training and fine-tuning of the Codex-12B model, consuming large amounts of compute resources measured in petaflop/s-days."|&lt;SEP&gt;The Azure platform was used to perform training and fine-tuning of the Codex-12B model, consuming significant compute resources."|</data>
  <data key="d7">compute infrastructure, training process&lt;SEP&gt;training infrastructure</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Legal considerations" target="Fair use">
  <data key="d5">14.0</data>
  <data key="d6">Training on internet data like GitHub repositories is considered to fall under fair use, impacting legal and policy decisions."|&lt;SEP&gt;Training on internet data such as GitHub repositories is considered to fall under fair use, influencing legal and ethical deployment."|</data>
  <data key="d7">legal framework&lt;SEP&gt;legal framework, training data</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Generated code" target="Predictive weightings">
  <data key="d5">17.0</data>
  <data key="d6">Generated code is primarily influenced by the model’s internal predictive weightings, not by copying training data directly."|&lt;SEP&gt;Generated code is primarily influenced by the model’s predictive weightings rather than direct copying, ensuring originality in outputs."|</data>
  <data key="d7">model internals&lt;SEP&gt;model internals, output generation</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Environmental impact" target="Renewable energy">
  <data key="d5">16.0</data>
  <data key="d6">Using renewable energy sources like those purchased by Azure reduces the environmental impact of large-scale compute activities."|&lt;SEP&gt;Using renewable energy sources reduces the environmental footprint of large-scale compute activities, as exemplified by Microsoft’s commitments."|</data>
  <data key="d7">environmental sustainability</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Risk mitigation" target="Content controls">
  <data key="d5">18.0</data>
  <data key="d6">Implementing content filtering and user review policies helps mitigate risks such as offensive or insecure code generation."|&lt;SEP&gt;Implementing content filtering, user review, and monitoring policies helps mitigate risks like offensive or insecure code generation."|</data>
  <data key="d7">safety measures</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Deep learning resurgence" target="Program induction">
  <data key="d5">15.0</data>
  <data key="d6">Advances in deep learning have led to progress in program induction, enabling models to learn algorithmic tasks."|&lt;SEP&gt;Progress in deep learning has enabled models to learn algorithms through program induction techniques."|</data>
  <data key="d7">research progress&lt;SEP&gt;research progress, neural methods</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Deep learning resurgence" target="Program synthesis">
  <data key="d5">15.0</data>
  <data key="d6">Advances in neural network architectures have facilitated the development of program synthesis, automating code generation."|&lt;SEP&gt;Deep learning techniques have also propelled the development of program synthesis, allowing automated code generation from specifications."|</data>
  <data key="d7">research progress&lt;SEP&gt;research progress, neural methods</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Program induction" target="Neural Turing Machine">
  <data key="d5">7.0</data>
  <data key="d6">Neural Turing Machines are used to implement program induction by learning algorithmic tasks with external memory."|</data>
  <data key="d7">neural architectures</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Program induction" target="Neural GPU">
  <data key="d5">7.0</data>
  <data key="d6">Neural GPU architectures are employed to learn and execute algorithms, aiding program induction tasks."|</data>
  <data key="d7">neural architectures</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Program induction" target="Recurrent models">
  <data key="d5">7.0</data>
  <data key="d6">Recurrent neural models like the Neural Program Interpreter facilitate learning recursive algorithms, contributing to program induction capabilities."|</data>
  <data key="d7">neural architectures</data>
  <data key="d8">chunk-a17c97bd5849d0ccac2f6a28eab01a8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Program synthesis" target="Manna, Z., and Waldinger, R. J.">
  <data key="d5">28.0</data>
  <data key="d6">Their 1971 work discusses automating program synthesis processes, pioneering early research in automatic code generation.</data>
  <data key="d7">AI, program synthesis</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Utskever" target="Neural Program Interpreter">
  <data key="d5">12.0</data>
  <data key="d6">Utskever's work is associated with the development or application of neural interpreters for programs.</data>
  <data key="d7">neural program interpretation</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Differentiable Neural Computer" target="Neural Program Interpreter">
  <data key="d5">10.0</data>
  <data key="d6">The Differentiable Neural Computer is an example of a neural architecture used in program understanding tasks.</data>
  <data key="d7">neural architecture, program reasoning</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Text-to-Code Retrieval" target="Code2Seq">
  <data key="d5">16.0</data>
  <data key="d6">Code2Seq enables retrieval of code snippets based on natural language, related to text-to-code tasks.</data>
  <data key="d7">retrieval, code generation</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Latent Predictor Networks" target="Ling et al. (2016)">
  <data key="d5">12.0</data>
  <data key="d6">Demonstrated code generation for Magic the Gathering cards using character-level models aided by latent modes.</data>
  <data key="d7">code generation, latent models</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="DeepCoder" target="Balog et al. (2017)">
  <data key="d5">16.0</data>
  <data key="d6">DeepCoder trained to predict functions in source code to guide program search, improving synthesis processes.</data>
  <data key="d7">program search, function prediction</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="CodeBERT" target="Feng et al. (2020)">
  <data key="d5">14.0</data>
  <data key="d6">CodeBERT trained on docstrings and functions for code search, linking natural language and code.</data>
  <data key="d7">model training, code search</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="PyMT5" target="Clement et al. (2020)">
  <data key="d5">14.0</data>
  <data key="d6">PyMT5 trained to translate between code and language, facilitating code translation tasks.</data>
  <data key="d7">translation, multilingual models</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="SPoC" target="Kulal et al. (2019)">
  <data key="d5">12.0</data>
  <data key="d6">SPoC considers producing functionally correct code from pseudocode within a fixed compilation budget.</data>
  <data key="d7">program correctness, compilation budget</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="TransCoder" target="Lachaux et al. (2020)">
  <data key="d5">14.0</data>
  <data key="d6">TransCoder translates code between languages in an unsupervised manner, improving cross-language code understanding.</data>
  <data key="d7">unsupervised translation, cross-language</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="ContraCode" target="Jain et al. (2020)">
  <data key="d5">16.0</data>
  <data key="d6">ContraCode leverages the space of functionally correct programs to improve code modeling and inference.</data>
  <data key="d7">contrastive learning, program correctness</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="RobustFill" target="Devlin et al. (2017)">
  <data key="d5">28.0</data>
  <data key="d6">RobustFill synthesizes multiple code samples through beam search to find programs consistent with input examples, improving robustness.&lt;SEP&gt;RobustFill synthesizes multiple code samples via beam search to find consistent programs, enhancing synthesis robustness.</data>
  <data key="d7">beam search, code synthesis&lt;SEP&gt;program synthesis, beam search</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="CodeSearchNet" target="Husain et al. (2019)">
  <data key="d5">12.0</data>
  <data key="d6">CodeSearchNet provides a large dataset for benchmarking code understanding and generation models.</data>
  <data key="d7">dataset, benchmarking</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="CodeXGLUE" target="Lu et al. (2021)">
  <data key="d5">12.0</data>
  <data key="d6">CodeXGLUE aggregates multiple code benchmarks, facilitating comprehensive evaluation of code models.</data>
  <data key="d7">benchmarking, evaluation</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="APPS" target="Hendrycks et al. (2021)">
  <data key="d5">14.0</data>
  <data key="d6">APPS benchmark measures functional correctness on programming problems, used for evaluating code models.</data>
  <data key="d7">evaluation, functional correctness</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bug Fixing" target="Drain et al. (2021)">
  <data key="d5">10.0</data>
  <data key="d6">Recent works focus on locating and fixing bugs in code, using static/dynamic analysis, learned rules, or genetic programming.</data>
  <data key="d7">debugging, bug localization</data>
  <data key="d8">chunk-ba9b42eee12401dc9fac455e631a8fd8</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Korel &amp; Rilling, 1997" target="learned association rules">
  <data key="d5">6.0</data>
  <data key="d6">Reference to foundational work on association rules applied in debugging contexts.</data>
  <data key="d7">reference, foundational knowledge</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="learned association rules" target="test suite">
  <data key="d5">11.0</data>
  <data key="d6">Association rules can inform the design of test suites to better evaluate program correctness.&lt;SEP&gt;Test suites are used to evaluate the correctness of program suggestions derived from learned association rules.</data>
  <data key="d7">evaluation, debugging&lt;SEP&gt;testing, debugging</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="genetic programming" target="test suite">
  <data key="d5">11.0</data>
  <data key="d6">Genetic programming approaches rely on test suites to validate generated programs.&lt;SEP&gt;Genetic programming approaches rely on test suites to validate generated solutions.</data>
  <data key="d7">validation, automatic debugging&lt;SEP&gt;validation, program synthesis</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="more recent works" target="neural machine translation">
  <data key="d5">14.0</data>
  <data key="d6">Recent bug-fixing approaches model the task as neural machine translation from buggy to corrected code.&lt;SEP&gt;Recent studies consider bug-fixing as neural machine translation from buggy to correct code.</data>
  <data key="d7">machine translation, bug fixing</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="neural machine translation" target="exact match">
  <data key="d5">12.0</data>
  <data key="d6">Models are evaluated based on their ability to produce an exact match against reference solutions.&lt;SEP&gt;Neural machine translation models are evaluated against exact matches to reference solutions.</data>
  <data key="d7">evaluation, accuracy</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="training large language models" target="natural language docstrings">
  <data key="d5">14.0</data>
  <data key="d6">Models are trained on datasets containing natural language descriptions to generate code bodies.&lt;SEP&gt;Models are trained on datasets containing natural language docstrings to learn code generation.</data>
  <data key="d7">training data, code generation&lt;SEP&gt;training data, code synthesis</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="fine-tuning GPT" target="dataset of human-written problems">
  <data key="d5">16.0</data>
  <data key="d6">Fine-tuning GPT involves training on datasets of human-written problems to improve code synthesis.&lt;SEP&gt;Fine-tuning involves training GPT on datasets of human-written programming problems to improve performance.</data>
  <data key="d7">model training, dataset</data>
  <data key="d8">chunk-66bca7f3ed0b2cecb27fd3dceca5cb83</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Graves, A." target="2012 34th International Conference on Software Engineering (ICSE)">
  <data key="d5">12.0</data>
  <data key="d6">The conference proceedings include research on neural network architectures, sequence generation, and software engineering methodologies.&lt;SEP&gt;The conference proceedings include research on neural networks and software engineering methodologies.</data>
  <data key="d7">conference, research topics</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Graves, A." target="Neural Turing Machines">
  <data key="d5">16.0</data>
  <data key="d6">Graves, A. introduced neural Turing machines as a novel computational model combining neural networks with external memory.&lt;SEP&gt;Graves, A. introduced neural Turing machines as a novel computational model.</data>
  <data key="d7">research contribution, model&lt;SEP&gt;research contribution, model introduction</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Gulwani, S." target="Automating String Processing">
  <data key="d5">7.0</data>
  <data key="d6">Gulwani's work focuses on automating string processing tasks in spreadsheets using input-output examples.</data>
  <data key="d7">research focus, automation</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Gulwani, S." target="Automating String Processing in Spreadsheets">
  <data key="d5">7.0</data>
  <data key="d6">Gulwani's work focuses on automating string manipulation tasks in spreadsheets using input-output examples, advancing program synthesis techniques.</data>
  <data key="d7">research focus, automation</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Deberta" target="He, P. et al.">
  <data key="d5">18.0</data>
  <data key="d6">He et al. developed Deberta, an NLP model that improves language understanding with disentangled attention mechanisms.&lt;SEP&gt;He et al. developed Deberta, an NLP model that improves language understanding with disentangled attention.</data>
  <data key="d7">model development, NLP</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Helmuth, T. and Spector, L." target="General Program Synthesis Benchmark Suite">
  <data key="d5">8.0</data>
  <data key="d6">Hindley's benchmark suite is used to evaluate and compare program synthesis algorithms on diverse tasks.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="General Program Synthesis Benchmark Suite" target="Hindley, A. et al.">
  <data key="d5">8.0</data>
  <data key="d6">Hindley's benchmark suite is used to evaluate program synthesis algorithms.</data>
  <data key="d7">evaluation, benchmarking</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Hendrycks, D. et al." target="Measuring Coding Challenge Competence">
  <data key="d5">14.0</data>
  <data key="d6">Hendrycks et al. investigate how applications can objectively assess programming skills through empirical studies.&lt;SEP&gt;Hendrycks et al. investigate how apps can measure software development skills.</data>
  <data key="d7">assessment, empirical study</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Hindle, A. et al." target="The Naturalness of Software">
  <data key="d5">16.0</data>
  <data key="d6">Hindle et al. propose that software code exhibits statistical properties similar to natural language.&lt;SEP&gt;Hindle et al. propose that software exhibits statistical properties similar to natural language, influencing code comprehension and analysis.</data>
  <data key="d7">theory, language properties</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Holtzman, A. et al." target="Neural Text Degeneration">
  <data key="d5">18.0</data>
  <data key="d6">Holtzman et al. studied issues like repetition and incoherence in neural text generation.&lt;SEP&gt;Holtzman et al. studied problems like repetition and incoherence in neural text generation, and proposed mitigation strategies.</data>
  <data key="d7">research findings, model issues</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Husain, H. et al." target="Codesearchnet Challenge">
  <data key="d5">16.0</data>
  <data key="d6">Husain et al. evaluate semantic code search systems' ability to understand and retrieve code semantically.&lt;SEP&gt;Husain et al. evaluate semantic code search systems' ability to understand, retrieve, and semantically match code snippets.</data>
  <data key="d7">evaluation, code understanding</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Contrastive Code Representation Learning" target="Jain, P. et al.">
  <data key="d5">18.0</data>
  <data key="d6">Jain et al. propose a contrastive learning approach to improve semantic code representations, enhancing code understanding and retrieval.&lt;SEP&gt;Jain et al. propose contrastive learning methods to improve semantic code representations.</data>
  <data key="d7">methodology, representation learning</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Jeffrey, D. et al." target="Bugfix Tool">
  <data key="d5">8.0</data>
  <data key="d6">Jeffrey et al. developed a machine learning-based tool to assist developers in fixing bugs.</data>
  <data key="d7">tool development, bug fixing</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bugfix Tool" target="Jeffrey, D., Feng, M., Gupta, N., and Gupta, R.">
  <data key="d5">8.0</data>
  <data key="d6">Jeffrey et al. developed a machine learning-based tool to assist developers in automatically fixing bugs in code.</data>
  <data key="d7">tool development, bug fixing</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Jones, C. and Bonsignour, O." target="Economics of Software Quality">
  <data key="d5">14.0</data>
  <data key="d6">Jones and Bonsignour analyze the economic impacts and costs associated with software quality management.&lt;SEP&gt;Jones and Bonsignour analyze the economic impacts, costs, and benefits associated with software quality assurance practices.</data>
  <data key="d7">economic analysis, software quality</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Kaiser, Ł. and Sutskever, I." target="Neural Gpus">
  <data key="d5">16.0</data>
  <data key="d6">Kaiser and Sutskever introduced neural GPUs capable of learning algorithms, enabling neural networks to perform algorithmic tasks.&lt;SEP&gt;Kaiser and Sutskever introduced neural GPUs, neural network architectures capable of learning algorithms and executing complex computations.</data>
  <data key="d7">model, algorithm learning</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Kenton, Z. et al." target="Alignment of Language Agents">
  <data key="d5">8.0</data>
  <data key="d6">Kenton et al. focus on aligning AI language agents with human values and goals.</data>
  <data key="d7">alignment, AI</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Alignment of Language Agents" target="Kenton, Z., Everitt, T., Weidinger, L., et al.">
  <data key="d5">8.0</data>
  <data key="d6">Kenton et al. focus on techniques and frameworks for aligning AI language models with human values and instructions.</data>
  <data key="d7">alignment, AI</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Keskar, N. S. et al." target="Ctrl: Conditional Transformer Language Model">
  <data key="d5">8.0</data>
  <data key="d6">Keskar et al. developed Ctrl, a transformer model for controllable language generation.</data>
  <data key="d7">model, controllable generation</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Ctrl: Conditional Transformer Language Model" target="Keskar, N. S., McCann, B., Varshney, L. R., et al.">
  <data key="d5">8.0</data>
  <data key="d6">Keskar et al. developed Ctrl, a conditional transformer model allowing controllable and attribute-specific language generation.</data>
  <data key="d7">model, controllable generation</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Korel, B. and Rilling, J." target="Dynamic Slicing in Debugging">
  <data key="d5">7.0</data>
  <data key="d6">Korel and Rilling applied dynamic slicing techniques to improve program debugging processes.</data>
  <data key="d7">debugging, technique</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Korel, B. and Rilling, J." target="Dynamic Slicing in Program Debugging">
  <data key="d5">7.0</data>
  <data key="d6">Korel and Rilling applied dynamic slicing techniques to analyze program execution, improving debugging efficiency.</data>
  <data key="d7">debugging, technique</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Kulal, S. et al." target="Spoc: Search-based Pseudocode to Code">
  <data key="d5">8.0</data>
  <data key="d6">Kulal et al. created Spoc, a system for translating pseudocode into executable code using search-based methods.</data>
  <data key="d7">system, code translation</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Spoc: Search-based Pseudocode to Code" target="Kulal, S., Pasupat, P., Chandra, K., Lee, M., Padon, O., Aiken, A., and Liang, P. S.">
  <data key="d5">8.0</data>
  <data key="d6">Kulal et al. created Spoc, a system that searches for code snippets matching pseudocode descriptions to facilitate automatic code generation.</data>
  <data key="d7">system, code translation</data>
  <data key="d8">chunk-603d0ab6656c1e8cc11a81310ec387dd</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Neural Information Processing Systems" target="Wallach, H., Larochelle, H., Beygelzimer, A., d'Alchée-Buc, F., Fox, E., Garnett, R.">
  <data key="d5">14.0</data>
  <data key="d6">The proceedings volume published in 2019 contains research on neural information processing, edited by these editors.</data>
  <data key="d7">publication, conference proceedings</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="gvisor" target="Open-sourcing">
  <data key="d5">12.0</data>
  <data key="d6">Lacasse, N. contributed to the open-source project of gvisor, a sandboxed container runtime, in 2018.</data>
  <data key="d7">software development, open-source</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Unsupervised translation of programming languages" target="Research">
  <data key="d5">16.0</data>
  <data key="d6">A 2020 arXiv paper explores methods for translating programming languages without supervision, contributing to programming language processing techniques.</data>
  <data key="d7">machine learning, translation</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Latent predictor networks" target="Code generation">
  <data key="d5">18.0</data>
  <data key="d6">A 2016 ACL paper discusses latent predictor networks used for generating code, advancing AI-driven code synthesis.</data>
  <data key="d7">machine learning, NLP</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Roberta" target="Pretraining approach">
  <data key="d5">20.0</data>
  <data key="d6">Roberta is a pretraining method that improves BERT's performance, introduced in 2019.</data>
  <data key="d7">natural language processing, model optimization</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Vilbert" target="Visiolinguistic representations">
  <data key="d5">22.0</data>
  <data key="d6">Vilbert provides visiolinguistic representations for vision-and-language tasks, introduced in 2019.</data>
  <data key="d7">multimodal learning, representation</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codexglue" target="Benchmark dataset">
  <data key="d5">24.0</data>
  <data key="d6">Codexglue serves as a benchmark for code understanding and generation, released in 2021.</data>
  <data key="d7">machine learning, datasets</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Maddison, C. J., and Tarlow, D." target="Structured generative models">
  <data key="d5">26.0</data>
  <data key="d6">They developed models for generating natural source code based on structure, presented at ICML 2014.</data>
  <data key="d7">program synthesis, generative models</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Recalibrating global data center energy-use estimates" target="Energy research">
  <data key="d5">30.0</data>
  <data key="d6">The 2020 study aims to improve the accuracy of global data center energy consumption estimates, impacting energy policy and sustainability.</data>
  <data key="d7">energy consumption, data analysis</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Cryptography" target="Applied cryptography">
  <data key="d5">32.0</data>
  <data key="d6">The book provides foundational and applied cryptography knowledge, relevant to secure communications, published in 2018.</data>
  <data key="d7">security, mathematics</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Sourcefinder" target="Malware Source-Code">
  <data key="d5">7.0</data>
  <data key="d6">Sourcefinder is used to identify malware source code from repositories on GitHub, linking source code analysis to malware detection.</data>
  <data key="d7">source code analysis, cybersecurity</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Sourcefinder" target="Malware source code">
  <data key="d5">7.0</data>
  <data key="d6">Sourcefinder is used to identify malware source code from repositories, linking source code analysis to cybersecurity threats.</data>
  <data key="d7">malware detection, source code analysis</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Biological Structure and Function" target="Scaling Unsupervised Learning">
  <data key="d5">8.0</data>
  <data key="d6">Scaling techniques enable the emergence of biological structure and function insights from large biological datasets.</data>
  <data key="d7">data analysis, biological modeling</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Neural Program Synthesis" target="Poisoning Vulnerabilities">
  <data key="d5">6.0</data>
  <data key="d6">Research demonstrates vulnerabilities in neural code completion systems, indicating security risks.</data>
  <data key="d7">security, neural networks</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Neural Program Synthesis" target="Sequence to Sequence Learning">
  <data key="d5">9.0</data>
  <data key="d6">Sequence-to-sequence models underpin neural program synthesis by translating input sequences into code or other outputs.</data>
  <data key="d7">model architecture, translation</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Learning Bug-Fixing Patches" target="Neural Machine Translation">
  <data key="d5">8.0</data>
  <data key="d6">Neural machine translation techniques are applied to learn bug-fixing patches from code repositories.</data>
  <data key="d7">software engineering, machine learning</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Pixel Recurrent Neural Networks" target="Image Processing">
  <data key="d5">7.0</data>
  <data key="d6">Pixel RNNs are used for image generation and processing tasks, utilizing recurrent connections in pixel space.</data>
  <data key="d7">image analysis, neural architectures</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Attention is All You Need" target="GPT-J-6B">
  <data key="d5">18.0</data>
  <data key="d6">The transformer architecture introduced in 'Attention is All You Need' forms the basis for models like GPT-J-6B.</data>
  <data key="d7">model architecture, neural networks</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Biological structure and function" target="Scaling unsupervised learning">
  <data key="d5">8.0</data>
  <data key="d6">Scaling unsupervised learning to large biological datasets enables the emergence of biological structure and function insights.</data>
  <data key="d7">biological data, machine learning</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Neural program synthesis" target="Poisoning vulnerabilities">
  <data key="d5">6.0</data>
  <data key="d6">Vulnerabilities in neural program synthesis systems can be exploited through poisoning attacks, highlighting security concerns.</data>
  <data key="d7">security, neural networks</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Neural program synthesis" target="Sequence-to-sequence learning">
  <data key="d5">9.0</data>
  <data key="d6">Sequence-to-sequence models underpin neural program synthesis by translating input sequences into code or other outputs.</data>
  <data key="d7">model architecture, translation</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Learning bug-fixing patches" target="Neural machine translation">
  <data key="d5">8.0</data>
  <data key="d6">Neural machine translation techniques are employed to learn bug-fixing patches from code repositories, aiding automated software maintenance.</data>
  <data key="d7">software engineering, machine learning</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Pixel recurrent neural networks" target="Image processing">
  <data key="d5">7.0</data>
  <data key="d6">Pixel RNNs are used for image generation and analysis, leveraging recurrent connections in pixel space.</data>
  <data key="d7">image analysis, neural architectures</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="In-ide code generation from natural language" target="F. F. Xu, B. Vasilescu, and G. Neubig">
  <data key="d5">16.0</data>
  <data key="d6">Authors authored a paper discussing the promise and challenges of in-IDE code generation from natural language.&lt;SEP&gt;Authors researched the promise and challenges of in-IDE code generation from natural language.</data>
  <data key="d7">research, natural language processing</data>
  <data key="d8">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Yin, P., and G. Neubig" target="Syntactic neural model for general-purpose code generation">
  <data key="d5">14.0</data>
  <data key="d6">Developed a neural model that leverages syntax for broad code generation tasks.&lt;SEP&gt;Developed a neural model that leverages syntax to improve code generation across multiple tasks.</data>
  <data key="d7">model development, neural networks</data>
  <data key="d8">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="W. Zaremba and I. Sutskever" target="Learning to execute">
  <data key="d5">12.0</data>
  <data key="d6">Explored methods for systems to learn code execution.&lt;SEP&gt;Explored methods for systems to learn how to execute code, establishing foundational work in neural program learning.</data>
  <data key="d7">learning, code execution</data>
  <data key="d8">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="R. Zellers, X. Lu, J. Hessel, Y. Yu, J. S. Park, J. Cao, A. Farhadi, and Y. Choi" target="Merlot: Multimodal neural script knowledge models">
  <data key="d5">18.0</data>
  <data key="d6">Created a multimodal neural model for script understanding and knowledge.&lt;SEP&gt;Created a multimodal neural model to understand and generate script knowledge, integrating visual and textual modalities.</data>
  <data key="d7">multimodal, neural networks&lt;SEP&gt;multimodal, script knowledge</data>
  <data key="d8">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="T. Z. Zhao, E. Wallace, S. Feng, D. Klein, and S. S. Singh" target="Calibrate before use">
  <data key="d5">20.0</data>
  <data key="d6">Proposed calibration techniques to improve few-shot performance in language models.&lt;SEP&gt;Proposed calibration techniques to improve the few-shot performance of language models, enhancing their adaptability.</data>
  <data key="d7">methodology, calibration</data>
  <data key="d8">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="A. Ziegler" target="Rote learning in GitHub Copilot suggestions">
  <data key="d5">18.0</data>
  <data key="d6">Analyzed the tendency of Copilot to suggest memorized code snippets, highlighting potential issues of over-reliance on rote memorization.&lt;SEP&gt;Analyzed the tendency of Copilot to suggest memorized code snippets, highlighting potential limitations.</data>
  <data key="d7">analysis, code suggestion</data>
  <data key="d8">chunk-3ac45c735d3bc9849e74dd1a2c194b20</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="words" target="return words">
  <data key="d5">9.0</data>
  <data key="d6">The function 'return words' operates on the string of words to extract or process individual words."|</data>
  <data key="d7">text processing, string manipulation, word extraction</data>
  <data key="d8">chunk-b9d1dd3aac85f5453acff84163bfde5a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="y" target="vowels">
  <data key="d5">7.0</data>
  <data key="d6">The letter 'y' is considered a vowel only at the end of words, affecting how vowels are counted in the function.</data>
  <data key="d7">phonetic role, contextual classification</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="y" target="vowels_count">
  <data key="d5">8.0</data>
  <data key="d6">The function counts 'y' as a vowel only when it appears at the end of the word, demonstrating contextual logic."|&gt;"context-dependent vowel classification</data>
  <data key="d7">8</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="multiply" target="result">
  <data key="d5">4.0</data>
  <data key="d6">The multiply function calculates the product of the unit digits of two numbers, storing the result in a variable."|&gt;"intermediate calculation, output</data>
  <data key="d7">4</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Sample_Calls" target="Vowels">
  <data key="d5">6.0</data>
  <data key="d6">Sample calls demonstrate how the vowels_count function processes different words, illustrating its application and behavior."|&gt;"testing, application</data>
  <data key="d7">6</data>
  <data key="d8">chunk-2218fd96f193ea8c303a15bc41a21f5b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Synthesis Evaluation Framework" target="Metrics for Formal Specifications">
  <data key="d5">18.0</data>
  <data key="d6">The framework employs attributes like reasoning over states, variable dependencies, and abstraction levels to measure synthesis quality.</data>
  <data key="d7">evaluation metrics, specification complexity</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Synthesis Evaluation Framework" target="Variable Interdependencies">
  <data key="d5">14.0</data>
  <data key="d6">Understanding variable interdependencies is crucial for evaluating a system’s ability to reason about state and correctness in generated code.</data>
  <data key="d7">reasoning, correctness assessment</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Synthesis Evaluation Framework" target="Temporal Reasoning">
  <data key="d5">12.0</data>
  <data key="d6">Temporal reasoning attributes assess a model's capacity to handle program states over time, including safety and liveness properties.</data>
  <data key="d7">state reasoning, safety and liveness</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Synthesis Evaluation Framework" target="Concurrency and Parallelism">
  <data key="d5">14.0</data>
  <data key="d6">Evaluating synthesis models' ability to reason about and generate concurrent and parallel code involving synchronization and fairness.</data>
  <data key="d7">concurrency reasoning, synchronization</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Synthesis Evaluation Framework" target="Hyperproperties">
  <data key="d5">16.0</data>
  <data key="d6">Hyperproperties like noninterference are security properties that require the synthesis system to produce deterministic and secure code behaviors.</data>
  <data key="d7">security properties, determinism</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Synthesis Evaluation Framework" target="Nondeterminism">
  <data key="d5">12.0</data>
  <data key="d6">Assessing the capability of synthesis models to handle nondeterministic algorithms and processes.</data>
  <data key="d7">algorithmic variability, multiple outcomes</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Natural Language Prompts" target="High-Level Requirements">
  <data key="d5">16.0</data>
  <data key="d6">High-level requirements are often expressed as natural language prompts that pose challenges for synthesis systems due to their ambiguity and abstraction.</data>
  <data key="d7">specification abstraction, natural language processing</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="High-Level Requirements" target="Lower-Level Specifications">
  <data key="d5">8.0</data>
  <data key="d6">Lower-level specifications are derived from high-level requirements, providing detailed constraints to guide synthesis.</data>
  <data key="d7">specification refinement, constraint setting</data>
  <data key="d8">chunk-38f5b1edf9dde338a2640f132d99659a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Nondeterminism" target="ML Algorithms">
  <data key="d5">8.0</data>
  <data key="d6">ML algorithms exemplify nondeterminism by producing different outputs for the same input across executions, especially in probabilistic models.</data>
  <data key="d7">algorithm behavior, randomness</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Capability" target="Alignment">
  <data key="d5">8.0</data>
  <data key="d6">A model's capability influences its potential for alignment or misalignment, depending on whether it produces outputs matching user intent.</data>
  <data key="d7">performance, intent</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Capability" target="Model Surgery">
  <data key="d5">6.0</data>
  <data key="d6">Model surgery modifies models to improve or change capabilities, impacting their potential for task performance.</data>
  <data key="d7">modification, capability</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Task X" target="Task Y">
  <data key="d5">7.0</data>
  <data key="d6">Task Y is constructed in a way that requires the model to perform task X to solve it, used to infer the model's capabilities.</data>
  <data key="d7">task dependency, evaluation</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Capability" target="Output A">
  <data key="d5">8.0</data>
  <data key="d6">The model's capability to produce output A is central to its alignment with user preferences.</data>
  <data key="d7">performance, user satisfaction</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Capability" target="Output B">
  <data key="d5">8.0</data>
  <data key="d6">The model's ability to avoid producing output B when undesired is crucial for proper alignment.</data>
  <data key="d7">accuracy, alignment</data>
  <data key="d8">chunk-50450e84744379a5c4f059c7d4f84019</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex models" target="alignment">
  <data key="d5">8.0</data>
  <data key="d6">Codex models are evaluated for alignment to determine their ability to produce correct, helpful, and safe code outputs.</data>
  <data key="d7">model evaluation, alignment</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="alignment" target="bug-free code">
  <data key="d5">9.0</data>
  <data key="d6">Alignment aims for models to consistently produce bug-free, correct code, reducing errors and harmful outputs.</data>
  <data key="d7">quality assurance, safety</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="formal analysis" target="dataset filtering">
  <data key="d5">6.0</data>
  <data key="d6">Formal analysis techniques can identify insecure or buggy code, aiding in filtering datasets for better training."|</data>
  <data key="d7">code quality assessment, security</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="transparency tools" target="model interpretability">
  <data key="d5">8.0</data>
  <data key="d6">Transparency tools enable understanding of model decision processes, helping assess alignment and safety."|</data>
  <data key="d7">explainability, model analysis</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="planet2" target="planet_names">
  <data key="d5">6.0</data>
  <data key="d6">The variable 'planet2' is used to index into the 'planet_names' list, indicating a relationship of referencing or selection."|</data>
  <data key="d7">6</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="planet_names" target="planet1_index">
  <data key="d5">7.0</data>
  <data key="d6">The 'planet1_index' determines which planet name is selected from the list, establishing a referencing relationship."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="planet_names" target="planet2_index">
  <data key="d5">7.0</data>
  <data key="d6">Similarly, 'planet2_index' is used to select a planet name from the list, linking index to object."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="anti_shuffle" target="string">
  <data key="d5">8.0</data>
  <data key="d6">The 'anti_shuffle' function processes a string to produce an ordered version of each word, indicating a transformation or processing relationship."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="count_up_to" target="prime numbers">
  <data key="d5">8.0</data>
  <data key="d6">The 'count_up_to' function generates prime numbers less than a given number, representing a generation or enumeration relationship."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="smallest_change" target="array">
  <data key="d5">8.0</data>
  <data key="d6">The 'smallest_change' function analyzes an array to determine the minimal modifications needed to make it palindromic, indicating an analysis or transformation relationship."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Generative Models" target="Bias in Code Generation">
  <data key="d5">9.0</data>
  <data key="d6">Bias in models like Codex leads to biased code outputs, demonstrating how societal biases are encoded."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Code Generation" target="Bias Effects">
  <data key="d5">8.0</data>
  <data key="d6">Bias affects code generation, producing stereotypical or harmful code snippets."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Probes" target="Bias in Model Outputs">
  <data key="d5">9.0</data>
  <data key="d6">Probes such as def gender(x): and def race(x): reveal biases like binary gender and limited racial categories in generated code."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Assessment" target="Bias in Models">
  <data key="d5">8.0</data>
  <data key="d6">Assessment methods evaluate the extent and nature of biases in model outputs to inform mitigation."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Mitigation" target="Bias in Models">
  <data key="d5">8.0</data>
  <data key="d6">Mitigation strategies aim to reduce biases in models to prevent harmful outputs."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Natural Language Processing" target="Bias Effects">
  <data key="d5">8.0</data>
  <data key="d6">Bias effects include stereotypes and harmful representations in generated texts and code."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Effects" target="Bias in Model Outputs">
  <data key="d5">8.0</data>
  <data key="d6">Harmful stereotypes and unfair representations are consequences of bias encoding."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Effects" target="Bias Impact">
  <data key="d5">9.0</data>
  <data key="d6">Bias in models can lead to societal harms such as stereotypes and discrimination."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Language Models" target="Prompts for Classification">
  <data key="d5">8.0</data>
  <data key="d6">Prompts designed to classify social categories can lead to biased or harmful model responses.</data>
  <data key="d7">prompt influence, bias reinforcement</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Analysis" target="generative models">
  <data key="d5">9.0</data>
  <data key="d6">The bias analysis explores how models like Codex encode harmful biases, indicating a relationship of investigation or exploration."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Analysis" target="Bias Co-occurrence Tests">
  <data key="d5">7.0</data>
  <data key="d6">Co-occurrence tests are used to quantify bias in generated text or code outputs.</data>
  <data key="d7">analytical techniques, bias detection</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Text Comments" target="Bias Reinforcement">
  <data key="d5">10.0</data>
  <data key="d6">Generated comments tend to co-occur with biased or prejudiced words, indicating reinforcement of stereotypes.</data>
  <data key="d7">bias measurement, language bias</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Text Comments" target="Codex">
  <data key="d5">6.0</data>
  <data key="d6">Codex's comment generation can reflect biases similar to GPT-3, especially when explicitly prompted to describe groups.</data>
  <data key="d7">model comparison, bias detection</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Reinforcement" target="Out-of-Distribution Usage">
  <data key="d5">7.0</data>
  <data key="d6">Model responses in unfamiliar contexts tend to be more biased or harmful, indicating robustness issues.</data>
  <data key="d7">model robustness, harm potential</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Reinforcement" target="Bias in Comments">
  <data key="d5">10.0</data>
  <data key="d6">Generated comments tend to include prejudiced terms when prompted with group-related words, reinforcing stereotypes.</data>
  <data key="d7">bias in output, stereotype reinforcement</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Reinforcement" target="Out-of-Distribution Prompts">
  <data key="d5">7.0</data>
  <data key="d6">Prompts outside the training distribution tend to produce more biased or harmful outputs, indicating robustness issues.</data>
  <data key="d7">model robustness, harm potential</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Reinforcement" target="Bias in Prompts">
  <data key="d5">8.0</data>
  <data key="d6">Leading prompts for classification of social categories can cause models to produce biased or harmful responses.</data>
  <data key="d7">prompt influence, harm</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Prompts" target="Prompts for Classification">
  <data key="d5">8.0</data>
  <data key="d6">Prompts designed to classify social categories tend to induce biased or stereotyped responses from models.</data>
  <data key="d7">prompt influence, bias reinforcement</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Prompts" target="Training Datasets">
  <data key="d5">9.0</data>
  <data key="d6">Biases present in training datasets influence the model's responses and propensity to generate biased content.</data>
  <data key="d7">data influence, bias propagation</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias Evaluation Methods" target="Co-occurrence Tests">
  <data key="d5">7.0</data>
  <data key="d6">Co-occurrence tests are used to quantify and detect bias in generated text and code outputs.</data>
  <data key="d7">analytical techniques, bias detection</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias in Comments" target="Codex">
  <data key="d5">6.0</data>
  <data key="d6">Codex's comment outputs, when prompted about groups, tend to reflect biases similar to GPT-3, especially in explicit prompts.</data>
  <data key="d7">model comparison, bias detection</data>
  <data key="d8">chunk-10b08670a9cf75866c6b05fa5b5cfc12</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Threat Actors" target="Malicious Code Generation">
  <data key="d5">8.0</data>
  <data key="d6">Threat actors may use Codex to assist in creating malware or malicious components, leveraging its code generation capabilities for offensive purposes.</data>
  <data key="d7">malicious use, cybersecurity threat</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Threat Actors" target="Malware">
  <data key="d5">8.0</data>
  <data key="d6">Threat actors may leverage Codex to develop malware or malicious code components, exploiting its code generation capabilities.</data>
  <data key="d7">malicious use, threat exploitation</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Threat Actors" target="Phishing">
  <data key="d5">7.0</data>
  <data key="d6">Threat actors could use AI-generated pretexts or code to facilitate phishing attacks, making scams more convincing.</data>
  <data key="d7">social engineering, attack facilitation</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Threat Actors" target="Polymorphic Malware">
  <data key="d5">6.0</data>
  <data key="d6">Threat actors might exploit Codex to create polymorphic malware that adapts to evade detection.</data>
  <data key="d7">malware development, evasion techniques</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Malicious Code Generation" target="Codex">
  <data key="d5">7.0</data>
  <data key="d6">Codex can generate code snippets that may be incorporated into complex malicious systems, though it is not proficient at standalone malicious code.</data>
  <data key="d7">code generation, offensive potential</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Vulnerability Discovery" target="Codex">
  <data key="d5">12.0</data>
  <data key="d6">Codex's ability to identify vulnerabilities is limited and generally inferior to basic static analysis tools, reducing its immediate utility for defensive purposes.&lt;SEP&gt;Codex's performance in vulnerability detection is limited and generally inferior to basic tools, reducing its immediate defensive utility.</data>
  <data key="d7">security analysis, tool comparison&lt;SEP&gt;security assessment, tool comparison</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Supply Chain Attack" target="Codex">
  <data key="d5">17.0</data>
  <data key="d6">Codex may suggest malicious or vulnerable dependencies, especially when prompted with misspelled package names, posing supply chain risks.&lt;SEP&gt;Codex may suggest malicious or vulnerable dependencies, especially with misspelled package names, creating supply chain risks.</data>
  <data key="d7">dependency risk, attack vector&lt;SEP&gt;software security, dependency risks</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model Training and Trust Boundary" target="Adversarial Inputs">
  <data key="d5">7.0</data>
  <data key="d6">Adversarial inputs during training or use could cause Codex to suggest malicious or insecure code, increasing security risks.</data>
  <data key="d7">adversarial attack, security vulnerability</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Malware" target="Codex">
  <data key="d5">7.0</data>
  <data key="d6">Codex can assist in generating code snippets for malware components, though not fully autonomous malicious code generation.</data>
  <data key="d7">code assistance, malicious potential</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Adversarial Inputs" target="Pre-training and Fine-tuning">
  <data key="d5">8.0</data>
  <data key="d6">Adversarial prompts during training or use can cause Codex to produce malicious, insecure, or unintended outputs, increasing security risks.</data>
  <data key="d7">adversarial attack, security breach</data>
  <data key="d8">chunk-bf1121c44634b616af61c49cd3adf29a</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Cryptography Experts" target="Configuration Parameters">
  <data key="d5">18.0</data>
  <data key="d6">Cryptography experts establish and recommend secure configuration parameters to prevent insecure cryptographic practices and vulnerabilities.&lt;SEP&gt;Cryptography experts establish consensus on secure configuration parameters to prevent insecure encryption practices.</data>
  <data key="d7">expert consensus, security standards&lt;SEP&gt;expertise, standards</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Encryption Keys" target="Insecure Encryption Keys">
  <data key="d5">16.0</data>
  <data key="d6">Insecure encryption keys, such as RSA keys shorter than 2048 bits or AES in ECB mode, are identified through security testing and standards as vulnerable.&lt;SEP&gt;Insecure encryption keys, such as RSA keys shorter than 2048 bits or AES in ECB mode, are identified through security testing and standards.</data>
  <data key="d7">security vulnerabilities, cryptographic standards</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Large Language Models Trained on Code" target="Programmers and Engineers">
  <data key="d5">9.0</data>
  <data key="d6">These models influence workflows and productivity of programmers and engineers, potentially altering their work practices.</data>
  <data key="d7">workflow impact, productivity</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Large Language Models Trained on Code" target="programmers and programmers">
  <data key="d5">9.0</data>
  <data key="d6">These models influence the workflows, productivity, and skill development of programmers and developers."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Large Language Models Trained on Code" target="Code generation tools">
  <data key="d5">8.0</data>
  <data key="d6">Models like Codex are examples of code generation tools that automate programming tasks and influence coding practices."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Insecure Encryption Keys" target="Codex">
  <data key="d5">7.0</data>
  <data key="d6">Codex models sometimes produce insecure cryptographic configurations, such as short RSA keys or ECB mode AES, which are identified as insecure outputs.</data>
  <data key="d7">AI-generated vulnerabilities, security risks</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Impact on Programmers and Engineers" target="Workforce Dynamics">
  <data key="d5">8.0</data>
  <data key="d6">AI tools like Codex influence work patterns, productivity, and role distribution among programmers and engineers.</data>
  <data key="d7">automation impact, employment trends</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Workforce Dynamics" target="Impacts on Programmers and Engineers">
  <data key="d5">8.0</data>
  <data key="d6">AI tools like Codex influence programming work, potentially increasing productivity, altering roles, and creating new job categories.</data>
  <data key="d7">automation, employment, role evolution</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Insecure Configurations" target="Codex">
  <data key="d5">7.0</data>
  <data key="d6">Codex models sometimes produce insecure cryptographic configurations, like short RSA keys or ECB mode AES, which are flagged as insecure outputs.</data>
  <data key="d7">AI-generated vulnerabilities, security risks</data>
  <data key="d8">chunk-d8479e6cf592a5f52ce4d6ea93fb04e9</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Women" target="Data Science and Analysis Roles">
  <data key="d5">8.0</data>
  <data key="d6">Women are more represented in data science and analysis roles, indicating a gendered pattern in role distribution.</data>
  <data key="d7">demographic pattern, role distribution</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Economic and Security Implications" target="Differential Package Import Rates">
  <data key="d5">9.0</data>
  <data key="d6">Variations in import rates can lead to economic advantages for dominant package maintainers and security risks due to reliance on specific packages.</data>
  <data key="d7">economic, security</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Survey of Python Developers" target="Differential Package Import Rates">
  <data key="d5">7.0</data>
  <data key="d6">Survey data illustrates usage patterns that inform understanding of package popularity and import behaviors.</data>
  <data key="d7">usage patterns, data analysis</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Dependence on Code Generation Models" target="Growing reliance">
  <data key="d5">8.0</data>
  <data key="d6">Users increasingly depend on AI tools for code import decisions, which may influence programming practices over time.</data>
  <data key="d7">dependency, workflow evolution</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="users (Stack Overflow, 2020)" target="data science and analysis roles">
  <data key="d5">7.0</data>
  <data key="d6">Data from Stack Overflow indicates that women are more represented in data science and analysis roles, highlighting demographic patterns."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="women" target="data science and analysis roles">
  <data key="d5">8.0</data>
  <data key="d6">Women are disproportionately represented in data science and analysis roles compared to other technical roles."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="programmers and programmers" target="Code generation tools">
  <data key="d5">8.0</data>
  <data key="d6">Tools like Codex automate repetitive tasks, enabling broader access and shifting skill requirements."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code generation tools" target="import packages and libraries">
  <data key="d5">8.0</data>
  <data key="d6">Codex imports packages at varying rates based on training data patterns, affecting code robustness and economic outcomes."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Patterns of package import rates" target="Economic implications">
  <data key="d5">9.0</data>
  <data key="d6">Variations in import rates can lead to economic advantages for dominant package maintainers and influence security."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Patterns of package import rates" target="Security implications">
  <data key="d5">8.0</data>
  <data key="d6">Unequal import patterns may pose security risks or vulnerabilities in software systems."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Patterns of package import rates" target="Survey of Python Developers (2020)">
  <data key="d5">7.0</data>
  <data key="d6">Survey data reflects the popularity and usage patterns of packages, informing understanding of import behaviors."|</data>
  <data key="d7">7</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Impacts of differential package import rates" target="Errors and robustness">
  <data key="d5">8.0</data>
  <data key="d6">Different import patterns can cause subtle errors or increase code robustness depending on context."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Impacts of differential package import rates" target="Economic and safety impacts">
  <data key="d5">9.0</data>
  <data key="d6">The pattern of package imports affects economic power and security in the software ecosystem."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Dependence on code generation models" target="Growing reliance">
  <data key="d5">8.0</data>
  <data key="d6">As users adapt to AI-assisted coding, reliance on models like Codex for import suggestions and coding decisions increases."|</data>
  <data key="d7">8</data>
  <data key="d8">chunk-706ca7a8d3fc8406a24b8328b849606b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Machine Learning Packages" target="Codex">
  <data key="d5">16.0</data>
  <data key="d6">Codex suggests machine learning packages like TensorFlow and PyTorch, influencing user choices and market adoption.&lt;SEP&gt;Codex suggests machine learning packages like TensorFlow and PyTorch, influencing user choices and possibly entrenching certain packages in the market.</data>
  <data key="d7">recommendation influence, market entrenchment</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Generation Technologies" target="Impacts on Labor Market">
  <data key="d5">9.0</data>
  <data key="d6">The deployment of code generation tools like Codex can influence labor market outcomes, worker productivity, wages, and barriers to entry in programming.</data>
  <data key="d7">labor impact, productivity, economic implications</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Open-source Developers" target="Biases in Training Data">
  <data key="d5">12.0</data>
  <data key="d6">Open-source developers are affected by AI suggestions that may include outdated practices, influencing their maintenance efforts and resource allocation.&lt;SEP&gt;Open-source developers' resource constraints and maintenance efforts are affected by AI suggestions, especially if biases lead to outdated practices.</data>
  <data key="d7">developer workload, resource constraints</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Biases in Training Data" target="Suggestions for Deprecated Methods">
  <data key="d5">14.0</data>
  <data key="d6">Biases in training data may cause Codex to recommend deprecated or outdated methods, impacting software maintenance and backward compatibility.</data>
  <data key="d7">training bias, software maintenance</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Impacts on Labor Market" target="Codex">
  <data key="d5">11.0</data>
  <data key="d6">Codex's capabilities may lead to substitution effects in high-skill domains, affecting wages and employment patterns.</data>
  <data key="d7">substitution, labor market effects</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Future Directions" target="Impacts on Worker Productivity">
  <data key="d5">20.0</data>
  <data key="d6">Future research aims to measure how Codex impacts real-world coding performance, productivity, and quality of life for developers.&lt;SEP&gt;Future research aims to quantify how AI tools like Codex affect real-world worker productivity and quality of life.</data>
  <data key="d7">future research, productivity impacts&lt;SEP&gt;future research, productivity measurement</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Code Documentation Practices" target="Impacts on Software Quality">
  <data key="d5">12.0</data>
  <data key="d6">Codex may improve documentation practices but also propagate subtle errors, influencing downstream software quality and debugging.</data>
  <data key="d7">software quality, documentation, error propagation</data>
  <data key="d8">chunk-735818e62b066d03c2144cdb5db162c1</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Codex" target="Repeated Sampling">
  <data key="d5">10.0</data>
  <data key="d6">Repeated sampling from Codex significantly increases the likelihood of generating correct solutions, with 70.2% success using 100 samples per problem.</data>
  <data key="d7">sampling strategy, performance enhancement</data>
  <data key="d8">chunk-8fe9cc07243d88be8beafa4c1840509b</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Model" target="HPC code dataset">
  <data key="d5">7.0</data>
  <data key="d6">The HPC code dataset provides training samples for models to learn code patterns and generate pragmas.</data>
  <data key="d7">training data, code samples</data>
  <data key="d8">chunk-47d2594b07c17f257a06cf89e43eef94</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Leveson, N" target="Risk matrix">
  <data key="d5">14.0</data>
  <data key="d6">Leveson proposed improvements to the standard risk matrix to enhance risk assessment practices in 2019.</data>
  <data key="d7">risk management, safety analysis</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Li, P. L., Ko, A. J., and Begel, A" target="Software engineers">
  <data key="d5">16.0</data>
  <data key="d6">The empirical study analyzes what traits distinguish great software engineers, published in 2020.</data>
  <data key="d7">software engineering, empirical research</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Generating high fidelity images" target="Image generation">
  <data key="d5">34.0</data>
  <data key="d6">The 2018 methodology uses subscale pixel networks to generate high-fidelity images, advancing image synthesis techniques.</data>
  <data key="d7">computer vision, deep learning</data>
  <data key="d8">chunk-c97846857e436f3dd2a3ffc454f7bc5d</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="In-ide Code Generation" target="Natural Language">
  <data key="d5">8.0</data>
  <data key="d6">Natural language descriptions are used as input for in-IDE code generation models, enabling automatic code synthesis.</data>
  <data key="d7">natural language processing, code synthesis</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="AI-Based Code Generation" target="Fun and Dystopia">
  <data key="d5">6.0</data>
  <data key="d6">Explores the societal and creative implications of AI-generated code, including dystopian themes.</data>
  <data key="d7">AI ethics, societal impact</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="In-ide code generation" target="Natural language">
  <data key="d5">8.0</data>
  <data key="d6">Natural language descriptions are used as input to generate code within IDEs, enabling seamless code synthesis from natural language.</data>
  <data key="d7">natural language processing, code synthesis</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="AI-based code generation" target="Fun and dystopia">
  <data key="d5">6.0</data>
  <data key="d6">Explores societal implications, dystopian themes, and creative uses of AI-generated code.</data>
  <data key="d7">AI ethics, societal impact</data>
  <data key="d8">chunk-861fc8218eac993fbe13b418ec4b837c</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="RL from Human Feedback" target="model improvement">
  <data key="d5">10.0</data>
  <data key="d6">RLHF uses human feedback to guide models toward better alignment with user expectations and safety standards."|</data>
  <data key="d7">reinforcement learning, human input</data>
  <data key="d8">chunk-acc067e535432960edbc682652b521e0</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Content Keywords" target="Core Concepts, Theories/Models, Methodologies, Study Designs, Evidence Types, Research Questions/Hypotheses, Results, Objects of Study, Taxonomies, Variables, Tools, Analytical Techniques, Disciplines, Spatiotemporal Information, Study Populations/Dataset, Applications/Implications, Limitations">
  <data key="d5">10.0</data>
  <data key="d6">Main themes and overarching topics of the document</data>
  <data key="d7">10</data>
  <data key="d8">chunk-26540abbca06fd8f3d8be2237ce61efe</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="Bias" target="harmful outputs">
  <data key="d5">9.0</data>
  <data key="d6">Bias in models leads to harmful outputs, such as stereotypes, demonstrating a cause-effect relationship."|</data>
  <data key="d7">9</data>
  <data key="d8">chunk-18c4f75a0246b1e0b98fe72403b2ee8e</data>
  <data key="d9">Chen et al. - 2021 - Evaluating Large Language Models Trained on Code.pdf</data>
</edge>
<edge source="HPC-Coder" target="Code Completion">
  <data key="d5">16.0</data>
  <data key="d6">HPC-Coder can auto-complete HPC functions and insert parallelization directives like OpenMP pragmas.&lt;SEP&gt;HPC-Coder can automatically complete HPC functions and insert parallelization directives like OpenMP pragmas.</data>
  <data key="d7">automation, code synthesis</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC-Coder" target="OpenMP Pragmas">
  <data key="d5">14.0</data>
  <data key="d6">HPC-Coder can decorate loops with OpenMP pragmas to enable parallel execution.&lt;SEP&gt;HPC-Coder can predict and insert OpenMP pragmas to parallelize loops in HPC codes.</data>
  <data key="d7">parallelization, code annotation</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Code Completion" target="Benchmark Tasks">
  <data key="d5">9.0</data>
  <data key="d6">Code completion tasks are used as benchmarks to evaluate models' ability to generate correct code from natural language descriptions.</data>
  <data key="d7">performance evaluation, code generation</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Performance Changes in Repositories" target="Modeling Performance">
  <data key="d5">12.0</data>
  <data key="d6">The model can predict performance changes in scientific application repositories based on source code features.&lt;SEP&gt;The model can predict performance variations across different scientific code repositories based on code features.</data>
  <data key="d7">performance prediction, data analysis</data>
  <data key="d8">chunk-c17dc636d560a988c23d0b7ee6ca279c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Perplexity" target="Text Generation">
  <data key="d5">9.0</data>
  <data key="d6">Perplexity directly influences the quality and confidence of text generation, as lower perplexity indicates better model understanding and prediction.</data>
  <data key="d7">model confidence, prediction quality</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Perplexity" target="Model Confidence">
  <data key="d5">9.0</data>
  <data key="d6">Perplexity measures the model's confidence in its predictions, with lower perplexity indicating higher confidence and better understanding.</data>
  <data key="d7">model confidence, prediction quality</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Perplexity" target="Downstream Tasks">
  <data key="d5">7.0</data>
  <data key="d6">Lower perplexity generally correlates with better performance on downstream tasks, indicating more reliable predictions.</data>
  <data key="d7">performance indicator, reliability</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Perplexity" target="Optimizer Steps">
  <data key="d5">7.0</data>
  <data key="d6">Perplexity is recorded every 1000 optimizer steps, linking training progress to model uncertainty.</data>
  <data key="d7">training progress, evaluation</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Perplexity" target="Training Loss">
  <data key="d5">8.0</data>
  <data key="d6">Training loss is used to compute perplexity, which indicates how well the model fits the training data.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Text Generation" target="Sampling Methods">
  <data key="d5">8.0</data>
  <data key="d6">Sampling methods such as temperature, top-k, and nucleus sampling influence the diversity, relevance, and coherence of generated text or code.</data>
  <data key="d7">sampling control, output quality</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Token Probability" target="Sampling Methods">
  <data key="d5">8.0</data>
  <data key="d6">Sampling methods manipulate token probability distributions to control randomness and coherence in generated text.</data>
  <data key="d7">sampling control, probability distribution</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Sampling Methods" target="Top-k Sampling">
  <data key="d5">12.0</data>
  <data key="d6">Top-k sampling limits token choices to the k most probable options, balancing diversity and relevance.&lt;SEP&gt;Top-k sampling restricts token choices to the top k most probable tokens, reducing randomness and focusing generation on likely options.</data>
  <data key="d7">focused sampling, relevance&lt;SEP&gt;restricted sampling, diversity control</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="LLMs for Code Generation" target="Training Approaches">
  <data key="d5">16.0</data>
  <data key="d6">LLMs trained on source code can be adapted for code generation, prediction, and translation tasks, with specialized training strategies.&lt;SEP&gt;LLMs trained on source code can be used for code generation, prediction, and translation, often with specialized training strategies.</data>
  <data key="d7">training strategies, application&lt;SEP&gt;training strategies, source code</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="HPC Source Code Dataset" target="Data Pre-processing">
  <data key="d5">9.0</data>
  <data key="d6">Data pre-processing steps are applied to the raw dataset to ensure quality and relevance for training, including deduplication and filtering.</data>
  <data key="d7">data cleaning, dataset preparation</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Selection" target="Training Setup and Methodology">
  <data key="d5">8.0</data>
  <data key="d6">The training setup and methodology are used to select the best model for downstream HPC tasks.</data>
  <data key="d7">model selection, training methodology</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Model Confidence" target="Downstream Tasks">
  <data key="d5">8.0</data>
  <data key="d6">Model confidence impacts the effectiveness of downstream tasks like text and code generation by reflecting the model's certainty.</data>
  <data key="d7">task performance, confidence</data>
  <data key="d8">chunk-80b64c5392960c5d4c391906f60b9a2c</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Downstream Tasks" target="Fig. 1">
  <data key="d5">8.0</data>
  <data key="d6">Figure 1 illustrates the pipeline from data collection to model deployment on various tasks, showing the workflow for training and evaluation.</data>
  <data key="d7">workflow, model application</data>
  <data key="d8">chunk-e78a79fd58794ba9c2d3c38bb8b05368</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="code contests dataset" target="solutions">
  <data key="d5">14.0</data>
  <data key="d6">The solutions are collected from the code contests dataset, which aggregates data from multiple online competitions.</data>
  <data key="d7">data collection, source of solutions</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="run time" target="solutions">
  <data key="d5">18.0</data>
  <data key="d6">Run time measurements are recorded for each solution on test cases to assess efficiency and performance.&lt;SEP&gt;Run time measurements are recorded for each solution on test cases to assess efficiency.</data>
  <data key="d7">performance measurement, efficiency</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="solutions" target="pairs of solutions">
  <data key="d5">16.0</data>
  <data key="d6">Solutions are grouped into pairs solving the same problem but differing in implementation, used for comparative analysis of efficiency and coding approaches.&lt;SEP&gt;Solutions are grouped into pairs solving the same problem but differing in implementation, used for comparative analysis.</data>
  <data key="d7">pairwise comparison, performance analysis</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="AdamW" target="training">
  <data key="d5">13.0</data>
  <data key="d6">The AdamW optimizer updates model weights during training, helping to minimize loss and improve convergence.</data>
  <data key="d7">optimization, training</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="model selection" target="research questions/hypotheses">
  <data key="d5">17.0</data>
  <data key="d6">Selecting models based on architecture, size, and pre-training data addresses research questions about optimal model performance.</data>
  <data key="d7">model choice, research</data>
  <data key="d8">chunk-93a5a4d02febb50f7431a4688bb7fe2f</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Training Loss" target="Optimizer">
  <data key="d5">7.0</data>
  <data key="d6">Optimizer steps are recorded every 1000 steps, during which training loss and perplexity are measured to monitor training progress.</data>
  <data key="d7">7</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Generated Code" target="Sampling Technique">
  <data key="d5">7.0</data>
  <data key="d6">Nucleus sampling with a cutoff of 0.93 is used to generate diverse code samples from the model.</data>
  <data key="d7">7</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Generated Code" target="Parallel Frameworks">
  <data key="d5">8.0</data>
  <data key="d6">OpenMP and MPI frameworks are employed to implement and test parallel code generated by the model.</data>
  <data key="d7">8</data>
  <data key="d8">chunk-7c9dc700be1265a346cc35786ad23072</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="PolyCoder+HPC" target="Figure 9">
  <data key="d5">8.0</data>
  <data key="d6">PolyCoder+HPC produces MPI code that correctly implements parallel routines like MPI_Allreduce, showing a better understanding of distributed memory programming."|</data>
  <data key="d7">distributed computing, MPI routines</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="PolyCoder+HPC" target="Figure 10">
  <data key="d5">9.0</data>
  <data key="d6">PolyCoder+HPC achieves speedups above 1, indicating its generated code is more efficient than sequential implementations, reflecting effective parallelization."|</data>
  <data key="d7">performance, efficiency</data>
  <data key="d8">chunk-3e334e5860963a6ca1939b6719cae953</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Code Llama”" target="“Open Foundation Models for Code”">
  <data key="d5">16.0</data>
  <data key="d6">“Code Llama is an example of a foundational model for code tasks, illustrating core concepts in AI-driven code processing.”&lt;SEP&gt;“Code Llama is an example of an open foundation model designed for code tasks, representing a core concept in AI for code.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Code Llama”" target="“F. Gloeckle”">
  <data key="d5">8.0</data>
  <data key="d6">“F. Gloeckle contributed to the research and development of foundation models for code, such as Code Llama, in 2023.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Android Mobile Malware Detection”" target="“Machine Learning”">
  <data key="d5">7.0</data>
  <data key="d6">“Machine learning techniques are applied to detect malware in Android devices, as studied systematically in 2021.”</data>
  <data key="d7">7</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Android Mobile Malware Detection”" target="“J. Senanayake”">
  <data key="d5">7.0</data>
  <data key="d6">“J. Senanayake conducted a systematic review on Android malware detection using machine learning, establishing the study design and evidence base.”</data>
  <data key="d7">7</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Code Summarization”" target="“J. Gu”">
  <data key="d5">8.0</data>
  <data key="d6">“J. Gu developed models for automatic code summarization, presented at IEEE SANER 2022, contributing to methodologies for code understanding.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Code Summarization”" target="“P. Salza”">
  <data key="d5">8.0</data>
  <data key="d6">“P. Salza contributed to the development of models for automatic code summarization, presented at IEEE SANER 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Code Summarization”" target="“H. C. Gall”">
  <data key="d5">8.0</data>
  <data key="d6">“H. C. Gall contributed to research on automatic code summarization at IEEE SANER 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Transformer-Based Approach for Source Code Summarization”" target="“Semantic Similarity Metrics”">
  <data key="d5">8.0</data>
  <data key="d6">“Semantic similarity metrics are used to evaluate the quality of summaries generated by transformer models, as discussed in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Transformer-Based Approach for Source Code Summarization”" target="“W. U. Ahmad”">
  <data key="d5">8.0</data>
  <data key="d6">“W. U. Ahmad developed transformer-based models for source code summarization, published on arXiv in 2020.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Transformer-Based Approach for Source Code Summarization”" target="“S. Chakraborty”">
  <data key="d5">8.0</data>
  <data key="d6">“S. Chakraborty contributed to transformer models for code summarization, published on arXiv in 2020.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Transformer-Based Approach for Source Code Summarization”" target="“B. Ray”">
  <data key="d5">8.0</data>
  <data key="d6">“B. Ray was involved in developing transformer-based models for code summarization, published on arXiv in 2020.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Transformer-Based Approach for Source Code Summarization”" target="“K.-W. Chang”">
  <data key="d5">8.0</data>
  <data key="d6">“K.-W. Chang contributed to transformer models for code summarization, published on arXiv in 2020.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Semantic Similarity Metrics”" target="“S. Haque”">
  <data key="d5">8.0</data>
  <data key="d6">“S. Haque evaluated semantic similarity metrics for source code summarization, presented at ICPC 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Semantic Similarity Metrics”" target="“Z. Eberhart”">
  <data key="d5">8.0</data>
  <data key="d6">“Z. Eberhart contributed to evaluating semantic similarity metrics for source code summarization in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Semantic Similarity Metrics”" target="“A. Bansal”">
  <data key="d5">8.0</data>
  <data key="d6">“A. Bansal worked on developing and evaluating semantic similarity metrics for source code summaries, presented at ICPC 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Semantic Similarity Metrics”" target="“C. McMillan”">
  <data key="d5">8.0</data>
  <data key="d6">“C. McMillan contributed to the evaluation of source code summarization techniques using semantic similarity metrics in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Learning from Developer Mistakes”" target="“Learning to Reduce False Positives in Bug Detectors”">
  <data key="d5">9.0</data>
  <data key="d6">“Both explore how models can learn from real developer bug-fixes to improve bug detection accuracy, with a focus on reducing false positives in 2022.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Learning from Developer Mistakes”" target="“T. Ahmed”">
  <data key="d5">8.0</data>
  <data key="d6">“T. Ahmed explored methods for learning from real developer bug fixes to improve bug localization and repair, published in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Learning from Developer Mistakes”" target="“P. Devanbu”">
  <data key="d5">8.0</data>
  <data key="d6">“P. Devanbu collaborated with T. Ahmed on research about learning from developer mistakes to localize and repair bugs, published in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Learning from Developer Mistakes”" target="“C. Richter”">
  <data key="d5">8.0</data>
  <data key="d6">“C. Richter studied how to learn from developer mistakes to localize and repair bugs, published on arXiv in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Learning from Developer Mistakes”" target="“H. Wehrheim”">
  <data key="d5">8.0</data>
  <data key="d6">“H. Wehrheim collaborated with C. Richter on bug localization and repair research, published on arXiv in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Attention is All You Need”" target="“Large Language Models of Code”">
  <data key="d5">9.0</data>
  <data key="d6">“The Transformer architecture introduced in this paper underpins many large language models of code, enabling advanced code understanding and generation.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Large Language Models of Code”" target="“Adverse Effects of Code Duplication”">
  <data key="d5">7.0</data>
  <data key="d6">“Research indicates that code duplication can adversely affect the training and performance of large language models of code, discussed in 2019.”</data>
  <data key="d7">7</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“A. Kharkar”" target="“Limitations”">
  <data key="d5">8.0</data>
  <data key="d6">“A. Kharkar’s work on reducing false positives addresses limitations in bug detection tools, published in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“R. Z. Moghaddam”" target="“Limitations”">
  <data key="d5">8.0</data>
  <data key="d6">“R. Z. Moghaddam contributed to improving bug detection accuracy, addressing limitations in false positives, published in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“M. Jin”" target="“Limitations”">
  <data key="d5">8.0</data>
  <data key="d6">“M. Jin’s research on bug localization and repair tackles limitations in automated bug fixing, published in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“X. Liu”" target="“Limitations”">
  <data key="d5">8.0</data>
  <data key="d6">“X. Liu contributed to bug detection and repair research, addressing limitations in bug localization, published in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“X. Shi”" target="“Limitations”">
  <data key="d5">8.0</data>
  <data key="d6">“X. Shi’s work on bug localization and repair addresses existing limitations in bug detection tools, published in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“C. B. Clement”" target="“Limitations”">
  <data key="d5">8.0</data>
  <data key="d6">“C. B. Clement contributed to bug detection and repair research, focusing on limitations in bug fixing accuracy, published in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“N. Sundaresan”" target="“Limitations”">
  <data key="d5">8.0</data>
  <data key="d6">“N. Sundaresan’s work addresses limitations in bug localization and repair, published in 2022.”</data>
  <data key="d7">8</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“A. Vaswani”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“A co-author of ‘Attention is All You Need,’ foundational paper introducing the Transformer architecture, published in 2017.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“N. Shazeer”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“A co-author of the Transformer architecture paper, contributing to the attention mechanism and model design, published in 2017.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“N. Parmar”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“A co-author of ‘Attention is All You Need,’ instrumental in developing the Transformer model, published in 2017.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“J. Uszkoreit”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“A co-author of the Transformer paper, contributing to the model’s architecture, published in 2017.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“L. Jones”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“A co-author of the Transformer architecture paper, involved in attention mechanism design, published in 2017.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“A. N. Gomez”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“A co-author of the Transformer paper, contributing to the model’s development, published in 2017.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“L. Kaiser”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“A co-author of the Transformer architecture paper, involved in model design, published in 2017.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“I. Polosukhin”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“A co-author of ‘Attention is All You Need,’ key in Transformer development, published in 2017.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“U. Alon”" target="“Content_keywords”">
  <data key="d5">9.0</data>
  <data key="d6">“Evaluation of large language models of code, focusing on performance and challenges, published in 2022.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“G. Neubig”" target="“Content_keywords”">
  <data key="d5">9.0</data>
  <data key="d6">“Assessment of large language models of code, including strengths and weaknesses, published in 2022.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“V. J. Hellendoorn”" target="“Content_keywords”">
  <data key="d5">9.0</data>
  <data key="d6">“Analysis of large language models of code, their evaluation metrics, and performance in 2022.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“M. Allamanis”" target="“Limitations”">
  <data key="d5">9.0</data>
  <data key="d6">“M. Allamanis discussed how code duplication adversely affects machine learning models of code, highlighting a key limitation in 2019.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“A. Radford”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“Radford et al. introduced the concept that language models can be unsupervised multitask learners, foundational for many AI models, in 2019.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“J. Wu”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“J. Wu contributed to the development of large language models, working with Radford et al. in 2019.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“R. Child”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“R. Child collaborated on the development of large-scale language models, as part of Radford et al. 2019.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“D. Luan”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“D. Luan contributed to the creation of large language models, as described in Radford et al. 2019.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“D. Amodei”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“D. Amodei was involved in the development of large language models, as part of Radford et al. 2019.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“I. Sutskever”" target="“Theories/Models”">
  <data key="d5">9.0</data>
  <data key="d6">“I. Sutskever co-authored the foundational paper on language models, significantly influencing AI research, published in 2019.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“V. A. Dobrev”" target="“Objects of Study”">
  <data key="d5">9.0</data>
  <data key="d6">“V. A. Dobrev studies high-order curvilinear finite element methods for hydrodynamics, contributing to scientific computing.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“T. V. Kolev”" target="“Objects of Study”">
  <data key="d5">9.0</data>
  <data key="d6">“T. V. Kolev researches high-order finite element methods for scientific simulations, as published in 2012.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“R. N. Rieben”" target="“Objects of Study”">
  <data key="d5">9.0</data>
  <data key="d6">“R. N. Rieben develops numerical methods for hydrodynamics, contributing to high-order finite element techniques.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Loshchilov and Hutter 2017" target="arXiv 1711.05101">
  <data key="d5">14.0</data>
  <data key="d6">The study discusses a methodology for fixing weight decay regularization in Adam, contributing to optimization techniques."|&lt;SEP&gt;The study proposes a methodology for fixing weight decay regularization in Adam, contributing to optimization techniques in machine learning."|</data>
  <data key="d7">optimization methodology, regularization&lt;SEP&gt;optimization, regularization, machine learning</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Chen et al. 2021" target="arXiv 2021">
  <data key="d5">16.0</data>
  <data key="d6">Evaluates large language models trained on code, analyzing their performance, capabilities, and potential applications."|&lt;SEP&gt;Evaluates large language models trained on code, assessing their performance and capabilities."|</data>
  <data key="d7">language models, code understanding&lt;SEP&gt;language models, code understanding, evaluation</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Devlin et al. 2019" target="Proceedings of NAACL 2019">
  <data key="d5">18.0</data>
  <data key="d6">Developed BERT, a deep bidirectional transformer model for language understanding, influencing NLP research."|&lt;SEP&gt;Developed BERT, a pre-trained language model for understanding language, influencing NLP methodology."|</data>
  <data key="d7">language understanding, transformer models&lt;SEP&gt;language understanding, transformer models, pretraining</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Liu et al. 2019" target="arXiv 1907.11692">
  <data key="d5">16.0</data>
  <data key="d6">Proposes RoBERTa, an improved pretraining approach for BERT that enhances language model performance."|&lt;SEP&gt;Proposes RoBERTa, an optimized version of BERT, enhancing language model pretraining techniques."|</data>
  <data key="d7">model optimization, pretraining&lt;SEP&gt;model optimization, pretraining, NLP</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Wei et al. 2023" target="arXiv 2312.02120">
  <data key="d5">14.0</data>
  <data key="d6">Introduces MagicCoder, a large language model specialized for source code, with applications in code generation and understanding."|&lt;SEP&gt;Introduces MagicCoder, a source code model based on large language models, with applications in code generation."|</data>
  <data key="d7">code generation, source code models&lt;SEP&gt;source code modeling, code generation, language models</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Döderlein et al. 2022" target="arXiv 2022.14699">
  <data key="d5">12.0</data>
  <data key="d6">Analyzes pilot studies of CoPilot and Codex, focusing on prompt temperature effects and performance in code generation."|&lt;SEP&gt;Studies the piloting of CoPilot and Codex, analyzing prompt temperature effects on code generation."|</data>
  <data key="d7">AI programming tools, prompt engineering&lt;SEP&gt;AI programming tools, prompt engineering, performance analysis</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Barke et al. 2022" target="arXiv 2206.15000">
  <data key="d5">14.0</data>
  <data key="d6">Investigates how programmers interact with AI code-generating models, providing insights into human-AI collaboration."|&lt;SEP&gt;Investigates how programmers interact with code-generating models, providing insights into human-AI collaboration."|</data>
  <data key="d7">programmer interaction, AI models&lt;SEP&gt;programmer interaction, AI models, usability</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Sarkar et al. 2022" target="arXiv 2208.06213">
  <data key="d5">12.0</data>
  <data key="d6">Explores experiences of programming with AI, emphasizing human-AI interaction."|&lt;SEP&gt;Explores programmers' experiences when programming with AI assistance, emphasizing human-AI interaction."|</data>
  <data key="d7">programming experience, AI assistance&lt;SEP&gt;programming experience, AI assistance, user perception</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Chen et al. 2023" target="arXiv 2023">
  <data key="d5">16.0</data>
  <data key="d6">Develops methods for data race detection using large language models, contributing to software reliability."|&lt;SEP&gt;Develops techniques for data race detection in software using large language models, contributing to software reliability."|</data>
  <data key="d7">software testing, language models&lt;SEP&gt;software testing, language models, data race detection</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="arXiv 2023" target="Munley et al. 2023">
  <data key="d5">14.0</data>
  <data key="d6">Creates LLM-based testsuites for compiler validation, advancing compiler testing methodologies."|&lt;SEP&gt;Designs LLM-driven testsuites for compiler validation, advancing compiler testing methodologies."|</data>
  <data key="d7">compiler validation, testing tools&lt;SEP&gt;compiler validation, testing tools, software engineering</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Alon et al. 2018" target="arXiv 1803.09473">
  <data key="d5">16.0</data>
  <data key="d6">Introduces code2vec for learning distributed representations of code, impacting code analysis techniques."|&lt;SEP&gt;Introduces code2vec, a technique for learning distributed representations of source code, impacting code analysis and embedding methods."|</data>
  <data key="d7">code embeddings, source code analysis, machine learning&lt;SEP&gt;code representation, embedding techniques</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="VenkataKeerthy et al. 2020" target="ACM 2020">
  <data key="d5">14.0</data>
  <data key="d6">Presents IR2V, a scalable program embedding technique based on LLVM IR for program analysis and representation."|&lt;SEP&gt;Presents IR2V, scalable program embeddings based on LLVM IR, facilitating program analysis."|</data>
  <data key="d7">program embeddings, LLVM IR&lt;SEP&gt;program embeddings, LLVM IR, program analysis</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Garg et al. 2022" target="Proceedings of the 30th ACM JOSE 2022">
  <data key="d5">18.0</data>
  <data key="d6">Applies deep learning to improve software performance, demonstrating AI's impact on software engineering."|</data>
  <data key="d7">software performance, deep learning&lt;SEP&gt;software performance, deep learning, AI in software engineering</data>
  <data key="d8">chunk-fbc178ca51bae28816d191153e754f68</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Deepdev-perf" target="Software Performance">
  <data key="d5">8.0</data>
  <data key="d6">Deepdev-perf aims to improve software performance by applying deep learning techniques to optimize software systems.</data>
  <data key="d7">application, optimization</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Deepdev-perf" target="ACM Conference">
  <data key="d5">7.0</data>
  <data key="d6">Deepdev-perf research was presented at the conference, indicating peer-reviewed dissemination of the methodology.</data>
  <data key="d7">research dissemination, peer review</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Natural Language Generation, Translation, and Comprehension" target="Bart">
  <data key="d5">9.0</data>
  <data key="d6">Bart is designed for tasks involving natural language generation, translation, and comprehension, serving as a tool for NLP applications.</data>
  <data key="d7">tools, language processing</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="Sequence-to-Sequence Pre-training" target="Bart">
  <data key="d5">8.0</data>
  <data key="d6">Bart employs sequence-to-sequence pre-training to enhance language understanding and generation capabilities.</data>
  <data key="d7">model architecture, pre-training technique</data>
  <data key="d8">chunk-25ebcde4744e2b19ba1d5d1fd25807b0</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
<edge source="“Content_keywords”" target="“F. Xu”">
  <data key="d5">9.0</data>
  <data key="d6">“Systematic evaluation of large language models of code, highlighting their capabilities and limitations, published in 2022.”</data>
  <data key="d7">9</data>
  <data key="d8">chunk-05dc85544943f63f4078b8c41f458d49</data>
  <data key="d9">Nichols et al. - 2024 - HPC-Coder Modeling Parallel Programs using Large Language Models.pdf</data>
</edge>
</graph></graphml>